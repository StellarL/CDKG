<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136756396846250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906002%26RESULT%3d1%26SIGN%3dKjt5nqmg6%252feV6O4IQxtmw4%252fHXXo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906002&amp;v=MDkyMzdidk1MejdCZDdHNEg5ak1xWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEbFU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="1 基础介绍 ">1 基础介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="1.1 Cortex-A72&lt;b&gt;处理器介绍&lt;/b&gt;">1.1 Cortex-A72<b>处理器介绍</b></a></li>
                                                <li><a href="#43" data-title="1.2 Evalite_SGEMM&lt;b&gt;实现概述&lt;/b&gt;">1.2 Evalite_SGEMM<b>实现概述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="2 优化实现 ">2 优化实现</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="2.1 &lt;b&gt;内联汇编&lt;/b&gt;">2.1 <b>内联汇编</b></a></li>
                                                <li><a href="#63" data-title="2.2 &lt;b&gt;数据重排&lt;/b&gt;">2.2 <b>数据重排</b></a></li>
                                                <li><a href="#71" data-title="2.3 &lt;b&gt;数据预取&lt;/b&gt;">2.3 <b>数据预取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="3 测试结果与分析 ">3 测试结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="图1 Cortex-A72架构">图1 Cortex-A72架构</a></li>
                                                <li><a href="#55" data-title="图2 Cortex-A72的流水线架构">图2 Cortex-A72的流水线架构</a></li>
                                                <li><a href="#56" data-title="图3 SGEBP与SGEPDOT计算模式">图3 SGEBP与SGEPDOT计算模式</a></li>
                                                <li><a href="#59" data-title="图4 SGEBP与SGEPDOT向量计算模式">图4 SGEBP与SGEPDOT向量计算模式</a></li>
                                                <li><a href="#69" data-title="图5 矩阵&lt;b&gt;&lt;i&gt;A&lt;/i&gt;&lt;/b&gt;、&lt;b&gt;&lt;i&gt;B&lt;/i&gt;&lt;/b&gt;、&lt;b&gt;&lt;i&gt;C&lt;/i&gt;&lt;/b&gt;的重排方案">图5 矩阵<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>的重排方案</a></li>
                                                <li><a href="#76" data-title="图6 原始算法与各项优化加入后的方阵模式浮点性能对比">图6 原始算法与各项优化加入后的方阵模式浮点性能对比</a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;方阵模式下&lt;/b&gt;&lt;i&gt;Evalite&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;与&lt;/b&gt;&lt;i&gt;OpenBLAS&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;的浮点性能测试结果&lt;/b&gt;"><b>表</b>1 <b>方阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的浮点性能测试结果</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;细长矩阵模式下&lt;/b&gt;&lt;i&gt;Evalite&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;与&lt;/b&gt;&lt;i&gt;OpenBLAS&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;的 浮点性能测试结果&lt;/b&gt;"><b>表</b>2 <b>细长矩阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的 浮点性能测试结果</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;连续小矩阵模式下&lt;/b&gt;&lt;i&gt;Evalite&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;与&lt;/b&gt;&lt;i&gt;OpenBLAS&lt;/i&gt;_&lt;i&gt;SGEMM&lt;/i&gt;&lt;b&gt;的 浮点性能测试结果&lt;/b&gt;"><b>表</b>3 <b>连续小矩阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的 浮点性能测试结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="101">


                                    <a id="bibliography_1" title="AMD.AMD Core Math Library (ACML) [EB/OL].[2018-09-12].http://developer.amd.com/acml.jsp." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=AMD Core Math Library(ACML)">
                                        <b>[1]</b>
                                        AMD.AMD Core Math Library (ACML) [EB/OL].[2018-09-12].http://developer.amd.com/acml.jsp.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_2" title="FILIPPONE S.The IBM parallel engineering and scientific subroutine library[C]//Proceedings of the 1995 International Workshop on Applied Parallel Computing, LNCS 1041.Berlin:Springer, 1995:199-206." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The IBM parallel engineering and scientific subroutine library">
                                        <b>[2]</b>
                                        FILIPPONE S.The IBM parallel engineering and scientific subroutine library[C]//Proceedings of the 1995 International Workshop on Applied Parallel Computing, LNCS 1041.Berlin:Springer, 1995:199-206.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_3" title="QUINTANA-ORTI E S, IGUAL F D, CASTILLO M, et al.Evaluation and tuning of the level 3 CUBLAS for graphics processors[C]//Proceedings of the 2008 IEEE International Symposium on Parallel and Distributed Processing Symposium.Piscataway, NJ:IEEE, 2008:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evaluation and tuning of the Level 3 CUBLAS for graphics processors">
                                        <b>[3]</b>
                                        QUINTANA-ORTI E S, IGUAL F D, CASTILLO M, et al.Evaluation and tuning of the level 3 CUBLAS for graphics processors[C]//Proceedings of the 2008 IEEE International Symposium on Parallel and Distributed Processing Symposium.Piscataway, NJ:IEEE, 2008:1-8.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_4" title="GOTO K, van der GEIJN R A.Anatomy of high-performance matrix multiplication[J].ACM Transactions on Mathematical Software, 2008, 34 (3) :Article No.12." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000102085&amp;v=MzExMDdQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGNFdiaFk9TmlmSVk3SzdIdGpOcjQ5Rlplc05ESFE4b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        GOTO K, van der GEIJN R A.Anatomy of high-performance matrix multiplication[J].ACM Transactions on Mathematical Software, 2008, 34 (3) :Article No.12.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_5" title="蒋孟奇, 张云泉, 宋刚, 等.GOTOBLAS一般矩阵乘法高效实现机制的研究[J].计算机工程, 2008, 34 (7) :84-86, 103. (JIANG M Q, ZHANG Y Q, SONG G, et al.Research on high performance implementation mechanism of GOTOBLAS general matrix-matrix multiplication[J].Computer Engineering, 2008, 34 (7) :84-86, 103.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200807030&amp;v=MjU2NTh0R0ZyQ1VSN3FmWnVac0Z5RGxVYnZNTHo3QmJiRzRIdG5NcUk5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        蒋孟奇, 张云泉, 宋刚, 等.GOTOBLAS一般矩阵乘法高效实现机制的研究[J].计算机工程, 2008, 34 (7) :84-86, 103. (JIANG M Q, ZHANG Y Q, SONG G, et al.Research on high performance implementation mechanism of GOTOBLAS general matrix-matrix multiplication[J].Computer Engineering, 2008, 34 (7) :84-86, 103.) 
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                    张先轶, 王茜, 张云泉.Open BLAS:龙芯3A CPU的高性能BLAS库[J].软件学报, 2011, 22 (增刊2) :208-216. (ZHANG X Y, WANG Q, ZHANG Y Q.Open BLAS:a high performance BLAS library on Loongson 3A CPU[J].Journal of Software, 2011, 22 (Suppl.2) :208-216.) </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_7" title="CHEN B, WANG L, WU Q, et al.Cross hardware-software boundary exploration for scalable and optimized deep learning platform design[J].IEEE Embedded Systems Letters, 2018, 10 (4) :107-110." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cross hardware-software boundary exploration for scalable and optimized deep learning platform design">
                                        <b>[7]</b>
                                        CHEN B, WANG L, WU Q, et al.Cross hardware-software boundary exploration for scalable and optimized deep learning platform design[J].IEEE Embedded Systems Letters, 2018, 10 (4) :107-110.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_8" title="LIN I, JEFF B, RICKARD I.ARM platform for performance and power efficiency-hardware and software perspectives[C]//Proceedings of the 2016 International Symposium on VLSI Design, Automation and Test.Piscataway, NJ:IIEEE, 2016:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ARM Platform for Performance and Power Efficiency-Hardware and Software Perspectives">
                                        <b>[8]</b>
                                        LIN I, JEFF B, RICKARD I.ARM platform for performance and power efficiency-hardware and software perspectives[C]//Proceedings of the 2016 International Symposium on VLSI Design, Automation and Test.Piscataway, NJ:IIEEE, 2016:1-5.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_9" title="VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C]//Proceedings of the 31st Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2017:5998-6008." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention is All You Need">
                                        <b>[9]</b>
                                        VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C]//Proceedings of the 31st Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2017:5998-6008.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_10" title="WANG F, JIANG H, ZUO K, et al.Design and implementation of a highly efficient DGEMM for 64-bit ARMv8 multi-core processors[C]//Proceedings of the 44th International Conference on Parallel Processing.Piscataway, NJ:IEEE, 2015:200-209." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Design and implementation of a highly efficient DGEMM for 64-bit ARMv8 multi-core processors">
                                        <b>[10]</b>
                                        WANG F, JIANG H, ZUO K, et al.Design and implementation of a highly efficient DGEMM for 64-bit ARMv8 multi-core processors[C]//Proceedings of the 44th International Conference on Parallel Processing.Piscataway, NJ:IEEE, 2015:200-209.
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_11" title="RUSITORU R.ARMv8 micro-architectural design space exploration for high performance computing using fractional factorial[C]//Proceedings of the 6th International Workshop on Performance Modeling, Benchmarking, and Simulation of High Performance Computing Systems.New York:ACM, 2015:Article No.8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ARMv8 micro-architectural design space exploration for high performance computing using fractional factorial">
                                        <b>[11]</b>
                                        RUSITORU R.ARMv8 micro-architectural design space exploration for high performance computing using fractional factorial[C]//Proceedings of the 6th International Workshop on Performance Modeling, Benchmarking, and Simulation of High Performance Computing Systems.New York:ACM, 2015:Article No.8.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_12" title="FLUR S, GRAY K E, PULTE C, et al.Modelling the ARMv8 architecture, operationally:concurrency and ISA[C]//Proceedings of the 43rd Annual ACM SIGPLAN Symposium on Principles of Programming Languages.New York:ACM, 2016:608-621." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modelling the ARMv8 architecture,operationally:concurrency and ISA">
                                        <b>[12]</b>
                                        FLUR S, GRAY K E, PULTE C, et al.Modelling the ARMv8 architecture, operationally:concurrency and ISA[C]//Proceedings of the 43rd Annual ACM SIGPLAN Symposium on Principles of Programming Languages.New York:ACM, 2016:608-621.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_13" title="LIU Z, JARVINEN K, LIU W, et al.Multiprecision multiplication on ARMv8[C]//Proceedings of the IEEE 24th Symposium on Computer Arithmetic.Piscataway, NJ:IEEE, 2017:10-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiprecision multiplication on ARMv8">
                                        <b>[13]</b>
                                        LIU Z, JARVINEN K, LIU W, et al.Multiprecision multiplication on ARMv8[C]//Proceedings of the IEEE 24th Symposium on Computer Arithmetic.Piscataway, NJ:IEEE, 2017:10-17.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_14" title="XU X, CLARKE C T, JONES S R.High performance code compression architecture for the embedded ARM/Th UMB processor[C]//Proceedings of the 1st Conference on Computing Frontiers.New York:ACM, 2004:451-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High performance code compressionarchitecture for the embedded ARM/THUMB processor">
                                        <b>[14]</b>
                                        XU X, CLARKE C T, JONES S R.High performance code compression architecture for the embedded ARM/Th UMB processor[C]//Proceedings of the 1st Conference on Computing Frontiers.New York:ACM, 2004:451-456.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_15" title="姜浩, 杜琦, 郭敏, 等.面向ARMv8 64位多核处理器的QGEMM设计与实现[J].计算机学报, 2017, 40 (9) :2018-2029. (JIANG H, DU Q, GUO M, et al.Design and implementation of QGEMM on ARMv8 64-bit multi-core processor[J].Chinese Journal of Computers, 2017, 40 (9) :2018-2029.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201709004&amp;v=MTY3MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEbFVidk1MejdCZHJHNEg5Yk1wbzlGWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        姜浩, 杜琦, 郭敏, 等.面向ARMv8 64位多核处理器的QGEMM设计与实现[J].计算机学报, 2017, 40 (9) :2018-2029. (JIANG H, DU Q, GUO M, et al.Design and implementation of QGEMM on ARMv8 64-bit multi-core processor[J].Chinese Journal of Computers, 2017, 40 (9) :2018-2029.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1557-1562 DOI:10.11772/j.issn.1001-9081.2018122608            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于ARMv</b>8<b>架构的面向机器翻译的单精度浮点通用矩阵乘法优化</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BE%9A%E9%B8%A3%E6%B8%85&amp;code=41987888&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">龚鸣清</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B6%E7%85%8C&amp;code=23856394&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">叶煌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%89%B4&amp;code=24282823&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张鉴</a>
                                <a href="javascript:;">卢兴敬</a>
                                <a href="javascript:;">陈伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E6%81%AF%E4%B8%AD%E5%BF%83&amp;code=0021859&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院计算机网络信息中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E6%90%9C%E7%8B%97%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京搜狗科技发展有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对使用ARM处理器的移动智能设备执行神经网络推理计算效率不高的问题, 提出了一套基于ARMv8架构的单精度浮点通用矩阵乘法 (SGEMM) 算法优化方案。首先, 确定ARMv8架构的处理器执行SGEMM算法的计算效率受限于向量化计算单元使用方案、指令流水线和缓存未命中的发生概率;其次, 针对三点导致计算效率受限的原因实现向量指令内联汇编、数据重排和数据预取三条优化技术;最后, 根据语音方向的神经网络中常见的三种矩阵模式设计测试实验, 实验中使用RK3399硬件平台运行程序。实验结果表示:方阵模式下单核计算速度为10.23 GFLOPS, 达到实测浮点峰值的78.2%;在细长矩阵模式下单核计算速度为6.35 GFLOPS, 达到实测浮点峰值的48.1%;在连续小矩阵模式下单核计算速度为2.53 GFLOPS, 达到实测浮点峰值19.2%。将优化后的SGEMM算法部署到语音识别神经网络程序中, 程序的实际语音识别速度取得了显著提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ARMv8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ARMv8;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%95%E6%8C%87%E4%BB%A4%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单指令多数据流计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9F%BA%E7%A1%80%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%BA%93&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">基础线性代数子程序库;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高性能计算;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    龚鸣清 (1994—) , 男, 湖北黄冈人, 硕士研究生, 主要研究方向:高性能计算、机器学习;;
                                </span>
                                <span>
                                    叶煌 (1979—) , 男, 江西铜鼓人, 副研究员, 博士, 主要研究方向:高性能计算;;
                                </span>
                                <span>
                                    *张鉴 (1972—) , 男, 北京人, 研究员, 博士, 博士生导师, CCF会员, 主要研究方向:高性能计算、科学计算、科学计算可视化;;
                                </span>
                                <span>
                                    卢兴敬 (1983—) , 男, 山东临沂人, 博士, CCF会员, 主要研究方向:高性能计算、深度学习、并行编程、编译技术;电子邮箱zhangjian@sccas.cn;
                                </span>
                                <span>
                                    陈伟 (1984—) , 男, 内蒙古呼和浩特人, 博士, CCF会员, 主要研究方向:人机交互、机器翻译、深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (2016YFB0201100, 2017YFB0202803);</span>
                                <span>国家自然科学基金资助项目 (11871454, 91630204, 61531166003);</span>
                                <span>中国科学院战略性先导科技专项 (B类) (XDB22020102) ;中国科学院信息化专项 (XXH13506-204);</span>
                    </p>
            </div>
                    <h1><b>Single precision floating general matrix multiply optimization for machine translation based on ARMv</b>8 <b>architecture</b></h1>
                    <h2>
                    <span>GONG Mingqing</span>
                    <span>YE Huang</span>
                    <span>ZHANG Jian</span>
                    <span>LU Xingjing</span>
                    <span>CHEN Wei</span>
            </h2>
                    <h2>
                    <span>Computer Network Information Center, Chinese Academy of Sciences</span>
                    <span>University of Chinese Academy of Sciences</span>
                    <span>Beijing Sogou Technology Development Company Limited</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the inefficiency of neural network inferential calculation executed by mobile intelligent devices using ARM processor, a set of Single precision floating GEneral Matrix Multiply (SGEMM) algorithm optimization scheme based on ARMv8 architecture was proposed. Firstly, it was determined that the computational efficiency of the processor based on ARMv8 architecture executing SGEMM algorithm was limited by the vectorized computation unit usage scheme, the instruction pipeline, and the probability of occurrence of cache miss. Secondly, three optimization techniques: vector instruction inline assembly, data rearrangement and data prefetching were implemented for the three reasons that the computational efficiency was limited. Finally, the test experiments were designed based on three matrix patterns commonly used in the neural network of speech direction and the programs were run on the RK3399 hardware platform. The experimental results show that, the single-core computing speed is 10.23 GFLOPS in square matrix mode, reaching 78.2% of the measured floating-point peak value; the single-core computing speed is 6.35 GFLOPS in slender matrix mode, reaching 48.1% of the measured floating-point peak value; and the single-core computing speed is 2.53 GFLOPS in continuous small matrix mode, reaching 19.2% of the measured floating-point peak value. With the optimized SGEMM algorithm deployed into the speech recognition neural network program, the actual speech recognition speed of program is significantly improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ARMv8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ARMv8;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=single%20instruction%20multiple%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">single instruction multiple data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=basic%20linear%20algebra%20subprogram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">basic linear algebra subprogram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=high%20performance%20computation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">high performance computation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    GONG Mingqing, born in 1994, M. S. candidate. His research interests include high performance computation, machine learning. ;
                                </span>
                                <span>
                                    YE Huang, born in 1979, Ph. D. , associate research fellow. His research interests include high performance computation. ;
                                </span>
                                <span>
                                    ZHANG Jian, born in 1972, Ph. D. , research fellow. His research interests include high performance computation, scientific computation, visualization in scientific computing. ;
                                </span>
                                <span>
                                    LU Xingjing, born in 1983, Ph. D. His research interests include high performance computation, deep learning, parallel programming, compiling technology. ;
                                </span>
                                <span>
                                    CHEN Wei, born in 1984, Ph. D. His research interests include human-computer interaction, machine translation, deep learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Key R&amp;D Program of China (2016YFB0201100, 2017YFB0202803);</span>
                                <span>the National Natural Science Foundation of China (11871454, 91630204, 61531166003);</span>
                                <span>the Strategic Priority Research Program of Chinese Academy of Sciences (B) (XDB22020102) ;the e-Science Foundation of Chinese Academy of Sciences (XXH13506-204);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="34">近年由Intel公司创始人摩尔提出的摩尔定律已经逐渐在以X86-64指令集为代表的复杂指令集 (Complex Instruction Set Computer, CISC) 型中央处理器 (Central Processing Unit, CPU) 上失效, 而以ARM为首的精简指令集 (Reduced Instruction Set Computer, RSIC) 型CPU则随着智能时代的到来进入了超高速发展期。ARM公司于2014年1月正式发布了首个64位架构ARMv8-A, ARMv8-A新加入数种特性, 例如:更大的寻址范围、数量更多位数更宽的通用寄存器组、并发执行浮点计算的128 b NEON向量单元、复合单指令多数据流 (Single Instruction Multiple Data, SIMD) 计算指令。</p>
                </div>
                <div class="p1">
                    <p id="35">高性能计算在桌面与服务器端CPU和其他大体积大功耗的高性能计算设备上是一个常见的研究课题, 早在几十年前第一台通用计算机ENIAC诞生的时候, 它承担的任务就是替美国军方高效计算弹道, 从数学模型的角度来看就是对一系列复杂的线性方程组进行近似求解, 而求解过程也是通过一系列复杂的线性代数计算来实现的。时至今日, 虽然通用计算机和中央处理器的性能可以满足普通用户的需求, 但是在执行线性代数计算的时候依然还是要依赖于对应平台的基础线性代数子程序库 (Basic Linear Algebra Subprograms, BLAS) , 针对目标硬件优化的BLAS库允许计算设备高效率的执行线性代数计算, 著名的BLAS库有:AMD的ACML<citation id="131" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、IBM的ESSL<citation id="132" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、NVIDIA的CUBLAS<citation id="133" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、TACC的GotoBLAS<citation id="135" type="reference"><link href="107" rel="bibliography" /><link href="109" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、 中国科学院计算技术研究所的OpenBLAS<citation id="134" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="36">本文旨在提高移动智能设备上神经网络推理计算的执行效率, 推理计算的执行过程中会大量调用单精度浮点通用矩阵乘法 (Single precision floating GEneral Matrix Multiply, SGEMM) 算法, 所以面向Cortex-A72架构进行SGEMM优化, 测试平台为RK3399, 实验参照对象为OpenBLAS库的0.3.4版本。因为OpenBLAS库为跨多平台的开源项目, 在公司的产品和实验室研究课题中有着广泛的应用<citation id="136" type="reference"><link href="113" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 选取OpenBLAS作为参考对象更具备说服力。</p>
                </div>
                <div class="p1">
                    <p id="37">首先根据GotoBLAS<citation id="137" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的思路, 实现SGEMM的计算子任务划分;其次, 使用Cortex-A72架构特性<citation id="138" type="reference"><link href="115" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>实现计算核心代码, 用于执行划分后的计算子任务;最后, 将不同的计算核心与数据重排方案匹配不同的矩阵规模。与OpenBLAS对比的实验结果为 (以下为行文方便, 本文实现的SGEMM为Evalite_SGEMM, OpenBLAS实现的SGEMM为OpenBLAS_SGEMM) :方阵模式下, Evalite_SGEMM相较于OpenBLAS_SGEMM性能提升了170%, 达到了实测峰值的78.2%;细长矩阵模式下, Evalite_SGEMM相较于OpenBLAS_SGEMM性能提升了312%, 达到了实测峰值的48.1%;连续小矩阵模式下, Evalite_SGEMM相较于OpenBLAS_SGEMM性能提升了283%, 达到了实测峰值的19.2%。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">1 基础介绍</h3>
                <h4 class="anchor-tag" id="39" name="39">1.1 Cortex-A72<b>处理器介绍</b></h4>
                <div class="p1">
                    <p id="40">图1是ARM官方网站上展示的Cortex-A72处理器的总体架构。从图1可知, Cortex-A72同时兼容32 b/64 b指令集, 处理器内置48 KB的3路组相连L1指令cache、32 KB的二路组相连L1级数据缓存 (D-cache) 和512 KB到4 MB的16路组相连L2数据共享缓存 (D-share_cache) , 一个集成电路板上集成1到4个Cortex-A72核心, 核心之间通过AMBA (Advanced Microcontroller Bus Architecture) 相连。Cortex-A72处理器采用台积电16 nm FinFET+制程, 使得核心主频最高可达到2.5 GHz。Cortex-A72采用的是3发射超标量乱序流水线, 每个核心内设32个128 b浮点寄存器v0～v31专门用于SIMD计算指令。</p>
                </div>
                <div class="p1">
                    <p id="41">Cortex-A72采用的是3发射超标量乱序流水线, 每个核心内设32个128 b浮点寄存器v0～v31专门用于SIMD计算指令。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Cortex-A72架构" src="Detail/GetImg?filename=images/JSJY201906002_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Cortex-A72架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Cortex-A72 architecture</p>

                </div>
                <h4 class="anchor-tag" id="43" name="43">1.2 Evalite_SGEMM<b>实现概述</b></h4>
                <div class="p1">
                    <p id="44">SGEMM标准化接口实现如下计算:</p>
                </div>
                <div class="p1">
                    <p id="45"><b><i>C</i></b>=<i>α</i>·[<b><i>A</i></b>×<b><i>B</i></b>]+<i>β</i>·<b><i>C</i></b>      (1) </p>
                </div>
                <div class="p1">
                    <p id="46">式中:<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>分别是规模为<i>M</i>×<i>O</i>、<i>O</i>×<i>N</i>、<i>M</i>×<i>N</i>的矩阵;<i>α</i>与<i>β</i>是作为系数的标量, 这里为了计算的泛化性, 假定<i>α</i>与<i>β</i>既不等于0也不等于1, 同时假定矩阵均以行主序存储。</p>
                </div>
                <div class="p1">
                    <p id="47">Sogou_SGEMM是移动智能设备上深度学习框架的基础数学库组成部分, 以机器翻译框架为例, 其中一个关键组成部分被称为转导模型<citation id="139" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 转导模型包含多种规格的SGEMM计算任务。针对语音方向深度学习框架中常用或者效率受限的3种矩阵规模进行调优:方阵 (<i>M</i>=<i>O</i>=<i>N</i>) 、细长阵 (<i>M</i>=2、4, <i>O</i>=256, <i>N</i>=30 000) 、迷你矩阵 (<i>M</i>≤16, <i>O</i>=64, <i>N</i>≤16) 。</p>
                </div>
                <div class="p1">
                    <p id="48">实现思路如下所述:第一步, 实现两个高度优化的计算核心子函数SGEBP与SGEPD, 旨在CPU运行这两个子函数时指令流水线更密集, 同时更少地发生控制冒险、数据冒险<citation id="140" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>;第二步, 重排<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>三个矩阵的数据存储顺序, 使得矩阵的数据存储顺序符合SGEBP和SGEPDOT在执行计算循环体时的连续读写顺序;第三步, 划分<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>三个矩阵, 使得SGEBP和SGEPD在计算一块子区域时, 数据在cache与主存之间的流通次数降到最低, 降低读写操作带来的额外时间开销。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">2 优化实现</h3>
                <div class="p1">
                    <p id="50">大规模矩阵计算的第一步是子区域分割, <i>GotoBLAS</i><citation id="141" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>中提出的划分方案总结并分析了全部情况, 所以本文的研究重心是如何利用<i>Cortex</i>-<i>A</i>72架构的特性, 提升子任务计算内核代码的效率<citation id="142" type="reference"><link href="121" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51">2.1 <b>内联汇编</b></h4>
                <div class="p1">
                    <p id="52">参照1.1节可知, <i>Cortex</i>-<i>A</i>72的理论流水线为3发射超标量乱序, 图2为<i>Cortex</i>-<i>A</i>72的流水线架构图。<i>Cortex</i>-<i>A</i>72的每1条指令在有序超标量下经过取指、译码、重命名后被乱序分派到各个执行单元上完成指令期望的操作, 在不用考虑数据相关性的前提下, 流水线可以在每一个<i>cycle</i>中同时执行3次整数计算、2次向量计算、1次分支跳转、1次读取和1次写回中的任意3条<citation id="143" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。此外<i>Cortex</i>-<i>A</i>72中内置了2个<i>SIMD</i>计算单元<i>NEON</i>, <i>NEON</i>最初引入的目的是提高视频和音频的解码速度。发展到<i>ARMv</i>8架构, 内置32个128 <i>b</i>浮点寄存器, 访存部件支持128 <i>b</i>单步读写, 因此本文利用<i>NEON</i>单元进行<i>SIMD</i>计算加速。本文的实现采用的是<i>GNU</i>与<i>LLVM</i>都支持的内联汇编语法结构, 在<i>C</i>程序中调用手动编写的汇编代码块。</p>
                </div>
                <div class="p1">
                    <p id="53">内联汇编要面向的是两个不同的计算内核<i>SGEBP</i>和<i>SGEPDOT</i>, 其计算模式分别如图3 (<i>a</i>) 、 (<i>b</i>) 所示, 图中<i>M</i>1、<i>N</i>1、<i>O</i>1、<i>M</i>2、<i>N</i>2、<i>O</i>2分别为各个矩阵的横纵轴, 同形状点表示的是一次内联汇编循环<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>涉及到的数据, 其中<b><i>A</i></b>、<b><i>B</i></b>的点只表示源操作数, 而<b><i>C</i></b>的点既表示源操作数也表示目的操作数。<b><i>A</i></b>的行和<b><i>B</i></b>的列坐标分别对应的是<b><i>C</i></b>的行和列坐标, 所以SGEBP和SGEPDOT计算模式可分别表示为式 (2) ～ (3) :</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">C</mi><mn>1</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mi>x</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">C</mi><mn>1</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mi>x</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>x</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>y</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><mn>1</mn></mrow></munderover><mi mathvariant="bold-italic">A</mi></mstyle></mrow></mstyle></mrow></mstyle><mn>1</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo></mrow></msub><mo>⋅</mo><mi mathvariant="bold-italic">B</mi><mn>1</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">C</mi><mn>2</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo>=</mo><mi>x</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">C</mi><mn>2</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo>=</mo><mi>x</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>x</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ο</mi><mn>2</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>y</mi></mrow></munder><mi mathvariant="bold-italic">A</mi></mstyle></mrow></mstyle></mrow></mstyle><mn>2</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo></mrow></msub><mo>⋅</mo><mi mathvariant="bold-italic">B</mi><mn>2</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Cortex-A72的流水线架构" src="Detail/GetImg?filename=images/JSJY201906002_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Cortex-A72的流水线架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Cortex-A72 pipeline architecture</p>

                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SGEBP与SGEPDOT计算模式" src="Detail/GetImg?filename=images/JSJY201906002_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SGEBP与SGEPDOT计算模式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Calculation modes of SGEBP and SGEPDOT</p>

                </div>
                <div class="p1">
                    <p id="57">SGEBP是沿着矩阵<b><i>B</i></b>1的<i>N</i>1轴进行内循环, 使得<b><i>A</i></b>1上的一个点跟<b><i>B</i></b>1上对应的一整行均相乘, 相乘的结果再累加到对应的<b><i>C</i></b>1上一行, 然后外层迭代<b><i>A</i></b>1沿着<i>O</i>1轴换到下一个点, <b><i>B</i></b>1沿着<i>O</i>1轴换到下一行, <b><i>C</i></b>1保持行号不变但返回到行首第一个点, 当对整个<i>O</i>1轴都迭代1次之后, <b><i>C</i></b>1的一行计算就全部完成了;SGEPDOT是沿着矩阵<b><i>B</i></b>2的<i>O</i>2轴进行内循环, <b><i>A</i></b>2上列号与<b><i>B</i></b>2上行号对应的点相乘再累加到对应的<b><i>C</i></b>2上一点, 然后外层迭代<b><i>A</i></b>2回到当前行行首, <b><i>B</i></b>2沿着<i>N</i>2轴切换到下一列, <b><i>C</i></b>2沿着<i>N</i>2轴切换到下一个点, 当对整个<i>N</i>2轴都迭代一次之后, <b><i>C</i></b>2的一行就全部计算完成了。</p>
                </div>
                <div class="p1">
                    <p id="58">上述模式属于点对点计算, 利用NEON向量化指令进行计算是优化的第一个目标, 所以需要将点对点计算组合成向量计算, {fmla v0.4s, v1.4s, v2.s[0]}, 这条指令的功能为v2寄存器上的1个单精度浮点数分别乘上v1寄存器上的4个单精度浮点数, 再累加到v0寄存器的4个单精度浮点数上, 其中v0和v1的4个单精度浮点数从位高到低一一对应。fmla意味着arm可以做到1条指令进行8次浮点计算, 符合矩阵乘法计算公式的基础操作, 所以内联汇编将围绕着fmla展开, 而使用fmla作为基本计算操作下, SGEBP和SGEPDOT的计算模式都要进行一定程度的修改, 如图4 (a) 、 (b) 所示。图中<b><i>A</i></b>3、<b><i>B</i></b>3、<b><i>C</i></b>3、<b><i>A</i></b>4、<b><i>B</i></b>4、<b><i>C</i></b>4分别是SGEBP和SGEPDOT一次内循环所需要的数据, 但是利用NEON执行单元后, 1条fmla指令同时计算矩阵<b><i>B</i></b>、<b><i>C</i></b>内的4个单精度浮点数。SGEBP模式<b><i>A</i></b>3上一个点乘以<b><i>B</i></b>3上一个向量再累加到<b><i>C</i></b>3上一个向量, 直到<b><i>B</i></b>3一整行数据都跟<b><i>A</i></b>3上同一个点完成乘法计算并累加到<b><i>C</i></b>3一整行上, <b><i>A</i></b>3沿着横轴切换到下个点, <b><i>B</i></b>3沿着纵轴向切换到下一行, 当整个<b><i>B</i></b>3都累加到<b><i>C</i></b>3同一行上, 标志着<b><i>C</i></b>3这一行上的计算完全结束;SGEPDOT模式变为<b><i>A</i></b>4上纵轴4个点为1个向量取出, <b><i>B</i></b>4上横轴4个点为1个向量取出, 然后展开4次fmla计算, 并依次再累加到<b><i>C</i></b>4的4个向量上, 然后<b><i>A</i></b>4沿着横轴切换到下一个向量上, <b><i>B</i></b>4沿着纵轴切换到下一个向量, 循环计算, 当<b><i>A</i></b>4沿着横轴循环到底, <b><i>B</i></b>4沿着纵轴循环到底, <b><i>C</i></b>4上4个向量的计算完全结束。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SGEBP与SGEPDOT向量计算模式" src="Detail/GetImg?filename=images/JSJY201906002_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SGEBP与SGEPDOT向量计算模式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Vector calculation modes of SGEBP and SGEPDOT</p>

                </div>
                <div class="p1">
                    <p id="60">在确定了使用fmla作为主要的向量计算指令后, 接下来研究的就是fmla在什么状态下才可以让流水线满排。这里本文参考了arm公司的《Cortex-A72优化指南》, 指南里对Cortex-A72的各种指令的执行参数进行了一一列举, 从指南里可以得知fmla指令在128 b格式下单条的执行延迟为7个cycle, Cortex-A72有2个SIMD执行部件, 并行执行延迟为3个cycle, 理想的吞吐量为每个cycle完成1条fmla指令。且文档里特别说明了, 混合计算指令 (乘加、乘减等) 实际执行的时候是将混合指令拆分成乘法、加法两条来执行, 所以混合计算指令的理论峰值吞吐量为每个cycle执行1条。</p>
                </div>
                <div class="p1">
                    <p id="61">为了验证文档里数据的正确性, 以及验证NEON执行指令时数据相关性, 参考《Cortex-A72优化指南》设计峰值测试实验, 结果为峰值下每1.167个cycle完成1条fmla, 循环展开3条以上目的寄存器不同的fmla下就可达到浮点峰值, 与指南中给出的每cycle完成1条的结果存在16%的偏差, 但测试结果显示NEON的单精度向量计算指令的数据相关性带来的延迟为4cycle, 与指南中给出的数据一致。对于实测峰值为13.2 GFLOPS, 而理论峰值为14.4 GFLOPS的状况, 在与测评平台的系统设计工程师沟通分析后认为, 这是由于底层的功耗调度驱动对处理器的性能进行了限制, 所以测试程序实际上是在功耗受限的处理器上运行。</p>
                </div>
                <div class="p1">
                    <p id="62">至此结合每个浮点寄存器可保存4个单精度浮点数的条件, 想要汇编代码块在执行的时候SIMD单元利用率高, 需要保证循环展开4条以上的目标寄存器不同的fmla指令, 即安排4个以上的浮点寄存器用于对矩阵<b><i>C</i></b>的访存操作, 但此点不适用于连续小矩阵乘模式的部分情况, 因为小矩阵模式下<b><i>C</i></b>本身规模太小用不满4个浮点寄存器。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">2.2 <b>数据重排</b></h4>
                <div class="p1">
                    <p id="64">2.1节是从计算指令的角度讨论如何让流水线满排, 而没有考虑访存指令在计算中的影响, 事实上计算访存比在<i>BLAS</i>优化中同样是一个需要的问题<citation id="144" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 因为当计算指令在流水线上达到足够的密度后, 访存指令获取数据的效率受到缓存未命中 (<i>cache miss</i>) 情况的限制, 从而限制了计算指令的执行效率<citation id="145" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。本文的内联汇编计算核心在迭代执行规模为4 096×4 096×4 096的矩阵乘法时, 浮点效率3.2 <i>GFLOPS</i>, 为理论峰值的22.2%。这是因为在迭代<i>SGEBP</i>或者<i>SGEPDOT</i>的时候需要循环多次读取整个矩阵<b><i>B</i></b>, 而本文测试使用的CPU L2 D-cache总量为512 KB, 当<b><i>B</i></b>的规模增大到512 KB以上时, 每次循环读取矩阵<b><i>B</i></b>的时候有一部分数据并不在D-cache上, 需要去主存上读取, 这部分数据的读取每一次都会产生cache miss, 从而造成了计算效率严重下降, 这是需要进行数据重排和预取的第一个原因。</p>
                </div>
                <div class="p1">
                    <p id="65">第二个原因依然是从访存指令出发, 从高级语言的角度来看对于数据的操作是直接的, 一套复合运算用C语言书写一行计算表达式就可以描述;但是从汇编的角度来看, 计算指令在执行之前需要把将要使用的变量读到通用寄存器上, 主存和cache上的数据必须经过寄存器才能被CPU的执行单元进行操作, 而由于数据相关性, 在数据没有被读入寄存器之前, 计算指令就不会执行, 刚才说到的cache miss是阻碍数据读入寄存器的一个因素, 而还有一个因素是执行load或者store指令时地址的变化。例如, 在SGEPDOT里, load矩阵<b><i>B</i></b>的数据是如下格式{ldr v0, [base];add base, base, x0;}, 之所以要这么做, 是因为<b><i>B</i></b>的数据是跳行读取的, x0是<b><i>B</i></b>的行字节宽度, 在读取一行上的某个向量之后, 就需要手动计算地址来定位到下一行, 这也是因为虽然ARMv8支持寄存器间址寻址, 但并不支持寄存器间址寻址后自动更新源地址, 而相反的, 如果是使用立即数间址寻址, 是支持在寻址之后自动更新源地址的, 也就是说如下两个格式{ldr v0, [base, #imme]!}, {ldr v0, [base, #imme];add base, base, #imme}完成的是一样的功能, 在使用的执行单元数量和种类相同的情况下, 前一种格式只需要1条指令, 而后一种格式需要2条指令, 且这2条指令之间存在数据相关, 即需要插入NOP来填塞流水线。</p>
                </div>
                <div class="p1">
                    <p id="66">第三个原因从计算访存比出发, 内联汇编代码core为了代码的简洁性和泛化性, 内部实现一层循环, 例如SGEPDOT的一次需要沿着0轴循环256步, 不可能把256步的每一步都写成代码, 正确的做法是直接写出8步或者16步的计算代码, 然后循环执行32次或者16次。这就导致了一个问题, 流水线想要循环执行的过程中迅速进入满排, 那么计算访存比就必须足够高, 根据式 (1) 可知, 最理想的情况为在循环体内2次load就可以展开4次fmla。</p>
                </div>
                <div class="p1">
                    <p id="67">综合以上3点, 本文采取了以下重排方案来分别处理矩阵<b><i>A</i></b>与<b><i>B</i></b>、<b><i>C</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="68">图5 (a) 是矩阵<b><i>A</i></b>、<b><i>C</i></b>的重排方案, (b) 是矩阵<b><i>B</i></b>的重排方案, 同形状的点表示重拍前后同列和同行上的4个数据单元。对于<b><i>A</i></b>来说是将同列上4个数变为同行上地址连续的4个数, 也可以看作是局部上的矩阵转置, 但是无论是行还是列都必须以4的倍数进行迭代的重排, 实际情况下往往行列都存在余数, 那剩下的一部分并不进行重排, 因为考虑剩余部分的兼容性会导致程序的结构变得复杂, 且实际测试结果表明余数部分的重排并不会带来性能上的明显提升。而将<b><i>A</i></b>进行图5 (a) 所示的重排后, 一次load就可以load原序里4个同列的点, 由矩阵乘法计算模型可知, 这4个点对应的<b><i>B</i></b>的数据也是相同的, 换句话说就是对<b><i>A</i></b>进行一次load, 再对比<b><i>B</i></b>进行一次load, 就已经可以展开4次目标寄存器不同的fmla计算。对于<b><i>B</i></b>的重排则是进一步地强化局部的计算访存比, 从图5 (b) 可以看出对<b><i>B</i></b>的重排, 是以1个向量为基本单位, 将同列的4个向量变为同行上地址连续的4个向量, 这样2次load (ARMv8指令集支持连续地址连读、连写2个数据单元) 就可以load 4个<b><i>B</i></b>上的向量, 并与<b><i>A</i></b>的4个点 (也可以看作为1个向量) 展开16次fmla计算, 且面对的是4个不同的目的寄存器, 从而16次fmla可以充分利用2个SIMD单元。在SGEBP模式下, 重排后的计算访存比为2;在SGEPDOT模式下, 重排后的计算访存比为4;且两种模式下访存指令都可以在一定程度上被fmla指令覆盖。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 矩阵A、B、C的重排方案" src="Detail/GetImg?filename=images/JSJY201906002_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 矩阵<b><i>A</i></b>、<b><i>B</i></b>、<b><i>C</i></b>的重排方案  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Rearrangement schemes of matrix <b><i>A</i></b>, <b><i>B</i></b> and <b><i>C</i></b></p>

                </div>
                <div class="p1">
                    <p id="70">此外, 重排可以沿着纵轴进行延长或者缩短的。在方阵上<b><i>A</i></b>、<b><i>B</i></b>的重排可以沿着纵轴到底部的, 而在2×256×30 000的规模上, <b><i>A</i></b>只有2列, 进行的就是2×4规模的重排, 同时细长矩阵模式下<b><i>B</i></b>的全列重排占据了一次完整计算98%的时间, 为了减少<b><i>B</i></b>全列重排对计算效率的严重影响, 对于细长矩阵模式的重排本文也作了一些变化。首先, <b><i>B</i></b>的重排是以4行为一个子区域进行的;其次, <b><i>B</i></b>的重排结果在重排完成后进行暂时性的保存, 也就是说当前计算完成之后, <b><i>B</i></b>重排后的并不只是用于最近的几次计算, 而是框架模型没有进行改动之前一直重复使用, 这里利用了神经网络推理计算中参数矩阵为常数矩阵的特性, 每次计算时都可能发生变动的是矩阵<b><i>A</i></b>与<b><i>C</i></b>, 所以对<b><i>B</i></b>进行一次重排之后, 可以满足一整次框架运行的计算需求, 甚至可以将常参数矩阵就按照重排之后的格式进行长期存储。同时对于方阵, 本文作了一个细节上的优化, 由于<b><i>A</i></b>和<b><i>C</i></b>都要乘以标量系数, 所以在进行全局矩阵标量点乘时, 本身就是对<b><i>A</i></b>和<b><i>C</i></b>的一次遍历, 将这次遍历融合到<b><i>A</i></b>和<b><i>C</i></b>重排上, 在矩阵小于512 KB的情况下有11.2%的加速效果。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">2.3 <b>数据预取</b></h4>
                <div class="p1">
                    <p id="72">重排完成之后, 内联汇编的计算顺序和矩阵的数据排列顺序达成一致, 数据在<i>cache</i>上得到充分重用, 但数据重排和子区域划分考虑到的<i>cache</i>是<i>L</i>2 <i>D</i>-<i>cache</i>, 对于<i>L</i>2数据<i>cache</i>来说能在计算中稳定保存的子区域, 在32 <i>KB</i> 大小的<i>L</i>1 <i>D</i>-<i>cache</i>上并不可行。<i>ARMv</i>8提供了数据预取指令来进一步解决高密度计算场景下的<i>L</i>1 <i>D</i>-<i>cache miss</i>问题, 例如{<i>prfm L</i>1<i>keep</i>, [<i>addr</i>]}就是将接下来需要使用到的首地址为<i>addr</i>的数据预取到<i>L</i>1 <i>D</i>-<i>cache</i>中, <i>keep</i>的意思是指预取的这部分数据将要接下来的时间内进行多次使用, <i>L</i>1 <i>D</i>-<i>cache</i>就不会轻易地将这部分预取的数据刷出, 还有另外一种后缀为<i>strm</i>, <i>strm</i>的意思指的是预取的这部分数据在接下来的一段时间内只计算一次, 这类的预取数据在计算结束之后就会被<i>L</i>1 <i>D</i>-<i>cache</i>优先丢弃<citation id="146" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="73">使用数据预取指令需要注意3个问题:第一, 预取指令的执行时间通常会超过执行访存指令并且没有发生<i>cache miss</i>情况下的时间, 这是因为预取的数据一般是分布在<i>L</i>2、<i>L</i>3 <i>D</i>-<i>cache</i>、或者主存上, 在预取数据的时候, 至少发生1次<i>cache miss</i>, 最多发生3次, 所以使用预取指令的时候, 要确保有足够的计算指令掩盖预取访存延迟。第二, 预取指令跟访存指令使用相同的访存执行单元, 预取访存延迟为几十个机器周期到上百个机器周期不等, 为了保证当前计算指令依赖的数据能够提前准备好, 预取指令在指令流水线上要跟正常访存指令保持一定间隔。第三, 预取指令并不是将紧接的几次计算指令所需要的数据预取到<i>L</i>1 <i>D</i>-<i>cache</i>中, 这是因为<i>ARM</i>的<i>D</i>-<i>cache</i>在设计上就考虑了空间局部性, 假设当前计算所使用到的数据其地址为<i>base</i>, 那么从<i>base</i>到 <i>base</i>+<i>x</i>地址范围内的连续数据都已经在L1 D-cache中了 (其中<i>x</i>是根据当前计算状态在一定范围内动态变化的值) , 所以正在计算中使用到的数据地址为<i>base</i>, 预取的数据地址为<i>base</i>+<i>y</i>, 当<i>y</i>≤<i>x</i>时, 预取就起不到任何加速作用, 根据目前平台的实际测试, 预取达到最好的加速效果, 是预取<i>base</i>+320地址所指向的数据。</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag">3 测试结果与分析</h3>
                <div class="p1">
                    <p id="75">本文测试使用的硬件平台为<i>Rockchip</i>公司生产的<i>RK</i>3399芯片, 内置2个<i>Cortex</i>-<i>A</i>72核心与4个<i>Cortex</i>-<i>A</i>53核心, 在测试过程中只开启一个<i>Cortex</i>-<i>A</i>72核心, 并锁定运行频率为1.8 <i>GHz</i>, 可计算得理论浮点峰值为14.4 <i>GFLOPS</i>, 由图6的代码实测峰值为13.2 <i>GFLOPS</i>, 考虑到芯片工艺、测试平台系统等非相关性干扰因素, 本文以实测峰值13.2 <i>GFLOPS</i>为对比基准。图6展示了3项优化工作累加之后与原始算法的计算性能对比结果。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906002_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 原始算法与各项优化加入后的方阵模式浮点性能对比" src="Detail/GetImg?filename=images/JSJY201906002_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 原始算法与各项优化加入后的方阵模式浮点性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906002_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Comparison of floating point performance between original</i><i>algorithm and after adding optimizations in square matrix mode</i></p>

                </div>
                <div class="p1">
                    <p id="77">从图6可知, 3项优化工作中:对性能提升效果最大的数据重排, 以4 096×4 096×4 096规模为例, 只累加向量化的版本浮点性能为3.27 <i>GFLOPS</i>, 累加向量化、数据重排实现的版本浮点性能为9.69 <i>GFLOPS</i>, 性能提升196%;其次是向量化, 以4 096×4 096×4 096规模为例, 原始算法的浮点性能为2.19 <i>GFLOPS</i>, 只累加向量化的版本浮点性能为3.27 <i>GFLOPS</i>, 性能提升49%;最后是数据预取, 以1 024×1 024×1 024规模为例, 累加向量化、数据重排的版本浮点性能为7.20 <i>GFLOPS</i>, 向量化、数据重排、数据预取实现全部累加的最终版本浮点性能为9.97 <i>GFLOPS</i>, 性能提升38%;最后, 以4 096×4 096×4 096规模为例, 原始算法的浮点性能为2.19 <i>GFLOPS</i>, 最终版本的浮点性能为10.23 <i>GFLOPS</i>, 性能提升367%。</p>
                </div>
                <div class="p1">
                    <p id="78">表1～3是<i>Evalite</i>_<i>SGEMM</i>与<i>OpenBLAS</i>_<i>SGEMM</i>的浮点性能测试结果。</p>
                </div>
                <div class="area_img" id="79">
                    <p class="img_tit"><b>表</b>1 <b>方阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的浮点性能测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Floating point performance test results of Evalite</i>_<i>SGEMM and</i><i>OpenBLAS</i>_<i>SGEMM in square matrix mode</i></p>
                    <p class="img_note">GFLOPS</p>
                    <table id="79" border="1"><tr><td><br />方阵模式</td><td><i>OpenBLAS</i>_<i>SGEMM</i></td><td><i>Evalite</i>_<i>SGEMM</i></td></tr><tr><td><br />4×4×4</td><td>0.040 000 00</td><td>0.038 260 87</td></tr><tr><td><br />16×16×16</td><td>1.092 682 93</td><td>1.357 575 76</td></tr><tr><td><br />64×64×64</td><td>0.936 759 78</td><td>2.370 035 34</td></tr><tr><td><br />256×256×256</td><td>1.404 292 22</td><td>4.508 072 87</td></tr><tr><td><br />1 024×1 024×1 024</td><td>3.634 215 87</td><td>9.968 394 96</td></tr><tr><td><br />4 096×4 096×4 096</td><td>3.787 539 46</td><td>10.233 434 66</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="80">由表1～3可知:方阵模式下, <i>Evalite</i>_<i>SGEMM</i>的最优浮点性能为10.23 <i>GFLOPS</i>, <i>OpenBLAS</i>_<i>SGEMM</i>的最优浮点性能为3.78 <i>GFLOPS</i>, <i>Evalite</i>_<i>SGEMM</i>相较于<i>OpenBLAS</i>_<i>SGEMM</i>性能提升了170%, 达到了实测峰值的78.2%;细长矩阵模式下, <i>Evalite</i>_<i>SGEMM</i>的最优浮点性能为6.35 <i>GFLOPS</i>, <i>OpenBLAS</i>_<i>SGEMM</i>的最优浮点性能为1.54 <i>GFLOPS</i>, <i>Evalite</i>_<i>SGEMM</i>相较于<i>OpenBLAS</i>_<i>SGEMM</i>性能提升了312%, 达到了实测峰值的48.1%;连续小矩阵模式下, <i>Evalite</i>_<i>SGEMM</i>的最优浮点性能为2.53 <i>GFLOPS</i>, <i>OpenBLAS</i>_<i>SGEMM</i>的最优浮点性能为0.66 <i>GFLOPS</i>, <i>Evalite</i>_<i>SGEMM</i>相较于<i>OpenBLAS</i>_<i>SGEMM</i>性能提升了283%, 达到了实测峰值的19.2%。</p>
                </div>
                <div class="area_img" id="81">
                    <p class="img_tit"><b>表</b>2 <b>细长矩阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的 浮点性能测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Floating point performance test results of Evalite</i>_<i>SGEMM and</i><i>OpenBLAS</i>_<i>SGEMM in slender matrix mode</i></p>
                    <p class="img_note">GFLOPS</p>
                    <table id="81" border="1"><tr><td><br />细长矩阵模式</td><td><i>OpenBLAS</i>_<br /><i>SGEMM</i></td><td><i>Evalite</i>_<i>SGEMM</i><br /> (无复用) </td><td><i>Evalite</i>_<i>SGEMM</i><br /> (有复用) </td></tr><tr><td><br />2×256×30 000</td><td>0.279 345 88</td><td>0.958 452 58</td><td>2.895 442 10</td></tr><tr><td><br />4×256×30 000</td><td>1.540 854 55</td><td>2.303 352 80</td><td>6.357 164 47</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="82">
                    <p class="img_tit"><b>表</b>3 <b>连续小矩阵模式下</b><i>Evalite</i>_<i>SGEMM</i><b>与</b><i>OpenBLAS</i>_<i>SGEMM</i><b>的 浮点性能测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 3 <i>Floating point performance test results of Evalite</i>_<i>SGEMM and</i><i>OpenBLAS</i>_<i>SGEMM in continuous small matrix mode</i></p>
                    <p class="img_note">GFLOPS</p>
                    <table id="82" border="1"><tr><td><br />连续小矩阵模式</td><td><i>OpenBLAS</i>_<i>SGEMM</i></td><td><i>Evalite</i>_<i>SGEMM</i></td></tr><tr><td><br />4×64×4</td><td>0.218 957 23</td><td>1.342 528 74</td></tr><tr><td><br />8×64×8</td><td>0.574 719 38</td><td>1.814 017 97</td></tr><tr><td><br />12×64×12</td><td>0.664 184 38</td><td>1.976 721 19</td></tr><tr><td><br />16×64×16</td><td>0.528 444 89</td><td>2.531 660 52</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="84">本文面向<i>ARMv</i>8架构提出了三种不同角度的<i>SGEMM</i>算法优化方案, 降低了移动智能设备上语音识别和机器翻译框架推理计算的时间消耗。实验结果表明, 优化后的<i>SGEMM</i>算法在保证了计算精度前提下有效地提升了计算速度。未来的工作, 还将考虑多线程优化, 从而进一步提高对整个处理器的利用率, 更好地降低语音识别和机器翻译框架推理计算的时间消耗。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="101">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=AMD Core Math Library(ACML)">

                                <b>[1]</b>AMD.AMD Core Math Library (ACML) [EB/OL].[2018-09-12].http://developer.amd.com/acml.jsp.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The IBM parallel engineering and scientific subroutine library">

                                <b>[2]</b>FILIPPONE S.The IBM parallel engineering and scientific subroutine library[C]//Proceedings of the 1995 International Workshop on Applied Parallel Computing, LNCS 1041.Berlin:Springer, 1995:199-206.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evaluation and tuning of the Level 3 CUBLAS for graphics processors">

                                <b>[3]</b>QUINTANA-ORTI E S, IGUAL F D, CASTILLO M, et al.Evaluation and tuning of the level 3 CUBLAS for graphics processors[C]//Proceedings of the 2008 IEEE International Symposium on Parallel and Distributed Processing Symposium.Piscataway, NJ:IEEE, 2008:1-8.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000102085&amp;v=MzA3NDk0OUZaZXNOREhROG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGNFdiaFk9TmlmSVk3SzdIdGpOcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>GOTO K, van der GEIJN R A.Anatomy of high-performance matrix multiplication[J].ACM Transactions on Mathematical Software, 2008, 34 (3) :Article No.12.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200807030&amp;v=MTQ2OTVsVWJ2TUx6N0JiYkc0SHRuTXFJOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeUQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>蒋孟奇, 张云泉, 宋刚, 等.GOTOBLAS一般矩阵乘法高效实现机制的研究[J].计算机工程, 2008, 34 (7) :84-86, 103. (JIANG M Q, ZHANG Y Q, SONG G, et al.Research on high performance implementation mechanism of GOTOBLAS general matrix-matrix multiplication[J].Computer Engineering, 2008, 34 (7) :84-86, 103.) 
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                张先轶, 王茜, 张云泉.Open BLAS:龙芯3A CPU的高性能BLAS库[J].软件学报, 2011, 22 (增刊2) :208-216. (ZHANG X Y, WANG Q, ZHANG Y Q.Open BLAS:a high performance BLAS library on Loongson 3A CPU[J].Journal of Software, 2011, 22 (Suppl.2) :208-216.) 
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cross hardware-software boundary exploration for scalable and optimized deep learning platform design">

                                <b>[7]</b>CHEN B, WANG L, WU Q, et al.Cross hardware-software boundary exploration for scalable and optimized deep learning platform design[J].IEEE Embedded Systems Letters, 2018, 10 (4) :107-110.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ARM Platform for Performance and Power Efficiency-Hardware and Software Perspectives">

                                <b>[8]</b>LIN I, JEFF B, RICKARD I.ARM platform for performance and power efficiency-hardware and software perspectives[C]//Proceedings of the 2016 International Symposium on VLSI Design, Automation and Test.Piscataway, NJ:IIEEE, 2016:1-5.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention is All You Need">

                                <b>[9]</b>VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C]//Proceedings of the 31st Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2017:5998-6008.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Design and implementation of a highly efficient DGEMM for 64-bit ARMv8 multi-core processors">

                                <b>[10]</b>WANG F, JIANG H, ZUO K, et al.Design and implementation of a highly efficient DGEMM for 64-bit ARMv8 multi-core processors[C]//Proceedings of the 44th International Conference on Parallel Processing.Piscataway, NJ:IEEE, 2015:200-209.
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ARMv8 micro-architectural design space exploration for high performance computing using fractional factorial">

                                <b>[11]</b>RUSITORU R.ARMv8 micro-architectural design space exploration for high performance computing using fractional factorial[C]//Proceedings of the 6th International Workshop on Performance Modeling, Benchmarking, and Simulation of High Performance Computing Systems.New York:ACM, 2015:Article No.8.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modelling the ARMv8 architecture,operationally:concurrency and ISA">

                                <b>[12]</b>FLUR S, GRAY K E, PULTE C, et al.Modelling the ARMv8 architecture, operationally:concurrency and ISA[C]//Proceedings of the 43rd Annual ACM SIGPLAN Symposium on Principles of Programming Languages.New York:ACM, 2016:608-621.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiprecision multiplication on ARMv8">

                                <b>[13]</b>LIU Z, JARVINEN K, LIU W, et al.Multiprecision multiplication on ARMv8[C]//Proceedings of the IEEE 24th Symposium on Computer Arithmetic.Piscataway, NJ:IEEE, 2017:10-17.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High performance code compressionarchitecture for the embedded ARM/THUMB processor">

                                <b>[14]</b>XU X, CLARKE C T, JONES S R.High performance code compression architecture for the embedded ARM/Th UMB processor[C]//Proceedings of the 1st Conference on Computing Frontiers.New York:ACM, 2004:451-456.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201709004&amp;v=MDUzMzlNTHo3QmRyRzRIOWJNcG85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGxVYnY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>姜浩, 杜琦, 郭敏, 等.面向ARMv8 64位多核处理器的QGEMM设计与实现[J].计算机学报, 2017, 40 (9) :2018-2029. (JIANG H, DU Q, GUO M, et al.Design and implementation of QGEMM on ARMv8 64-bit multi-core processor[J].Chinese Journal of Computers, 2017, 40 (9) :2018-2029.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906002" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906002&amp;v=MDkyMzdidk1MejdCZDdHNEg5ak1xWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEbFU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
