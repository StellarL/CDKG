<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991416353750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903002%26RESULT%3d1%26SIGN%3dySogERrR%252fwgZwCTv4UsO10SJoB8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903002&amp;v=MjIwMzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRG1VNzdQTHo3QmQ3RzRIOWpNckk5Rlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="2 问题分析 ">2 问题分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="2.1 &lt;b&gt;决策树算法&lt;/b&gt;">2.1 <b>决策树算法</b></a></li>
                                                <li><a href="#85" data-title="2.2 C4.5&lt;b&gt;处理不平衡数据的不足&lt;/b&gt;">2.2 C4.5<b>处理不平衡数据的不足</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="3 改进方法 ">3 改进方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#110" data-title="1) 引入缓和因子&lt;i&gt;δ&lt;/i&gt;。">1) 引入缓和因子<i>δ</i>。</a></li>
                                                <li><a href="#115" data-title="2) 用均匀分布熵代替分布熵。">2) 用均匀分布熵代替分布熵。</a></li>
                                                <li><a href="#120" data-title="3) 改进分布熵函数。">3) 改进分布熵函数。</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="4 实验与评估 ">4 实验与评估</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="4.1 NSL-KDD&lt;b&gt;测试&lt;/b&gt;">4.1 NSL-KDD<b>测试</b></a></li>
                                                <li><a href="#143" data-title="4.2 &lt;b&gt;工业控制过程的异常检测&lt;/b&gt;">4.2 <b>工业控制过程的异常检测</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#153" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#92" data-title="图1 偏斜划分的数据分布">图1 偏斜划分的数据分布</a></li>
                                                <li><a href="#107" data-title="图2 平均划分的数据分布">图2 平均划分的数据分布</a></li>
                                                <li><a href="#124" data-title="图3 香农熵和&lt;i&gt;C&lt;/i&gt; (&lt;i&gt;X&lt;/i&gt;) ">图3 香农熵和<i>C</i> (<i>X</i>) </a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验数据集&lt;/b&gt;"><b>表</b>1 <b>实验数据集</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;各决策树结果对比&lt;/b&gt;"><b>表</b>2 <b>各决策树结果对比</b></a></li>
                                                <li><a href="#146" data-title="图4 SWaT测试平台过程概述">图4 SWaT测试平台过程概述</a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;混淆矩阵&lt;/b&gt;"><b>表</b>3 <b>混淆矩阵</b></a></li>
                                                <li><a href="#152" data-title="&lt;b&gt;表&lt;/b&gt;4 SWaT&lt;b&gt;检测结果&lt;/b&gt;"><b>表</b>4 SWaT<b>检测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="257">


                                    <a id="bibliography_1" title="ESKIN E, ARNOLD A, PRERAU M, et al.A geometric framework for unsupervised anomaly detection[J].Applications of Data Mining in Computer Security, 2002, 6:77-101." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A geometric framework for unsupervised anomaly detection">
                                        <b>[1]</b>
                                        ESKIN E, ARNOLD A, PRERAU M, et al.A geometric framework for unsupervised anomaly detection[J].Applications of Data Mining in Computer Security, 2002, 6:77-101.
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_2" title="ISERMANN R, BALLE P.Trends in the application of model-based fault detection and diagnosis of technical processes[J].Control Engineering Practice, 1997, 5 (5) :709-719." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501446177&amp;v=MjExNThETnFvOUVZTzhKRFhzK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSktGMFVheFU9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        ISERMANN R, BALLE P.Trends in the application of model-based fault detection and diagnosis of technical processes[J].Control Engineering Practice, 1997, 5 (5) :709-719.
                                    </a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_3" title="KOU Y, LU C T, SIRWONGWATTANA S, et al.Survey of fraud detection techniques[C]//Proceedings of the 2004 IEEE International Conference on Networking, Sensing and Control.Piscataway, NJ:IEEE, 2004:749-754." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Survey of fraud detection techniques">
                                        <b>[3]</b>
                                        KOU Y, LU C T, SIRWONGWATTANA S, et al.Survey of fraud detection techniques[C]//Proceedings of the 2004 IEEE International Conference on Networking, Sensing and Control.Piscataway, NJ:IEEE, 2004:749-754.
                                    </a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_4" title="王莉莉, 付忠良, 陶攀, 等.基于主动学习不平衡多分类AdaBoost算法的心脏病分类[J].计算机应用, 2017, 37 (7) :1994-1998. (WANG L L, FU Z L, TAO P, et al.Heart disease classification based on active imbalance multi-class Ada Boost algorithm[J].Journal of Computer Applications, 2017, 37 (7) :1994-1998.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201707031&amp;v=MjE3MDU3cWZadVpwRmlEbVU3N1BMejdCZDdHNEg5Yk1xSTlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        王莉莉, 付忠良, 陶攀, 等.基于主动学习不平衡多分类AdaBoost算法的心脏病分类[J].计算机应用, 2017, 37 (7) :1994-1998. (WANG L L, FU Z L, TAO P, et al.Heart disease classification based on active imbalance multi-class Ada Boost algorithm[J].Journal of Computer Applications, 2017, 37 (7) :1994-1998.) 
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_5" title="FU K, CHENG D, TU Y, et al.Credit card fraud detection using convolutional neural networks[C]//Proceedings of the 2016 International Conference on Neural Information Processing.Berlin:Springer, 2016:483-490." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Credit card fraud detection using convolutional neural networks">
                                        <b>[5]</b>
                                        FU K, CHENG D, TU Y, et al.Credit card fraud detection using convolutional neural networks[C]//Proceedings of the 2016 International Conference on Neural Information Processing.Berlin:Springer, 2016:483-490.
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_6" title="DANENAS P, GARSVA G.Selection of support vector machines based classifiers for credit risk domain[J].Expert Systems with Applications, 2015, 42 (6) :3194-3204." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15D14C7870ECFBCCBF5DA12B084298D4&amp;v=MDgwNzhmQnJMVTA1dDlnekx1L3dhOD1OaWZPZmJLOWF0REkzSWhOWSt0NmZ3cEx2R1ZobkRvSk9YN2czaEk5ZmJDZFRjNmJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        DANENAS P, GARSVA G.Selection of support vector machines based classifiers for credit risk domain[J].Expert Systems with Applications, 2015, 42 (6) :3194-3204.
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_7" title="MARTIN-DIAZ I, MORINIGO-SOTELO D, DUQUE-PEREZ O, et al.Early fault detection in induction motors using Ada Boost with imbalanced small data and optimized sampling[J].IEEE Transactions on Industry Applications, 2017, 53 (3) :3066-3075." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Early fault detection in induction motors using Ada Boost with imbalanced small data and optimized sampling">
                                        <b>[7]</b>
                                        MARTIN-DIAZ I, MORINIGO-SOTELO D, DUQUE-PEREZ O, et al.Early fault detection in induction motors using Ada Boost with imbalanced small data and optimized sampling[J].IEEE Transactions on Industry Applications, 2017, 53 (3) :3066-3075.
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_8" title="赵楠, 张小芳, 张利军.不平衡数据分类研究综述[J].计算机科学, 2018, 45 (S1) :22-27. (ZHAO N, ZHANG X F, ZHANG L J.Overview of imbalanced data classification[J].Computer Science, 2018, 45 (S1) :22-27.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2018S1005&amp;v=MjUwMDBGckNVUjdxZlp1WnBGaURtVTc3UEx6N0JiN0c0SDltdnJvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        赵楠, 张小芳, 张利军.不平衡数据分类研究综述[J].计算机科学, 2018, 45 (S1) :22-27. (ZHAO N, ZHANG X F, ZHANG L J.Overview of imbalanced data classification[J].Computer Science, 2018, 45 (S1) :22-27.) 
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_9" title="IRTAZA A, ADNAN S M, AHMED K T, et al.An ensemble based evolutionary approach to the class imbalance problem with applications in CBIR[J].Applied Sciences, 2018, 8 (4) :495." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An ensemble based evolutionary approach to the class imbalance problem with applications in CBIR">
                                        <b>[9]</b>
                                        IRTAZA A, ADNAN S M, AHMED K T, et al.An ensemble based evolutionary approach to the class imbalance problem with applications in CBIR[J].Applied Sciences, 2018, 8 (4) :495.
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_10" title="GALAR M, FERNANDEZ A, BARRENECHEA E, et al.EUSBoost:enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling[J].Pattern Recognition, 2013, 46 (12) :3460-3471." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300161907&amp;v=MTI4NzUrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpKS0YwVWF4VT1OaWZPZmJLOUg5UE9ySTlGWmUwT0JYdw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        GALAR M, FERNANDEZ A, BARRENECHEA E, et al.EUSBoost:enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling[J].Pattern Recognition, 2013, 46 (12) :3460-3471.
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_11" title="CHAWLA N V, BOWYER K W, HALL L O, et al.SMOTE:synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research, 2011, 16 (1) :321-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">
                                        <b>[11]</b>
                                        CHAWLA N V, BOWYER K W, HALL L O, et al.SMOTE:synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research, 2011, 16 (1) :321-357.
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_12" title="LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence in Medicine in Europe.Berlin:Springer, 2001:63-66." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">
                                        <b>[12]</b>
                                        LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence in Medicine in Europe.Berlin:Springer, 2001:63-66.
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_13" title="KUBAT M, MATWIN S.Addressing the curse of imbalanced training sets:one-sided selection[C]//Proceedings of the 14th International Conference on Machine Learning.New York:ACM, 1997:179-186." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Addressing the Curse of Imbalanced Training Sets:One-Sided Selection">
                                        <b>[13]</b>
                                        KUBAT M, MATWIN S.Addressing the curse of imbalanced training sets:one-sided selection[C]//Proceedings of the 14th International Conference on Machine Learning.New York:ACM, 1997:179-186.
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_14" title="TAHIR M A, KITTLER J, MIKOLAJCZYK K, et al.A multiple expert approach to the class imbalance problem using inverse random under sampling[C]//Proceedings of the 8th International Workshop on Multiple Classifier Systems.Berlin:Springer, 2009:82-91." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Multiple Expert Approach to the Class Imbalance Problem Using Inverse Random under Sampling">
                                        <b>[14]</b>
                                        TAHIR M A, KITTLER J, MIKOLAJCZYK K, et al.A multiple expert approach to the class imbalance problem using inverse random under sampling[C]//Proceedings of the 8th International Workshop on Multiple Classifier Systems.Berlin:Springer, 2009:82-91.
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_15" title="IMRAN M, RAO V S, AMARASIMHA T, et al.A novel technique on class imbalance big data using analogous over sampling approach[J].International Journal of Computational Intelligence Research, 2017, 13 (10) :2407-2417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel technique on class imbalance big data using analogous over sampling approach">
                                        <b>[15]</b>
                                        IMRAN M, RAO V S, AMARASIMHA T, et al.A novel technique on class imbalance big data using analogous over sampling approach[J].International Journal of Computational Intelligence Research, 2017, 13 (10) :2407-2417.
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_16" title="LIMA C F L, de ASSIS F M, de SOUZA C P.Decision tree based on Shannon, R&#233;nyi and Tsallis entropies for intrusion tolerant systems[C]//Proceedings of the 5th International Conference on Internet Monitoring and Protection.Piscataway, NJ:IEEE, 2010:117-122." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Decision tree based on Shannon R&amp;#233;nyi and Tsallis entropies for intrusion tolerant systems">
                                        <b>[16]</b>
                                        LIMA C F L, de ASSIS F M, de SOUZA C P.Decision tree based on Shannon, R&#233;nyi and Tsallis entropies for intrusion tolerant systems[C]//Proceedings of the 5th International Conference on Internet Monitoring and Protection.Piscataway, NJ:IEEE, 2010:117-122.
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_17" title="BOONCHUAY K, SINAPIROMSARAN K, LURSINSAP C.Decision tree induction based on minority entropy for the class imbalance problem[J].Pattern Analysis and Applications, 2017, 20 (3) :769-782." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Decision tree induction based on minority entropy for the class imbalance problem">
                                        <b>[17]</b>
                                        BOONCHUAY K, SINAPIROMSARAN K, LURSINSAP C.Decision tree induction based on minority entropy for the class imbalance problem[J].Pattern Analysis and Applications, 2017, 20 (3) :769-782.
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_18" title="KIRSHNERS A, PARSHUTIN S, GORSKIS H.Entropy-based classifier enhancement to handle imbalanced class problem[J].Procedia Computer Science, 2017, 104:586-591." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Entropy-based classifier enhancement to handle imbalanced class problem">
                                        <b>[18]</b>
                                        KIRSHNERS A, PARSHUTIN S, GORSKIS H.Entropy-based classifier enhancement to handle imbalanced class problem[J].Procedia Computer Science, 2017, 104:586-591.
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_19" title="LI X, ZHAO H, ZHU W.A cost sensitive decision tree algorithm with two adaptive mechanisms[J].Knowledge-Based Systems, 2015, 88:24-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA246F5C387083EAECDD8AA2F1D2F5F12&amp;v=MTY2MzRmQnJMVTA1dDlnekx1L3dhOD1OaWZPZmNLNkd0ZTZxdnhHYk93UEJIOU12bU5nbmt0MU9RN2cyaE5CZThTUk03dWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        LI X, ZHAO H, ZHU W.A cost sensitive decision tree algorithm with two adaptive mechanisms[J].Knowledge-Based Systems, 2015, 88:24-33.
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_20" title="郑燕, 王杨, 郝青峰, 等.用于不平衡数据分类的代价敏感超网络算法[J].计算机应用, 2014, 34 (5) :1336-1340. (ZHENG Y, WANG Y, HAO Q F, et al.Cost-sensitive hypernetworks for imbalanced data classification[J].Journal of Computer Applications, 2014, 34 (5) :1336-1340.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201405029&amp;v=MDA3MjU3RzRIOVhNcW85SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRG1VNzdQTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        郑燕, 王杨, 郝青峰, 等.用于不平衡数据分类的代价敏感超网络算法[J].计算机应用, 2014, 34 (5) :1336-1340. (ZHENG Y, WANG Y, HAO Q F, et al.Cost-sensitive hypernetworks for imbalanced data classification[J].Journal of Computer Applications, 2014, 34 (5) :1336-1340.) 
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_21" title="LEE S J, XU Z, LI T, et al.A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making[J].Journal of Biomedical Informatics, 2018, 78:144-155." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making">
                                        <b>[21]</b>
                                        LEE S J, XU Z, LI T, et al.A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making[J].Journal of Biomedical Informatics, 2018, 78:144-155.
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_22" title="QUINLAN J R.C4.5:Programs for Machine Learning[M].San Francisco, CA:Morgan Kaufmann, 1993:17-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=C4.5: Programs for Machine Learning">
                                        <b>[22]</b>
                                        QUINLAN J R.C4.5:Programs for Machine Learning[M].San Francisco, CA:Morgan Kaufmann, 1993:17-26.
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_23" title="FRANK E, HALL M A, WITTEN L H.The WEKA workbench.online appendix forData mining:practical machine learning tools and techniques[EB/OL]. (2016-11-22) [2018-05-04].https://www.cs.waikato.ac.nz/ml/weka/Witten_et_al_2016_appendix.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The WEKA Workbench">
                                        <b>[23]</b>
                                        FRANK E, HALL M A, WITTEN L H.The WEKA workbench.online appendix forData mining:practical machine learning tools and techniques[EB/OL]. (2016-11-22) [2018-05-04].https://www.cs.waikato.ac.nz/ml/weka/Witten_et_al_2016_appendix.pdf.
                                    </a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_24" title="DHANABAL L, SHANTHARAJAH S P.A study on NSL-KDDdataset for intrusion detection system based on classification algorithms[J].International Journal of Advanced Research in Computer and Communication Engineering, 2015, 4 (6) :446-452." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A study on NSL-KDDdataset for intrusion detection system based on classification algorithms">
                                        <b>[24]</b>
                                        DHANABAL L, SHANTHARAJAH S P.A study on NSL-KDDdataset for intrusion detection system based on classification algorithms[J].International Journal of Advanced Research in Computer and Communication Engineering, 2015, 4 (6) :446-452.
                                    </a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_25" title="ADEPU S, MATHUR A.An investigation into the response of a water treatment system to cyber attacks[C]//Proceedings of the 17th IEEEInternational Symposium on High Assurance Systems Engineering.Washington, DC:IEEE Computer Society, 2016:141-148." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Investigation into the Response of a Water Treatment System to Cyber Attacks">
                                        <b>[25]</b>
                                        ADEPU S, MATHUR A.An investigation into the response of a water treatment system to cyber attacks[C]//Proceedings of the 17th IEEEInternational Symposium on High Assurance Systems Engineering.Washington, DC:IEEE Computer Society, 2016:141-148.
                                    </a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_26" title="GOH J, ADEPU S, JUNEJO K N, et al.A dataset to support research in the design of secure water treatment systems[C]//Proceedings of the 11th International Conference on Critical Information Infrastructures Security.Berlin:Springer, 2016:88-99." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A dataset to support research in the design of secure water treatment systems">
                                        <b>[26]</b>
                                        GOH J, ADEPU S, JUNEJO K N, et al.A dataset to support research in the design of secure water treatment systems[C]//Proceedings of the 11th International Conference on Critical Information Infrastructures Security.Berlin:Springer, 2016:88-99.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-09-29 09:50</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),623-628 DOI:10.11772/j.issn.1001-9081.2018071513            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>针对不平衡数据的决策树改进方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BC%9F&amp;code=38690344&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E8%80%80%E6%BB%A8&amp;code=41276908&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢耀滨</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%B9%E9%9D%92&amp;code=41276909&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尹青</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%95%B0%E5%AD%A6%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%85%88%E8%BF%9B%E8%AE%A1%E7%AE%97%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%88%98%E7%95%A5%E6%94%AF%E6%8F%B4%E9%83%A8%E9%98%9F%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6&amp;code=1702647&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数学工程与先进计算国家重点实验室战略支援部队信息工程大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对异常检测中异常数据与正常数据的比例严重不平衡导致决策树性能下降的问题, 提出了C4.5决策树的三种改进方法——C4.5+<i>δ</i>、均匀分布熵 (UDE) 和改进分布熵函数 (IDEF) 。首先, 推导了C4.5算法中属性选择准则会倾向于选择偏斜划分的属性;然后, 分析了偏斜划分使得异常 (少数类) 检测精度下降的原因;其次, 分别通过引入缓和因子、均匀分布熵或替换分布熵函数改进了C4.5算法的属性选择准则——信息增益率;最后, 利用WEKA平台和NSL-KDD数据集对改进的决策树进行验证。实验结果表明, 三种改进方法均能提高异常检测精度。其中, 相比于C4.5, C4.5+7、UDE和IDEF算法在KDDTest-21数据集上的少数类检测精度 (灵敏度) 分别提高了3.16、3.02和3.12个百分点, 均优于采用Rényi熵和Tsallis熵作为分裂准则的方法。此外, 利用三种改进的决策树检测工业控制系统中的异常, 不仅可以提高异常的查全率还能减小误报率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不平衡数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">异常检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%86%B3%E7%AD%96%E6%A0%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">决策树;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=C4.5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">C4.5;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息增益率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王伟 (1993—) , 男, 浙江温州人, 硕士研究生, 主要研究方向:工控安全、机器学习;;
                                </span>
                                <span>
                                    *谢耀滨 (1981—) , 男, 福建龙海人, 副教授, 硕士, 主要研究方向:工控安全;电子邮箱xybsoft@gmail.com;
                                </span>
                                <span>
                                    尹青 (1968—) , 女, 江苏徐州人, 教授, 博士, 主要研究方向:信息安全、形式化验证、逆向分析。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61802431);</span>
                    </p>
            </div>
                    <h1><b>Decision tree improvement method for imbalanced data</b></h1>
                    <h2>
                    <span>WANG Wei</span>
                    <span>XIE Yaobin</span>
                    <span>YIN Qing</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Mathematic Engineering and Advanced Computing (Information Engineering University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Focusing on the problem that serious imbalance between abnormal data and normal data in anomaly detection will lead to performance degradation of decision tree, three improved methods for C4.5 decision tree were proposed, which are C4.5+<i>δ</i>, UDE (Uniform Distribution Entropy) and IDEF (Improved Distribution Entropy Function) . Firstly, it was deduced that the attribute selection criterion of C4.5 tends to choose the ones with imbalanced splitting. Secondly, why imbalanced splitting decreases the accuracy of anomaly (minority) detection was analyzed. Thirdly, the attribute selection criterion — information gain ratio of C4.5 was improved by introducing relaxation factor and uniform distribution entropy, or substituting distribution entropy function. Finally, three improved decision trees were verified on WEKA platform and NSL-KDD dataset. Experimental results show that three proposed improved methods can increase the accuracy of anomaly detection. Compared with C4.5, the accuracies of C4.5+7, UDE and IDEF on KDDTest-21 dataset are improved by 3.16, 3.02 and 3.12 percentage points respectively, which are better than the methods using Rényi entropy or Tsallis entropy as splitting criterion. Furthermore, using improved decision trees to detect anomalies in the industrial control system can not only improve the recall ratio of anomalies, but also reduce false positive rate.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=imbalanced%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">imbalanced data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=anomaly%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">anomaly detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=decision%20tree&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">decision tree;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=C4.5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">C4.5;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=information%20gain%20ratio&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">information gain ratio;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Wei, born in 1993, M. S. candidate. His research interests include industrial control security, machine learning.;
                                </span>
                                <span>
                                    XIE Yaobin, born in 1981, M. S. , associate professor. His research interests include industrial control security.;
                                </span>
                                <span>
                                    YIN Qing, born in 1968, Ph. D. , professor. Her research interests include information security, formal verification, reverse analysis.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-23</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61802431);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="57" name="57" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="58">异常检测是指从某个系统的日常数据中识别非预期模式, 即异常数据。异常通常由恶意行为或违规操作引发, 因此异常检测技术广泛应用于网络安全、故障检测等领域<citation id="309" type="reference"><link href="257" rel="bibliography" /><link href="259" rel="bibliography" /><link href="261" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">异常检测可以视为一种特殊的分类问题, 即分离目标数据集中的正常数据与异常数据。因此, 绝大多数基于机器学习的分类方法, 如神经网络、支持向量机、决策树等, 都可以应用于异常检测。然而异常检测面临数据不平衡问题, 即目标数据集中异常数据与正常数据的分布是不平衡的, 其中异常数据一般远远少于正常数据。数据不平衡问题在医疗诊断<citation id="310" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、信用卡诈骗检测<citation id="311" type="reference"><link href="265" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、银行风险管控<citation id="312" type="reference"><link href="267" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、系统故障检测<citation id="313" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等应用中十分常见。在传统分类问题中, 整体准确度由不同类别的准确度加权组成, 因此多数类的准确度对整体准确度的影响要远大于少数类。在传统方法中, 分类器会倾向于保证多数类的准确度而牺牲少数类的准确度, 导致少数类的漏报率较高。然而在很多异常检测的现实应用中将异常 (少数类) 误判为正常 (多数类) 的代价要远远高于相反的情况, 因此需要尽可能地检测出异常, 降低漏报率。例如, 在癌症的诊断中, 将癌症 (少数类) 患者误诊为健康 (多数类) 的危害要远大于将非癌症患者误诊为癌症的危害, 所以要保证检测结果为阳性时尽可能地覆盖真正的癌症患者。</p>
                </div>
                <div class="p1">
                    <p id="60">对于不平衡分类问题, 主要从数据和算法两个层面来解决<citation id="314" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。数据层面的方法首先通过数据预处理平衡数据分布从而消除多数类的影响, 而后运用传统方法进行分类;算法层面的方法通过修改学习算法来处理不平衡分类问题。这些方法保留原有方法的主体思想, 通过调整决策阈值使其偏向于少数类或者在学习过程中引入错误分类代价提高少数类的重要性。除此之外, 许多研究人员将数据层面和算法层面的方法相结合<citation id="315" type="reference"><link href="273" rel="bibliography" /><link href="275" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 为不平衡分类问题提供了全新的综合性解决方案。</p>
                </div>
                <div class="p1">
                    <p id="61">本文从算法层面入手, 对C4.5决策树的特征选择准则进行改进。本文的主要贡献在于:1) 提出了三种针对不平衡数据的C4.5决策树改进方法;2) 运用改进的决策树进行异常检测并验证了其有效性。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="63">为了提升机器学习算法处理不平衡数据的性能, 研究人员提出了许多解决办法, 大致可分为数据层面和算法层面。数据层面的方法独立于分类器, 具有较高的灵活性与普适性;算法层面的方法通过修改学习算法解决不平衡分类问题, 具有较强的针对性。</p>
                </div>
                <div class="p1">
                    <p id="64">数据层面包含过采样法、欠采样法、过采样和欠采样的综合法。采样方式分为启发式和非启发式, 非启发式采样法通常由随机过采样和随机欠采样组成。合成少数类过采样技术 (Synthetic Minority Oversampling TEchnique, SMOTE) <citation id="316" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是一种典型的启发式过采样方法, 该算法的提出是为了解决随机过采样法增加过拟合风险的问题。另外, 启发式过采样方法包括<i>K</i>近邻规则 (<i>K</i>-Nearest Neighbor, <i>K</i>NN) 、邻域清理规则 (Neighborhood CLeaning rule, NCL) <citation id="317" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、OSS (One-Sided Selection) <citation id="318" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>和IRUS (Inverse Random Under Sampling) <citation id="319" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="65">Imran等<citation id="320" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了OSIBD (Over Sampling on Imbalance Big Data) 算法提升不平衡分类的性能。该算法采用新型的过采样策略对数据集进行预处理。首先, 根据数据分布移除少数类样本中的噪声和边缘点;随后, 在处理后的少数类样本之间插入合成样本实现混合过采样;最后, 利用C4.5算法进行分类。实验结果证明, 改进后的方案中精确度、召回率均有所提升。</p>
                </div>
                <div class="p1">
                    <p id="66">在算法层面, 不同算法的解决方法有所差异, 下面将着重介绍关于决策树算法的相关研究工作。在传统的决策树算法中, 香农熵用于度量样例集合的不纯净度, 并作为树节点的分裂依据。Lima等<citation id="321" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>针对熵的测量方法对决策树进行改进, 分别采用Rényi熵和Tsallis熵代替香农熵作为分裂准则。在KDD (Knowledge Discovery and Data mining) 数据集上进行实验, 结果表明依据Rényi熵和Tsallis熵建立的决策树模型更加紧凑与高效。</p>
                </div>
                <div class="p1">
                    <p id="67">为了提升决策树在不平衡数据集上的学习性能, Boonchuay等<citation id="322" type="reference"><link href="289" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出了一种全新的不纯净度度量方法——少数类熵 (Minority Entropy, ME) 。首先, 确定少数类分布的范围并忽视范围外的多数类样本;随后, 计算并衡量少数类范围内的香农熵。该方法通过排除纯净部分的多数类样本, 缓解了不平衡分布的问题。</p>
                </div>
                <div class="p1">
                    <p id="68">Kirshners等<citation id="323" type="reference"><link href="291" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>在熵函数的计算公式中引入了权重概念。其中, 权重代表每一类样本的重要性, 且与分布概率成反比。改进的决策树算法在学习阶段之前计算初始的类分布概率, 提高学习阶段中对少数类的重视程度。实验结果表明在不同的数据集上该算法的敏感度 (即少数类的准确率) 有显著提升。</p>
                </div>
                <div class="p1">
                    <p id="69">代价敏感学习是一种解决不平衡分类问题的有效途径。Li等<citation id="324" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出了一种代价敏感决策树算法, 其中包含了两种自适应机制。自适应分割点选择机制将属性的代价引入到信息增益率的计算公式中, 代替原始的遍历选择机制;自适应属性删除机制在节点选择过程中删除冗余属性。相比于C4.5, 改进后的算法不仅降低了平均分类代价, 而且缩短了算法的运行时间;郑燕等<citation id="325" type="reference"><link href="295" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出了一种代价敏感超网络Boosting集成算法, 首先将代价敏感学习引入超网络模型, 而后利用Boosting算法对代价敏感超网络进行集成, 以处理不平衡数据分类问题。</p>
                </div>
                <div class="p1">
                    <p id="70">除此之外, 集成法通过综合多种方法为不平衡分类问题提供全新的综合性解决方案, 其优势在于通过融合不同方面的优势提高了算法的稳定性。文献<citation id="326" type="reference">[<a class="sup">21</a>]</citation>中介绍了一种基于包裹式特征选择的引导聚集 (Bagging) 框架, 该框架包含数据预处理和Bagging两个过程。数据预处理过程中, 首先采用随机欠采样压缩数据, 而后利用包裹式特征选择算法删除冗余属性;Bagging过程中, 通过引导采样生成多个子集, 而后在多个子集上分别训练决策树, 最终输出由多个决策树投票决定的结果。</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag">2 问题分析</h3>
                <div class="p1">
                    <p id="72">为了解决不平衡分类问题, 本章对决策树算法进行分析并寻找导致分类性能下降的原因。在2.1节中, 介绍了决策树算法的过程及相应的准则;在2.2节中, 通过分析两种数据分布情况探究C4.5算法中属性选择对不平衡数据分类的影响。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.1 <b>决策树算法</b></h4>
                <div class="p1">
                    <p id="74">决策树算法采用自上而下、分而治之的方式递归建立分类器。在训练集<i>D</i>={<i>X</i><sub><i>i</i></sub>, <i>Y</i><sub><i>i</i></sub>}<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow></math></mathml> (其中<i>X</i>代表特征属性, <i>Y</i>代表目标属性) 上, 决策树建立过程如下:</p>
                </div>
                <div class="p1">
                    <p id="76">1) 根据分裂准则, 在数据集<i>D</i>上选择一个最优分裂属性;</p>
                </div>
                <div class="p1">
                    <p id="77">2) 在最优分裂属性上选择最优分裂点, 将数据集<i>D</i>分为<i>D</i><sub>L</sub>和<i>D</i><sub>R</sub>两个子节点;</p>
                </div>
                <div class="p1">
                    <p id="78">3) 在子节点上重复上述步骤, 直到所有叶节点满足停止准则。</p>
                </div>
                <div class="p1">
                    <p id="79">在每次迭代过程中, 决策树随着子节点的分裂不断生长。当所有的叶节点均满足停止准则时, 决策树停止生长。停止准则通常由纯净度、叶节点数和树深度等条件组成。</p>
                </div>
                <div class="p1">
                    <p id="80">分裂准则通过计算不纯净度决定叶节点如何分裂。最常用的分裂准则是基于香农熵的信息增益:</p>
                </div>
                <div class="p1">
                    <p id="81"><i>IG</i> (<i>Y</i>|<i>X</i>) =<i>H</i><sub>Shannon</sub> (<i>Y</i>) -<i>E</i><sub><i>x</i></sub>[<i>H</i><sub>Shannon</sub> (<i>Y</i>|<i>x</i>) ]      (1) </p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext><mtext>a</mtext><mtext>n</mtext><mtext>n</mtext><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Y</mi></mrow><mi>n</mi></munderover><mi>p</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mspace width="0.25em" /><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中<i>IG</i>表示分裂前后的信息增益 (即熵的衰减值) 。香农熵的定义如式 (2) 所示, 其值域范围为[0, lb <i>n</i>], 当<i>p</i> (<i>y</i><sub><i>i</i></sub>) 相等时达到极大值, 当<i>p</i> (<i>y</i><sub><i>i</i></sub>) 等于0或1时达到最小值。因此, 最大化信息增益准则将引导节点向纯净分类。</p>
                </div>
                <div class="p1">
                    <p id="84">常用的决策树算法有ID3、C4.5<citation id="327" type="reference"><link href="299" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>等。ID3算法根据最大化信息增益准则选择最优分裂属性, 导致其倾向于选择取值多的属性; C4.5算法对ID3算法进行改进, 根据最大化信息增益率准则选择最优分裂属性。为了滤除虚高的信息增益率——低信息增益、低分布熵, C4.5算法涵盖一种启发式规则——首先滤除信息增益低于平均值的属性, 而后比较剩余属性的信息增益率。本文将在下一节中分析C4.5决策树建立过程中选择不同的属性对不平衡数据的影响。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2.2 C4.5<b>处理不平衡数据的不足</b></h4>
                <div class="p1">
                    <p id="86">C4.5算法根据信息增益率选择最优分裂属性, 信息增益率公式计算如下:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mi>G</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中<i>H</i> (<i>X</i>) 表示同级子节点的分布熵。随着子节点数量的增多, <i>H</i> (<i>X</i>) 相应增大, 从而抑制子节点数量对信息增益的影响。</p>
                </div>
                <div class="p1">
                    <p id="89">由于理想子节点数量未知, C4.5算法在处理连续型数值属性时, 采取迭代二元分裂的方式实现多元分裂。在每次迭代过程中, 节点分裂出两个子节点, 此时的信息增益不受子节点数量影响;而子节点权重的差异导致<i>H</i> (<i>X</i>) 在[0, 1]区间波动。当数据分布不平衡时, 子节点的权重存在严重偏斜的情况。当<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo>&gt;</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo>&lt;</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>→</mo><mn>1</mn></mrow></math></mathml>时, <i>H</i> (<i>X</i>) →0。在信息增益具有可比性的情况下, 算法倾向于选择偏斜划分的属性。</p>
                </div>
                <div class="p1">
                    <p id="91">接下来, 本文将通过分析两种分布情况探究C4.5算法中属性选择对不平衡数据分类的影响。图1展示了一种偏斜划分的数据分布情况, 其中当前节点的最优分裂属性为<i>X</i><sub>1</sub>, 三角形表示少数类, 圆形表示多数类, [<i>x</i><sub><i>a</i></sub>, <i>x</i><sub><i>b</i></sub>]为两类数据的重叠区。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903002_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 偏斜划分的数据分布" src="Detail/GetImg?filename=images/JSJY201903002_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 偏斜划分的数据分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903002_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Data distribution of imbalanced splitting</p>

                </div>
                <div class="p1">
                    <p id="93">C4.5决策树是以最大化信息增益为分裂准则 (式 (1) ) , 即最小化分裂后熵的期望值<i>E</i><sub><i>x</i></sub>[<i>H</i><sub>shannon</sub> (<i>Y</i>|<i>x</i>) ]。二元分裂的熵期望计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="94"><i>E</i><sub><i>x</i></sub>=<i>W</i> (<i>X</i>&gt;<i>x</i>) <i>H</i> (<i>Y</i>|<i>X</i>&gt;<i>x</i>) +<i>W</i> (<i>X</i>&lt;<i>x</i>) <i>H</i> (<i>Y</i>|<i>X</i>&lt;<i>x</i>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="95">当分裂点为<i>x</i><sub><i>a</i></sub>时, <i>H</i> (<i>Y</i>|<i>X</i>&lt;<i>x</i><sub><i>a</i></sub>) =0, 熵期望简化为<i>E</i><sub><i>x</i></sub>[<i>H</i> (<i>Y</i>|<i>x</i><sub><i>a</i></sub>) ]=<i>W</i> (<i>X</i>&gt;<i>x</i><sub><i>a</i></sub>) <i>H</i> (<i>Y</i>|<i>X</i>&gt;<i>x</i><sub><i>a</i></sub>) ;当分裂点为<i>x</i><sub><i>b</i></sub>时, <i>H</i> (<i>Y</i>|<i>X</i>&gt;<i>x</i><sub><i>b</i></sub>) =0, 熵期望简化为 <i>E</i><sub><i>x</i></sub>[<i>H</i> (<i>Y</i>|<i>x</i><sub><i>b</i></sub>) ]=<i>W</i> (<i>X</i>&lt;<i>x</i><sub><i>b</i></sub>) <i>H</i> (<i>Y</i>|<i>X</i>&lt;<i>x</i><sub><i>b</i></sub>) 。显而易见, <i>E</i><sub><i>x</i></sub>[<i>H</i> (<i>Y</i>|<i>x</i><sub><i>a</i></sub>) ]&lt;<i>E</i><sub><i>x</i></sub>[<i>H</i> (<i>Y</i>|<i>x</i><sub><i>b</i></sub>) ]。此时, 倾向于选择<i>x</i><sub><i>a</i></sub>为最优分裂点。</p>
                </div>
                <div class="p1">
                    <p id="96">当根据<i>x</i><sub><i>a</i></sub>划分后, <i>X</i>&lt;<i>x</i><sub><i>a</i></sub>的样例从数据集中剔除, <i>X</i>&gt;<i>x</i><sub><i>a</i></sub>的样例进入下一轮迭代。而在下一轮迭代中, 少数类的减少使得不平衡加剧, 从节点样例中剔除少数类的难度将进一步加大。当多数类中混叠的少数类小于一定的比例时, 算法停止迭代。最终以牺牲少数类的准确度为代价, 保全整体的准确率。</p>
                </div>
                <div class="p1">
                    <p id="97">图2展示了一种平均划分的数据分布情况, 此类情况通常在属性选择阶段被忽视。其中, 当前节点的最优分裂属性为<i>X</i><sub>2</sub>, 三角形表示少数类, 圆形表示多数类, [<i>x</i><sub><i>a</i></sub>, <i>x</i><sub><i>b</i></sub>]为两类数据的重叠区。</p>
                </div>
                <div class="p1">
                    <p id="98">假设多数类样本数是少数类的<i>n</i>倍 (即不平衡率为<i>n</i>) , 且重叠区不平衡率与整体保持一致。如果少数类总数为<i>N</i>、重叠区中有<i>z</i>个少数类, 则多数类总数为<i>nN</i>且重叠区中有<i>nz</i>个多数类。重叠区样本数占整体的比例为<i>ξ</i>并且可以忽略不计, 则<i>W</i> (<i>X</i>&lt;<i>x</i><sub><i>a</i></sub>) /<i>W</i> (<i>X</i>) ≈<i>W</i> (<i>X</i>&lt;<i>x</i><sub><i>b</i></sub>) /<i>W</i> (<i>X</i>) =<i>η</i>。</p>
                </div>
                <div class="p1">
                    <p id="99">当分裂点为<i>x</i><sub><i>a</i></sub>时, 属性值小于<i>x</i><sub><i>a</i></sub>的子节点纯净——即<i>IR</i> (<i>Y</i>|<i>X</i>&lt;<i>x</i><sub><i>a</i></sub>) =0, 属性值大于<i>x</i><sub><i>a</i></sub>的子节点不纯净度为<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>R</mi><mo stretchy="false"> (</mo><mrow><mi>Y</mi><mo stretchy="false">|</mo></mrow><mrow><mi>X</mi><mo>&gt;</mo></mrow><mi>x</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mi>Ν</mi><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>Ν</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, 熵期望简化为<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">[</mo><mi>Η</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext><mtext>a</mtext><mtext>n</mtext><mtext>n</mtext><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mi>Η</mi><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>, 其中<i>H</i> (<i>p</i>) 代表<i>H</i> (<i>p</i>, 1-<i>p</i>) ;当分裂点为<i>x</i><sub><i>b</i></sub>时, 属性值小于<i>x</i><sub><i>b</i></sub>的子节点不纯净度为<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo>&lt;</mo><mi>x</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mi>z</mi><mrow><mi>η</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>Ν</mi></mrow></mfrac><mo>=</mo><mfrac><mi>ξ</mi><mrow><mi>η</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, 属性值大于<i>x</i><sub><i>b</i></sub>的子节点不纯净度为<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo>&gt;</mo><mi>x</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ν</mi><mo>-</mo><mi>z</mi></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>Ν</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>ξ</mi></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, 熵期望简化为<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>E</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">[</mo><mi>Η</mi><mo stretchy="false">]</mo><mo>=</mo></mrow><mi>η</mi><mi>Η</mi><mrow><mo> (</mo><mrow><mfrac><mi>ξ</mi><mrow><mi>η</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mi>Η</mi><mrow><mo> (</mo><mrow><mfrac><mrow><mn>1</mn><mo>-</mo><mi>ξ</mi></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="105">当<i>η</i>→0.5时, 由于熵函数的凸函数性质, 显然<i>E</i><sub><i>x</i></sub>[<i>H</i><sub>Shannon</sub> (<i>Y</i>|<i>x</i><sub><i>a</i></sub>) ]&lt;<i>E</i><sub><i>x</i></sub>[<i>H</i><sub>Shannon</sub> (<i>Y</i>|<i>x</i><sub><i>b</i></sub>) ]。当根据最优分裂点<i>x</i><sub><i>a</i></sub>划分后, 将<i>X</i>&lt;<i>x</i><sub><i>a</i></sub>的样例从数据集中剔除, <i>X</i>&gt;<i>x</i><sub><i>a</i></sub>的样例进入下一轮迭代。而在下一轮迭代中, 多数类的减少使得不平衡情况有所缓解。理想情况下, 经过多轮迭代后节点的类别分布平衡。</p>
                </div>
                <div class="p1">
                    <p id="106">本章以两种分布情况为例探究了属性选择对不平衡数据分类的影响。经过分析得知, 选择平均划分的属性有助于解决不平衡分类问题。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903002_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 平均划分的数据分布" src="Detail/GetImg?filename=images/JSJY201903002_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 平均划分的数据分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903002_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Data distribution of balanced splitting</p>

                </div>
                <h3 id="108" name="108" class="anchor-tag">3 改进方法</h3>
                <div class="p1">
                    <p id="109">为了缓和或消除分布熵对信息增益率的影响, 本章结合上文的分析, 提出了三种信息增益率的改进方法。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110">1) 引入缓和因子<i>δ</i>。</h4>
                <div class="p1">
                    <p id="111">信息增益率计算公式 (式 (3) ) 中, 分布熵<i>H</i> (<i>X</i>) 在0到1之间变化。在极端情况下, 信息增益率是信息增益的无穷倍, 此时信息增益明显起不到主导作用。因此, 在信息增益率的计算公式中引入缓和因子<i>δ</i>。改进后的信息增益率计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mi>G</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>+</mo><mi>δ</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">引入缓和因子后, 信息增益率被限定在<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mi>Ι</mi><mi>G</mi></mrow><mrow><mi>δ</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mo>, </mo><mfrac><mrow><mi>Ι</mi><mi>G</mi></mrow><mi>δ</mi></mfrac></mrow><mo>]</mo></mrow></mrow></math></mathml>范围, 削弱了分布熵对于信息增益的抑制作用。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">2) 用均匀分布熵代替分布熵。</h4>
                <div class="p1">
                    <p id="116">为了消除枚举型属性的子节点数量对信息增益的影响, C4.5算法引入分布熵。而在处理连续数值型属性时, 采取迭代二元分裂的方式实现多元分裂。在每一次迭代过程中, 节点分裂数为2, 此时信息增益不受子节点数量的影响。但在面对不平衡数据时, 分布熵抑制了信息增益的主导作用。因此, 本方法采用均匀分布熵 (Uniform Distribution Entropy, UDE) 代替分布熵, 改进后的信息增益率计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mi>G</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>/</mo><mi>n</mi><mo>, </mo><mn>1</mn><mo>/</mo><mi>n</mi><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>1</mn><mo>/</mo><mi>n</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中<i>n</i>为样例子集的数量。</p>
                </div>
                <div class="p1">
                    <p id="119">改进后的信息增益率不仅抵消了子节点数量对信息增益的影响, 而且消除了子节点的分布情况对信息增益的影响。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120">3) 改进分布熵函数。</h4>
                <div class="p1">
                    <p id="121">二元香农分布熵函数的图像如图3中虚线部分所示。二元分布从[0.5, 0.5] (即平均分布) 到[0.1, 0.9]的过程中, 香农熵衰减超过50%。此时, 分布熵在信息增益率中占据主导地位, 因此, 可通过改进分布熵函数 (Improved Distribution Entropy Function, IDEF) 削弱分布熵的影响, 即采用从平均分布到偏斜分布的过程中衰减缓慢的函数代替分布熵函数。新函数需满足熵函数的部分性质, 如对称性、确定性、非负性、连续性、上凸性和极值性等。本方法采用如下函数代替香农分布熵函数:</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>k</mi><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>α</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">其中:<i>k</i>为系数, <i>α</i>为可调参数, 且<i>α</i>&lt;1。为了使峰值与原函数保持一致, 将<i>k</i>设为<i>n</i><sup><i>nα</i></sup>lb <i>n</i>。<i>C</i> (<i>X</i>) 的图像如图3中最上方曲线所示, 当<i>α</i>=1/3时, 二元分布从[0.5, 0.5]到[0.1, 0.9]的过程中, 衰减减少至30%以内。</p>
                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903002_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 香农熵和C (X)" src="Detail/GetImg?filename=images/JSJY201903002_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 香农熵和<i>C</i> (<i>X</i>)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903002_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Shannon entropy and <i>C</i> (<i>X</i>) </p>

                </div>
                <h3 id="125" name="125" class="anchor-tag">4 实验与评估</h3>
                <div class="p1">
                    <p id="126">本章将通过两部分实验对所提方法的有效性进行验证。4.1节将展示在NSL-KDD数据集上评估提出的方法处理不平衡数据的性能, 并与采用Rényi熵和Tsallis熵的方法进行对比;4.2节将利用改进的决策树进行工业控制系统中的异常检测;本文实验依托由新西兰怀卡托大学开发的公开数据挖掘工作平台——怀卡托智能分析环境 (Waikato Environment for Knowledge Analysis, WEKA) <citation id="328" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 通过修改WEKA 3.8.2中的J48 (即C4.5) 决策树实现。实验采用十折交叉验证方式, 并开启剪枝过程。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">4.1 NSL-KDD<b>测试</b></h4>
                <div class="p1">
                    <p id="128">NSL-KDD数据集<citation id="329" type="reference"><link href="303" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>是一个面向网络入侵检测系统的公开数据集, 共包含41维特征属性以及1维目标属性。KDDTest-21数据集包含2 152个正常样本与9 698个异常样本;KDDTrain+数据集包含67 343个异常样本、58 630个正常样本。为了使偏斜率多样化并且降低数据规模, 本文对KDDTrain+数据集中的异常样本和正常样本随机抽样, 构造了5个不同偏斜率的数据集。本节实验中使用的数据集如表1所示。</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表</b>1 <b>实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Experimental datasets</p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />数据集</td><td>正样本数</td><td>负样本数</td><td>偏斜率</td></tr><tr><td><br />KDDTest-21</td><td>2 152</td><td>9 698</td><td>4.51</td></tr><tr><td><br />KDD101</td><td>1 000</td><td>10 000</td><td>10.00</td></tr><tr><td><br />KDD102</td><td>2 000</td><td>10 000</td><td>5.00</td></tr><tr><td><br />KDD103</td><td>3 000</td><td>10 000</td><td>3.33</td></tr><tr><td><br />KDD104</td><td>4 000</td><td>10 000</td><td>2.50</td></tr><tr><td><br />KDD105</td><td>5 000</td><td>10 000</td><td>2.00</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="130">在不平衡数据的情况下, 准确率和错误率不足以衡量分类算法的性能。因此, 本文额外引入两项衡量指标——灵敏度 (又称为召回率或查全率) 和特异度。灵敏度表示分类算法正确预测正样本数量占实际正样本数量的百分率, 其公式表述如式8所示。其中, 真阳性 (True Positives, TP) 表示预测为正的正样本数, 假阴性 (False Negatives, FN) 表示预测为负的正样本数。</p>
                </div>
                <div class="p1">
                    <p id="131"><i>Sensitivity</i>=<i>TP</i>/ (<i>TP</i>+<i>FN</i>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="132">特异度表示分类算法正确预测负样本数量占实际负样本数量的百分率, 其公式表述如式 (9) 所示。其中, 真阴性 (True Negatives, TN) 表示预测为负的负样本数, 假阳性 (False Positives, FP) 表示预测为正的负样本数。</p>
                </div>
                <div class="p1">
                    <p id="133"><i>Specificity</i>=<i>TN</i>/ (<i>TN</i>+<i>FP</i>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="134">本文提出的方法在KDDTest-21及KDD101～105数据集上的结果对比如表2所示。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表</b>2 <b>各决策树结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Comparison of results for each decision trees</p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td>数据集</td><td>算法</td><td>准确<br />率/%</td><td>错误<br />率/%</td><td>灵敏<br />度/%</td><td>特异<br />度/%</td><td>叶节<br />点数</td><td>决策树<br />大小</td></tr><tr><td rowspan="8"><br />KDDTest-21</td><td>C4.5</td><td>97.12</td><td>2.88</td><td>90.75</td><td>98.54</td><td>500</td><td>590</td><td rowspan="50"></td><td rowspan="50"></td><td rowspan="50"></td><td rowspan="50"></td><td rowspan="50"></td><td rowspan="50"></td></tr><tr><td><br />C4.5+3</td><td>97.68</td><td>2.32</td><td>93.63</td><td>98.58</td><td>539</td><td>632</td></tr><tr><td><br />C4.5+5</td><td>97.59</td><td>2.41</td><td>93.40</td><td>98.52</td><td>472</td><td>566</td></tr><tr><td><br />C4.5+7</td><td>97.76</td><td>2.24</td><td>93.91</td><td>98.62</td><td>196</td><td>286</td></tr><tr><td><br />UDE</td><td>97.74</td><td>2.26</td><td>93.77</td><td>98.62</td><td>172</td><td>265</td></tr><tr><td><br />IDEF</td><td>97.75</td><td>2.25</td><td>93.87</td><td>98.61</td><td>225</td><td>317</td></tr><tr><td><br />Rényi</td><td>97.51</td><td>2.49</td><td>93.63</td><td>98.37</td><td>454</td><td>558</td></tr><tr><td><br />Tsallis</td><td>97.54</td><td>2.46</td><td>92.94</td><td>98.57</td><td>576</td><td>656</td></tr><tr><td rowspan="8"><br />KDD101</td><td><br />C4.5</td><td>99.55</td><td>0.45</td><td>97.40</td><td>99.76</td><td>105</td><td>133</td></tr><tr><td><br />C4.5+3</td><td>99.67</td><td>0.33</td><td>97.90</td><td>99.85</td><td>138</td><td>159</td></tr><tr><td><br />C4.5+5</td><td>99.75</td><td>0.25</td><td>98.80</td><td>99.85</td><td>205</td><td>227</td></tr><tr><td><br />C4.5+7</td><td>99.70</td><td>0.30</td><td>98.20</td><td>99.85</td><td>205</td><td>227</td></tr><tr><td><br />UDE</td><td>99.82</td><td>0.18</td><td>98.90</td><td>99.91</td><td>138</td><td>159</td></tr><tr><td><br />IDEF</td><td>99.72</td><td>0.28</td><td>97.70</td><td>99.92</td><td>109</td><td>135</td></tr><tr><td><br />Rényi</td><td>99.66</td><td>0.34</td><td>97.50</td><td>99.88</td><td>156</td><td>187</td></tr><tr><td><br />Tsallis</td><td>99.58</td><td>0.42</td><td>97.10</td><td>99.83</td><td>147</td><td>168</td></tr><tr><td rowspan="8"><br />KDD102</td><td><br />C4.5</td><td>99.48</td><td>0.53</td><td>97.80</td><td>99.81</td><td>44</td><td>78</td></tr><tr><td><br />C4.5+3</td><td>99.65</td><td>0.35</td><td>98.65</td><td>99.85</td><td>145</td><td>169</td></tr><tr><td><br />C4.5+7</td><td>99.65</td><td>0.35</td><td>98.70</td><td>99.84</td><td>145</td><td>169</td></tr><tr><td><br />C4.5+11</td><td>99.66</td><td>0.34</td><td>98.75</td><td>99.84</td><td>152</td><td>176</td></tr><tr><td><br />UDE</td><td>99.64</td><td>0.36</td><td>98.60</td><td>99.85</td><td>145</td><td>169</td></tr><tr><td><br />IDEF</td><td>99.62</td><td>0.38</td><td>98.60</td><td>99.82</td><td>137</td><td>171</td></tr><tr><td><br />Rényi</td><td>99.48</td><td>0.52</td><td>97.95</td><td>99.79</td><td>176</td><td>210</td></tr><tr><td><br />Tsallis</td><td>99.51</td><td>0.49</td><td>97.75</td><td>99.86</td><td>164</td><td>198</td></tr><tr><td rowspan="9"><br />KDD103</td><td><br />C4.5</td><td>99.38</td><td>0.62</td><td>98.40</td><td>99.68</td><td>177</td><td>218</td></tr><tr><td><br />C4.5+3</td><td>99.51</td><td>0.49</td><td>98.40</td><td>99.84</td><td>217</td><td>241</td></tr><tr><td><br />C4.5+7</td><td>99.49</td><td>0.51</td><td>98.37</td><td>99.83</td><td>216</td><td>239</td></tr><tr><td><br />C4.5+11</td><td>99.58</td><td>0.42</td><td>98.80</td><td>99.81</td><td>176</td><td>202</td></tr><tr><td><br />C4.5+15</td><td>99.58</td><td>0.42</td><td>98.80</td><td>99.81</td><td>113</td><td>146</td></tr><tr><td><br />UDE</td><td>99.48</td><td>0.52</td><td>98.53</td><td>99.76</td><td>147</td><td>171</td></tr><tr><td><br />IDEF</td><td>99.57</td><td>0.43</td><td>98.83</td><td>99.68</td><td>131</td><td>164</td></tr><tr><td><br />Rényi</td><td>99.52</td><td>0.48</td><td>98.50</td><td>99.82</td><td>97</td><td>132</td></tr><tr><td><br />Tsallis</td><td>99.48</td><td>0.52</td><td>98.60</td><td>99.75</td><td>240</td><td>276</td></tr><tr><td rowspan="9"><br />KDD104</td><td><br />C4.5</td><td>99.41</td><td>0.59</td><td>98.73</td><td>99.69</td><td>175</td><td>217</td></tr><tr><td><br />C4.5+5</td><td>99.56</td><td>0.44</td><td>98.90</td><td>99.82</td><td>179</td><td>203</td></tr><tr><td><br />C4.5+10</td><td>99.56</td><td>0.44</td><td>98.90</td><td>99.82</td><td>179</td><td>203</td></tr><tr><td><br />C4.5+15</td><td>99.67</td><td>0.33</td><td>99.28</td><td>99.83</td><td>175</td><td>203</td></tr><tr><td><br />C4.5+20</td><td>99.68</td><td>0.32</td><td>99.28</td><td>99.84</td><td>115</td><td>144</td></tr><tr><td><br />UDE</td><td>99.56</td><td>0.44</td><td>98.95</td><td>99.81</td><td>163</td><td>187</td></tr><tr><td><br />IDEF</td><td>99.66</td><td>0.34</td><td>99.28</td><td>99.82</td><td>130</td><td>158</td></tr><tr><td><br />Rényi</td><td>99.46</td><td>0.54</td><td>98.65</td><td>99.79</td><td>109</td><td>148</td></tr><tr><td><br />Tsallis</td><td>99.39</td><td>0.61</td><td>98.65</td><td>99.69</td><td>361</td><td>399</td></tr><tr><td rowspan="8"><br />KDD105</td><td><br />C4.5</td><td>99.35</td><td>0.65</td><td>99.06</td><td>99.50</td><td>181</td><td>225</td></tr><tr><td><br />C4.5+3</td><td>99.54</td><td>0.46</td><td>99.04</td><td>99.79</td><td>160</td><td>192</td></tr><tr><td><br />C4.5+7</td><td>99.55</td><td>0.45</td><td>99.04</td><td>99.80</td><td>221</td><td>252</td></tr><tr><td><br />C4.5+11</td><td>99.65</td><td>0.35</td><td>99.42</td><td>99.77</td><td>176</td><td>209</td></tr><tr><td><br />UDE</td><td>99.61</td><td>0.39</td><td>99.22</td><td>99.80</td><td>168</td><td>201</td></tr><tr><td><br />IDEF</td><td>99.62</td><td>0.38</td><td>99.22</td><td>99.82</td><td>135</td><td>166</td></tr><tr><td><br />Rényi</td><td>99.52</td><td>0.48</td><td>99.00</td><td>99.78</td><td>172</td><td>209</td></tr><tr><td><br />Tsallis</td><td>99.46</td><td>0.54</td><td>99.02</td><td>99.68</td><td>180</td><td>215</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">第一列表示数据集名称, 第二列为决策树及其改进方法的简称, 其中C4.5+<i>δ</i>表示方法 (一) 引入缓和因子<i>δ</i>、UDE表示方法 (二) 用均匀分布熵代替分布熵、IDEF表示方法 (三) 改进分布熵函数。此外, 文献<citation id="330" type="reference">[<a class="sup">16</a>]</citation>中提出的基于Rényi熵和Tsallis熵的决策树作为本文的比对方法, 作者针对不纯净度的度量方法对决策树进行改进, 分别采用Rényi熵和Tsallis熵代替香农熵作为分裂准则。Rényi熵和Tsallis熵的计算公式如式 (10) 和式 (11) 所示:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><msub><mrow></mrow><mi>α</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>-</mo><mi>α</mi></mrow></mfrac><mspace width="0.25em" /><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>α</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mi>α</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>α</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>α</mi></msubsup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">在KDDTest-21数据集上, C4.5+<i>δ</i>、UDE、IDEF相对于C4.5均有所提升, 且C4.5+<i>δ</i>提升幅度最大, 如表2所示 (加粗部分表示最佳性能) 。当<i>δ</i>=7时, C4.5+7的准确率达到97.76%。与C4.5算法相比, C4.5+7的灵敏度 (少数类的分类精度) 提升了3.16个百分比, 且特异度 (即多数类的分类精度) 也有小幅提升。而Rényi熵和Tsallis熵在提升灵敏度的同时, 特异度有所下降。此外, 叶节点数与决策树大小代表模型的复杂度 (后续分析中以决策树大小代表模型复杂度) 。与C4.5算法相比, C4.5+7算法生成的决策树减小了51.53%。因此, 三种改进方法在提升检测效果的同时, 又大幅度降低了模型的复杂度。</p>
                </div>
                <div class="p1">
                    <p id="139">接下来, 利用KDD101～105数据集对三种改进方法进行验证与对比, 以探究在不同偏斜率的情况下三种算法的适用性。在KDD101数据集上, C4.5+<i>δ</i>、UDE、IDEF相对于C4.5均有所提升。其中, UDE算法在准确率、错误率和灵敏度上均取得了最优值。相比于C4.5算法, C4.5+5、UDE、IDEF算法的灵敏度分别提升了1.4%、1.5%、0.3%;在特异度指标方面, UDE算法略逊色于IDEF算法。虽然三种改进方法均不同程度上增加了模型的复杂度 (UDE模型复杂度相对于C4.5算法提高了19.55个百分点) , 但仍优于Rényi熵和Tsallis熵 (Rényi熵和Tsallis熵分别提高了40.6和26.32个百分点) 。因此, 可理解为由于KDD101数据集偏斜严重, 提高模型复杂度是提升决策树性能的必要条件。</p>
                </div>
                <div class="p1">
                    <p id="140">在KDD102上, C4.5+<i>δ</i>、UDE、IDEF相对于C4.5算法均有所提升。当<i>δ</i>增至11时, C4.5+<i>δ</i>的各项性能指标达到最优值, 其中灵敏度从97.8%提升至98.75%;尽管Tsallis熵方法的特异度达到了99.86%, 但灵敏度相对于原始算法有所下降。在此数据集上虽然Tsallis熵方法提高了准确率, 但其显然不是解决不平衡分类问题的有效方法。</p>
                </div>
                <div class="p1">
                    <p id="141">从KDD101至KDD104, 数据集趋于平衡, C4.5+<i>δ</i>性能最优时对应的参数<i>δ</i>逐渐增大。当<i>δ</i>大于最优值后, 性能趋于稳定, 但随着<i>δ</i>增大模型趋于简单化。除此之外, 随着不平衡情况的减缓, 改进方法的提升幅度逐渐降低, 而Rényi熵和Tsallis熵方法逐渐失效。例如, 在KDD104数据集上, 虽然基于Rényi熵的方法准确率高于C4.5算法, 但其灵敏度相对于C4.5算法有所降低。与KDD104类似, Rényi熵和Tsallis熵方法在KDD105数据集上 (即面临轻微不平衡的情况时) 失去效果。</p>
                </div>
                <div class="p1">
                    <p id="142">表2展示了几种方法在面临不同偏斜率的数据集时的性能。总体而言, C4.5+<i>δ</i>在解决不平衡分类问题时表现出了突出的性能;而UDE与IDEF也拥有解决不平衡分类问题的能力, 并且相对于C4.5+<i>δ</i>而言, 具有更好的泛化性能。</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143">4.2 <b>工业控制过程的异常检测</b></h4>
                <div class="p1">
                    <p id="144">工业控制过程的异常检测常常也面临数据不平衡问题, 因为工控系统中正常状态明显多于异常状态。本节利用改进的决策树算法进行工业控制领域的异常检测, 进而证明所提方法的实用价值。</p>
                </div>
                <div class="p1">
                    <p id="145">水处理安全测试平台 (Secure Water Treatment, SWaT) <citation id="331" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>是现实工业中水处理工厂的模型, 其处理过程共分为6个阶段, 如图4所示。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903002_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SWaT测试平台过程概述" src="Detail/GetImg?filename=images/JSJY201903002_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SWaT测试平台过程概述  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903002_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Overview of SWaT testbed processes</p>

                </div>
                <div class="p1">
                    <p id="147">SWaT数据集<citation id="332" type="reference"><link href="307" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>共记录了该系统11天的运行数据。前7天系统正常运行, 后4天对该系统不定时发动36次攻击。</p>
                </div>
                <div class="p1">
                    <p id="148">本节实验在SWaT后4天记录的数据上进行, 共包含396 019个正常数据与53 900个异常数据。检测结果通过混淆矩阵直观展示, 混淆矩阵定义如表3所示。</p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit"><b>表</b>3 <b>混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Confusion matrix</p>
                    <p class="img_note"></p>
                    <table id="149" border="1"><tr><td rowspan="2"><br />实际</td><td colspan="2"><br />预测</td></tr><tr><td><br />正样本</td><td>负样本</td></tr><tr><td><br />正样本</td><td>TP</td><td>FN</td></tr><tr><td><br />负样本</td><td>FP</td><td>TP</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="150">C4.5算法及三种改进方法关于SWaT的异常检测结果如表4所示。原始的C4.5算法检测结果中, 异常数据的漏报数量为119, 误报数量为90。此时, C4.5算法向正常类偏斜。当<i>δ</i>=7时, C4.5+<i>δ</i>算法的检测效果最佳。其中, 异常的漏报数量为92, 而误报数量为82。与C4.5算法相比, C4.5+7算法的漏检率减小了22.69%、误报率减小了8.89%。从实验结果来看, 两类数据的错误分类数量基本持平。因此, C4.5+<i>δ</i>基本上解决了不平衡分类问题。另外, UDE与IDEF的检测结果相同。相对于C4.5而言, 异常的漏报数量从119减少至103, 而误报数量从90减少至97。从实验效果来看, UDE和IDEF算法在一定程度上缓解了不平衡分类问题。</p>
                </div>
                <div class="p1">
                    <p id="151">由表4可知, 三种改进方法均能改善工控异常检测中的不平衡分类问题。其中, UDE与IDEF提高了异常的检测效率, 但未彻底解决不平衡问题;而C4.5+<i>δ</i>提升效果明显优于UDE与IDEF, 经过改进, 异常数据和正常数据的错误分类数量基本持平, 基本上解决了异常检测的不平衡问题。</p>
                </div>
                <div class="area_img" id="152">
                                            <p class="img_tit">
                                                <b>表</b>4 SWaT<b>检测结果</b>
                                                    <br />
                                                Tab. 4 Detection results for SWaT
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903002_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201903002_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903002_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 SWaT检测结果" src="Detail/GetImg?filename=images/JSJY201903002_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="153" name="153" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="154">在平衡数据的分类任务中, 决策树因其简单高效且具有强解释性而备受瞩目。然而, 当面临不平衡数据时, 决策树算法偏向于多数类使其性能大打折扣。同时, 在异常检测任务中, 尽管异常数据远远少于正常数据, 但异常数据的检测率尤其重要。因此, 本文分析了C4.5决策树的不平衡原因, 并提出了属性选择准则的三种改进方法——C4.5+<i>δ</i>、UDE、IDEF。</p>
                </div>
                <div class="p1">
                    <p id="155">对改进的决策树算法在不同偏斜率的KDD数据集上进行测试, 三种方法的灵敏度和特异度均有明显提升。与Rényi熵和Tsallis熵相比, 本文提出的方法在提升少数类准确率的同时, 还保证了多数类的准确率。最后, 改进的决策树应用于工业控制系统的异常检测过程中, 实验结果证明本文提出的方法能改善不平衡分类问题。</p>
                </div>
                <div class="p1">
                    <p id="156">计划从数据层面开展下一步工作, 提出适用于异常检测的人工合成少数类方法, 结合本文的方法形成综合性解决方案, 进一步提升异常检测的性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="257">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A geometric framework for unsupervised anomaly detection">

                                <b>[1]</b>ESKIN E, ARNOLD A, PRERAU M, et al.A geometric framework for unsupervised anomaly detection[J].Applications of Data Mining in Computer Security, 2002, 6:77-101.
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501446177&amp;v=MjU3Mjcrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpKS0YwVWF4VT1OaWZPZmJLN0h0RE5xbzlFWU84SkRYcw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>ISERMANN R, BALLE P.Trends in the application of model-based fault detection and diagnosis of technical processes[J].Control Engineering Practice, 1997, 5 (5) :709-719.
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Survey of fraud detection techniques">

                                <b>[3]</b>KOU Y, LU C T, SIRWONGWATTANA S, et al.Survey of fraud detection techniques[C]//Proceedings of the 2004 IEEE International Conference on Networking, Sensing and Control.Piscataway, NJ:IEEE, 2004:749-754.
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201707031&amp;v=MTQwODRSN3FmWnVacEZpRG1VNzdQTHo3QmQ3RzRIOWJNcUk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>王莉莉, 付忠良, 陶攀, 等.基于主动学习不平衡多分类AdaBoost算法的心脏病分类[J].计算机应用, 2017, 37 (7) :1994-1998. (WANG L L, FU Z L, TAO P, et al.Heart disease classification based on active imbalance multi-class Ada Boost algorithm[J].Journal of Computer Applications, 2017, 37 (7) :1994-1998.) 
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Credit card fraud detection using convolutional neural networks">

                                <b>[5]</b>FU K, CHENG D, TU Y, et al.Credit card fraud detection using convolutional neural networks[C]//Proceedings of the 2016 International Conference on Neural Information Processing.Berlin:Springer, 2016:483-490.
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15D14C7870ECFBCCBF5DA12B084298D4&amp;v=MjA4MjY3ZzNoSTlmYkNkVGM2YkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXQ5Z3pMdS93YTg9TmlmT2ZiSzlhdERJM0loTlkrdDZmd3BMdkdWaG5Eb0pPWA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>DANENAS P, GARSVA G.Selection of support vector machines based classifiers for credit risk domain[J].Expert Systems with Applications, 2015, 42 (6) :3194-3204.
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Early fault detection in induction motors using Ada Boost with imbalanced small data and optimized sampling">

                                <b>[7]</b>MARTIN-DIAZ I, MORINIGO-SOTELO D, DUQUE-PEREZ O, et al.Early fault detection in induction motors using Ada Boost with imbalanced small data and optimized sampling[J].IEEE Transactions on Industry Applications, 2017, 53 (3) :3066-3075.
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2018S1005&amp;v=MDkwNDhadVpwRmlEbVU3N1BMejdCYjdHNEg5bXZybzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>赵楠, 张小芳, 张利军.不平衡数据分类研究综述[J].计算机科学, 2018, 45 (S1) :22-27. (ZHAO N, ZHANG X F, ZHANG L J.Overview of imbalanced data classification[J].Computer Science, 2018, 45 (S1) :22-27.) 
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An ensemble based evolutionary approach to the class imbalance problem with applications in CBIR">

                                <b>[9]</b>IRTAZA A, ADNAN S M, AHMED K T, et al.An ensemble based evolutionary approach to the class imbalance problem with applications in CBIR[J].Applied Sciences, 2018, 8 (4) :495.
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300161907&amp;v=MDE2MThubFVyakpLRjBVYXhVPU5pZk9mYks5SDlQT3JJOUZaZTBPQlh3K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>GALAR M, FERNANDEZ A, BARRENECHEA E, et al.EUSBoost:enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling[J].Pattern Recognition, 2013, 46 (12) :3460-3471.
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">

                                <b>[11]</b>CHAWLA N V, BOWYER K W, HALL L O, et al.SMOTE:synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research, 2011, 16 (1) :321-357.
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">

                                <b>[12]</b>LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence in Medicine in Europe.Berlin:Springer, 2001:63-66.
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Addressing the Curse of Imbalanced Training Sets:One-Sided Selection">

                                <b>[13]</b>KUBAT M, MATWIN S.Addressing the curse of imbalanced training sets:one-sided selection[C]//Proceedings of the 14th International Conference on Machine Learning.New York:ACM, 1997:179-186.
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Multiple Expert Approach to the Class Imbalance Problem Using Inverse Random under Sampling">

                                <b>[14]</b>TAHIR M A, KITTLER J, MIKOLAJCZYK K, et al.A multiple expert approach to the class imbalance problem using inverse random under sampling[C]//Proceedings of the 8th International Workshop on Multiple Classifier Systems.Berlin:Springer, 2009:82-91.
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel technique on class imbalance big data using analogous over sampling approach">

                                <b>[15]</b>IMRAN M, RAO V S, AMARASIMHA T, et al.A novel technique on class imbalance big data using analogous over sampling approach[J].International Journal of Computational Intelligence Research, 2017, 13 (10) :2407-2417.
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Decision tree based on Shannon R&amp;#233;nyi and Tsallis entropies for intrusion tolerant systems">

                                <b>[16]</b>LIMA C F L, de ASSIS F M, de SOUZA C P.Decision tree based on Shannon, Rényi and Tsallis entropies for intrusion tolerant systems[C]//Proceedings of the 5th International Conference on Internet Monitoring and Protection.Piscataway, NJ:IEEE, 2010:117-122.
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Decision tree induction based on minority entropy for the class imbalance problem">

                                <b>[17]</b>BOONCHUAY K, SINAPIROMSARAN K, LURSINSAP C.Decision tree induction based on minority entropy for the class imbalance problem[J].Pattern Analysis and Applications, 2017, 20 (3) :769-782.
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Entropy-based classifier enhancement to handle imbalanced class problem">

                                <b>[18]</b>KIRSHNERS A, PARSHUTIN S, GORSKIS H.Entropy-based classifier enhancement to handle imbalanced class problem[J].Procedia Computer Science, 2017, 104:586-591.
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA246F5C387083EAECDD8AA2F1D2F5F12&amp;v=MjQyNDNkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDlnekx1L3dhOD1OaWZPZmNLNkd0ZTZxdnhHYk93UEJIOU12bU5nbmt0MU9RN2cyaE5CZThTUk03dQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>LI X, ZHAO H, ZHU W.A cost sensitive decision tree algorithm with two adaptive mechanisms[J].Knowledge-Based Systems, 2015, 88:24-33.
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201405029&amp;v=Mjc5MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbVU3N1BMejdCZDdHNEg5WE1xbzlIYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>郑燕, 王杨, 郝青峰, 等.用于不平衡数据分类的代价敏感超网络算法[J].计算机应用, 2014, 34 (5) :1336-1340. (ZHENG Y, WANG Y, HAO Q F, et al.Cost-sensitive hypernetworks for imbalanced data classification[J].Journal of Computer Applications, 2014, 34 (5) :1336-1340.) 
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making">

                                <b>[21]</b>LEE S J, XU Z, LI T, et al.A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making[J].Journal of Biomedical Informatics, 2018, 78:144-155.
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=C4.5: Programs for Machine Learning">

                                <b>[22]</b>QUINLAN J R.C4.5:Programs for Machine Learning[M].San Francisco, CA:Morgan Kaufmann, 1993:17-26.
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The WEKA Workbench">

                                <b>[23]</b>FRANK E, HALL M A, WITTEN L H.The WEKA workbench.online appendix forData mining:practical machine learning tools and techniques[EB/OL]. (2016-11-22) [2018-05-04].https://www.cs.waikato.ac.nz/ml/weka/Witten_et_al_2016_appendix.pdf.
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A study on NSL-KDDdataset for intrusion detection system based on classification algorithms">

                                <b>[24]</b>DHANABAL L, SHANTHARAJAH S P.A study on NSL-KDDdataset for intrusion detection system based on classification algorithms[J].International Journal of Advanced Research in Computer and Communication Engineering, 2015, 4 (6) :446-452.
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Investigation into the Response of a Water Treatment System to Cyber Attacks">

                                <b>[25]</b>ADEPU S, MATHUR A.An investigation into the response of a water treatment system to cyber attacks[C]//Proceedings of the 17th IEEEInternational Symposium on High Assurance Systems Engineering.Washington, DC:IEEE Computer Society, 2016:141-148.
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A dataset to support research in the design of secure water treatment systems">

                                <b>[26]</b>GOH J, ADEPU S, JUNEJO K N, et al.A dataset to support research in the design of secure water treatment systems[C]//Proceedings of the 11th International Conference on Critical Information Infrastructures Security.Berlin:Springer, 2016:88-99.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903002&amp;v=MjIwMzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRG1VNzdQTHo3QmQ3RzRIOWpNckk5Rlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="4" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
