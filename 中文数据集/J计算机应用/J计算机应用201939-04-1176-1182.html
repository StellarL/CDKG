<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779522158750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904039%26RESULT%3d1%26SIGN%3dwxsCHPXhSrBRuFNCDfHOeBHtN94%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904039&amp;v=MDM4MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUx6Qkx6N0JkN0c0SDlqTXE0OUdiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="1 增强方法 ">1 增强方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="1.1 &lt;b&gt;方法流程&lt;/b&gt;">1.1 <b>方法流程</b></a></li>
                                                <li><a href="#60" data-title="1.2 DCP&lt;b&gt;算法与参数选取&lt;/b&gt;">1.2 DCP<b>算法与参数选取</b></a></li>
                                                <li><a href="#84" data-title="1.3 POSHE&lt;b&gt;算法&lt;/b&gt;">1.3 POSHE<b>算法</b></a></li>
                                                <li><a href="#104" data-title="1.4 &lt;b&gt;自适应融合算法&lt;/b&gt;">1.4 <b>自适应融合算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="2 实验与结果分析 ">2 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#113" data-title="2.1 &lt;b&gt;数据库与实验环境&lt;/b&gt;">2.1 <b>数据库与实验环境</b></a></li>
                                                <li><a href="#117" data-title="2.2 &lt;b&gt;方法评估&lt;/b&gt;">2.2 <b>方法评估</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="3 结语 ">3 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 本文方法流程">图1 本文方法流程</a></li>
                                                <li><a href="#83" data-title="图2 各图像的变异系数">图2 各图像的变异系数</a></li>
                                                <li><a href="#86" data-title="图3 &lt;i&gt;HE&lt;/i&gt;增强图像">图3 <i>HE</i>增强图像</a></li>
                                                <li><a href="#100" data-title="图4 加权模板及各子块">图4 加权模板及各子块</a></li>
                                                <li><a href="#107" data-title="图5 增强图像的标准差比较">图5 增强图像的标准差比较</a></li>
                                                <li><a href="#116" data-title="图6 自建库手掌静脉图像采集装置">图6 自建库手掌静脉图像采集装置</a></li>
                                                <li><a href="#128" data-title="图7 &lt;i&gt;ω&lt;/i&gt;不同取值时的&lt;i&gt;EER&lt;/i&gt;">图7 <i>ω</i>不同取值时的<i>EER</i></a></li>
                                                <li><a href="#133" data-title="图8 不同子块大小的&lt;i&gt;POSHE&lt;/i&gt;增强图">图8 不同子块大小的<i>POSHE</i>增强图</a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;子块大小对&lt;/b&gt;EER&lt;b&gt;的影响&lt;/b&gt;"><b>表</b>1 <b>子块大小对</b>EER<b>的影响</b></a></li>
                                                <li><a href="#137" data-title="图9 融合前后的增强图像对比">图9 融合前后的增强图像对比</a></li>
                                                <li><a href="#140" data-title="图10 不同方法的增强图像比较">图10 不同方法的增强图像比较</a></li>
                                                <li><a href="#144" data-title="图11 不同增强方法的&lt;i&gt;ROC&lt;/i&gt;曲线">图11 不同增强方法的<i>ROC</i>曲线</a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同增强方法的&lt;/b&gt;EER、CRR&lt;b&gt;和运算时间&lt;/b&gt;"><b>表</b>2 <b>不同增强方法的</b>EER、CRR<b>和运算时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="173">


                                    <a id="bibliography_1" title="孟宪静, 袭肖明, 杨璐, 等.基于灰度不均匀矫正和SIFT的手指静脉识别方法[J].南京大学学报 (自然科学版) , 2018, 54 (1) :1-10. (MENG X J, XI X M, YANG L, et al.Finger vein recognition based on intensity inhomogeneity correction and scale invariant tfeature transform[J].Journal of Nanjing University (Natural Science) , 2018, 54 (1) :1-10.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJDZ201801001&amp;v=MDkyMTVxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCS3lmUGRMRzRIOW5Ncm85RlpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        孟宪静, 袭肖明, 杨璐, 等.基于灰度不均匀矫正和SIFT的手指静脉识别方法[J].南京大学学报 (自然科学版) , 2018, 54 (1) :1-10. (MENG X J, XI X M, YANG L, et al.Finger vein recognition based on intensity inhomogeneity correction and scale invariant tfeature transform[J].Journal of Nanjing University (Natural Science) , 2018, 54 (1) :1-10.) 
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_2" title="KUBANEK M, SMORAWA D, HOLOTYAK T.Feature extraction of palm vein patterns based on two-dimensional density function[C]//ICAISC 2015:Proceedings of the 2015 Artificial Intelligence and Soft Computing, LNCS 9120.Berlin:Springer, 2015:101-111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature extraction of palm vein patterns based on two-dimensional density function">
                                        <b>[2]</b>
                                        KUBANEK M, SMORAWA D, HOLOTYAK T.Feature extraction of palm vein patterns based on two-dimensional density function[C]//ICAISC 2015:Proceedings of the 2015 Artificial Intelligence and Soft Computing, LNCS 9120.Berlin:Springer, 2015:101-111.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_3" title="SHIN K Y, PARK Y H, NGUYEN D T, et al.Finger-vein image enhancement using a fuzzy-based fusion method with Gabor and Retinex filtering[J].Sensors, 2014, 14 (2) :3095-3129." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Finger-vein image enhancement using a fuzzy-based fusion method with Gabor and Retinex filtering">
                                        <b>[3]</b>
                                        SHIN K Y, PARK Y H, NGUYEN D T, et al.Finger-vein image enhancement using a fuzzy-based fusion method with Gabor and Retinex filtering[J].Sensors, 2014, 14 (2) :3095-3129.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_4" title="ZHANG L G.A novel algorithm for hand vein enhancement and segmentation based on the Retinex method[EB/OL].[2018-05-10].http://dx.doi.org/10.2495/CECNet130411." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel algorithm for hand vein enhancement and segmentation based on the Retinex method">
                                        <b>[4]</b>
                                        ZHANG L G.A novel algorithm for hand vein enhancement and segmentation based on the Retinex method[EB/OL].[2018-05-10].http://dx.doi.org/10.2495/CECNet130411.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_5" title="YANG X, JIAN L, WU W, et al.Implementing real-time RCF-Retinex image enhancement method using CUDA[J].Journal of RealTime Image Processing, 2018, 25 (4) :1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Implementing real-time RCF-Retinex image enhancement method using CUDA">
                                        <b>[5]</b>
                                        YANG X, JIAN L, WU W, et al.Implementing real-time RCF-Retinex image enhancement method using CUDA[J].Journal of RealTime Image Processing, 2018, 25 (4) :1-11.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_6" title="杨数强, 杨杰慧, 宋亚龙.手指静脉图像小波增强算法[J].现代电子技术, 2013, 36 (15) :73-75. (YANG S Q, YANG J H, SONG Y L.Finger vein image enhancement algorithm based on wavelet transform[J].Modern Electronics Technique, 2013, 36 (15) :73-75.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201315024&amp;v=MjQ5NTlCUFNuUFpMRzRIOUxOcW85SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        杨数强, 杨杰慧, 宋亚龙.手指静脉图像小波增强算法[J].现代电子技术, 2013, 36 (15) :73-75. (YANG S Q, YANG J H, SONG Y L.Finger vein image enhancement algorithm based on wavelet transform[J].Modern Electronics Technique, 2013, 36 (15) :73-75.) 
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_7" title="ZHANG C, FU Y.Research on the image enhancement algorithm based on improved wavelet transform[J].Journal of Convergence Information Technology, 2013, 8 (6) :384-392." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD13070300066950&amp;v=MDcxNDFqM2Fhcks3SHRiTXJJOUZaTzBKQlhrNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGb1hhUnM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        ZHANG C, FU Y.Research on the image enhancement algorithm based on improved wavelet transform[J].Journal of Convergence Information Technology, 2013, 8 (6) :384-392.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_8" title="陈朋, 姜立, 王海霞, 等.基于散射卷积网络的手指静脉识别方法研究[J].浙江工业大学学报, 2018, 46 (1) :56-60. (CHEN P, JIANG L, WANG H X, et al.Finger vein recognition based on scattering convolution network[J].Journal of Zhejiang University of Technology, 2018, 46 (1) :56-60.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZJGD201801010&amp;v=MDU4NzdMekJQeWZNYXJHNEg5bk1ybzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        陈朋, 姜立, 王海霞, 等.基于散射卷积网络的手指静脉识别方法研究[J].浙江工业大学学报, 2018, 46 (1) :56-60. (CHEN P, JIANG L, WANG H X, et al.Finger vein recognition based on scattering convolution network[J].Journal of Zhejiang University of Technology, 2018, 46 (1) :56-60.) 
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_9" title="HAJIAN A, AMLI D.Sharpness enhancement of finger-vein image based on modified un-sharp mask with Log-Gabor filter[J].Procedia Computer Science, 2018, 126 (7) :431-440." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES131B27FE19BEE4CF279E25214B10F181&amp;v=MjQxMDZmT2ZiSzdINlBPcVBrd1plSjllUWs5dkdBUjdUWUlTbnJnclJaSGVMTGlSTEtlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoekx5OHc2RT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        HAJIAN A, AMLI D.Sharpness enhancement of finger-vein image based on modified un-sharp mask with Log-Gabor filter[J].Procedia Computer Science, 2018, 126 (7) :431-440.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_10" title="蔡超峰, 任景英.基于直方图均衡化的手背静脉图像对比度增强[J].计算机应用, 2013, 33 (4) :1125-1127. (CAI C F, REN J.Contrast enhancement of hand vein images based on histogram equalization[J].Journal of Computer Applications, 2013, 33 (4) :1125-1127.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201304058&amp;v=MzExODRSN3FmWnVac0Z5RGhVTHpCTHo3QmQ3RzRIOUxNcTQ5QWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        蔡超峰, 任景英.基于直方图均衡化的手背静脉图像对比度增强[J].计算机应用, 2013, 33 (4) :1125-1127. (CAI C F, REN J.Contrast enhancement of hand vein images based on histogram equalization[J].Journal of Computer Applications, 2013, 33 (4) :1125-1127.) 
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_11" title="FRANCIS M.An efficient algorithm to enhance near infrared images of blood vein in antecubital fossa based on adaptive histogram equalization[C]//Proceedings on ELSEVIER International Conference on Emerging Trends in Electrical Engineering.Amsterdam:Elsevier, 2014:35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm to enhance near infrared images of blood vein in antecubital fossa based on adaptive histogram equalization">
                                        <b>[11]</b>
                                        FRANCIS M.An efficient algorithm to enhance near infrared images of blood vein in antecubital fossa based on adaptive histogram equalization[C]//Proceedings on ELSEVIER International Conference on Emerging Trends in Electrical Engineering.Amsterdam:Elsevier, 2014:35.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_12" title="JENA G, JENA S, BONAM V R.Image enhancement using fuzzy set[C]//AHFE 2017:Proceedings of the 2017 Advances in Human Factors in Simulation and Modeling.Berlin:Springer, 2017:141-150." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image enhancement using fuzzy set">
                                        <b>[12]</b>
                                        JENA G, JENA S, BONAM V R.Image enhancement using fuzzy set[C]//AHFE 2017:Proceedings of the 2017 Advances in Human Factors in Simulation and Modeling.Berlin:Springer, 2017:141-150.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                    江晓龙, 王华彬, 王东旭, 等.改进的单幅近红外掌纹掌静脉图像融合识别[J/OL].计算机应用研究, 2019.[2018-04-12].http://www.arocmag.com/article/02-2019-07-055.html. (JIANG X L, WANG H B, WANG D X, et al.Improved fusion recognition for near infrared palmprint and palm vein image[J/OL].Application Research of Computers, 2019.[2018-04-12].http://www.arocmag.com/article/02-2019-07-055.html.) </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_14" title="ZHAO J, TIAN H, X U W, et al.A new approach to hand vein image enhancement[C]//Proceedings of the 2009 Second International Conference on Intelligent Computation Technology and Automation.Piscataway, NJ:IEEE, 2009:499-501." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new approach to hand vein image enhancement">
                                        <b>[14]</b>
                                        ZHAO J, TIAN H, X U W, et al.A new approach to hand vein image enhancement[C]//Proceedings of the 2009 Second International Conference on Intelligent Computation Technology and Automation.Piscataway, NJ:IEEE, 2009:499-501.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_15" title="HE K, SUN J, TANG X.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (12) :2341-2353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single Image Haze Removal Using Dark Channel Prior">
                                        <b>[15]</b>
                                        HE K, SUN J, TANG X.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (12) :2341-2353.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_16" title="KIM J Y, KIM L S, HWANG S H.An advanced contrast enhancement using partially overlapped sub-block histogram equalization[J].IEEE Transactions on Circuits&amp;amp;Systems for Video Technology, 2001, 11 (4) :475-484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An advanced contrast enhancement using partially overlapped sub-block histogram equalization">
                                        <b>[16]</b>
                                        KIM J Y, KIM L S, HWANG S H.An advanced contrast enhancement using partially overlapped sub-block histogram equalization[J].IEEE Transactions on Circuits&amp;amp;Systems for Video Technology, 2001, 11 (4) :475-484.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_17" title="ZHOU Y, KUMAR A.Human identification using palm-vein images[J].IEEE Transactions on Information Forensics&amp;amp;Security, 2011, 6 (4) :1259-1274." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Human Identification Using Palm-Vein Images">
                                        <b>[17]</b>
                                        ZHOU Y, KUMAR A.Human identification using palm-vein images[J].IEEE Transactions on Information Forensics&amp;amp;Security, 2011, 6 (4) :1259-1274.
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_18" title="周宇佳, 刘娅琴, 杨丰, 等.基于方向特征的手掌静脉识别[J].中国图象图形学报, 2014, 19 (2) :243-252. (ZHOU YJ, LIU Y Q, YANG F, et al.Palm-vein recognition based on oriented features[J].Journal of Image and Graphics, 2014, 19 (2) :243-252.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201402010&amp;v=MTczNDVMRzRIOVhNclk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCUHlyZmI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        周宇佳, 刘娅琴, 杨丰, 等.基于方向特征的手掌静脉识别[J].中国图象图形学报, 2014, 19 (2) :243-252. (ZHOU YJ, LIU Y Q, YANG F, et al.Palm-vein recognition based on oriented features[J].Journal of Image and Graphics, 2014, 19 (2) :243-252.) 
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_19" title="LIU Y, ZHOU Y, QIU S, et al.Real-time locating method for palmvein image acquisition[C]//ICIG 2015:Proceedings of the2015 Image and Graphics.Berlin:Springer, 2015:94-110." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time locating method for palmvein image acquisition">
                                        <b>[19]</b>
                                        LIU Y, ZHOU Y, QIU S, et al.Real-time locating method for palmvein image acquisition[C]//ICIG 2015:Proceedings of the2015 Image and Graphics.Berlin:Springer, 2015:94-110.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_20" title="EZHILMARAN D, JOSEPH R B.Finger vein biometric system with type-2 fuzzy enhancement and minutiae matching[C]//Proceedings of the 2017 IEEE Region 10 Symposium.Piscataway, NJ:IEEE, 2017:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Finger vein biometric system with type-2 fuzzy enhancement and minutiae matching">
                                        <b>[20]</b>
                                        EZHILMARAN D, JOSEPH R B.Finger vein biometric system with type-2 fuzzy enhancement and minutiae matching[C]//Proceedings of the 2017 IEEE Region 10 Symposium.Piscataway, NJ:IEEE, 2017:1-4.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_21" title="KANG W, LIU Y, WU Q, et al.Contact-free palm-vein recognition based on local invariant features[J].PLo S One, 2014, 9 (5) :1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contact-free palm-vein recognition based on local invariant features">
                                        <b>[21]</b>
                                        KANG W, LIU Y, WU Q, et al.Contact-free palm-vein recognition based on local invariant features[J].PLo S One, 2014, 9 (5) :1-12.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_22" title="QIU S, LIU Y, ZHOU Y, et al.Finger-vein recognition based on dual-sliding window localization and pseudo-elliptical transformer[J].Expert Systems with Applications, 2016, 64:618-632." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Finger-vein recognition based on dual-sliding window localization and pseudo-elliptical transformer">
                                        <b>[22]</b>
                                        QIU S, LIU Y, ZHOU Y, et al.Finger-vein recognition based on dual-sliding window localization and pseudo-elliptical transformer[J].Expert Systems with Applications, 2016, 64:618-632.
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_23" title="袁玲, 黄靖, 刘娅琴, 等.基于图像融合的去掌纹手掌静脉图像增强方法[J].科学技术与工程, 2016, 16 (36) :48-54. (YUAN L, HUANG J, LIU Y Q, et al.Palm vein enhancement algorithm by removing palmprint based on image fusion[J].Science Technology and Engineering, 2016, 16 (36) :48-54.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201636009&amp;v=MzIwNTQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCTGpYQmZiRzRIOWZQcVk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        袁玲, 黄靖, 刘娅琴, 等.基于图像融合的去掌纹手掌静脉图像增强方法[J].科学技术与工程, 2016, 16 (36) :48-54. (YUAN L, HUANG J, LIU Y Q, et al.Palm vein enhancement algorithm by removing palmprint based on image fusion[J].Science Technology and Engineering, 2016, 16 (36) :48-54.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-18 09:28</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1176-1182 DOI:10.11772/j.issn.1001-9081.2018092043            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于自适应融合的手掌静脉增强方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A8%84%E6%A2%A6%E8%8E%B9&amp;code=41473334&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">娄梦莹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E4%B8%BD%E8%8E%8E&amp;code=41186459&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁丽莎</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%A8%85%E7%90%B4&amp;code=08022096&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘娅琴</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E9%9B%AA%E6%A2%85&amp;code=41473335&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万雪梅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E4%B8%B0&amp;code=08053963&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨丰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%96%B9%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6%E7%94%9F%E7%89%A9%E5%8C%BB%E5%AD%A6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0060982&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南方医科大学生物医学工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对掌脉轮廓不清晰, 图像对比度低、亮度低, 进而导致识别性能降低的现象, 提出一种自适应融合的手掌静脉增强方法。首先, 基于暗原色先验 (DCP) 去雾算法, 根据掌脉图像变异系数自适应选择去雾系数, 得到DCP增强图像, 并且基于部分子块重叠直方图均衡 (POSHE) 算法得到POSHE增强图像;然后, 将图像分为16个子块, 依据图像灰度均值与标准差确定各子块权重;最后, 根据各子块权重对DCP和POSHE增强图像进行自适应融合, 得到最终增强图像。该方法既保留了DCP算法在增强图像对比度和亮度的同时不引入明显噪声的优点, 又保留了POSHE算法在增强图像对比度和亮度的同时不损失局部细节的特点;同时, 两者的自适应融合既解决了DCP图像阴影部分掌脉缺失现象, 又削弱了POSHE产生的块效应。在对两个公开库和自建库分别进行的实验中, 三个数据库的等错误率分别为0.000 4、0.047 2、0.057 9, 识别率分别为99.98%、94.27%、92.05%。实验结果表明, 与现有的图像增强方法相比, 该方法降低了等错误率, 提高了识别精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E6%8E%8C%E9%9D%99%E8%84%89%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手掌静脉图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9A%97%E5%8E%9F%E8%89%B2%E5%85%88%E9%AA%8C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">暗原色先验;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%83%A8%E5%88%86%E5%AD%90%E5%9D%97%E9%87%8D%E5%8F%A0%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">部分子块重叠直方图均衡化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E5%9D%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分块;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    娄梦莹 (1994—) , 女, 山东滨州人, 硕士研究生, 主要研究方向:模式识别、图像处理;;
                                </span>
                                <span>
                                    袁丽莎 (1993—) , 女, 湖北松滋人, 硕士研究生, 主要研究方向:模式识别、图像处理;;
                                </span>
                                <span>
                                    *刘娅琴 (1965—) , 女, 湖南邵阳人, 教授, 硕士, 主要研究方向:生物特征识别、图像处理;电子邮箱liuyq@smu.edu.cn;
                                </span>
                                <span>
                                    万雪梅 (1996—) , 女, 四川成都人, 主要研究方向:图像处理;;
                                </span>
                                <span>
                                    杨丰 (1965—) , 男, 湖北麻城人, 教授, 博士, 主要研究方向:医学成像、机器学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61771233);</span>
                                <span>广东省研发与产业化项目 (2013B090500104);</span>
                    </p>
            </div>
                    <h1><b>Palm vein enhancement method based on adaptive fusion</b></h1>
                    <h2>
                    <span>LOU Mengying</span>
                    <span>YUAN Lisha</span>
                    <span>LIU Yaqin</span>
                    <span>WAN Xuemei</span>
                    <span>YANG Feng</span>
            </h2>
                    <h2>
                    <span>School of Biomedical Engineering, Southern Medical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the degradation of recognition performance caused by unclear palm vein contour, low image contrast and brightness, a new palm vein enhancement method based on adaptive fusion was proposed. Firstly, based on Dark Channel Prior (DCP) defogging algorithm and adaptively selected defogging coefficient according to variation coefficient of the palm vein image, DCP enhanced image was obtained. And based on Partial Overlapped Sub-block Histogram Equalization (POSHE) algorithm, POSHE enhanced image was obtained. Secondly, the image was divided into 16 sub-blocks, and the weight of each sub-block was determined by the gray mean and the standard deviation. Finally, two kinds of enhanced images were fused adaptively according to the weight of each sub-block, obtaining the adaptive fused enhanced image. This method not only retains the advantages of DCP algorithm in enhancing image contrast and brightness without introducing significant noise, but also preserves the benefits of POSHE algorithm in enhancing image contrast and brightness without losing local details. Meanwhile, adaptive fusion of the two algorithms solves the problem of missing palm vein in shadow areas of DCP images and reduces the blocking artifacts produced by POSHE. Experimental results carried out on two public databases and a self-built database show that the equal error rates are 0.000 4, 0.047 2, 0.057 9 and the correct recognition rates are 99.98%, 94.27%, 92.05% respectively, indicating that compared with existing image enhancement methods, the proposed method reduces the equal error rate and improves the recognition accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=palm%20vein%20image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">palm vein image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dark%20Channel%20Prior%20(DCP)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dark Channel Prior (DCP) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Partial%20Overlapped%20Sub-block%20Histogram%20Equalization%20(POSHE)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Partial Overlapped Sub-block Histogram Equalization (POSHE) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=blocking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">blocking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=adaptive%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">adaptive fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LOU Mengying, born in 1994, M. S. candidate. Her research interests include pattern recognition, image processing.;
                                </span>
                                <span>
                                    YUAN Lisha, born in 1993, M. S. candidate. Her research interests include pattern recognition, image processing.;
                                </span>
                                <span>
                                    LIU Yaqin, born in 1965, M. S. , professor. Her research interests include biometric recognition, image processing.;
                                </span>
                                <span>
                                    WAN Xuemei, born in 1996. Her research interests include image processing.;
                                </span>
                                <span>
                                    YANG Feng, born in 1965, Ph. D. , professor. His research interests include medical imaging, machine learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61771233);</span>
                                <span>the R&amp;D and Industrialization Project in Guangdong Province (2013B090500104);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="50">随着社会的发展、科技的进步, 人们对个人身份识别和鉴定的安全性、准确性要求越来越高, 传统的身份识别和鉴定方法已经不能满足当前社会的需要。生物特征识别技术是根据人的生理特征或行为特征进行身份识别和鉴定的技术, 因具有更高的普遍性、唯一性、稳定性受到广泛关注和研究。目前, 现有的身份识别和鉴定的方法有掌纹识别、指纹识别、人脸识别、虹膜识别等<citation id="219" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 而掌静脉识别作为一种新兴的生物特征识别技术, 属于内生理特征, 不会磨损, 是活体时才存在的特征, 难伪造, 比掌纹、指纹识别更具安全性, 比人脸识别更具稳定性, 比虹膜识别更具应用的普遍性<citation id="220" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。因此, 掌静脉识别逐渐成为生物特征识别领域的焦点, 有更好的发展前景。</p>
                </div>
                <div class="p1">
                    <p id="51">静脉图像增强是手掌静脉识别技术中的重要研究内容, 直接影响特征提取与匹配结果, 进而影响识别精度。现有的图像增强方法按处理方式分为频率域和空间域两大类。</p>
                </div>
                <div class="p1">
                    <p id="52">频率域增强算法包括:1) 基于傅里叶变换的图像增强, 可滤除高频噪声, 增强原始静脉图像的边缘, 但在图像突变部分增强效果较差;2) 基于Retinex算法<citation id="222" type="reference"><link href="177" rel="bibliography" /><link href="179" rel="bibliography" /><link href="181" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation> 的图像增强, 可增强图像对比度, 同时保持了颜色的恒常性, 但边界区域易产生光晕;3) 基于小波变换<citation id="223" type="reference"><link href="183" rel="bibliography" /><link href="185" rel="bibliography" /><link href="187" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>的图像增强, 是傅里叶变换的延伸, 弥补了傅里叶变换的不足, 具有细化分析的功能, 可增强图像突变部分细节信息, 但计算复杂, 时间开销较大;4) 基于Gabor滤波<citation id="221" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>的图像增强, 具有良好的频率选择性, 可有效地去除噪声, 同时保持图像静脉结构, 但运行时间长, 实时性较差。</p>
                </div>
                <div class="p1">
                    <p id="53">空间域增强算法包括:1) 基于直方图均衡化<citation id="224" type="reference"><link href="191" rel="bibliography" /><link href="193" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>的图像增强, 通过拉伸增强图像对比度和亮度, 但会丢失局部细节信息;为改善直方图均衡化增强效果, 后又提出局部直方图均衡化、自适应直方图均衡化和限制对比度自适应直方图均衡化 (Contrast Limited Adaptive Histogram Equalization, CLAHE) 等, 明显增强了静脉图像的细节信息, 但会出现不同程度的块效应。2) 基于灰度变换的图像增强, 可增强图像低灰度区细节, 提高图像的对比度, 但会产生局部细节丢失现象。3) 基于模糊集<citation id="225" type="reference"><link href="195" rel="bibliography" /><link href="197" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>的图像增强, 提高了低灰度区域和高灰度区域之间的对比度, 但增强区域单一, 会丢失低灰度静脉细节信息。</p>
                </div>
                <div class="p1">
                    <p id="54">总之, 各种增强方法针对不同的图像有不同的增强效果, 各有优劣, 有效地利用现有方法的优势, 通过相互融合避开各方法的缺陷是本文的研究重点和方向。</p>
                </div>
                <div class="p1">
                    <p id="55">针对由于光照不均匀、手部肌肤厚度不均匀<citation id="226" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、采集装置受限制以及图像采集环境不稳定等因素、采集到的图像静脉纹理细节较弱, 静脉图像对比度不高, 且图像明暗过渡不自然、局部清晰、局部模糊等现象, 本文提出基于暗原色先验 (Dark Channel Prior, DCP) 去雾算法<citation id="227" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和基于子块部分重叠的直方图均衡 (Partially Overlapped Sub-block Histogram Equalization, POSHE) 算法<citation id="228" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的自适应图像融合方法。DCP算法针对昏暗不明、低对比度、低亮度图像有较好增强效果, 能在增强图像对比度和亮度的同时不引入明显噪声, 不需要额外参数, 计算简便;POSHE算法对图像进行分块局部处理, 解决了传统的直方图均衡 (Histogram Equalization, HE) 算法对全局处理产生的局部区域过亮、过暗以及局部细节损失问题, 可在增强图像对比度和亮度的同时不损失局部细节。两种算法自适应融合既解决了DCP图像阴影部分掌脉缺失现象又解决了POSHE产生的块效应, 同时可以自适应地对每幅图像选择最佳融合权重。用本文方法分别对香港理工大学 (The Hong Kong Polytechnic University, PolyU) 数据库、中国科学院自动化研究所 (Institute of Automation, Chinese Academy of Sciences, CASIA) 数据库和自建库进行实验, 实验结果表明, 与已有的图像增强方法相比, 本文方法计算简单, 对掌静脉图像增强效果好, 能降低等错误率、提高识别精度。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">1 增强方法</h3>
                <h4 class="anchor-tag" id="57" name="57">1.1 <b>方法流程</b></h4>
                <div class="p1">
                    <p id="58">本文方法流程如图1所示, 首先采用文献<citation id="229" type="reference">[<a class="sup">17</a>]</citation>方法对掌静脉原始图像进行感兴趣区域 (Region Of Interest, ROI) 定位和提取, 得到ROI图像;其次用自适应DCP和POSHE算法分别对ROI图像增强, 并将DCP增强图像和POSHE增强图像自适应融合, 得到最终的增强图像;最后采用文献<citation id="230" type="reference">[<a class="sup">18</a>]</citation>方法进行特征提取与匹配, 计算相应的等错误率和识别率。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法流程" src="Detail/GetImg?filename=images/JSJY201904039_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of the proposed method</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60">1.2 DCP<b>算法与参数选取</b></h4>
                <h4 class="anchor-tag" id="61" name="61">1.2.1 DCP算法</h4>
                <div class="p1">
                    <p id="62">He等<citation id="231" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>于2011年提出了基于暗原色先验的去雾算法<citation id="232" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。该算法能有效增强图像对比度和亮度同时不引入明显噪声, 且不需要额外参数, 适用于低质量手掌静脉图像的增强。</p>
                </div>
                <div class="p1">
                    <p id="63">暗通道的定义:在一幅拥有RGB (Red Green Blue) 三个通道的图像<b><i>J</i></b> (<i>x</i>) 中, 对RGB三个通道和以大小为<i>n</i>×<i>n</i>的滤波器模板<i>Ω</i> (<i>x</i>) 进行两次最小值滤波, 即:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><mo>∈</mo><mi mathvariant="bold-italic">Ω</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><mo>∈</mo><mo stretchy="false"> (</mo><mi>r</mi><mo>, </mo><mi>g</mi><mo>, </mo><mi>b</mi><mo stretchy="false">) </mo></mrow></munder><mi mathvariant="bold-italic">J</mi><msup><mrow></mrow><mi>c</mi></msup><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mi mathvariant="bold-italic">J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>→</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<b><i>J</i></b><sup><i>c</i></sup>表示图像的每个通道;<i>Ω</i> (<i>x</i>) 表示以像素<i>x</i>为中心的一个窗口。</p>
                </div>
                <div class="p1">
                    <p id="66">在计算机视觉和计算机图形中, 雾图形成模型如式 (2) 所示:</p>
                </div>
                <div class="p1">
                    <p id="67"><b><i>I</i></b> (<i>x</i>) =<b><i>J</i></b> (<i>x</i>) <i>t</i> (<i>x</i>) +<b><i>A</i></b> (1-<i>t</i> (<i>x</i>) )      (2) </p>
                </div>
                <div class="p1">
                    <p id="68">其中:<b><i>I</i></b> (<i>x</i>) 为雾化图像;<b><i>J</i></b> (<i>x</i>) 为恢复图像;<i>t</i> (<i>x</i>) 为透射率;<b><i>A</i></b>为大气光值。</p>
                </div>
                <div class="p1">
                    <p id="69">有时在去雾时需要保留一定程度的雾, 因此, 引入一个在区间[0, 1]内的因子<i>ω</i>进行修正, 根据暗通道先验理论, 得到透射率估算公式:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mi>ω</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><mo>∈</mo><mi mathvariant="bold-italic">Ω</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>c</mi></munder><mo stretchy="false"> (</mo><mfrac><mrow><mi mathvariant="bold-italic">J</mi><msup><mrow></mrow><mi>c</mi></msup><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mrow><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mi>c</mi></msup></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">其中:<i>ω</i> (0&lt;<i>ω</i>&lt;1) 是雾的保留系数, 1为完全去雾, 0为不去雾。</p>
                </div>
                <div class="p1">
                    <p id="72">在具体应用中可以借助暗通道从原始图像中获取<b><i>A</i></b>的值, 即</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>a</mi><msup><mrow></mrow><mtext>r</mtext></msup><mo>=</mo><mi>s</mi><mi>u</mi><mi>m</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo>/</mo><mi>Ν</mi></mtd></mtr><mtr><mtd><mi>a</mi><msup><mrow></mrow><mtext>g</mtext></msup><mo>=</mo><mi>s</mi><mi>u</mi><mi>m</mi><msub><mrow></mrow><mtext>g</mtext></msub><mo>/</mo><mi>Ν</mi></mtd></mtr><mtr><mtd><mi>a</mi><msup><mrow></mrow><mtext>b</mtext></msup><mo>=</mo><mi>s</mi><mi>u</mi><mi>m</mi><msub><mrow></mrow><mtext>b</mtext></msub><mo>/</mo><mi>Ν</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><msup><mrow></mrow><mtext>r</mtext></msup><mo>, </mo><mi>a</mi><msup><mrow></mrow><mtext>g</mtext></msup><mo>, </mo><mi>a</mi><msup><mrow></mrow><mtext>b</mtext></msup><mo stretchy="false">]</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中:<i>sum</i><sub>r</sub>、<i>sum</i><sub>g</sub>、<i>sum</i><sub>b</sub>分别表示r、g、b三个通道值的和。</p>
                </div>
                <div class="p1">
                    <p id="75">计算出<i>t</i> (<i>x</i>) 和<b><i>A</i></b>后, 代入式 (2) , 得到去雾图像:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">A</mi></mrow><mrow><mi>max</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>+</mo><mi mathvariant="bold-italic">A</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中:<i>t</i><sub>0</sub>用来限定<i>t</i> (<i>x</i>) 的下限值, 本文取0.1。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">1.2.2 <i>ω</i>自适应选取</h4>
                <div class="p1">
                    <p id="79">DCP算法中去雾系数<i>ω</i>表示对图像的去雾程度, 其取值范围为[0, 1], 但是图像之间由于采集过程中光照等外部环境有差异, 这种差异性决定了图像之间去雾程度的差异性, 即<i>ω</i>取值的差异性, <i>ω</i>固定取值不能满足对所有图像去雾的准确性。考虑到不同图像之间的差异性反映在图像的灰度值上, 可用图像的变异系数 (即标准差与均值的比值) 表示图像之间的灰度差异, 进而表示图像的去雾程度。从三个数据库中各取200类, 共1 200幅图像, 计算每幅图像的变异系数, 如图2所示, 由图2可看出图像之间的灰度差异性显著。</p>
                </div>
                <div class="p1">
                    <p id="80">本文根据图像灰度值的变化程度决定DCP算法的去雾程度, 将DCP算法参数进行自适应调节。具体是用图像之间的灰度差异表示图像去雾程度的差异, 即去雾系数<i>ω</i>根据灰度图像的变异系数进行自适应选取, 表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="81"><i>ω</i>=<i>δ</i>/<i>μ</i>      (6) </p>
                </div>
                <div class="p1">
                    <p id="82">其中: <i>μ</i>、<i>δ</i>分别表示ROI图像的均值和标准差。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 各图像的变异系数" src="Detail/GetImg?filename=images/JSJY201904039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 各图像的变异系数  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Variation coefficient of each image</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84">1.3 POSHE<b>算法</b></h4>
                <div class="p1">
                    <p id="85">直方图均衡化算法<citation id="233" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>是一种常用的图像处理方法, 主要用于增强图像对比度, 使图像亮度均匀分布并消除偏亮或偏暗的情况。<i>HE</i>增强结果如图3所示, 由图可看出<i>HE</i>限制了局部区域的对比度拉伸力度, 丢失了局部细节信息。为进一步提高<i>HE</i>算法的增强效果, 本文使用基于子块部分重叠的直方图均衡算法<citation id="234" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 该算法能基本消除块效应, 计算效率高, 图像细节增强效果好。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 HE增强图像" src="Detail/GetImg?filename=images/JSJY201904039_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>HE</i>增强图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Enhanced images of HE</i></p>

                </div>
                <div class="p1">
                    <p id="87"><i>POSHE</i>算法是在一幅<i>M</i>×<i>N</i>的输入图像的左上角定义一个<i>m</i>×<i>n</i>的子块, 对子块进行直方图均衡, 然后子块按照一定的步长从左到右、从上到下的移动, 重复上述过程, 直至子块移动至右下角。</p>
                </div>
                <div class="p1">
                    <p id="88">基于POSHE算法的定义, 需要构建加权模板, 以图4 (a) 所示的3×3加权模板为例, 中心子块的变换函数由中心子块及其8邻域子块决定, 加权模板推导如下:</p>
                </div>
                <div class="p1">
                    <p id="89">将输入图像划分为9个区域, 如图4 (b) 。对每个区域进行POSHE处理, 设子块大小为2×2, 步长为1。图4 (c) ～ (f) 分别为每次进行直方图均衡的子块:其中<i>e</i>是四个子块的重叠部分, 则<i>e</i>的输出值为:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false"> (</mo><mi>Τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">其中4个子块的直方图均衡分别如下:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>;<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>a</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup></mrow><mrow><mn>4</mn><mi>n</mi><mo>/</mo><mn>9</mn></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="area_img" id="172">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201904039_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="98">其中:<i>n</i>为输入图像的像素;<i>n</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>x</mi></msubsup></mrow></math></mathml>为<i>x</i> (<i>x</i>=<i>a</i>, <i>b</i>, …, <i>i</i>) 区域内灰度值为<i>j</i>的像素数。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 加权模板及各子块" src="Detail/GetImg?filename=images/JSJY201904039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 加权模板及各子块  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Weighted templates and sub-blocks</p>

                </div>
                <div class="p1">
                    <p id="101">综上:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false"> (</mo><mi>Τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>k</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mfrac><mn>9</mn><mn>4</mn></mfrac><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo>+</mo><mfrac><mn>9</mn><mn>8</mn></mfrac><mo stretchy="false"> (</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>f</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>h</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mfrac><mn>9</mn><mrow><mn>1</mn><mn>6</mn></mrow></mfrac><mo stretchy="false"> (</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>a</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>c</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>g</mi></msubsup><mo>+</mo><mi>n</mi><msubsup><mrow></mrow><mi>j</mi><mi>i</mi></msubsup><mo stretchy="false">) </mo></mrow><mi>n</mi></mfrac></mrow><mo>]</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mi>p</mi><msub><mrow></mrow><mi>e</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mn>8</mn></mfrac><mo stretchy="false">[</mo><mi>p</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mn>6</mn></mrow></mfrac><mo stretchy="false">[</mo><mi>p</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msubsup><mrow></mrow><mi>j</mi><mi>e</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">可见, 式 (13) 的概率函数和图4 (a) 的加权模板相吻合。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">1.4 <b>自适应融合算法</b></h4>
                <div class="p1">
                    <p id="105"><i>DCP</i>算法增强后的图像提高了对比度和亮度, 能够清晰地分辨出掌静脉和掌纹信息;<i>POSHE</i>算法将阴影部分的掌静脉与背景区分出来, 明显增强了掌静脉图像的细节信息。但是<i>DCP</i>算法阴影部分的掌静脉与背景融为一体, 难以分割, 丢失这部分掌静脉细节信息;<i>POSHE</i>算法出现部分区域过度增强现象, 灰度突变部分存在轻微的块效应。基于以上两种算法的优缺点, 本文将<i>DCP</i>算法与<i>POSHE</i>算法自适应融合进行图像增强。</p>
                </div>
                <div class="p1">
                    <p id="106">通过大量实验发现增强效果与图像的标准差有一定关联, 当标准差大于某一特定值时, 图像过增强, 边缘模糊;当标准差小于某一特定值时, 图像欠增强, 对比度和亮度不明显, 静脉与背景区分不大。<i>POSHE</i>增强效果越好, 静脉细节越清晰, 像素分布越均匀, 子块之间的标准差波动越小。从三个数据库中各取一幅图像分成16个子块, 计算各子块的标准差如图5 (<i>a</i>) 所示, 由图可看出, <i>POSHE</i>增强图标准差波动幅度大, 而<i>DCP</i>增强图标准差波动幅度小, 并且在某些子块两者标准差趋势互补, 每个子块自适应融合增强图明显缩小了标准差的波动范围, 且将标准差固定在区间[0.1, 0.2]内, 中和了<i>POSHE</i>增强图标准差过大引起的过增强和<i>DCP</i>增强图标准差过小引起的欠增强现象。图5 (<i>b</i>) 是从三个数据库中各取200类, 得到每幅图的标准差, 自适应融合得到了更好的对比度和亮度增强。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 增强图像的标准差比较" src="Detail/GetImg?filename=images/JSJY201904039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 增强图像的标准差比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 5 <i>Standard deviation comparison of enhanced images</i></p>

                </div>
                <div class="p1">
                    <p id="108">由于<i>POSHE</i>算法增强的图像容易出现对比度和亮度局部过增强现象, 导致静脉和背景边缘模糊, 而<i>DCP</i>算法可中和<i>POSHE</i>算法的过增强现象, 并削弱其块效应。<i>DCP</i>算法针对灰度级较小的图像增强效果更好, 但当图像灰度级较大时, 增强效果欠佳;<i>POSHE</i>算法针对灰度不均匀的图像增强效果更好, 可增强图像细节, 但当图像灰度分布比较均匀时效果不明显, 且会出现局部块效应。每种算法对于不同的灰度图像效果不同, 所以根据像素均值比较整个图像的明暗程度设置<i>DCP</i>权重, 根据标准差设置<i>POSHE</i>权重。为使局部自适应融合效果更好, 局部静脉细节更清晰, 将每幅图像分成大小为32×32的16个子块, 分别进行自适应融合。当标准差偏大时, 图像均匀性差, 相邻子块之间的权重差异过大, 子块之间会出现对比度变化不均匀现象, 按1∶1调整<i>POSHE</i>权重, 可以使子块之间明暗变化均匀, 且静脉细节清晰, 亮度与对比度适中;当标准差偏小时, 图像比较均匀, 相邻子块之间的权重差异小, 子块之间对比度无明显变化, 按灰度级均值调整<i>DCP</i>算法权重, 静脉与背景边缘清晰, 整体亮度适中且块效应不明显。计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="109"><b><i>I</i></b> (<i>x</i>) =<i>g</i> (<i>i</i>) <b><i>I</i></b><sub>DCP</sub> (<i>x</i>) + (1-<i>g</i> (<i>i</i>) ) <b><i>I</i></b><sub>POSHE</sub> (<i>x</i>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mn>2</mn><mn>5</mn><mn>5</mn></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mn>0</mn><mo>.</mo><mn>0</mn><mn>1</mn><mo>&lt;</mo><mi>δ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>δ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo>.</mo><mn>1</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">其中:<b><i>I</i></b> (<i>x</i>) 表示自适应融合增强图像;<b><i>I</i></b><sub>DCP</sub> (<i>x</i>) 表示DCP增强图像;<b><i>I</i></b><sub>POSHE</sub> (<i>x</i>) 表示POSHE增强图像;<i>g</i> (<i>i</i>) 表示融合权重; <i>μ</i><sub><i>i</i></sub>、<i>δ</i><sub><i>i</i></sub>分别表示每个子块的均值和标准差;<i>i</i>=1, 2, …, 16表示图像各子块。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">2 实验与结果分析</h3>
                <h4 class="anchor-tag" id="113" name="113">2.1 <b>数据库与实验环境</b></h4>
                <div class="p1">
                    <p id="114">为验证本文算法的效果, 实验采用三个手掌静脉数据库的图像进行:一是<i>PolyU</i>库, 图像采集方式为完全的接触式采集, 基本不产生平移、旋转, 图像质量高, 对250个男性和女性分两次采集, 两次采集的平均时间间隔为9 <i>d</i>, 每次采集左右手各6幅图像, 数据库中共6 000幅图像, 本文采用第一次采集的3 000幅图像进行实验。二是作者实验室建立的手掌静脉数据库 (简称“自建库”) , 图像采集方式为半接触式采集, 采集过程中由于平移、旋转、采集环境等因素图像质量较低, 采用文献<citation id="235" type="reference">[<a class="sup">19</a>]</citation>中提出的采集装置, 如图6所示, 对300名学生每人左右手各采集6幅图像, 数据库中共有3 600幅图像。三是<i>CASIA</i>库, 图像采集方式为完全的非接触式采集, 采集过程产生平移、旋转, 图像质量低, 对100名志愿者每人左右手各采集6幅图像, 数据库中共1 200幅图像。</p>
                </div>
                <div class="p1">
                    <p id="115">实验运行环境为<i>Python</i> 3.6.3, <i>Matlab R</i>2018<i>a</i>, 硬件平台为<i>Windows</i> 10操作系统, <i>CPU</i>为<i>Intel Core i</i>5-4590, 主频3.30 <i>GHz</i>, 内存为8 <i>GB</i>, <i>GPU</i>为<i>NVIDIA GeForce GTX</i> 1060<i>Ti</i>, 显存6 <i>GB</i>。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 自建库手掌静脉图像采集装置" src="Detail/GetImg?filename=images/JSJY201904039_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 自建库手掌静脉图像采集装置  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Palm vein image acquisition device for self</i>-<i>built database</i></p>

                </div>
                <h4 class="anchor-tag" id="117" name="117">2.2 <b>方法评估</b></h4>
                <h4 class="anchor-tag" id="118" name="118">2.2.1 评价指标</h4>
                <div class="p1">
                    <p id="119">在图像识别中评价模型时要用到的指标:</p>
                </div>
                <div class="p1">
                    <p id="120">1) 在验证模式下, 将数据库中的所有图像进行两两匹配, 采用错误接受率 (<i>False Acceptance Rate</i>, <i>FAR</i>) 、错误拒绝率 (<i>False Rejection Rate</i>, <i>FRR</i>) 、等错误率 (<i>Equal Error Rate</i>, <i>EER</i>) 来衡量系统性能。<i>FAR</i>指不同的人被认为是同一个人的比率;<i>FRR</i>指同一个人被认为不是同一个人的比率;<i>EER</i>指<i>FAR</i>和<i>FRR</i>相等时二者的值, 是衡量一个身份认证系统的综合指标。在同一个坐标中<i>FAR</i>随阈值增大而减小, <i>FRR</i>随阈值增大而增大, 交点就是<i>EER</i>的值。对于一个更优的掌静脉算法, 在相同阈值情况下, <i>FAR</i>和<i>FRR</i>都越小越好, 即<i>EER</i>越小越好, 计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mi>Ν</mi><mi>F</mi><mi>A</mi><mo>/</mo><mi>Ν</mi><mi>Ι</mi><mi>R</mi><mi>A</mi></mtd></mtr><mtr><mtd><mi>F</mi><mi>R</mi><mi>R</mi><mo>=</mo><mi>Ν</mi><mi>F</mi><mi>R</mi><mo>/</mo><mi>Ν</mi><mi>G</mi><mi>R</mi><mi>A</mi></mtd></mtr><mtr><mtd><mi>E</mi><mi>E</mi><mi>R</mi><mo>=</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>F</mi><mi>A</mi><mi>R</mi><mo stretchy="false">) </mo><mo>=</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">其中:<i>NFA</i>、<i>NIRA</i>分别表示错误接受次数和类间测试次数;<i>NFR</i>、<i>NGRA</i>分别表示错误拒绝次数和类内测试次数。</p>
                </div>
                <div class="p1">
                    <p id="123">2) 在识别模式下, 随机选择一幅图像作为模板, 将剩下的5幅图像作为测试样本, 用正确识别率 (Correct Recognition Rate, CRR) 衡量该系统的性能。<i>CRR</i>是指在识别模式下, 识别正确的比率, 是正确识别次数与实验总次数的比值, 即<i>CRR</i>越大越好, 计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>R</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>V</mi><msub><mrow></mrow><mi>C</mi></msub></mrow><mrow><mi>V</mi><msub><mrow></mrow><mi>S</mi></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">其中:<i>V</i><sub><i>C</i></sub>、<i>V</i><sub><i>S</i></sub>分别表示正确识别次数和实验总次数。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126">2.2.2 去雾系数<i>ω</i>对识别精度的影响</h4>
                <div class="p1">
                    <p id="127">根据式 (6) 对DCP算法中的去雾系数<i>ω</i>进行自适应, 此方法既符合不同图像对去雾程度的不同需求又省去了对<i>ω</i>复杂的调参测试过程;既节约实验时间又提高了增强效果。图7是以CASIA库为例, 只进行DCP增强时<i>ω</i>取不同值得到的<i>EER</i>, 由图可看出, 自适应选取<i>ω</i>更满足每幅图像对去雾程度的需要, 可以获得更佳的增强效果, <i>EER</i> (图中曲线与直线交点) 为0.114 2, 在所有<i>ω</i>取值中达到最低。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 ω不同取值时的EER" src="Detail/GetImg?filename=images/JSJY201904039_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 <i>ω</i>不同取值时的<i>EER</i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 <i>EER</i> of different values of <i>ω</i></p>

                </div>
                <h4 class="anchor-tag" id="129" name="129">2.2.3 子块大小对识别精度的影响</h4>
                <div class="p1">
                    <p id="130">在实验中, 输入图像均为128×128的手掌静脉<i>ROI</i>图像, 故以8的倍数作为子块长度。输入图像的尺寸较小, 为了尽量减小块效应, 实验移动步长取1。图8显示了子块大小分别为8×8、16×16、32×32时<i>POSHE</i>算法的增强效果。</p>
                </div>
                <div class="p1">
                    <p id="131">对于<i>PolyU</i>库和自建库, 如图8可看出, 当子块大小为8×8时, 静脉的增强效果不够理想, 且图像噪声比较大;当子块大小为16×16和32×32时, 能看到清晰的掌静脉;当子块大小为32×32时, 虽然静脉比较清晰, 但是图像中部分非静脉区域过黑, 边缘黑化尤为明显, 严重影响后期静脉的识别和匹配。取子块大小为16×16不仅解决了非静脉区域过度黑化的问题, 也可降低计算量, 节省时间, 更符合实时性的要求。对于<i>CASIA</i>库图像, 当子块大小取8×8和16×16时, 图像块效应的影响远大于非静脉区域黑化产生的影响, 因此, 对于<i>CASIA</i>库子块大小取32×32增强效果最佳。</p>
                </div>
                <div class="p1">
                    <p id="132">为节约运行时间, 并选出最佳的子块大小, 只采用改变子块大小的<i>POSHE</i>增强, 并从三个数据库中分别取小部分图像 (100类, 共600幅图像) 进行实验, 计算EER, 实验结果如表1, 经验证以上结论完全正确。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同子块大小的POSHE增强图" src="Detail/GetImg?filename=images/JSJY201904039_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同子块大小的<i>POSHE</i>增强图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 8 <i>Enhanced images of POSHE with different subblock sizes</i></p>

                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表</b>1 <b>子块大小对</b>EER<b>的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Effect of sub</i>-<i>block size on</i> EER</p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td rowspan="2"><br />子块大小</td><td colspan="3"><br />EER</td></tr><tr><td><br /><i>PolyU</i>库</td><td>自建库</td><td><i>CASIA</i>库</td></tr><tr><td><br />8×8</td><td>0.005 1</td><td>0.065 4</td><td>0.114 0</td></tr><tr><td><br />16×16</td><td>0.001 7</td><td>0.045 6</td><td>0.076 0</td></tr><tr><td><br />32×32</td><td>0.001 9</td><td>0.045 8</td><td>0.068 8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">2.2.4 自适应融合方法增强效果分析</h4>
                <div class="p1">
                    <p id="136">图9分别为3个数据库的<i>DCP</i>增强图、<i>POSHE</i>增强图、自适应融合增强图。<i>DCP</i>增强图噪声小, 多数静脉区边界清晰, 但对比度和亮度提升不大, 部分静脉区域欠增强, 部分静脉与背景融为一体, 如图9 (<i>a</i>) 圈出部分;<i>POSHE</i>增强图静脉增强明显, 但整体图像对比度和亮度偏高, 背景与静脉边缘模糊, 部分非静脉区域过增强, 掌纹噪声影响较大, 有较小的块效应, 如图9 (<i>b</i>) 圈出部分;自适应融合增强图融合了两种增强方法的优势, 图像整体亮度与对比度适中, 静脉与背景边界清晰且局部静脉细节清晰, 掌纹噪声影响小。</p>
                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 融合前后的增强图像对比" src="Detail/GetImg?filename=images/JSJY201904039_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 融合前后的增强图像对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 9 <i>Enhanced image comparison before and after fusion</i></p>

                </div>
                <h4 class="anchor-tag" id="138" name="138">2.2.5 与已有方法的比较</h4>
                <div class="p1">
                    <p id="139">将本文方法与目前增强效果较好的几种方法进行比较:文献<citation id="236" type="reference">[<a class="sup">20</a>]</citation>方法分为图像模糊化、图像隶属度值和去模糊化三个主要阶段, 使用具有模糊隶属度值的区间2型模糊集增强, 得到更为明亮、清晰的增强图像。文献<citation id="237" type="reference">[<a class="sup">21</a>]</citation>方法为先用高斯差分 (<i>Difference Of Gaussians</i>, <i>DOG</i>) 滤波器增强静脉细节, 高斯核的半径比为4∶1;再用直方图均衡化提高对比度, 突出静脉, 得到最终增强图像。文献<citation id="238" type="reference">[<a class="sup">22</a>]</citation>方法为先使用双曲正切函数代替<i>sigmoidal</i>函数提高图像对比度;其次使用4个方向的<i>Gabor</i>滤波器滤除噪声并突出方向信息;最后用<i>CLAHE</i>进一步增强对比度, 得到增强图像。文献<citation id="239" type="reference">[<a class="sup">23</a>]</citation>方法先将估计背景灰度矩阵与<i>ROI</i>图像作差, 对图像进行<i>CLAHE</i>增强得到初步去噪、增强的掌静脉图像;再构建8个方向滤波器, 提取掌纹;并将掌纹提取图像与初步增强图像进行加权融合、阈值分割, 得到最终增强图像。不同增强方法的增强图像如图10所示。</p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同方法的增强图像比较" src="Detail/GetImg?filename=images/JSJY201904039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 不同方法的增强图像比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 10 <i>Enhanced image comparison by different methods</i></p>

                </div>
                <div class="p1">
                    <p id="141">本文EER和识别率的计算均采用文献<citation id="240" type="reference">[<a class="sup">18</a>]</citation>方法, 实验结果如表2所示, 可看出本文方法在三个数据库中的EER大部分都低于现有的增强方法, 由于自建库图像受运动模糊影响较大, 部分静脉比较模糊, 所以基于模糊集的方法和用<i>Gabor</i>方向滤波器增强的方法效果会稍微好一些, 但在两个公开库增强效果一般。<i>Gabor</i>滤波器的增强时间会随方向滤波器的增加而增加, 方向滤波器过多会影响实时性;模糊集方法只对自建库模糊图像增强效果较好, 增强区域单一。</p>
                </div>
                <div class="p1">
                    <p id="142">表2中CRR表示不同增强方法的识别率, 识别率越高, 增强效果越好。图11为<i>PolyU</i>库、自建库和<i>CASIA</i>库的受试者工作特征 (<i>Receiver Operating Characteristic</i>, <i>ROC</i>) 曲线, 由此可看出, 本文方法在三个数据库中的识别率基本都高于现有的增强方法。</p>
                </div>
                <div class="p1">
                    <p id="143">算法的高效性对于实际识别系统的设计具有一定的现实意义, 本文对增强算法的时间进行统计, 求取平均值。表2中展示出不同增强方法对运算时间的影响, 其中, 文献<citation id="242" type="reference">[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>]</citation>方法比较简单, 直接应用于整幅图, 用时少;本文方法采用了分块融合的形式, 运算时间有所增加, 但以0.14 <i>s</i>的时间进行增强仍能够满足实时性的要求;文献<citation id="241" type="reference">[<a class="sup">22</a>]</citation>方法使用4个方向<i>Gabor</i>滤波器, 用时较其他方法多。由此看出, 本文方法简单有效, 在获得较好的识别精度的同时, 所用运算时间也比较少, 具有实时性。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904039_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 不同增强方法的ROC曲线" src="Detail/GetImg?filename=images/JSJY201904039_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 不同增强方法的<i>ROC</i>曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904039_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 11 <i>ROC curves of different enhancement methods</i></p>

                </div>
                <h3 id="145" name="145" class="anchor-tag">3 结语</h3>
                <div class="p1">
                    <p id="146">本文研究的目的是设计合适的方法, 尽可能提高掌静脉图像的对比度和亮度, 突出掌静脉的细节信息, 为后续的掌静脉识别提供更可靠的增强图像。本文方法基于<i>DCP</i>和<i>POSHE</i>算法, 将两种算法增强后的图像进行自适应选取最优融合权重, 实现优劣互补, 解决了<i>DCP</i>算法丢失局部细节信息与<i>POSHE</i>算法带来的过增强和块效应等问题。实验结果表明, 本文方法与现有增强方法相比增强效果更好, 提高了识别率, 降低了EER。本文提出的自适应融合方法可以拓展至其他增强方法, 为进一步研究不同增强算法之间的自适应融合提供参考, 以期获得更好的增强效果。</p>
                </div>
                <div class="area_img" id="147">
                    <p class="img_tit"><b>表</b>2 <b>不同增强方法的</b>EER、CRR<b>和运算时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 EER, CRR <i>and computing time of different enhancement methods</i></p>
                    <p class="img_note"></p>
                    <table id="147" border="1"><tr><td rowspan="2">方法</td><td colspan="2"><br /><i>PolyU</i>库</td><td rowspan="2"></td><td colspan="2"><br />自建库</td><td rowspan="2"></td><td colspan="2"><br /><i>CASIA</i>库</td><td rowspan="2">运算<br />时间/<i>s</i></td></tr><tr><td><br />EER</td><td>CRR/%</td><td><br />EER</td><td>CRR/%</td><td><br />EER</td><td>CRR/%</td></tr><tr><td>文献[20]方法</td><td>0.007 9</td><td>99.12</td><td></td><td>0.055 4</td><td>92.48</td><td></td><td>0.108 7</td><td>88.00</td><td>0.01</td></tr><tr><td><br />文献[21]方法</td><td>0.001 6</td><td>99.82</td><td></td><td>0.058 5</td><td>92.03</td><td></td><td>0.087 5</td><td>89.70</td><td>0.01</td></tr><tr><td><br />文献[22]方法</td><td>0.001 7</td><td>99.76</td><td></td><td>0.041 8</td><td>94.34</td><td></td><td>0.054 9</td><td>93.15</td><td>0.33</td></tr><tr><td><br />文献[23]方法</td><td>0.001 0</td><td>99.91</td><td></td><td>0.061 9</td><td>91.62</td><td></td><td>0.049 2</td><td>93.59</td><td>0.06</td></tr><tr><td><br />本文方法</td><td>0.000 4</td><td>99.98</td><td></td><td>0.057 9</td><td>92.05</td><td></td><td>0.047 2</td><td>94.27</td><td>0.14</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="173">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJDZ201801001&amp;v=MDAzMDJmUGRMRzRIOW5Ncm85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCS3k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>孟宪静, 袭肖明, 杨璐, 等.基于灰度不均匀矫正和SIFT的手指静脉识别方法[J].南京大学学报 (自然科学版) , 2018, 54 (1) :1-10. (MENG X J, XI X M, YANG L, et al.Finger vein recognition based on intensity inhomogeneity correction and scale invariant tfeature transform[J].Journal of Nanjing University (Natural Science) , 2018, 54 (1) :1-10.) 
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature extraction of palm vein patterns based on two-dimensional density function">

                                <b>[2]</b>KUBANEK M, SMORAWA D, HOLOTYAK T.Feature extraction of palm vein patterns based on two-dimensional density function[C]//ICAISC 2015:Proceedings of the 2015 Artificial Intelligence and Soft Computing, LNCS 9120.Berlin:Springer, 2015:101-111.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Finger-vein image enhancement using a fuzzy-based fusion method with Gabor and Retinex filtering">

                                <b>[3]</b>SHIN K Y, PARK Y H, NGUYEN D T, et al.Finger-vein image enhancement using a fuzzy-based fusion method with Gabor and Retinex filtering[J].Sensors, 2014, 14 (2) :3095-3129.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel algorithm for hand vein enhancement and segmentation based on the Retinex method">

                                <b>[4]</b>ZHANG L G.A novel algorithm for hand vein enhancement and segmentation based on the Retinex method[EB/OL].[2018-05-10].http://dx.doi.org/10.2495/CECNet130411.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Implementing real-time RCF-Retinex image enhancement method using CUDA">

                                <b>[5]</b>YANG X, JIAN L, WU W, et al.Implementing real-time RCF-Retinex image enhancement method using CUDA[J].Journal of RealTime Image Processing, 2018, 25 (4) :1-11.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201315024&amp;v=MTY4MTNvOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUx6QlBTblBaTEc0SDlMTnE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>杨数强, 杨杰慧, 宋亚龙.手指静脉图像小波增强算法[J].现代电子技术, 2013, 36 (15) :73-75. (YANG S Q, YANG J H, SONG Y L.Finger vein image enhancement algorithm based on wavelet transform[J].Modern Electronics Technique, 2013, 36 (15) :73-75.) 
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD13070300066950&amp;v=MTcwNjlqM2Fhcks3SHRiTXJJOUZaTzBKQlhrNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGb1hhUnM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>ZHANG C, FU Y.Research on the image enhancement algorithm based on improved wavelet transform[J].Journal of Convergence Information Technology, 2013, 8 (6) :384-392.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZJGD201801010&amp;v=MTY2NzdMekJQeWZNYXJHNEg5bk1ybzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>陈朋, 姜立, 王海霞, 等.基于散射卷积网络的手指静脉识别方法研究[J].浙江工业大学学报, 2018, 46 (1) :56-60. (CHEN P, JIANG L, WANG H X, et al.Finger vein recognition based on scattering convolution network[J].Journal of Zhejiang University of Technology, 2018, 46 (1) :56-60.) 
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES131B27FE19BEE4CF279E25214B10F181&amp;v=MDk4NjM5ZVFrOXZHQVI3VFlJU25yZ3JSWkhlTExpUkxLZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHpMeTh3NkU9TmlmT2ZiSzdINlBPcVBrd1plSg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>HAJIAN A, AMLI D.Sharpness enhancement of finger-vein image based on modified un-sharp mask with Log-Gabor filter[J].Procedia Computer Science, 2018, 126 (7) :431-440.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201304058&amp;v=MjU3MTVxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCTHo3QmQ3RzRIOUxNcTQ5QWJJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>蔡超峰, 任景英.基于直方图均衡化的手背静脉图像对比度增强[J].计算机应用, 2013, 33 (4) :1125-1127. (CAI C F, REN J.Contrast enhancement of hand vein images based on histogram equalization[J].Journal of Computer Applications, 2013, 33 (4) :1125-1127.) 
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm to enhance near infrared images of blood vein in antecubital fossa based on adaptive histogram equalization">

                                <b>[11]</b>FRANCIS M.An efficient algorithm to enhance near infrared images of blood vein in antecubital fossa based on adaptive histogram equalization[C]//Proceedings on ELSEVIER International Conference on Emerging Trends in Electrical Engineering.Amsterdam:Elsevier, 2014:35.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image enhancement using fuzzy set">

                                <b>[12]</b>JENA G, JENA S, BONAM V R.Image enhancement using fuzzy set[C]//AHFE 2017:Proceedings of the 2017 Advances in Human Factors in Simulation and Modeling.Berlin:Springer, 2017:141-150.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                江晓龙, 王华彬, 王东旭, 等.改进的单幅近红外掌纹掌静脉图像融合识别[J/OL].计算机应用研究, 2019.[2018-04-12].http://www.arocmag.com/article/02-2019-07-055.html. (JIANG X L, WANG H B, WANG D X, et al.Improved fusion recognition for near infrared palmprint and palm vein image[J/OL].Application Research of Computers, 2019.[2018-04-12].http://www.arocmag.com/article/02-2019-07-055.html.) 
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new approach to hand vein image enhancement">

                                <b>[14]</b>ZHAO J, TIAN H, X U W, et al.A new approach to hand vein image enhancement[C]//Proceedings of the 2009 Second International Conference on Intelligent Computation Technology and Automation.Piscataway, NJ:IEEE, 2009:499-501.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single Image Haze Removal Using Dark Channel Prior">

                                <b>[15]</b>HE K, SUN J, TANG X.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (12) :2341-2353.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An advanced contrast enhancement using partially overlapped sub-block histogram equalization">

                                <b>[16]</b>KIM J Y, KIM L S, HWANG S H.An advanced contrast enhancement using partially overlapped sub-block histogram equalization[J].IEEE Transactions on Circuits&amp;Systems for Video Technology, 2001, 11 (4) :475-484.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Human Identification Using Palm-Vein Images">

                                <b>[17]</b>ZHOU Y, KUMAR A.Human identification using palm-vein images[J].IEEE Transactions on Information Forensics&amp;Security, 2011, 6 (4) :1259-1274.
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201402010&amp;v=Mjg0NTJyWTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVMekJQeXJmYkxHNEg5WE0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>周宇佳, 刘娅琴, 杨丰, 等.基于方向特征的手掌静脉识别[J].中国图象图形学报, 2014, 19 (2) :243-252. (ZHOU YJ, LIU Y Q, YANG F, et al.Palm-vein recognition based on oriented features[J].Journal of Image and Graphics, 2014, 19 (2) :243-252.) 
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time locating method for palmvein image acquisition">

                                <b>[19]</b>LIU Y, ZHOU Y, QIU S, et al.Real-time locating method for palmvein image acquisition[C]//ICIG 2015:Proceedings of the2015 Image and Graphics.Berlin:Springer, 2015:94-110.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Finger vein biometric system with type-2 fuzzy enhancement and minutiae matching">

                                <b>[20]</b>EZHILMARAN D, JOSEPH R B.Finger vein biometric system with type-2 fuzzy enhancement and minutiae matching[C]//Proceedings of the 2017 IEEE Region 10 Symposium.Piscataway, NJ:IEEE, 2017:1-4.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contact-free palm-vein recognition based on local invariant features">

                                <b>[21]</b>KANG W, LIU Y, WU Q, et al.Contact-free palm-vein recognition based on local invariant features[J].PLo S One, 2014, 9 (5) :1-12.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Finger-vein recognition based on dual-sliding window localization and pseudo-elliptical transformer">

                                <b>[22]</b>QIU S, LIU Y, ZHOU Y, et al.Finger-vein recognition based on dual-sliding window localization and pseudo-elliptical transformer[J].Expert Systems with Applications, 2016, 64:618-632.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201636009&amp;v=MDU1NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpCTGpYQmZiRzRIOWZQcVk5RmJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>袁玲, 黄靖, 刘娅琴, 等.基于图像融合的去掌纹手掌静脉图像增强方法[J].科学技术与工程, 2016, 16 (36) :48-54. (YUAN L, HUANG J, LIU Y Q, et al.Palm vein enhancement algorithm by removing palmprint based on image fusion[J].Science Technology and Engineering, 2016, 16 (36) :48-54.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904039&amp;v=MDM4MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUx6Qkx6N0JkN0c0SDlqTXE0OUdiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
