<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991925572500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903017%26RESULT%3d1%26SIGN%3dOYr8JFXtrhdcWB6CXtFM%252bB0BiOg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903017&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903017&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903017&amp;v=MDYyMzh2TEx6N0JkN0c0SDlqTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 数据采集与预处理 ">1 数据采集与预处理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="1.1 &lt;b&gt;数据采集&lt;/b&gt;">1.1 <b>数据采集</b></a></li>
                                                <li><a href="#54" data-title="1.2 &lt;b&gt;数据预处理&lt;/b&gt;">1.2 <b>数据预处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="2 周期划分与特征提取 ">2 周期划分与特征提取</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="2.1 &lt;b&gt;周期划分&lt;/b&gt;">2.1 <b>周期划分</b></a></li>
                                                <li><a href="#64" data-title="2.2 &lt;b&gt;特征提取&lt;/b&gt;">2.2 <b>特征提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="3 分类器融合算法 ">3 分类器融合算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="3.1 &lt;b&gt;提取判别因子&lt;/b&gt;">3.1 <b>提取判别因子</b></a></li>
                                                <li><a href="#91" data-title="3.2 &lt;b&gt;构建表决函数&lt;/b&gt;">3.2 <b>构建表决函数</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="4.1 &lt;b&gt;实验准备&lt;/b&gt;">4.1 <b>实验准备</b></a></li>
                                                <li><a href="#132" data-title="4.2 &lt;b&gt;实验设计与结果分析&lt;/b&gt;">4.2 <b>实验设计与结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#160" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="图1 多分类器识别融合算法">图1 多分类器识别融合算法</a></li>
                                                <li><a href="#52" data-title="图2 手机放置位置">图2 手机放置位置</a></li>
                                                <li><a href="#56" data-title="图3 滤波前后数据">图3 滤波前后数据</a></li>
                                                <li><a href="#66" data-title="图4 不同个体的步态周期">图4 不同个体的步态周期</a></li>
                                                <li><a href="#81" data-title="图5 不同个体的区间划分">图5 不同个体的区间划分</a></li>
                                                <li><a href="#82" data-title="图6 新特征提取流程">图6 新特征提取流程</a></li>
                                                <li><a href="#83" data-title="图7 MSV算法流程">图7 MSV算法流程</a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;备选分类器&lt;/b&gt;"><b>表</b>1 <b>备选分类器</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;测试集识别率&lt;/b&gt;"><b>表</b>2 <b>测试集识别率</b></a></li>
                                                <li><a href="#148" data-title="图8 不同特征下的训练和测试时间">图8 不同特征下的训练和测试时间</a></li>
                                                <li><a href="#149" data-title="图9 所有特征对应的ReliefF值">图9 所有特征对应的ReliefF值</a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;验证集识别率&lt;/b&gt;"><b>表</b>3 <b>验证集识别率</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;不同融合算法的识别率&lt;/b&gt;"><b>表</b>4 <b>不同融合算法的识别率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" LIU R, ZHOU J, LIU M, et al. A wearable acceleration sensor system for gait recognition [C]// Proceedings of the 2007 2nd IEEE Conference on Industrial Electronics and Applications. Piscataway, NJ: IEEE, 2007: 2654-2659." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A wearable acceleration sensor system for gait recognition">
                                        <b>[1]</b>
                                         LIU R, ZHOU J, LIU M, et al. A wearable acceleration sensor system for gait recognition [C]// Proceedings of the 2007 2nd IEEE Conference on Industrial Electronics and Applications. Piscataway, NJ: IEEE, 2007: 2654-2659.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" MUAAZ M, MAYRHOFER R. Accelerometer based gait recognition using adapted Gaussian mixture models [C]// Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media. New York: ACM, 2016: 288-291." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accelerometer based gait recognition using adapted Gaussian mixture models">
                                        <b>[2]</b>
                                         MUAAZ M, MAYRHOFER R. Accelerometer based gait recognition using adapted Gaussian mixture models [C]// Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media. New York: ACM, 2016: 288-291.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     万彩艳. 基于智能手机加速度传感器的步态身份识别[D].常州:常州大学, 2018: 21-35. (WAN C Y. Gait identification based on mobile-phone acceleration sensor [D]. Changzhou: Changzhou University, 2018: 21-35.) </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" SUN B, WANG Y, BANDA J. Gait characteristic analysis and identification based on the iPhone&#39;s accelerometer and gyrometer [J]. Sensors, 2014, 14 (9) : 17037-17054." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gait characteristic analysis and identification based on the i Phone&amp;#39;&amp;#39;s accelerometer and gyrometer">
                                        <b>[4]</b>
                                         SUN B, WANG Y, BANDA J. Gait characteristic analysis and identification based on the iPhone&#39;s accelerometer and gyrometer [J]. Sensors, 2014, 14 (9) : 17037-17054.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 张丽娜.基于加速度传感器的步态特征身份认证[D].沈阳:沈阳工业大学, 2014: 40-65. (ZHANG L N. Gait feature authentication based on acceleration sensor [D]. Shenyang: Shenyang University of Technology, 2014: 40-65.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014308675.nh&amp;v=MTcwOTBacEZpRGxXN3ZMVkYyNkdyQzRGdGZMcXBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         张丽娜.基于加速度传感器的步态特征身份认证[D].沈阳:沈阳工业大学, 2014: 40-65. (ZHANG L N. Gait feature authentication based on acceleration sensor [D]. Shenyang: Shenyang University of Technology, 2014: 40-65.) 
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" MUAAZ M, MAYRHOFER R. An analysis of different approaches to gait recognition using cell phone based accelerometers [C]// Proceedings of the 11th International Conference on Advances in Mobile Computing and Multimedia. New York: ACM, 2013: 293-300." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An analysis of different approaches to gait recognition using cell phone based accelerometers">
                                        <b>[6]</b>
                                         MUAAZ M, MAYRHOFER R. An analysis of different approaches to gait recognition using cell phone based accelerometers [C]// Proceedings of the 11th International Conference on Advances in Mobile Computing and Multimedia. New York: ACM, 2013: 293-300.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 王忠民, 王科, 贺炎.高可信度加权的多分类器融合行为识别模型[J].计算机应用, 2016, 36 (12) :3353-3357. (WANG Z M, WANG K, HE Y. Multiple classifier fusion model for activity recognition based on high reliability weighted [J]. Journal of Computer Applications, 2016, 36 (12) :3353-3357.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201612021&amp;v=MDE1NDl1WnBGaURsVzd2TEx6N0JkN0c0SDlmTnJZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         王忠民, 王科, 贺炎.高可信度加权的多分类器融合行为识别模型[J].计算机应用, 2016, 36 (12) :3353-3357. (WANG Z M, WANG K, HE Y. Multiple classifier fusion model for activity recognition based on high reliability weighted [J]. Journal of Computer Applications, 2016, 36 (12) :3353-3357.) 
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" YUAN Y, WANG C, ZHANG J, et al. An ensemble approach for activity recognition with accelerometer in mobile-phone [C]// Proceedings of the 11th International Conference on Computational Science and Engineering. Washington, DC: IEEE Computer Society, 2014: 1469-1474." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Ensemble Approach for Activity Recognition with Accelerometer in Mobile-Phone">
                                        <b>[8]</b>
                                         YUAN Y, WANG C, ZHANG J, et al. An ensemble approach for activity recognition with accelerometer in mobile-phone [C]// Proceedings of the 11th International Conference on Computational Science and Engineering. Washington, DC: IEEE Computer Society, 2014: 1469-1474.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" BAYAT A, POMPLUN M, TRAN D A. A study on human activity recognition using accelerometer data from smartphones [J]. Procedia Computer Science, 2014, 34: 450-457." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700488288&amp;v=MDQ5ODJNSERuUXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyakpLRjRjYmhFPU5pZk9mYks4SDlETXFJOUZZTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         BAYAT A, POMPLUN M, TRAN D A. A study on human activity recognition using accelerometer data from smartphones [J]. Procedia Computer Science, 2014, 34: 450-457.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" SPRAGER S, JURIC M B. An efficient HOS-based gait authentication of accelerometer data [J]. IEEE Transactions on Information Forensics and Security, 2015, 10 (7) : 1486-1498." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient HOS-based gait authentication of accelerometer data">
                                        <b>[10]</b>
                                         SPRAGER S, JURIC M B. An efficient HOS-based gait authentication of accelerometer data [J]. IEEE Transactions on Information Forensics and Security, 2015, 10 (7) : 1486-1498.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" LU H, HUANG J, SAHA T, et al. Unobtrusive gait verification for mobile phones [C]// Proceedings of the 2014 ACM International Symposium on Wearable Computers. New York: ACM, 2014: 91-98." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unobtrusive gait verification for mobile phones">
                                        <b>[11]</b>
                                         LU H, HUANG J, SAHA T, et al. Unobtrusive gait verification for mobile phones [C]// Proceedings of the 2014 ACM International Symposium on Wearable Computers. New York: ACM, 2014: 91-98.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" DERAWI M, BOURS P. Gait and activity recognition using commercial phones[J]. Computers and Security, 2013, 39: 137-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500312620&amp;v=MTg3NzBmT2ZiSzlIOVBPcW85Rlorb05DbjQ1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpKS0Y0Y2JoRT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         DERAWI M, BOURS P. Gait and activity recognition using commercial phones[J]. Computers and Security, 2013, 39: 137-144.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" WATANABE Y. Influence of holding smart phone for acceleration-based gait authentication [C]// Proceedings of the 2014 5th International Conference on Emerging Security Technologies. Washington, DC: IEEE Computer Society, 2014: 30-33." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Influence of holding smart phone for accelerationbased gait authentication">
                                        <b>[13]</b>
                                         WATANABE Y. Influence of holding smart phone for acceleration-based gait authentication [C]// Proceedings of the 2014 5th International Conference on Emerging Security Technologies. Washington, DC: IEEE Computer Society, 2014: 30-33.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" HOANG T, CHOI D. Secure and privacy enhanced gait authentication on smart phone [J]. The Scientific World Journal, 2014, 2014: Article ID 438254." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Secure and privacy enhanced gait authentication on smart phone">
                                        <b>[14]</b>
                                         HOANG T, CHOI D. Secure and privacy enhanced gait authentication on smart phone [J]. The Scientific World Journal, 2014, 2014: Article ID 438254.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" PRIMO A, PHOHA V V, KUMAR R, et al. Context-aware active authentication using smartphone accelerometer measurements [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops. Washington, DC: IEEE Computer Society, 2014: 98-105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-aware active authentication using smart phone accelerometer measurements">
                                        <b>[15]</b>
                                         PRIMO A, PHOHA V V, KUMAR R, et al. Context-aware active authentication using smartphone accelerometer measurements [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops. Washington, DC: IEEE Computer Society, 2014: 98-105.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 钱竞光, 宋雅伟, 叶强, 等.步行动作的生物力学原理及其步态分析[J].南京体育学院学报 (自然科学版) , 2006, 5 (4) :1-7. (QIAN J G, SONG Y W, YE Q, et al. The biomechanics principle of walking and analysis on gaits[J]. Journal of Nanjing Institute of Physical Education (Natural Science) , 2006, 5 (4) :1-7.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NTXZ200604001&amp;v=MDg2MTZxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkxLem5UZExHNEh0Zk1xNDlGWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         钱竞光, 宋雅伟, 叶强, 等.步行动作的生物力学原理及其步态分析[J].南京体育学院学报 (自然科学版) , 2006, 5 (4) :1-7. (QIAN J G, SONG Y W, YE Q, et al. The biomechanics principle of walking and analysis on gaits[J]. Journal of Nanjing Institute of Physical Education (Natural Science) , 2006, 5 (4) :1-7.) 
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 王科.多分类器融合算法在行为识别中的应用研究[D].西安:西安邮电大学, 2017: 40-61. (WANG K. Application and research of multiple classifier fusion algorithm in activity recognition [D]. Xi&#39;an: Xi&#39;an University of Posts and Telecommunications, 2017: 40-61.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017079279.nh&amp;v=MTE4NjJDVVI3cWZadVpwRmlEbFc3dkxWRjI2R2JPL0Y5UExwcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         王科.多分类器融合算法在行为识别中的应用研究[D].西安:西安邮电大学, 2017: 40-61. (WANG K. Application and research of multiple classifier fusion algorithm in activity recognition [D]. Xi&#39;an: Xi&#39;an University of Posts and Telecommunications, 2017: 40-61.) 
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 黄莉莉, 汤进, 孙登第, 等.基于多标签ReliefF的特征选择算法[J].计算机应用, 2012, 32 (10) :2888-2890. (HUANG L L, TANG J, SUN D D, et al. Feature selection algorithm based on multi-label ReliefF [J]. Journal of Computer Applications, 2012, 32 (10) :2888-2890.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201210054&amp;v=MzE5NzVsVzd2TEx6N0JkN0c0SDlQTnI0OUFZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaUQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         黄莉莉, 汤进, 孙登第, 等.基于多标签ReliefF的特征选择算法[J].计算机应用, 2012, 32 (10) :2888-2890. (HUANG L L, TANG J, SUN D D, et al. Feature selection algorithm based on multi-label ReliefF [J]. Journal of Computer Applications, 2012, 32 (10) :2888-2890.) 
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" QU J, ZHANG Z, GONG T. A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion [J]. Neurocomputing, 2016, 171 (C) : 837-853.This work is partially supported by the National Natural Science Foundation of China (61772248) .HUAN Zhan, born in 1969, M. S., associate professor. His research interests include Internet of things, intelligent control.CHEN Xuejie, born in 1994, M. S. candidate. His research interests include Internet of things, intelligent control.LYU Shiyun, born in 1994, M. S. candidate. Her research interests include Internet of things, intelligent control.GENG Hongyang, born in 1995, M. S. candidate. His research interests include Internet of things, intelligent control." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion&amp;quot;">
                                        <b>[19]</b>
                                         QU J, ZHANG Z, GONG T. A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion [J]. Neurocomputing, 2016, 171 (C) : 837-853.This work is partially supported by the National Natural Science Foundation of China (61772248) .HUAN Zhan, born in 1969, M. S., associate professor. His research interests include Internet of things, intelligent control.CHEN Xuejie, born in 1994, M. S. candidate. His research interests include Internet of things, intelligent control.LYU Shiyun, born in 1994, M. S. candidate. Her research interests include Internet of things, intelligent control.GENG Hongyang, born in 1995, M. S. candidate. His research interests include Internet of things, intelligent control.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-19 13:54</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),712-718 DOI:10.11772/j.issn.1001-9081.2018071638            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多分类器融合的步态识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%87%E6%88%98&amp;code=25361396&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郇战</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%AD%A6%E6%9D%B0&amp;code=38653307&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈学杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%95%E5%A3%AB%E4%BA%91&amp;code=41275248&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕士云</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%80%BF%E5%AE%8F%E6%9D%A8&amp;code=36551311&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">耿宏杨</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B8%B8%E5%B7%9E%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0268985&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">常州大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了提高现有基于智能手机加速度传感器步态身份识别的性能, 提出了一种基于多分类器融合 (MCF) 的识别方法。首先, 针对现有方法所提取的步态特征较为单一的问题, 对单个步态周期提取相对匀变加速度的速度变化量, 以及单位时间内加速度变化量作为两类新特征 (共16个) ;其次, 将新特征结合常用的时域、频域特征组成新的特征集, 用于训练识别效果与训练时间俱佳的多个分类器;最后, 采用多尺度投票法 (MSV) 对多分类器的输出进行融合处理, 得到最终的分类结果。为了检测该方法的性能, 采集了32个志愿者的步态数据。实验结果表明, 新特征对于单个分类器的识别率平均提升5.95个百分点, 最终通过MSV融合算法的识别率为97.78%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%88%86%E7%B1%BB%E5%99%A8%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多分类器融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">融合算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%8A%95%E7%A5%A8%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多尺度投票法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A5%E6%80%81%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">步态特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郇战 (1969—) , 男, 陕西咸阳人, 副教授, 硕士, 主要研究方向:物联网、智能控制;;
                                </span>
                                <span>
                                    *陈学杰 (1994—) , 男, 江苏宿迁人, 硕士研究生, 主要研究方向:物联网、智能控制;电子邮箱1214136456@qq.com;
                                </span>
                                <span>
                                    吕士云 (1995—) , 女, 江苏盐城人, 硕士研究生, 主要研究方向:物联网、智能控制;;
                                </span>
                                <span>
                                    耿宏杨 (1995—) , 男, 江苏宿迁人, 硕士研究生, 主要研究方向:物联网、智能控制。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61772248);</span>
                    </p>
            </div>
                    <h1><b>Gait recognition method based on multiple classifier fusion</b></h1>
                    <h2>
                    <span>HUAN Zhan</span>
                    <span>CHEN Xuejie</span>
                    <span>LYU Shiyun</span>
                    <span>GENG Hongyang</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Engineering, Changzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To improve the performance of gait recognition based on smartphone accelerometer, a recognition method based on Multiple Classifier Fusion (MCF) was proposed. Firstly, as the gait features extracted from the existing methods were relatively simple, the speed variation of the relative gradual acceleration extracted from each single gait cycle and the acceleration variation per unit time were taken as two new types of features (16 in total) . Secondly, combing the new features with the frequently-used time domain and frequency domain features to form a new feature set, which could be used to train multiple classifiers with excellent recognition effect and short training time. Finally, Multiple Scale Voting (MSV) was used to fuse the output of the multiple classifiers to obtain the final classification result. To test the performance of the proposed method, the gait data of 32 volunteers were collected. Experimental results show that the recognition rate of new features for a single classifier is increased by 5.95 % on average, and the final recognition rate of MSV fusion algorithm is 97.78%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multiple%20Classifier%20Fusion%20(MCF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multiple Classifier Fusion (MCF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fusion%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fusion algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multiple%20scale%20voting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multiple scale voting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=gait%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">gait feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=motion%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">motion feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HUAN Zhan, born in 1969, M. S. , associate professor. His research interests include Internet of things, intelligent control.;
                                </span>
                                <span>
                                    CHEN Xuejie, born in 1994, M. S. candidate. His research interests include Internet of things, intelligent control.;
                                </span>
                                <span>
                                    LYU Shiyun, born in 1994, M. S. candidate. Her research interests include Internet of things, intelligent control.;
                                </span>
                                <span>
                                    GENG Hongyang, born in 1995, M. S. candidate. His research interests include Internet of things, intelligent control.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-08</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61772248);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="41">人类的步态包含非常独特的模式, 可用于身份的识别和验证。传统的基于可穿戴式传感器步态身份识别都是通过在人体固定部位捆绑专用传感器采集步态数据<citation id="162" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>;近年来, 智能手机的快速普及其及功能的不断发展, 使在不影响用户正常工作、学习和生活的情况下, 利用智能手机内置的加速度传感器对用户进行步态身份识别变为可能<citation id="163" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。但是由于智能手机种类繁杂、内置加速度传感器性能差异较大等因素, 都使得最终采集到的数据差异较大, 识别的难度大, 从而直接影响识别的准确率和可信度。</p>
                </div>
                <div class="p1">
                    <p id="42">为了提高步态识别的准确率, 国内外的研究者们对基于智能手机加速度传感器的步态身份识别进行持续性的探索研究, 目前的研究成果主要体现在以下三个方面:</p>
                </div>
                <div class="p1">
                    <p id="43">1) 步态周期提取与特征选择。文献<citation id="164" type="reference">[<a class="sup">3</a>]</citation>利用形状上下文 (Shape Context, SC) 和线性时间归一化 (Linear Time Normalization, LTN) 相结合提取典型周期, 通过典型周期特征来表示整个步态数据特征, 实验结果表明身份识别的准确率达到97.1%。文献<citation id="165" type="reference">[<a class="sup">4</a>]</citation>分别从步态数据中提取步态频率、对称系数、数值波动范围和特征曲线的相似系数作为特征, 最后根据这些特征提出权重投票机制进行分类识别, 实验结果表明提出的这几类特征能够有效地进行分类识别。</p>
                </div>
                <div class="p1">
                    <p id="44">2) 改进或提出新的分类算法。文献<citation id="166" type="reference">[<a class="sup">5</a>]</citation>提出一种新的动态时间规整 (Dynamic Time Warping, DTW) 算法, 将特征点的时间和幅值作为一个二维序列采用波峰和波谷成对搜索最小累计距离路径, 再通过阈值判断实现身份识别, 但是该方法目前只在小样本内得到验证。文献<citation id="167" type="reference">[<a class="sup">6</a>]</citation>提出了一种分段线性逼近 (Piecewise Linear Approximation, PLA) 的步态周期提取方法, 在原有支持向量机 (Support Vector Machine, SVM) 高斯内核的基础上引入一种新型的弹性距离度量核 (Gaussian Dynamic Time Wrap, GDTW) 函数, 通过实验验证DTW和PLA两种方法在提取步态周期方面的性能, 结果表明提出的方法极大地改善了分类结果。</p>
                </div>
                <div class="p1">
                    <p id="45">3) 利用集成学习通过构建多个学习器完成学习任务。文献<citation id="168" type="reference">[<a class="sup">7</a>]</citation>利用蚁群算法优选特征训练多分类器, 提出高可信度加权投票法对分类器输出进行融合处理, 最终模型识别率较单一分类器提升3%以上;文献<citation id="169" type="reference">[<a class="sup">8</a>]</citation>利用多个极速学习机的输出进行简单均值算法融合处理, 最终模型输出识别准确率比单个极速学习机高出3.6%。集成学习优点在于通过将多个学习器进行结合, 常可以获得比单一学习器更优越的泛化性能, 但这也取决于融合算法的选取, 适当的融合算法往往可以获得较好的泛化能力, 反之亦然。</p>
                </div>
                <div class="p1">
                    <p id="46">上述文献对人员加速度信号作了普适性的特征选取, 并取得了较好的识别率, 但并未对人员步行时的运动特征进行探究;并且都选取识别率最好的单一分类器进行探究。针对上述不足, 本文从步态数据中提取加速度变化率以及相对于匀加速度的速度变化量作为新特征, 结合常用时频域特征对多个分类器进行建模识别, 并且提出多尺度投票法 (Multiple Scale Voting, MSV) 进行融合处理, 进而得到最终的识别结果。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 数据采集与预处理</h3>
                <div class="p1">
                    <p id="48">为了提高现有基于智能手机加速度传感器的步态身份识别性能, 提出了一种基于多分类器融合 (Multiple Classifier Fusion, MCF) 的识别方法, 具体算法流程如图1所示。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 多分类器识别融合算法" src="Detail/GetImg?filename=images/JSJY201903017_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 多分类器识别融合算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Multi-classifier recognition fusion algorithm</p>

                </div>
                <h4 class="anchor-tag" id="50" name="50">1.1 <b>数据采集</b></h4>
                <div class="p1">
                    <p id="51">为了获取稳定的步态数据, 传统都是将传感器固定在腰后部、大腿根部、手臂、脚踝等几个位置, 但是当放置在手臂和脚踝进行数据采集时, 由于手部和脚部的一系列不自主的抖动, 造成信号中夹杂较多的噪声, 进而影响所获得数据的完整性和稳定性;为了增加步态数据信号采集时候的稳定性, 在采集数据时将智能手机放置在大腿根部的裤子口袋中, 并且利用内置的加速度传感器来采集数据, 具体放置位置如图2所示。采集数据时利用三星Note Ⅱ系列的智能手机进行采集, 采样频率为100 Hz。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 手机放置位置" src="Detail/GetImg?filename=images/JSJY201903017_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 手机放置位置  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Mobile phone location</p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">1.2 <b>数据预处理</b></h4>
                <div class="p1">
                    <p id="55">人员运动时原始加速度信号中含有高频噪声, 主要来自两个方面:一是手机加速度传感器本身的原因;二是在采集步态数据的过程中, 因人体的生理抖动产生的噪声。考虑到加速度传感器自身灵敏度较高这一特性, 即使细小的抖动也会影响加速度数值的变化, 进而会影响之后的特征提取和分类识别率;因此, 在保留有用信息的同时, 也需要尽量地去除噪声对数据的干扰。针对步态特征信号主要集中在数据的较低频率部分, 采用3阶巴特沃斯低通滤波器<citation id="170" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>进行滤波去除高频噪声, 图3为滤波前后的步态数据。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 滤波前后数据" src="Detail/GetImg?filename=images/JSJY201903017_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 滤波前后数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Data before and after filtering</p>

                </div>
                <h3 id="57" name="57" class="anchor-tag">2 周期划分与特征提取</h3>
                <h4 class="anchor-tag" id="58" name="58">2.1 <b>周期划分</b></h4>
                <div class="p1">
                    <p id="59">常用的周期划分方法有基于帧分割<citation id="171" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>和基于周期分割两种。基于帧分割, 又被称为基于固定滑动窗口的分割;窗口表示一次被用于处理的数据量, 因此该方法就是按照固定数据长度进行周期划分。该方法能够快速地实现时间序列的分割处理;窗口又被分为重叠的和不重叠窗口, 主要是由窗口大小和滑动步长决定;该方法由于实现简单, 在目前的研究中常被使用, 虽然该方法有很好的实时性以及能够保持步态的模式特征, 但是却不能很好地反映步态的相位以及不能解决步态模式引起的时间变化问题。与基于帧分割不同, 基于周期的分割方法以步态周期为基础, 能够充分体现出步态数据的隐藏生物特征。考虑到步态加速度数据通常表现为一组具有周期性特性的数据, 因此本文采用基于周期的分割方法。具体算法主要分为以下3个步骤:</p>
                </div>
                <div class="p1">
                    <p id="60">步骤1 周期长度估算。据统计正常人平均0.8 s到1.2 s步行两步, 由于在采集数据时只放置了一个手机在右侧的裤口袋中, 因此两步刚好对应数据上的一个周期;再加之采样频率被设置为100 Hz, 因此一个周期对应的数据点大约在80～120个。</p>
                </div>
                <div class="p1">
                    <p id="61">步骤2 周期检测。利用局部极小值<citation id="172" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>对步态数据进行周期检测, 即认为两个相邻极小值之间所包含的数据为单个步态周期。</p>
                </div>
                <div class="p1">
                    <p id="62">步骤3 剔除异常周期。通过上述两个步骤, 可以把步态数据划分成单个步态周期, 但是这些周期并不是全都适合用于特征提取, 需要对这些周期进行筛选, 剔除异常周期。本文在剔除非正常周期时采用DTW计算相似距离, 将那些距离相差较大的周期剔除。</p>
                </div>
                <div class="p1">
                    <p id="63">经过上述步骤所提取不同个体的单个步态周期如图4所示。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">2.2 <b>特征提取</b></h4>
                <div class="p1">
                    <p id="65">特征提取是为了从已获得的单个步态周期中提取可以表征个体身份的特征向量, 是分类识别技术中的关键所在, 特征提取的效果会直接影响分类器的训练以及最终分类识别的准确率。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同个体的步态周期" src="Detail/GetImg?filename=images/JSJY201903017_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同个体的步态周期  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Gait cycles of different individuals</p>

                </div>
                <h4 class="anchor-tag" id="67" name="67">2.2.1 传统步态特征</h4>
                <div class="p1">
                    <p id="68">传统的基于加速度信号特征提取方法有时域分析法<citation id="173" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、频域分析法<citation id="174" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和时频域分析法<citation id="175" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。结合上述方法提取传统特征有平均值、标准差、步频、四分位距、能量、过零数、偏度、峰度、均方根、周期长度、傅里叶系数、步速等。其中可以被用来表示步态数据信号的波形特点和简单的统计特征, 如平均值、标准差、过零数等一系列时域特征;又如步数、步频等一系类特征可以用来表征个体的生物特征;而诸如傅里叶系数等都是频域特征, 通常被用来表示个体步态中的周期性信息。虽然传统特征计算简单, 但是很少有可以表征个体步态运动过程中的特征, 而且利用传统特征所取得的识别率并不高。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2.2 运动特征</h4>
                <div class="p1">
                    <p id="70">针对传统特征不能很好体现步态的生物特征, 本文提出一种新的步态特征提取方法, 用于提取个体的运动特征。众所周知, 加速度传感器采集的步态数据是一个连续的时间序列;从运动的角度, 个体的步行是一个变加速度运动。对于一个变加速度运动可以结合下面两个角度进行刻画:1) 可以将变加速度运动按照加速度数值大小增加和减少进行分割, 将其划分成变加速和变减速两种类别, 再用单位时间内变加速和变减速的加速度变化量描述变加速度运动;2) 对于单个变加速运动区间, 通过计算其相对于匀加速度的速度变化量, 用以刻画改区间运动的相对稳定程度。文献<citation id="176" type="reference">[<a class="sup">16</a>]</citation>通过步行动作的生物力学原理分析得出:足地接触力在每个步态周期转折点出现极值, 足跟着地时有一极大值, 随着足部逐渐放平, 受力面积逐渐增大, 受力减少, 足部完全放平时受力达到最小, 至足跟离地, 足趾蹬地时出现另一极大值, 即在整个步态周期中受力曲线具有典型的对称双峰性质, 那么加速度曲线也应该呈现出双峰性质, 并且研究认为不同年龄人体的足地接触力无显著性差异。因此结合上述分析, 本文对单个步态周期提取周期起点 (<i>start</i>) 、第一个极大值点 (<i>max</i><sub><i>f</i></sub>) 、第一个极小值 (<i>min</i><sub><i>f</i></sub>) 、最后一个极小值 (<i>min</i><sub><i>e</i></sub>) 、最后一个极大值 (<i>max</i><sub><i>e</i></sub>) 、步态周期终点 (<i>end</i>) 6个特征点, 将步态数据分成5个变加速运动的区间, 不同个体的区间划分的结果如图5所示;将两两特征点之间的连线视作为匀加速运动, 因此单位时间内变加速和变减速的加速度变化量就可以被表示为这五条直线的斜率;而单个区间内相对匀加速运动的速度变化量可以用原始变加速度曲线与匀加速直线所围成的面积表示。因此, 本文新添16个特征值, 即6个特征值点、5个斜率以及5个面积。新特征的提取流程如图6所示, 具体步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="71">步骤1 对周期划分出来的单个步态周期提取6个特征点: <b><i>V</i></b>=[<i>start</i>, <i>max</i><sub><i>f</i></sub>, <i>min</i><sub><i>f</i></sub>, <i>min</i><sub><i>e</i></sub>, <i>max</i><sub><i>e</i></sub>, <i>end</i>], 以及6个特征点对应的时间:<b><i>T</i></b>=[<i>t</i><sub>start</sub>, <i>t</i><sub>max<sub><i>f</i></sub></sub>, <i>t</i><sub>min<sub><i>f</i></sub></sub>, <i>t</i><sub>min<sub><i>e</i></sub></sub>, <i>t</i><sub>max<sub><i>e</i></sub></sub>, <i>t</i><sub>end</sub>]。</p>
                </div>
                <div class="p1">
                    <p id="72">步骤2 利用步骤1所提取的6个特征点将单个步态周期划分成5个不同的步态区域。</p>
                </div>
                <div class="p1">
                    <p id="73">步骤3 利用式 (1) 提取第<i>i</i>个步态区域的单位时间内变加速或变减速的加速度变化量<i>CIC</i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="74"><i>CIC</i><sub><i>i</i></sub>= (<i>V</i><sub><i>i</i>+1</sub>-<i>V</i><sub><i>i</i></sub>) / (<i>T</i><sub><i>i</i>+1</sub>-<i>T</i><sub><i>i</i></sub>) ; 0≤<i>i</i>≤4      (1) </p>
                </div>
                <div class="p1">
                    <p id="75">步骤4 提取第<i>i</i>个步态区域内相对匀加速运动的速度变化量<i>RCIV</i><sub><i>i</i></sub>, 其实就是求区域内步态加速度曲线与该区域匀加速直线所围成的面积;由于手机的采样频率为100 Hz, 那么所采集的两两数据点之间的间隔为0.01 s, 因此可以将<i>RCIV</i><sub><i>i</i></sub>近似为区域所有两两步态数据点之间直线段<i>l</i>与该区域匀加速直线<i>L</i>所围成的面积之和。<i>RCIV</i><sub><i>i</i></sub>计算类型分为两类, 一类是<i>L</i>和<i>l</i>的交点在线段之间, 另一类是除此以外的其他情形, 为了方便计算, 令第<i>i</i>个区域<i>Ω</i>内任意直线段起点为<i>Q</i> (<i>v</i><sub><i>a</i></sub>, <i>t</i><sub><i>a</i></sub>) , 终点为<i>G</i> (<i>v</i><sub><i>b</i></sub>, <i>t</i><sub><i>b</i></sub>) , <i>L</i>和<i>l</i>的交点为<i>M</i> (<i>v</i><sub><i>m</i></sub>, <i>h</i>) ;<i>L</i>的方程可以用式 (2) 计算。<i>RCIV</i><sub><i>i</i></sub>可以用式 (3) 计算。式 (3) 中<i>RCIV</i><sub><i>i</i></sub>表示第<i>i</i>个区域<i>Ω</i>的相对匀加速运动的速度变化量, <i>Z</i><sub><i>a</i></sub>=abs (<i>v</i><sub><i>a</i></sub>-<i>y</i><sub><i>i</i></sub> (<i>t</i><sub><i>a</i></sub>) ) , <i>Z</i><sub><i>b</i></sub>=abs (<i>v</i><sub><i>b</i></sub>-<i>y</i><sub><i>i</i></sub> (<i>t</i><sub><i>b</i></sub>) ) , <i>h</i>= (<i>β</i><sub>1</sub>-<i>β</i><sub>2</sub>) / (<i>k</i><sub>1</sub>-<i>k</i><sub>2</sub>) , 其中: <i>β</i><sub>1</sub>=<i>V</i><sub><i>i</i></sub>-<i>CIC</i><sub><i>i</i></sub>×<i>T</i><sub><i>i</i></sub>, <i>β</i><sub>2</sub>=<i>v</i><sub><i>a</i></sub>+ (<i>v</i><sub><i>b</i></sub>-<i>v</i><sub><i>a</i></sub>) / (<i>t</i><sub><i>b</i></sub>-<i>t</i><sub><i>a</i></sub>) , <i>k</i><sub>1</sub>=<i>CIC</i><sub><i>i</i></sub>, <i>k</i><sub>2</sub>= (<i>v</i><sub><i>b</i></sub>-<i>v</i><sub><i>a</i></sub>) / (<i>t</i><sub><i>b</i></sub>-<i>t</i><sub><i>a</i></sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="76"><i>y</i><sub><i>i</i></sub>=<i>CIC</i><sub><i>i</i></sub> (<i>x</i>-<i>T</i><sub><i>i</i></sub>) +<i>V</i><sub><i>i</i></sub>; 0≤<i>i</i>≤4      (2) </p>
                </div>
                <div class="area_img" id="179">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="79" name="79" class="anchor-tag">3 分类器融合算法</h3>
                <div class="p1">
                    <p id="80">单个分类器通常只对个别个体具有较高的识别率, 因此本文为了实现各个分类器之间优势互补, 将多分类器的输出通过融合算法得到最终的识别结果。融合算法在多分类器融合模型中有着至关重要的地位, 它的好坏将直接决定着最终的识别率。传统投票法<citation id="177" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>是最常用的融合算法之一, 其基本的表决规则是每个分类器都具有投票权, 仲裁原则是少数服从多数, 但是由于每个分类器的性能不同, 对于每个人的识别效果也有较大差异, 因此传统的投票法很难结合多个分类器的优势, 达到预期的识别效果。针对传统投票法存在的不足, 本文将投票法的表决原则结合其仲裁原则进行改进, 提出一种多尺度投票法 (Multiple Scale Voting, MSV) 。MSV算法的基本思想是:一个未知样本在多分类器经过投票法不能非常准确对样本类别进行判断时, 结合各个分类器对其输出类别的识别率、F1_score等多个尺度对样本进行分类;MSV算法不仅保留了传统投票法的特点, 而且结合了单一分类器对不同类型样本的识别性能, 使得各分类器优势互补。MSV算法主要分为提取判别因子和构建表决函数两个步骤, 具体流程如图7所示。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同个体的区间划分" src="Detail/GetImg?filename=images/JSJY201903017_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同个体的区间划分  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Interval division of different individuals</p>

                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 新特征提取流程" src="Detail/GetImg?filename=images/JSJY201903017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 新特征提取流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Extraction process of new feature</p>

                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 MSV算法流程" src="Detail/GetImg?filename=images/JSJY201903017_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 MSV算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Flow chart of MSV algorithm</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84">3.1 <b>提取判别因子</b></h4>
                <div class="p1">
                    <p id="85">对于拥有<i>M</i>个分类器<i>C</i><sub><i>m</i></sub> (<i>m</i>=1, 2, …, <i>M</i>) 与<i>N</i>个类别<i>c</i><sub><i>i</i></sub> (<i>i</i>=1, 2, …, <i>N</i>) 的模式识别问题, 传统投票法是通过统计各个分类器输出样本标签的重复次数, 将重复次数最多的类别标签作为最终的分类结果。传统投票法的优势在于算法实现简单, 并且当不同类别标签重复次数相差越大识别的准确率就越高, 但是当样本各个样本标签重复次数极为相近甚至相等时, 传统投票法就失去了对多分类器的融合作用, 也不能给出准确的分类结果, 为此就需要利用判别因子选择不同的判别准则。判别因子的提取分为以下两步。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">1) 根据式 (4) 统计第<i>i</i>个分类器所输出样本标签的次数<i>b</i><sub><i>i</i></sub> (<i>b</i><sub><i>i</i></sub>∈<b><i>B</i></b>) 。</h4>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mn>1</mn><mo>, </mo><mtext> </mtext><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>a</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>Μ</mi><mo>, </mo><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>Μ</mi></mtd></mtr><mtr><mtd><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≠</mo><mi>a</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>Μ</mi><mo>, </mo><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>Μ</mi></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中:<i>a</i><sub><i>i</i></sub>表示第<i>i</i>个分类器输出的样别标签, <i>c</i><sub><i>i</i></sub>的初值为1。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2) 根据式 (5) 提取判别因子<b><i>K</i></b>。</h4>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo stretchy="false">) </mo><mi mathvariant="bold-italic">Κ</mi><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false">[</mo><mn>1</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>0</mn><mo stretchy="false">]</mo><mo>, </mo><mtext> </mtext><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>&gt;</mo><mi>Μ</mi><mo>/</mo><mn>2</mn><mspace width="0.25em" /><mtext>a</mtext><mtext>n</mtext><mtext>d</mtext><mspace width="0.25em" /><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>-</mo><mi>min</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>&gt;</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>0</mn><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mn>1</mn><mo>&lt;</mo><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>≤</mo><mi>Μ</mi><mo>/</mo><mn>2</mn></mtd></mtr><mtr><mtd><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>1</mn><mo>, </mo><mn>0</mn><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>&gt;</mo><mi>Μ</mi><mo>/</mo><mn>2</mn><mspace width="0.25em" /><mtext>a</mtext><mtext>n</mtext><mtext>d</mtext><mspace width="0.25em" /><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>-</mo><mi>min</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">) </mo><mo>≤</mo><mn>1</mn></mtd></mtr></mtable></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">3.2 <b>构建表决函数</b></h4>
                <div class="p1">
                    <p id="92">为了充分融合各个分类器的优点, 结合不同判别因子构建表决函数 (<i>Bel</i><sub><i>i</i></sub>∈<b><i>Bel</i></b>, 0≤<i>i</i>≤3) , 本文一共构建4个不同的表决函数。对于任意的单分类器<i>C</i><sub><i>m</i></sub> (<i>m</i>=1, 2, …, <i>M</i>) 的分类效果都可以用式 (6) 的混淆矩阵 (Confusion Matrix, <b><i>CM</i></b>) 表示:</p>
                </div>
                <div class="area_img" id="180">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="95">其中:<i>n</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>m</mi></msubsup></mrow></math></mathml>表示第<i>m</i>个分类器将第<i>c</i><sub><i>i</i></sub>类的样本分类成第<i>c</i><sub><i>j</i></sub>类的数量。</p>
                </div>
                <div class="p1">
                    <p id="97">基于混淆矩阵对于一个原属于<i>c</i><sub><i>i</i></sub>类的未知样本<i>x</i>, <i>C</i><sub><i>m</i></sub>分类器将其分类成<i>c</i><sub><i>j</i></sub>的概率 (<i>p</i><sub><i>m</i></sub>∈<b><i>P</i></b>) 以及<i>c</i><sub><i>i</i></sub>类的召回率 (<i>R</i><sub><i>m</i></sub>∈<b><i>R</i></b>) 分别可以用式 (7) 、式 (8) 计算:</p>
                </div>
                <div class="area_img" id="181">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="102">根据式 (7) 、式 (8) 可以推导出式 (9) 用于计算<i>C</i><sub><i>m</i></sub>分类器对于<i>c</i><sub><i>i</i></sub>类的F1_Score (<i>F</i><sub><i>m</i></sub>∈<b><i>F</i></b>) 。</p>
                </div>
                <div class="area_img" id="182">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">根据式 (4) 、 (7) 、 (8) 、 (9) 分别构建下述判决权重分配以及表决函数:</p>
                </div>
                <div class="area_img" id="183">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="110">式 (10) 、 (11) 分别是第1个表决权重分配和表决函数;</p>
                </div>
                <div class="area_img" id="184">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="114">式 (12) 、 (13) 分别是第2个表决权重分配和表决函数;</p>
                </div>
                <div class="area_img" id="185">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="117">式 (14) 是融合所有分类器的识别结果而构建的第3个表决函数;</p>
                </div>
                <div class="area_img" id="186">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903017_18600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="121">式 (15) 、 (16) 分别是第4个表决权重分配和表决函数。</p>
                </div>
                <div class="p1">
                    <p id="122">对于一个未知样本<i>x</i>, 先经过多分类器进行分类, 然后将多分类器分类结果经过MSV融合算法得到最终的分类所属<i>label</i>, 并且可以用式 (17) 予以计算:</p>
                </div>
                <div class="p1">
                    <p id="123"><i>label</i>=<b><i>K</i></b><sup>T</sup>·<b><i>Bel</i></b>      (17) </p>
                </div>
                <h3 id="124" name="124" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="125" name="125">4.1 <b>实验准备</b></h4>
                <h4 class="anchor-tag" id="126" name="126">4.1.1 实验数据与环境</h4>
                <div class="p1">
                    <p id="127">本文利用在数据采集中介绍的采集方法, 针对32名年龄在25岁左右的志愿者进行数据采集, 其中男女生各16名, 他们身高均在150～190 cm, 在采集过中志愿者在水平的地面上用他们正常步行模式行走大约100 m的距离;每位志愿者需要被采集30组独立的实验数据, 以避免整体实验数据具有偶然性, 保证数据能够更好地刻画出个体的步态特征。</p>
                </div>
                <div class="p1">
                    <p id="128">实验环境:本文以python 3.6作为软件平台;硬件平台采用Intel Core i7处理器, 主频为2.7 GHz, 内存为8 GB;并且采用64位Windows 10操作系统。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">4.1.2 多分类器选择</h4>
                <div class="p1">
                    <p id="130">基分类器选择是多分类器融合的基础, 为了尽可能选择优秀的分类器用于融合, 本文选择以下10个常用的分类器作为备选项, 如表1所示。</p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表</b>1 <b>备选分类器</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Alternative classifiers</p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td><br />分类器名称</td><td>代号</td></tr><tr><td><br />Multinomial Naive Bayes (多项式朴素贝叶斯) </td><td><i>C</i><sub>1</sub></td></tr><tr><td><br />Bernoulli Naive Bayes (伯努利朴素贝叶斯) </td><td><i>C</i><sub>2</sub></td></tr><tr><td><br />Gaussian Naive Bayes (高斯朴素贝叶斯) </td><td><i>C</i><sub>3</sub></td></tr><tr><td><br /><i>k</i>-Nearest Neighbors (<i>k</i>-近邻) </td><td><i>C</i><sub>4</sub></td></tr><tr><td><br />Ridge Regression (岭回归) </td><td><i>C</i><sub>5</sub></td></tr><tr><td><br />Decision Tree (决策树) </td><td><i>C</i><sub>6</sub></td></tr><tr><td><br />Random Forest (随机森林) </td><td><i>C</i><sub>7</sub></td></tr><tr><td><br />Support Vector Machine (支持向量机) </td><td><i>C</i><sub>8</sub></td></tr><tr><td><br />AdaBoost (自适应增强学习) </td><td><i>C</i><sub>9</sub></td></tr><tr><td><br />Multi-Layer Perceptron (感知器) </td><td><i>C</i><sub>10</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">4.2 <b>实验设计与结果分析</b></h4>
                <div class="p1">
                    <p id="133">为了测试传统特征在本文所采集数据上的表现, 验证本文提出的新特征可分性、新特征与传统特征融合效果以及MSV多分类器融合算法的性能, 主要通过设计以下2个实验予以验证。</p>
                </div>
                <div class="p1">
                    <p id="134">1) 多分类器筛选。</p>
                </div>
                <div class="p1">
                    <p id="135">多分类器筛选的目的很明确就是从10个备选的分类器中选择最为合适的分类器作融合。为了完成多分类器的筛选本文主要通过以下3个小实验予以论证:</p>
                </div>
                <div class="p1">
                    <p id="136">a) 通过传统特征来验证所采集到的数据具有良好的可分性, 并从备选的10个基分类器中选中合适的分类器用于融合。</p>
                </div>
                <div class="p1">
                    <p id="137">b) 通过利用备选的10个基分类器对新特征进行分类, 同样也寻找适合融合的备选分类器, 并与传统特征所选分类器进行对比。</p>
                </div>
                <div class="p1">
                    <p id="138">c) 对比新特征与传统特征对样本的区分能力;并且融合新特征与传统特征进行分类, 同样从备选分类器中进行选择最终合适的分类器, 并与前两者选出的分类器进行比较, 最终确定融合的分类器。</p>
                </div>
                <div class="p1">
                    <p id="139">2) 通过实验对比验证MSV融合算法的可靠性。</p>
                </div>
                <div class="p1">
                    <p id="140">为了更好地训练每一个分类器、对每一个分类器进行更好的评判, 以及获得用于MSV融合算法先验知识, 如:分类器对于单个个体的识别率、召回率等, 本文在所有的分类实验中将实验数据平均分成10等份, 其中6份作为训练集, 在训练时采用十折的方法对分类器进行训练;2份作为测试集, 用于测试分类器以及获取先验知识;2份作为验证集, 主要验证算法的可靠性以及融合算法的融合效果。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141">4.2.1 多分类器筛选</h4>
                <div class="p1">
                    <p id="142">a) 结合2.2.1节所介绍的传统步态特征, 本文对<i>X</i>、<i>Y</i>、<i>Z</i>轴的单个步态周期分别提取下述15个传统特征值用于分类实验, 分别是:均值、标准差、偏度、峰度、均方根、过零率、四分位距、周期长度、能量以及前6位傅里叶系数, 由于这些是常见的时频域以及统计学特征, 其计算公式也相对简单, 在此不再赘述。</p>
                </div>
                <div class="p1">
                    <p id="143">b) 从<i>X</i>、<i>Y</i>、<i>Z</i>轴的单个步态周期分别提取本文所介绍的相对匀加速运动的速度变化量等16个新特征, 采用备选的10个分类器进行分类实验。</p>
                </div>
                <div class="p1">
                    <p id="144">c) 将针对<i>X</i>、<i>Y</i>、<i>Z</i>轴的单个步态周期分别所提取的15个传统特征值和16个新特征值 (一共93个特征, 3×15个传统特征, 3×16个新特征) 进行融合, 首先通过ReliefF算法<citation id="178" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>计算各个特征对样本的区分能力, 来验证新特征是否具有更好的可分性;其次, 同样采用备选的分类器进行分类实验。</p>
                </div>
                <div class="p1">
                    <p id="145">令本文所选取传统特征集为<i>T</i><sub>1</sub>;新特征集为<i>T</i><sub>2</sub>;新特征和传统特征融合特征集为<i>T</i><sub>3</sub>。</p>
                </div>
                <div class="p1">
                    <p id="146">表2、图8分别是10个备选分类器在<i>T</i><sub>1</sub>、<i>T</i><sub>2</sub>、<i>T</i><sub>3</sub>三个特征集上的测试集识别率以及训练一次对应分类器和测试集所需要的时间, 图9为93个不同步态特征所对应的ReliefF值。</p>
                </div>
                <div class="area_img" id="147">
                    <p class="img_tit"><b>表</b>2 <b>测试集识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Recognition rate of test sets </p>
                    <p class="img_note">%</p>
                    <table id="147" border="1"><tr><td>分类器</td><td><i>T</i><sub>1</sub></td><td><i>T</i><sub>2</sub></td><td><i>T</i><sub>3</sub></td><td></td><td>分类器</td><td><i>T</i><sub>1</sub></td><td><i>T</i><sub>2</sub></td><td><i>T</i><sub>3</sub></td></tr><tr><td><i>C</i><sub>1</sub></td><td>64.88</td><td>56.85</td><td>83.72</td><td></td><td><i>C</i><sub>6</sub></td><td>87.83</td><td>74.12</td><td>88.53</td></tr><tr><td><br /><i>C</i><sub>2</sub></td><td>15.23</td><td>14.40</td><td>30.24</td><td></td><td><i>C</i><sub>7</sub></td><td>91.70</td><td>80.32</td><td>93.59</td></tr><tr><td><br /><i>C</i><sub>3</sub></td><td>83.33</td><td>68.32</td><td>92.02</td><td></td><td><i>C</i><sub>8</sub></td><td>86.25</td><td>85.29</td><td>86.86</td></tr><tr><td><br /><i>C</i><sub>4</sub></td><td>88.48</td><td>84.51</td><td>92.93</td><td></td><td><i>C</i><sub>9</sub></td><td>12.25</td><td>8.12</td><td>12.52</td></tr><tr><td><br /><i>C</i><sub>5</sub></td><td>90.40</td><td>89.40</td><td>95.47</td><td></td><td><i>C</i><sub>10</sub></td><td>81.92</td><td>78.18</td><td>85.86</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同特征下的训练和测试时间" src="Detail/GetImg?filename=images/JSJY201903017_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同特征下的训练和测试时间  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Training and testing time under different features</p>

                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903017_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 所有特征对应的ReliefF值" src="Detail/GetImg?filename=images/JSJY201903017_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 所有特征对应的ReliefF值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903017_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 ReliefF value corresponding to all features</p>

                </div>
                <div class="p1">
                    <p id="150">由表2的<i>T</i><sub>1</sub>列可得, 本文采集的步态数据针对传统特征在大部分的备选分类器上都获得不错的识别率, 最高识别率可以达到91.7%, 这从侧面说明个体的步态特征作为生物特征的一种能够很好用于人员识别, 传统步态特征对步态具有一定的可分性, 但是识别率并不是很高。</p>
                </div>
                <div class="p1">
                    <p id="151">由表2的<i>T</i><sub>2</sub>列可得, 本文提取的新特征值对比传统特征值在各个分类器的分类效果上有所欠缺, 但是识别率相差并不算很大, 最小相差的识别为0.83个百分点, 最大相差15.01个百分点;新特征达到的最高识别率为89.40%, 与传统特征的最高识别率相差2.3个百分点, 说明新特征本身就具有较好的可分性, 为下面特征融合奠定理论依据。</p>
                </div>
                <div class="p1">
                    <p id="152">由ReliefF算法可知, 特征对应的ReliefF值越大, 说明该特征对样本具有更大的区分能力;通过图9可得, 在前10的ReliefF值对应的特征中新特征占有6个, 并且这6个新特征值ReliefF值和为0.314, 4个传统特征ReliefF值和为0.174;在前40的ReliefF值对应的特征中新特征占有20个, 并且这20个新特征值ReliefF值和为0.571, 20个传统特征ReliefF值和为0.529;在所有93个特征中新特征ReliefF值和为0.861, 传统特征ReliefF值和为0.737。综合上述分析可以得出:新特征相比传统特征具有更好的分类效果。由表2的<i>T</i><sub>3</sub>列可得, 新特征和传统特征相融合对于所有备选分类器的识别率都有较大幅度提升, 相比传统特征平均提升5.95个百分点的识别率, 最高识别率可以达到95.47%, 说明特征融合是很成功。</p>
                </div>
                <div class="p1">
                    <p id="153">通过表2可以得出, 在10个备选分类器中<i>C</i><sub>3</sub>、<i>C</i><sub>4</sub>、<i>C</i><sub>5</sub>、<i>C</i><sub>6</sub>、<i>C</i><sub>7</sub>、<i>C</i><sub>8</sub>、<i>C</i><sub>10</sub>这7个分类器无论是在传统特征、新特征还是传统特征与新特征融合都取得较好的识别率, 体现出这7个分类器具有很好的稳定性;通过图8可以得出<i>C</i><sub>8</sub>、<i>C</i><sub>10</sub>这两个分类器在训练时需要消耗大量时间, 如果用于分类器融合会大幅度融合分类器的时间消耗;因此综合时间消耗和准确率两方面考虑, 本文选用<i>C</i><sub>3</sub>、<i>C</i><sub>4</sub>、<i>C</i><sub>5</sub>、<i>C</i><sub>6</sub>、<i>C</i><sub>7</sub>作为融合算法的基分类器。</p>
                </div>
                <h4 class="anchor-tag" id="154" name="154">4.2.2 MSV融合算法验证</h4>
                <div class="p1">
                    <p id="155">本文主要通过两个方面来验证MSV融合算法:第一通过对比单一分类器在三种特征集下验证集的识别率和MSV算法融合之后的识别率;第二通过对比MSV融合算法和不同多分类器融合算法的识别率。表3是所选择的5种基分类器在三种特征集下验证集的识别率;表4是不同融合算法识别率的对比实验结果。</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表</b>3 <b>验证集识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Recognition rate of verification sets </p>
                    <p class="img_note">%</p>
                    <table id="156" border="1"><tr><td><br />分类器</td><td>传统特征</td><td>新特征值</td><td>融合特征</td></tr><tr><td><br /><i>C</i><sub>3</sub></td><td>84.50</td><td>70.31</td><td>92.87</td></tr><tr><td><br /><i>C</i><sub>4</sub></td><td>88.62</td><td>85.74</td><td>94.57</td></tr><tr><td><br /><i>C</i><sub>5</sub></td><td>89.80</td><td>89.73</td><td>95.84</td></tr><tr><td><br /><i>C</i><sub>6</sub></td><td>88.29</td><td>73.34</td><td>87.51</td></tr><tr><td><br /><i>C</i><sub>7</sub></td><td>92.02</td><td>82.41</td><td>94.83</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="157">
                    <p class="img_tit"><b>表</b>4 <b>不同融合算法的识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Recognition rate of different fusion algorithms </p>
                    <p class="img_note"> %</p>
                    <table id="157" border="1"><tr><td><br />融合算法</td><td>传统特征</td><td>新特征</td><td>融合特征</td></tr><tr><td><br />传统投票法</td><td>93.52</td><td>88.10</td><td>96.31</td></tr><tr><td><br />贝叶斯投票法<sup>[19]</sup></td><td>89.60</td><td>83.13</td><td>91.76</td></tr><tr><td><br />MSV算法</td><td>93.72</td><td>90.12</td><td>97.78</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="158">通过表3和表2可以得出, 所选的5种基分类器无论在测试集还是验证集都有较好的识别效果, 并且识别率几乎一致, 表现出所选基分类器拥有很好的稳定性。</p>
                </div>
                <div class="p1">
                    <p id="159">通过表3和表4可以得出, 传统投票法和MSV算法在三种上所得到的识别率相差不是很大, MSV算法取得的识别率最小只高出0.2个百分点, 最大高出2.02个百分点;但是传统投票法相比MSV算法缺乏稳定性, 例如, 在新特征集基分类器的最高识别率为89.73%, 而传统投票法融合之后的识别率反而低了1.63个百分点;出现上述现象可以归纳为以下两个原因:其一, 由于基分类器的识别率都比较高, 这样就造成对于一个未知样本大多数基分类器都会大概率输出正确且一致的分类结果, 致使通过传统投票法之后得到较高的识别率, 例如, 在传统特征集有4个基分类器的识别率高于88%, 在融合特征集上4个基分类器识别率高于92%, 所以在这两类特征集上传统投票法都取得较高的识别率, 对比与MSV算法也相差不大;其二, 由于传统投票法是按照少数服从多数的准则进行融合, 这样就会造成如果基分类器的识别率都不是很高, 导致有很多未知样本经过传统投票法融合之后, 所谓的少数和多数相差很小;假设对于部分未知样本, 5个基分类器有2个基分类器输出一致的结果, 而其他3个基分类器输出的结果各不相同, 这样传统投票法只有小几率会预测出正确的样本分类, 从而致使传统投票法融合后识别率不高, 甚至会低于基分类器的识别率, 造成传统投票法具有不稳定性, 例如在新特征集上有4个基分类器的识别率低于86%, 致使经过传统投票法融合后识别率仅为88.10%, 低于<i>C</i><sub>5</sub>分类器的识别率。通过对比其他的多分类器融合算法, 三种特征集在MSV算法融合后识别率都有所提高, 并且在各个特征集上的识别率都要优于其他融合算法;三种特征集在MSV算法融合后识别率相比5种基分类器中最大识别率平均提高1.34个百分点, 最高的识别率是融合特征所达到的97.78%;综合上述分析, 可以得出MSV算法具有优异的多分类器融合性能。</p>
                </div>
                <h3 id="160" name="160" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="161">本文将单个步态周期数据利用极大值和极小值划分成5个运动区域;分别提取运动区域内的相对匀加速度的速度变化量, 以及单位时间内加速度变化量作为两类新特征;将新特征结合传统的时域和频域特征组成新的特征集, 用于训练筛选出来的5个基分类器;再将各个分类器的预测结果经过MSV多分类器融合算法得到最终的预测结果。实验结果表明:新特征利用测试集在5个基分类器上具有不错的识别效果, 最高的准确率达到89.40%, 并且新特征的ReliefF值也要高于传统特征值, 体现新特征具有良好的可分性;新特征和传统特征融合同样在测试集上取得很高识别率, 相对于单一传统特征识别率有较大提升, 最高识别率达到95.47%;经过MSV算法融合后识别率相对于5种基分类器中最大识别率平均提高1.34个百分点, 最高的识别率是融合特征所达到的97.78%;在新特征和传统特征相融合的特征集上, MSV融合算法相比其他多分类器融合算法识别率平均提高3.75个百分点, 体现出MSV算法具有优异的多分类器融合性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A wearable acceleration sensor system for gait recognition">

                                <b>[1]</b> LIU R, ZHOU J, LIU M, et al. A wearable acceleration sensor system for gait recognition [C]// Proceedings of the 2007 2nd IEEE Conference on Industrial Electronics and Applications. Piscataway, NJ: IEEE, 2007: 2654-2659.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accelerometer based gait recognition using adapted Gaussian mixture models">

                                <b>[2]</b> MUAAZ M, MAYRHOFER R. Accelerometer based gait recognition using adapted Gaussian mixture models [C]// Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media. New York: ACM, 2016: 288-291.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 万彩艳. 基于智能手机加速度传感器的步态身份识别[D].常州:常州大学, 2018: 21-35. (WAN C Y. Gait identification based on mobile-phone acceleration sensor [D]. Changzhou: Changzhou University, 2018: 21-35.) 
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gait characteristic analysis and identification based on the i Phone&amp;#39;&amp;#39;s accelerometer and gyrometer">

                                <b>[4]</b> SUN B, WANG Y, BANDA J. Gait characteristic analysis and identification based on the iPhone's accelerometer and gyrometer [J]. Sensors, 2014, 14 (9) : 17037-17054.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014308675.nh&amp;v=MjEwNzZQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzd2TFZGMjZHckM0RnRmTHFwRWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 张丽娜.基于加速度传感器的步态特征身份认证[D].沈阳:沈阳工业大学, 2014: 40-65. (ZHANG L N. Gait feature authentication based on acceleration sensor [D]. Shenyang: Shenyang University of Technology, 2014: 40-65.) 
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An analysis of different approaches to gait recognition using cell phone based accelerometers">

                                <b>[6]</b> MUAAZ M, MAYRHOFER R. An analysis of different approaches to gait recognition using cell phone based accelerometers [C]// Proceedings of the 11th International Conference on Advances in Mobile Computing and Multimedia. New York: ACM, 2013: 293-300.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201612021&amp;v=MjkxNTJGaURsVzd2TEx6N0JkN0c0SDlmTnJZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 王忠民, 王科, 贺炎.高可信度加权的多分类器融合行为识别模型[J].计算机应用, 2016, 36 (12) :3353-3357. (WANG Z M, WANG K, HE Y. Multiple classifier fusion model for activity recognition based on high reliability weighted [J]. Journal of Computer Applications, 2016, 36 (12) :3353-3357.) 
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Ensemble Approach for Activity Recognition with Accelerometer in Mobile-Phone">

                                <b>[8]</b> YUAN Y, WANG C, ZHANG J, et al. An ensemble approach for activity recognition with accelerometer in mobile-phone [C]// Proceedings of the 11th International Conference on Computational Science and Engineering. Washington, DC: IEEE Computer Society, 2014: 1469-1474.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700488288&amp;v=MTg5OTRReG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSktGNGNiaEU9TmlmT2ZiSzhIOURNcUk5RllPTUhEbg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> BAYAT A, POMPLUN M, TRAN D A. A study on human activity recognition using accelerometer data from smartphones [J]. Procedia Computer Science, 2014, 34: 450-457.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient HOS-based gait authentication of accelerometer data">

                                <b>[10]</b> SPRAGER S, JURIC M B. An efficient HOS-based gait authentication of accelerometer data [J]. IEEE Transactions on Information Forensics and Security, 2015, 10 (7) : 1486-1498.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unobtrusive gait verification for mobile phones">

                                <b>[11]</b> LU H, HUANG J, SAHA T, et al. Unobtrusive gait verification for mobile phones [C]// Proceedings of the 2014 ACM International Symposium on Wearable Computers. New York: ACM, 2014: 91-98.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500312620&amp;v=MDY0MDdGWitvTkNuNDVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyakpLRjRjYmhFPU5pZk9mYks5SDlQT3FvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> DERAWI M, BOURS P. Gait and activity recognition using commercial phones[J]. Computers and Security, 2013, 39: 137-144.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Influence of holding smart phone for accelerationbased gait authentication">

                                <b>[13]</b> WATANABE Y. Influence of holding smart phone for acceleration-based gait authentication [C]// Proceedings of the 2014 5th International Conference on Emerging Security Technologies. Washington, DC: IEEE Computer Society, 2014: 30-33.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Secure and privacy enhanced gait authentication on smart phone">

                                <b>[14]</b> HOANG T, CHOI D. Secure and privacy enhanced gait authentication on smart phone [J]. The Scientific World Journal, 2014, 2014: Article ID 438254.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-aware active authentication using smart phone accelerometer measurements">

                                <b>[15]</b> PRIMO A, PHOHA V V, KUMAR R, et al. Context-aware active authentication using smartphone accelerometer measurements [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops. Washington, DC: IEEE Computer Society, 2014: 98-105.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NTXZ200604001&amp;v=Mjg0NDNUZExHNEh0Zk1xNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkxLem4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 钱竞光, 宋雅伟, 叶强, 等.步行动作的生物力学原理及其步态分析[J].南京体育学院学报 (自然科学版) , 2006, 5 (4) :1-7. (QIAN J G, SONG Y W, YE Q, et al. The biomechanics principle of walking and analysis on gaits[J]. Journal of Nanjing Institute of Physical Education (Natural Science) , 2006, 5 (4) :1-7.) 
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017079279.nh&amp;v=MDE4NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzd2TFZGMjZHYk8vRjlQTHBwRWJQSVE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 王科.多分类器融合算法在行为识别中的应用研究[D].西安:西安邮电大学, 2017: 40-61. (WANG K. Application and research of multiple classifier fusion algorithm in activity recognition [D]. Xi'an: Xi'an University of Posts and Telecommunications, 2017: 40-61.) 
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201210054&amp;v=MDIyMTh2TEx6N0JkN0c0SDlQTnI0OUFZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 黄莉莉, 汤进, 孙登第, 等.基于多标签ReliefF的特征选择算法[J].计算机应用, 2012, 32 (10) :2888-2890. (HUANG L L, TANG J, SUN D D, et al. Feature selection algorithm based on multi-label ReliefF [J]. Journal of Computer Applications, 2012, 32 (10) :2888-2890.) 
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion&amp;quot;">

                                <b>[19]</b> QU J, ZHANG Z, GONG T. A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion [J]. Neurocomputing, 2016, 171 (C) : 837-853.This work is partially supported by the National Natural Science Foundation of China (61772248) .HUAN Zhan, born in 1969, M. S., associate professor. His research interests include Internet of things, intelligent control.CHEN Xuejie, born in 1994, M. S. candidate. His research interests include Internet of things, intelligent control.LYU Shiyun, born in 1994, M. S. candidate. Her research interests include Internet of things, intelligent control.GENG Hongyang, born in 1995, M. S. candidate. His research interests include Internet of things, intelligent control.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903017" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903017&amp;v=MDYyMzh2TEx6N0JkN0c0SDlqTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
