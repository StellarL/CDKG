<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136778013096250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904028%26RESULT%3d1%26SIGN%3d4Nmhi2KqIU4BRLDJIhykXHUFBc8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904028&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904028&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904028&amp;v=MjgyODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGdXN3ZQTHo3QmQ3RzRIOWpNcTQ5SGJJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#53" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="1 Heron作业模型 ">1 Heron作业模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="2 问题建模与分析 ">2 问题建模与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="2.1 &lt;b&gt;资源约束模型&lt;/b&gt;">2.1 <b>资源约束模型</b></a></li>
                                                <li><a href="#99" data-title="2.2 &lt;b&gt;最优通信开销模型&lt;/b&gt;">2.2 <b>最优通信开销模型</b></a></li>
                                                <li><a href="#110" data-title="2.3 &lt;b&gt;流分类模型&lt;/b&gt;">2.3 <b>流分类模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#139" data-title="3 流分类调度策略 ">3 流分类调度策略</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#141" data-title="3.1 &lt;b&gt;流分类算法&lt;/b&gt;">3.1 <b>流分类算法</b></a></li>
                                                <li><a href="#158" data-title="3.2 &lt;b&gt;流簇分配算法&lt;/b&gt;">3.2 <b>流簇分配算法</b></a></li>
                                                <li><a href="#169" data-title="3.3 &lt;b&gt;流分类任务调度算法&lt;/b&gt;">3.3 <b>流分类任务调度算法</b></a></li>
                                                <li><a href="#190" data-title="3.4 &lt;b&gt;算法部署与实现&lt;/b&gt;">3.4 <b>算法部署与实现</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#202" data-title="4 实验 ">4 实验</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#203" data-title="4.1 &lt;b&gt;实验环境&lt;/b&gt;">4.1 <b>实验环境</b></a></li>
                                                <li><a href="#215" data-title="4.2 &lt;b&gt;实验结果分析&lt;/b&gt;">4.2 <b>实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#239" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="图1 拓扑逻辑模型">图1 拓扑逻辑模型</a></li>
                                                <li><a href="#72" data-title="图2 拓扑实例模型">图2 拓扑实例模型</a></li>
                                                <li><a href="#76" data-title="图3 Heron实例分配模型">图3 Heron实例分配模型</a></li>
                                                <li><a href="#201" data-title="图4 改进的Heron系统结构">图4 改进的Heron系统结构</a></li>
                                                <li><a href="#205" data-title="&lt;b&gt;表&lt;/b&gt;1 Heron&lt;b&gt;集群软硬件配置&lt;/b&gt;"><b>表</b>1 Heron<b>集群软硬件配置</b></a></li>
                                                <li><a href="#208" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;测试拓扑运行参数配置&lt;/b&gt;"><b>表</b>2 <b>测试拓扑运行参数配置</b></a></li>
                                                <li><a href="#211" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;参数&lt;/b&gt;pending&lt;b&gt;与&lt;/b&gt;timeout&lt;b&gt;对拓扑元组失败率的影响&lt;/b&gt;"><b>表</b>3 <b>参数</b>pending<b>与</b>timeout<b>对拓扑元组失败率的影响</b></a></li>
                                                <li><a href="#213" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;流分类调度算法参数配置&lt;/b&gt;"><b>表</b>4 <b>流分类调度算法参数配置</b></a></li>
                                                <li><a href="#229" data-title="图5 两种调度策略下系统完成时延对比">图5 两种调度策略下系统完成时延对比</a></li>
                                                <li><a href="#230" data-title="图6 两种调度策略下拓扑节点间通信开销对比">图6 两种调度策略下拓扑节点间通信开销对比</a></li>
                                                <li><a href="#233" data-title="图7 两种调度策略下FileWordCount拓扑工作节点资源利用率对比">图7 两种调度策略下FileWordCount拓扑工作节点资源利用率对比</a></li>
                                                <li><a href="#237" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;两种调度策略下测试拓扑的系统吞吐量对比&lt;/b&gt;"><b>表</b>5 <b>两种调度策略下测试拓扑的系统吞吐量对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="273">


                                    <a id="bibliography_1" title="孙大为.大数据流式计算:应用特征和技术挑战[J].大数据, 2015, 1 (3) :99-105. (SUN D W.Big data stream computing:features and challenges[J].Big Data Research, 2015, 1 (3) :99-105.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSJU201503008&amp;v=MDUyMjk5VE1ySTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEZ1c3dk9JVDdCZTdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        孙大为.大数据流式计算:应用特征和技术挑战[J].大数据, 2015, 1 (3) :99-105. (SUN D W.Big data stream computing:features and challenges[J].Big Data Research, 2015, 1 (3) :99-105.) 
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_2" title="Seagate.Data age 2025[EB/OL].[2018-08-10].https://www.seagate.com/files/www-content/our-story/trends/files/data-age-2025-white-paper-simplified-chinese.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Data age 2025">
                                        <b>[2]</b>
                                        Seagate.Data age 2025[EB/OL].[2018-08-10].https://www.seagate.com/files/www-content/our-story/trends/files/data-age-2025-white-paper-simplified-chinese.pdf.
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_3" title="孙大为, 张广艳, 郑纬民.大数据流式计算:关键技术及系统实例[J].软件学报, 2014, 25 (4) :839-862. (SUN D W, ZHANGG Y, ZHENG W M.Big data stream computing:technologies and instances[J].Journal of Software, 2014, 25 (4) :839-862.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201404011&amp;v=MjQ5NzJxNDlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEZ1c3dk9OeWZUYkxHNEg5WE0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        孙大为, 张广艳, 郑纬民.大数据流式计算:关键技术及系统实例[J].软件学报, 2014, 25 (4) :839-862. (SUN D W, ZHANGG Y, ZHENG W M.Big data stream computing:technologies and instances[J].Journal of Software, 2014, 25 (4) :839-862.) 
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_4" title="TOSHNIWAL A, TANEJA S, SHUKLA A, et al.Storm@Twitter[C]//Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data.New York:ACM, 2014:147-156." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Storm@twitter">
                                        <b>[4]</b>
                                        TOSHNIWAL A, TANEJA S, SHUKLA A, et al.Storm@Twitter[C]//Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data.New York:ACM, 2014:147-156.
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_5" title="CARBONE P, EWEN S, HARIDI S, et al.Apache Flink&lt;sup&gt;TM&lt;/sup&gt;:stream and batch processing in a single engine[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 36 (4) :28-38." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apache flink:Stream and batch processing in a single engine">
                                        <b>[5]</b>
                                        CARBONE P, EWEN S, HARIDI S, et al.Apache Flink&lt;sup&gt;TM&lt;/sup&gt;:stream and batch processing in a single engine[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 36 (4) :28-38.
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_6" title="ANIELLO L, BALDONI R, QUERZONI L.Adaptive online scheduling in Storm[C]//Proceedings of the 7th ACM International Conference on Distributed Event-Based Systems.New York:ACM, 2013:207-218." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive online scheduling in storm">
                                        <b>[6]</b>
                                        ANIELLO L, BALDONI R, QUERZONI L.Adaptive online scheduling in Storm[C]//Proceedings of the 7th ACM International Conference on Distributed Event-Based Systems.New York:ACM, 2013:207-218.
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_7" title="XU J L, CHEN Z H, TANG J, et al.T-Storm:traffic-aware online scheduling in Storm[C]//Proceedings of the 34th IEEE International Conference on Distributed Computing Systems.Piscataway, NJ:IEEE, 2014:535-544." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=T-Storm:Traffic-Aware Online Scheduling in Storm">
                                        <b>[7]</b>
                                        XU J L, CHEN Z H, TANG J, et al.T-Storm:traffic-aware online scheduling in Storm[C]//Proceedings of the 34th IEEE International Conference on Distributed Computing Systems.Piscataway, NJ:IEEE, 2014:535-544.
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_8" title="PENG B Y, HOSSEINI M, HONG Z H, et al.R-Storm:resourceaware scheduling in Storm[C]//Proceedings of the 16th Annual Middleware Conference.New York:ACM, 2015:149-161." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=R-Storm:resource-aware scheduling in Storm">
                                        <b>[8]</b>
                                        PENG B Y, HOSSEINI M, HONG Z H, et al.R-Storm:resourceaware scheduling in Storm[C]//Proceedings of the 16th Annual Middleware Conference.New York:ACM, 2015:149-161.
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_9" title="鲁亮, 于炯, 卞琛, 等.大数据流式计算框架Storm的任务迁移策略[J].计算机研究与发展, 2018, 55 (1) :71-92. (LU L, YU J, BIAN C, et al.A task migration strategy in big data stream computing with Storm[J].Journal of Computer Research and Development, 2018, 55 (1) :71-92.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801005&amp;v=MTA2NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEZ1c3dk9MeXZTZExHNEg5bk1ybzlGWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        鲁亮, 于炯, 卞琛, 等.大数据流式计算框架Storm的任务迁移策略[J].计算机研究与发展, 2018, 55 (1) :71-92. (LU L, YU J, BIAN C, et al.A task migration strategy in big data stream computing with Storm[J].Journal of Computer Research and Development, 2018, 55 (1) :71-92.) 
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_10" title="李梓杨, 于炯, 卞琛, 等.基于流网络的流式计算动态任务调度策略[J].计算机应用, 2018, 38 (9) :2560-2567. (LI Z Y, YU J, BIAN C, et al.Dynamic task dispatching strategy for stream processing based on flow network[J].Journal of Computer Applications, 2018, 38 (9) :2560-2567.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201809021&amp;v=MTYwNDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEZ1c3dk9MejdCZDdHNEg5bk1wbzlIWllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        李梓杨, 于炯, 卞琛, 等.基于流网络的流式计算动态任务调度策略[J].计算机应用, 2018, 38 (9) :2560-2567. (LI Z Y, YU J, BIAN C, et al.Dynamic task dispatching strategy for stream processing based on flow network[J].Journal of Computer Applications, 2018, 38 (9) :2560-2567.) 
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_11" title="de ASSUNCAO M D, da SILVA VEITH A, BUYYA R.Distributed data stream processing and edge computing:a survey on resource elasticity and future directions[J].Journal of Network&amp;amp;Computer Applications, 2018, 103:1-17." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3D7110A41C2D882EABC09C4CF2C32182&amp;v=MDEzOTMvNUJaWmdOZUhReHpXTmltRXg5UVF6bTMyUTNDckdXUkxLZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHpMMjN4SzQ9TmlmT2ZiRE1HZEROcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        de ASSUNCAO M D, da SILVA VEITH A, BUYYA R.Distributed data stream processing and edge computing:a survey on resource elasticity and future directions[J].Journal of Network&amp;amp;Computer Applications, 2018, 103:1-17.
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_12" title="SHUKLA A, SIMMHAN Y.Model-driven scheduling for distributed stream processing systems[J].Journal of Parallel&amp;amp;Distributed Computing, 2018, 117:98-114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0407B1978491A0282F84BD1AF94D7991&amp;v=MzAyMDc1T2d2ajNXUThmY2FUVExPZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHpMMjN4SzQ9TmlmT2ZiTzhIdGErcm9aQ2JPOEdEUTA1elI0Um5EZA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        SHUKLA A, SIMMHAN Y.Model-driven scheduling for distributed stream processing systems[J].Journal of Parallel&amp;amp;Distributed Computing, 2018, 117:98-114.
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_13" title="TRUONG T M, HARWOOD A, SINNOTT R O.Predicting the stability of large-scale distributed stream processing systems on the cloud[C]//Proceedings of the 7th International Conference on Cloud Computing and Services Science.Piscataway, NJ:IEEE, 2017:603-610." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting the stability of large-scale distributed stream processing systems on the cloud">
                                        <b>[13]</b>
                                        TRUONG T M, HARWOOD A, SINNOTT R O.Predicting the stability of large-scale distributed stream processing systems on the cloud[C]//Proceedings of the 7th International Conference on Cloud Computing and Services Science.Piscataway, NJ:IEEE, 2017:603-610.
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_14" title="SUN D, HUANG R.A stable online scheduling strategy for realtime stream computing over fluctuating big data streams[J].IEEEAccess, 2016, 4:8593-8607." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A stable online scheduling strategy for real-time stream computing over fluctuating big data streams">
                                        <b>[14]</b>
                                        SUN D, HUANG R.A stable online scheduling strategy for realtime stream computing over fluctuating big data streams[J].IEEEAccess, 2016, 4:8593-8607.
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_15" title="KULKARNI S, BHAGAT N, FU M, et al.Twitter Heron:stream processing at scale[C]//Proceedings of the 2015 ACM SIGMODInternational Conference on Management of Data.New York:ACM, 2015:239-250." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Twitter heron:Stream processing at scale">
                                        <b>[15]</b>
                                        KULKARNI S, BHAGAT N, FU M, et al.Twitter Heron:stream processing at scale[C]//Proceedings of the 2015 ACM SIGMODInternational Conference on Management of Data.New York:ACM, 2015:239-250.
                                    </a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_16" title="FU M, MITTAL S, KEDIGEHALLI V, et al.Streaming@Twitter[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 38 (4) :15-27." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Streaming@Twitter">
                                        <b>[16]</b>
                                        FU M, MITTAL S, KEDIGEHALLI V, et al.Streaming@Twitter[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 38 (4) :15-27.
                                    </a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_17" title="FU M, AGRAWAL A, FLORATOU A, et al.Twitter Heron:towards extensible streaming engines[C]//Proceedings of the2017 IEEE 33rd International Conference on Data Engineering.Piscataway, NJ:IEEE, 2017:35-44." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Twitter Heron:towards extensible streaming engines">
                                        <b>[17]</b>
                                        FU M, AGRAWAL A, FLORATOU A, et al.Twitter Heron:towards extensible streaming engines[C]//Proceedings of the2017 IEEE 33rd International Conference on Data Engineering.Piscataway, NJ:IEEE, 2017:35-44.
                                    </a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_18" title="Apache.Apache Aurora[EB/OL].[2018-08-10].http://aurora.apache.org." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apache Aurora">
                                        <b>[18]</b>
                                        Apache.Apache Aurora[EB/OL].[2018-08-10].http://aurora.apache.org.
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_19" title="HINDMAN B, KONWINSKI A, ZAHARIA M, et al.Mesos:a platform for fine-grained resource sharing in the data center[C]//Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation.Berkeley:USENIX Association, 2010:429-483." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mesos:A Platform for Fine-Grained Resource Sharing in the Data Center">
                                        <b>[19]</b>
                                        HINDMAN B, KONWINSKI A, ZAHARIA M, et al.Mesos:a platform for fine-grained resource sharing in the data center[C]//Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation.Berkeley:USENIX Association, 2010:429-483.
                                    </a>
                                </li>
                                <li id="311">


                                    <a id="bibliography_20" title="VAVILAPALLI V K, MURTHY A C, AGARWAL S, et al.Apache Hadoop YARN:yet another resource negotiator[C]//Proceedings of the 4th Annual Symposium on Cloud Computing.New York:ACM, 2013:5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apache Hadoop YARN:yet another resource negotiator">
                                        <b>[20]</b>
                                        VAVILAPALLI V K, MURTHY A C, AGARWAL S, et al.Apache Hadoop YARN:yet another resource negotiator[C]//Proceedings of the 4th Annual Symposium on Cloud Computing.New York:ACM, 2013:5.
                                    </a>
                                </li>
                                <li id="313">


                                    <a id="bibliography_21" title="KREPS J, NARKHEDE N, RAO J.Kafka:a distributed messaging system for log processing[EB/OL].[2018-05-10].http://pages.cs.wisc.edu/~akella/CS744/F17/838-Cloud Papers/Kafka.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kafka:a distributed messaging system for log processing">
                                        <b>[21]</b>
                                        KREPS J, NARKHEDE N, RAO J.Kafka:a distributed messaging system for log processing[EB/OL].[2018-05-10].http://pages.cs.wisc.edu/~akella/CS744/F17/838-Cloud Papers/Kafka.pdf.
                                    </a>
                                </li>
                                <li id="315">


                                    <a id="bibliography_22" title="Apache.Apache Distributed Log[EB/OL].[2018-05-10].http://bookkeeper.apache.org/distributedlog/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apache Distributed Log">
                                        <b>[22]</b>
                                        Apache.Apache Distributed Log[EB/OL].[2018-05-10].http://bookkeeper.apache.org/distributedlog/.
                                    </a>
                                </li>
                                <li id="317">


                                    <a id="bibliography_23" title="Twitter.Implementing a custom scheduler[EB/OL].[2018-05-10].https://apache.github.io/incubator-heron/docs/contributors/custom-scheduler/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Implementing a custom scheduler">
                                        <b>[23]</b>
                                        Twitter.Implementing a custom scheduler[EB/OL].[2018-05-10].https://apache.github.io/incubator-heron/docs/contributors/custom-scheduler/.
                                    </a>
                                </li>
                                <li id="319">


                                    <a id="bibliography_24" title="KULKARNI S.Apache/incubator-heron[EB/OL].[2018-05-16].https://github.com/apache/incubator-heron." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apache/incubator-heron">
                                        <b>[24]</b>
                                        KULKARNI S.Apache/incubator-heron[EB/OL].[2018-05-16].https://github.com/apache/incubator-heron.
                                    </a>
                                </li>
                                <li id="321">


                                    <a id="bibliography_25" title="KAMBURUGAMUVE S, RAMASAMY K, SWANY M, et al.Low latency stream processing:Apache Heron with Infiniband&amp;amp;Intel Omni-Path[C]//Proceedings of the 10th International Conference on Utility and Cloud Computing.New York:ACM, 2017:101-110." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low latency stream processing:Apache Heron with Infiniband&amp;amp;Intel Omni-Path">
                                        <b>[25]</b>
                                        KAMBURUGAMUVE S, RAMASAMY K, SWANY M, et al.Low latency stream processing:Apache Heron with Infiniband&amp;amp;Intel Omni-Path[C]//Proceedings of the 10th International Conference on Utility and Cloud Computing.New York:ACM, 2017:101-110.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-27 16:48</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1106-1116 DOI:10.11772/j.issn.1001-9081.2018081848            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>大数据流式计算框架Heron环境下的流分类任务调度策略</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%AF%91%E5%A4%A9&amp;code=35903194&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张译天</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E7%82%AF&amp;code=10240278&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于炯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%B2%81%E4%BA%AE&amp;code=40313040&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁亮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%A2%93%E6%9D%A8&amp;code=37910848&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李梓杨</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E7%96%86%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0181515&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新疆大学软件学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E7%96%86%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0029470&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新疆大学信息科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E6%B0%91%E8%88%AA%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国民航大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>新型大数据流式计算框架Apache Heron默认使用轮询调度算法进行任务调度, 忽略了拓扑运行时状态以及任务实例间不同通信方式对系统性能的影响。针对这个问题, 提出Heron环境下流分类任务调度策略 (DSC-Heron) , 包括流分类算法、流簇分配算法和流分类调度算法。首先通过建立Heron作业模型明确任务实例间不同通信方式的通信开销差异;其次基于流分类模型, 根据任务实例间实时数据流大小对数据流进行分类;最后将相互关联的高频数据流整体作为基本调度单元构建任务分配计划, 在满足资源约束条件的同时尽可能多地将节点间通信转化为节点内通信以最小化系统通信开销。在包含9个节点的Heron集群环境下分别运行SentenceWordCount、WordCount和FileWordCount拓扑, 结果表明DSC-Heron相对于Heron默认调度策略, 在系统完成时延、节点间通信开销和系统吞吐量上分别平均优化了8.35%、7.07%和6.83%;在负载均衡性方面, 工作节点的CPU占用率和内存占用率标准差分别平均下降了41.44%和41.23%。实验结果表明, DSC-Heron对测试拓扑的运行性能有一定的优化作用, 其中对接近真实应用场景的FileWordCount拓扑优化效果最为显著。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流式计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Apache%20Heron&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Apache Heron;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">任务调度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据流分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%80%9A%E4%BF%A1%E5%BC%80%E9%94%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">通信开销;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张译天 (1995—) , 男, 河南商丘人, 硕士研究生, CCF会员, 主要研究方向:云计算、实时计算、分布式计算;;
                                </span>
                                <span>
                                    *于炯 (1964—) , 男, 北京人, 教授, 博士生导师, 博士, CCF会员, 主要研究方向:网格计算、分布式计算;电子邮箱yujiong@xju.edu.cn;
                                </span>
                                <span>
                                    鲁亮 (1990—) , 男, 湖南湘潭人, 讲师, 博士, CCF会员, 主要研究方向:云计算、分布式计算、内存计算;;
                                </span>
                                <span>
                                    李梓杨 (1993—) , 男, 新疆乌鲁木齐人, 博士研究生, CCF会员, 主要研究方向:云计算、分布式计算。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61462079, 61562078, 61562086);</span>
                                <span>国家科技支撑计划项目 (2015BAH02F01);</span>
                                <span>新疆维吾尔自治区自然科学基金资助项目 (2017D01A20);</span>
                                <span>新疆维吾尔自治区高校科研计划项目 (XJEDU2016S106);</span>
                    </p>
            </div>
                    <h1><b>Task scheduling strategy based on data stream classification in Heron</b></h1>
                    <h2>
                    <span>ZHANG Yitian</span>
                    <span>YU Jiong</span>
                    <span>LU Liang</span>
                    <span>LI Ziyang</span>
            </h2>
                    <h2>
                    <span>Software College, Xinjiang University</span>
                    <span>College of Information Science and Engineering, Xinjiang University</span>
                    <span>School of Computer Science and Technology, Civil Aviation University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In a new platform for big data stream processing called Heron, the round-robin scheduling algorithm is usually used for task scheduling by default, which does not consider the topology runtime state and the impact of different communication modes among task instances on Heron's performance. To solve this problem, a task scheduling strategy based on Data Stream Classification in Heron (DSC-Heron) was proposed, including data stream classification algorithm, data stream cluster allocation algorithm and data stream classification scheduling algorithm. Firstly, the instance allocation model of Heron was established to clarify the difference in communication overhead among different communication modes of the task instances. Secondly, the data stream was classified according to the real-time data stream size between task instances based on the data stream classification model of Heron. Finally, the packing plan of Heron was constructed by using the interrelated high-frequency data streams as the basic scheduling unit to complete the scheduling to minimize the communication cost by transforming inter-node data streams into intra-node ones as many as possible. After running SentenceWordCount, WordCount and FileWordCount topologies in a Heron cluster environment with 9 nodes, the results show that compared with the Heron default scheduling strategy, DSC-Heron has 8.35%, 7.07% and 6.83% improvements in system complete latency, inter-node communication overhead and system throughput respectively; in the load balancing aspect, the standard deviations of CPU usage and memory usage of the working nodes are decreased by 41.44% and 41.23% respectively. All experimental results show that DSC-Heron can effectively improve the performance of the topologies, and has the most significant optimization effect on FileWordCount topology which is close to the real application scenario.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=big%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">big data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=stream%20computing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">stream computing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Apache%20Heron&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Apache Heron;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=task%20scheduling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">task scheduling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20stream%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data stream classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=communication%20overhead&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">communication overhead;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Yitian, born in 1995, M. S. candidate. His research interests include cloud computing, real-time computing, distributed computing.;
                                </span>
                                <span>
                                    YU Jiong, born in 1964, Ph. D. , professor. His research interests include grid computing, distributed computing.;
                                </span>
                                <span>
                                    LU Liang, born in 1990, Ph. D. , lecturer. His research interests include cloud computing, distributed computing, in-memory computing.;
                                </span>
                                <span>
                                    LI Ziyang, born in 1993, Ph. D. candidate. His research interests include cloud computing, distributed computing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61462079, 61562078, 61562086);</span>
                                <span>the National Key Technology R&amp;D Program of China (2015BAH02F01);</span>
                                <span>the Natural Science Foundation of Xinjiang Uygur Autonomous Region of China (2017D01A20);</span>
                                <span>the Educational Research Program of Xinjiang Uygur Autonomous Region of China (XJEDU2016S106);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="53" name="53" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="54">随着云计算、物联网、移动互联、社交媒体和人工智能等新型信息技术和应用模式的不断发展, 数据正以前所未有的方式推动人类社会进入大数据时代<citation id="323" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。国际数据公司 (International Data Corporation, IDC) 发布的白皮书《数据时代2025》中显示, 预计到2025年全球互联网数据总量达162 ZB, 其中超过1/4的数据为实时数据, 而物联网实时数据将占这部分数据的95%以上<citation id="324" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。面对实时大数据具有的实时性、易失性、突发性、无序性和无限性的新特征<citation id="325" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 传统的MapReduce等批处理方式不再适用, 分布式大数据流式计算应运而生。流数据处理摒弃了传统批处理中对数据先存储后计算的方式, 将数据以数据流的形式在数据产生初期进行计算, 使用可靠传输模式而不对计算中间结果进行存储, 在对数据分析实时性要求较高的场景中得到了广泛的应用, 并不断融入实时图像识别、智慧城市等人工智能的发展中。</p>
                </div>
                <div class="p1">
                    <p id="55">目前, 在典型的流数据处理系统 (例如, Storm<citation id="326" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、Flink<citation id="327" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>) 中, 默认调度算法常采用静态轮询调度算法。该算法实现简单, 在拓扑提交时对拓扑进行任务分配, 拓扑运行期间任务分配状态不再发生改变;但静态轮询调度算法在进行任务分配时, 仅考虑资源的可满足性将任务均匀分配到各个工作节点, 未考虑拓扑中任务间的关联关系和节点间的通信开销, 会对集群性能产生一定影响。针对这一问题, 国内外研究人员针对不同流式计算平台提出在线调度算法, 在拓扑运行过程中通过实时监测集群运行状态, 对已分配的任务进行重调度或调整, 以使集群具有更高效的性能。针对Storm环境, 文献<citation id="328" type="reference">[<a class="sup">6</a>]</citation>提出自适应调度策略, 分为离线调度和在线调度。其中在线调度通过实时监测拓扑运行过程中CPU负载和工作节点间数据流流量等数据, 依次将通信开销较大的一对任务调度到CPU负载较小的工作节点中。该策略可以较好地降低Storm的通信开销, 但实验中使用的是自定义链式拓扑, 缺乏一定的代表性。文献<citation id="329" type="reference">[<a class="sup">7</a>]</citation>提出流量感知在线调度策略T-Storm, 旨在最小化进程间和工作节点间通信开销, 同时实现了细粒度的任务分配控制, 可以通过调整预设参数控制工作节点数量。但该策略忽略了直接通信的一对任务之间的数据流情况且调度执行开销较大。文献<citation id="330" type="reference">[<a class="sup">8</a>]</citation>提出资源感知调度策略R-Storm, 通过将CPU、内存和网络带宽资源映射为三维空间向量, 使用最小化向量距离的方法寻找任务和工作节点的分配关系, 从而最大化资源利用并提高系统吞吐量。该策略充分考虑了集群资源的有效利用, 但拓扑中各任务的资源需求由编程人员设定而非实时监测获得, 很难应用于资源需求变化较大的在线调度。文献<citation id="331" type="reference">[<a class="sup">9</a>]</citation>提出一种异构环境下的任务迁移策略TMSH-Storm, 将超出阈值节点中的阻尼线程细粒度地迁移至满足条件的目标节点, 避免了资源溢出后的任务重部署, 可以较好地降低调度时延和节点间通信开销。针对Flink环境, 文献<citation id="332" type="reference">[<a class="sup">10</a>]</citation>提出流网络的流式计算动态任务调度策略。该策略通过建立流网络模型, 基于最大流算法使模型在满足延迟约束前提下提高集群的实际吞吐量, 能在一定程度上解决输入速率增加阶段出现的计算延迟升高问题。但该策略仅关注集群输入速率急剧上升阶段的性能优化, 且没有考虑流网络容量动态变化的问题。针对其他流式计算系统, 文献<citation id="333" type="reference">[<a class="sup">11</a>]</citation>从资源分配的角度出发, 对多代分布式流处理系统的弹性资源调度机制进行对比并提出未来研究方向。文献<citation id="334" type="reference">[<a class="sup">12</a>]</citation>基于拓扑任务与集群资源的分配与映射关系提出模型驱动的调度策略, 为流处理系统提供高效的资源利用率和吞吐量。文献<citation id="335" type="reference">[<a class="sup">13</a>,<a class="sup">14</a>]</citation>侧重于流处理系统的稳定性, 分别提出一种基于队列的稳定性预测模型和一种稳定的在线调度策略以优化系统性能。</p>
                </div>
                <div class="p1">
                    <p id="56">Heron<citation id="341" type="reference"><link href="301" rel="bibliography" /><link href="303" rel="bibliography" /><link href="305" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>是Twitter为解决其上一代分布式流处理平台Storm在可扩展性、可调试性、可管理性以及集群资源共享等方面问题, 而构建的新一代分布式流处理平台<citation id="336" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。Heron在2015年已经取代Storm, 成为Twitter实际使用的实时数据处理系统<citation id="337" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 现已进入Apache开源项目孵化器。Heron在设计层面对Storm进行多方面优化的同时, 其默认调度策略仍使用轮询 (Round Robin, RR) 算法进行任务实例分配。该算法根据拓扑中任务实例资源需求和容器资源需求, 创建用于调度的任务分配计划, 然后交由Heron调度器 (Aurora<citation id="338" type="reference"><link href="307" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、Mesos<citation id="339" type="reference"><link href="309" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、YARN<citation id="340" type="reference"><link href="311" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>等) 分配至工作节点。对于Twitter目前使用的Aurora调度器, Heron将一个拓扑对应于Aurora中一个工作 (Job) , 一个容器与其中分配的任务实例作为Aurora的一个资源分配单元, 由Aurora负责将这些单元分配至集群中满足资源需求的工作节点中运行。在配置了Aurora调度器的Heron集群中, 工作节点资源分配由Mesos负责进行, 其采用DRF (Dominant Resource Fairness) 资源分配策略为Aurora框架中提交的任务寻找集群中注册的合适工作节点进行任务分配。在Heron调度策略和任务分配过程中仍存在如下问题:1) 任务分配没有考虑任务实例间通信开销, 忽略了节点间通信和节点内通信的差异;2) 任务分配仅考虑了任务实例和工作节点资源的约束关系, 且算法采用资源最大化对齐的方式容易造成资源浪费;3) 仅提供了静态调度策略, 无法针对运行状态下的拓扑进行实时调度。</p>
                </div>
                <div class="p1">
                    <p id="57">针对Heron默认调度策略中存在的上述问题, 本文提出流分类调度策略 (task scheduling strategy based on Data Stream Classification in Heron, DSC-Heron) , 主要工作如下:</p>
                </div>
                <div class="p1">
                    <p id="58">1) 提出Heron作业模型, 将拓扑中任务实例通信方式划分为节点间、容器间和实例间通信, 明确不同通信方式间的通信开销差异。</p>
                </div>
                <div class="p1">
                    <p id="59">2) 以Heron作业模型为基础, 提出资源约束模型、最优通信开销模型和流分类模型, 作为提出DSC-Heron任务调度策略的理论依据。</p>
                </div>
                <div class="p1">
                    <p id="60">3) 提出流分类调度策略, 包括流分类算法、流簇分配算法和流分类调度算法。该策略首先根据数据流实时大小对数据流进行分类, 然后以高频数据流关联的高频流簇为单位进行任务调度, 使得拓扑的任务分配在满足资源约束条件的同时最小化节点间通信开销。</p>
                </div>
                <div class="p1">
                    <p id="61">4) 使用Heron示例拓扑和自定义拓扑对流分类调度策略进行性能评估。实验结果表明, 相较于Heron默认调度策略, DSC-Heron在系统完成时延、节点间数据流大小和吞吐量方面均有一定的优化效果。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">1 Heron作业模型</h3>
                <div class="p1">
                    <p id="63">在Heron中, 拓扑是用户定义流式作业的抽象, 使用有向无环图 (Directed Acyclic Graph, DAG) 表示, 由组件和数据流构成。组件分为Spout和Bolt两类:Spout为数据源编程单元, 可以从Kafka<citation id="342" type="reference"><link href="313" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、DistributedLog<citation id="343" type="reference"><link href="315" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>或HDFS (Hadoop Distributed File System) 中不间断地读取数据, 以数据流的形式传递给下游组件;Bolt为数据流处理单元, 用于实现数据处理逻辑。数据流是对组件间以元组形式进行数据传递的抽象, 可以通过不同的流组模式定义元组的传递和分组方式。由此定义拓扑逻辑模型如下。</p>
                </div>
                <div class="p1">
                    <p id="64"><b>定义</b>1 拓扑逻辑模型。任意拓扑可记为二元组 (<i>C</i>, <i>S</i>) 。其中, <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo>=</mo><mo stretchy="false">{</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>c</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>C</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>表示拓扑组件集合, <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>C</mi><mo>|</mo></mrow><mspace width="0.25em" /><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>C</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>表示拓扑数据流集合。这样用于表示拓扑逻辑结构的二元组 (<i>C</i>, <i>S</i>) 称为Heron的拓扑逻辑模型。如图1所示拓扑, {<i>c</i><sub><i>a</i></sub>, <i>c</i><sub><i>b</i></sub>, …, <i>c</i><sub><i>g</i></sub>}为组件集合, {<i>s</i><sub><i>a</i>, <i>c</i></sub>, <i>s</i><sub><i>a</i>, <i>d</i></sub>, …, <i>s</i><sub><i>e</i>, <i>g</i></sub>}为数据流集合。其中, {<i>c</i><sub><i>a</i></sub>, <i>c</i><sub><i>b</i></sub>}为Spout, 负责读取外部数据并将数据以数据流的形式发送至下游组件;{<i>c</i><sub><i>f</i></sub>, <i>c</i><sub><i>g</i></sub>}为拓扑中数据处理终点, 数据在此将流入其他系统或持久化至数据库。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 拓扑逻辑模型" src="Detail/GetImg?filename=images/JSJY201904028_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 拓扑逻辑模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Logical model of topology</p>

                </div>
                <div class="p1">
                    <p id="68">Heron中为提高系统并行度和数据处理速度可以为拓扑中每个组件定义运行并行度, 并在拓扑提交时为每个组件创建相应数量的任务实例。每个任务实例运行一个Java进程且运行在一个JVM中。由此定义拓扑实例模型如下。</p>
                </div>
                <div class="p1">
                    <p id="69"><b>定义</b>2 拓扑实例模型。对于任意组件<i>c</i><sub><i>i</i></sub>∈<i>C</i>, 定义<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>为该组件的任务实例集合, 其中<i>I</i><sub><i>ij</i></sub>表示组件<i>c</i><sub><i>i</i></sub>运行的第<i>j</i>个任务实例。特别地, 若组件<i>c</i><sub><i>i</i></sub>的并行度为1, 定义<i>I</i><sub><i>i</i></sub>={<i>I</i><sub><i>i</i>1</sub>}。这样以拓扑逻辑模型为基础, 根据各个组件并行度创建出的拓扑结构, 称为拓扑实例模型。此时, 由于组件的并行运行, 拓扑中实际的数据流集合表示为<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>。图2即为图1所示拓扑的一种实例模型, 组件<i>c</i><sub><i>d</i></sub>的并行度为3, 其任务实例集合为<i>I</i><sub><i>d</i></sub>={<i>I</i><sub><i>d</i>1</sub>, <i>I</i><sub><i>d</i>2</sub>, <i>I</i><sub><i>d</i>3</sub>};组件<i>c</i><sub><i>f</i></sub>的并行度为2, 其任务实例集合为<i>I</i><sub><i>f</i></sub>={<i>I</i><sub><i>f</i>1</sub>, <i>I</i><sub><i>f</i>2</sub>};其余组件并行度为1。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 拓扑实例模型" src="Detail/GetImg?filename=images/JSJY201904028_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 拓扑实例模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Instance model of topology</p>

                </div>
                <div class="p1">
                    <p id="73">在Heron实际任务分配过程中, 由调度器负责根据任务分配算法将各个任务实例分配至容器, 创建拓扑的任务分配计划, 然后将容器分配至工作节点。定义集群中工作节点集合为<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo>=</mo><mo stretchy="false">{</mo><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>, 每个工作节点中可分配多个容器, 一个容器可分配多个任务实例。对于<i>n</i><sub><i>i</i></sub>∈<i>N</i>, 有<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>t</mi><mi>m</mi><mi>g</mi><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>i</mi><mrow><mo>|</mo><mrow><mi>S</mi><mi>t</mi><mi>m</mi><mi>g</mi><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>, 其中<i>st</i><sub><i>ij</i></sub>表示第<i>i</i>个工作节点中分配的第<i>j</i>个容器。定义任务实例分配模型和任务分配计划如下。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Heron实例分配模型" src="Detail/GetImg?filename=images/JSJY201904028_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Heron实例分配模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Instance allocation model of Heron</p>

                </div>
                <div class="p1">
                    <p id="77"><b>定义</b>3 实例分配模型。假设某拓扑的任务实例集合为:<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>, 其中<i>I</i><sub><i>ij</i></sub>表示<i>c</i><sub><i>i</i></sub>组件的第<i>j</i>个任务实例。若<i>I</i><sub><i>ij</i></sub>分配到了<i>n</i><sub><i>k</i></sub>节点中的第<i>l</i>个容器中, 记为<i>f</i> (<i>I</i><sub><i>ij</i></sub>) =<i>n</i><sub><i>k</i></sub>且<i>g</i> (<i>I</i><sub><i>ij</i></sub>) =<i>st</i><sub><i>kl</i></sub>且<i>h</i> (<i>st</i><sub><i>kl</i></sub>) =<i>n</i><sub><i>k</i></sub>, 其中<i>f</i>、<i>g</i>和<i>h</i>为任务分配算法定义的任务分配函数。任务分配完成后得到的<i>f</i> (<i>I</i><sub><i>ij</i></sub>) =<i>n</i><sub><i>k</i></sub>、<i>g</i> (<i>I</i><sub><i>ij</i></sub>) =<i>st</i><sub><i>kl</i></sub>和<i>h</i> (<i>st</i><sub><i>kl</i></sub>) =<i>n</i><sub><i>k</i></sub>称为任务分配模型, 其中任务实例与容器的分配关系称为任务分配计划 (Packing Plan) 。如图3为图2表示的拓扑实例模型根据轮询分配算法创建的实例分配模型, 描述了真实的拓扑任务实例分配情况。其中分配至工作节点的每个容器中都运行一个流管理器 (Stream Manager, SM) , 负责各个任务实例间的数据传递。以<i>I</i><sub><i>a</i></sub>和<i>I</i><sub><i>d</i>1</sub>为例, 任务分配模型分别表示为: <i>f</i> (<i>I</i><sub><i>a</i></sub>) =<i>n</i><sub>1</sub>, <i>g</i> (<i>I</i><sub><i>a</i></sub>) =<i>st</i><sub>11</sub>, <i>h</i> (<i>st</i><sub>11</sub>) =<i>n</i><sub>1</sub>和<i>f</i> (<i>I</i><sub><i>d</i>1</sub>) =<i>n</i><sub>2</sub>, <i>g</i> (<i>I</i><sub><i>d</i>1</sub>) =<i>st</i><sub>22</sub>, <i>h</i> (<i>st</i><sub>22</sub>) =<i>n</i><sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="79">根据实例分配模型可知, Heron任务实例之间的通信需要经过所在容器中的SM进行路由。集群中各个SM彼此连接形成一个全连接网络, 将复杂度为<i>O</i> (<i>N</i> (<i>N</i>-1) /2) 的<i>N</i>个任务实例间通信, 通过<i>M</i>个SM简化为<i>O</i> (<i>M</i> (<i>M</i>-1) /2) , 其中<i>N</i>≫<i>M</i>。因此, 在Heron集群中存在三种不同的通信方式:</p>
                </div>
                <div class="p1">
                    <p id="80">1) 工作节点间通信, 即集群不同物理工作节点间任务实例的通信方式。这种通信方式中, 数据流需要经过源任务实例、源任务所属SM、目的任务所属SM和目的任务实例进行传输, 会占用大量的网络带宽资源, 是集群中通信开销最大的一种通信方式。如图3中, 任务实例<i>I</i><sub><i>a</i></sub>和<i>I</i><sub><i>d</i>1</sub>间的通信即属于工作节点间通信。</p>
                </div>
                <div class="p1">
                    <p id="81">2) 容器间通信, 即同一工作节点、不同容器中任务实例之间的通信方式。这种通信方式不占用网络带宽, 数据流在同一节点的不同任务间进行传递, 但仍需要经过源任务实例、目的任务实例以及各自所属的SM, 属于进程间通信且通信开销较小。如图3中, 任务实例<i>I</i><sub><i>d</i>2</sub>和<i>I</i><sub><i>c</i></sub>间的通信即为容器间通信方式。</p>
                </div>
                <div class="p1">
                    <p id="82">3) 实例间通信, 即同一工作节点且同一容器中任务实例间的直接通信。这种通信方式在一个容器中进行, 数据流只经过一个SM进行传输, 是三种通信方式中通信开销最小的一种。由于在Heron中每个任务实例都是一个Java进程, 因此这种通信方式也属于进程间通信, 但由于减少了数据流经过的SM数量, 因此通信开销较容器间通信开销小。如图3中, 任务实例<i>I</i><sub><i>b</i></sub>和<i>I</i><sub><i>g</i></sub>间即属于实例间通信方式。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">2 问题建模与分析</h3>
                <div class="p1">
                    <p id="84">本章在Heron作业模型的基础之上提出资源约束模型、最优通信开销模型和流分类模型。其中资源约束模型为任务分配的基础条件;最优通信开销模型论证了节点间和节点内通信开销的相互关系, 为最小化通信开销的任务调度过程提供依据;流分类模型定义了拓扑中数据流分类的理论基础。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2.1 <b>资源约束模型</b></h4>
                <div class="p1">
                    <p id="86">Heron集群一般包括CPU、内存和磁盘三种资源。针对本文研究内容, 引入网络带宽资源并忽略容易满足的磁盘资源, 由此构建集群中各工作节点<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo>=</mo><mo stretchy="false">{</mo><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>的资源模型为<i>r</i>={<i>r</i><sup>C</sup>, <i>r</i><sup>M</sup>, <i>r</i><sup>B</sup>}。其中CPU资源为<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msup><mrow></mrow><mtext>C</mtext></msup><mo>=</mo><mo stretchy="false">{</mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mtext>C</mtext></msubsup><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mtext>C</mtext></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></msub></mrow><mtext>C</mtext></msubsup><mo stretchy="false">}</mo></mrow></math></mathml>;内存资源为<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msup><mrow></mrow><mtext>Μ</mtext></msup><mo>=</mo><mo stretchy="false">{</mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mtext>Μ</mtext></msubsup><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mtext>Μ</mtext></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></msub></mrow><mtext>Μ</mtext></msubsup><mo stretchy="false">}</mo></mrow></math></mathml>;网络带宽资源为<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msup><mrow></mrow><mtext>B</mtext></msup><mo>=</mo><mo stretchy="false">{</mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mtext>B</mtext></msubsup><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mtext>B</mtext></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></msub></mrow><mtext>B</mtext></msubsup><mo stretchy="false">}</mo></mrow></math></mathml>。若任务实例<i>I</i><sub><i>ij</i></sub>分配到节点<i>n</i><sub><i>k</i></sub>的容器<i>st</i><sub><i>kl</i></sub>中, 设拓扑中配置的任务实例CPU资源需求为<i>R</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>C</mtext></msubsup></mrow></math></mathml> (单位为CPU核心数) , 内存资源需求为<i>R</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>Μ</mtext></msubsup></mrow></math></mathml> (单位为B) , 实际网络带宽占用为<i>o</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>B</mtext></msubsup></mrow></math></mathml> (单位为bps) 。容器CPU资源需求为<i>R</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>C</mtext></msubsup></mrow></math></mathml> (单位为CPU核心数) , 内存资源需求为<i>R</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>Μ</mtext></msubsup></mrow></math></mathml> (单位为B) , 实际网络带宽占用为<i>o</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>B</mtext></msubsup></mrow></math></mathml> (单位为bps) 。为保证集群高效运行, 需满足的资源约束如下:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>R</mi></mstyle><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>C</mtext></msubsup><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>R</mi></mstyle><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>C</mtext></msubsup><mo>≤</mo><mi>α</mi><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mtext>C</mtext></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>R</mi></mstyle><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>Μ</mtext></msubsup><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>R</mi></mstyle><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>Μ</mtext></msubsup><mo>≤</mo><mi>β</mi><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mtext>Μ</mtext></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>o</mi></mstyle><msubsup><mrow></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mtext>B</mtext></msubsup><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>o</mi></mstyle><msubsup><mrow></mrow><mrow><mi>s</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow><mtext>B</mtext></msubsup><mo>≤</mo><mi>γ</mi><mi>r</mi><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mtext>B</mtext></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">在Heron应用环境中, 为使各个工作节点不会出现满负荷运行状态以影响集群运行性能, 需要为每个工作节点预留少量的计算资源。因此, 在上述资源约束中, <i>α</i>、 <i>β</i>、<i>γ</i>分别为集群管理人员为CPU、内存和网络带宽资源设定的资源阈值参数, 该参数可根据集群资源情况进行设置。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">2.2 <b>最优通信开销模型</b></h4>
                <div class="p1">
                    <p id="100">由第1章可知, 在拓扑提交至<i>Heron</i>集群运行时包含三种通信方式。其中工作节点间通信开销最大, 容器间通信次之, 实例间通信开销最小。为保证拓扑在集群中的高效运行, 应在满足资源约束模型的同时最小化这三类通信开销。然而在拓扑提交后, 任务实例和数据流总数量即固定下来。因此, 若要最小化拓扑通信开销, 则需最小化容器间通信开销和节点间通信开销, 即尽可能将节点间通信和容器间通信转化为实例间通信。通信开销可使用任务间传输的单位数据流大小进行度量, 定义拓扑中实例I<sub>ij</sub>和I<sub>kl</sub>之间的数据流大小为v<sub>ij, kl</sub>或v<sub>kl, ij</sub> (v的下标与数据流向无关, 单位为<i>tuple</i>/<i>s</i>) , 即可建立如下优化模型:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo></mrow></munder><mspace width="0.25em" /></mstyle><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mspace width="0.25em" /></mstyle><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">等价于:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>max</mi></mrow><mspace width="0.25em" /><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">证明 由定义3可知, 在拓扑提交并创建完成任务分配计划后, 拓扑中任务实例及数据流总数均已确定, 在拓扑运行期间不会改变。由此, 拓扑中包含的数据流总量V计算如下:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>V</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">因此, 当节点间数据流大小<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></math></mathml>和同一节点不同容器间数据流大小<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>≠</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></math></mathml>取得最小值时, 即等价于任务实例间直接通信的数据流<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></math></mathml>取最大值。 证毕。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110">2.3 <b>流分类模型</b></h4>
                <div class="p1">
                    <p id="111">定义拓扑实例模型中所有任务实例集合为<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mo>=</mo><mo stretchy="false">{</mo><mi>Ι</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>, 其中I<sub>i</sub>表示组件c<sub>i</sub>的任务实例集合<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>。由I<sub>ij</sub>和I<sub>kl</sub>间数据流s<sub>ij, kl</sub>传输的单位数据流大小为v<sub>ij, kl</sub>, 则对于拓扑实例模型中所有数据流总量V及数据流均值<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>为:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>V</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo>∈</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>∧</mo><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≠</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>V</mi><mo>¯</mo></mover><mo>=</mo><mi>V</mi><mo>/</mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">则s<sub>ij, kl</sub>的数据流大小偏离均值的绝对偏离量为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub><mo>=</mo><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>V</mi><mo>¯</mo></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">进而可以求出数据流集合<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>中数据流的总绝对偏移量和平均偏移量:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>Δ</mtext><mi>V</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>∈</mo><mi>S</mi></mrow></munder><mtext>Δ</mtext></mstyle><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>Δ</mtext><mover accent="true"><mi>V</mi><mo>¯</mo></mover><mo>=</mo><mtext>Δ</mtext><mi>V</mi><mo>/</mo><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">依据上述数值定义数据流s<sub>ij, kl</sub>的分类如下:</p>
                </div>
                <div class="p1">
                    <p id="122">1) 若满足式 (13) , 则s<sub>ij, kl</sub>为高频数据流。</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>≥</mo><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow></math></mathml>且<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>≥</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="126">2) 若满足式 (14) , 则s<sub>ij, kl</sub>为中高频数据流。</p>
                </div>
                <div class="p1">
                    <p id="127" class="code-formula"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>≥</mo><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow></math></mathml>且<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>&lt;</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="130">3) 若满足式 (15) , 则s<sub>ij, kl</sub>为中低频数据流。</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula"><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>&lt;</mo><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow></math></mathml>且<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>&lt;</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="134">4) 若满足式 (16) , 则s<sub>ij, kl</sub>为低频数据流。</p>
                </div>
                <div class="p1">
                    <p id="135" class="code-formula"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub><mo>&lt;</mo><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow></math></mathml>且<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>v</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>k</mi><mi>l</mi></mrow></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>≥</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mover accent="true"><mi>V</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="138"><b>定义</b>4 高频数据流簇。如果高频数据流s<sub>ij, kl</sub>关联的任务实例I<sub>ij</sub>和I<sub>kl</sub>分别与高频数据流s<sub>gh, ij</sub>和s<sub>kl, mn</sub>关联, 则这些相互连接的高频数据流组成的集合SC<sub>ij, kl</sub>={…, s<sub>gh, ij</sub>, s<sub>ij, kl</sub>, s<sub>kl, mn</sub>, …}称为数据流s<sub>ij, kl</sub>的高频数据流簇 (简称高频流簇) 。由该定义可知, 每个高频流簇中包含了与一个高频数据流相关联的所有高频数据流, 并且拓扑中任意高频流的流簇规模的最大值为拓扑的关键路径 (Critical Path) 长度。在DSC-Heron中, 将高频流簇作为整体进行调度以最大化节点内通信, 即高频流簇为该策略的粗粒度调度单元。</p>
                </div>
                <h3 id="139" name="139" class="anchor-tag">3 流分类调度策略</h3>
                <div class="p1">
                    <p id="140">本章基于上述模型提出流分类调度策略 (DSC-Heron) , 包括流分类算法、流簇分配算法和流分类调度算法。其中流分类算法以流分类模型为基础, 以数据流实时大小为依据对数据流进行分类;流簇分配算法以高频流簇为基本单元进行任务分配;流分类调度算法对不同类别的数据流依次进行调度, 最终完成目标任务分配计划的构建。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141">3.1 <b>流分类算法</b></h4>
                <div class="p1">
                    <p id="142">通过使用3.4节提出的负载监测模块对集群中任务实例以及实例间数据流大小进行监测, 实时获取拓扑中任务实例间数据流大小, 得到拓扑的数据流集合<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>作为输入;然后根据流分类模型将集合<i>S</i>划分为高频数据流集<i>Hf</i>、中频数据流集<i>Mf</i>和低频数据流集<i>Nf</i>。具体算法如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="144">算法1 流分类算法。</p>
                </div>
                <div class="p1">
                    <p id="145">输入 数据流集合<mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="147">输出 高频数据流集<i>Hf</i>;中频数据流集<i>Mf</i>;低频数据流集<i>Nf</i>。</p>
                </div>
                <div class="p1">
                    <p id="148">步骤1 根据<i>S</i>中各个数据流大小<i>v</i><sub><i>ij</i>, <i>kl</i></sub>, 使用式 (8) 计算数据流总量<i>V</i>;使用式 (9) 计算数据流平均值<mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>;使用式 (10) 计算<i>s</i><sub><i>ij</i>, <i>kl</i></sub>的绝对偏差值;使用式 (11) 计算数据流总绝对偏差Δ<i>V</i>;使用式 (12) 平均偏差Δ<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="151">步骤2 根据<i>v</i><sub><i>ij</i>, <i>kl</i></sub>大小降序排序<i>S</i>并进行遍历, 进行如下判断:若数据流<i>s</i><sub><i>ij</i>, <i>kl</i></sub>满足式 (13) , 将其加入高频数据流集<i>Hf</i>;若满足式 (14) 或式 (15) , 将其加入中频数据流集合<i>Mf</i>;若满足式 (16) , 将其加入低频数据流集合<i>Nf</i>。</p>
                </div>
                <div class="p1">
                    <p id="152">步骤3 返回<i>Hf</i>、<i>Mf</i>和<i>Nf</i>。</p>
                </div>
                <div class="p1">
                    <p id="153">流分类算法步骤1中包括两次对数据流集合<i>S</i>的遍历。第一次遍历数据流集合<i>S</i>, 计算出拓扑数据流总量<i>V</i>, 进而可以计算数据流平均值<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>。第二次遍历数据流集合<i>S</i>, 由数据流平均值<mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>计算各个数据流的绝对偏差值, 同时累加计算所有数据流的总绝对偏差值Δ<i>V</i>和平均偏差值Δ<mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>。算法步骤2～3根据流分类模型中的式 (13) ～ (16) , 使用步骤1计算所得值, 对数据流集合遍历的同时进行数据流的分类并返回分类所得不同数据流集合。由此可知, 该算法的时间复杂度为数据流集合<i>S</i>的大小, 即<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158">3.2 <b>流簇分配算法</b></h4>
                <div class="p1">
                    <p id="159">由定义4可知, <i>DSC</i>-<i>Heron</i>将高频数据流关联的高频流簇作为调度的基本单元, 尽可能得将同一高频流簇相关的任务实例调度到同一工作节点。在调度的过程中, 需要根据当前高频数据流关联的任务实例在高频流集合Hf中递归搜索与之关联的流簇, 然后对该流簇中的任务实例进行分配, 由此得到流簇分配算法。具体算法如算法2所示。</p>
                </div>
                <div class="p1">
                    <p id="160">算法2 流簇分配算法。</p>
                </div>
                <div class="p1">
                    <p id="161">输入 数据流s<sub>ij, kl</sub>关联的任务实例I<sub>ij</sub>和I<sub>kl</sub>;高频数据流集合Hf;目标节点n<sub>k</sub>;原始任务分配计划PP<sub><i>old</i></sub>;当前目标任务分配计划PP<sub><i>new</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="162">输出 更新后的目标任务分配计划PP<sub><i>new</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="163">步骤1 根据I<sub>ij</sub>和I<sub>kl</sub>在Hf中搜索关联的高频数据流s<sub>gh, ij</sub>和s<sub>kl, mn</sub>, 若不存在相关联高频数据流或存在任务实例I<sub>gh</sub>、I<sub>mn</sub>且均已分配则递归结束。若存在且未分配, 根据PP<sub><i>old</i></sub>判断I<sub>gh</sub>和I<sub>mn</sub>是否分别位于目标节点n<sub>k</sub>中:</p>
                </div>
                <div class="p1">
                    <p id="164">如果是, 判断将该任务实例仍分配至n<sub>k</sub>中是否满足资源约束条件:若满足则进行分配, 更新PP<sub><i>new</i></sub>并进行步骤2;若不满足则查找当前PP<sub><i>new</i></sub>中负载最小的工作节点进行调度。</p>
                </div>
                <div class="p1">
                    <p id="165">如果否, 判断将未分配任务实例调度到n<sub>k</sub>节点之后是否满足资源约束条件:若满足进行调度, 更新PP<sub><i>new</i></sub>并进行步骤2;若不满足则查找当前PP<sub><i>new</i></sub>中负载最小的节点进行调度。</p>
                </div>
                <div class="p1">
                    <p id="166">步骤2 在Hf中递归查找I<sub>gh</sub>和I<sub>mn</sub>关联的高频数据流s<sub>ef, gh</sub>和s<sub>mn, op</sub>, 若存在任务实例I<sub>ef</sub>, I<sub>op</sub>未分配, 重复步骤1直至递归结束。</p>
                </div>
                <div class="p1">
                    <p id="167">流簇分配算法是一个递归的集合搜索过程, 它将一个高频数据流关联的源任务实例、目的任务实例和高频数据流集合作为输入, 分别对源任务实例和目的任务实例在高频数据流集合中搜索相关联的高频数据流, 并依次对搜索结果中包含的未分配任务实例进行调度, 以更新目标任务分配计划。同时, 该搜索过程也是构建该数据流高频流簇SC的过程。若一条高频数据流在高频数据流集合中不存在关联的高频流或存在且均已经分配完成则递归结束, 返回对该条数据流构建完成的目标任务分配计划。流簇分配算法将每个高频数据流的关联的流簇集合整体作为任务调度对象, 旨在最大化节点内任务间数据流, 根据最优通信开销模型即等价于最小化节点间数据流, 以减少拓扑整体通信开销。根据该递归算法可知, 其时间复杂度为:<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>Η</mi><mi>f</mi></mrow><mo>|</mo></mrow><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>S</mi><mi>C</mi></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>。其中, 由于SC的最大值等于拓扑关键路径长度, 因此该算法的运行时间与拓扑的层数以及高频数据流集合规模有关。</p>
                </div>
                <h4 class="anchor-tag" id="169" name="169">3.3 <b>流分类任务调度算法</b></h4>
                <div class="p1">
                    <p id="170">流分类调度算法整合了流分类算法和流簇分配算法, 将流分类算法中得到的高频流集合作为输入, 通过遍历数据流集合S, 首先对其中高频数据流进行分配并对该数据流调用流簇分配算法进行任务调度, 直至所有的高频数据流分配完成, 然后对未分配的中频数据流和低频数据流分別调度, 完成构建目标任务分配计划。具体算法如算法3所示。</p>
                </div>
                <div class="p1">
                    <p id="171">算法3 流分类调度算法。</p>
                </div>
                <div class="p1">
                    <p id="172">输入 数据流集合<mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></msub><mo stretchy="false">}</mo></mrow></math></mathml>;高频数据流集合Hf;中频数据流集合Mf;低频数据流集合Nf;原始任务分配计划PP<sub><i>old</i></sub>;目标任务分配计划PP<sub><i>new</i></sub>;任务实例负载集合W={w<sub>I<sub>ij</sub></sub>}。</p>
                </div>
                <div class="p1">
                    <p id="174">输出 目标任务分配计划PP<sub><i>new</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="175">初始化 由负载监测模块获取当前各数据流大小v<sub>ij, kl</sub>和各任务实例<i>CPU</i>负载w<sub>I<sub>ij</sub></sub>以初始化数据流集合S与任务实例负载集合W;使用流分类算法得到各数据流分类集合Hf、Mf、Nf;初始化PP<sub><i>new</i></sub>为空。</p>
                </div>
                <div class="p1">
                    <p id="176">步骤1 根据数据流v<sub>ij, kl</sub>的大小对集合S进行降序排序, 遍历集合S中各数据流s<sub>ij, kl</sub>。</p>
                </div>
                <div class="p1">
                    <p id="177">步骤2 如果s<sub>ij, kl</sub>属于高频数据流集合Hf, 进行如下步骤:</p>
                </div>
                <div class="p1">
                    <p id="178">①判断数据流s<sub>ij, kl</sub>关联的两个任务实例I<sub>ij</sub>和I<sub>kl</sub>是否在PP<sub><i>new</i></sub>中已经重新分配, 若都已经重新分配则对该数据流的调度结束。</p>
                </div>
                <div class="p1">
                    <p id="179">②若仅其中一个任务已分配, 这里以I<sub>ij</sub>已分配至工作节点n<sub>k</sub>且I<sub>kl</sub>未分配为例, 进行如下步骤:</p>
                </div>
                <div class="p1">
                    <p id="180"> (<i>a</i>) 根据PP<sub><i>old</i></sub>判断I<sub>ij</sub>和I<sub>kl</sub>是否位于同一节点。若在同一节点n<sub>k</sub>, 更新PP<sub><i>new</i></sub>并调用流簇分配算法, 分配s<sub>ij, kl</sub>关联的其他高频数据流, 调度结束。</p>
                </div>
                <div class="p1">
                    <p id="181"> (<i>b</i>) 若I<sub>ij</sub>和I<sub>kl</sub>位于不同节点, 根据资源约束模型判断I<sub>kl</sub>调度到工作n<sub>k</sub>后是否满足资源约束, 若满足则将I<sub>kl</sub>调度到工作节点n<sub>k</sub>, 更新PP<sub><i>new</i></sub>并调用流簇分配算法, 分配s<sub>ij, kl</sub>关联的高频数据流, 调度结束。若不满足, 则根据W查找当前PP<sub><i>new</i></sub>中负载最小节点分配任务I<sub>kl</sub>。</p>
                </div>
                <div class="p1">
                    <p id="182">③若任务实例I<sub>ij</sub>和I<sub>kl</sub>均未分配, 进行如下步骤:</p>
                </div>
                <div class="p1">
                    <p id="183"> (<i>a</i>) 根据PP<sub><i>old</i></sub>判断I<sub>ij</sub>和I<sub>kl</sub>是否位于同一节点, 若在同一节点n<sub>k</sub>, 更新PP<sub><i>new</i></sub>并调用流簇分配算法, 分配s<sub>ij, kl</sub>关联的高频数据流, 调度结束。</p>
                </div>
                <div class="p1">
                    <p id="184"> (<i>b</i>) 若I<sub>ij</sub>和I<sub>kl</sub>位于不同节点n<sub>i</sub>和n<sub>k</sub>中, 计算当前分配计划PP<sub><i>new</i></sub>中n<sub>i</sub>和n<sub>k</sub>已分配任务的负载, 将I<sub>ij</sub>和I<sub>kl</sub>分配到负载较小的节点中, 并根据资源约束模型判断调度过程中是否满足资源约束, 若满足则逐个调度任务, 更新PP<sub><i>new</i></sub>并调用流簇分配算法, 分配s<sub>ij, kl</sub>关联的高频数据流, 调度结束。若在调度任务实例I<sub>kl</sub>时已不满足资源约束条件, 则将其调度至当前负载最小的节点。</p>
                </div>
                <div class="p1">
                    <p id="185">步骤3 如果s<sub>ij, kl</sub>属于中频数据流集合Mf, 则重复步骤2中的①～③, 但不再调用流簇分配算法, 此时高频数据流已经调度完成。</p>
                </div>
                <div class="p1">
                    <p id="186">步骤4 结束数据流集合S的遍历, 对剩下低频数据流集合Nf中s<sub>ij, kl</sub>计算当前PP<sub><i>new</i></sub>中各个节点的任务负载情况, 优先将任务I<sub>ij</sub>、I<sub>kl</sub>调度到负载较轻的节点中并保证满足资源约束条件, 直到全部任务调度完成。</p>
                </div>
                <div class="p1">
                    <p id="187">算法步骤1中根据集合中数据流的大小对数据流集合S进行降序排序, 这样可以保证在对集合S进行遍历时, 对高频数据流进行优先处理。步骤2对集合S进行遍历, 对属于高频数据流集合的当前数据流进行调度。该步骤中包含的①～③分别是对当前高频数据流关联的两个任务实例是否在目标任务分配计划中分配完成进行判断, 目的是为了避免对可能出现在不同高频数据流中的同一任务实例进行重复调度。步骤①中, 如果当前的两个任务实例均已经在目标任务分配计划中分配完成, 则不再进行重复调度。步骤②中, 当前两个任务实例中仅有一个任务实例已经分配, 则优先将未分配的任务实例调度到已分配任务实例当前所在的工作节点中, 此举是为了最大化节点内任务实例间的直接通信以最小化节点间的通信开销。但在这种调度的过程中, 需要判断调度发生后目标节点是否满足资源约束条件:若满足则可以进行调度, 完成最大化节点内通信开销;若不满足, 则需要使用当前目标任务分配计划PP<sub><i>new</i></sub>和任务负载集合W寻找当前集群中负载最小的工作节点分配该任务, 目的是为了在未能满足最小化通信开销的情况下, 尽量平衡集群各工作节点负载从而在负载均衡的角度优化集群性能。步骤③中为当前两个任务实例均未重新分配, 需要依次对两个未分配任务实例进行调度。首先根据原始任务分配计划PP<sub><i>old</i></sub>判断两个任务实例是否位于同一节点, 并优先将两个任务调度到其中当前负载较轻的工作节点中, 以最小化通信开销的同时均衡集群负载。但在对两个任务进行依次调度时, 均需要对目标工作节点计算调度完成后的资源约束情况, 若不满足资源约束, 则同步骤②中的方法相同, 将该任务实例分配至当前集群中负载最小的工作节点。通过步骤1～2, 算法将数据流集合S中包含的高频数据流及其关联高频流簇调度完成, 因此步骤3对中频数据流集合中的数据流进行调度时, 不需要考虑高频流簇的分配, 仅对中频数据流本身继续调度。算法步骤4进行之前, 前序算法步骤已经对数据流集合S中高频数据流和中频数据流调度结束, 此时只剩下低频数据流, 而低频数据流在拓扑中对整体通信开销的影响最小, 因此仅对其进行负载均衡处理, 依次将低频数据流调度至集群当前负载较小的工作节点中, 最终完成全部数据流的调度。根据该算法步骤可知, 该算法在对数据流集合S遍历的同时分别将属于各个类别的数据流调度至符合条件的工作节点中, 因此算法时间复杂度为<mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow><mo>⋅</mo><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml> (其中<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>Ν</mi><mo>|</mo></mrow></mrow></math></mathml>为工作节点数量) 。</p>
                </div>
                <h4 class="anchor-tag" id="190" name="190">3.4 <b>算法部署与实现</b></h4>
                <div class="p1">
                    <p id="191">Heron为编程人员提供了可扩展的Custom Scheduler<citation id="344" type="reference"><link href="317" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>实现。为实现自定义调度器, 需要实现与Heron调度器相关的IPacking、ILauncher、IScheduler和IUploader四个Java接口。在本文实验中, DSC-Heron基于Heron中默认AuroraScheduler进行部署和实现, Uploader仍使用HDFS不作修改, 但分别实现了以下三个接口:</p>
                </div>
                <h4 class="anchor-tag" id="266" name="266">1) DSCPacking。</h4>
                <div class="p1">
                    <p id="192">实现IPacking接口, 用于部署DSC-Heron以构建目标任务分配计划, 为调度控制模块对拓扑任务的重调度提供依据。</p>
                </div>
                <h4 class="anchor-tag" id="267" name="267">2) DSCLauncher。</h4>
                <div class="p1">
                    <p id="193">实现ILauncher接口, 替换原有的AuroraLauncher。用于在拓扑提交后创建DSCScheduler对象实例并调用其onSchedule方法启动自定义调度器。</p>
                </div>
                <h4 class="anchor-tag" id="268" name="268">3) DSCScheduler。</h4>
                <div class="p1">
                    <p id="194">实现IScheduler接口, 替换默认AuroraScheduler, 拓扑提交后将由该调度器完成拓扑的初次调度。其中部署调度触发模块和调度控制模块, 用于重调度的触发以及使用DSCPacking创建的目标任务分配计划更新拓扑, 完成重调度过程。</p>
                </div>
                <div class="p1">
                    <p id="195">在拓扑重调度的过程中, 需要实时获取各工作节点以及工作节点内各任务实例的CPU负载。对于各任务进程的CPU资源占用信息, 可以通过Java API中ThreadMXBean类的getThreadCpuTime (long id) 方法获取, 其中id为各Java进程中运行任务实例的线程ID。对于各工作节点的CPU负载, 可以通过对运行在该工作节点中的任务实例CPU负载进行累加求得。此外, 工作节点中相关硬件参数可通过/proc目录下的相关文件获得。在代码编写完成后, 使用Maven创建自定义调度器的jar文件, 将其放置到${HERON_HOME}/lib/scheduler目录下, 并在${HERON_HOME}/conf/aurora目录下的scheduler.yaml文件中进行配置DSCScheduler和DSCLauncher类名后即可使用。</p>
                </div>
                <div class="p1">
                    <p id="196">改进后的Heron系统结构如图4所示。其中, 在Heron系统结构中新增的四个自定义模块分别是:</p>
                </div>
                <h4 class="anchor-tag" id="269" name="269">1) 负载监测模块。</h4>
                <div class="p1">
                    <p id="197">部署在各个工作节点中, 负责在一定时间窗口内监测工作节点中运行的任务实例CPU负载、任务间数据流大小和内存资源占用等信息, 并将监测信息实时写入数据存储模块。使用该模块, 需要在拓扑中各Spout的open () 和nextTuple () 方法以及各Bolt的prepare () 和execute () 方法中调用该模块。</p>
                </div>
                <h4 class="anchor-tag" id="270" name="270">2) 调度触发模块。</h4>
                <div class="p1">
                    <p id="198">部署在DSCScheduler中并在该调度器对象实例化时启动。负责在满足重调度触发条件时调用调度控制模块中重调度方法完成DSC-Heron的重调度过程。</p>
                </div>
                <h4 class="anchor-tag" id="271" name="271">3) 数据存储模块。</h4>
                <div class="p1">
                    <p id="199">存储并实时更新负载监测模块获取的任务实例监测信息, 这里使用MySQL数据库实现。</p>
                </div>
                <h4 class="anchor-tag" id="272" name="272">4) 调度控制模块。</h4>
                <div class="p1">
                    <p id="200">完成流分类调度策略的核心模块, 通过调度触发模块调用。根据原始任务分配计划获取由DSC-Heron构建的目标任务分配计划, 更新拓扑任务分配以完成任务调度过程。该模块采用与DSCScheduler松耦合的设计范式, 便于未来部署其他在线重调度算法。</p>
                </div>
                <div class="area_img" id="201">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 改进的Heron系统结构" src="Detail/GetImg?filename=images/JSJY201904028_201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 改进的Heron系统结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Improved architecture of Heron</p>

                </div>
                <h3 id="202" name="202" class="anchor-tag">4 实验</h3>
                <h4 class="anchor-tag" id="203" name="203">4.1 <b>实验环境</b></h4>
                <div class="p1">
                    <p id="204">实验环境采用硬件配置相同的PC搭建一个9节点的Heron集群。其中一个主控节点运行Heron、Heron Tracker、Heron UI、Mesos Master和Aurora Scheduler;一个协调节点运行ZooKeeper和MySQL等服务;一个节点运行Heron自动创建的拓扑管理进程 (Topology Master) 用于管理拓扑整个生命周期;其余节点为工作节点分别运行Mesos Agent、Aurora Observer和Aurora Executor, 负责实际运行拓扑的任务实例。此外, 集群中各节点共同运行HDFS作为Heron的Uploader系统组件并负责共享Heron Binaries文件。实验集群的软硬件配置如表1所示。</p>
                </div>
                <div class="area_img" id="205">
                    <p class="img_tit"><b>表</b>1 Heron<b>集群软硬件配置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Software and hardware configuration of Heron cluster</p>
                    <p class="img_note"></p>
                    <table id="205" border="1"><tr><td><br />配置项</td><td>配置参数</td></tr><tr><td><br />CPU</td><td>Intel core i7 4790/3.6 GHz/4cores</td></tr><tr><td><br />RAM</td><td>6 GB DDR3 1 600 MHz</td></tr><tr><td><br />NIC</td><td>100 Mbps LAN</td></tr><tr><td><br />HDD</td><td>1 TB, 7 200 r·min<sup>-1</sup>, SATA3</td></tr><tr><td><br />OS</td><td>Ubuntu 16.04</td></tr><tr><td><br />Heron Client/Tools</td><td>0.17.5</td></tr><tr><td><br />JDK</td><td>jdk1.8.0_151</td></tr><tr><td><br />ZooKeeper</td><td>3.4.10</td></tr><tr><td><br />Python</td><td>2.7</td></tr><tr><td><br />MySQL</td><td>5.7</td></tr><tr><td><br />Apache Aurora</td><td>0.17.1</td></tr><tr><td><br />Apache Mesos</td><td>1.4.1</td></tr><tr><td><br />Hadoop/HDFS</td><td>2.7.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="206">实验采用Heron Github开源项目<citation id="345" type="reference"><link href="319" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提供的Sentence WordCount和WordCount示例拓扑以及自定义FileWordCount拓扑, 三种拓扑中采用不同的结构和数据源以评估DSC-Heron在不同场景中的表现。其中SentenceWordCount拓扑包含三层结构:第一层Spout组件随机创建一个长度为128×1 024的句子数组并随机发射;第二层Bolt组件 (名为Split) 通过空格字符分割句子产生单词;第三层Bolt组件 (名为Count) 接受Split中发送的单词并进行计数。WordCount为两层结构, Spout组件 (名为word) 随机生成单词并发射, 由Bolt (名为consumer) 组件进行统计。FileWordCount拓扑结构与SentenceWordCount相同, 但数据源来自原版英文历史小说《双城记》, 格式为txt。SentenceWordCount拓扑相对于WordCount的两层结构, 包含的数据流数量和流簇规模较大, 两者对比有利于评估系统性能的优化效果。FileWordCount拓扑数据源采用真实文本文档, 其中各单词出现的频率不尽相同, 在实际的应用场景中有一定代表性。</p>
                </div>
                <div class="p1">
                    <p id="207">实验拓扑中设置了各组件的并行度和资源需求, 数据流在各组件间的传递模式, 可用的容器数量以及资源需求, 详细的测试拓扑运行参数配置如表2所示。</p>
                </div>
                <div class="area_img" id="208">
                    <p class="img_tit"><b>表</b>2 <b>测试拓扑运行参数配置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Operating parameters configuration of test topologies</p>
                    <p class="img_note"></p>
                    <table id="208" border="1"><tr><td><br />测试拓扑</td><td colspan="2">参数名称</td><td>参数值</td></tr><tr><td rowspan="6"><br />SentenceWord<br />Count/<br />FileWordCount</td><td><br />component.spout.parallelism</td><td colspan="2">4</td></tr><tr><td><br />component.spout.ram</td><td colspan="2">512 MB</td></tr><tr><td><br />component.split.parallelism</td><td colspan="2">10</td></tr><tr><td><br />component.split.ram</td><td colspan="2">512 MB</td></tr><tr><td><br />component.count.parallelism</td><td colspan="2">10</td></tr><tr><td><br />component.count.ram</td><td colspan="2">512 MB</td></tr><tr><td rowspan="4"><br />WordCount</td><td><br />component.word.parallelism</td><td colspan="2">8</td></tr><tr><td><br />component.word.ram</td><td colspan="2">512 MB</td></tr><tr><td><br />component.consumer.parallelism</td><td colspan="2">16</td></tr><tr><td><br />component.consumer.ram</td><td colspan="2">512 MB</td></tr><tr><td rowspan="7"><br />测试拓扑<br />公共参数</td><td><br />container.cpu.requested</td><td colspan="2">2cores</td></tr><tr><td><br />container.ram.requested</td><td colspan="2">3 GB</td></tr><tr><td><br />container.disk.requested</td><td colspan="2">3 GB</td></tr><tr><td><br />topology.max.spout.pending</td><td colspan="2">1 000</td></tr><tr><td><br />topology.message.timeout.secs</td><td colspan="2">60 s</td></tr><tr><td><br />topology.stmgrs</td><td colspan="2">6</td></tr><tr><td><br />topology.reliability.mode</td><td colspan="2">ATLEAST_ONCE</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="209">表2中:topology.max.spout.pending (简称为pending) 的值为Spout缓存队列的最大容量, 当队列长度达到设置的容量时Spout停止发送数据, 当队列长度小于设定值时Spout持续发送数据, 从而实现对拓扑数据传输速率的控制。topology.message.timeout.secs (简称为timeout) 的值配合ATLEAST_ONCE可靠性语义模式和Acknowledgement<citation id="346" type="reference"><link href="321" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>机制使用。实验拓扑在Bolt组件中设置ack机制, 唯一标识标记的元组从Spout中发射, 在timeout设定的时间内经过各个组件处理完成后由Spout中ack方法进行确认, 若没有在该参数规定的时间内接受到指定元组, Heron则会重新发送以保证ATLESAT_ONCE的有效进行。</p>
                </div>
                <div class="p1">
                    <p id="210">对于参数pending和timeout的取值, 在默认调度策略下使用SentenceWordCount拓扑经过多次实验得到表3所示参数取值对拓扑元组失败率的影响, 在表2所示参数下其他测试拓扑实验结果与此类似。其中, pending的值设置为100且timeout值设置为60 s时, 虽然拓扑运行前5 min的失败率较低, 但由于pending的值较小无法正常发挥集群运行性能且无法体现真实应用场景;当pending的值设置为1 000且timeout的值设置为60 s时, 拓扑提交后前5 min内的元组失败率为6.6%, 相对于相同pending值但timeout值为30 s时拓扑运行的20%失败率, 元组失败率明显降低并且有少量拓扑出现重新发送的情况, 该场景较符合真实应用场景且集群能够快速地趋于稳定。而当pending的值设置为10 000且timeout的值为60 s时, 元组失败率较高, 此时虽然提高timeout参数值可以降低元组失败率, 但会导致CPU负载过高从而使集群运行情况不可预测。因此, pending的值设置为1 000, timeout的值设置为60 s, 在当前集群的配置下能够较好地满足实验的需要。</p>
                </div>
                <div class="area_img" id="211">
                    <p class="img_tit"><b>表</b>3 <b>参数</b>pending<b>与</b>timeout<b>对拓扑元组失败率的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Impact of parameters pending and timeout on tuple failure rate of topology</p>
                    <p class="img_note"></p>
                    <table id="211" border="1"><tr><td><br />pending取值</td><td>timeout取值/s</td><td>拓扑元组失败率/%</td></tr><tr><td><br />100</td><td>60</td><td>2.0</td></tr><tr><td><br />1 000</td><td>60</td><td>6.6</td></tr><tr><td><br />1 000</td><td>30</td><td>20.0</td></tr><tr><td><br />10 000</td><td>60</td><td>58.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="212">此外, 由于集群中主控节点独立运行, 拓扑管理器单独运行于一个工作节点的容器中, ZooKeeper和MySQL等服务进程占用一个节点资源, 因此集群中可分配任务实例的工作节点数量为6。在表2中将topology.stmgrs的数量设置为6, 即容器数量与集群中工作节点的数量相同, 意味着每个工作节点中仅运行一个容器, 从而消除容器间通信带来的开销, 重点关注节点间通信和节点内实例间通信的转换对集群性能的影响。</p>
                </div>
                <div class="area_img" id="213">
                    <p class="img_tit"><b>表</b>4 <b>流分类调度算法参数配置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Peremeters configuration of data stream classification scheduling algorithm</p>
                    <p class="img_note"></p>
                    <table id="213" border="1"><tr><td><br />配置文件</td><td>参数</td><td>值</td></tr><tr><td><br />主控节点</td><td>reschedule.timeout</td><td>130 s</td></tr><tr><td><br /></td><td><i>α</i></td><td>0.7</td></tr><tr><td><br /></td><td><i>β</i></td><td>1</td></tr><tr><td><br />工作节点</td><td><i>γ</i></td><td>1</td></tr><tr><td><br /></td><td>time.window.count</td><td>3</td></tr><tr><td><br /></td><td>time.window.length</td><td>5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="214">为验证DSC-Heron的有效性, 本文与Heron默认的轮询调度策略进行了对比, 表4中列出了DSC-Heron的参数设置, 其中主控节点根据reschedule.timeout参数触发重调度。工作节点中<i>α</i>、 <i>β</i>和<i>γ</i>为资源约束模型中设置的资源阈值参数, 为避免节点满负荷运行影响集群性能, <i>α</i>值设置为0.7, 由于Heron容器中已为系统级进程留有内存资源, 因此<i>β</i>和<i>γ</i>的值设置为1。time.window.length和time.window.count为负载监测模块中设置的数据统计窗口大小和数量, 即使用长度为5 s的时间窗口对数据采样3次统计平均值。此外Heron集群的其他配置参数与默认轮询调度算法的参数均取默认值。</p>
                </div>
                <h4 class="anchor-tag" id="215" name="215">4.2 <b>实验结果分析</b></h4>
                <div class="p1">
                    <p id="216">本节对DSC-Heron从系统完成时延、通信开销、集群资源负载以及系统吞吐量四个方面进行评估。实验测试拓扑采用表2中设置的拓扑运行参数, 实验数据统一使用表4中设置的长度为5数量为3的时间窗口进行统计, 统计时长为5 min。</p>
                </div>
                <h4 class="anchor-tag" id="217" name="217">4.2.1 系统完成时延测试</h4>
                <div class="p1">
                    <p id="218">系统完成时延 (Complete Latency) 表示一个元组从Spout发射经拓扑中各层Bolt处理完成后最终被Spout中Acknowledgement机制确认的时间消耗, 反映了拓扑完整处理一个元组的响应时间, 刻画了拓扑的运行效率, 是评估集群性能的重要度量指标。图5统计了在Heron默认调度策略 (图例中Default) 和流分类调度策略 (图例中DSC-Heron) 下, 运行SentenceWordCount、WordCount和FileWordCount拓扑的系统完成时延。</p>
                </div>
                <div class="p1">
                    <p id="219">如图5所示, 三个测试拓扑从开始运行到触发DSC-Heron重调度 (130 s) 之前, 拓扑的任务分配均使用Heron默认的轮询调度策略。在0～20 s任务实例的启动阶段中, Spout尚未发射元组, 因此该阶段的系统完成时延为零。在其后阶段, 由于Spout缓存队列中出现元组拥塞, 拓扑运行处于波动状态, 系统完成时延出现较高的峰值。随着大量元组的被处理, 时延峰值结束, 三个测试拓扑在70 s左右逐渐趋于平稳。此时, 默认调度策略的调度过程已经结束, 而DSC-Heron在拓扑中部署的负载监测模块已经开始收集拓扑任务实例的CPU负载以及任务实例间数据流大小等数据, 为数据流的分类和任务实例的调度优化提供依据。</p>
                </div>
                <div class="p1">
                    <p id="220">图5 (a) 为在两种调度策略下运行SentenceWordCount时系统完成时延的对比情况。DSC-Heron在130 s时被触发, 此时拓扑停止运行并重新分配任务实例。任务实例的停止导致数据流传输的停止, 因此在130～185 s重调度时间段内系统完成时延无法监测。在重调度过程中, 对于重调度后仍位于原工作节点的任务实例, Heron保持其进程暂停状态而非终止Java进程, 而对于重新分配至不同工作节点的任务实例, 则需要终止原始任务进程重新创建。因此, 重调度之后的启动过程与拓扑初始启动过程不同:对于暂停状态的任务实例重新启动, 仅需要重新创建分配至不同工作节点中的任务实例进程。DSC-Heron在190 s时完成拓扑的重新启动, 运行稳定后的系统完成时延相对于Heron默认调度策略降低约8.45%。</p>
                </div>
                <div class="p1">
                    <p id="221">图5 (b) 反映了WordCount拓扑在默认和DSC-Heron调度策略下的运行情况, 其中初始启动和重调度过程与SentenceWordCount相同。重调度完成后, 系统完成时延相对于默认调度策略降低约5.10%。相对于WordCount拓扑, DSC-Heron能够较好地降低SentenceWordCount拓扑运行时延的原因主要是:1) SentenceWordCount的三层结构使得拓扑的数据流在工作节点间的分布较分散且高频流簇规模较大;2) 流簇分配算法可以更好地将高频流簇整体调度到同一工作节点中, 从而将更多的节点间通信转换为节点内通信, 更大程度上降低了拓扑整体通信开销。</p>
                </div>
                <div class="p1">
                    <p id="222">图5 (c) 中描述了FileWordCount在默认调度策略和DSC-Heron下的运行情况。FileWordCount具有与SentenceWord Count相同的拓扑结构, 但数据源采用真实的文本内容, 相对于随机生成单词的SentenceWordCount拓扑更接近真实应用场景。由于英文原著中包含单词的词频具有明显差异, 该拓扑运行时数据流大小之间差异较大, 因此节点间高频数据流对系统性能影响权重更大, 使得针对节点间数据流进行调度的流分类调度算法能够更好的发挥作用。重调度后系统完成时延相对于默认调度策略降低约11.5%。</p>
                </div>
                <div class="p1">
                    <p id="223">综上所述, DSC-Heron在三个拓扑测试中均可以降低系统完成时延, 系统完成时延平均下降了8.35%。对于结构较为简单且数据流大小差异不大的WordCount拓扑, 该策略对系统性能的优化效果较弱;但对于三层结构的SentenceWordCount和FileWordCount, 由于节点间数据流数量的增加以及流簇规模的扩大, DSC-Heron表现出较好的优化效果。其中对于较接近真实应用场景的FileWordCount拓扑, 英语原著中词频的差异导致拓扑中数据流大小差异较大, 高频数据流对集群性能影响更加突出且流分类算法对数据流的分类更加明确, 使得DSC-Heron对该拓扑的优化效果在三个测试拓扑中最为明显。</p>
                </div>
                <h4 class="anchor-tag" id="224" name="224">4.2.2 通信开销测试</h4>
                <div class="p1">
                    <p id="225">由第1章Heron任务实例分配模型提出的三种任务间通信方式可知, 节点间通信开销最大, 实例间通信开销最小, 同时实验中每个容器运行在一个工作节点中从而消除容器间通信。因此根据最优通信开销模型, 节点间数据流大小可以作为衡量集群性能的另一项指标。图6为三个测试拓扑分别使用默认调度策略和DSC-Heron运行时单位时间内节点间元组传输总量变化情况。</p>
                </div>
                <div class="p1">
                    <p id="226">如图6所示, 在重调度触发之前, 两策略均采用默认轮询调度算法进行任务分配, 因此表现出的节点间数据流变化趋势大致相同。其中与系统完成时延相同, 0～20 s时间段内由于任务实例尚未完全启动, 导致节点间数据流大小也为零。DSC-Heron的重调度均触发在130 s, 该时间与图5中系统完成延迟的重调度触发时间一致。</p>
                </div>
                <div class="p1">
                    <p id="227">图6 (a) 、 (b) 分别反映了SentenceWordCount和Word Count拓扑运行时节点间数据流大小的变化情况。DSC-Heron重调度完成后, 两拓扑的节点间数据流大小稳定值较默认调度策略分别降低约7.2%和3.2%。对比这两个拓扑, DSC-Heron对SentenceWordCount节点间数据流大小的优化较为明显的原因与拓扑结构和组件并行度相关, 在表2所示组件并行度的条件下, WordCount两层的结构在拓扑实例模型中所包含的数据流数量较少 (128条) , 同时高频流簇的规模最多为2, 使得DSC-Heron在执行上有一定的局限性。而SentenceWordCount三层的结构包含了更多的数据流 (140条) , 使拓扑任务分配后处于节点间的数据流数量较多, 因此DSC-Heron在针对节点间数据流进行优化时, 对SentenceWordCount拓扑的优化效果较好。</p>
                </div>
                <div class="p1">
                    <p id="228">FileWordCount拓扑的节点间数据流大小情况如图6 (c) 所示, 运行DSC-Heron时的节点间数据流大小较默认调度策略降低约10.8%, 三个拓扑测试中节点间数据流大小平均下降了7.07%。由此可知, 与DSC-Heron能够更有效地降低FileWordCount的系统完成时延相同, 在具有较大数据流差异的仿真应用场景下, DSC-Heron能够更加有效地优化拓扑节点间通信开销。</p>
                </div>
                <div class="area_img" id="229">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 两种调度策略下系统完成时延对比" src="Detail/GetImg?filename=images/JSJY201904028_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 两种调度策略下系统完成时延对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Comparison of system complete latency between default and DSC-Heron strategy</p>

                </div>
                <div class="area_img" id="230">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 两种调度策略下拓扑节点间通信开销对比" src="Detail/GetImg?filename=images/JSJY201904028_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 两种调度策略下拓扑节点间通信开销对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Comparison of inter-node communication overhead between default and DSC-Heron strategy</p>

                </div>
                <h4 class="anchor-tag" id="231" name="231">4.2.3 集群资源负载测试</h4>
                <div class="p1">
                    <p id="232">本节讨论DSC-Heron对集群各工作节点CPU和内存资源利用率的负载均衡优化效果。如图7所示, 为FileWordCount拓扑在默认调度策略和DSC-Heron下运行稳定时, 集群中6个工作节点的CPU和内存资源占用情况。</p>
                </div>
                <div class="area_img" id="233">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904028_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 两种调度策略下FileWordCount拓扑工作节点资源利用率对比" src="Detail/GetImg?filename=images/JSJY201904028_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 两种调度策略下FileWordCount拓扑工作节点资源利用率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904028_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison of CPU and RAM utilization on FileWordCount between default and DSC-Heron strategy</p>

                </div>
                <div class="p1">
                    <p id="234">如图7所示, FileWordCount拓扑在两种调度策略运行稳定时, 两种资源都没有出现超出设定资源阈值的情况。其中, 默认调度策略进行任务实例分配时不考虑实际运行的负载情况, 容易导致集群中工作节点负载不均衡从而影响集群性能;而DSC-Heron在优先考虑最小化节点间通信开销的同时, 将无法满足资源约束模型的高频数据流关联的部分任务实例, 以及中低频数据流关联的任务实例根据节点负载情况均匀地分配至各工作节点中, 使任务分配在满足集群资源约束模型的基础上均衡工作节点负载。因此在图7中, 由于DSC-Heron对任务实例的重新分配, 降低了工作节点3、4的资源占用率, 同时均衡地提高了工作节点2、5的资源占用。根据实验数据, FileWordCount拓扑在默认调度策略和DSC-Heron下分别运行时, 工作节点CPU利用率的标准差分别为0.040和0.010, 内存利用率的标准差分别为0.054和0.016, 两种资源利用率的标准差分别下降了75.00%和70.37%。此外在两种调度策略下运行WordCount拓扑时, CPU和内存资源利用率标准差分别下降了6.45%和14.29%;运行SentenceWordCount拓扑时, CPU和内存资源利用率标准差分别下降了42.86%和39.02%;三个测试拓扑CPU和内存资源利用率平均分别下降了41.44%和41.23%。由此可见, DSC-Heron在运行三种测试拓扑时, 均可以优化集群工作节点的负载均衡。但由于WordCount拓扑的数据流差异较小和高频流簇规模的限制, DSC-Heron在对该拓扑的优化效果较另外两个拓扑弱, 而对数据流差异较大且拓扑结构较复杂的FileWordCount拓扑优化最为有效。</p>
                </div>
                <h4 class="anchor-tag" id="235" name="235">4.2.4 系统吞吐量测试</h4>
                <div class="p1">
                    <p id="236">流式计算系统的吞吐量描述了系统单位时间内成功处理的数据元组数量, 是衡量系统性能的一项重要指标。表5即为在Heron默认调度策略和DSC-Heron下, SentenceWord Count、WordCount和FileWordCount三个测试拓扑分别运行时的系统吞吐量对比情况。</p>
                </div>
                <div class="area_img" id="237">
                    <p class="img_tit"><b>表</b>5 <b>两种调度策略下测试拓扑的系统吞吐量对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 5 Comparison of system throughput between default and DSC-Heron strategy</p>
                    <p class="img_note"></p>
                    <table id="237" border="1"><tr><td rowspan="2"><br />测试拓扑</td><td colspan="2"><br />系统吞吐量/ (10<sup>6</sup>tuples·min<sup>-1</sup>) </td></tr><tr><td><br />Default</td><td>DSC-Heron</td></tr><tr><td><br />SentenceWordCount</td><td>10.48</td><td>11.09</td></tr><tr><td><br />WordCount</td><td>14.46</td><td>14.87</td></tr><tr><td><br />FileWordCount</td><td>11.57</td><td>12.94</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="238">从表5可看出:由于WordCount拓扑中Spout组件的并行度设置为8, 比SentenceWordCount和FileWordCount拓扑中Spout组件的任务实例数量多一倍, 因此WordCount拓扑运行时的吞吐量比SentenceWordCount和FileWordCount的吞吐量高;但由于该拓扑结构和数据流的随机化限制, 使得拓扑在使用DSC-Heron运行时, 系统完成时延和节点间数据流大小较默认调度策略优化均较弱, 相应的系统吞吐量较默认调度策略的提高在三个测试拓扑中最小, 吞吐量提高了约2.84%。SentenceWordCount和FileWordCount具有相同的拓扑结构, 其主要区别在于前者采用随机化的数据作为输入, 而后者采用真实的英文文学作品为数据源, 因此FileWordCount较SentenceWordCount中各数据流大小差距较为明显, 使得在运行FileWordCount拓扑时, 数据流分类模型能够更好区分高频、中频和低频数据流, 流分类调度算法能够更多地将节点间高频数据流转换为节点内数据流, 因此对该拓扑吞吐量的优化效果较为明显。实验结果表明, 使用DSC-Heron运行SentenceWordCount和FileWordCount拓扑时, 系统吞吐量较默认调度策略分别提高了约5.82%、11.84%, 三个测试拓扑的吞吐量平均优化率为6.83%。由此可见, DSC-Heron在运行接近真实应用场景的FileWordCount拓扑时性能优化较为显著, 该策略在接近真实应用场景下具有一定的有效性。</p>
                </div>
                <h3 id="239" name="239" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="240">新一代流式计算框架Heron的调度策略默认采用轮询调度算法, 该算法在对任务分配的过程中仅考虑资源的可满足性, 忽略了拓扑本身的逻辑结构以及各任务间不同通信方式对系统性能的影响。针对该问题, 本文首先根据Heron任务分配机制建立作业模型, 明确拓扑中三种通信方式的通信开销差异;然后提出流分类模型及流簇概念, 通过实时监测拓扑运行情况对数据流进行分类;进而提出流分类调度策略 (DSC-Heron) , 使其在满足资源约束条件的基础上, 将拓扑中高频数据流及流簇作为整体尽可能地调度至同一工作节点, 以最小化节点间数据流从而最优化拓扑整体通信开销, 提高Heron集群运行效率。最后通过与Heron默认调度策略对比, 在系统完成时延、节点间通信开销、集群工作节点资源负载以及系统吞吐量四个方面论证了流分类调度策略的有效性。</p>
                </div>
                <div class="p1">
                    <p id="241">下一步研究工作主要包括以下两个方面: 1) 针对集群资源利用率, 实验中为消除容器间通信开销, 每个工作节点只分配一个容器, 这种分配方式容易造成集群资源浪费。如何在加入容器间通信方式的同时, 进一步优化通信开销是下一步的研究内容。2) 通过实验发现, Heron系统中的在线重调度时间间隔在60 s左右, 这对实时性要求较高的流处理系统来说时间较长, 因此下一步将研究如何缩短重调度的时间间隔, 使其更好地适用于真实应用场景。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="273">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSJU201503008&amp;v=MDQzNTdCdEdGckNVUjdxZlp1WnNGeURnVzd2T0lUN0JlN0c0SDlUTXJJOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>孙大为.大数据流式计算:应用特征和技术挑战[J].大数据, 2015, 1 (3) :99-105. (SUN D W.Big data stream computing:features and challenges[J].Big Data Research, 2015, 1 (3) :99-105.) 
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Data age 2025">

                                <b>[2]</b>Seagate.Data age 2025[EB/OL].[2018-08-10].https://www.seagate.com/files/www-content/our-story/trends/files/data-age-2025-white-paper-simplified-chinese.pdf.
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201404011&amp;v=MDIxMjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGdXN3ZPTnlmVGJMRzRIOVhNcTQ5RVpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>孙大为, 张广艳, 郑纬民.大数据流式计算:关键技术及系统实例[J].软件学报, 2014, 25 (4) :839-862. (SUN D W, ZHANGG Y, ZHENG W M.Big data stream computing:technologies and instances[J].Journal of Software, 2014, 25 (4) :839-862.) 
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Storm@twitter">

                                <b>[4]</b>TOSHNIWAL A, TANEJA S, SHUKLA A, et al.Storm@Twitter[C]//Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data.New York:ACM, 2014:147-156.
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apache flink:Stream and batch processing in a single engine">

                                <b>[5]</b>CARBONE P, EWEN S, HARIDI S, et al.Apache Flink<sup>TM</sup>:stream and batch processing in a single engine[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 36 (4) :28-38.
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive online scheduling in storm">

                                <b>[6]</b>ANIELLO L, BALDONI R, QUERZONI L.Adaptive online scheduling in Storm[C]//Proceedings of the 7th ACM International Conference on Distributed Event-Based Systems.New York:ACM, 2013:207-218.
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=T-Storm:Traffic-Aware Online Scheduling in Storm">

                                <b>[7]</b>XU J L, CHEN Z H, TANG J, et al.T-Storm:traffic-aware online scheduling in Storm[C]//Proceedings of the 34th IEEE International Conference on Distributed Computing Systems.Piscataway, NJ:IEEE, 2014:535-544.
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=R-Storm:resource-aware scheduling in Storm">

                                <b>[8]</b>PENG B Y, HOSSEINI M, HONG Z H, et al.R-Storm:resourceaware scheduling in Storm[C]//Proceedings of the 16th Annual Middleware Conference.New York:ACM, 2015:149-161.
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801005&amp;v=MjQwNjhIOW5Ncm85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGdXN3ZPTHl2U2RMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>鲁亮, 于炯, 卞琛, 等.大数据流式计算框架Storm的任务迁移策略[J].计算机研究与发展, 2018, 55 (1) :71-92. (LU L, YU J, BIAN C, et al.A task migration strategy in big data stream computing with Storm[J].Journal of Computer Research and Development, 2018, 55 (1) :71-92.) 
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201809021&amp;v=MTEyODNCZDdHNEg5bk1wbzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEZ1c3dk9Mejc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>李梓杨, 于炯, 卞琛, 等.基于流网络的流式计算动态任务调度策略[J].计算机应用, 2018, 38 (9) :2560-2567. (LI Z Y, YU J, BIAN C, et al.Dynamic task dispatching strategy for stream processing based on flow network[J].Journal of Computer Applications, 2018, 38 (9) :2560-2567.) 
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3D7110A41C2D882EABC09C4CF2C32182&amp;v=MDM3NDBJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh6TDIzeEs0PU5pZk9mYkRNR2RETnIvNUJaWmdOZUhReHpXTmltRXg5UVF6bTMyUTNDckdXUkxLZENPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>de ASSUNCAO M D, da SILVA VEITH A, BUYYA R.Distributed data stream processing and edge computing:a survey on resource elasticity and future directions[J].Journal of Network&amp;Computer Applications, 2018, 103:1-17.
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0407B1978491A0282F84BD1AF94D7991&amp;v=MDQ2OTA0PU5pZk9mYk84SHRhK3JvWkNiTzhHRFEwNXpSNFJuRGQ1T2d2ajNXUThmY2FUVExPZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHpMMjN4Sw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>SHUKLA A, SIMMHAN Y.Model-driven scheduling for distributed stream processing systems[J].Journal of Parallel&amp;Distributed Computing, 2018, 117:98-114.
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting the stability of large-scale distributed stream processing systems on the cloud">

                                <b>[13]</b>TRUONG T M, HARWOOD A, SINNOTT R O.Predicting the stability of large-scale distributed stream processing systems on the cloud[C]//Proceedings of the 7th International Conference on Cloud Computing and Services Science.Piscataway, NJ:IEEE, 2017:603-610.
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A stable online scheduling strategy for real-time stream computing over fluctuating big data streams">

                                <b>[14]</b>SUN D, HUANG R.A stable online scheduling strategy for realtime stream computing over fluctuating big data streams[J].IEEEAccess, 2016, 4:8593-8607.
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Twitter heron:Stream processing at scale">

                                <b>[15]</b>KULKARNI S, BHAGAT N, FU M, et al.Twitter Heron:stream processing at scale[C]//Proceedings of the 2015 ACM SIGMODInternational Conference on Management of Data.New York:ACM, 2015:239-250.
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Streaming@Twitter">

                                <b>[16]</b>FU M, MITTAL S, KEDIGEHALLI V, et al.Streaming@Twitter[J].Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2015, 38 (4) :15-27.
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Twitter Heron:towards extensible streaming engines">

                                <b>[17]</b>FU M, AGRAWAL A, FLORATOU A, et al.Twitter Heron:towards extensible streaming engines[C]//Proceedings of the2017 IEEE 33rd International Conference on Data Engineering.Piscataway, NJ:IEEE, 2017:35-44.
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apache Aurora">

                                <b>[18]</b>Apache.Apache Aurora[EB/OL].[2018-08-10].http://aurora.apache.org.
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mesos:A Platform for Fine-Grained Resource Sharing in the Data Center">

                                <b>[19]</b>HINDMAN B, KONWINSKI A, ZAHARIA M, et al.Mesos:a platform for fine-grained resource sharing in the data center[C]//Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation.Berkeley:USENIX Association, 2010:429-483.
                            </a>
                        </p>
                        <p id="311">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apache Hadoop YARN:yet another resource negotiator">

                                <b>[20]</b>VAVILAPALLI V K, MURTHY A C, AGARWAL S, et al.Apache Hadoop YARN:yet another resource negotiator[C]//Proceedings of the 4th Annual Symposium on Cloud Computing.New York:ACM, 2013:5.
                            </a>
                        </p>
                        <p id="313">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kafka:a distributed messaging system for log processing">

                                <b>[21]</b>KREPS J, NARKHEDE N, RAO J.Kafka:a distributed messaging system for log processing[EB/OL].[2018-05-10].http://pages.cs.wisc.edu/~akella/CS744/F17/838-Cloud Papers/Kafka.pdf.
                            </a>
                        </p>
                        <p id="315">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apache Distributed Log">

                                <b>[22]</b>Apache.Apache Distributed Log[EB/OL].[2018-05-10].http://bookkeeper.apache.org/distributedlog/.
                            </a>
                        </p>
                        <p id="317">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Implementing a custom scheduler">

                                <b>[23]</b>Twitter.Implementing a custom scheduler[EB/OL].[2018-05-10].https://apache.github.io/incubator-heron/docs/contributors/custom-scheduler/.
                            </a>
                        </p>
                        <p id="319">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apache/incubator-heron">

                                <b>[24]</b>KULKARNI S.Apache/incubator-heron[EB/OL].[2018-05-16].https://github.com/apache/incubator-heron.
                            </a>
                        </p>
                        <p id="321">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low latency stream processing:Apache Heron with Infiniband&amp;amp;Intel Omni-Path">

                                <b>[25]</b>KAMBURUGAMUVE S, RAMASAMY K, SWANY M, et al.Low latency stream processing:Apache Heron with Infiniband&amp;Intel Omni-Path[C]//Proceedings of the 10th International Conference on Utility and Cloud Computing.New York:ACM, 2017:101-110.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904028" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904028&amp;v=MjgyODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGdXN3ZQTHo3QmQ3RzRIOWpNcTQ5SGJJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
