<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136481929033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909038%26RESULT%3d1%26SIGN%3dSAdF9S2sSqBbBoj58aae1VfaMjY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909038&amp;v=MDAwNDFyQ1VSN3FmWnVac0Z5am5WTHpCTHo3QmQ3RzRIOWpNcG85R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="1.1 LIOP&lt;b&gt;描述子&lt;/b&gt;">1.1 LIOP<b>描述子</b></a></li>
                                                <li><a href="#66" data-title="1.2 &lt;b&gt;基于&lt;/b&gt;NSCT&lt;b&gt;的多支持区域&lt;/b&gt;LIOP&lt;b&gt;描述子&lt;/b&gt;">1.2 <b>基于</b>NSCT<b>的多支持区域</b>LIOP<b>描述子</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="2 本文方法 ">2 本文方法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#104" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#114" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#65" data-title="图1 旋转不变坐标系下的邻域点">图1 旋转不变坐标系下的邻域点</a></li>
                                                <li><a href="#71" data-title="图2 非抽样Contourlet变换">图2 非抽样Contourlet变换</a></li>
                                                <li><a href="#73" data-title="图3 利用NSCT产生的多支持区域">图3 利用NSCT产生的多支持区域</a></li>
                                                <li><a href="#103" data-title="图4 图像复制-粘贴伪造检测算法过程">图4 图像复制-粘贴伪造检测算法过程</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;图像复制-粘贴伪造检测算法性能比较&lt;/b&gt;"><b>表</b>1 <b>图像复制-粘贴伪造检测算法性能比较</b></a></li>
                                                <li><a href="#113" data-title="图5 图像复制-粘贴伪造实例的检测结果">图5 图像复制-粘贴伪造实例的检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="141">


                                    <a id="bibliography_1" title=" REDI J A,TAKTAK W,DUGELAY J.Digital image forensics:a booklet for beginners [J].Multimedia Tools and Applications,2011,51(1):133-162." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Digital image forensics: a booklet for beginners">
                                        <b>[1]</b>
                                         REDI J A,TAKTAK W,DUGELAY J.Digital image forensics:a booklet for beginners [J].Multimedia Tools and Applications,2011,51(1):133-162.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_2" title=" 周萌萌,杨鸿波,高晶敏,等.基于快速分块的复制-粘贴图像检测算法[J].计算机应用,2016,36(S1):117-121.(ZHOU M M,YANG H B,GAO J M,et al.Copy-move image detection algorithm based on fast blocking[J].Journal of Computer Applications,2016,36(S1):117-121.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2016S1030&amp;v=MTg0NjdmWnVac0Z5am5WTHpCTHo3QmQ3RzRIOWV2cm85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         周萌萌,杨鸿波,高晶敏,等.基于快速分块的复制-粘贴图像检测算法[J].计算机应用,2016,36(S1):117-121.(ZHOU M M,YANG H B,GAO J M,et al.Copy-move image detection algorithm based on fast blocking[J].Journal of Computer Applications,2016,36(S1):117-121.)
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_3" title=" CHRISTLEIN V,RIESS C,JORDAN J,et al.An evaluation of popular copy-move forgery detection approaches [J].IEEE Transactions on Information Forensics and Security,2012,7(6):1841-1854." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Evaluation of Popular Copy-Move Forgery Detection Approaches">
                                        <b>[3]</b>
                                         CHRISTLEIN V,RIESS C,JORDAN J,et al.An evaluation of popular copy-move forgery detection approaches [J].IEEE Transactions on Information Forensics and Security,2012,7(6):1841-1854.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_4" title=" AMERINI I,BALLAN L,CALDELLI R,et al.A SIFT-based forensic method for copy-move attack detection and transformation recovery [J].IEEE Transactions on Information Forensics and Security,2011,6(3):1099-1110." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A SIFT-Based Forensic Method for Copy–Move Attack Detection and Transformation Recovery">
                                        <b>[4]</b>
                                         AMERINI I,BALLAN L,CALDELLI R,et al.A SIFT-based forensic method for copy-move attack detection and transformation recovery [J].IEEE Transactions on Information Forensics and Security,2011,6(3):1099-1110.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_5" title=" LI J,LI X,YANG B,et al.Segmentation-based image copy-move forgery detection scheme [J].IEEE Transactions on Information Forensics and Security,2015,10(3):507-518." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation-based image copy-move forgery detection scheme">
                                        <b>[5]</b>
                                         LI J,LI X,YANG B,et al.Segmentation-based image copy-move forgery detection scheme [J].IEEE Transactions on Information Forensics and Security,2015,10(3):507-518.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_6" title=" RYU S,KIRCHNER M,LEE M,et al.Rotation invariant localization of duplicated image regions based on zernike moments [J].IEEE Transactions on Information Forensics and Security,2013,8(8):1355-1370." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rotation invariant localization of duplicated image regions based on Zernike moments">
                                        <b>[6]</b>
                                         RYU S,KIRCHNER M,LEE M,et al.Rotation invariant localization of duplicated image regions based on zernike moments [J].IEEE Transactions on Information Forensics and Security,2013,8(8):1355-1370.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_7" title=" 林晶,黄添强,赖玥聪,等.采用量化离散余弦变换系数检测视频单帧连续多次复制粘贴篡改[J].计算机应用,2016,36(5):1356-1361.(LIN J,HUANG T Q,LAI Y C,et al.Detection of continuously and repeated copy-move forgery to single frame in videos by quantized DCT coefficients [J].Journal of Computer Applications,2016,36(5):1356-1361.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201605035&amp;v=MDYzMzR6cXFCdEdGckNVUjdxZlp1WnNGeWpuVkx6Qkx6N0JkN0c0SDlmTXFvOUdZWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         林晶,黄添强,赖玥聪,等.采用量化离散余弦变换系数检测视频单帧连续多次复制粘贴篡改[J].计算机应用,2016,36(5):1356-1361.(LIN J,HUANG T Q,LAI Y C,et al.Detection of continuously and repeated copy-move forgery to single frame in videos by quantized DCT coefficients [J].Journal of Computer Applications,2016,36(5):1356-1361.)
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_8" title=" ZIMBA M,SUN X.DWT-PCA (EVD) based copy-move image forgery detection [J].International Journal of Digital Content Technology and Its Applications,2011,5(1):251-258." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQDEF87C5FC447D7047F3F5A6F987C74593&amp;v=MjY1MDBhc2JPRnRhL3F2azJZTzhJZUhzNXl4Rmw2VWw0T1htVXBSb3lDcldRUUxPY0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMcTR3NkU9TmozYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         ZIMBA M,SUN X.DWT-PCA (EVD) based copy-move image forgery detection [J].International Journal of Digital Content Technology and Its Applications,2011,5(1):251-258.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_9" title=" KANG X,WEI S.Identifying tampered regions using singular value decomposition in digital image forensics [C]// Proceedings of the 2008 International Conference on Computer Science and Software Engineering.Piscataway,NJ:IEEE,2008:926-930." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Identifying Tampered Regions Using Singular Value Decomposition in Digital Image Forensics">
                                        <b>[9]</b>
                                         KANG X,WEI S.Identifying tampered regions using singular value decomposition in digital image forensics [C]// Proceedings of the 2008 International Conference on Computer Science and Software Engineering.Piscataway,NJ:IEEE,2008:926-930.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_10" title=" KAKAR P,SUDHA N.Exposing postprocessed copy-paste forgeries through transform-invariant features [J].IEEE Transactions on Information Forensics and Security,2012,7(3):1018-1028." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exposing postprocessed copy-paste forgeries through transform-invariant features">
                                        <b>[10]</b>
                                         KAKAR P,SUDHA N.Exposing postprocessed copy-paste forgeries through transform-invariant features [J].IEEE Transactions on Information Forensics and Security,2012,7(3):1018-1028.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_11" title=" 柴建伟,刘婷.改进的SIFT耦合特征点集群的图像伪造检测算法[J].西南师范大学学报(自然科学版),2018,43(3):34-41.(CHAI J W,LIU T.Image forgery detection algorithm based on improved SIFT coupled feature point clustering [J].Journal of Southwest China Normal University (Natural Science Edition),2018,43(3):34-41.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201803006&amp;v=MTkxNjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WTHpCUFNQUlpiRzRIOW5Nckk5RllvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         柴建伟,刘婷.改进的SIFT耦合特征点集群的图像伪造检测算法[J].西南师范大学学报(自然科学版),2018,43(3):34-41.(CHAI J W,LIU T.Image forgery detection algorithm based on improved SIFT coupled feature point clustering [J].Journal of Southwest China Normal University (Natural Science Edition),2018,43(3):34-41.)
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_12" title=" SHIVAKUMAR B L,BABOO S S.Detection of region duplication forgery in digital images using SURF [J].International Journal of Computer Science Issues,2011,8(4):199-205." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00004593895&amp;v=MTU3MjRSN3FkWitadUZpcmxVNzNQSTFjPU5qM2Fhck80SHRISXFvWkdiT0lLWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         SHIVAKUMAR B L,BABOO S S.Detection of region duplication forgery in digital images using SURF [J].International Journal of Computer Science Issues,2011,8(4):199-205.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_13" title=" 陈辉映,张大兴,杨珊珊,等.基于SURF的图像多区域复制粘贴篡改检测[J].计算机工程与设计,2018,39(8):2593-2597.(CHEN H Y,ZHANG D X,YANG S S,et al.Image multiple copy-move forgery detection based on SURF algorithm [J].Computer Engineering and Design,2018,39(8):2593-2597.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201808034&amp;v=MTE0NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZMekJOaWZZWkxHNEg5bk1wNDlHWUk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         陈辉映,张大兴,杨珊珊,等.基于SURF的图像多区域复制粘贴篡改检测[J].计算机工程与设计,2018,39(8):2593-2597.(CHEN H Y,ZHANG D X,YANG S S,et al.Image multiple copy-move forgery detection based on SURF algorithm [J].Computer Engineering and Design,2018,39(8):2593-2597.)
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_14" title=" WANG Z,FAN B,WU F.Local intensity order pattern for feature description [C]// Proceedings of the 2011 International Conference on Computer Vision.Piscataway,NJ:IEEE,2011:603-610." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local intensity order pattern for feature description">
                                        <b>[14]</b>
                                         WANG Z,FAN B,WU F.Local intensity order pattern for feature description [C]// Proceedings of the 2011 International Conference on Computer Vision.Piscataway,NJ:IEEE,2011:603-610.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_15" title=" 邹玮刚,周志辉,王洋.基于非降采样轮廓波变换的图像修复算法[J].计算机应用,2017,37(2):553-558.(ZOU W G,ZHOU Z H,WANG Y.Image inpainting algorithm based on non-subsampled contourlet transform [J].Journal of Computer Applications,2017,37(2):553-558.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201702044&amp;v=MjkzNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZMekJMejdCZDdHNEg5Yk1yWTlCWUk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         邹玮刚,周志辉,王洋.基于非降采样轮廓波变换的图像修复算法[J].计算机应用,2017,37(2):553-558.(ZOU W G,ZHOU Z H,WANG Y.Image inpainting algorithm based on non-subsampled contourlet transform [J].Journal of Computer Applications,2017,37(2):553-558.)
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_16" title=" MATAS J,CHUM O,URBAN M,et al.Robust wide-baseline stereo from maximally stable extremal regions [J].Image and Vision Computing,2004,22(10):761-767." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349782&amp;v=MjY5NjIvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlGd1RhUnM9TmlmT2ZiSzdIdERPclk5RVorOEdDM1E3b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         MATAS J,CHUM O,URBAN M,et al.Robust wide-baseline stereo from maximally stable extremal regions [J].Image and Vision Computing,2004,22(10):761-767.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_17" title=" FAN B,WU F,HU Z.Rotationally invariant descriptors using intensity order pooling [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2012,34(10):2031-2045." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rotationally Invariant Descriptors Using Intensity Order Pooling">
                                        <b>[17]</b>
                                         FAN B,WU F,HU Z.Rotationally invariant descriptors using intensity order pooling [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2012,34(10):2031-2045.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_18" title=" 勾承甫,陈斌,赵雪专,等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用,2016,36(9):2566-2569.(GOU C F,CHEN B,ZHAO X Z,et al.Object tracking algorithm based on random sampling consensus estimation[J].Journal of Computer Applications,2016,36(9):2566-2569.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201609040&amp;v=MjQ0NjRSN3FmWnVac0Z5am5WTHpCTHo3QmQ3RzRIOWZNcG85QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         勾承甫,陈斌,赵雪专,等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用,2016,36(9):2566-2569.(GOU C F,CHEN B,ZHAO X Z,et al.Object tracking algorithm based on random sampling consensus estimation[J].Journal of Computer Applications,2016,36(9):2566-2569.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-17 15:29</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2707-2711 DOI:10.11772/j.issn.1001-9081.2019020306            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多支持区域局部亮度序的图像伪造检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A2%9C%E6%99%AE&amp;code=41326532&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜普</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%8F%E4%BA%AE%E4%BA%AE&amp;code=40542959&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏亮亮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B5%E6%85%A7&amp;code=33807945&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邵慧</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E4%B8%9C%E5%8D%87&amp;code=33808239&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴东升</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%99%BA%E8%83%BD%E5%BB%BA%E7%AD%91%E4%B8%8E%E5%BB%BA%E7%AD%91%E8%8A%82%E8%83%BD%E5%AE%89%E5%BE%BD%E7%9C%81%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%AE%89%E5%BE%BD%E5%BB%BA%E7%AD%91%E5%A4%A7%E5%AD%A6)&amp;code=0836967&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智能建筑与建筑节能安徽省重点实验室(安徽建筑大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%89%E5%BE%BD%E5%BB%BA%E7%AD%91%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">安徽建筑大学电子与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>图像伪造检测是目前数字图像处理领域中的一个研究热点,其中复制-粘贴是最常用的伪造手段。由于伪造区域在粘贴前会被进行一定的尺度、旋转、JPEG压缩、添加噪声等操作,这使得检测伪造区域具有一定的挑战性。针对图像复制-粘贴伪造技术,提出一种基于多支持区域局部亮度序模式(LIOP)的图像伪造检测算法。首先,利用最大稳定极值区域(MSER)算法提取具有仿射不变性的区域作为支持区域;其次,利用非抽样Contourlet变换得到不同尺度、不同分辨率和不同方向的多个支持区域;然后,在每个支持区域上提取同时具有旋转不变性和单调亮度不变性的LIOP描述子,并利用双向距离比值法实现特征初匹配;接着,采用空间聚类将匹配的特征进行归类,进而用随机抽样一致性(RANSAC)算法对每个归类进行几何变换参数估计;最后,使用必要的后处理等操作来检测出伪造区域。实验表明,提出的算法具有较高的伪造检测精度与可信度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像伪造;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%8D%E5%88%B6-%E7%B2%98%E8%B4%B4%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">复制-粘贴检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%94%AF%E6%8C%81%E5%8C%BA%E5%9F%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多支持区域;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E6%8A%BD%E6%A0%B7Contourlet%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非抽样Contourlet变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E4%BA%AE%E5%BA%A6%E5%BA%8F%E6%A8%A1%E5%BC%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部亮度序模式;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    颜普(1986—),男,安徽亳州人,讲师,博士,CCF会员,主要研究方向:计算机视觉、模式识别;;
                                </span>
                                <span>
                                    *苏亮亮(1986—),男,安徽安庆人,讲师,博士,CCF会员,主要研究方向:视频图像处理、模式识别;电子邮箱yanpu8188@163.com;
                                </span>
                                <span>
                                    邵慧(1979—),女,安徽长丰人,副教授,博士,主要研究方向:机器学习、图像处理;;
                                </span>
                                <span>
                                    吴东升(1966—),男,安徽枞阳人,教授,博士,主要研究方向:电磁场理论、数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61672032);</span>
                                <span>安徽省自然科学基金资助项目(1908085QF281);</span>
                                <span>安徽建筑大学博士科研启动基金资助项目(2017QD13,2015QD07);</span>
                    </p>
            </div>
                    <h1><b>Image forgery detection based on local intensity order and multi-support region</b></h1>
                    <h2>
                    <span>YAN Pu</span>
                    <span>SU Liangliang</span>
                    <span>SHAO Hui</span>
                    <span>WU Dongsheng</span>
            </h2>
                    <h2>
                    <span>Anhui Provincial Key Laboratory of Intelligent Building and Building Energy Conservation (Anhui Jianzhu University)</span>
                    <span>College of Electronic and Information Engineering, Anhui Jianzhu University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Image forgery detection is currently one of the research focuses of digital image processing, and copy-move forgery is the most frequently used techniques in it. The forgery region is subjected to the operations of scale, rotation, JPEG compression, adding noise and so on before the image moved in, thus detecting the forgery becomes hard. Aimming at the image copy-move forgery technology, an image forgery detection algorithm based on Local Intensity Order Pattern(LIOP) and multiple support regions was proposed. Firstly, the affine invariant regions were detected as support regions by Maximally Stable Extremal Region(MSER) algorithm. Secondly, multiple support regions of different scales, resolutions and directions were obtained by NonSubsampled Contourlet Transform(NSCT). Thirdly, the LIOP descriptors invariant to monotonic intensity change and image rotation were extracted on each support region, and the initial feature matching was implemented via bidirectional distance ratio method. Fourthly, spatial clustering was used to classify the matching features, and geometric transformation parameters were estimated for each cluster by using RANdom SAmple Consensus(RANSAC) algorithm. Finally, the essential operations like post-processing were performed to detect the forgery regions. The experimental results show that the proposed algorithm has higher forgery detection accuracy and reliability.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20forgery&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image forgery;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=copy-move%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">copy-move detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-support%20region&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-support region;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nonsubsampled%20Contourlet%20Transform(NSCT)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nonsubsampled Contourlet Transform(NSCT);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Local%20Intensity%20Order%20Pattern(LIOP)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Local Intensity Order Pattern(LIOP);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YAN Pu, born in 1986, Ph. D. , lecturer. His research interests include computer vision, pattern recognition. ;
                                </span>
                                <span>
                                    SU Liangliang, born in 1986, Ph. D. , lecturer. His research interests include video image processing, pattern recognition. ;
                                </span>
                                <span>
                                    SHAO Hui, born in 1979, Ph. D. , associate professor. Her research interests include machine learning, image processing. ;
                                </span>
                                <span>
                                    WU Dongsheng, born in 1966, Ph. D. , professor. His research interests include electromagnetic field theory, data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-02-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61672032);</span>
                                <span>the Natural Science Foundation of Anhui Province(1908085QF281);</span>
                                <span>the Doctoral Scientific Research Foundation of Anhui Jianzhu University(2017QD13,2015QD07);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">数字图像在当今通信过程中有着非常重要的角色。随着数字图像处理软件和修改设备的发展,数字图像可以轻易地被篡改而不留下任何明显的篡改痕迹<citation id="177" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,即使非专业人员都可以很容易利用图像编辑工具(如Photoshop)来修改已有图像。图像操控和伪造的数量也在快速增长,这给人们判断一幅图像的原创性和准确性带来极大的困扰,特别对判断司法鉴定中作为证据图像的真伪更加具有挑战性<citation id="178" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。 因此,鉴定图像是否被伪造是至关重要的,可以广泛应用在犯罪现场勘测、司法鉴定和许多其他领域<citation id="179" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="41">图像伪造检测技术是指在没有任何先验知识的情况下可以确认原始图像的可信度。常见的数字图像伪造方法有重采样、拼接、复制-粘贴等,其中复制-粘贴伪造是最简单和最常见的数字图像篡改方法。复制-粘贴伪造是指图像中任意形状和大小的区域被复制然后放置在图像的另一区域<citation id="180" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,其目的是通过增强图像的视觉效果来掩盖图像的重要数据或影响识别图像的真实目标<citation id="181" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。由于复制区域来自同一图像中,其本质属性如噪声、颜色、纹理等都和整体图像一致,这导致鉴别过程异常麻烦。同时复制区域在粘贴前会进行一定的尺度和旋转操作,这使得检测伪造区域具有一定的挑战性。</p>
                </div>
                <div class="p1">
                    <p id="42">近年来图像复制-粘贴伪造检测是图像鉴别中最活跃的研究课题之一。在过去的几十年里, 许多图像复制-粘贴伪造检测方法被提出,这些方法主要被归为两大分支:基于块的伪造检测和基于特征点的伪造检测<citation id="182" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。基于块的图像复制-粘贴伪造检测方法首先重叠划分图像得到重叠的图像块,然后对每个图像块进行特征提取,最后对相似区域进行排序来寻求伪造痕迹<citation id="183" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。在基于块的方法中,用于描述区域块的特征主要有离散余弦变换 (Discrete Cosine Transform,DCT)系数<citation id="184" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、矩不变量<citation id="185" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、离散小波变换 (Discrete Wavelet Transform,DWT)<sup></sup><citation id="186" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、奇异值分解(Singular Value Decomposition, SVD)<citation id="187" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>等特征。尽管这类方法对JPEG压缩、加性噪声和模糊变换是鲁棒的,但很难很好地处理尺度变换和旋转变换。</p>
                </div>
                <div class="p1">
                    <p id="43">另外,基于块的图像复制-粘贴伪造检测方法从任意重叠块区域来提取局部特征,这不仅导致这类方法具有较高的时间复杂度,而且往往会出现假阳性错误,很难构建对亮度区域不变的特征描述<citation id="188" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。因此,近年来基于特征点的图像复制-粘贴伪造检测方法越来越被重视,这类方法在许多图像变换下被证实具有更强的说服力。基于特征点的图像复制-粘贴伪造检测方法主要考虑特征点所在区域并利用特征描述子来表示可疑区域,常用的特征描述子有尺度不变特征变换(Scale-Invariant Feature Transform, SIFT)<citation id="190" type="reference"><link href="147" rel="bibliography" /><link href="161" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">11</a>]</sup></citation>和加速鲁棒特征(Speeded-Up Robust Feature, SURF) <citation id="191" type="reference"><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。然而这些方法为了使构建的特征描述子具有旋转不变性,必须计算支持区域的主方向并按照该方向对支持区域进行校正,这不仅大大增加了算法的计算复杂度,而且不可避免地会产生误差。此外,这些方法利用归一化操作使得构建的特征描述子对线性亮度变化具有一定的不变性,但却不能很好地处理非线性亮度变化问题(如单调亮度变化)<citation id="189" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">为了解决上述问题,提出了一种基于多尺度局部亮度序模式(Local Intensity Order Pattern, LIOP)的图像伪造检测算法。所使用的LIOP描述子利用全局亮度序对支持区域进行划分,这种划分不需要计算支持区域的主方向,不仅节约计算量,而且在理论上能够保证所构造描述子具有真正的旋转不变性。另外LIOP描述子利用局部亮度序对划分区域进行描述,以使LIOP描述子对图像单调亮度变化具有不变性。然而LIOP描述子是在单支持区域内构造的,单支持区域不足以保证后续的特征点匹配有很高的准确率,因此利用非抽样Contourlet变换(Nonsubsampled Contourlet Transform,NSCT)<citation id="192" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>得到不同尺度、不同分辨率和不同方向的多个支持区域来提高LIOP描述子的鉴别力。可见,所提算法创新点为:1)利用同时具有旋转不变性和单调亮度不变性的LIOP描述子进行图像伪造区域检测;2)利用NSCT得到不同尺度、不同分辨率和不同方向的多个支持区域来提高LIOP描述子的鉴别力,从而提高了图像伪造区域检测算法的鲁棒性。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 相关知识</h3>
                <h4 class="anchor-tag" id="46" name="46">1.1 LIOP<b>描述子</b></h4>
                <div class="p1">
                    <p id="47">图像伪造技术会让图像局部亮度模式发生改变,而LIOP是一种基于亮度序的图像局部特征描述子,LIOP使用了两种亮度序:全局亮度序和局部亮度序,全局亮度序用于划分检测区域,局部亮度序用于生成局部描述子。相对于传统描述子,LIOP描述子有众多优点。首先该描述子不需要计算支持区域的主方向,这不仅大大降低了计算量,而且大幅减小了因计算主方向产生的误差;其次该描述子具有真正的旋转不变性,而不是通过旋转支持区域的主方向而获得旋转不变性,对旋转变换更加鲁棒;最后该描述子是利用局部亮度序来构建特征描述向量,对非线性亮度变化(单调亮度变化)具有不变性,能很好地处理亮度变换问题。LIOP描述子主要分为预处理、特征区域检测、区域划分和特征描述子的构建。在本文中,预处理主要利用高斯滤波器消除噪声的影响。特征区域检测利用最大稳定极值区域(Maximally Stable Extremal Region, MSER)算法<citation id="193" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提取图像的最大稳定极值区域作为支持区域,该区域具有仿射不变性,这是SIFT和SURF算法所不具备的。为了后续检测伪造区域的需要,检测的特征点需要具有一定的密度,可通过调整MSER算法的区域最小尺寸参数来完成该过程。区域划分是对支持区域内所有亮度值进行非降排序,将支持区域按照亮度值大小等间隔地划分为<i>B</i>个子区域。</p>
                </div>
                <div class="p1">
                    <p id="48">划分区域后接下来便是计算LIOP描述子。对于一个特征点<i>X</i><sub>0</sub>,其支持区域是<i>R</i>,在该支持区域内任意一像素点<i>X</i>∈<i>R</i>,均可以建立一个旋转不变的坐标系,即以<mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>X</mi><msub><mrow></mrow><mn>0</mn></msub><mi>X</mi></mrow><mo stretchy="true">→</mo></mover></mrow></math></mathml>为<i>x</i>轴,垂直于<mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>X</mi><msub><mrow></mrow><mn>0</mn></msub><mi>X</mi></mrow><mo stretchy="true">→</mo></mover></mrow></math></mathml>为<i>y</i>轴,则在旋转不变坐标系下,在单位圆上以正<i>y</i>轴上为起点,等间隔得到像素点<i>X</i>的<i>N</i>个邻域点(即距离<i>X</i>最近的<i>N</i>个点),如图1所示,在旋转不变坐标系下得到<i>X</i>的4邻域,本文根据文献<citation id="194" type="reference">[<a class="sup">14</a>]</citation>的建议,设置邻域点个数为4。这<i>N</i>个邻域点的亮度值按照坐标轴逆时针顺序进行排序,得到<i>K</i>(<i>X</i>)=(<i>I</i>(<i>X</i><sub>1</sub>),<i>I</i>(<i>X</i><sub>2</sub>),…,<i>I</i>(<i>X</i><sub><i>N</i></sub>)),其中<i>X</i><sub>1</sub>,<i>X</i><sub>2</sub>,…,<i>X</i><sub><i>N</i></sub>是像素点<i>X</i>的<i>N</i>个邻域点,<i>I</i>(<i>X</i><sub>1</sub>),<i>I</i>(<i>X</i><sub>2</sub>),…,<i>I</i>(<i>X</i><sub><i>N</i></sub>)是<i>X</i><sub>1</sub>,<i>X</i><sub>2</sub>,…,<i>X</i><sub><i>N</i></sub>所对应的亮度值。定义一个映射<i>γ</i>:</p>
                </div>
                <div class="p1">
                    <p id="51"><i>γ</i>(<b><i>K</i></b>)=<i>π</i>; <b><i>K</i></b>∈<b><i>P</i></b><sup><i>N</i></sup>, <i>π</i>∈<i>Π</i><sup><i>N</i></sup>      (1)</p>
                </div>
                <div class="p1">
                    <p id="52">其中,<i>Π</i><sup><i>N</i></sup>是整数{1,2,…,<i>N</i>}所有可能的排列集合,<b><i>P</i></b><sup><i>N</i></sup>表示<i>N</i>维向量,这里<i>π</i>=(<i>i</i><sub>1</sub>,<i>i</i><sub>2</sub>,…,<i>i</i><sub><i>N</i></sub>)并且<i>k</i><sub><i>i</i><sub>1</sub></sub>≤<i>k</i><sub><i>i</i><sub>2</sub></sub>≤…≤<i>k</i><sub><i>i</i><sub><i>N</i></sub></sub>,<i>k</i><sub><i>i</i><sub>1</sub></sub>,<i>k</i><sub><i>i</i><sub>2</sub></sub>,…,<i>k</i><sub><i>i</i><sub><i>N</i></sub></sub>是<i>N</i>维向量<b><i>K</i></b>的元素,<i>π</i>是向量<b><i>K</i></b>的中所有元素按照非降序排列后的索引值。很显然,<i>Π</i><sup><i>N</i></sup>中有<i>N</i>!种排列,这<i>N</i>!种排列可以建立一个索引表。定义<b><i>V</i></b><mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>!</mo></mrow><mi>i</mi></msubsup></mrow></math></mathml>是只有第<i>i</i>个元素为1其他元素全为0的<i>N</i>!维向量,则函数ϕ表示将排列<i>π</i>映射到<b><i>V</i></b><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>!</mo></mrow><mi>i</mi></msubsup></mrow></math></mathml>上:</p>
                </div>
                <div class="p1">
                    <p id="55">ϕ(<i>π</i>)=<b><i>V</i></b><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>!</mo></mrow><mrow><mi>Ι</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>π</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>; <i>π</i>∈<i>Π</i><sup><i>N</i></sup>      (2)</p>
                </div>
                <div class="p1">
                    <p id="57">其中:<i>Ind</i>(<i>π</i>)是<i>π</i>在索引表的索引,<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">V</mi><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>!</mo></mrow><mrow><mi>Ι</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>π</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mn>0</mn><mo>,</mo><mtable><mtr><mtd></mtd><mtd><mn>1</mn></mtd><mtd></mtd><mtd></mtd></mtr></mtable><mo>,</mo><mn>0</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></mstyle><mrow><mo stretchy="false">(</mo><mi>Ι</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>γ</mi><mo stretchy="false">(</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></munder></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="59">根据上述定义,像素点<i>X</i>的LIOP值可以定义为:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">L</mi><mi mathvariant="bold-italic">Ι</mi><mi mathvariant="bold-italic">Ο</mi><mi mathvariant="bold-italic">Ρ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>ϕ</mtext><mo stretchy="false">(</mo><mi>γ</mi><mo stretchy="false">(</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">V</mi><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>!</mo></mrow><mrow><mi>Ι</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>γ</mi><mo stretchy="false">(</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo></mtd></mtr><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mn>0</mn><mo>,</mo><mtable><mtr><mtd></mtd><mtd><mn>1</mn></mtd><mtd></mtd><mtd></mtd></mtr></mtable><mo>,</mo><mn>0</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></mstyle><mrow><mo stretchy="false">(</mo><mi>Ι</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>γ</mi><mo stretchy="false">(</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></munder><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">每个子区域的描述子可以通过叠加该区域内所有像素点的LIOP值来获得,最终的LIOP描述子可以通过串联所有子区域的描述子得到:</p>
                </div>
                <div class="p1">
                    <p id="62"><b><i>F</i></b>=(<b><i>des</i></b><sub>1</sub>,<b><i>des</i></b><sub>2</sub>,…,<b><i>des</i></b><sub><i>B</i></sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="63">其中<i>B</i>是划分子区域的个数,<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">d</mi><mi mathvariant="bold-italic">e</mi><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mi mathvariant="bold-italic">L</mi><mi mathvariant="bold-italic">Ι</mi><mi mathvariant="bold-italic">Ο</mi><mi mathvariant="bold-italic">Ρ</mi></mrow></mstyle><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>表示第<b><i>i</i></b>个子区域的描述向量。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909038_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 旋转不变坐标系下的邻域点" src="Detail/GetImg?filename=images/JSJY201909038_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 旋转不变坐标系下的邻域点  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909038_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Neighborhoods under rotation invariant coordinate system</p>

                </div>
                <h4 class="anchor-tag" id="66" name="66">1.2 <b>基于</b>NSCT<b>的多支持区域</b>LIOP<b>描述子</b></h4>
                <div class="p1">
                    <p id="67">图像伪造技术常常会让图像产生局部扭曲,而在单一支持区域上构建的特征描述子不能很好地处理图像局部扭曲所产生的问题,目前常用的多支持区域策略是N嵌套的多支持区域<citation id="195" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,但该策略仅利用了检测区域的空间信息。利用非抽样<i>Contourlet</i>变换可得到不同尺度、不同分辨率和不同方向的多支持区域,该策略不仅获取检测区域的空间信息,还能表征检测区间的频域信息、方向信息及尺度信息。因此,使用基于<i>NSCT</i>的多支持区域策略可以增强<i>LIOP</i>描述子的鉴别力。</p>
                </div>
                <div class="p1">
                    <p id="68">非抽样<i>Contourlet</i>变换由非抽样塔状滤波器(<i>NonSubsampled Pyramid</i>, <i>NSP</i>)和非抽样方向性滤波器组(<i>NonSubsampled Directional Filter Bank</i>, <i>NSDFB</i>)组成,其结构如图2所示。由图2可知,<i>NSP</i>具有多尺度性,这使得分解后的子带具有良好的尺度信息,同时<i>NSDFB</i>具有多方向性,这使得分解后的子带具有良好的方向信息。<i>NSP</i>与<i>NSDFB</i>能完全重构信号的条件为:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>H</i><sub>0</sub>(<i>z</i>)<i>G</i><sub>0</sub>(<i>z</i>)+<i>H</i><sub>1</sub>(<i>z</i>)<i>G</i><sub>1</sub>(<i>z</i>)=1      (5)</p>
                </div>
                <div class="p1">
                    <p id="70">其中:<i>H</i><sub>0</sub>(<i>z</i>)、<i>H</i><sub>1</sub>(<i>z</i>)表示分解滤波器,<i>G</i><sub>0</sub>(<i>z</i>)、<i>G</i><sub>1</sub>(<i>z</i>)表示重建滤波器。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909038_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 非抽样Contourlet变换" src="Detail/GetImg?filename=images/JSJY201909038_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 非抽样Contourlet变换  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909038_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Nonsubsampled contourlet transform</p>

                </div>
                <div class="p1">
                    <p id="72">此外,NSP和NSDFB都是非下采样的,经NSCT分解后的子带和原图像大小一致,低频子带不存在频率混叠现象,能反映原始图像的完整信息<citation id="196" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。所以本文利用NSCT产生不同尺度和方向的低频子带作为多支持区域,其中的方向滤波器为db4,分解层数为4。图3是利用NSCT产生的4个不同尺度和方向的多支持区域。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909038_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 利用NSCT产生的多支持区域" src="Detail/GetImg?filename=images/JSJY201909038_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 利用NSCT产生的多支持区域  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909038_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Multiple support regions using NSCT</p>

                </div>
                <div class="p1">
                    <p id="74">假若<i>R</i>是MSER算法检测的一个最大稳定极值区域,由式(4)可得到支持区域<i>R</i>的特征向量<b><i>F</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="75"><b><i>F</i></b>=(<b><i>des</i></b><sub>1</sub>,<b><i>des</i></b><sub>2</sub>,…,<b><i>des</i></b><sub><i>B</i></sub>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="76">串联<i>N</i>个支持区域(由NSCT产生的<i>N</i>个支持区域)的特征向量形成<i>N</i>个支持区域下LIOP描述子<b><i>w</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="77"><b><i>w</i></b>=(<b><i>F</i></b><sub>1</sub>,<b><i>F</i></b><sub>2</sub>,…,<b><i>F</i></b><sub><i>N</i></sub>)      (7)</p>
                </div>
                <div class="p1">
                    <p id="78">其中<b><i>F</i></b><sub><i>i</i></sub>表示第<i>i</i>个支持区域的特征向量(<i>i</i>=1,2,…,<i>N</i>),其中参数<i>N</i>取4,<i>B</i>取6。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag">2 本文方法</h3>
                <div class="p1">
                    <p id="80">本文提出的基于多支持区域<i>LIOP</i>描述子的图像伪造检测算法分为4个步骤:特征点提取、特征描述、特征匹配和变换估计。图4是本文算法的流程。若待检测图像的特征点集(即<i>MSER</i>算法检测区域的中心)为T:</p>
                </div>
                <div class="p1">
                    <p id="81"><i>T</i>={<i>t</i><sub>1</sub>,<i>t</i><sub>2</sub>,…,<i>t</i><sub><i>n</i></sub>}      (8)</p>
                </div>
                <div class="p1">
                    <p id="82">其中每个特征点<i>t</i><sub><i>i</i></sub>∈<i>T</i>(<i>i</i>=1,2,…,<i>n</i>)对应一个MSER区域,可以得到对应的多支持区域LIOP描述子<b><i>w</i></b><sub><i>i</i></sub>,进而得到特征描述子集合<i>ψ</i>:</p>
                </div>
                <div class="p1">
                    <p id="83"><i>ψ</i>={<b><i>w</i></b><sub>1</sub>,<b><i>w</i></b><sub>2</sub>,…,<b><i>w</i></b><sub><i>n</i></sub>}      (9)</p>
                </div>
                <div class="p1">
                    <p id="84">对每个特征描述子<b><i>w</i></b><sub><i>i</i></sub>∈<i>ψ</i>(<i>i</i>=1,2,…,<i>n</i>),采用最简单常用的双向欧氏距离比值法进行匹配。即如果特征点<i>t</i><sub><i>A</i></sub>和<i>t</i><sub><i>B</i></sub>是一对匹配对,则有:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>A</mi></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>A</mi></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>&lt;</mo><mi>η</mi><mspace width="0.25em" /><mo>&amp;</mo><mspace width="0.25em" /><mfrac><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>B</mi></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>B</mi></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>&lt;</mo><mi>η</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中:<i>d</i>(·)表示求欧氏距离,<b><i>w</i></b><sub><i>A</i></sub>和<b><i>w</i></b><sub><i>B</i></sub>分别是<i>t</i><sub><i>A</i></sub>和<i>t</i><sub><i>B</i></sub>对应的LIOP描述子,并且<b><i>w</i></b><sub><i>B</i></sub>和<b><i>w</i></b><sub><i>C</i></sub>是距离<b><i>w</i></b><sub><i>A</i></sub>最近和次近的特征描述子,同时保证<b><i>w</i></b><sub><i>A</i></sub>和<b><i>w</i></b><sub><i>D</i></sub>是距离<b><i>w</i></b><sub><i>B</i></sub>最近和次近的特征描述子,<i>η</i>是阈值,取0.6。</p>
                </div>
                <div class="p1">
                    <p id="87">这样就可以得到一组特征匹配对:{<i>m</i><sub>1</sub>,<i>m</i><sub>2</sub>,…,<i>m</i><sub><i>q</i></sub>}和{<i>p</i><sub>1</sub>,<i>p</i><sub>2</sub>,…,<i>p</i><sub><i>q</i></sub>},其中特征点<i>m</i><sub><i>r</i></sub>与<i>p</i><sub><i>r</i></sub>是一对特征匹配,<i>m</i><sub><i>r</i></sub>∈<i>T</i>,<i>p</i><sub><i>r</i></sub>∈<i>T</i>(<i>r</i>=1,2,…,<i>q</i>)。接下来利用空间距离将{<i>m</i><sub>1</sub>,<i>m</i><sub>2</sub>,…,<i>m</i><sub><i>q</i></sub>}或{<i>p</i><sub>1</sub>,<i>p</i><sub>2</sub>,…,<i>p</i><sub><i>q</i></sub>}进行归类,首先计算每个特征点的距离概率密度<i>E</i>(<i>m</i><sub><i>i</i></sub>):</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mi>d</mi></mstyle><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>m</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mi>d</mi></mstyle></mrow></mstyle><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>m</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mspace width="0.25em" /><mi>E</mi><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">利用式(12)选取使<i>E</i>(<i>m</i><sub><i>i</i></sub>)最小的特征点<i>m</i><sub>0</sub>作为初始点,然后通过式(13)判定特征点<i>m</i><sub><i>l</i></sub>(<i>l</i>=1,2,…,<i>q</i>)是否与<i>m</i><sub>0</sub>为一类。</p>
                </div>
                <div class="p1">
                    <p id="90">‖<i>m</i><sub><i>l</i></sub>-<i>m</i><sub>0</sub>‖≤<i>δ</i>      (13)</p>
                </div>
                <div class="p1">
                    <p id="91">其中<i>δ</i>为判定阈值,与图像篡改区域位置有关,选择200。同理余下的特征点重复上述过程直到所有特征点都归类为止,{<i>p</i><sub>1</sub>,<i>p</i><sub>2</sub>,…,<i>p</i><sub><i>q</i></sub>}的归类与{<i>m</i><sub>1</sub>,<i>m</i><sub>2</sub>,…,<i>m</i><sub><i>q</i></sub>}一一对应。</p>
                </div>
                <div class="p1">
                    <p id="92">对每一个归类,利用随机抽样一致性(RANdom SAmple Consensus, RANSAC)算法<citation id="197" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>进行几何变换估计,其目的是进一步剔除不精确的匹配对,使检测的伪造区域更加精确。该算法利用式(14)剔除不精确的匹配对:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">U</mi><mrow><mo>(</mo><mrow><mtable><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow><mo>-</mo><mrow><mo>(</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>&lt;</mo><mi>ε</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mtable><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">和</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">是匹配特征点的齐次坐标系,‖·‖<sub>2</sub>表示2-范数操作,阈值<i>ε</i>取3,<b><i>U</i></b>是类间的单应矩阵,本文使用仿射变换估计,即:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">U</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>a</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mi>a</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd><mtd><mi>s</mi><msub><mrow></mrow><mi>x</mi></msub></mtd></mtr><mtr><mtd><mi>a</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd><mtd><mi>a</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd><mtd><mi>s</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd><mtd><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">是控制坐标变换中旋转和尺度等变换,<b><i>s</i></b><sub><b><i>x</i></b></sub>和<b><i>s</i></b><sub><b><i>y</i></b></sub>是坐标变换中<b><i>x</i></b>和<b><i>y</i></b>轴的平移量。最后进行必要的后处理,即对类内一组特征点计算最优凸包、连接边界和进行形态学运算,得到伪造区域。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909038_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 图像复制-粘贴伪造检测算法过程" src="Detail/GetImg?filename=images/JSJY201909038_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 图像复制-粘贴伪造检测算法过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909038_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Process of image copy-move forgery detection algorithm</p>

                </div>
                <h3 id="104" name="104" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="105">实验使用文献<citation id="198" type="reference">[<a class="sup">3</a>]</citation>所提供的图像复制-粘贴伪造数据库,该数据库常被用于验证复制-粘贴、重采样和<i>JPEG</i>压缩等伪造检测算法。该数据有48个基准图像,从这些基准图像中选择感兴趣的伪造区域。选择的伪造区域经过不同程度的操作(如旋转和尺度变换、添加不同强度的高斯噪声、<i>JPEG</i>压缩等)后复制-粘贴到原基准图像中,形成伪造图像。</p>
                </div>
                <div class="p1">
                    <p id="106">图像复制-粘贴伪造检测算法最常用的评价标准时准确率 (<i>precision</i>) 和查全率(<i>recall</i>),其定义如下:</p>
                </div>
                <div class="p1">
                    <p id="107"><i>precision</i>=<i>TP</i>/(<i>TP</i>+<i>FP</i>)      (16)</p>
                </div>
                <div class="p1">
                    <p id="108"><i>recall</i>=<i>TP</i>/(<i>TP</i>+<i>FN</i>)      (17)</p>
                </div>
                <div class="p1">
                    <p id="109">其中:<i>TP</i>代表被正确检测为伪造图像的个数,<i>FP</i>代表被错误检测为伪造图像的个数,<i>FN</i>表示伪造图像未被检测到的个数。</p>
                </div>
                <div class="p1">
                    <p id="110">LIOP描述子的时间复杂度与区域划分和计算每个像素的LIOP值有关。LIOP描述子利用亮度序进行区域划分,即对支持区域内所有亮度值进行排序,将支持区域等间隔地划分为<i>B</i>个子区域,而对支持区域内所有亮度值进行排序的复杂度是<i>Ο</i>(<i>N</i> log <i>N</i>),其中<i>N</i>表示支持区域内的像素个数。按照文中第1.1节所述,计算每个像素的LIOP值需要计算<i>N</i>!个排列,因此所需复杂度是<i>Ο</i>(<i>N</i><sup>3</sup>)。</p>
                </div>
                <div class="p1">
                    <p id="111">为了验证本文算法的优越性,把基于特征点的图像复制-粘贴伪造检测常用的几种方法作为对比算法:基于SIFT耦合特征点集群的图像复制-粘贴伪造检测算法<citation id="199" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、基于SIFT的图像复制-粘贴伪造检测算法<citation id="200" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和基于SURF的图像复制-粘贴伪造检测算法<citation id="201" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。统计结果如表1所示,可以看出,无论准确率,还是查全率,本文提出的算法比其他几种算法性能更优,这是由于多支持区域LIOP描述子的优越性所决定的。图5是4种算法在图像复制-粘贴伪造数据库中的几个例子。可以看出,本文所提出的算法具有很高的准确率和可信度,基于SIFT耦合特征点集群的算法紧随其后,与本文算法的性能较为接近,而基于SIFT和SURF的算法不仅正确匹配对有所减少,而且精度也有待提高。</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表</b>1 <b>图像复制-粘贴伪造检测算法性能比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Performance comparison of image copy-move forgery detection algorithms</p>
                    <p class="img_note"></p>
                    <table id="112" border="1"><tr><td><br />方法</td><td>准确率/%</td><td>查全率/%</td></tr><tr><td><br />基于SIFT耦合特征点集群的检测方法</td><td>92.26</td><td>90.47</td></tr><tr><td><br />基于SIFT的检测方法</td><td>88.10</td><td>86.05</td></tr><tr><td><br />基于SURF的检测方法</td><td>90.70</td><td>88.64</td></tr><tr><td><br />本文方法</td><td>95.45</td><td>91.30</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909038_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 图像复制-粘贴伪造实例的检测结果" src="Detail/GetImg?filename=images/JSJY201909038_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 图像复制-粘贴伪造实例的检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909038_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Detection results of several copy-move forged regions</p>

                </div>
                <h3 id="114" name="114" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="115">针对现有图像复制-粘贴伪造区域检测算法大多数受图像旋转变换、尺度变换和亮度变化的影响,提出了一种基于多支持区域<i>LIOP</i>描述子的图像复制-粘贴伪造区域检测算法,利用<i>NSCT</i>得到不同尺度、不同分辨率和不同方向的多个支持区域,在每个支持区域上计算同时具有旋转不变的和单调亮度不变的<i>LIOP</i>描述子。实验结果表明:本文算法相对于<i>SIFT</i>算法和<i>SURF</i>算法具有较高的准确率和查全率。但所提出的算法仅仅针对图像复制-粘贴伪造技术,在后续的工作中将进一步改进所提算法以用于更加复杂的篡改手段。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="141">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Digital image forensics: a booklet for beginners">

                                <b>[1]</b> REDI J A,TAKTAK W,DUGELAY J.Digital image forensics:a booklet for beginners [J].Multimedia Tools and Applications,2011,51(1):133-162.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2016S1030&amp;v=MDU3MDU3RzRIOWV2cm85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WTHpCTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 周萌萌,杨鸿波,高晶敏,等.基于快速分块的复制-粘贴图像检测算法[J].计算机应用,2016,36(S1):117-121.(ZHOU M M,YANG H B,GAO J M,et al.Copy-move image detection algorithm based on fast blocking[J].Journal of Computer Applications,2016,36(S1):117-121.)
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Evaluation of Popular Copy-Move Forgery Detection Approaches">

                                <b>[3]</b> CHRISTLEIN V,RIESS C,JORDAN J,et al.An evaluation of popular copy-move forgery detection approaches [J].IEEE Transactions on Information Forensics and Security,2012,7(6):1841-1854.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A SIFT-Based Forensic Method for Copy–Move Attack Detection and Transformation Recovery">

                                <b>[4]</b> AMERINI I,BALLAN L,CALDELLI R,et al.A SIFT-based forensic method for copy-move attack detection and transformation recovery [J].IEEE Transactions on Information Forensics and Security,2011,6(3):1099-1110.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation-based image copy-move forgery detection scheme">

                                <b>[5]</b> LI J,LI X,YANG B,et al.Segmentation-based image copy-move forgery detection scheme [J].IEEE Transactions on Information Forensics and Security,2015,10(3):507-518.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rotation invariant localization of duplicated image regions based on Zernike moments">

                                <b>[6]</b> RYU S,KIRCHNER M,LEE M,et al.Rotation invariant localization of duplicated image regions based on zernike moments [J].IEEE Transactions on Information Forensics and Security,2013,8(8):1355-1370.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201605035&amp;v=MjgxNDU3RzRIOWZNcW85R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WTHpCTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 林晶,黄添强,赖玥聪,等.采用量化离散余弦变换系数检测视频单帧连续多次复制粘贴篡改[J].计算机应用,2016,36(5):1356-1361.(LIN J,HUANG T Q,LAI Y C,et al.Detection of continuously and repeated copy-move forgery to single frame in videos by quantized DCT coefficients [J].Journal of Computer Applications,2016,36(5):1356-1361.)
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQDEF87C5FC447D7047F3F5A6F987C74593&amp;v=MjMyODFzYk9GdGEvcXZrMllPOEllSHM1eXhGbDZVbDRPWG1VcFJveUNyV1FRTE9jQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeExxNHc2RT1OajNhYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> ZIMBA M,SUN X.DWT-PCA (EVD) based copy-move image forgery detection [J].International Journal of Digital Content Technology and Its Applications,2011,5(1):251-258.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Identifying Tampered Regions Using Singular Value Decomposition in Digital Image Forensics">

                                <b>[9]</b> KANG X,WEI S.Identifying tampered regions using singular value decomposition in digital image forensics [C]// Proceedings of the 2008 International Conference on Computer Science and Software Engineering.Piscataway,NJ:IEEE,2008:926-930.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exposing postprocessed copy-paste forgeries through transform-invariant features">

                                <b>[10]</b> KAKAR P,SUDHA N.Exposing postprocessed copy-paste forgeries through transform-invariant features [J].IEEE Transactions on Information Forensics and Security,2012,7(3):1018-1028.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201803006&amp;v=MTY4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZMekJQU1BSWmJHNEg5bk1ySTlGWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 柴建伟,刘婷.改进的SIFT耦合特征点集群的图像伪造检测算法[J].西南师范大学学报(自然科学版),2018,43(3):34-41.(CHAI J W,LIU T.Image forgery detection algorithm based on improved SIFT coupled feature point clustering [J].Journal of Southwest China Normal University (Natural Science Edition),2018,43(3):34-41.)
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00004593895&amp;v=MDk5NjFNSDdSN3FkWitadUZpcmxVNzNQSTFjPU5qM2Fhck80SHRISXFvWkdiT0lLWTNrNXpCZGg0ajk5U1hxUnJ4b3hj&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> SHIVAKUMAR B L,BABOO S S.Detection of region duplication forgery in digital images using SURF [J].International Journal of Computer Science Issues,2011,8(4):199-205.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201808034&amp;v=MDA0OTFNcDQ5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WTHpCTmlmWVpMRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 陈辉映,张大兴,杨珊珊,等.基于SURF的图像多区域复制粘贴篡改检测[J].计算机工程与设计,2018,39(8):2593-2597.(CHEN H Y,ZHANG D X,YANG S S,et al.Image multiple copy-move forgery detection based on SURF algorithm [J].Computer Engineering and Design,2018,39(8):2593-2597.)
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local intensity order pattern for feature description">

                                <b>[14]</b> WANG Z,FAN B,WU F.Local intensity order pattern for feature description [C]// Proceedings of the 2011 International Conference on Computer Vision.Piscataway,NJ:IEEE,2011:603-610.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201702044&amp;v=MDI5OTVuVkx6Qkx6N0JkN0c0SDliTXJZOUJZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 邹玮刚,周志辉,王洋.基于非降采样轮廓波变换的图像修复算法[J].计算机应用,2017,37(2):553-558.(ZOU W G,ZHOU Z H,WANG Y.Image inpainting algorithm based on non-subsampled contourlet transform [J].Journal of Computer Applications,2017,37(2):553-558.)
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349782&amp;v=MTE5NDJxUVRNbndaZVp0RmlubFVyM0lJRndUYVJzPU5pZk9mYks3SHRET3JZOUVaKzhHQzNRN29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> MATAS J,CHUM O,URBAN M,et al.Robust wide-baseline stereo from maximally stable extremal regions [J].Image and Vision Computing,2004,22(10):761-767.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rotationally Invariant Descriptors Using Intensity Order Pooling">

                                <b>[17]</b> FAN B,WU F,HU Z.Rotationally invariant descriptors using intensity order pooling [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2012,34(10):2031-2045.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201609040&amp;v=MDQ4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZMekJMejdCZDdHNEg5Zk1wbzlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 勾承甫,陈斌,赵雪专,等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用,2016,36(9):2566-2569.(GOU C F,CHEN B,ZHAO X Z,et al.Object tracking algorithm based on random sampling consensus estimation[J].Journal of Computer Applications,2016,36(9):2566-2569.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909038" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909038&amp;v=MDAwNDFyQ1VSN3FmWnVac0Z5am5WTHpCTHo3QmQ3RzRIOWpNcG85R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
