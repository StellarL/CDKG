<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637139023678228750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903041%26RESULT%3d1%26SIGN%3db3nnIqndAf0%252bLDZWakPSElq66eY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903041&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903041&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903041&amp;v=MjczNjZHNEg5ak1ySTlCWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMck9MejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="1 模型介绍 ">1 模型介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="1.1 &lt;b&gt;跟随速度选取&lt;/b&gt;">1.1 <b>跟随速度选取</b></a></li>
                                                <li><a href="#45" data-title="1.2 &lt;b&gt;视差速度选取&lt;/b&gt;">1.2 <b>视差速度选取</b></a></li>
                                                <li><a href="#71" data-title="1.3 &lt;b&gt;多模滤波模型&lt;/b&gt;">1.3 <b>多模滤波模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="2 仿真结果 ">2 仿真结果</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#152" data-title="3 结语 ">3 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="图1 三维椭球投影">图1 三维椭球投影</a></li>
                                                <li><a href="#81" data-title="图2 交互多模滤波流程">图2 交互多模滤波流程</a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;视差速度及相应残差均值&lt;/b&gt;"><b>表</b>1 <b>视差速度及相应残差均值</b></a></li>
                                                <li><a href="#139" data-title="图3 视差速度 (0.1～0.5 m/s) 与残差均值关系">图3 视差速度 (0.1～0.5 m/s) 与残差均值关系</a></li>
                                                <li><a href="#141" data-title="图4 视差速度 (0.2～0.5 m/s) 与残差均值关系">图4 视差速度 (0.2～0.5 m/s) 与残差均值关系</a></li>
                                                <li><a href="#146" data-title="图5 次优视差算法与启发式算法仿真结果">图5 次优视差算法与启发式算法仿真结果</a></li>
                                                <li><a href="#147" data-title="图6 目标实际轨迹与预测轨迹 (视差速度0.5 m/s) ">图6 目标实际轨迹与预测轨迹 (视差速度0.5 m/s) </a></li>
                                                <li><a href="#148" data-title="图7 传统方法与多模滤波方法轨迹">图7 传统方法与多模滤波方法轨迹</a></li>
                                                <li><a href="#150" data-title="图8 传统方法与多模滤波方法残差均值">图8 传统方法与多模滤波方法残差均值</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" WANG C-C, THORPE C. Simultaneous localization and mapping with detection and tracking of moving objects [C]// Proceedings of the 2002 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2002: 2918-2924." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization and mapping with detection and tracking of moving objects">
                                        <b>[1]</b>
                                         WANG C-C, THORPE C. Simultaneous localization and mapping with detection and tracking of moving objects [C]// Proceedings of the 2002 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2002: 2918-2924.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WANG C-C, THORPE C, THRUN S, et al. Simultaneous localization, mapping and moving object tracking [J]. International Journal of Robotics Research, 2007, 26 (9) : 889-916." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization, mapping and moving object tracking">
                                        <b>[2]</b>
                                         WANG C-C, THORPE C, THRUN S, et al. Simultaneous localization, mapping and moving object tracking [J]. International Journal of Robotics Research, 2007, 26 (9) : 889-916.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" WAN K W, WANG C-C, TON T T. Weakly interacting object tracking in indoor environments [C]// Proceedings of the 2008 IEEE Workshop on Advanced Robotics and Its Social Impacts. Piscataway, NJ: IEEE, 2008:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weakly interacting object tracking in indoor environments">
                                        <b>[3]</b>
                                         WAN K W, WANG C-C, TON T T. Weakly interacting object tracking in indoor environments [C]// Proceedings of the 2008 IEEE Workshop on Advanced Robotics and Its Social Impacts. Piscataway, NJ: IEEE, 2008:1-6.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" WANG C-C, THORPE C, THRUN S. Online simultaneous localization and mapping with detection and tracking of moving objects: theory and results from a ground vehicle in crowded urban areas [C]// Proceedings of the 2003 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2003, 1: 842-849." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online simultaneous localiza-tion and mapping with detection and tracking of moving ob-jects:Theory and results from a ground vehicle in crowded ur-ban areas">
                                        <b>[4]</b>
                                         WANG C-C, THORPE C, THRUN S. Online simultaneous localization and mapping with detection and tracking of moving objects: theory and results from a ground vehicle in crowded urban areas [C]// Proceedings of the 2003 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2003, 1: 842-849.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" BAIG Q, VU T-D, AYCARD O. Online localization and mapping with moving objects detection in dynamic outdoor environments [C]// Proceedings of the 2009 IEEE 5th International Conference on Intelligent Computer Communication and Processing. Piscataway, NJ: IEEE, 2009: 190-195." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online localization and mapping with moving objects detection in dynamic outdoor environments">
                                        <b>[5]</b>
                                         BAIG Q, VU T-D, AYCARD O. Online localization and mapping with moving objects detection in dynamic outdoor environments [C]// Proceedings of the 2009 IEEE 5th International Conference on Intelligent Computer Communication and Processing. Piscataway, NJ: IEEE, 2009: 190-195.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" WANG C-C, LO T-C, YANG S-W. Interacting object tracking in crowded urban areas [C]// Proceedings of the 2007 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2007: 4626-4632." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interacting object tracking in crowded urban areas">
                                        <b>[6]</b>
                                         WANG C-C, LO T-C, YANG S-W. Interacting object tracking in crowded urban areas [C]// Proceedings of the 2007 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2007: 4626-4632.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" CIVERA J, DAVISON A J, MONTIEL J M M. Inverse depth parametrization for monocular SLAM [J]. IEEE Transactions on Robotics, 2008, 24 (5) : 932-945." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Inverse Depth Parametrization for Monocular SLAM">
                                        <b>[7]</b>
                                         CIVERA J, DAVISON A J, MONTIEL J M M. Inverse depth parametrization for monocular SLAM [J]. IEEE Transactions on Robotics, 2008, 24 (5) : 932-945.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" DAVISON A J. Real-time simultaneous localisation and mapping with a single camera [C]// ICCV &#39;03: Proceedings of the 9th IEEE International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1403." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time simultaneous localisation and mapping with a single camera">
                                        <b>[8]</b>
                                         DAVISON A J. Real-time simultaneous localisation and mapping with a single camera [C]// ICCV &#39;03: Proceedings of the 9th IEEE International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1403.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" DAVISON A J, REID I D, MOLTON N D, et al. MonoSLAM: real-time single camera SLAM [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 1052-1067." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MonoSLAM: Real-Time Single Camera SLAM">
                                        <b>[9]</b>
                                         DAVISON A J, REID I D, MOLTON N D, et al. MonoSLAM: real-time single camera SLAM [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 1052-1067.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" ESS A, LEIBE B, SCHINDLER K, et al. Robust multiperson tracking from a mobile platform [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (10) : 1831-1846." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust multiperson tracking from a mobile platform">
                                        <b>[10]</b>
                                         ESS A, LEIBE B, SCHINDLER K, et al. Robust multiperson tracking from a mobile platform [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (10) : 1831-1846.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" ESS A, LEIBE B, SCHINDLER K, et al. Moving obstacle detection in highly dynamic scenes [C]// Proceedings of the 2009 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2009:56-63." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Moving obstacle detection in highly dynamic scenes">
                                        <b>[11]</b>
                                         ESS A, LEIBE B, SCHINDLER K, et al. Moving obstacle detection in highly dynamic scenes [C]// Proceedings of the 2009 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2009:56-63.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" ESS A, LEIBE B, SCHINDLER K, et al. A mobile vision system for robust multi-person tracking [C]// Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2008: 1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A mobile vision systemfor robust multi-person tracking">
                                        <b>[12]</b>
                                         ESS A, LEIBE B, SCHINDLER K, et al. A mobile vision system for robust multi-person tracking [C]// Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2008: 1-8.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" CIVERA J, GRASA O G, DAVISON A J, et al. 1-point RANSAC for extended Kalman filtering: application to real-time structure from motion and visual odometry [J]. Journal of Field Robotics, 2010, 27 (5) : 609-631." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001252569&amp;v=MTcyNDJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpL2xVci9MSlZjPU5pZmNhck80SHRITnJZcEhZZTBHWTNrNXpC&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         CIVERA J, GRASA O G, DAVISON A J, et al. 1-point RANSAC for extended Kalman filtering: application to real-time structure from motion and visual odometry [J]. Journal of Field Robotics, 2010, 27 (5) : 609-631.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" LI H-P, XU D-M, ZHANG F-B, et al. Consistency analysis of EKF-based SLAM by measurement noise and observation times [J]. Acta Automatica Sinica, 2009, 35 (9) : 1177-1184." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300117346&amp;v=MjAxMzJmYks3SHRETnJJOUZaZW9JRDNnL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSUlWNFhieHM9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         LI H-P, XU D-M, ZHANG F-B, et al. Consistency analysis of EKF-based SLAM by measurement noise and observation times [J]. Acta Automatica Sinica, 2009, 35 (9) : 1177-1184.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 梁明杰, 闵华清, 罗荣华.基于图优化的同时定位与地图创建综述[J].机器人, 2013, 35 (4) :500-512. (LIANG M J, MIN H Q, LUO R H. Graph-based SLAM: a survey [J]. Robot, 2013, 35 (4) : 500-512.) This work is partially supported by the National Natural Science Foundation of China (61503389) , the Natural Science Foundation of Shaanxi Province (2016JM6061) .HUANG Shuai, born in 1994, M. S. candidate. His research interests include object tracking, monocular SLAM.FU Guangyuan, born in 1965, Ph. D., professor. His research interests include artificial intelligence, command information system.WU Ming, born in 1981, Ph. D., lecturer. His research interests include object tracking, monocular SLAM.YUE Min, born in 1995, Ph. D. candidate. Her research interests include object tracking, monocular SLAM." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201304016&amp;v=MDA0NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMckJMenpaZkxHNEg5TE1xNDlFWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         梁明杰, 闵华清, 罗荣华.基于图优化的同时定位与地图创建综述[J].机器人, 2013, 35 (4) :500-512. (LIANG M J, MIN H Q, LUO R H. Graph-based SLAM: a survey [J]. Robot, 2013, 35 (4) : 500-512.) This work is partially supported by the National Natural Science Foundation of China (61503389) , the Natural Science Foundation of Shaanxi Province (2016JM6061) .HUANG Shuai, born in 1994, M. S. candidate. His research interests include object tracking, monocular SLAM.FU Guangyuan, born in 1965, Ph. D., professor. His research interests include artificial intelligence, command information system.WU Ming, born in 1981, Ph. D., lecturer. His research interests include object tracking, monocular SLAM.YUE Min, born in 1995, Ph. D. candidate. Her research interests include object tracking, monocular SLAM.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-19 14:12</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),864-868 DOI:10.11772/j.issn.1001-9081.2018071535            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>未知环境基于单目次优视差的多模滤波目标跟踪算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E5%B8%85&amp;code=41275263&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄帅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%98%E5%85%89%E8%BF%9C&amp;code=35497819&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">付光远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BC%8D%E6%98%8E&amp;code=36145256&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">伍明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B2%B3%E6%95%8F&amp;code=41275264&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">岳敏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%81%AB%E7%AE%AD%E5%86%9B%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6301%E6%95%99%E7%A0%94%E5%AE%A4&amp;code=1699750&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">火箭军工程大学301教研室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在未知环境下基于单目视觉的机器人同时定位、地图构建和目标追踪的耦合问题 (SLAMOT) 中, 需要足够的视差才能满足目标跟踪的可观性条件。同时, 针对目标运动的不确定性以及系统对于目标运动方式的未知性, 提出一种基于次优视差的多模滤波目标跟踪算法。首先, 采用目标不确定性椭球投影面积变化最大的方向为次优视差方向, 并将其作为机器人视差控制方向;然后, 采用多模滤波算法计算目标各种运动方式的概率;其次, 对各运动方式的目标状态进行估计, 最后根据各运动方式的概率加权估计出目标状态。另外, 考虑到工程应用中应减小能耗, 因此, 在满足目标跟踪要求的条件下, 降低视差速度。仿真实验表明:视差速度为0.3 m/s时, 次优视差算法的残差均值为0.16 m, 而启发式算法、多模滤波算法、传统扩展卡尔曼滤波 (EKF) 算法的残差均值为0.25 m、0.06 m和0.16 m。在视差速度较低时, 所提算法也能满足目标跟踪的可观性条件, 具有较强的工程应用价值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%8C%E6%97%B6%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E6%9E%84%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同时定位与地图构建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%A8%A1%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多模滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AC%A1%E4%BC%98%E8%A7%86%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">次优视差;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">控制策略;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黄帅 (1994—) , 男, 湖南岳阳人, 硕士研究生, 主要研究方向:目标跟踪、单目SLAM;;
                                </span>
                                <span>
                                    *付光远 (1965—) , 男, 四川眉山人, 教授, 博士, 主要研究方向:人工智能、指挥信息系统;电子邮箱h511508354@163.com;
                                </span>
                                <span>
                                    伍明 (1981—) , 男, 陕西西安人, 讲师, 博士, 主要研究方向:目标跟踪、单目SLAM;;
                                </span>
                                <span>
                                    岳敏 (1995—) , 女, 陕西西安人, 博士研究生, 主要研究方向:目标跟踪、单目SLAM。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61503389);</span>
                                <span>陕西省自然科学基金资助项目 (2016JM6061);</span>
                    </p>
            </div>
                    <h1><b>Multi-mode filtering object tracking algorithm based on monocular suboptimal parallax under unknown environment</b></h1>
                    <h2>
                    <span>HUANG Shuai</span>
                    <span>FU Guangyuan</span>
                    <span>WU Ming</span>
                    <span>YUE Min</span>
            </h2>
                    <h2>
                    <span>Teaching and Research Section 301, Rocket Force University of Engineering</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Under unknown environment, Simultaneous Localization, Mapping and Object Tracking (SLAMOT) based on monocular vision needs sufficient parallax to meet the observability condition of object tracking. Focused on the uncertainty of target motion and the unknown of the system on target motion mode, a multi-mode filtering target tracking algorithm based on monocular suboptimal parallax was proposed. Firstly, the direction in which the target uncertain ellipsoid projection area changed the most was selected as the suboptimal parallax direction and was used as the robot parallax control direction. Then, multi-mode filtering algorithm was used to calculate the probability of different motion modes of the target, estimating the target state of different motion modes. Finally, the target state was estimated according to the probabilistic weighting of each motion mode. The simulation results show that the residual error of suboptimal disparity algorithm is 0.16 m when the parallax velocity is 0.3 m/s, meanwhile the residual means of heuristic algorithm, multimode filtering algorithm, traditional Extended Kalman Filter (EKF) algorithm are 0.25 m, 0.06 m and 0.16 m respectively. Besides, when the parallax speed is small, the proposed algorithm also can satisfy the observability condition of target tracking, having important engineering application value.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Simultaneous%20Localization%20And%20Mapping%20(SLAM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Simultaneous Localization And Mapping (SLAM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-mode%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-mode filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=suboptimal%20parallax&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">suboptimal parallax;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=control%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">control strategy;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HUANG Shuai, born in 1994, M. S. candidate. His research interests include object tracking, monocular SLAM.;
                                </span>
                                <span>
                                    FU Guangyuan, born in 1965, Ph. D. , professor. His research interests include artificial intelligence, command information system.;
                                </span>
                                <span>
                                    WU Ming, born in 1981, Ph. D. , lecturer. His research interests include object tracking, monocular SLAM.;
                                </span>
                                <span>
                                    YUE Min, born in 1995, Ph. D. candidate. Her research interests include object tracking, monocular SLAM.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61503389);</span>
                                <span>the Natural Science Foundation of Shaanxi Province (2016JM6061);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="34">随着计算机和感知技术的不断发展, 机器人领域逐渐成为学者们研究的热点。未知环境下机器人目标跟踪是指移动机器人在陌生环境中对运动目标的空间状态进行估计的过程。而目标状态估计是以移动机器人自身状态估计为基础的, 要在未知环境中实现移动机器人自身状态估计, 实际就是解决同时定位与地图构建 (Simultaneous Localization and Mapping, SLAM) 问题。实际就是解决机器人SLAM问题。因此, 未知环境下机器人目标跟踪所研究的是机器人同时定位、地图构建与目标跟踪 (Simultaneous Localization, Mapping and Object Tracking, SLAMOT) 问题, 它能够实现机器人对自身状态、环境状态和目标状态的同时估计。</p>
                </div>
                <div class="p1">
                    <p id="35">2002年, 卡内基梅隆大学Wang等<citation id="159" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>首次提出将SLAM和动态目标侦测和跟踪 (Detection and Tracking of Moving Objects, DTMO) 作为一个耦合问题来处理的思想, 该方法以栅格地图差异性比较为基础, 并利用智能导航车Naclab11平台成功地进行了城市环境地图构建, 结果验证了其有效性。此后, 文献<citation id="162" type="reference">[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</citation>中系统地给出了该问题基于贝叶斯理论的解决框架, 方法基于两种假设条件:首先, 假设系统能够成功区分环境特征和目标的观测值。其次, 假设目标观测值只影响目标的状态更新而对机器人和环境特征状态没有影响, 该假设实际上是将SLAM和DTMO问题作为两个独立过程来考虑, 并没有考虑机器人和目标间的相关性对系统状态估计的影响。Vu等<citation id="160" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>运用全局邻域法 (Global Nearest Neighborhood, GNN) 进行动态物体检测并用扩展卡尔曼滤波 (Extended Kalman Filter, EKF ) 对运动物体进行跟踪, 但该方法假设物体运动模态唯一, 因此不能解决机动目标跟踪问题。Wang等<citation id="161" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>介绍了一种基于交互模态的机动目标跟踪方法, 使系统能够对动静 (Move-Stop) 模态运动的目标进行跟踪, 但该方法依然假设机器人和目标的状态估计相互独立。以上研究成果都是基于主动式传感器系统, 而这类传感器存在体积大、质量重、消耗能量多、设备造价高、观测距离有限等缺陷, 这些缺陷限制了SLAMOT的实际应用范围。单目视觉传感器, 凭借其体积小、耗能少、造价低廉、细节呈现度高及直观性好等特点, 正逐渐受到机器人学界的重视。目前, 尽管存在利用单目传感器解决SLAM问题的方法, 但这些方法并未同时考虑目标跟踪 (Object Tracking, OT) 问题。</p>
                </div>
                <div class="p1">
                    <p id="36">对于基于单目视觉的SLAMOT问题来说, 首先, 由于目标的动态性和运动模式未知性, 已有的基于视觉的SLAM估计方法 (例如, 反转深度法<citation id="163" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>、批优化方法<citation id="164" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>) 将无法有效和实时地完成目标状态估计, 因此无法满足目标跟踪的实际需求;其次, 单目视觉目标跟踪等同于纯方位角目标跟踪问题, 学界称之为:方位角目标运动分析问题 (Bearing Only Target Motion Analysis, BOTMA) 。为了满足BOTMA可观性条件, 通常要求观测平台相对于目标机动运动, 而传统BOTMA方法假设在机动过程中观测平台状态已知, 但在实际应用中, 则需要首先解决观测平台自身的状态估计问题。同时, 为了保证观测平台运行的安全性, 系统还需对外界环境状态进行估计。最后, 已有的未知环境下移动平台运动目标跟踪方法, 一般采用多传感器信息融合来实现移动平台和目标状态的独立估计, 多传感器的使用限制了研究成果的应用范围并且降低了问题的难度, 而独立估计方法没有考虑不同对象状态的耦合性问题, 因此影响了系统状态估计的准确性。</p>
                </div>
                <div class="p1">
                    <p id="37">经过学者们长期的研究, 目前, SFM (Structure From Motion) 和滤波的方法成为了解决单目SLAM问题的主流<citation id="166" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation> 。滤波的方法运算较快, 能较好满足SLAM实时性需求。而SFM的方法<citation id="165" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 通过大量计算达到优化的目的, 整体估计精度较高, 但实时性较差。为了满足后续目标跟踪实时性要求, 并解决目标的动态性和运动模式未知性问题, 本文选用多模滤波的方法对单目SLAMOT问题进行研究。在对目标状态估计时, 会在三维空间产生不确定性椭球, 如果不对机器人进行适当的控制, 不确定性椭球就会累积得越来越大, 最终导致跟踪过程失败。为了避免这种情况, 一方面, 需要控制机器人产生足够的视差, 使得目标保持可观性;另一方面, 需要控制机器人接近目标, 从而不跟丢目标。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">1 模型介绍</h3>
                <div class="p1">
                    <p id="39">在利用EKF框架估计和更新目标的状态的过程中, 根据协方差矩阵和估计目标的坐标可知, 目标的实际位置在以某一点为中心的三维椭球中。为了更好地跟踪目标, 需要制定相应的控制策略, 使机器人既能跟踪上目标, 又能更准确地估计出目标的状态。为此, 本文将控制速度分解为两个方向的控制速度:1) 跟随速度;2) 视差速度。不妨设机器人能达到的最大速度为<i>v</i><sub>0</sub>, 跟随速度最大为<i>v</i><sub>1</sub>, 视差速度最大为<i>v</i><sub>2</sub>。则有:</p>
                </div>
                <div class="p1">
                    <p id="40"><i>v</i><sub>1</sub>+<i>v</i><sub>2</sub>=<i>v</i><sub>0</sub>      (1) </p>
                </div>
                <h4 class="anchor-tag" id="41" name="41">1.1 <b>跟随速度选取</b></h4>
                <div class="p1">
                    <p id="42">选取机器人位置与目标位置连线方向作为跟随速度方向。制定合适的跟随速度大小, 使机器人既能跟踪上目标, 又能减少能耗 (降低机器人速度) 。直观来看, 当机器人与目标距离相对较大的时候, 跟随速度应该相应地提高, 这样才不至于跟丢目标;当机器人与目标距离较小的时候, 跟随速度应当适当降低, 以减少机器人能量的损失。为此, 设计相应的跟随速度大小与机器人到目标距离的函数:</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mo>=</mo><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mtext>e</mtext><msup><mrow></mrow><mrow><mfrac><mrow><mo>-</mo><mn>1</mn></mrow><mrow><msqrt><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44"> (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 为机器人坐标, (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>, <i>z</i><sub>1</sub>) 为目标坐标, <i>v</i><sub>1</sub>为机器人所能达到的最大跟随速度。由式 (2) 可以看出, 当距离较大时, 速度<i>v</i>的速度大小接近<i>v</i><sub>0</sub>;当距离较小时, <i>v</i>的速度大小接近0。</p>
                </div>
                <h4 class="anchor-tag" id="45" name="45">1.2 <b>视差速度选取</b></h4>
                <div class="p1">
                    <p id="46">根据协方差矩阵和目标的估计位置, 可以求出目标在三维空间中的不确定性椭球。为了量化视差大小, 可以将视差问题转化为三维椭球投影面积变化大小问题, 最后, 将其抽象为一个三维空间求梯度问题。推导求解出机器人视差速度方向过程如图1。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 三维椭球投影" src="Detail/GetImg?filename=images/JSJY201903041_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 三维椭球投影  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Three-dimensional ellipsoid projection</p>

                </div>
                <div class="p1">
                    <p id="48">三维空间中, 任何椭球通过平移和旋转总能转换成球心在原点的标准形式。形如:</p>
                </div>
                <div class="p1">
                    <p id="49" class="code-formula">
                        <mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>z</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="50">求得椭球面上 (<i>x</i>, <i>y</i>, <i>z</i>) 点处的切平面法向量为:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mfrac><mrow><mn>2</mn><mi>x</mi></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>, </mo><mfrac><mrow><mn>2</mn><mi>y</mi></mrow><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>, </mo><mfrac><mrow><mn>2</mn><mi>z</mi></mrow><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">在三维空间中, 机器人的位置坐标为 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) , 把机器人和目标的连线方向作为平行投影方向, 即投影方向为向量 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="53">所以, 椭球上被投影的点满足以下两个条件:</p>
                </div>
                <div class="p1">
                    <p id="54">1) 该点在椭球表面上。</p>
                </div>
                <div class="p1">
                    <p id="55">2) 该点处切平面的法向量与投影方向垂直。</p>
                </div>
                <div class="p1">
                    <p id="56">将其描述成数学形式为:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>z</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mfrac><mrow><mn>2</mn><mi>x</mi><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>2</mn><mi>y</mi><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>2</mn><mi>z</mi><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">将其投影到<i>XOY</i>平面 (即将式中<i>z</i>用<i>x</i>和<i>y</i>替换) 得到投影后表达式为:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mfrac><mn>1</mn><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mfrac><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>4</mn></msup><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mo stretchy="false"> (</mo><mfrac><mn>1</mn><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mfrac><mrow><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>b</mi><msup><mrow></mrow><mn>4</mn></msup><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mfrac><mrow><mn>2</mn><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /><mi>x</mi><mi>y</mi><mo>-</mo><mn>1</mn><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mn>0</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">而一般的椭圆方程为:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>Ax</i><sup>2</sup>+<i>Bxy</i>+<i>Cy</i><sup>2</sup>+<i>Dx</i>+<i>Ey</i>+1=0      (7) </p>
                </div>
                <div class="p1">
                    <p id="62">其几何中心为:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo>=</mo><mfrac><mrow><mi>B</mi><mi>E</mi><mo>-</mo><mn>2</mn><mi>C</mi><mi>D</mi></mrow><mrow><mn>4</mn><mi>A</mi><mi>C</mi><mo>-</mo><mi>B</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mtd></mtr><mtr><mtd><mi>Y</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo>=</mo><mfrac><mrow><mi>B</mi><mi>D</mi><mo>-</mo><mn>2</mn><mi>A</mi><mi>E</mi></mrow><mrow><mn>4</mn><mi>A</mi><mi>C</mi><mo>-</mo><mi>B</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其长短半轴分别<i>a</i><sub>1</sub>, <i>b</i><sub>1</sub>, 则有:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mn>2</mn><mo stretchy="false"> (</mo><mi>A</mi><mi>X</mi><msub><mrow></mrow><mtext>c</mtext></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>C</mi><mi>Y</mi><msub><mrow></mrow><mtext>c</mtext></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>B</mi><mi>X</mi><msub><mrow></mrow><mtext>c</mtext></msub><mi>Y</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>A</mi><mo>+</mo><mi>C</mi><mo>+</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>A</mi><mo>-</mo><mi>C</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>B</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr><mtr><mtd><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mn>2</mn><mo stretchy="false"> (</mo><mi>A</mi><mi>X</mi><msub><mrow></mrow><mtext>c</mtext></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>C</mi><mi>Y</mi><msub><mrow></mrow><mtext>c</mtext></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>B</mi><mi>X</mi><msub><mrow></mrow><mtext>c</mtext></msub><mi>Y</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>A</mi><mo>+</mo><mi>C</mi><mo>-</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>A</mi><mo>-</mo><mi>C</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>B</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">根据椭圆面积公式可知, 投影在<i>XOY</i>平面的椭圆面积为π<i>a</i><sub>1</sub><i>b</i><sub>1</sub>。而三维空间中的截面的法向量为 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 。设椭球投影面积为<i>S</i>, 根据高等数学中投影知识有:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mtext>π</mtext><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><msqrt><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>/</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">根据式 (10) , 可以求出投影面积在点 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 的梯度, 即求出在点 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 处使得投影面积变化最大的方向。</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mo>∂</mo><mi>S</mi></mrow><mrow><mo>∂</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo>, </mo><mfrac><mrow><mo>∂</mo><mi>S</mi></mrow><mrow><mo>∂</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo>, </mo><mfrac><mrow><mo>∂</mo><mi>S</mi></mrow><mrow><mo>∂</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">将 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 的实际数值代入式 (11) , 即可得到梯度方向。不管是梯度方向还是梯度的反方向都是使得投影面积变化最大的方向, 即得到了机器人控制方向。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">1.3 <b>多模滤波模型</b></h4>
                <div class="p1">
                    <p id="72">交互多模滤波器 (Interacting Multi-Mode Filter, IMMF) 是计算效率较高的次优状态估计算法, 主要用于对马尔可夫切换系统的估计问题。假设<b><i>z</i></b><sub><i>k</i></sub>代表<i>k</i>时刻得到的观测值, <b><i>X</i></b><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>和<b><i>P</i></b><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>为<i>k</i>时刻对于<i>j</i>模态系统状态估计和协方差阵, <b><i>X</i></b><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup></mrow></math></mathml>和<b><i>P</i></b><mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup></mrow></math></mathml>为<i>k</i>时刻对于<i>j</i>模态混合初始状态和协方差阵, <b><i>X</i></b><sub><i>k</i></sub>和<b><i>P</i></b><sub><i>k</i></sub>为<i>k</i>时刻系统的组合状态估计值和协方差阵, <i>μ</i><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>j</mi></mrow></msubsup></mrow></math></mathml>为<i>k</i>时刻的混合可能性值, <i>μ</i><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>为<i>k</i>时刻的模态可能性值, <i>Λ</i><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>为目标<i>j</i>模态的相似度函数, <b><i>v</i></b><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>代表<i>j</i>模态系统此刻的观测残差向量。<i>M</i>为可能的所有模态集合序列, 算法框架如图2所示。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 交互多模滤波流程" src="Detail/GetImg?filename=images/JSJY201903041_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 交互多模滤波流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Interactive multi-mode filtering process</p>

                </div>
                <div class="p1">
                    <p id="82">该处理过程如下:</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">1) 数据交互过程。</h4>
                <div class="p1">
                    <p id="84">首先对于∀<i>i</i>, <i>j</i>∈[1, 2, …, <i>M</i>]计算混合概率值<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>j</mi></mrow></msubsup><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>/</mo><mover accent="true"><mi>c</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo><mi mathvariant="bold-italic">p</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msup><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup></mrow></math></mathml>, 其中假设目标运动模态按照马尔可夫链规律变化, 不同模态间的转化可能性为<b><i>p</i></b><sup><i>i</i>, <i>j</i></sup>=<i>P</i> (<i>Mod</i><sub><i>k</i></sub>=<i>j</i>|<i>Mod</i><sub><i>k</i>-1</sub>=<i>i</i>) ( <i>j</i>, <i>i</i>∈[1, 2, …, <i>M</i>]) ;<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>c</mi><mo>¯</mo></mover></math></mathml><sub><i>j</i></sub>为归一化因数 (先验模式概率值) , 其值为<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>c</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi mathvariant="bold-italic">p</mi></mstyle><msup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msup><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup></mrow></math></mathml>。之后对于∀<i>j</i>∈[1, 2, …, <i>M</i>]计算初始状态和协方差阵, 即:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi mathvariant="bold-italic">X</mi></mstyle><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>j</mi></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">{</mo></mstyle><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>+</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup><msup><mo stretchy="false">]</mo><mo>′</mo></msup><mo stretchy="false">}</mo><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>j</mi></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2) 不同模态状态预测阶段。</h4>
                <div class="p1">
                    <p id="90">对于目标运动不同模态<b><i>j</i></b>∈[1, 2, …, <b><i>M</i></b>], 其对应系统状态向量和协方差阵的预测:</p>
                </div>
                <div class="p1">
                    <p id="91"><b><i>X</i></b><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">|</mo><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml>=<b><i>f</i></b><sup><i>sp</i>, <i>j</i></sup> (<b><i>X</i></b><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup></mrow></math></mathml>, <b><i>u</i></b><sup>R</sup><sub><i>k</i>|<i>k</i>-1</sub>, Δ<i>t</i>, <b><i>A</i></b><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi mathvariant="bold">Τ</mi><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">j</mi></mrow></msubsup></mrow></math></mathml>, <b><i>q</i></b><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi mathvariant="bold">Τ</mi><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">j</mi></mrow></msubsup></mrow></math></mathml>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="96"><b><i>P</i></b><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>=<b><i>f</i></b><sup><i>cp</i>, <i>j</i></sup> (<b><i>P</i></b><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">j</mi></mrow></msubsup></mrow></math></mathml>, <b><i>X</i></b><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msubsup></mrow></math></mathml>, <b><i>u</i></b><sup>R</sup><sub><i>k</i>|<i>k</i>-1</sub>, <b><i>Q</i></b><sup>u</sup>, Δ<i>t</i>, <b><i>A</i></b><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi mathvariant="bold">Τ</mi><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">j</mi><mspace width="0.25em" /></mrow></msubsup></mrow></math></mathml>, <b><i>Q</i></b><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi mathvariant="bold-italic">Τ</mi><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">j</mi><mspace width="0.25em" /></mrow></msubsup></mrow></math></mathml>)      (15) </p>
                </div>
                <div class="p1">
                    <p id="102">其中<b><i>f</i></b><sup><i>sp</i>, <i>j</i></sup>, <b><i>f</i></b><sup><i>cp</i>, <i>j</i></sup>分别代表针对不同目标运动模态的系统状态和协方差预测函数, 若有观测值出现继续, 否则转到步骤6) 。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">3) 不同模态状态更新阶段。</h4>
                <div class="p1">
                    <p id="104">针对不同目标运动模式, 完成不同模态系统状态和协方差阵的更新:</p>
                </div>
                <div class="p1">
                    <p id="105"><b><i>X</i></b><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>=<b><i>X</i></b><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">|</mo><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml>+<b><i>K</i></b><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">k</mi><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>·<b><i>v</i></b><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">k</mi><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>      (16) </p>
                </div>
                <div class="p1">
                    <p id="110"><b><i>P</i></b><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>=<b><i>P</i></b><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">|</mo><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml>-<b><i>K</i></b><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">k</mi><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>·<b><i>S</i></b><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>· (<b><i>K</i></b><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">k</mi><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml>) ′      (17) </p>
                </div>
                <h4 class="anchor-tag" id="116" name="116">4) 模式概率更新。</h4>
                <div class="p1">
                    <p id="117">不同于传统的IMM (Interactive Multi-Mode) , 此处<i>Λ</i><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>的取值只考虑目标观测值可能性并不考虑特征观测值可能性, 因此<i>Λ</i><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml>=Ν (<b><i>v</i></b><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">k</mi><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml> (1:2) ;0, <b><i>S</i></b><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">k</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">k</mi><mo>-</mo><mn>1</mn></mrow><mi mathvariant="bold-italic">j</mi></msubsup></mrow></math></mathml> (1:2, 1:2) ) , 其中<b><i>v</i></b><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup></mrow></math></mathml> (1:2) 表示取<b><i>v</i></b><mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml>的前两项 (对应目标观测值差异) , <b><i>S</i></b><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">|</mo><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml> (1:2, 1:2) 表示取<b><i>S</i></b><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">|</mo><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup></mrow></math></mathml>的1至2行和1至2列组成的子阵 (对应目标观测协方差子阵) 。之后对于各模式<i>j</i>计算本次更新后的模式可能性 (后验模式概率值) , 即:</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>/</mo><mi>c</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi mathvariant="bold-italic">Λ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>⋅</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi mathvariant="bold-italic">p</mi></mstyle><msup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msup><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>/</mo><mi>c</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi mathvariant="bold-italic">Λ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>⋅</mo><mover accent="true"><mi>c</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">其中<b><i>c</i></b>为归一化因数。</p>
                </div>
                <h4 class="anchor-tag" id="128" name="128">5) 系统扩充。</h4>
                <div class="p1">
                    <p id="167">当发现新特征的观测值时, 完成状态向量和协方差阵的扩充。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">6) 系统状态估计, 协方差阵组合产生。</h4>
                <div class="p1">
                    <p id="130">最终通过加权得到本次迭代的系统状态估计和协方差阵, 计算方法如下:</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="bold-italic">X</mi></mstyle><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mo stretchy="false">{</mo></mstyle><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>+</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>j</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>k</mi></msub><msup><mo stretchy="false">]</mo><mo>′</mo></msup><mo stretchy="false">}</mo><mo>⋅</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="132" name="132" class="anchor-tag">2 仿真结果</h3>
                <div class="p1">
                    <p id="133">本文先在传统EKF_SLAM (Extended Kalman Filter—Simultaneous Localization and Mapping) 框架内, 分别研究次优视差算法和启发式算法的跟踪效果。在此基础上, 再研究多模滤波算法的跟踪效果。</p>
                </div>
                <div class="p1">
                    <p id="134">在人们的先验认知中, 平行椭球最短轴会产生较大的视差 (启发式算法) 。为了验证次优视差算法的可行性, 将启发式算法与次优视差算法进行对照实验。通过对比目标的实际位置与估计位置的残差均值大小, 评定更优的方法。</p>
                </div>
                <div class="p1">
                    <p id="135">实验所用电脑为DELL INTEL I5 双核, Matlab仿真实验软件, 以及Toolbox工具箱。</p>
                </div>
                <div class="p1">
                    <p id="136">不难想象, 视差速度将影响视差大小, 从而影响对目标状态的估计效果。为此, 分别设置视差速度从0.1 m/s到0.5 m/s, 研究其对跟踪效果的影响, 得到表1。</p>
                </div>
                <div class="area_img" id="137">
                    <p class="img_tit"><b>表</b>1 <b>视差速度及相应残差均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Parallax speed and corresponding residual mean</p>
                    <p class="img_note"></p>
                    <table id="137" border="1"><tr><td rowspan="2"><br />视差速度/ (m·s<sup>-1</sup>) </td><td><br />残差均值/m</td><td rowspan="2"></td></tr><tr><td><br />启发式均值</td><td>本文方法</td></tr><tr><td><br />0.1</td><td>18.20</td><td>0.46</td></tr><tr><td><br />0.2</td><td>0.35</td><td>0.25</td></tr><tr><td><br />0.3</td><td>0.25</td><td>0.16</td></tr><tr><td><br />0.4</td><td>0.15</td><td>0.15</td></tr><tr><td><br />0.5</td><td>0.13</td><td>0.10</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="138">为了更加直观地反映表1中数据, 将其转换为柱状图的形式如图3和4所示。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 视差速度 (0.1～0.5 m/s) 与残差均值关系" src="Detail/GetImg?filename=images/JSJY201903041_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 视差速度 (0.1～0.5 m/s) 与残差均值关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Relationship between parallax speed, 0.1 m/s to 0.5 m/s, and residual mean</p>

                </div>
                <div class="p1">
                    <p id="140">由于视差速度为0.1 m/s时, 启发式方法的残差均值过大, 影响对整体效果的观测, 故剔除视差速度为0.1 m/s的点, 得到图4。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 视差速度 (0.2～0.5 m/s) 与残差均值关系" src="Detail/GetImg?filename=images/JSJY201903041_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 视差速度 (0.2～0.5 m/s) 与残差均值关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Relationship between parallax speed, 0.2 m/s to 0.5 m/s, and residual mean</p>

                </div>
                <div class="p1">
                    <p id="142">当视差速度分别为0.1 m/s (较小) 、0.3 m/s (中等) 和0.5 m/s (较大) 时, 通过仿真, 得到启发式算法和次优视差算法的结果如图5所示。</p>
                </div>
                <div class="p1">
                    <p id="143">当视差速度大小为0.1 m/s时, 由图5 (a) 和图5 (b) 可以看出, 次优视差算法残差均值为0.46 m远远小于启发式算法残差均值18.2 m;当视差速度为0.3 m/s (中等) 时, 由图5 (c) 和图5 (d) 可以看出, 启发式算法残差均值为0.25 m, 次优视差算法残差均值为0.16 m;当视差速度为0.5 m/s (较大) 时, 由图5 (e) 和图5 (f) 可以看出, 启发式算法和次优视差算法残差均值分别为0.13 m、0.1 m。由此可见, 次优视差算法跟踪效果比启发式算法好, 但随着视差速度提高, 两种算法差距越来越小。</p>
                </div>
                <div class="p1">
                    <p id="144">当视差速度为0.5 m/s时, 得到次优视差算法的目标跟踪轨迹如图6所示。</p>
                </div>
                <div class="p1">
                    <p id="145">而在实际情况中, 机动目标大多数是以多模态运动的。因此, 用多模滤波的方法对机动目标进行跟踪显得十分必要。分别用传统EKF_SLAM算法和多模滤波算法对机动目标进行跟踪。在仿真实验中, 设定目标1～100帧及451～520帧为定速模型;101～450帧及 521～550为转弯模型 (转弯时速度大小保持不变) ;551～600帧为加速模型。得到轨迹如图7所示。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 次优视差算法与启发式算法仿真结果" src="Detail/GetImg?filename=images/JSJY201903041_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 次优视差算法与启发式算法仿真结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Simulation results of suboptimal parallax algorithm and heuristic algorithm</p>

                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 目标实际轨迹与预测轨迹 (视差速度0.5 m/s)" src="Detail/GetImg?filename=images/JSJY201903041_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 目标实际轨迹与预测轨迹 (视差速度0.5 m/s)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Target actual trajectory and predicted trajectory with parallax speed of 0.5 m/s</p>

                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 传统方法与多模滤波方法轨迹" src="Detail/GetImg?filename=images/JSJY201903041_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 传统方法与多模滤波方法轨迹  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Trajectory of traditional method and multi-mode filtering method</p>

                </div>
                <div class="p1">
                    <p id="149">在此基础上, 分别计算两种算法的残差均值, 得到图8。</p>
                </div>
                <div class="area_img" id="150">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903041_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 传统方法与多模滤波方法残差均值" src="Detail/GetImg?filename=images/JSJY201903041_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 传统方法与多模滤波方法残差均值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903041_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Residual mean of traditional method and multi-mode filtering method</p>

                </div>
                <div class="p1">
                    <p id="151">由图8 (a) 和图8 (b) 可以看出, 传统EKF_SLAM目标跟踪残差均值为0.15 m, 而多模滤波目标跟踪残差均值仅为0.06 m。另外, 在目标模态变化时, 多模滤波目标跟踪能更准确地预测目标状态。</p>
                </div>
                <h3 id="152" name="152" class="anchor-tag">3 结语</h3>
                <div class="p1">
                    <p id="153">本文通过数学推导证明本文方法的理论性, 通过仿真实验验证了本文方法的可行性, 同时根据仿真实验结果可以得出以下结论:</p>
                </div>
                <div class="p1">
                    <p id="154">1) 在视差速度大小相同的情况下, 本文算法要优于启发式算法。</p>
                </div>
                <div class="p1">
                    <p id="155">2) 当视差速度较小时, 启发式算法误差很大, 导致跟踪失败, 而本文算法误差较小, 能保持跟踪正常进行, 这说明本文方法能够节省能耗, 具有工程应用价值。</p>
                </div>
                <div class="p1">
                    <p id="156">3) 随着控制速度增大, 所获得的视差越大, 两种方法对目标状态的估计误差越小, 同时两种方法之间估计的差距也越小。</p>
                </div>
                <div class="p1">
                    <p id="157">4) 对于机动目标, 多模滤波的目标跟踪算法估计效果更准确, 其残差均值不到传统EKF_SLAM目标跟踪算法的1/2。</p>
                </div>
                <div class="p1">
                    <p id="158">5) 视差方向的选取和速度大小的控制对目标跟踪影响大, 说明对于单目SLAMOT问题, 控制策略的研究十分必要。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization and mapping with detection and tracking of moving objects">

                                <b>[1]</b> WANG C-C, THORPE C. Simultaneous localization and mapping with detection and tracking of moving objects [C]// Proceedings of the 2002 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2002: 2918-2924.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization, mapping and moving object tracking">

                                <b>[2]</b> WANG C-C, THORPE C, THRUN S, et al. Simultaneous localization, mapping and moving object tracking [J]. International Journal of Robotics Research, 2007, 26 (9) : 889-916.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weakly interacting object tracking in indoor environments">

                                <b>[3]</b> WAN K W, WANG C-C, TON T T. Weakly interacting object tracking in indoor environments [C]// Proceedings of the 2008 IEEE Workshop on Advanced Robotics and Its Social Impacts. Piscataway, NJ: IEEE, 2008:1-6.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online simultaneous localiza-tion and mapping with detection and tracking of moving ob-jects:Theory and results from a ground vehicle in crowded ur-ban areas">

                                <b>[4]</b> WANG C-C, THORPE C, THRUN S. Online simultaneous localization and mapping with detection and tracking of moving objects: theory and results from a ground vehicle in crowded urban areas [C]// Proceedings of the 2003 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2003, 1: 842-849.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online localization and mapping with moving objects detection in dynamic outdoor environments">

                                <b>[5]</b> BAIG Q, VU T-D, AYCARD O. Online localization and mapping with moving objects detection in dynamic outdoor environments [C]// Proceedings of the 2009 IEEE 5th International Conference on Intelligent Computer Communication and Processing. Piscataway, NJ: IEEE, 2009: 190-195.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interacting object tracking in crowded urban areas">

                                <b>[6]</b> WANG C-C, LO T-C, YANG S-W. Interacting object tracking in crowded urban areas [C]// Proceedings of the 2007 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2007: 4626-4632.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Inverse Depth Parametrization for Monocular SLAM">

                                <b>[7]</b> CIVERA J, DAVISON A J, MONTIEL J M M. Inverse depth parametrization for monocular SLAM [J]. IEEE Transactions on Robotics, 2008, 24 (5) : 932-945.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time simultaneous localisation and mapping with a single camera">

                                <b>[8]</b> DAVISON A J. Real-time simultaneous localisation and mapping with a single camera [C]// ICCV '03: Proceedings of the 9th IEEE International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1403.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MonoSLAM: Real-Time Single Camera SLAM">

                                <b>[9]</b> DAVISON A J, REID I D, MOLTON N D, et al. MonoSLAM: real-time single camera SLAM [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 1052-1067.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust multiperson tracking from a mobile platform">

                                <b>[10]</b> ESS A, LEIBE B, SCHINDLER K, et al. Robust multiperson tracking from a mobile platform [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (10) : 1831-1846.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Moving obstacle detection in highly dynamic scenes">

                                <b>[11]</b> ESS A, LEIBE B, SCHINDLER K, et al. Moving obstacle detection in highly dynamic scenes [C]// Proceedings of the 2009 IEEE International Conference on Robotics and Automation. Piscataway, NJ: IEEE, 2009:56-63.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A mobile vision systemfor robust multi-person tracking">

                                <b>[12]</b> ESS A, LEIBE B, SCHINDLER K, et al. A mobile vision system for robust multi-person tracking [C]// Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2008: 1-8.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001252569&amp;v=Mjg4NTZVci9MSlZjPU5pZmNhck80SHRITnJZcEhZZTBHWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaS9s&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> CIVERA J, GRASA O G, DAVISON A J, et al. 1-point RANSAC for extended Kalman filtering: application to real-time structure from motion and visual odometry [J]. Journal of Field Robotics, 2010, 27 (5) : 609-631.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300117346&amp;v=MTM2NjlpZk9mYks3SHRETnJJOUZaZW9JRDNnL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSUlWNFhieHM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> LI H-P, XU D-M, ZHANG F-B, et al. Consistency analysis of EKF-based SLAM by measurement noise and observation times [J]. Acta Automatica Sinica, 2009, 35 (9) : 1177-1184.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201304016&amp;v=Mjk1MDZxZlp1WnBGeW5sVUxyQkx6elpmTEc0SDlMTXE0OUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 梁明杰, 闵华清, 罗荣华.基于图优化的同时定位与地图创建综述[J].机器人, 2013, 35 (4) :500-512. (LIANG M J, MIN H Q, LUO R H. Graph-based SLAM: a survey [J]. Robot, 2013, 35 (4) : 500-512.) This work is partially supported by the National Natural Science Foundation of China (61503389) , the Natural Science Foundation of Shaanxi Province (2016JM6061) .HUANG Shuai, born in 1994, M. S. candidate. His research interests include object tracking, monocular SLAM.FU Guangyuan, born in 1965, Ph. D., professor. His research interests include artificial intelligence, command information system.WU Ming, born in 1981, Ph. D., lecturer. His research interests include object tracking, monocular SLAM.YUE Min, born in 1995, Ph. D. candidate. Her research interests include object tracking, monocular SLAM.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903041" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903041&amp;v=MjczNjZHNEg5ak1ySTlCWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMck9MejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI2aVh3Zy9MOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
