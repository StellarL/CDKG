<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136456057315000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910016%26RESULT%3d1%26SIGN%3dzSE%252bWRbpnYOs6zhpKqtrlKMKwws%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910016&amp;v=MjU5NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oVWJ6SUx6N0JkN0c0SDlqTnI0OUVZb1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 构建集成式长短期记忆网络 ">1 构建集成式长短期记忆网络</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="2 基于VGG-16网络优化卷积层参数 ">2 基于VGG-16网络优化卷积层参数</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="3 基于&lt;i&gt;DC&lt;/i&gt;-&lt;i&gt;ILSTM&lt;/i&gt;网络的烟雾检测方法 ">3 基于<i>DC</i>-<i>ILSTM</i>网络的烟雾检测方法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="4.1 &lt;b&gt;实验环境&lt;/b&gt;">4.1 <b>实验环境</b></a></li>
                                                <li><a href="#90" data-title="4.2 &lt;b&gt;实验数据集&lt;/b&gt;">4.2 <b>实验数据集</b></a></li>
                                                <li><a href="#92" data-title="4.3 &lt;b&gt;实验评价标准&lt;/b&gt;">4.3 <b>实验评价标准</b></a></li>
                                                <li><a href="#96" data-title="4.4 &lt;b&gt;实验结果与分析&lt;/b&gt;">4.4 <b>实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="图1 LSTM细胞结构示意图">图1 LSTM细胞结构示意图</a></li>
                                                <li><a href="#62" data-title="图2 ILSTM模块结构">图2 ILSTM模块结构</a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;i&gt;VGG&lt;/i&gt;-16&lt;b&gt;与其他&lt;/b&gt;&lt;i&gt;CNN&lt;/i&gt;&lt;b&gt;模型参数比较&lt;/b&gt;"><b>表</b>1 <i>VGG</i>-16<b>与其他</b><i>CNN</i><b>模型参数比较</b></a></li>
                                                <li><a href="#68" data-title="图3 基于&lt;i&gt;VGG&lt;/i&gt;-16网络的迁移学习模型">图3 基于<i>VGG</i>-16网络的迁移学习模型</a></li>
                                                <li><a href="#71" data-title="图4 &lt;i&gt;DC&lt;/i&gt;-&lt;i&gt;ILSTM&lt;/i&gt;网络结构">图4 <i>DC</i>-<i>ILSTM</i>网络结构</a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;i&gt;CNN&lt;/i&gt;&lt;b&gt;与其他模型训练过程中 验证集的准确性对比&lt;/b&gt; 单位:%"><b>表</b>2 <i>CNN</i><b>与其他模型训练过程中 验证集的准确性对比</b> 单位:%</a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;i&gt;ILSTM&lt;/i&gt;&lt;b&gt;和&lt;/b&gt;&lt;i&gt;LSTM&lt;/i&gt;&lt;b&gt;训练过程中 验证集的准确性对比&lt;/b&gt;"><b>表</b>3 <i>ILSTM</i><b>和</b><i>LSTM</i><b>训练过程中 验证集的准确性对比</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;i&gt;VGG&lt;/i&gt;-16&lt;b&gt;和&lt;/b&gt;&lt;i&gt;DC&lt;/i&gt;-&lt;i&gt;ILSTM&lt;/i&gt;&lt;b&gt;训练过程中 验证集的准确性对比&lt;/b&gt;"><b>表</b>4 <i>VGG</i>-16<b>和</b><i>DC</i>-<i>ILSTM</i><b>训练过程中 验证集的准确性对比</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;三种方法的视频烟雾检测速度比较&lt;/b&gt;"><b>表</b>5 <b>三种方法的视频烟雾检测速度比较</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;表&lt;/b&gt;6 &lt;b&gt;三种方法的测试结果&lt;/b&gt;"><b>表</b>6 <b>三种方法的测试结果</b></a></li>
                                                <li><a href="#112" data-title="图5 视频样本">图5 视频样本</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="130">


                                    <a id="bibliography_1" title="GENOVESE A,LABATI R D,PIURI V,et al.Wildfire smoke detection using computational intelligence techniques[C]//Proceedings of the 2011 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications.Piscataway:IEEE,2011:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wildfire Smoke Detection Using Computational Intelligence Techniques">
                                        <b>[1]</b>
                                        GENOVESE A,LABATI R D,PIURI V,et al.Wildfire smoke detection using computational intelligence techniques[C]//Proceedings of the 2011 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications.Piscataway:IEEE,2011:1-6.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_2" title="YUAN F.Video-based smoke detection with histogram sequence of LBP and LBPV pyramids[J].Fire Safety Journal,2011,46(3):132-139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100458948&amp;v=MDU4NDc9TmlmT2ZiSzdIdERPcm85RllPNEhCWGd4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZvV2FSSQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        YUAN F.Video-based smoke detection with histogram sequence of LBP and LBPV pyramids[J].Fire Safety Journal,2011,46(3):132-139.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_3" title="TOREYIN B U,DEDEOGLU Y,CETIN A E.Contour based smoke detection in video using wavelets[C]//Proceedings of the14th European Signal Processing Conference.Piscataway:IEEE,2006:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contour based smoke detection in video using wavelets">
                                        <b>[3]</b>
                                        TOREYIN B U,DEDEOGLU Y,CETIN A E.Contour based smoke detection in video using wavelets[C]//Proceedings of the14th European Signal Processing Conference.Piscataway:IEEE,2006:1-5.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_4" title="YU C,FAN J,WANG J,et al.Video fire smoke detection using motion and color features[J].Fire Technology,2010,46(3):651-663." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15110200836187&amp;v=MTUwMDVNbndaZVp0RmlubFVyM0lJVm9XYVJJPU5qN0Jhcks5SDlETXJZOUZiT2dKRFhRK29CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        YU C,FAN J,WANG J,et al.Video fire smoke detection using motion and color features[J].Fire Technology,2010,46(3):651-663.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_5" title="JIA Y,YUAN J,WANG J,et al.A saliency-based method for early smoke detection in video sequences[J].Fire Technology,2016,52(5):1271-1292." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Saliency-Based Method for Early Smoke Detection in Video Sequences">
                                        <b>[5]</b>
                                        JIA Y,YUAN J,WANG J,et al.A saliency-based method for early smoke detection in video sequences[J].Fire Technology,2016,52(5):1271-1292.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_6" title="ZHANG Q,XU J,XU L,et al.Deep convolutional neural networks for forest fire detection[C]//Proceedings of the 2016 International Forum on Management,Education and Information Technology Application.Paris:Atlantis Press,2016:568-575." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural networks for forest fire detection">
                                        <b>[6]</b>
                                        ZHANG Q,XU J,XU L,et al.Deep convolutional neural networks for forest fire detection[C]//Proceedings of the 2016 International Forum on Management,Education and Information Technology Application.Paris:Atlantis Press,2016:568-575.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_7" title="FRIZZI S,KAABI R,BOUCHOUICHA M,et al.Convolutional neural network for video fire and smoke detection[C]//Proceedings of the,42nd Annual Conference of the IEEE Industrial Electronics Society.Piscataway:IEEE,2016:877-882." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network for video fire and smoke detection">
                                        <b>[7]</b>
                                        FRIZZI S,KAABI R,BOUCHOUICHA M,et al.Convolutional neural network for video fire and smoke detection[C]//Proceedings of the,42nd Annual Conference of the IEEE Industrial Electronics Society.Piscataway:IEEE,2016:877-882.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_8" title="YIN Z,WAN B,YUAN F,et al.A deep normalization and convolutional neural network for image smoke detection[J].IEEE Access,2017,5:18429-18438." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A deep normalization and convolutional neural network for image smoke detection">
                                        <b>[8]</b>
                                        YIN Z,WAN B,YUAN F,et al.A deep normalization and convolutional neural network for image smoke detection[J].IEEE Access,2017,5:18429-18438.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_9" title="MUHAMMAD K,AHMAD J,MEHMOOD I,et al.Convolutional neural networks based fire detection in surveillance videos[J].IEEE Access,2018,6:18174-18183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolu- tionalNeural Networks based Fire Detection in Surveillance Vi-deos">
                                        <b>[9]</b>
                                        MUHAMMAD K,AHMAD J,MEHMOOD I,et al.Convolutional neural networks based fire detection in surveillance videos[J].IEEE Access,2018,6:18174-18183.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_10" title="SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[10]</b>
                                        SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1-9.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_11" title="ZHANG Q,LIN G,ZHANG Y,et al.Wildland forest fire smoke detection based on faster R-CNN using synthetic smoke images[J].Procedia Engineering,2018,211:441-446." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA2978B314EA7D7F89CA432F7CA797800&amp;v=MTU3MDdIWWZPR1FsZkJyTFUwNXRwaHhieTl3Nmc9TmlmT2ZjSzZGOWJFM1l4RVlKNStDd2crdVI0YW1VNTVTMzJVcTJGRWZydVRUYnFmQ09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        ZHANG Q,LIN G,ZHANG Y,et al.Wildland forest fire smoke detection based on faster R-CNN using synthetic smoke images[J].Procedia Engineering,2018,211:441-446.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_12" title="王文朋,毛文涛,何建樑,等.基于深度迁移学习的烟雾识别方法[J].计算机应用,2017,37(11):144-149,161.(WANG W P,MAO W T,HE J L,et al.Smoke recognition based on deep transfer learning[J].Journal of Computer Applications,2017,37(11):144-149,161.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201711025&amp;v=MjYzNDF6N0JkN0c0SDliTnJvOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oVWJ6SUw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        王文朋,毛文涛,何建樑,等.基于深度迁移学习的烟雾识别方法[J].计算机应用,2017,37(11):144-149,161.(WANG W P,MAO W T,HE J L,et al.Smoke recognition based on deep transfer learning[J].Journal of Computer Applications,2017,37(11):144-149,161.)
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_13" title="FILONENKO A,KURNIANGGORO L,JO K.Smoke detection on video sequences using convolutional and recurrent neural networks[C]//Proceedings of the 2017 International Conference on Computational Collective Intelligence,LNCS 10449.Cham:Springer,2017:558-566." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Smoke detection on video sequences using convolutional and recurrent neural networks">
                                        <b>[13]</b>
                                        FILONENKO A,KURNIANGGORO L,JO K.Smoke detection on video sequences using convolutional and recurrent neural networks[C]//Proceedings of the 2017 International Conference on Computational Collective Intelligence,LNCS 10449.Cham:Springer,2017:558-566.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_14" title="HU C,TANG P,JIN W,et al.Real-time fire detection based on deep convolutional long-recurrent networks and optical flow method[C]//Proceedings of the 37th Chinese Control Conference.Piscataway:IEEE,2018:9061-9066." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time fire detection based on deep convolutional long-recurrent networks and optical flow method">
                                        <b>[14]</b>
                                        HU C,TANG P,JIN W,et al.Real-time fire detection based on deep convolutional long-recurrent networks and optical flow method[C]//Proceedings of the 37th Chinese Control Conference.Piscataway:IEEE,2018:9061-9066.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-08-19 09:03</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),2883-2887 DOI:10.11772/j.issn.1001-9081.2019040707            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度卷积长短期记忆网络的森林火灾烟雾检测模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%AB%E9%91%AB&amp;code=42897028&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卫鑫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AD%A6%E6%B7%91%E7%BA%A2&amp;code=08871331&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武淑红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%80%80%E5%8A%9B&amp;code=24226514&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王耀力</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学信息与计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对采样的每帧烟雾特征具有极大的相似性,以及森林火灾烟雾数据集相对较小且单调等问题,为充分利用烟雾的静态与动态信息来达到预防森林火灾的目的,提出一种深度卷积集成式长短期记忆网络(DC-ILSTM)模型。首先,使用在ImageNet数据集上预训练好的VGG-16网络进行基于同构数据的特征迁移,以有效提取出烟雾特征;其次,基于池化层与长短期记忆网络(LSTM)提出一种集成式长短期记忆网络(ILSTM),并利用ILSTM分段融合烟雾特征;最后,搭建一种可训练的深度神经网络模型用于森林火灾烟雾检测。烟雾检测实验中,与深卷积长递归网络(DCLRN)相比,DC-ILSTM在最佳效率下以10帧的优势检测到烟雾,而且在测试准确率上提高了1.23个百分点。实验结果表明,DC-ILSTM在森林火灾烟雾检测中有很好的适用性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%83%9F%E9%9B%BE%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">烟雾检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迁移学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微量数据集;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    卫鑫(1994—),女,山西吕梁人,硕士研究生,主要研究方向:机器学习、深度学习;;
                                </span>
                                <span>
                                    *武淑红(1969—),女,山西太原人,副教授,博士,主要研究方向:音视频编码算法、金融信息系统设计、SoC与嵌入式系统;电子邮箱1660347265@qq.com;
                                </span>
                                <span>
                                    王耀力(1965—),男,山西太原人,副教授,博士,主要研究方向:信息系统设计、人机视觉分析与处理、嵌入式系统。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61828601);</span>
                                <span>山西省自然科学基金资助项目(201801D121141);</span>
                    </p>
            </div>
                    <h1><b>Forest fire smoke detection model based on deep convolution long short-term memory network</b></h1>
                    <h2>
                    <span>WEI Xin</span>
                    <span>WU Shuhong</span>
                    <span>WANG Yaoli</span>
            </h2>
                    <h2>
                    <span>College of Information and Computer, Taiyuan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Since the smoke characteristics of each sampled frame have great similarity, and the forest fire smoke dataset is relatively small and monotonous, in order to make full use of the static and dynamic information of smoke to prevent forest fires, a Deep Convolution Integrated Long Short-Term Memory network(DC-ILSTM) model was proposed. Firstly, VGG-16 networks pre-trained on ImageNet dataset were used for feature transfer based on isomorphic data to effectively extract smoke characteristics. Secondly, an Integrated Long Short-Term Memory network(ILSTM) based on pooling layer and Long Short-Term Memory network(LSTM) was proposed, and ILSTM was used for segmental fusion of smoke characteristics. Finally, a trainable deep neural network model was built for forest fire smoke detection. In the smoke detection experiment, compared with Deep Convolution Long Recursive Network(DCLRN), DC-ILSTM can detect smoke with 10 frames advantage under the optimal efficiency and has the test accuracy increased by 1.23 percentage points. The theoretical analysis and simulation results show that DC-ILSTM has good applicability in forest fire smoke detection.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=smoke%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">smoke detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20Short-Term%20Memory%20network(LSTM)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long Short-Term Memory network(LSTM);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=transfer%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">transfer learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=small%20dataset&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">small dataset;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WEI Xin,born in 1994,M.S.candidate.Her research interests include machine learning,deep learning.;
                                </span>
                                <span>
                                    WU Shuhong,born in 1969,Ph.D.,associate professor.Her research interests include audio and video coding algorithms,financial information system design,So C and embedded system.;
                                </span>
                                <span>
                                    WANG Yaoli,born in 1965,Ph.D.,associate professor.His research interests include information system design,man-machine vision analysisand processing,embedded system.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-24</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61828601);</span>
                                <span>the Natural Science Foundation of Shanxi Province(201801D121141);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="32">传统的烟雾检测方法大多采用物理传感器进行检测,该类方法对环境依赖较强、检测范围小,且需要安装大量传感器,对人力和物力造成较大消耗。随着图像处理、模式识别和人工智能等技术的发展,视频烟雾检测技术具有很好的应用前景。该技术不仅弥补了传统方法的不足,而且在初期能够对火灾进行有效检测,降低火灾所造成的危害。</p>
                </div>
                <div class="p1">
                    <p id="33">相较于传统的计算机视觉方法<citation id="160" type="reference"><link href="130" rel="bibliography" /><link href="132" rel="bibliography" /><link href="134" rel="bibliography" /><link href="136" rel="bibliography" /><link href="138" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>,深度学习算法可从大量的图像数据集中进行自主学习,避免了人工提取特征的不足。文献<citation id="158" type="reference">[<a class="sup">6</a>]</citation>提出了一种级联卷积神经网络(Convolutional Neural Network, CNN)火灾分类器。该分类器将AlexNet网络与两个完全连接层和一个分类层相结合,达到了预防火灾的目的;文献<citation id="159" type="reference">[<a class="sup">7</a>]</citation>选取了一种用于视频火灾和烟雾检测的卷积神经网络,为火灾预测提供了一定的决策方向。但是,通过以上方法所构建的卷积神经网络模型仅限于处理2D输入问题,需要逐帧处理视频图像,时间开销显著增加。</p>
                </div>
                <div class="p1">
                    <p id="34">随后,文献<citation id="161" type="reference">[<a class="sup">8</a>]</citation>提出一种新型深度归一化卷积神经网络(Deep Normalization and CNN, DNCNN),将传统的卷积层替换为归一化层与卷积层;文献<citation id="162" type="reference">[<a class="sup">9</a>]</citation>采用与GoogLeNet<citation id="163" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>相似的模型进行烟雾检测。该类方法采用的模型均需以大量数据为研究基础,但在烟雾识别领域实际可用的烟雾数据量相对较小且单调。针对数据限制这一问题,文献<citation id="164" type="reference">[<a class="sup">11</a>]</citation>在野外森林火灾烟雾探测中使用了faster R-CNN,并且通过合成图像来创建烟雾图像序列以增强数据集。合成烟雾图像虽然可一定程度上提高检测性能,但在数据处理及训练过程中增加了较多成本。</p>
                </div>
                <div class="p1">
                    <p id="35">最近,利用循环神经网络(Recurrent Neural Network, RNN)解决视频烟雾检测问题得到了发展。此方法在文献<citation id="165" type="reference">[<a class="sup">12</a>]</citation>的下一阶段工作中也有提到。为了有效地利用长时间烟雾运动信息,文献<citation id="166" type="reference">[<a class="sup">13</a>]</citation>基于RNN提出了一种递归卷积神经网络,并成功应用于视频烟雾检测领域;文献<citation id="167" type="reference">[<a class="sup">14</a>]</citation>提出一种深度卷积长递归神经网络(Deep Convolutional Long-Recurrent Network, DCLRN),并将DCLRN与光流方法相结合,实现了对开放空间环境下火灾的实时监测。该类方法由于容易受烟雾变化和与烟雾特征相似的雾的干扰,在一些场景中无法进行很好的识别;同时,在如何结合更多的鉴别信息来改善烟雾检测问题上有待进一步研究。</p>
                </div>
                <div class="p1">
                    <p id="36">鉴于以上问题,本文将深度CNN和长短期记忆网络(Long Short-Term Memory network, LSTM)相结合提出一种深度卷积集成式长短期记忆网络(Deep Convolution Integrated LSTM, DC-ILSTM)模型。该模型不仅提取烟雾运动和空间特征,而且通过递归方法探索有效的信息来综合考虑烟雾区域的属性。首先,基于当下较为先进的深度CNN模型提出一种具有更好泛化能力的深度卷积网络用于提取烟雾特征;其次,为避免采样视频帧间存在的相似性问题,提出了一种集成式长短期记忆网络(Integrated LSTM, ILSTM)以处理烟雾特征;然后,针对森林火灾烟雾数据集小且单一的问题,使用预训练好的VGG-16网络进行特征迁移;最后,构建了一种可训练的网络模型。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag">1 构建集成式长短期记忆网络</h3>
                <div class="p1">
                    <p id="38">长短期记忆网络(LSTM)作为一种特殊的循环神经网络(RNN),不仅具有RNN对前面信息进行长时记忆的特点,还通过增加遗忘门避免长期依赖的问题。</p>
                </div>
                <div class="p1">
                    <p id="39">LSTM将输入映射到隐藏状态,并将隐藏状态映射到输出,可以有效地学习输入序列动态信息。在LSTM细胞结构中,包括遗忘门<i>f</i><sub><i>t</i></sub>、输入门<i>i</i><sub><i>t</i></sub>、输出门<i>O</i><sub><i>t</i></sub>和1个记忆单元,其内部结构如图1所示。</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910016_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 LSTM细胞结构示意图" src="Detail/GetImg?filename=images/JSJY201910016_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 LSTM细胞结构示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910016_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Schematic diagram of LSTM cell structure</p>

                </div>
                <div class="p1">
                    <p id="41">遗忘门决定了保留多少上一时刻的单元状态<i>C</i><sub><i>t</i></sub><sub>-1</sub>信息在当前状态<i>C</i><sub><i>t</i></sub>中,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="42"><i>f</i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i>f</i></sub>·+<i><b>b</b></i><sub><i>f</i></sub>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="43">输入门控制新信息的输入,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="44"><i>i</i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i>i</i></sub>·+<i><b>b</b></i><sub><i>i</i></sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="45"><i>C</i><sub><i>t</i></sub>′=tanh(<i><b>W</b></i><sub><i>c</i></sub>·+<i><b>b</b></i><sub><i>c</i></sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="46">更新记忆单元状态计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="47"><i>C</i><sub><i>t</i></sub>= <i>f</i><sub><i>t</i></sub>*<i>C</i><sub><i>t</i></sub><sub>-1</sub>+<i>i</i><sub><i>t</i></sub>*<i>C</i><sub><i>t</i></sub>′      (4)</p>
                </div>
                <div class="p1">
                    <p id="48">输出门计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>O</i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i>o</i></sub>+<i><b>b</b></i><sub><i>o</i></sub>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="50"><i>h</i><sub><i>t</i></sub>=<i>O</i><sub><i>t</i></sub>*tanh(<i>C</i><sub><i>t</i></sub>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="51">输出层计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="52"><i>y</i><sub><i>t</i></sub>=<i><b>W</b></i><sub><i>y</i></sub><i>h</i><sub><i>t</i></sub>      (7)</p>
                </div>
                <div class="p1">
                    <p id="53">LSTM能够分析烟雾的动态变化,但是,目前一些工作已经显示出在烟雾变化非常缓慢和具有与烟雾极其相似特征的场景下,仍然存在检测效率较低的问题。这是由于在同一个烟雾视频中,采样的每帧烟雾特征具有一定相似性。这使得LSTM不能够很好地学习输入的特征序列。因此,本文提出了ILSTM模块。</p>
                </div>
                <div class="p1">
                    <p id="54">ILSTM模块结构如图2所示。该模块首先将输入的烟雾特征序列进行分段处理;其次通过式(8)将分段的烟雾特征序列<i>x</i><sub><i>t</i></sub>∈<b>R</b><sup>4 096</sup>映射到[0,1]范围之间。</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">其中:<i>x</i><sub><i>t</i></sub>为实际值;<i>x</i>′<sub><i>t</i></sub>为归一化后的值;<i>x</i><sub>max</sub>与<i>x</i><sub>min</sub>为特征值中的最大与最小值。</p>
                </div>
                <div class="p1">
                    <p id="57">然后将得到的归一化输出值经过最大池化层处理。最大值池化算法就是对池化域中的特征值取最大。计算公式如式(9)所示:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>=</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中:<i>c</i>为池化域的大小和步长,矩阵<i>S</i>为池化操作后的特征图。</p>
                </div>
                <div class="p1">
                    <p id="60">最后,将聚合的特征输入到LSTM单元中,该单元将进一步融合烟雾特征进行最终的检测分类。</p>
                </div>
                <div class="p1">
                    <p id="61">本文提出的ILSTM模块目的是降低输入序列维度,并学习不同的特征表示。在实验中,该模块首先将特征序列均匀地划分成<i>d</i>个时间段;其次,每个时间段(即长度为<i>n</i>/<i>d</i>)特征值归一化到[0,1];然后,这些聚合的特征经过最大池化层(卷积核大小为2×2,步长为2);最后,结合LSTM单元递归地学习输入序列时序信息。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910016_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 ILSTM模块结构" src="Detail/GetImg?filename=images/JSJY201910016_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 ILSTM模块结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910016_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 ILSTM module structure diagram</p>

                </div>
                <h3 id="63" name="63" class="anchor-tag">2 基于VGG-16网络优化卷积层参数</h3>
                <div class="p1">
                    <p id="64">本文探索和比较了三种不同的<i>CNN</i>模型用于森林火灾烟雾检测,即<i>AlexNet</i>、<i>GoogleNet</i>和<i>VGG</i>-19。在<i>AlexNet</i>和<i>GoogleNet</i>模型中,分别使用大小为11×11和7×7,步长为3和5的较大卷积核,可能会忽略烟雾区域的重要特征。使用<i>VGG</i>-16的目的是使用大小为3×3,步长为1的卷积核,这有利于处理和提取烟雾图像的每个像素的特征;同时,与<i>VGG</i>-19相比,在精度几乎相同情况下使用的卷积层和参数较少。<i>VGG</i>-16与<i>AlexNet</i>和<i>GoogleNet</i>模型的参数比较如表1所示。从表1可看出,<i>VGG</i>- 16在<i>ImageNet</i>数据集上的<i>Top</i>-1准确率、<i>Top</i>-5准确率和<i>Top</i>-5测试错误率均优于其他最先进的架构。因此,本文根据森林火灾烟雾检测问题对<i>VGG</i>-16模型的体系结构进行了改进。</p>
                </div>
                <div class="area_img" id="65">
                    <p class="img_tit"><b>表</b>1 <i>VGG</i>-16<b>与其他</b><i>CNN</i><b>模型参数比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Parameter comparison of VGG</i>-16 <i>and other CNN models</i></p>
                    <p class="img_note"></p>
                    <table id="65" border="1"><tr><td><br />模型</td><td>参数量/10<sup>6</sup></td><td><i>Top</i>-1<br />准确率/%</td><td><i>Top</i>-5<br />准确率/%</td><td><i>Top</i>-5<br />错误率/%</td></tr><tr><td><i>GoogleNet</i></td><td>60</td><td>69.8</td><td>89.3</td><td>6.7</td></tr><tr><td><br /><i>AlexNet</i></td><td>7</td><td>57.5</td><td>80.3</td><td>16.4</td></tr><tr><td><br /><i>VGG</i>-16</td><td>138</td><td>70.5</td><td>91.0</td><td>7.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="66">本文基于<i>VGG</i>-16网络的迁移学习模型如图3所示。本文在<i>ImageNet</i>数据集上对模型进行了微调,以便用于森林火灾中烟和非烟的预期分类。如图3所示左侧是本文所使用的烟雾识别模型,主要由卷积层和下采样层交替构成。该模型共包含13个卷积层、5个下采样层,以及1个全连接层,其中:第一段由3×3×64卷积核构成的两层卷积层,第二段由3×3×128卷积核构成的两层卷积层,第三段由3×3×256卷积核构成的三层卷积层,第四段由3×3×512卷积核构成的三层卷积层,第五段由3×3×512的卷积核构成的三层卷积层,最后连接一层全连接层,神经元个数为4 096。</p>
                </div>
                <div class="p1">
                    <p id="67">该模型主要是由<i>VGG</i>-16网络迁移得到,同时加载了对应的<i>VGG</i>-16网络已经训练好的参数。首先,基于<i>VGG</i>-16网络构造卷积层和全连接层;其次,以烟雾数据集作为输入,获取<i>ImageNet</i>上已训练好的<i>VGG</i>-16网络中的卷积层参数;然后,训练模型并微调参数;最后,进行模型预测。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910016_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于VGG-16网络的迁移学习模型" src="Detail/GetImg?filename=images/JSJY201910016_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于<i>VGG</i>-16网络的迁移学习模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910016_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.3 <i>Transfer learning model based on VGG</i>-16</p>

                </div>
                <h3 id="69" name="69" class="anchor-tag">3 基于<i>DC</i>-<i>ILSTM</i>网络的烟雾检测方法</h3>
                <div class="p1">
                    <p id="70">该方法的主要目的是构建一种可训练的深度神经网络模型实现森林火灾烟雾检测。<i>DC</i>-<i>ILSTM</i>网络模型结构如图4所示。该模型首先用<i>VGG</i>-16提取N维特征;其次,K帧视频形成一个长度为K的N维特征序列,即K×N序列;然后,将K×N序列平均划分为d个时间段进行<i>ILSTM</i>模块处理;最后,通过<i>ILSTM</i>模块的输入映射到连接层输出二分类结果(即类别的个数)。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 DC-ILSTM网络结构" src="Detail/GetImg?filename=images/JSJY201910016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 <i>DC</i>-<i>ILSTM</i>网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.4 <i>Structure diagram of DC</i>-<i>ILSTM network</i></p>

                </div>
                <div class="p1">
                    <p id="72">在迁移学习中,使用基于<i>ImageNet</i>数据集的<i>VGG</i>-16模型作为<i>CNN</i>模型来提取每帧烟雾特征。实验结果表明,在<i>ImageNet</i>数据集上训练的网络具有更好的泛化能力。</p>
                </div>
                <div class="p1">
                    <p id="73">在烟雾特征融合过程中,<i>ILSTM</i>模块使用最大池化层或平均池化层可以进一步提高视频检测准确率;同时,<i>LSTM</i>结构使用了256个过滤器,且大小为3×3、步长为1。实验结果表明,相比直接使用<i>LSTM</i>网络,<i>ILSTM</i>网络显著提高烟雾检测的准确率。</p>
                </div>
                <div class="p1">
                    <p id="74">该模型动态地输入一组任意长度的图片帧,静态地输出两种类型结果(有烟、无烟)。实验算法主要步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="75"><i>Step</i>1 提取视频的每帧图像,预处理数据。该方法按有烟和无烟进行分类处理、调整大小(3×224×224)、随机变换(随机旋转、剪切、翻转等)和归一化。</p>
                </div>
                <div class="p1">
                    <p id="76"><i>Step</i>2 预训练一个基于<i>ImageNet</i>图像分类的<i>VGG</i>-16模型。</p>
                </div>
                <div class="p1">
                    <p id="77"><i>Step</i>3 训练<i>DC</i>-<i>ILSTM</i>模型:</p>
                </div>
                <div class="p1">
                    <p id="78">1)共享预训练的<i>VGG</i>-16模型的序列空间特征;</p>
                </div>
                <div class="p1">
                    <p id="79">2)以上特征输入到<i>ILSTM</i>单元;</p>
                </div>
                <div class="p1">
                    <p id="80">3)经过<i>ILSTM</i>序列特征融合进行二分类检测。</p>
                </div>
                <div class="p1">
                    <p id="81">实验设置如下:</p>
                </div>
                <div class="p1">
                    <p id="82">1)N是<i>DC</i>-<i>ILSTM</i>网络进行一次处理的数据流量。以实验训练为例,N=8。</p>
                </div>
                <div class="p1">
                    <p id="83">2)T是<i>DC</i>-<i>ILSTM</i>网络层处理的总时间步长,即作为一次输入<i>ILSTM</i>的视频帧数。以实验训练为例,T=16。</p>
                </div>
                <div class="p1">
                    <p id="84">3)T×N×4 096是预训练层的输出尺度。其中:4 096是<i>VGG</i>-16中全连接层的维数,即卷积特征维数。</p>
                </div>
                <div class="p1">
                    <p id="85">4)<i>d</i>是平均划分时间段,即作为ILSTM记忆单元输入。以实验训练为例,<i>d</i>=3。</p>
                </div>
                <div class="p1">
                    <p id="86">5)图3是本文模型的卷积层参数详细配置。以实验训练为例,学习率为10<sup>-4</sup>,迭代次数为300和优化函数采用ADAM。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag">4 实验与结果分析</h3>
                <h4 class="anchor-tag" id="88" name="88">4.1 <b>实验环境</b></h4>
                <div class="p1">
                    <p id="89">该算法的硬件平台是<i>Intel Core i</i>5-4200<i>U CPU</i>@2.30 <i>GHz</i>,<i>GPU GEFORCE GTX</i> 1080<i>ti</i>,<i>Ubuntu</i>14.0.4,8 <i>GB</i>内存。实验环境为<i>Python</i>3.5,<i>Tensorflow</i>1.7.0和<i>Keras</i>框架,包括<i>CNN</i>(<i>VGG</i>-16)和<i>LSTM</i>。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">4.2 <b>实验数据集</b></h4>
                <div class="p1">
                    <p id="91">本文采用的实验数据集来自于<i>CVPR</i>实验室(<i>https</i>://<i>cvpr</i>.<i>kmu</i>.<i>ac</i>.<i>kr</i>)、中国消防科学国家重点实验室(<i>http</i>://<i>smoke</i>.<i>ustc</i>.<i>edu</i>.<i>cn</i>)、 <i>Bilkent</i>大学的公开火灾火焰视频库(<i>http</i>://<i>signal</i>.<i>ee</i>.<i>bilkent</i>.<i>edu</i>.<i>tr</i>/<i>VisiFire</i>/)和网络采集(例如:<i>Ultimate Chase</i>公司提供的资源库(<i>http</i>://<i>ultimatechase</i>.<i>com</i>))。实验数据集综合了以上三个数据集和额外收集的关于森林环境数据,共由60个烟雾视频和150个非烟雾视频组成,能充分体现数据的多样性。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">4.3 <b>实验评价标准</b></h4>
                <div class="p1">
                    <p id="93">本文采用准确率<i>Accuracy</i>、精确率<i>Precision</i>、召回率<i>Recall</i>和两者的调和均值<i>F</i>1来衡量网络性能。各指标计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mn>2</mn><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mn>2</mn><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中:<i>TP</i>为预测正类为正类;<i>TN</i>为预测负类为负类;<i>FP</i>为预测负类为正类;<i>FN</i>为预测正类为负类。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96">4.4 <b>实验结果与分析</b></h4>
                <div class="p1">
                    <p id="97">实验视频包括60个烟雾视频和150个非烟雾视频。本文采用交叉验证的方法将样本集按照比例被划分为训练集、验证集和测试集。其中,训练集占总样本50%(30个烟雾视频、70个非烟雾视频),验证集和测试集各占25%(各包含15个烟雾视频、40个非烟雾视频)。</p>
                </div>
                <div class="p1">
                    <p id="98">实验一 在迁移学习中,<i>VGG</i>-16网络与其他<i>CNN</i>网络进行对比。</p>
                </div>
                <div class="p1">
                    <p id="99">本文使用<i>VGG</i>-16网络与其他<i>CNN</i>模型进行比较。表2显示了它们在验证集上各参数的对比。从表2中可看出,使用<i>AlexNet</i>的准确率最低,假阳性和假阴性分值最差;虽然使用<i>GoogleNet</i>的检测结果要优于<i>AlexNet</i>,但与<i>VGG</i>-16模型相比,其准确率仍然较低,误报率较高。具体而言,与<i>AlexNet</i>和<i>GoogleNet</i>相比,<i>VGG</i>-16取得了较好的效果,其中,最小假阳性为2.60%、最小假阴性为2.46%、最高准确率达93.31%,因此,使用<i>VGG</i>-16模型性能优于其他模型。</p>
                </div>
                <div class="area_img" id="100">
                    <p class="img_tit"><b>表</b>2 <i>CNN</i><b>与其他模型训练过程中 验证集的准确性对比</b> 单位:% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.2 <i>Accuracy comparison of validation sets</i><i>during CNN and other model training</i><i>unit</i>:%</p>
                    <p class="img_note"></p>
                    <table id="100" border="1"><tr><td><br />模型</td><td>假阳性</td><td>假阴性</td><td>准确率</td></tr><tr><td><br /><i>GoogleNet</i></td><td>2.84</td><td>2.53</td><td>92.65</td></tr><tr><td><br /><i>AlexNet</i></td><td>3.17</td><td>2.61</td><td>90.05</td></tr><tr><td><br /><i>VGG</i>-16</td><td>2.60</td><td>2.46</td><td>93.31</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="101">实验二 基于<i>VGG</i>-16网络的<i>LSTM</i>与<i>ILSTM</i>模块检测效果对比。</p>
                </div>
                <div class="p1">
                    <p id="102">本文分别使用<i>VGG</i>-16网络结合<i>LSTM</i>网络与改进的<i>ILSTM</i>网络进行对比。表3显示了训练过程中验证集的假阳性、假阴性和准确率,可看出,结合<i>ILSTM</i>模块准确性要优于<i>LSTM</i>,其中,假阳性最小为2.41%、假阴性最小为2.26%和最高准确率为94.53%,准确率提高了1.32个百分点。</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表</b>3 <i>ILSTM</i><b>和</b><i>LSTM</i><b>训练过程中 验证集的准确性对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.3 <i>Accuracy comparison of validation sets</i><i>during ILSTM and LSTM training</i></p>
                    <p class="img_note">单位:%</p>
                    <table id="103" border="1"><tr><td><br />模型</td><td>假阳性</td><td>假阴性</td><td>准确率</td></tr><tr><td><br /><i>GoogleNet</i></td><td>2.84</td><td>2.53</td><td>92.65</td></tr><tr><td><br /><i>ILSTM</i></td><td>2.41</td><td>2.26</td><td>94.53</td></tr><tr><td><br /><i>LSTM</i></td><td>2.57</td><td>2.41</td><td>93.21</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="104">实验三 基于<i>DC</i>-<i>ILSTM</i>网络的森林火灾烟雾检测方法与其他最先进的方法检测效果对比。</p>
                </div>
                <div class="p1">
                    <p id="105">在<i>DC</i>-<i>ILSTM</i>网络进行训练时,每次迭代8个视频,然后平均取30帧图像。在<i>VGG</i>-16模型中,对8个视频进行分类;而在<i>ILSTM</i>模块中,以30帧图像平均地划分为3个时间段进行分类;最后<i>ILSTM</i>模块的分类作为最终的检测结果。在测试过程中,分别对<i>VGG</i>-16模型和<i>DC</i>-<i>ILSTM</i>模型进行了测试。</p>
                </div>
                <div class="p1">
                    <p id="106">表4显示了训练过程中验证集的准确性,可看出结合<i>ILSTM</i>单元的检测效果优于<i>VGG</i>-16模型,且准确率提高了1.22个百分点。</p>
                </div>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表</b>4 <i>VGG</i>-16<b>和</b><i>DC</i>-<i>ILSTM</i><b>训练过程中 验证集的准确性对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.4 <i>Accuracy comparison of validation sets</i><i>during VGG</i>-16 <i>and DC</i>-<i>ILSTM training</i></p>
                    <p class="img_note">单位:%</p>
                    <table id="107" border="1"><tr><td><br />模型</td><td>假阳性</td><td>假阴性</td><td>准确率</td></tr><tr><td><br /><i>GoogleNet</i></td><td>2.84</td><td>2.53</td><td>92.65</td></tr><tr><td><br /><i>VGG</i>16</td><td>2.60</td><td>2.46</td><td>93.31</td></tr><tr><td><br /><i>DC</i>-<i>ILSTM</i></td><td>2.41</td><td>2.26</td><td>94.53</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="108">本文对测试集进行测试。测试样本如图5所示的(<i>a</i>)～(<i>h</i>)。实验分别用<i>DC</i>-<i>ILSTM</i>网络与<i>Hu</i>等<citation id="168" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的深卷积长递归网络(<i>DCLRN</i>)和<i>Filonenko</i>等<citation id="169" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出的卷积和递归网络进行对比。表5是以最早检测出的帧序号为指标,评估各个方法的检测效果。从表5中可看出,本文方法相比其他两种方法能够提前检测到烟雾。例如,在<i>Video</i>2中,视频总帧数为190,相比文献<citation id="170" type="reference">[<a class="sup">14</a>]</citation>方法和文献<citation id="171" type="reference">[<a class="sup">13</a>]</citation>方法,本文方法<i>DC</i>-<i>ILSTM</i>分别以提前10帧和15帧检测到烟雾;同样,在1 007帧数量的<i>Video</i>3中,本文方法以367帧检测到烟雾,比文献<citation id="172" type="reference">[<a class="sup">14</a>]</citation>方法提前17帧。</p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表</b>5 <b>三种方法的视频烟雾检测速度比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.5 <i>Performance speed comparison for</i><i>video smoke detection of three methods</i></p>
                    <p class="img_note"></p>
                    <table id="109" border="1"><tr><td rowspan="2"><br />视频类型</td><td rowspan="2">总帧数</td><td colspan="3"><br />最早检测出的帧序号</td></tr><tr><td><br />文献[14]方法</td><td>文献[13]方法</td><td><i>DC</i>-<i>ILSTM</i></td></tr><tr><td><br /><i>Video</i>1<br /><i>light smoke</i></td><td>201</td><td>37</td><td>34</td><td>25</td></tr><tr><td><br /><i>Video</i>2 <br /><i>forest smoke</i></td><td>190</td><td>45</td><td>40</td><td>30</td></tr><tr><td><br /><i>Video</i>3 <br /><i>road smoke</i></td><td>1 007</td><td>384</td><td>374</td><td>367</td></tr><tr><td><br /><i>Video</i>4 <br /><i>car smoke</i></td><td>470</td><td>22</td><td>23</td><td>20</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit"><b>表</b>6 <b>三种方法的测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.6 <i>Test results of three methods</i></p>
                    <p class="img_note">unit:%</p>
                    <table id="110" border="1"><tr><td><br />方法</td><td>准确率</td><td>精确率</td><td>召回率</td><td>F1</td></tr><tr><td> 文献[14]方法</td><td>93.30</td><td>90.00</td><td>90.00</td><td>90.00</td></tr><tr><td><br /> 文献[13]方法</td><td>93.50</td><td>91.00</td><td>90.20</td><td>90.50</td></tr><tr><td><br /><i>DC</i>-<i>ILSTM</i></td><td>94.53</td><td>91.10</td><td>89.20</td><td>91.30</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:烟雾视频为正类;非烟雾视频为负类。</p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="111">总之,本文方法在对烟雾视频进行测试时,性能优于其他两种方法,具体测试结果如表6所示。烟雾视频为正类,非烟雾视频为负类。本文方法之所以能取得较好的性能,并且速度比较快,主要是由于提出的<i>ILSTM</i>网络对空间和运动上下文特征融合;但是在似烟雾环境下检测性能用有所延迟。例如,野外森林环境中飘动的云与运动缓慢的烟雾。视频样本如图5所示的(<i>i</i>)～(<i>l</i>)。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910016_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 视频样本" src="Detail/GetImg?filename=images/JSJY201910016_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 视频样本  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910016_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.5 <i>Sample images of videos</i></p>

                </div>
                <h3 id="113" name="113" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="114">针对森林火灾烟雾检测的问题,本文提出了一种深度神经网络<i>DC</i>-<i>ILSTM</i>模型。该模型不仅提出结合<i>ILSTM</i>模块进行烟雾特征融合;而且,在深度迁移学习架构上处理森林火灾小样本数据集。在实验中,基于公开数据集对该模型进行评估,分别与<i>LSTM</i>模型和最先进的森林火灾烟雾检测方法进行比较。结果表明,在检测性能上,该模型以更小的最早帧数检测到烟雾;同时,检测精度达94.5%以上,比<i>DCLRN</i>提高了1.03个百分点。在下一阶段工作中,我们还需进一步优化模型提高森林火灾烟雾检测的准确率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="130">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wildfire Smoke Detection Using Computational Intelligence Techniques">

                                <b>[1]</b>GENOVESE A,LABATI R D,PIURI V,et al.Wildfire smoke detection using computational intelligence techniques[C]//Proceedings of the 2011 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications.Piscataway:IEEE,2011:1-6.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100458948&amp;v=MDg0ODZubFVyM0lJVm9XYVJJPU5pZk9mYks3SHRET3JvOUZZTzRIQlhneG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>YUAN F.Video-based smoke detection with histogram sequence of LBP and LBPV pyramids[J].Fire Safety Journal,2011,46(3):132-139.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contour based smoke detection in video using wavelets">

                                <b>[3]</b>TOREYIN B U,DEDEOGLU Y,CETIN A E.Contour based smoke detection in video using wavelets[C]//Proceedings of the14th European Signal Processing Conference.Piscataway:IEEE,2006:1-5.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15110200836187&amp;v=MTA1NDk5RE1yWTlGYk9nSkRYUStvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVm9XYVJJPU5qN0Jhcks5SA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>YU C,FAN J,WANG J,et al.Video fire smoke detection using motion and color features[J].Fire Technology,2010,46(3):651-663.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Saliency-Based Method for Early Smoke Detection in Video Sequences">

                                <b>[5]</b>JIA Y,YUAN J,WANG J,et al.A saliency-based method for early smoke detection in video sequences[J].Fire Technology,2016,52(5):1271-1292.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural networks for forest fire detection">

                                <b>[6]</b>ZHANG Q,XU J,XU L,et al.Deep convolutional neural networks for forest fire detection[C]//Proceedings of the 2016 International Forum on Management,Education and Information Technology Application.Paris:Atlantis Press,2016:568-575.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network for video fire and smoke detection">

                                <b>[7]</b>FRIZZI S,KAABI R,BOUCHOUICHA M,et al.Convolutional neural network for video fire and smoke detection[C]//Proceedings of the,42nd Annual Conference of the IEEE Industrial Electronics Society.Piscataway:IEEE,2016:877-882.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A deep normalization and convolutional neural network for image smoke detection">

                                <b>[8]</b>YIN Z,WAN B,YUAN F,et al.A deep normalization and convolutional neural network for image smoke detection[J].IEEE Access,2017,5:18429-18438.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolu- tionalNeural Networks based Fire Detection in Surveillance Vi-deos">

                                <b>[9]</b>MUHAMMAD K,AHMAD J,MEHMOOD I,et al.Convolutional neural networks based fire detection in surveillance videos[J].IEEE Access,2018,6:18174-18183.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[10]</b>SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1-9.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA2978B314EA7D7F89CA432F7CA797800&amp;v=MDY3MjlZeEVZSjUrQ3dnK3VSNGFtVTU1UzMyVXEyRkVmcnVUVGJxZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhieTl3Nmc9TmlmT2ZjSzZGOWJFMw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>ZHANG Q,LIN G,ZHANG Y,et al.Wildland forest fire smoke detection based on faster R-CNN using synthetic smoke images[J].Procedia Engineering,2018,211:441-446.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201711025&amp;v=MjUxNDZHNEg5Yk5ybzlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluaFVieklMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>王文朋,毛文涛,何建樑,等.基于深度迁移学习的烟雾识别方法[J].计算机应用,2017,37(11):144-149,161.(WANG W P,MAO W T,HE J L,et al.Smoke recognition based on deep transfer learning[J].Journal of Computer Applications,2017,37(11):144-149,161.)
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Smoke detection on video sequences using convolutional and recurrent neural networks">

                                <b>[13]</b>FILONENKO A,KURNIANGGORO L,JO K.Smoke detection on video sequences using convolutional and recurrent neural networks[C]//Proceedings of the 2017 International Conference on Computational Collective Intelligence,LNCS 10449.Cham:Springer,2017:558-566.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time fire detection based on deep convolutional long-recurrent networks and optical flow method">

                                <b>[14]</b>HU C,TANG P,JIN W,et al.Real-time fire detection based on deep convolutional long-recurrent networks and optical flow method[C]//Proceedings of the 37th Chinese Control Conference.Piscataway:IEEE,2018:9061-9066.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910016&amp;v=MjU5NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oVWJ6SUx6N0JkN0c0SDlqTnI0OUVZb1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
