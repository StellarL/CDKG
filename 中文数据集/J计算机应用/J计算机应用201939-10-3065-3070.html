<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136463655283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910045%26RESULT%3d1%26SIGN%3d5DVDaIc0sP0Xm8R724Kmaz3WGbY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910045&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910045&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910045&amp;v=MjA5MzN5amtWTDdJTHo3QmQ3RzRIOWpOcjQ5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 语音增强原理 ">1 语音增强原理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="2 掩蔽估计与优化 ">2 掩蔽估计与优化</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="2.1 &lt;b&gt;算法整体框架&lt;/b&gt;">2.1 <b>算法整体框架</b></a></li>
                                                <li><a href="#59" data-title="2.2 &lt;b&gt;掩蔽估计&lt;/b&gt;">2.2 <b>掩蔽估计</b></a></li>
                                                <li><a href="#90" data-title="2.3 &lt;b&gt;基于凸优化的掩蔽估计&lt;/b&gt;">2.3 <b>基于凸优化的掩蔽估计</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#139" data-title="3.1 &lt;b&gt;实验参数与评价指标&lt;/b&gt;">3.1 <b>实验参数与评价指标</b></a></li>
                                                <li><a href="#144" data-title="3.2 &lt;b&gt;结果与分析&lt;/b&gt;">3.2 <b>结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#156" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="图1 本文算法框架">图1 本文算法框架</a></li>
                                                <li><a href="#78" data-title="图2 平滑系数 &lt;i&gt;β&lt;/i&gt;^ 随瞬时信噪比变化曲线">图2 平滑系数 <i>β</i>^ 随瞬时信噪比变化曲线</a></li>
                                                <li><a href="#88" data-title="图3 10 dB的Engine噪声下各频带内瞬时信噪比与估计先验信噪比">图3 10 dB的Engine噪声下各频带内瞬时信噪比与估计先验信噪比</a></li>
                                                <li><a href="#108" data-title="图4 带噪语音与噪声的互相关系数&lt;i&gt;ρ&lt;/i&gt;与 其估计值&lt;mathml id=&quot;175&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi&gt;ρ&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;/math&gt;&lt;/mathml&gt;在各频带内变化曲线">图4 带噪语音与噪声的互相关系数<i>ρ</i>与 其估计值<mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ρ</mi><mo>^</mo></mover></math></mathml>在各频带内变化曲线</a></li>
                                                <li><a href="#134" data-title="图5 &lt;i&gt;n&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;=&lt;i&gt;n&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;=1时平滑处理示意图">图5 <i>n</i><sub>1</sub>=<i>n</i><sub>2</sub>=1时平滑处理示意图</a></li>
                                                <li><a href="#136" data-title="图6 不同掩蔽得到增强语音的归一化能量波形">图6 不同掩蔽得到增强语音的归一化能量波形</a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;掩蔽优化前后的&lt;/b&gt;&lt;i&gt;PESQ&lt;/i&gt;&lt;b&gt;结果&lt;/b&gt;"><b>表</b>1 <b>掩蔽优化前后的</b><i>PESQ</i><b>结果</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;掩蔽优化前后的&lt;/b&gt;STOI&lt;b&gt;平均值&lt;/b&gt;"><b>表</b>2 <b>掩蔽优化前后的</b>STOI<b>平均值</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;掩蔽优化前后的&lt;/b&gt;segSNR&lt;b&gt;平均值&lt;/b&gt;"><b>表</b>3 <b>掩蔽优化前后的</b>segSNR<b>平均值</b></a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;三种语音增强算法在不同信噪比下的&lt;/b&gt;PESQ&lt;b&gt;平均值&lt;/b&gt;"><b>表</b>4 <b>三种语音增强算法在不同信噪比下的</b>PESQ<b>平均值</b></a></li>
                                                <li><a href="#153" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;三种语音增强算法在不同信噪比下的&lt;/b&gt;STOI&lt;b&gt;平均值&lt;/b&gt;"><b>表</b>5 <b>三种语音增强算法在不同信噪比下的</b>STOI<b>平均值</b></a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表&lt;/b&gt;6 &lt;b&gt;三种语音增强算法在不同信噪比下的&lt;/b&gt;segSNR&lt;b&gt;平均值&lt;/b&gt;"><b>表</b>6 <b>三种语音增强算法在不同信噪比下的</b>segSNR<b>平均值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="223">


                                    <a id="bibliography_1" title="曹亮,张天骐,高洪兴,等.基于听觉掩蔽效应的多频带谱减语音增强方法[J].计算机工程与设计,2013,34(1):235-240.(CAO L,ZHANG T Q,GAO H X,et al.Multi-band spectral subtraction method for speech enhancement based on masking property of human auditory system[J].Computer Engineering and Design,2013,34(1):235-240.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201301045&amp;v=MzA1NDNZWkxHNEg5TE1ybzlCWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqa1ZMN0lOaWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        曹亮,张天骐,高洪兴,等.基于听觉掩蔽效应的多频带谱减语音增强方法[J].计算机工程与设计,2013,34(1):235-240.(CAO L,ZHANG T Q,GAO H X,et al.Multi-band spectral subtraction method for speech enhancement based on masking property of human auditory system[J].Computer Engineering and Design,2013,34(1):235-240.)
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_2" title="李季碧,马永保,夏杰,等.一种基于修正倒谱平滑技术改进的维纳滤波语音增强算法[J].重庆邮电大学学报(自然科学版),2016,28(4):462-467.(LI J B,MA Y B,XIA J,et al.An improved Wiener filtering speech enhancement algorithm based on modified cepstrum smooth technology[J].Journal of Chongqing University of Posts and Telecommunications(Natural Science Edition),2016,28(4):462-467.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CASH201604004&amp;v=MTE5OTdMN0lKaXpZWnJHNEg5Zk1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqa1Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        李季碧,马永保,夏杰,等.一种基于修正倒谱平滑技术改进的维纳滤波语音增强算法[J].重庆邮电大学学报(自然科学版),2016,28(4):462-467.(LI J B,MA Y B,XIA J,et al.An improved Wiener filtering speech enhancement algorithm based on modified cepstrum smooth technology[J].Journal of Chongqing University of Posts and Telecommunications(Natural Science Edition),2016,28(4):462-467.)
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_3" title="BOROWICZ A,PETROVSKY A.Signal subspace approach for psychoacoustically motivated speech enhancement[J].Speech communication,2011,53(2):210-219." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300465324&amp;v=MDI5MTQzSUlGOFRheEk9TmlmT2ZiSzdIdERPckk5RllPMEtEMzQ5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        BOROWICZ A,PETROVSKY A.Signal subspace approach for psychoacoustically motivated speech enhancement[J].Speech communication,2011,53(2):210-219.
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_4" title="HU K,WANG D.Unvoiced speech segregation from nonspeech interference via CASA and spectral subtraction[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(6):1600-1609." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unvoiced Speech Segregation From Nonspeech Interference via CASA and Spectral Subtraction">
                                        <b>[4]</b>
                                        HU K,WANG D.Unvoiced speech segregation from nonspeech interference via CASA and spectral subtraction[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(6):1600-1609.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_5" title="WANG Y,NARAYANAN A,WANG D,et al.On training targets for supervised speech separation[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2014,22(12):1849-1858." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM0E6E7473F6DC5B47300C24AE9430C360&amp;v=MTQ2NDYxN2YzbEx5eEVRNmo4T1NudVQyUnN4ZXJMblJyeWZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4TG00d2FnPU5pZklZN1BOR0tUTHE0aEdFdQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        WANG Y,NARAYANAN A,WANG D,et al.On training targets for supervised speech separation[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2014,22(12):1849-1858.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_6" title="BAO F,ABDULLA W H.Noise masking method based on an effective ratio mask estimation in Gammatone channels[J].APSIPATransactions on Signal and Information Processing,2018,7(e5):1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Noise masking method based on an effective ratio mask estimation in Gammatone channels">
                                        <b>[6]</b>
                                        BAO F,ABDULLA W H.Noise masking method based on an effective ratio mask estimation in Gammatone channels[J].APSIPATransactions on Signal and Information Processing,2018,7(e5):1-12.
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_7" title="SUN M,LI Y,GEMMEKE J F,et al.Speech enhancement under low SNR conditions via noise estimation using sparse and low-rank NMF with Kullback-Leibler divergence[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2015,23(7):1233-1242." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM9E8CF857A519612F45A9CCDAFCC552CB&amp;v=MTYwNjFTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeExtNHdhZz1OaWZJWTdyTkZxSzZwNHBDRmU0T0JYbzR6V0FYNzA1ME93eVczV1JHQ3JlUlI4bnRDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        SUN M,LI Y,GEMMEKE J F,et al.Speech enhancement under low SNR conditions via noise estimation using sparse and low-rank NMF with Kullback-Leibler divergence[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2015,23(7):1233-1242.
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_8" title="NAHMA L,YONG P C,DAM H H,et al.Convex combination framework for a priori SNR estimation in speech enhancement[C]//Proceedings of the 2017 IEEE International Conference on Acoustics,Speech and Signal Processing.Piscataway,NJ.IEEE,2017:4975-4979." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convex combination framework for a priori SNR estimation in speech enhancement">
                                        <b>[8]</b>
                                        NAHMA L,YONG P C,DAM H H,et al.Convex combination framework for a priori SNR estimation in speech enhancement[C]//Proceedings of the 2017 IEEE International Conference on Acoustics,Speech and Signal Processing.Piscataway,NJ.IEEE,2017:4975-4979.
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_9" title="蒋毅,刘润生,冯振明.基于听感知特性的双麦克风近讲语音增强算法[J].清华大学学报(自然科学版),2014(9):1179-1183.(JIANG Y,LIU R S,FENG Z M.Dual-microphone speech enhancement algorithm based on the auditory features for a closetalk system[J].Journal of Tsinghua University(Science and Technology),2014,54(9):1179-1183.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHXB201409010&amp;v=MTM3MTMzenFxQnRHRnJDVVI3cWZadVpzRnlqa1ZMN0lOQ1hUYkxHNEg5WE1wbzlFWklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        蒋毅,刘润生,冯振明.基于听感知特性的双麦克风近讲语音增强算法[J].清华大学学报(自然科学版),2014(9):1179-1183.(JIANG Y,LIU R S,FENG Z M.Dual-microphone speech enhancement algorithm based on the auditory features for a closetalk system[J].Journal of Tsinghua University(Science and Technology),2014,54(9):1179-1183.)
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_10" title="BAO F,ABDULLA W H.A new ratio mask representation for CASA-based speech enhancement[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2019,27(1):7-19." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new ratio mask representation for CASA-based speech enhancement">
                                        <b>[10]</b>
                                        BAO F,ABDULLA W H.A new ratio mask representation for CASA-based speech enhancement[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2019,27(1):7-19.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_11" title="YONG P C,NORDHOLM S,DAM H H,et al.On the optimization of sigmoid function for speech enhancement[C]//Proceedings of the 19th European Signal Processing Conference.Piscataway:IEEE,2011:211-215." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the optimization of sigmoid function for speech enhancement">
                                        <b>[11]</b>
                                        YONG P C,NORDHOLM S,DAM H H,et al.On the optimization of sigmoid function for speech enhancement[C]//Proceedings of the 19th European Signal Processing Conference.Piscataway:IEEE,2011:211-215.
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_12" title="CHEN Z,HOHMANN V.Online monaural speech enhancement based on periodicity analysis and a priori SNR estimation[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2015,23(11):1904-1916." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM2713DAB3F79FB896B40DFA01444DFB35&amp;v=MjM5NDdoN2o4SlBnN2lyUll4ZmNiaU43bWFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4TG00d2FnPU5pZklZN0cvSDlLNDN2MUdFdXdHZWc0eHhoQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        CHEN Z,HOHMANN V.Online monaural speech enhancement based on periodicity analysis and a priori SNR estimation[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2015,23(11):1904-1916.
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_13" title="ZHENG C,TAN Z,PENG R,et al.Guided spectrogram filtering for speech dereverberation[J].Applied Acoustics,2018,134(5):154-159." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC752FC0B2C8730FE17B3104DD5433CC6&amp;v=MDYxODlXTVM3VTErU1gvbTJHWXdmYkdYTnNtWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTR3YWc9TmlmT2ZjQy9HOU82M0k4M1pwZ0hDMzg1dQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        ZHENG C,TAN Z,PENG R,et al.Guided spectrogram filtering for speech dereverberation[J].Applied Acoustics,2018,134(5):154-159.
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_14" title="GAROFOLO J S,LAMEL L F,FISHER W M,et al.TIMITAcoustic-Phonetic Continuous Speech Corpus[EB/OL].[2019-01-12].https://catalog.ldc.upenn.edu/LDC93S1." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=TIMITAcoustic-Phonetic Continuous Speech Corpus">
                                        <b>[14]</b>
                                        GAROFOLO J S,LAMEL L F,FISHER W M,et al.TIMITAcoustic-Phonetic Continuous Speech Corpus[EB/OL].[2019-01-12].https://catalog.ldc.upenn.edu/LDC93S1.
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_15" title="VARGA A,STEENEKEN H J M.Assessment for automatic speech recognition II:NOISEX-92:a database and an experiment to study the effect of additive noise on speech recognition systems[J].Speech Communication,1993,12(3):247-251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems">
                                        <b>[15]</b>
                                        VARGA A,STEENEKEN H J M.Assessment for automatic speech recognition II:NOISEX-92:a database and an experiment to study the effect of additive noise on speech recognition systems[J].Speech Communication,1993,12(3):247-251.
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_16" title="GERKMANN T,HENDRIKS R C.Unbiased MMSE-based noise power estimation with low complexity and low tracking delay[J].IEEE Transactions on Audio,Speech,and Language Processing,2012,20(4):1383-1393." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unbiased MMSE-Based Noise Power Estimation With Low Complexity and Low Tracking Delay">
                                        <b>[16]</b>
                                        GERKMANN T,HENDRIKS R C.Unbiased MMSE-based noise power estimation with low complexity and low tracking delay[J].IEEE Transactions on Audio,Speech,and Language Processing,2012,20(4):1383-1393.
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_17" title="International Telecommunications Union(ITU).Perceptual Evaluation of Speech Quality(PESQ):an objective method for end-toend speech quality assessment of narrow-band telephone networks and speech codecs[EB/OL].[2019-01-12].https://www.itu.int/rec/T-REC-P.862-200102-I/en." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs">
                                        <b>[17]</b>
                                        International Telecommunications Union(ITU).Perceptual Evaluation of Speech Quality(PESQ):an objective method for end-toend speech quality assessment of narrow-band telephone networks and speech codecs[EB/OL].[2019-01-12].https://www.itu.int/rec/T-REC-P.862-200102-I/en.
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_18" title="TAAL C H,HENDRIKS R C,HEUSDENS R,et al.An algorithm for intelligibility prediction of time-frequency weighted noisy speech[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(7):2125-2136." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech">
                                        <b>[18]</b>
                                        TAAL C H,HENDRIKS R C,HEUSDENS R,et al.An algorithm for intelligibility prediction of time-frequency weighted noisy speech[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(7):2125-2136.
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_19" title="LOIZOU P C,KIM G.Reasons why current speech-enhancement algorithms do not improve speech intelligibility and suggested solutions[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(1):47-56." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reasons why Current Speech-Enhancement Algorithms do not Improve Speech Intelligibility and Suggested Solutions">
                                        <b>[19]</b>
                                        LOIZOU P C,KIM G.Reasons why current speech-enhancement algorithms do not improve speech intelligibility and suggested solutions[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(1):47-56.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-07-05 16:52</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),3065-3070 DOI:10.11772/j.issn.1001-9081.2019030486            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于掩蔽估计与优化的单通道语音增强算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%9B%E5%AE%9B%E8%90%A5&amp;code=42897049&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">葛宛营</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%A4%A9%E9%AA%90&amp;code=10728494&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张天骐</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0174747&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆邮电大学通信与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>单通道语音增强算法通过从带噪语音中估计并抑制噪声成分来得到增强语音。然而,噪声估计算法在计算时存在过估现象,导致部分估计噪声能量值比实际值大。尽管可以通过补偿消去这些过估值,但引入的误差同样会降低增强语音的整体质量。针对此问题,提出一种基于计算听觉场景分析(CASA)的时频掩蔽估计与优化算法。首先,通过直接判决(DD)算法估计先验信噪比(SNR)并计算初始掩蔽;其次,利用噪声与带噪语音在Gammatone频带内的互相关(ICC)系数来计算噪声的存在概率,结合带噪语音能量谱得到新的噪声估计,减少原估计噪声中的过估成分;然后,利用优化算法对初始掩蔽进行迭代处理以减少其中因噪声过估而存在的误差并增加其中的目标语音成分,在满足条件后停止迭代并得到新的掩蔽;最后,利用新的掩蔽合成增强语音。实验结果表明在不同的背景噪声下,相比优化前,新的掩蔽使增强语音获得了较高的主观语音质量(PESQ)和语音可懂度(STOI)值,提升了语音听感与可懂度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AE%A1%E7%AE%97%E5%90%AC%E8%A7%89%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算听觉场景分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AD%E9%9F%B3%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">语音增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E9%A2%91%E6%8E%A9%E8%94%BD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时频掩蔽;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%99%AA%E5%A3%B0%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">噪声估计;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A9%E8%94%BD%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">掩蔽优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AD%E9%9F%B3%E5%8F%AF%E6%87%82%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">语音可懂度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    葛宛营(1994—),男,河南三门峡人,硕士研究生,主要研究方向:语音信号处理、语音增强;;
                                </span>
                                <span>
                                    *张天骐(1971—),男,四川眉山人,教授,博士,主要研究方向:扩频通信、盲信号处理、语音信号处理。电子邮箱zhangtq@cqupt.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61671095,61702065,61701067,61771085);</span>
                                <span>信号与信息处理重庆市市级重点实验室建设项目(CSTC2009CA2003);</span>
                                <span>重庆市研究生科研创新项目(CYS17219);</span>
                                <span>重庆市教育委员会科研项目(KJ1600427,KJ1600429);</span>
                    </p>
            </div>
                    <h1><b>Monaural speech enhancement algorithm based on mask estimation and optimization</b></h1>
                    <h2>
                    <span>GE Wanying</span>
                    <span>ZHANG Tianqi</span>
            </h2>
                    <h2>
                    <span>School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Monaural speech enhancement algorithms obtain enhanced speech by estimating and negating the noise components in speech with noise. However, the over-estimation and the error of the introduction to make up the over-estimation of noise power make detrimental effect on the enhanced speech. To constrain the distortion caused by noise over-estimation, a time-frequency mask estimation and optimization algorithm based on Computational Auditory Scene Analysis(CASA) was proposed. Firstly, Decision Directed(DD) algorithm was used to estimate the priori Signal-to-Noise Ratio(SNR) and calculate the initial mask. Secondly, the Inter-Channel Correlation(ICC) factor between noise and speech with noise in each Gammatone filterbank channel was used to calculate the noise presence probability, the new noise estimation was obtained by the probability combining with the power spectrum of speech with noise, and the over-estimation of the primary estimated noise was decreased. Thirdly, the initial mask was iterated by the optimization algorithm to reduce the error caused by the noise over-estimation and raise the target speech components in the mask, and the new mask was obtained when the iteration stopped with the conditions met. Finally, the optimization method was used to optimize the estimated mask. The enhanced speech was composed by using the new mask. Experimental results demonstrate that the new mask has higher Perceptual Evaluation of Speech Quality(PESQ) and Short-Time Objective Intelligibility measure(STOI) values of the enhanced speech in comparison with the mask before optimization, improving the intelligibility and listening feeling of speech.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=computational%20auditory%20scene%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">computational auditory scene analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=speech%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">speech enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=time-frequency%20mask&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">time-frequency mask;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=noise%20estimation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">noise estimation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=mask%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">mask optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=speech%20intelligibility&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">speech intelligibility;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    GE Wanying,born in 1994,M.S.candidate.His research interests include signal processing,speech enhancement.;
                                </span>
                                <span>
                                    ZHANG Tianqi,born in 1971,Ph.D.,professor.Her research interests include spread spectrum communications,blind signal processing, speech signal processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61671095,61702065,61701067,61771085);</span>
                                <span>the Project of Key Laboratory of Signal and Information Processing of Chongqing(CSTC2009CA2003);</span>
                                <span>the Chongqing Graduate Research and Innovation Project(CYS17219);</span>
                                <span>the Research Project of Chongqing Educational Commission(KJ1600427,KJ1600429);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="42">语音增强作为一项前端处理技术,目的是从受噪声干扰的语音中提取出目标语音。按照接收麦克风的个数可将语音增强方法分为单通道和多通道增强方法。相对于多通道语音增强方法,单通道语音增强方法具有成本低、易实现等优点,在通信、语音识别等领域有着广泛的应用。传统的单通道语音增强方法包括谱减法<citation id="261" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、维纳滤波法<citation id="262" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、子空间算法<citation id="263" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="43">近年来,研究人员通过模拟人耳处理声音信号的方式,提出了计算听觉场景分析(Computational Auditory Scene Analysis, CASA),其中Gammatone滤波器组便是一种用来模拟人耳耳蜗的听觉模型。经过滤波器组处理后的语音信号,能够得到相对传统方式更好的效果。基于CASA的语音增强算法通常根据基音周期<citation id="264" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、倒谱系数GFCC(Gammatone Filter Cepstral Coefficient)<citation id="265" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、能量谱GF-POW(Gammatone Frequency Power Spectrum)<citation id="266" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等特征,构造区分目标语音与背景噪声的掩蔽,进而得到增强后的语音信号。在单通道语音增强算法中,需要对噪声能量进行估计,然而由于噪声的随机性,使得估计过程中存在过估现象,从而降低了增强语音的整体质量<citation id="268" type="reference"><link href="233" rel="bibliography" /><link href="235" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。文献<citation id="267" type="reference">[<a class="sup">6</a>]</citation>利用Gammatone滤波器组的非线性频率特征,计算噪声与带噪语音在滤波器组各频带内的互相关系数,减少估计噪声中过估的成分后采用凸优化算法迭代得到语音能量谱的估计。但算法在得到语音能量谱后还需要进一步聚类处理,利用计算得到的掩蔽恢复增强语音。受聚类准确性的影响,通常恢复得到的增强语音在听感和可懂度方面存在欠缺。</p>
                </div>
                <div class="p1">
                    <p id="44">针对上述问题,本文提出一种结合直接判决(Decision Directed, DD)算法<citation id="269" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和频带内互相关(Inter-Channel Correlation, ICC)系数<citation id="270" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>的时频掩蔽估计与优化算法。首先,通过DD算法得到初始掩蔽估计;接着,计算出各频带内噪声与带噪语音的互相关系数,得到噪声的存在概率;然后,根据掩蔽的特性确定目标函数,结合前两步结果,通过优化算法减少初始掩蔽中的误差;最后,利用新的掩蔽从带噪语音中去除噪声信号,得到增强语音。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 语音增强原理</h3>
                <div class="p1">
                    <p id="46">一般情况下,带噪语音由语音和加性噪声合成:</p>
                </div>
                <div class="p1">
                    <p id="47"><i>y</i>(<i>n</i>)=<i>s</i>(<i>n</i>)+<i>d</i>(<i>n</i>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="48">其中: <i>y</i>为带噪语音;<i>s</i>和<i>d</i>分别为语音和噪声信号;<i>n</i>为离散时间序列。</p>
                </div>
                <div class="p1">
                    <p id="49">声信号经过Gammatone滤波器组滤波后被分到带宽不同的64个频带中,各频带的中心频率和带宽由等效矩形带宽(Equivalent Rectangular Bandwidth, ERB)方法确定<citation id="271" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。将各频带内的声信号经过加窗、分帧后得到时频单元序列,计算每个时频单元的能量后得到声信号的能量谱<citation id="272" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。假设噪声与目标语音相互独立,经过滤波器组处理后信号的能量在时间帧为<i>t</i>、频带中心频率为<i>f</i>的时频单元中表示为:</p>
                </div>
                <div class="p1">
                    <p id="50"><i>Y</i>(<i>t</i>, <i>f</i>)=<i>S</i>(<i>t</i>, <i>f</i>)+<i>D</i>(<i>t</i>, <i>f</i>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="51">其中:<i>Y</i>、<i>S</i>和<i>D</i>分别表示带噪语音、语音和噪声的能量。</p>
                </div>
                <div class="p1">
                    <p id="52">CASA语音增强需要利用掩蔽与带噪语音合成时域内的增强语音<citation id="273" type="reference"><link href="231" rel="bibliography" /><link href="233" rel="bibliography" /><link href="241" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">10</a>]</sup></citation>。理想二值掩蔽(Ideal Binary Mask, IBM)为一种常用的掩蔽,其值当目前时频点上语音能量占主导时为1,其他情况下为0。采用IBM得到的增强语音能够保留目标语音占主导的部分,消去其他部分。另一种掩蔽为理想浮值掩蔽(Ideal Ratio Mask, IRM),取值在0～1,且语音部分的值比噪声部分大。相对于IBM,采用IRM得到的增强语音能够保存夹杂在噪声中的弱语音成分,具有更高的语音质量。因此本文计算的掩蔽为理想浮值掩蔽,公式为:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>+</mo><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">2 掩蔽估计与优化</h3>
                <h4 class="anchor-tag" id="55" name="55">2.1 <b>算法整体框架</b></h4>
                <div class="p1">
                    <p id="56">本文算法的整体框架如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="57">算法包含两部分:掩蔽估计和掩蔽优化。在掩蔽估计部分,估计噪声并计算后验信噪比后,利用最大似然估计得到先验信噪比,然后计算初始掩蔽。在掩蔽优化部分,将通过Gammatone滤波器组后的带噪语音与估计噪声信号分帧、加窗处理后进行离散傅里叶变换,计算各频带内带噪语音与噪声信号的互相关系数;为了修正噪声过估对初始掩蔽的影响,将得到的互相关系数作为噪声的存在概率并结合带噪语音得到优化目标,利用优化目标对初始掩蔽进行迭代处理,在减少过估而引起的偏差的同时,增加掩蔽中包含的目标语音成分。最后使用优化后的新掩蔽合成增强语音。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法框架" src="Detail/GetImg?filename=images/JSJY201910045_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flowchart of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="59" name="59">2.2 <b>掩蔽估计</b></h4>
                <div class="p1">
                    <p id="60">由式(2)～(3)可得掩蔽与语音能量的关系为:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>S</i>(<i>t</i>, <i>f</i>)=<i>M</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)·<i>Y</i>(<i>t</i>, <i>f</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="62">将式(3)上下同除以<i>D</i>(<i>t</i>, <i>f</i>),可得</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>ξ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>ξ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">即<i>M</i><sub><i>S</i></sub>是关于先验信噪比<i>ξ</i>的函数。先验信噪比<i>ξ</i>和后验信噪比<i>γ</i>可由式(6)～(7)计算得出:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ξ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mi>λ</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>γ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>Y</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mi>λ</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">其中:<i>λ</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)=E,<i>λ</i><sub><i>D</i></sub>(<i>t</i>, <i>f</i>)=E,符号E表示取期望。</p>
                </div>
                <div class="p1">
                    <p id="67">由DD算法得到先验信噪比的估计<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml>可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mspace width="0.25em" /><mi>β</mi><mo>⋅</mo><mfrac><mrow><mrow><mi>S</mi><mo>^</mo><mspace width="0.25em" /></mrow><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>β</mi><mo stretchy="false">)</mo><mo>⋅</mo><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mtext>Μ</mtext><mtext>L</mtext></mrow></msup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">其中: <i>β</i>为平衡系数,取值范围在0～1。<i>S</i>^ 和<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sub><i>D</i></sub>分别为<i>S</i>和<i>λ</i><sub><i>D</i></sub>的估计值;<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mtext>Μ</mtext><mtext>L</mtext></mrow></msup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>max</mi></mrow><mover accent="true"><mi>γ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>-</mo><mn>1</mn><mo>,</mo><mn>0</mn></mrow></math></mathml>为最大似然(Maximum Likelihood, ML)估计下的先验信噪比。</p>
                </div>
                <div class="p1">
                    <p id="70">可以看出DD算法中<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml>值的计算受<i>β</i>取值的影响:当<i>β</i>趋于1时,<mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml>(<i>t</i>, <i>f</i>)的值接近于<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></math></mathml>,其结果存在一帧的延迟,降低了估计的准确性;当<i>β</i>趋于0时,<mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml>(<i>t</i>, <i>f</i>)的值由最大似然估计方法决定,其结果在非语音段波动较大,引起恼人的音乐噪声。</p>
                </div>
                <div class="p1">
                    <p id="71">通常使用当前时频单元内的后验信噪比代替前一帧的先验信噪比<citation id="274" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>来减小延迟导致的准确性偏差:</p>
                </div>
                <div class="area_img" id="72">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910045_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="73">其中:<i>M</i>^ <sub><i>S</i></sub>为掩蔽的估计值。</p>
                </div>
                <div class="p1">
                    <p id="74">式(9)虽然减小了延迟引入的误差,但由于噪声的不稳定性,在不同的背景噪声下选取固定的平衡系数<i>β</i>同样会影响到计算<mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml><sub>MDD</sub>的准确性。因此引入一个耦合系数对平衡系数进行实时调整<citation id="275" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="75">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910045_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="76">其中:0&lt;<i>β</i>^ (<i>t</i>, <i>f</i>)&lt;1;<i>k</i>^ (<i>t</i>, <i>f</i>)为当前时频单元内瞬时信噪比(Instantaneous SNR)的估计值,表示为<mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>k</mi><mo>^</mo><mspace width="0.25em" /></mrow><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>γ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>-</mo><mn>1</mn></mrow></math></mathml>;<i>a</i>、<i>c</i>和<i>ζ</i>为常量系数。</p>
                </div>
                <div class="p1">
                    <p id="77">图2为选取<i>a</i>=-2,<i>c</i>=2.7,<i>ζ</i>=0.015时平衡系数随实时信噪比变化曲线。当<i>k</i>^ (<i>t</i>, <i>f</i>)&lt;0 dB时,可以判断该时频单元属于非语音段,令 <i>β</i>^ (<i>t</i>, <i>f</i>)趋于1使估计的先验信噪比接近于当前的后验信噪比;当0 dB≤<i>k</i>^ (<i>t</i>, <i>f</i>)≤7 dB时, <i>β</i>^ (<i>t</i>, <i>f</i>)随<i>k</i>^ (<i>t</i>, <i>f</i>)增大而递减,此时的时频单元属于弱语音段,实时调整 <i>β</i>^ (<i>t</i>, <i>f</i>)能够在计算掩蔽时保留更多语音成分;在语音段,即<i>k</i>^ (<i>t</i>, <i>f</i>)&gt;7 dB时,估计的先验信噪比值接近于其最大似然估计值。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 平滑系数 β^ 随瞬时信噪比变化曲线" src="Detail/GetImg?filename=images/JSJY201910045_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 平滑系数 <i>β</i>^ 随瞬时信噪比变化曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 <i>β</i>^ varying with instantaneous SNR</p>

                </div>
                <div class="p1">
                    <p id="79">改进后的DD算法为:</p>
                </div>
                <div class="area_img" id="80">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910045_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="82">增益函数<i>G</i><citation id="276" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mspace width="0.25em" /><mrow><mi>max</mi></mrow><mrow><mo>〖</mo><mrow><mi>G</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo>,</mo><mrow><mo>(</mo><mrow><mfrac><mrow><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext></mrow><mn>2</mn></msubsup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext></mrow><mn>2</mn></msubsup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中:<i>G</i><sub>min</sub>为实验选取的定值。利用增益函数替代<i>M</i>^ <sub><i>S</i></sub>能够提升增强语音的主观听感<citation id="277" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="85">利用改进后DD算法得到的初始掩蔽<image id="218" type="formula" href="images/JSJY201910045_21800.jpg" display="inline" placement="inline"><alt></alt></image><sub>Sprop</sub>为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>Μ</mi><mo>^</mo><mspace width="0.25em" /></mrow><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">图3为10 dB的Engine噪声下估计得到的<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml>、<mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml><sub>MDD</sub>和<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml><sub>prop</sub>与瞬时信噪比的对比曲线。选取频带数为10、20、46和49,对应的中心频率分别为234 Hz、496 Hz、2 100 Hz和2 437 Hz。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 10 dB的Engine噪声下各频带内瞬时信噪比与估计先验信噪比" src="Detail/GetImg?filename=images/JSJY201910045_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 10 dB的Engine噪声下各频带内瞬时信噪比与估计先验信噪比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Comparison of instantaneous SNR and priori SNR estimation in different Gammatone frequency channels under 10 dB Engine noise</p>

                </div>
                <div class="p1">
                    <p id="89">可以看出在瞬时信噪比较高的部分,使用DD算法得到结果存在延时。对比四幅图片得到,相对于其他两种算法,<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml><sub>prop</sub>的结果在低频部分更接近真实的瞬时信噪比。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">2.3 <b>基于凸优化的掩蔽估计</b></h4>
                <h4 class="anchor-tag" id="91" name="91">2.3.1 基于凸优化的语音增强</h4>
                <div class="p1">
                    <p id="92">文献<citation id="278" type="reference">[<a class="sup">6</a>]</citation>提出在已知带噪语音和噪声能量谱的情况下,计算<i>S</i>^ (<i>t</i>, <i>f</i>)的过程可以看作凸优化(Convex Optimization)的过程,表示为:</p>
                </div>
                <div class="area_img" id="219">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910045_21900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="94">目标函数<i>J</i>的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>J</mi><mo>=</mo><mo stretchy="false">∥</mo><mi>Y</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>-</mo><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mi>λ</mi><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">选取式(15)为目标函数的目的在于,令式(14)得到的解<image id="220" type="formula" href="images/JSJY201910045_22000.jpg" display="inline" placement="inline"><alt></alt></image> (<i>t</i>, <i>f</i>)与<i>Y</i>(<i>t</i>, <i>f</i>)-<i>D</i>(<i>t</i>, <i>f</i>)之间的差值尽可能最小,使语音能量值尽可能接近最优值。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">2.3.2 噪声存在概率与优化目标</h4>
                <div class="p1">
                    <p id="98">噪声估计过程中不可避免存在误差,尤其对噪声的过估计会引起<image id="221" type="formula" href="images/JSJY201910045_22100.jpg" display="inline" placement="inline"><alt></alt></image> (t, f)取负值。尽管可以通过补偿手段消去这些负值,但同样会损失掉部分语音成分,降低合成增强语音的听感和可懂度。</p>
                </div>
                <div class="p1">
                    <p id="99">为解决此问题,将式(15)修改后得:</p>
                </div>
                <div class="area_img" id="222">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910045_22200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="103">其中0≤ρ(t, f)≤1为当前时频单元内带噪语音与噪声的频带内互相关系数<citation id="279" type="reference"><link href="233" rel="bibliography" /><link href="241" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">10</a>]</sup></citation>,其计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">y</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi></mrow><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi></mrow></msub></mrow><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi></mrow></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi></mrow></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中: <i><b>y</b></i><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi></mrow><mtext>Τ</mtext></msubsup></mrow></math></mathml>和<i><b>d</b></i><sub><i>t</i></sub><sub>, </sub><sub><i>f</i></sub>分别表示时间帧为<i>t</i>、频带中心频率为<i>f</i>的时频单元内,带噪语音和估计噪声的时域信号经过离散傅里叶变换后得到的幅度谱;符号“T”表示转置。由于计算得到的能量值非负,式(15)中第二项可记作<i>S</i>(<i>t</i>, <i>f</i>)。</p>
                </div>
                <div class="p1">
                    <p id="106">式(17)得到的<i>ρ</i>可以当作带噪语音中噪声存在的概率。因此在求解式(14)过程中可用<i>ρ</i>(<i>t</i>, <i>f</i>)·<i>Y</i>(<i>t</i>, <i>f</i>)代替噪声能量。通过优化算法不断减小<i>Y</i>(<i>t</i>, <i>f</i>)-<i>ρ</i>(<i>t</i>, <i>f</i>)·<i>Y</i>(<i>t</i>, <i>f</i>)-<i>S</i>(<i>t</i>, <i>f</i>)的值,在满足停止条件后终止迭代,得到语音能量的估计<i>S</i>^ (<i>t</i>, <i>f</i>)。</p>
                </div>
                <div class="p1">
                    <p id="107">图4为选定频带内<i>ρ</i>的变化曲线。从上至下分别为第10、20、46和49频带内真实噪声下<i>ρ</i>与估计噪声下<mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ρ</mi><mo>^</mo></mover></math></mathml>的曲线。可以看出当噪声相同时,不同频带内计算得到的互相关系数互不相同。这是因为声信号通过Gammatone滤波器组后被分解到了不同的频带内,各频带对应的信号特征也不相同。同时在低频(频带数较小)部分,利用真实噪声和估计噪声得到的互相关系数波动较大,说明带噪语音中目标语音更集中在低频部分,使得在语音部分带噪语音与噪声的互相关程度较小。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 带噪语音与噪声的互相关系数ρ与 其估计值ρ^在各频带内变化曲线" src="Detail/GetImg?filename=images/JSJY201910045_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 带噪语音与噪声的互相关系数<i>ρ</i>与 其估计值<mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ρ</mi><mo>^</mo></mover></math></mathml>在各频带内变化曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.4 ρ <i>between noise and speech with noise and</i><i>its estimated value</i><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ρ</mi><mo>^</mo></mover></math></mathml><i>in different Gammatone frequency channels</i></p>

                </div>
                <h4 class="anchor-tag" id="109" name="109">2.3.3 掩蔽优化</h4>
                <div class="p1">
                    <p id="110">由于语音能量取值范围为(0,+∞),且各时频单元间能量值差异很大,导致每次迭代计算<i>S</i>^ (<i>t</i>, <i>f</i>)的运算量十分大。同时,为解决聚类的准确性和二值掩蔽对算法的影响,本文使用浮值掩蔽值替代式(14)中的能量值来当作优化目标:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>Μ</mi><mo>^</mo><mspace width="0.25em" /></mrow><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mrow><mi>Μ</mi><msub><mrow></mrow><mi>S</mi></msub></mrow></munder><mspace width="0.25em" /><mi>J</mi><mo stretchy="false">[</mo><mi>Μ</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">由于<i>M</i>^ <sub><i>S</i></sub>(<i>t</i>, <i>f</i>)∈(0,1),因此式(18)在计算时每次迭代需要的运算量要小于式(14)。同时为保证合成目标语音的整体质量,针对不同的带噪语音,在优化的初始阶段选取初次迭代值<i>M</i><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mn>0</mn></msubsup></mrow></math></mathml>=<i>M</i>^ <sub>Sprop</sub>,通过对<i>M</i>^ <sub>Sprop</sub>迭代处理,弥补因为噪声估计算法中存在的过估现象而缺失掉的语音成分。</p>
                </div>
                <div class="p1">
                    <p id="113">选取的目标函数为:</p>
                </div>
                <div class="p1">
                    <p id="114"><i>J</i>[<i>M</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)]=</p>
                </div>
                <div class="p1">
                    <p id="115">‖<i>M</i><sub><i>Y</i></sub>(<i>t</i>, <i>f</i>)-<i>ρ</i>(<i>t</i>, <i>f</i>)·<i>M</i><sub><i>Y</i></sub>(<i>t</i>, <i>f</i>)-<i>M</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)‖<mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+</p>
                </div>
                <div class="p1">
                    <p id="116"><i>λ</i>·<i>M</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)      (19)</p>
                </div>
                <div class="p1">
                    <p id="117">其中:<mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>Y</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>Y</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>+</mo><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>为带噪语音的掩蔽,将其上下同除以<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sub><i>D</i></sub>(<i>t</i>, <i>f</i>)后得:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>Y</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mover accent="true"><mi>γ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mover accent="true"><mi>ξ</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">确定目标函数后,利用梯度下降法<citation id="280" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>求得<i>M</i>^ <sub><i>S</i></sub>。算法中第<i>k</i>次迭代时梯度ᐁ<sup><i>k</i></sup>的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∇</mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>d</mtext><mi>J</mi></mrow><mrow><mtext>d</mtext><mi>Μ</mi><msubsup><mrow></mrow><mi>S</mi><mi>k</mi></msubsup><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">对<i>M</i><sub><i>S</i></sub>(<i>t</i>, <i>f</i>)的第<i>k</i>次迭代结果为:</p>
                </div>
                <div class="p1">
                    <p id="122"><i>M</i><mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>(<i>t</i>, <i>f</i>)=<i>M</i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mi>k</mi></msubsup></mrow></math></mathml>(<i>t</i>, <i>f</i>)-<i>μ</i>·ᐁ<sup><i>k</i></sup>(<i>t</i>, <i>f</i>)      (22)</p>
                </div>
                <div class="p1">
                    <p id="123">其中: <i>μ</i>为每次迭代的步长。当式(23)条件满足时停止迭代:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><mo>=</mo><mrow><mo>|</mo><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>Μ</mi><msubsup><mrow></mrow><mi>S</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">)</mo><mo>-</mo><mi>J</mi><mo stretchy="false">(</mo><mi>Μ</mi><msubsup><mrow></mrow><mi>S</mi><mi>k</mi></msubsup><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>≤</mo><mi>θ</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">根据上文的内容描述,本文提出的掩蔽优化算法可以分为以下步骤:</p>
                </div>
                <div class="p1">
                    <p id="126">1)<i>k</i>=0,初始化<i>M</i><mathml id="183"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mn>0</mn></msubsup></mrow></math></mathml>=<i>M</i>^ <sub>Sprop</sub>,根据式(17)计算频带内互相关系数<i>ρ</i>。</p>
                </div>
                <div class="p1">
                    <p id="127">2)根据式(21)计算梯度ᐁ<sup><i>k</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="128">3)根据式(22)计算<i>M</i><mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="129">4)根据式(23)计算<i>ε</i>。</p>
                </div>
                <div class="p1">
                    <p id="130">5)如果<i>ε</i>≤<i>θ</i>,退出循环;否则<i>k</i>=<i>k</i>+1,转至步骤2)。</p>
                </div>
                <div class="p1">
                    <p id="131">计算得到的掩蔽在语音部分不平整,需要结合当前时频点和其邻近点进一步进行平滑处理。对<i>M</i>^ <sub><i>S</i></sub>(<i>t</i>, <i>f</i>)做平滑处理<citation id="281" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>后得到本文中用于合成增强语音的掩蔽:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>Μ</mi><mo>^</mo><mspace width="0.25em" /></mrow><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext><mtext>e</mtext><mtext>x</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>-</mo><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>t</mi><mo>+</mo><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>f</mi><mo>-</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>f</mi><mo>+</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></munderover><mrow><mfrac><mrow><mrow><mi>Μ</mi><mo>^</mo><mspace width="0.25em" /></mrow><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">)</mo></mrow><mi>Ν</mi></mfrac></mrow></mstyle></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中:<i>N</i>=(2<i>n</i><sub>1</sub>+1)·(2<i>n</i><sub>2</sub>+1)。图5为<i>n</i><sub>1</sub>=<i>n</i><sub>2</sub>=1时平滑处理中当前点与其邻近点示意图。</p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 n1=n2=1时平滑处理示意图" src="Detail/GetImg?filename=images/JSJY201910045_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 <i>n</i><sub>1</sub>=<i>n</i><sub>2</sub>=1时平滑处理示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Smooth processing with <i>n</i><sub>1</sub>=<i>n</i><sub>2</sub>=1</p>

                </div>
                <div class="p1">
                    <p id="135">图6为在5 dB的Engine噪声下,计算得到的初始掩蔽与优化后掩蔽恢复的增强语音在第10、20、46、49频带内的归一化能量波形。</p>
                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910045_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同掩蔽得到增强语音的归一化能量波形" src="Detail/GetImg?filename=images/JSJY201910045_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同掩蔽得到增强语音的归一化能量波形  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910045_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Normalized power of enhanced speeches using different masks</p>

                </div>
                <div class="p1">
                    <p id="137">可以看出在低频部分,<i>M</i>^ <sub>Sprop</sub>和<i>M</i>^ <sub>Sconvex</sub>恢复的语音能量差异不大,两者均接近于使用IRM合成的语音。在高频部分,使用<i>M</i>^ <sub>Sconvex</sub>得到的增强语音的能量更加突出,其波形相对于<i>M</i>^ <sub>Sprop</sub>更接近于理想情况。</p>
                </div>
                <h3 id="138" name="138" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="139" name="139">3.1 <b>实验参数与评价指标</b></h4>
                <div class="p1">
                    <p id="140">仿真实验选取<i>TIMIT</i>数据库<citation id="282" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>中的语音信号。信号采样频率为16 <i>kHz</i>,16 <i>bit</i>量化,时长约为2 <i>s</i>。噪声取自<i>noisex</i>-92数据库<citation id="283" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>,分别为<i>Babble</i>噪声、<i>Engine</i>噪声和<i>White</i>噪声,分别在输入信噪比为-5～5 <i>dB</i>、间隔为1 <i>dB</i>的情况下测试本文算法。</p>
                </div>
                <div class="p1">
                    <p id="141">实验使用4阶64频带<i>Gammatone</i>滤波器组,每一帧长20 <i>ms</i>,帧重叠为50%。选取参数为:式(10)中,<i>a</i>=-2,<i>c</i>=2.7,<i>ζ</i>=0.015。式(12)中,<i>G</i><sub>min</sub>=0.178。式(19)中<i>λ</i>=0.02,式(22)中<i>μ</i>=0.01,式(23)中<i>θ</i>=0.3。式(24)中<i>n</i><sub>1</sub>=1,<i>n</i><sub>2</sub>=1。</p>
                </div>
                <div class="p1">
                    <p id="142">本文使用文献<citation id="284" type="reference">[<a class="sup">16</a>]</citation>算法对时域的噪声信号进行估计,将该算法与文献<citation id="285" type="reference">[<a class="sup">6</a>]</citation>算法作为对比算法。选取的评价指标除分段信噪比(segmental Signal-to-Noise Ratio, segSNR)外,还有主观语音质量(Perceptual Evaluation of Speech Quality, PESQ)<citation id="286" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation> 和语音可懂度(Short-Time Objective Intelligibility measure, STOI)<citation id="287" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="143">分段信噪比计算信号每帧的信噪比后取平均值,其值越高说明算法对噪声的抑制效果越好;PESQ表示增强语音的主观听感,其得分越高,表明增强语音的听感越好;STOI反映了增强语音的失真程度,其数值越大表明算法造成的失真越小,语音的可懂度越高。</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144">3.2 <b>结果与分析</b></h4>
                <div class="p1">
                    <p id="145">表1～2给出了在三种背景噪声下掩蔽优化前后得到的平均<i>PESQ</i>和<i>STOI</i>值。比较结果可以看出,经过掩蔽优化后增强语音的听感与可懂度都得到了提升,尤其是在<i>Engine</i>噪声下两项指标提升较为明显。</p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表</b>1 <b>掩蔽优化前后的</b><i>PESQ</i><b>结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Average PESQ score before and after mask optimization</i></p>
                    <p class="img_note"></p>
                    <table id="146" border="1"><tr><td><br />噪声类型</td><td>优化前算法</td><td>本文算法</td></tr><tr><td><br /><i>Babble</i></td><td>1.923</td><td><b>1.975</b></td></tr><tr><td><br />Engine</td><td>2.039</td><td><b>2.083</b></td></tr><tr><td><br />White</td><td>1.944</td><td><b>1.973</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="147">
                    <p class="img_tit"><b>表</b>2 <b>掩蔽优化前后的</b>STOI<b>平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.2 Average STOI score before and after mask optimization</p>
                    <p class="img_note"></p>
                    <table id="147" border="1"><tr><td><br />噪声类型</td><td>优化前算法</td><td>本文算法</td></tr><tr><td><br />Babble</td><td>0.714</td><td><b>0.719</b></td></tr><tr><td><br />Engine</td><td>0.724</td><td><b>0.740</b></td></tr><tr><td><br />White</td><td>0.698</td><td><b>0.712</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="148">表3为两种掩蔽得到的segSNR平均值。可见,在Babble噪声和White噪声下,掩蔽优化后得到的segSNR值均小于优化前的结果,即本文提出的掩蔽优化算法无法有效抑制噪声。分析其原因,虽然估计的频带间互相关系数和真实值存在相似性(见图4),但其取值范围在低频部分并不相同,使得计算得到的噪声存在概率总是大于实际概率。因此相对初始掩蔽,优化后的掩蔽在合成增强语音时保留了更多的噪声成分。</p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit"><b>表</b>3 <b>掩蔽优化前后的</b>segSNR<b>平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.3 Average segSNR before and after mask optimization</p>
                    <p class="img_note">单位:dB</p>
                    <table id="149" border="1"><tr><td><br />噪声类型</td><td>优化前算法</td><td>本文算法</td></tr><tr><td><br />Babble</td><td>-<b>0.209</b></td><td>-0.407</td></tr><tr><td><br />Engine</td><td>-0.473</td><td>-<b>0.332</b></td></tr><tr><td><br />White</td><td><b>0.300</b></td><td>-0.167</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="150">对比表4中三种算法的PESQ值可看出:本文算法比对比算法得到了相对较高的PESQ值,但在Babble噪声下其结果低于文献<citation id="288" type="reference">[<a class="sup">6</a>]</citation>算法,是因为文献<citation id="289" type="reference">[<a class="sup">6</a>]</citation>采用了结合IBM与IRM的掩蔽,且最终掩蔽中IBM占比较大,使其算法在吵闹噪声下能够消去多余的噪声成分,得到更好的主观听感。在其他噪声环境下,本文算法得到的主观听感均高于对比算法。</p>
                </div>
                <div class="area_img" id="151">
                    <p class="img_tit"><b>表</b>4 <b>三种语音增强算法在不同信噪比下的</b>PESQ<b>平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.4 Average PESQ score of three algorithms under various SNR conditions</p>
                    <p class="img_note"></p>
                    <table id="151" border="1"><tr><td><br />噪声类型</td><td>信噪比/dB</td><td>本文算法</td><td>文献[16]算法</td><td>文献[6]算法</td></tr><tr><td></td><td>-5</td><td>1.846</td><td>1.808</td><td><b>1.850</b></td></tr><tr><td><br />Babble</td><td>0</td><td><b>1.970</b></td><td>1.912</td><td>1.928</td></tr><tr><td><br /></td><td>5</td><td>2.121</td><td>2.041</td><td><b>2.183</b></td></tr><tr><td><br /></td><td>-5</td><td><b>1.911</b></td><td>1.860</td><td>1.871</td></tr><tr><td><br />Engine</td><td>0</td><td><b>2.091</b></td><td>1.983</td><td>2.037</td></tr><tr><td><br /></td><td>5</td><td><b>2.230</b></td><td>2.092</td><td>2.218</td></tr><tr><td><br /></td><td>-5</td><td><b>1.765</b></td><td>1.665</td><td>1.710</td></tr><tr><td><br />White</td><td>0</td><td><b>1.979</b></td><td>1.893</td><td>1.972</td></tr><tr><td><br /></td><td>5</td><td><b>2.163</b></td><td>2.079</td><td>2.148</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="152">表5为三种算法的STOI值对比。观察表5中的数据,本文算法能够有效保留增强语音中的语音成分,得到了相对较高的语音可懂度。</p>
                </div>
                <div class="area_img" id="153">
                    <p class="img_tit"><b>表</b>5 <b>三种语音增强算法在不同信噪比下的</b>STOI<b>平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.5 Average STOI of three algorithms under various SNR conditions</p>
                    <p class="img_note"></p>
                    <table id="153" border="1"><tr><td><br />噪声类型</td><td>信噪比/dB</td><td>本文算法</td><td>文献[16]算法</td><td>文献[6]算法</td></tr><tr><td></td><td>-5</td><td>0.705</td><td>0.685</td><td><b>0.709</b></td></tr><tr><td><br />Babble</td><td>0</td><td><b>0.716</b></td><td>0.694</td><td><b>0.716</b></td></tr><tr><td><br /></td><td>5</td><td><b>0.744</b></td><td>0.723</td><td>0.741</td></tr><tr><td><br /></td><td>-5</td><td><b>0.720</b></td><td>0.699</td><td>0.712</td></tr><tr><td><br />Engine</td><td>0</td><td><b>0.743</b></td><td>0.726</td><td>0.737</td></tr><tr><td><br /></td><td>5</td><td><b>0.755</b></td><td>0.738</td><td>0.748</td></tr><tr><td><br /></td><td>-5</td><td><b>0.676</b></td><td>0.656</td><td>0.667</td></tr><tr><td><br />White</td><td>0</td><td><b>0.716</b></td><td>0.699</td><td>0.711</td></tr><tr><td><br /></td><td>5</td><td><b>0.754</b></td><td>0.733</td><td>0.748</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="154">表6为三种算法得到的segSNR值。由表6可知,文献<citation id="290" type="reference">[<a class="sup">16</a>]</citation>算法有最高的噪声抑制性能,而采用Gammatone频带内互相关系数的文献<citation id="291" type="reference">[<a class="sup">6</a>]</citation>算法与本文算法均取得了较低的segSNR值。这一方面是由于频带间互相关系数和真实值存在差异,另一方面是改进的DD算法在计算时并未区分语音的低频和高频成分,同时其在瞬时信噪比较低时对<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>ξ</mi><mo>^</mo></mover></math></mathml><sub>prop</sub>的估计不准确,使得初始掩蔽中仍保留了部分噪声成分。解决这一问题是本研究下一步工作之一。然而,相对于抑制噪声的能力,语音增强算法更注重提升语音听感与可懂度<citation id="292" type="reference"><link href="233" rel="bibliography" /><link href="259" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">19</a>]</sup></citation>,根据PESQ和STOI结果,本文算法在这两个方面优于对比算法。</p>
                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表</b>6 <b>三种语音增强算法在不同信噪比下的</b>segSNR<b>平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.6 Average segSNR of three algorithms under various SNR conditions</p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />噪声类型</td><td>信噪比/dB</td><td>本文算法</td><td>文献[16]算法</td><td>文献[6]算法</td></tr><tr><td></td><td>-5</td><td>-1.980</td><td>-<b>1.637</b></td><td>-1.934</td></tr><tr><td><br />Babble</td><td>0</td><td>-0.376</td><td>-<b>0.340</b></td><td>-0.393</td></tr><tr><td><br /></td><td>5</td><td>0.770</td><td><b>0.874</b></td><td>0.244</td></tr><tr><td><br /></td><td>-5</td><td>-1.902</td><td>-<b>1.522</b></td><td>-3.668</td></tr><tr><td><br />Engine</td><td>0</td><td>-0.654</td><td>-<b>0.432</b></td><td>-1.256</td></tr><tr><td><br /></td><td>5</td><td>0.711</td><td><b>0.782</b></td><td>0.466</td></tr><tr><td><br /></td><td>-5</td><td>-1.368</td><td>-<b>1.165</b></td><td>-2.098</td></tr><tr><td><br />White</td><td>0</td><td>-0.481</td><td>-<b>0.377</b></td><td>-1.704</td></tr><tr><td><br /></td><td>5</td><td>0.271</td><td><b>1.002</b></td><td>0.177</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="156" name="156" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="157">本文针对单通道语音增强时,传统噪声估计算法中存在的过估现象会影响增强语音的整体质量问题,提出一种基于时频掩蔽估计与优化的单通道语音增强算法。该算法在得到初始掩蔽后,利用迭代优化增加初始掩蔽中的目标语音成分。实验结果表明,算法虽然不能提升初始掩蔽抑制噪声的性能,但在另外两项关键指标(PESQ和STOI)上本文算法较对比算法均有明显提升,说明本文算法能有效提升增强语音的听感与可懂度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="223">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201301045&amp;v=MDIyNDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWprVkw3SU5pZllaTEc0SDlMTXJvOUJZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>曹亮,张天骐,高洪兴,等.基于听觉掩蔽效应的多频带谱减语音增强方法[J].计算机工程与设计,2013,34(1):235-240.(CAO L,ZHANG T Q,GAO H X,et al.Multi-band spectral subtraction method for speech enhancement based on masking property of human auditory system[J].Computer Engineering and Design,2013,34(1):235-240.)
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CASH201604004&amp;v=Mjc4ODl1WnNGeWprVkw3SUppellackc0SDlmTXE0OUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>李季碧,马永保,夏杰,等.一种基于修正倒谱平滑技术改进的维纳滤波语音增强算法[J].重庆邮电大学学报(自然科学版),2016,28(4):462-467.(LI J B,MA Y B,XIA J,et al.An improved Wiener filtering speech enhancement algorithm based on modified cepstrum smooth technology[J].Journal of Chongqing University of Posts and Telecommunications(Natural Science Edition),2016,28(4):462-467.)
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300465324&amp;v=MDYyMTRNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSUY4VGF4ST1OaWZPZmJLN0h0RE9ySTlGWU8wS0QzNDlvQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>BOROWICZ A,PETROVSKY A.Signal subspace approach for psychoacoustically motivated speech enhancement[J].Speech communication,2011,53(2):210-219.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unvoiced Speech Segregation From Nonspeech Interference via CASA and Spectral Subtraction">

                                <b>[4]</b>HU K,WANG D.Unvoiced speech segregation from nonspeech interference via CASA and spectral subtraction[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(6):1600-1609.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM0E6E7473F6DC5B47300C24AE9430C360&amp;v=MjUwMDdCckxVMDV0cGh4TG00d2FnPU5pZklZN1BOR0tUTHE0aEdFdTE3ZjNsTHl4RVE2ajhPU251VDJSc3hlckxuUnJ5ZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>WANG Y,NARAYANAN A,WANG D,et al.On training targets for supervised speech separation[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2014,22(12):1849-1858.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Noise masking method based on an effective ratio mask estimation in Gammatone channels">

                                <b>[6]</b>BAO F,ABDULLA W H.Noise masking method based on an effective ratio mask estimation in Gammatone channels[J].APSIPATransactions on Signal and Information Processing,2018,7(e5):1-12.
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM9E8CF857A519612F45A9CCDAFCC552CB&amp;v=MjcyNDJLNnA0cENGZTRPQlhvNHpXQVg3MDUwT3d5VzNXUkdDcmVSUjhudENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTR3YWc9TmlmSVk3ck5GcQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>SUN M,LI Y,GEMMEKE J F,et al.Speech enhancement under low SNR conditions via noise estimation using sparse and low-rank NMF with Kullback-Leibler divergence[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2015,23(7):1233-1242.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convex combination framework for a priori SNR estimation in speech enhancement">

                                <b>[8]</b>NAHMA L,YONG P C,DAM H H,et al.Convex combination framework for a priori SNR estimation in speech enhancement[C]//Proceedings of the 2017 IEEE International Conference on Acoustics,Speech and Signal Processing.Piscataway,NJ.IEEE,2017:4975-4979.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHXB201409010&amp;v=MDMwMTFNcG85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5amtWTDdJTkNYVGJMRzRIOVg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>蒋毅,刘润生,冯振明.基于听感知特性的双麦克风近讲语音增强算法[J].清华大学学报(自然科学版),2014(9):1179-1183.(JIANG Y,LIU R S,FENG Z M.Dual-microphone speech enhancement algorithm based on the auditory features for a closetalk system[J].Journal of Tsinghua University(Science and Technology),2014,54(9):1179-1183.)
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new ratio mask representation for CASA-based speech enhancement">

                                <b>[10]</b>BAO F,ABDULLA W H.A new ratio mask representation for CASA-based speech enhancement[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2019,27(1):7-19.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the optimization of sigmoid function for speech enhancement">

                                <b>[11]</b>YONG P C,NORDHOLM S,DAM H H,et al.On the optimization of sigmoid function for speech enhancement[C]//Proceedings of the 19th European Signal Processing Conference.Piscataway:IEEE,2011:211-215.
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM2713DAB3F79FB896B40DFA01444DFB35&amp;v=MzAxNTlCckxVMDV0cGh4TG00d2FnPU5pZklZN0cvSDlLNDN2MUdFdXdHZWc0eHhoQmg3ajhKUGc3aXJSWXhmY2JpTjdtYUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>CHEN Z,HOHMANN V.Online monaural speech enhancement based on periodicity analysis and a priori SNR estimation[J].IEEE/ACM Transactions on Audio,Speech and Language Processing,2015,23(11):1904-1916.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC752FC0B2C8730FE17B3104DD5433CC6&amp;v=MDI5MDFPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTR3YWc9TmlmT2ZjQy9HOU82M0k4M1pwZ0hDMzg1dVdNUzdVMStTWC9tMkdZd2ZiR1hOc21aQw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>ZHENG C,TAN Z,PENG R,et al.Guided spectrogram filtering for speech dereverberation[J].Applied Acoustics,2018,134(5):154-159.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=TIMITAcoustic-Phonetic Continuous Speech Corpus">

                                <b>[14]</b>GAROFOLO J S,LAMEL L F,FISHER W M,et al.TIMITAcoustic-Phonetic Continuous Speech Corpus[EB/OL].[2019-01-12].https://catalog.ldc.upenn.edu/LDC93S1.
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems">

                                <b>[15]</b>VARGA A,STEENEKEN H J M.Assessment for automatic speech recognition II:NOISEX-92:a database and an experiment to study the effect of additive noise on speech recognition systems[J].Speech Communication,1993,12(3):247-251.
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unbiased MMSE-Based Noise Power Estimation With Low Complexity and Low Tracking Delay">

                                <b>[16]</b>GERKMANN T,HENDRIKS R C.Unbiased MMSE-based noise power estimation with low complexity and low tracking delay[J].IEEE Transactions on Audio,Speech,and Language Processing,2012,20(4):1383-1393.
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs">

                                <b>[17]</b>International Telecommunications Union(ITU).Perceptual Evaluation of Speech Quality(PESQ):an objective method for end-toend speech quality assessment of narrow-band telephone networks and speech codecs[EB/OL].[2019-01-12].https://www.itu.int/rec/T-REC-P.862-200102-I/en.
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech">

                                <b>[18]</b>TAAL C H,HENDRIKS R C,HEUSDENS R,et al.An algorithm for intelligibility prediction of time-frequency weighted noisy speech[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(7):2125-2136.
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reasons why Current Speech-Enhancement Algorithms do not Improve Speech Intelligibility and Suggested Solutions">

                                <b>[19]</b>LOIZOU P C,KIM G.Reasons why current speech-enhancement algorithms do not improve speech intelligibility and suggested solutions[J].IEEE Transactions on Audio,Speech,and Language Processing,2011,19(1):47-56.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910045" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910045&amp;v=MjA5MzN5amtWTDdJTHo3QmQ3RzRIOWpOcjQ5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
