<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136444400440000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJY201911004%26RESULT%3d1%26SIGN%3deqm3J%252b1qnVGYJy0iO12pjn3vKPk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911004&amp;v=MTk3OTZWTHZNTHo3QmQ3RzRIOWpOcm85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#59" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="1 相关技术 ">1 相关技术</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="1.1 &lt;b&gt;三支决策基本理论&lt;/b&gt;">1.1 <b>三支决策基本理论</b></a></li>
                                                <li><a href="#73" data-title="1.2 &lt;b&gt;聚类集成&lt;/b&gt;">1.2 <b>聚类集成</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="2 基聚类三支筛选 ">2 基聚类三支筛选</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="2.1 &lt;b&gt;基于信息熵的类簇不确定性度量&lt;/b&gt;">2.1 <b>基于信息熵的类簇不确定性度量</b></a></li>
                                                <li><a href="#104" data-title="2.2 &lt;b&gt;面向基聚类的三支筛选方法&lt;/b&gt;">2.2 <b>面向基聚类的三支筛选方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="3 实验结果 ">3 实验结果</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#167" data-title="3.1 &lt;b&gt;基数据集和评价方法&lt;/b&gt;">3.1 <b>基数据集和评价方法</b></a></li>
                                                <li><a href="#190" data-title="3.2 &lt;b&gt;对比实验分析&lt;/b&gt;">3.2 <b>对比实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#212" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;集合&lt;/b&gt;&lt;i&gt;Π&lt;/i&gt;&lt;b&gt;中类簇和数据对象分布&lt;/b&gt;"><b>表</b>1 <b>集合</b><i>Π</i><b>中类簇和数据对象分布</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;类簇不确定性计算&lt;/b&gt;"><b>表</b>2 <b>类簇不确定性计算</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;基聚类质量评价指标&lt;/b&gt;"><b>表</b>3 <b>基聚类质量评价指标</b></a></li>
                                                <li><a href="#170" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;数据集描述&lt;/b&gt;"><b>表</b>4 <b>数据集描述</b></a></li>
                                                <li><a href="#192" data-title="图1 阈值对算法性能的影响">图1 阈值对算法性能的影响</a></li>
                                                <li><a href="#195" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;不同数据集的阈值&lt;/b&gt;"><b>表</b>5 <b>不同数据集的阈值</b></a></li>
                                                <li><a href="#206" data-title="图2 各方法在基准数据集上的性能比较">图2 各方法在基准数据集上的性能比较</a></li>
                                                <li><a href="#211" data-title="&lt;b&gt;表&lt;/b&gt;6 &lt;b&gt;不同聚类集成方法效果对比&lt;/b&gt;"><b>表</b>6 <b>不同聚类集成方法效果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="330">


                                    <a id="bibliography_1" title=" 宋敬环.聚类集成算法研究[D].哈尔滨:哈尔滨工程大学,2015:1.(SONG J H.Research on clustering ensemble method[D].Harbin:Harbin Engineering University,2015:1)." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018050909.nh&amp;v=MTQ3OTh0R0ZyQ1VSN3FmWnVac0Z5bm5WTHZNVkYyNkZyTzlIdGpNcHBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         宋敬环.聚类集成算法研究[D].哈尔滨:哈尔滨工程大学,2015:1.(SONG J H.Research on clustering ensemble method[D].Harbin:Harbin Engineering University,2015:1).
                                    </a>
                                </li>
                                <li id="332">


                                    <a id="bibliography_2" title=" STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining partitionings[J].Journal of Machine Learning Research,2003,3(3):583-617." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cluster ensembles - A knowledge reuse framework for combining multiple partitions">
                                        <b>[2]</b>
                                         STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining partitionings[J].Journal of Machine Learning Research,2003,3(3):583-617.
                                    </a>
                                </li>
                                <li id="334">


                                    <a id="bibliography_3" title=" YU Z,LI L,LIU J,et al.Adaptive noise immune cluster ensemble using affinity propagation[J].IEEE Transactions on Knowledge and Data Engineering,2015,27(12):3176-3189." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive noise immune cluster ensemble using affinity propagation">
                                        <b>[3]</b>
                                         YU Z,LI L,LIU J,et al.Adaptive noise immune cluster ensemble using affinity propagation[J].IEEE Transactions on Knowledge and Data Engineering,2015,27(12):3176-3189.
                                    </a>
                                </li>
                                <li id="336">


                                    <a id="bibliography_4" title=" HUANG D,LAI J,WANG C.Combining multiple clusterings via crowd agreement estimation and multi-granularity link analysis[J].Neurocomputing,2015,170:240-250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES57E07D6381E7F3CC59F9C03CAB0A7BF6&amp;v=MTUyODE5SEwyNGxHYk9wNkN3bzZ2R1VXNDBsME8zL2gzMk5IZWNPVE44eVpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4YnE0eEt3PU5pZk9mYmEvYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         HUANG D,LAI J,WANG C.Combining multiple clusterings via crowd agreement estimation and multi-granularity link analysis[J].Neurocomputing,2015,170:240-250.
                                    </a>
                                </li>
                                <li id="338">


                                    <a id="bibliography_5" title=" YANG Y.Elements of information theory[J].Journal of the American Statistical Association,2008,103(3):429-429." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800006060&amp;v=MTk1ODlySzdIdGZPcDQ5RlpPc0pESG81b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZ3VGJoWT1Oam5CYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         YANG Y.Elements of information theory[J].Journal of the American Statistical Association,2008,103(3):429-429.
                                    </a>
                                </li>
                                <li id="340">


                                    <a id="bibliography_6" title=" IAM-ON N,BOONGOEN T,GARRETT S,et al.A link-based approach to the cluster ensemble problem[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2396-2409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Link-Based Approach to the Cluster Ensemble Problem">
                                        <b>[6]</b>
                                         IAM-ON N,BOONGOEN T,GARRETT S,et al.A link-based approach to the cluster ensemble problem[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2396-2409.
                                    </a>
                                </li>
                                <li id="342">


                                    <a id="bibliography_7" title=" WANG T.CA-Tree:a hierarchical structure for efficient and scalable coassociation-based cluster ensembles[J].IEEE Transactions on Systems,Man,and Cybernetics,Part B:Cybernetics,2011,41(3):686-698." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CA-Tree: A hierarchical structure for efficient and scalable coassociation-based cluster ensembles">
                                        <b>[7]</b>
                                         WANG T.CA-Tree:a hierarchical structure for efficient and scalable coassociation-based cluster ensembles[J].IEEE Transactions on Systems,Man,and Cybernetics,Part B:Cybernetics,2011,41(3):686-698.
                                    </a>
                                </li>
                                <li id="344">


                                    <a id="bibliography_8" title=" TUMER K,AGOGINO A K.Ensemble clustering with voting active clusters[J].Pattern Recognition Letters,2008,29(14):1947-1953." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414231&amp;v=MjA3OTgzSUlWd1RiaFk9TmlmT2ZiSzdIdERPckk5RllPb0xEbjg0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         TUMER K,AGOGINO A K.Ensemble clustering with voting active clusters[J].Pattern Recognition Letters,2008,29(14):1947-1953.
                                    </a>
                                </li>
                                <li id="346">


                                    <a id="bibliography_9" title=" 董彩云,杜韬,郭春燕,等.聚类后的关联规则快速更新算法研究[J].计算机应用研究,2004,21(11):30-32.(DONG C Y,DU T,GUO C Y,et al.Research on fast adapting algorithm of association rules after clustering[J].Application Research of Computers,2004,21(11):30-32.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200411010&amp;v=MjgwMDl1WnNGeW5uVkx2TUx6N1NaTEc0SHRYTnJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         董彩云,杜韬,郭春燕,等.聚类后的关联规则快速更新算法研究[J].计算机应用研究,2004,21(11):30-32.(DONG C Y,DU T,GUO C Y,et al.Research on fast adapting algorithm of association rules after clustering[J].Application Research of Computers,2004,21(11):30-32.)
                                    </a>
                                </li>
                                <li id="348">


                                    <a id="bibliography_10" title=" TOPCHY A,JAIN A K,PUNCH W.Clustering ensembles:models of consensus and weak partitions [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(12):1866-1881." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering Ensembles: Models of Consensus and Weak Partitions">
                                        <b>[10]</b>
                                         TOPCHY A,JAIN A K,PUNCH W.Clustering ensembles:models of consensus and weak partitions [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(12):1866-1881.
                                    </a>
                                </li>
                                <li id="350">


                                    <a id="bibliography_11" title=" STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining multiple partitions [J].Journal of Machine Learning Research,2002,3:583-617." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cluster ensembles-a knowledge reuse framework for combining partitions">
                                        <b>[11]</b>
                                         STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining multiple partitions [J].Journal of Machine Learning Research,2002,3:583-617.
                                    </a>
                                </li>
                                <li id="352">


                                    <a id="bibliography_12" title=" FRED A L,JAIN A K.Combining multiple clusterings using evidence accumulation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(6):835-850." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining multiple clusterings using evidence accumulation">
                                        <b>[12]</b>
                                         FRED A L,JAIN A K.Combining multiple clusterings using evidence accumulation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(6):835-850.
                                    </a>
                                </li>
                                <li id="354">


                                    <a id="bibliography_13" title=" FERN X Z,BRODLEY C E.Random projection for high dimensional data clustering:a cluster ensemble approach[C]// Proceedings of the 20th International Conference on Machine Learning.Palo Alto:AAAI Press,2003:187-192." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Random Projection for High Dimensional Data Clustering:A Cluster Ensemble Approach">
                                        <b>[13]</b>
                                         FERN X Z,BRODLEY C E.Random projection for high dimensional data clustering:a cluster ensemble approach[C]// Proceedings of the 20th International Conference on Machine Learning.Palo Alto:AAAI Press,2003:187-192.
                                    </a>
                                </li>
                                <li id="356">


                                    <a id="bibliography_14" title=" KUNCHEVA L I,VETRO D P.Evaluation of stability of k-means cluster ensembles with respect to random initialization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1798-1808." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evaluation of stability of k-means cluster ensembles with respect to random initialization">
                                        <b>[14]</b>
                                         KUNCHEVA L I,VETRO D P.Evaluation of stability of k-means cluster ensembles with respect to random initialization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1798-1808.
                                    </a>
                                </li>
                                <li id="358">


                                    <a id="bibliography_15" title=" MINAEIBIDGOLI B,TOPCHY A,PUNCH W F.Ensembles of partitions via data resampling[C]// Proceedings of the 2004 International Conference on Information Technology:Coding and Computing.Washington,DC:IEEE Computer Society,2004:188-192." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensembles of Partitions via Data Resampling">
                                        <b>[15]</b>
                                         MINAEIBIDGOLI B,TOPCHY A,PUNCH W F.Ensembles of partitions via data resampling[C]// Proceedings of the 2004 International Conference on Information Technology:Coding and Computing.Washington,DC:IEEE Computer Society,2004:188-192.
                                    </a>
                                </li>
                                <li id="360">


                                    <a id="bibliography_16" title=" DUDOIT S,FRIDLYAND J.Bagging to improve the accuracy of a clustering procedure[J].Bioinformatics,2003,19(9):1090-1099." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bagging to improve the accuracy of a clustering procedure">
                                        <b>[16]</b>
                                         DUDOIT S,FRIDLYAND J.Bagging to improve the accuracy of a clustering procedure[J].Bioinformatics,2003,19(9):1090-1099.
                                    </a>
                                </li>
                                <li id="362">


                                    <a id="bibliography_17" title=" YANG Y,JIANG J.Hybrid sampling-based clustering ensemble with global and local constitutions[J].IEEE Transactions on Neural Networks and Learning Systems,2017,27(5):952-965." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hybrid sampling-based clustering ensemble with global and local constitutions">
                                        <b>[17]</b>
                                         YANG Y,JIANG J.Hybrid sampling-based clustering ensemble with global and local constitutions[J].IEEE Transactions on Neural Networks and Learning Systems,2017,27(5):952-965.
                                    </a>
                                </li>
                                <li id="364">


                                    <a id="bibliography_18" title=" ZHOU P,DU L,WANG H,et al.Learning a robust consensus matrix for clustering ensemble via Kullback-Leibler divergence minimization[C]// Proceedings of the 24th International Conference on Artificial Intelligence.Palo Alto:AAAI Press,2015:4112-4118." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning a robust consensus matrix for clustering ensemble via KullbackLeibler divergence minimization">
                                        <b>[18]</b>
                                         ZHOU P,DU L,WANG H,et al.Learning a robust consensus matrix for clustering ensemble via Kullback-Leibler divergence minimization[C]// Proceedings of the 24th International Conference on Artificial Intelligence.Palo Alto:AAAI Press,2015:4112-4118.
                                    </a>
                                </li>
                                <li id="366">


                                    <a id="bibliography_19" title=" YU Z,LUO P,YOU J,et al.Incremental semi-supervised clustering ensemble for high dimensional data clustering[J].IEEE Transactions on Knowledge and Data Engineering,2016,28(3):701-714." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incremental Semi-supervised Clustering Ensemble for High Dimensional Data Clustering">
                                        <b>[19]</b>
                                         YU Z,LUO P,YOU J,et al.Incremental semi-supervised clustering ensemble for high dimensional data clustering[J].IEEE Transactions on Knowledge and Data Engineering,2016,28(3):701-714.
                                    </a>
                                </li>
                                <li id="368">


                                    <a id="bibliography_20" title=" YAO Y.An outline of a theory of three-way decisions[C]// Proceedings of the 8th International Conference on Rough Sets and Current Trends in Computing.Heidelberg:Springer,2012:1-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An outline of a theory of three-way decisions">
                                        <b>[20]</b>
                                         YAO Y.An outline of a theory of three-way decisions[C]// Proceedings of the 8th International Conference on Rough Sets and Current Trends in Computing.Heidelberg:Springer,2012:1-17.
                                    </a>
                                </li>
                                <li id="370">


                                    <a id="bibliography_21" title=" WANG L,MIAO D,ZHAO C.Chinese emotion recognition based on three-way decisions[C]// Proceedings of the 10th International Conference on Rough Sets and Knowledge Technology.Heidelberg:Springer,2015:299-308." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Chinese Emotion Recognition Based on Three-Way Decisions">
                                        <b>[21]</b>
                                         WANG L,MIAO D,ZHAO C.Chinese emotion recognition based on three-way decisions[C]// Proceedings of the 10th International Conference on Rough Sets and Knowledge Technology.Heidelberg:Springer,2015:299-308.
                                    </a>
                                </li>
                                <li id="372">


                                    <a id="bibliography_22" title=" XU J,MIAO D,ZHANG Y,et al.A three-way decisions model with probabilistic rough sets for stream computing[J].International Journal of Approximate Reasoning,2017,88:1-22." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES62AFECD5B0FF5B88459339A613EBB01C&amp;v=MjcxNTd1dDVlbmxMeHg0WDd6WitTM2FUcWhNMkRNRG1SYnZzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJxNHhLdz1OaWZPZmJXNmI2ZTUzUHRBRg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         XU J,MIAO D,ZHANG Y,et al.A three-way decisions model with probabilistic rough sets for stream computing[J].International Journal of Approximate Reasoning,2017,88:1-22.
                                    </a>
                                </li>
                                <li id="374">


                                    <a id="bibliography_23" title=" LI W,XU W H.Double-quantitative decisiontheoretic rough set[J].Information Sciences,2015,316:54-67." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15120801000203&amp;v=MjA0NzJmYks5SDlQTXA0OUVaT3NQRG53Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlWd1RiaFk9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         LI W,XU W H.Double-quantitative decisiontheoretic rough set[J].Information Sciences,2015,316:54-67.
                                    </a>
                                </li>
                                <li id="376">


                                    <a id="bibliography_24" title=" QIAN Y,ZHANG H,SANG Y,et al.Multi-granulation decisiontheoretic rough sets[J].International Journal of Approximate Reasoning,2014,55(1) :225-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900044842&amp;v=MjM2MjJNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZ3VGJoWT1OaWZPZmJLN0h0VE1wbzlGWk84TEJIZzdvQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         QIAN Y,ZHANG H,SANG Y,et al.Multi-granulation decisiontheoretic rough sets[J].International Journal of Approximate Reasoning,2014,55(1) :225-237.
                                    </a>
                                </li>
                                <li id="378">


                                    <a id="bibliography_25" title=" 苗夺谦,徐菲菲,姚一豫,等.粒计算的集合论描述[J].计算机学报,2012,35(2):351-363.(MIAO D Q,XU F F,YAO Y Y,et al.Set-theoretic formulation of granular computing[J].Chinese Journal of Computers,2012,35(2):351-363.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201202015&amp;v=MTg1Mzh2TUx6N0Jkckc0SDlQTXJZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         苗夺谦,徐菲菲,姚一豫,等.粒计算的集合论描述[J].计算机学报,2012,35(2):351-363.(MIAO D Q,XU F F,YAO Y Y,et al.Set-theoretic formulation of granular computing[J].Chinese Journal of Computers,2012,35(2):351-363.)
                                    </a>
                                </li>
                                <li id="380">


                                    <a id="bibliography_26" title=" ABUALIGAH L M,KHADER A T,AL-BETAR M A,et al.Text feature selection with a robust weight scheme and dynamic dimension reduction to text document clustering[J].Expert Systems with Applications,2017,84(C):24-36." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES367A1B1D3C9427BB902687649427E30A&amp;v=MTIyOTJXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJxNHhLdz1OaWZPZmJDK0dhRE4zWTR4WjVnR0NINCt2V1FhNmoxN1FIamtxQnN4ZTdYaFJycnVDT052RlNpVw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         ABUALIGAH L M,KHADER A T,AL-BETAR M A,et al.Text feature selection with a robust weight scheme and dynamic dimension reduction to text document clustering[J].Expert Systems with Applications,2017,84(C):24-36.
                                    </a>
                                </li>
                                <li id="382">


                                    <a id="bibliography_27" title=" HUANG D,WANG C,LAI J.Locally weighted ensemble clustering[J].IEEE Transactions on Cybernetics,2016,48(5):1460-1473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locally weighted ensemble clustering">
                                        <b>[27]</b>
                                         HUANG D,WANG C,LAI J.Locally weighted ensemble clustering[J].IEEE Transactions on Cybernetics,2016,48(5):1460-1473.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-07-31 14:06</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(11),3120-3126 DOI:10.11772/j.issn.1001-9081.2019050864            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向聚类集成的基聚类三支筛选方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E5%81%A5%E9%94%8B&amp;code=08016715&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐健锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E4%BC%9F%E5%BA%B7&amp;code=43224059&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹伟康</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A2%81%E4%BC%9F&amp;code=41567454&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梁伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E9%AB%98%E6%B4%81&amp;code=31753813&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程高洁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%BF%9C%E5%81%A5&amp;code=33484682&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张远健</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%98%8C%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0252160&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南昌大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%98%8C%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0118734&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南昌大学软件学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同济大学电子与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>当前聚类集成的研究主要是围绕着集成策略的优化展开,而针对基聚类质量的度量及优化却较少研究。基于信息熵理论提出了一种基聚类的质量度量指标,并结合三支决策思想构造了面向基聚类的三支筛选方法。首先预设基聚类筛选三支决策的阈值<i>α</i>、<i>β</i>,然后计算各基聚类中类簇质量的平均值,并把其作为各基聚类的质量度量指标,最后实施三支决策。决策策略为:当某个基聚类的质量度量指标小于阈值<i>β</i>时,删除该基聚类;当某个基聚类的质量度量指标大于等于阈值<i>α</i>时,保留该基聚类;当某个基聚类的质量度量指标大于等于<i>β</i>小于<i>α</i>时,重新计算该基聚类质量,并且再次实施上述三支决策直至没有基聚类被删除或达到指定迭代次数。对比实验结果表明,基聚类三支筛选方法能够有效提升聚类集成效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E6%94%AF%E5%86%B3%E7%AD%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三支决策;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB%E9%9B%86%E6%88%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类集成;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9F%BA%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">基聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E6%94%AF%E7%AD%9B%E9%80%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三支筛选;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *徐健锋(1973—)，男，江西南昌人，教授，博士，CCF会员，主要研究方向:粒计算、粗糙集、三支决策、深度学习、聚类集成,电子邮箱jianfeng_x@ncu.edu.cn;
                                </span>
                                <span>
                                    邹伟康(1995—)，男，江西吉安人，硕士研究生，主要研究方向:粒计算、粗糙集、三支决策、聚类集成;;
                                </span>
                                <span>
                                    梁伟(1993—)，男，江苏连云港人，硕士研究生，主要研究方向:机器学习、粒计算、粗糙集、三支决策、深度学习、聚类集成;;
                                </span>
                                <span>
                                    程高洁(1985—)，女，江西临川人，讲师，硕士，主要研究方向:粒计算、粗糙集、机器学习、聚类集成;;
                                </span>
                                <span>
                                    张远健(1990—)，男，江苏扬州人，博士研究生，CCF会员，主要研究方向:粒计算、三支决策、多标签学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-06</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61763031,61673301);</span>
                                <span>国家重点研发计划项目(213);</span>
                    </p>
            </div>
                    <h1><b>Three-way screening method of basic clustering for ensemble clustering</b></h1>
                    <h2>
                    <span>XU Jianfeng</span>
                    <span>ZOU Weikang</span>
                    <span>LIANG Wei</span>
                    <span>CHENG Gaojie</span>
                    <span>ZHANG Yuanjian</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Nanchang University</span>
                    <span>School of Software, Nanchang University</span>
                    <span>College of Electronics and Information Engineering, Tongji University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, the researches of ensemble clustering mainly focus on the optimization of ensemble strategy, while the measurement and optimization of the quality of basic clustering are rarely studied. On the basis of information entropy theory, a quality measurement index of basic clustering was proposed, and a three-way screening method for basic clustering was constructed based on three-way decision. Firstly, <i>α</i>, <i>β</i> were reset as the thresholds of three-way decision of basic clustering screening. Secondly, the average cluster quality of each basic clustering was calculated and was used as the quality measurement index of each basic clustering. Finally, the three-way decision was implemented. For one three-way screening, its decision strategy is:1) deleting the basic clustering if the quality measurement index of the basic clustering is less than the threshold <i>β</i>; 2) keeping the basic clustering if the quality measurement index of the basic clustering is greater than or equals to the threshold <i>α</i>; 3) recalculating the quality of a basic clustering and if the quality measurement index of the basic clustering is greater than <i>β</i> and less than <i>α</i> or equals to <i>β</i>. For the third option, the decision process continues until there is no deletion of basic clustering or reaching the times of iteration. The comparative experiments show that the three-way screening method of basic clustering can effectively improve the ensemble clustering effects.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-way%20decision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-way decision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ensemble%20clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ensemble clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=basic%20clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">basic clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-way%20screening&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-way screening;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    XU Jianfeng, born in 1973, Ph. D., professor. His research interests include granular computing, rough set, three-way decision, deep learning, ensemble clustering. ;
                                </span>
                                <span>
                                    ZOU Weikang, born in 1995, M. S. candidate. His research interests include granular computing, rough set, three-way decision, ensemble clustering. ;
                                </span>
                                <span>
                                    LIANG Wei, born in 1993, M. S. candidate. His research interests include machine learning, granular computing, rough set, three-way decision, deep learning, ensemble clustering. ;
                                </span>
                                <span>
                                    CHENG Gaojie, born in 1985, M. S., lecturer. Her research interests include granular computing, rough set, machine learning, ensemble clustering. ;
                                </span>
                                <span>
                                    ZHANG Yuanjian, born in 1990, Ph. D. candidate. His research interests include granular computing, three-way decision, multi-label learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-05-06</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61763031,61673301);</span>
                                <span>the National Key Research and Development Program of China(213);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="59" name="59" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="60">近年来,由于聚类效果及鲁棒性方面的优势,聚类集成算法已经逐步成为无监督机器学习的一种热点研究问题。聚类集成的主要思想是通过融合不同版本的基聚类成员来实现无监督的分类任务<citation id="384" type="reference"><link href="330" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。聚类集成的效果主要与该算法的两个主要环节紧密相关: 首先是产生高质量的基聚类成员集合,其次是设计高效的集成策略(一致性函数)。当前聚类集成技术的主要研究内容也围绕上述两个步骤展开。</p>
                </div>
                <div class="p1">
                    <p id="61">其中集成策略就是通过有效的组合策略将基聚类成员高效地组合起来。集成策略主要有超图<citation id="388" type="reference"><link href="332" rel="bibliography" /><link href="334" rel="bibliography" /><link href="336" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、信息论<citation id="385" type="reference"><link href="338" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、关联矩阵<citation id="389" type="reference"><link href="340" rel="bibliography" /><link href="342" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>、投票<citation id="386" type="reference"><link href="344" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、关联规则<citation id="387" type="reference"><link href="346" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="62">而对于基聚类成员产生,主要有如下两种方法:一是采用同一聚类方法设置不同的初始参数<citation id="390" type="reference"><link href="348" rel="bibliography" /><link href="350" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>或者不同聚类方法<citation id="391" type="reference"><link href="352" rel="bibliography" /><link href="354" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>作用于同一数据集来得到不同的基聚类成员; 二是采用同一聚类方法处理同一数据集的不同非等值变形进而得到不同的基聚类成员,变形包括对数据集进行投影<citation id="392" type="reference"><link href="356" rel="bibliography" /><link href="358" rel="bibliography" /><link href="360" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>和采样<citation id="393" type="reference"><link href="362" rel="bibliography" /><link href="364" rel="bibliography" /><link href="366" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>操作处理。这两种方法都以生成高质量的基聚类为研究目标,但是多次反复的基聚类计算过程难免会生成部分低质量基聚类,而针对基聚类质量的度量及其筛选方法的研究文献报道目前还较少。如果能够构造有效的基聚类质量度量,并且根据基聚类质量对基聚类进行优化筛选必然能够提升聚类集成的效果。鉴于基聚类质量的度量是一种典型的不确定问题,本文采用信息熵理论提出了一种基聚类质量度量方法,并且结合三支决策思想<citation id="394" type="reference"><link href="368" rel="bibliography" /><link href="370" rel="bibliography" /><link href="372" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>构造了基聚类三支筛选优化模型。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag">1 相关技术</h3>
                <h4 class="anchor-tag" id="64" name="64">1.1 <b>三支决策基本理论</b></h4>
                <div class="p1">
                    <p id="65">三支决策是来源于粗糙集理论<citation id="396" type="reference"><link href="374" rel="bibliography" /><link href="376" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>的一种重要的粒计算方法<citation id="395" type="reference"><link href="378" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。相较于传统的二支决策(正/负决策)而言,三支决策增加了延迟决策作为不能准确作出正负决策时的决策行为,三支决策也合理地解释了粗糙集理论中的三个决策域(正域、负域和边界域)划分行为。</p>
                </div>
                <div class="p1">
                    <p id="66">三支决策基本思想是通过评价函数<i>λ</i>对某个数据对象集合<i>D</i>中的元素<i>x</i>∈<i>D</i>进行不确定程度的划分:</p>
                </div>
                <div class="p1">
                    <p id="67">当<i>λ</i>(<i>x</i>)≥<i>α</i>时,元素<i>x</i>被划分到集合<i>D</i>的正决策域<i>POS</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>x</i>);</p>
                </div>
                <div class="p1">
                    <p id="68">当<i>λ</i>(<i>x</i>)&lt;<i>β</i>时,元素<i>x</i>被划分到集合<i>D</i>的负决策域<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>x</i>);</p>
                </div>
                <div class="p1">
                    <p id="69">当<i>β</i>≤<i>λ</i>(<i>x</i>)&lt;<i>α</i>时,元素<i>x</i>被划分到集合<i>D</i>的延迟决策域<i>BND</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>x</i>)。</p>
                </div>
                <div class="p1">
                    <p id="70">其中(<i>α</i>, <i>β</i>)为三支决策阈值,通常设定为 0≤<i>β</i>&lt;<i>α</i>≤1。</p>
                </div>
                <div class="p1">
                    <p id="71">基于三支决策,全域<i>D</i>可以被划分为3个不相交的区域:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mi>Ο</mi><mi>S</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>α</mi><mo>,</mo><mspace width="0.25em" /><mi>β</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mrow><mrow><mi>x</mi><mo>∈</mo><mi>D</mi></mrow><mo>|</mo></mrow><mi>λ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≥</mo><mi>α</mi><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><mi>B</mi><mi>Ν</mi><mi>D</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>α</mi><mo>,</mo><mspace width="0.25em" /><mi>β</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><mo>∈</mo><mi>D</mi><mo stretchy="false">|</mo><mi>β</mi><mo>≤</mo><mi>λ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>α</mi><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><mi>Ν</mi><mi>E</mi><mi>G</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>α</mi><mo>,</mo><mspace width="0.25em" /><mi>β</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><mo>∈</mo><mi>D</mi><mo stretchy="false">|</mo><mi>λ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>β</mi><mo stretchy="false">}</mo></mtd></mtr></mtable></mrow></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">1.2 <b>聚类集成</b></h4>
                <div class="p1">
                    <p id="74">聚类集成的算法流程主要由基聚类的生成和基聚类的集成两个主要步骤构成。其中,生成<i>M</i>个基聚类就是对数据集<i>D</i>执行<i>M</i>次聚类,<i>M</i>次聚类的结果构成的基聚类集合可记作<i>Π</i>={<i>C</i><sup>1</sup>,<i>C</i><sup>2</sup>,…,<i>C</i><sup><i>M</i></sup>},其中<i>C</i><sup><i>i</i></sup>∈<i>Π</i>表示<i>Π</i>中第<i>i</i>个基聚类。<i>Π</i>的基数<mathml id="214"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>Π</mi><mo>|</mo></mrow><mo>=</mo><mi>Μ</mi></mrow></math></mathml>为基聚类成员数量,|*|表示集合的基数。<i>Π</i>中任意基聚类成员<i>C</i><sup><i>i</i></sup>∈<i>Π</i>都由若干个簇构成,记作<i>C</i><sup><i>i</i></sup>={<i>c</i><mathml id="215"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>i</mi></msubsup></mrow></math></mathml>,<i>c</i><mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>i</mi></msubsup></mrow></math></mathml>,…,<i>c</i><mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>i</mi></msubsup></mrow></math></mathml>},其中任一<i>c</i><mathml id="218"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>i</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>i</i></sup>表示基聚类<i>C</i><sup><i>i</i></sup>中的第<i>j</i>个类簇,<i>C</i><sup><i>i</i></sup>的基数<mathml id="219"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>C</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>|</mo></mrow><mo>=</mo><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>表示<i>C</i><sup><i>i</i></sup>由<i>N</i><sub><i>i</i></sub>个类簇构成。<i>Π</i>中的任意基聚类<i>C</i><sup><i>i</i></sup>∈<i>Π</i>,<i>C</i><sup><i>j</i></sup>∈<i>Π</i>,<i>i</i>≠<i>j</i>,则<i>C</i><sup><i>i</i></sup>与<i>C</i><sup><i>j</i></sup>的基数可以根据算法设计要求设定为相同或者不同,即<i>N</i><sub><i>i</i></sub>=<i>N</i><sub><i>j</i></sub>或者<i>N</i><sub><i>i</i></sub>≠<i>N</i><sub><i>j</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="75">基聚类集成则是使用合适的集成方法对基聚类集合<i>Π</i>进行聚合。其聚合过程可以表示为<i>C</i>′=<i>f</i>(<i>Π</i>),其中一致性函数<i>f</i>为集成方法,<i>C</i>′为最终聚类结果。对于集成方法<i>f</i>,常用的有层次聚类法、投票法、信息论方法和图划分法等方法。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">2 基聚类三支筛选</h3>
                <div class="p1">
                    <p id="77">基聚类是聚类集成的基础,基聚类集合的每个成员<i>C</i><sup><i>i</i></sup>∈<i>Π</i>的质量对聚类集成结果都有较大的影响。为了降低低质量基聚类成员对聚类集成的影响,本章提出了一种基聚类成员质量评价方法,并且采用三支决策的思想构造一种基聚类成员择优筛选的算法。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.1 <b>基于信息熵的类簇不确定性度量</b></h4>
                <div class="p1">
                    <p id="79">在信息理论<citation id="397" type="reference"><link href="338" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>中,信息熵是对随机变量相关不确定性的度量。在聚类集成中给定任一类簇<i>c</i><mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>,其中<i>C</i><sup><i>n</i></sup>∈<i>Π</i>,则<i>c</i><mathml id="221"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>中的数据对象有可能在另一个基聚类<i>C</i><sup><i>m</i></sup>∈<i>Π</i>中被划分在<i>C</i><sup><i>m</i></sup>多个簇中。显然,<i>c</i><mathml id="222"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>中的数据对象最多可以属于<i>C</i><sup><i>m</i></sup>中的所有<i>N</i><sub><i>m</i></sub>个不同的簇,其中<mathml id="223"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>m</mi></msub><mo>=</mo><mrow><mo>|</mo><mrow><mi>C</mi><msup><mrow></mrow><mi>m</mi></msup></mrow><mo>|</mo></mrow></mrow></math></mathml>。基于以上情况,基于信息熵的类簇不确定性度量定义如下。</p>
                </div>
                <div class="p1">
                    <p id="80"><b>定义</b>1 在基聚类<i>Π</i>中,对任意<i>c</i><mathml id="224"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>,<i>c</i><mathml id="225"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>m</i></sup>,其中<i>C</i><sup><i>n</i></sup>∈<i>Π</i>,<i>C</i><sup><i>m</i></sup>∈<i>Π</i>且<i>c</i><mathml id="226"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∩<i>c</i><mathml id="227"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>≠∅,则<i>c</i><mathml id="228"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相对于<i>c</i><mathml id="229"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>的不确定度量为:</p>
                </div>
                <div class="p1">
                    <p id="81"><i>H</i>(<i>c</i><mathml id="230"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>,<i>c</i><mathml id="231"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>)=-<i>p</i>(<i>c</i><mathml id="232"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>,<i>c</i><mathml id="233"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>)ln <i>p</i>(<i>c</i><mathml id="234"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>,<i>c</i><mathml id="235"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="82">其中<mathml id="236"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo>,</mo><mi>c</mi><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mstyle displaystyle="true"><mo>∩</mo><mi>c</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="83">一组随机变量的不确定性通常使用变量的联合信息熵<citation id="398" type="reference"><link href="338" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>来度量。由于对于<i>Π</i>任一基聚类<i>C</i><sup><i>n</i></sup>={ <i>c</i><mathml id="237"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup></mrow></math></mathml>,<i>c</i><mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>n</mi></msubsup></mrow></math></mathml>,…, <i>c</i><mathml id="239"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mi>n</mi></msubsup></mrow></math></mathml>} 中的<i>N</i><sub><i>n</i></sub>个类簇相互独立,因此根据定义1,<i>C</i><sup><i>n</i></sup>中任意一个类簇<i>c</i><mathml id="240"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>相对于另一个基聚类<i>C</i><sup><i>m</i></sup>∈<i>Π</i>的不确定性可计为<i>c</i><mathml id="241"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>中元素出现在<i>C</i><sup><i>m</i></sup>中各个类簇样本的概率总和。因此,类簇<i>c</i><mathml id="242"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相较于基聚类<i>C</i><sup><i>m</i></sup>的不确定性可定义为:</p>
                </div>
                <div class="p1">
                    <p id="84"><b>定义</b>2 给定基聚类集合<i>Π</i>,类簇<i>c</i><mathml id="243"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相对基聚类<i>C</i><sup><i>m</i></sup>的不确定性度量为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msup><mrow></mrow><mi>m</mi></msup><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>m</mi></msub></mrow></munderover><mi>p</mi></mstyle><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo>,</mo><mi>c</mi><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo><mrow><mi>ln</mi></mrow><mspace width="0.25em" /><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo>,</mo><mi>c</mi><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中:<i>N</i><sub><i>m</i></sub>是<i>C</i><sup><i>m</i></sup>中的类簇数,<i>c</i><mathml id="244"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>是<i>C</i><sup><i>m</i></sup>中第<i>j</i>个类簇。</p>
                </div>
                <div class="p1">
                    <p id="87">定义2给出了每个类簇相对任一基聚类的不确定度量形式。对于∀<i>i</i>, <i>j</i>,<i>m</i>,<i>p</i>(<i>c</i><sub><i>i</i></sub>,<i>c</i><mathml id="245"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>m</mi></msubsup></mrow></math></mathml>)∈[0,1],得到<i>H</i><sup><i>m</i></sup>(<i>c</i><sub><i>i</i></sub>)∈[0,+∞)。当<i>c</i><sub><i>i</i></sub>中的所有数据对象属于<i>c</i><sup><i>m</i></sup>的同一簇时,<i>c</i><sub><i>i</i></sub>相对<i>C</i><sup><i>m</i></sup>的不确定性达到其最小值(<i>H</i><sup><i>m</i></sup>(<i>c</i><sub><i>i</i></sub>)=0)。当<i>c</i><sup><i>m</i></sup>的所有簇与<i>c</i><sub><i>i</i></sub>的交集均不为空集时,<i>c</i><sub><i>i</i></sub>相对<i>C</i><sup><i>m</i></sup>的不确定性将达到最大值。</p>
                </div>
                <div class="p1">
                    <p id="88">假定基聚类间相互独立,<i>c</i><mathml id="246"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>相对<i>Π</i>的不确定性可以被表示<i>c</i><mathml id="247"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相对<i>Π</i>中所有<mathml id="248"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>Π</mi><mo>|</mo></mrow></mrow></math></mathml>个基聚类的不确定性之和。因此,类簇<i>c</i><sub><i>i</i></sub>相较基聚类集合<i>Π</i>的不确定性定义为:</p>
                </div>
                <div class="p1">
                    <p id="89"><b>定义</b>3 给定基聚类集合<i>Π</i>={<i>C</i><sup>1</sup>,<i>C</i><sup>2</sup>,…,<i>C</i><sup><i>M</i></sup>},任一基聚类<i>C</i><sup><i>n</i></sup>∈<i>Π</i>的某一类簇<i>c</i><mathml id="249"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>相对<i>Π</i>的不确定性程度计算如下:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mi>Π</mi></msub><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>Η</mi></mstyle><msup><mrow></mrow><mi>m</mi></msup><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">其中<i>M</i>是集合<i>Π</i>中基聚类的基数。</p>
                </div>
                <div class="p1">
                    <p id="92">任一类簇<i>c</i><mathml id="250"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>∈<i>C</i><sup><i>n</i></sup>相对集合<i>Π</i>的不确定性能够反映出聚类集成结果<i>C</i>′中出现类簇<i>c</i><mathml id="251"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>可能性。如果每个基聚类中都存在与<i>c</i><mathml id="252"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相同的类簇,则可以认为<i>c</i><mathml id="253"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>一定出现<i>C</i>′中,那么<i>c</i><mathml id="254"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>相对<i>Π</i>的不确定性达到其最小值,即<i>H</i><sub><i>Π</i></sub>(<i>c</i><sub><i>i</i></sub>)=0。另外,<i>c</i><mathml id="255"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>出现在<i>C</i>′的概率随<i>c</i><sub><i>i</i></sub>相对<i>Π</i>的不确定性增大而递减。</p>
                </div>
                <div class="p1">
                    <p id="93">为更好地理解不确定性的求解过程,下面给出了一个实例。其中,3个基聚类组成的集合<i>Π</i>={<i>C</i><sup>1</sup>,<i>C</i><sup>2</sup>,<i>C</i><sup>3</sup>}。<i>C</i><sup>1</sup>包含3个类簇{<i>c</i><mathml id="256"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="257"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="258"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>},<i>C</i><sup>2</sup>包含4个类簇{<i>c</i><mathml id="259"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="260"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="261"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="262"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>2</mn></msubsup></mrow></math></mathml>},<i>C</i><sup>3</sup>包含4个类簇{<i>c</i><mathml id="263"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>3</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="264"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>3</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="265"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>3</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="266"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>3</mn></msubsup></mrow></math></mathml>}。每个类簇包含的数据对象见表1。</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表</b>1 <b>集合</b><i>Π</i><b>中类簇和数据对象分布</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Cluster and object distribution in set <i>Π</i></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td><br />基聚类</td><td>类簇</td><td>数据对象</td></tr><tr><td rowspan="3"><br /><i>C</i><sup>1</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></td><td><i>d</i><sub>1</sub>,<i>d</i><sub>3</sub>,<i>d</i><sub>9</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></td><td><i>d</i><sub>2</sub>,<i>d</i><sub>5</sub>,<i>d</i><sub>6</sub>,<i>d</i><sub>10</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></td><td><i>d</i><sub>4</sub>,<i>d</i><sub>7</sub>,<i>d</i><sub>8</sub></td></tr><tr><td rowspan="4"><br /><i>C</i><sup>2</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></td><td><i>d</i><sub>1</sub>,<i>d</i><sub>4</sub>,<i>d</i><sub>7</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></td><td><i>d</i><sub>3</sub>,<i>d</i><sub>8</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></td><td><i>d</i><sub>2</sub>,<i>d</i><sub>5</sub>,<i>d</i><sub>9</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>2</mn></msubsup></mrow></math></td><td><i>d</i><sub>6</sub>,<i>d</i><sub>10</sub></td></tr><tr><td rowspan="4"><br /><i>C</i><sup>3</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>3</mn></msubsup></mrow></math></td><td><i>d</i><sub>1</sub>,<i>d</i><sub>3</sub>,<i>d</i><sub>7</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>3</mn></msubsup></mrow></math></td><td><i>d</i><sub>2</sub>,<i>d</i><sub>8</sub>,<i>d</i><sub>10</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>3</mn></msubsup></mrow></math></td><td><i>d</i><sub>4</sub>,<i>d</i><sub>6</sub></td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>3</mn></msubsup></mrow></math></td><td><i>d</i><sub>5</sub>,<i>d</i><sub>9</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="95">如表1所示,类簇<i>c</i><mathml id="267"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>包含3个数据对象,<i>c</i><mathml id="268"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>包含4个数据对象,<i>c</i><mathml id="269"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>包含3个数据对象。若要计算<i>C</i><sup>1</sup>中3个类簇相对集合<i>Π</i>的不确定性。则按照以下步骤:</p>
                </div>
                <div class="p1">
                    <p id="96">根据定义1计算类簇<i>c</i><sub><i>i</i></sub>相对集合<i>Π</i>中排除自身以外所有类簇的不确定性。以类簇<i>c</i><mathml id="270"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>为例,即为计算<i>c</i><mathml id="271"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>与集合<i>Π</i>中除其自身以外的10个类簇间的不确定性,即 <i>H</i>(<i>c</i><mathml id="272"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="273"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></mathml>)=-<i>p</i>(<i>c</i><sup>1</sup><sub>3</sub>,<i>c</i><sup>2</sup><sub>1</sub>)ln <i>p</i>(<i>c</i><sup>1</sup><sub>3</sub>,<i>c</i><sup>2</sup><sub>1</sub>)=-(2/3)×ln (2/3)≈0.270 3,同理可得<i>H</i>(<i>c</i><mathml id="274"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="275"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>)≈0.366 2,<i>H</i>(<i>c</i><mathml id="276"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="277"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>3</mn></msubsup></mrow></math></mathml>)≈0.366 2,<i>H</i>(<i>c</i><mathml id="278"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="279"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>3</mn></msubsup></mrow></math></mathml>)≈0.366 2,<i>H</i>(<i>c</i><mathml id="280"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="281"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>3</mn></msubsup></mrow></math></mathml>)≈0.366 2。另外,由于<i>c</i><mathml id="282"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>与<i>c</i><mathml id="283"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></mathml>交集为空,故<i>H</i>(<i>c</i><mathml id="284"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="285"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></mathml>)=0,同理可得<i>H</i>(<i>c</i><mathml id="286"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="287"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>2</mn></msubsup></mrow></math></mathml>)=0,<i>H</i>(<i>c</i><mathml id="288"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="289"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>3</mn></msubsup></mrow></math></mathml>)=0, <i>H</i>(<i>c</i><mathml id="290"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="291"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>)=0,<i>H</i>(<i>c</i><mathml id="292"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></mathml>,<i>c</i><mathml id="293"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>)=0。</p>
                </div>
                <div class="p1">
                    <p id="97">根据定义2计算计算类簇<i>c</i><sub><i>i</i></sub>相对集合<i>Π</i>中基聚类<i>C</i><sup><i>m</i></sup>的不确定性。根据定义3计算类簇<i>c</i><sub><i>i</i></sub>相对集合<i>Π</i>的不确定性, 得到所有类簇相对整个集合的不确定性,结果见表2。</p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表</b>2 <b>类簇不确定性计算</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Uncertainty computation of clusters</p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td><br />基聚类</td><td>类簇</td><td>类簇相对整个集合的不确定性</td></tr><tr><td rowspan="3"><br /><i>C</i><sup>1</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math>)=1.735 1</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math>)=1.732 7</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>1</mn></msubsup></mrow></math>)=1.735 1</td></tr><tr><td rowspan="4"><br /><i>C</i><sup>2</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math>)=1.273 1</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math>)=1.386 2</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math>)=1.273 1</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>2</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>2</mn></msubsup></mrow></math>)=0.693 1</td></tr><tr><td rowspan="4"><br /><i>C</i><sup>3</sup></td><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>3</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>3</mn></msubsup></mrow></math>)=1.273 1</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>3</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>3</mn></msubsup></mrow></math>)=1.735 1</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>3</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>3</mn></msubsup></mrow></math>)=1.386 2</td></tr><tr><td><br /><i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>3</mn></msubsup></mrow></math></td><td><i>H</i><sub><i>Π</i></sub>(<i>c</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>3</mn></msubsup></mrow></math>)=0.693 1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="99">至此,聚类集合<i>Π</i>中任一类簇<i>c</i><sub><i>i</i></sub>∈<i>Π</i>都可以给出对于<i>Π</i>的不确定性, 但由于各个基聚类的类簇个数不同,基聚类质量很难使用联合信息熵衡量。为此,一种用基聚类类簇平均熵来表示基聚类不确定性的方法被提出。</p>
                </div>
                <div class="p1">
                    <p id="100"><b>定义</b>4 对于集合<i>Π</i>中的基聚类<i>C</i><sup><i>m</i></sup>,约定衡量其不确定性指标为基聚类类簇平均熵<i>H</i><sub><i>μ</i></sub>(<i>C</i><sup><i>m</i></sup>)。<i>H</i><sub><i>μ</i></sub>(<i>C</i><sup><i>m</i></sup>)表示基聚类<i>C</i><sup><i>m</i></sup>中类簇对基聚类<i>C</i><sup><i>m</i></sup>的不确定性贡献程度,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mi>μ</mi></msub><mo stretchy="false">(</mo><mi>C</mi><msup><mrow></mrow><mi>m</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msup><mrow></mrow><mi>m</mi></msup></mrow></munderover><mi>Η</mi></mstyle><msub><mrow></mrow><mi>Π</mi></msub><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup><mo stretchy="false">)</mo><mo>/</mo><mi>n</mi><msup><mrow></mrow><mi>m</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">其中: 类簇<i>c</i><mathml id="294"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup></mrow></math></mathml>表示基聚类<i>C</i><sup><i>m</i></sup>中的第<i>i</i>个类簇,<i>n</i><sup><i>m</i></sup>为基聚类<i>C</i><sup><i>m</i></sup>中的类簇个数,<i>H</i><sub><i>Π</i></sub>(<i>c</i><mathml id="295"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup></mrow></math></mathml>)表示基聚类<i>C</i><sup><i>m</i></sup>中类簇<i>c</i><mathml id="296"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup></mrow></math></mathml>的熵值。</p>
                </div>
                <div class="p1">
                    <p id="103">因此,基聚类不确定性可以通过定义4中的类簇平均熵衡量。类簇平均熵越大,基聚类的不确定性越强,即基聚类的质量越差; 相反,类簇平均熵越小,基聚类的不确定性越弱,即基聚类的质量越好,故类簇平均熵可以作为衡量基聚类质量的度量指标。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">2.2 <b>面向基聚类的三支筛选方法</b></h4>
                <div class="p1">
                    <p id="105">三支决策思想解决不确定问题的过程符合人类正常决策方式思维模式。因此,基于三支决策理论和定义4,用于三支决策的基聚类质量评价函数<i>λ</i>(<i>C</i><sup><i>m</i></sup>)被构建,定义为:</p>
                </div>
                <div class="p1">
                    <p id="106"><b>定义</b>5 对于任一基聚类<i>C</i><sup><i>m</i></sup>∈<i>Π</i>,其基聚类筛选三支决策的评价函数为<i>λ</i>(<i>C</i><sup><i>m</i></sup>)=e<sup>-</sup><sup><i>H</i></sup><sub><sup><i>μ</i></sup></sub><sup>(</sup><sup><i>Cm</i></sup><sup>)</sup>,其中,<i>H</i><sub><i>μ</i></sub>(<i>C</i><sup><i>m</i></sup>)为聚类<i>C</i><sup><i>m</i></sup>的类簇平均熵。</p>
                </div>
                <div class="p1">
                    <p id="107">评价函数<i>λ</i>(<i>C</i><sup><i>m</i></sup>)∈(0,1]是类簇平均熵<i>H</i><sub><i>μ</i></sub>(<i>c</i><mathml id="297"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup></mrow></math></mathml>)∈[0,+∞)的归一化形式,通过归一函数使得基聚类质量的度量指标符合三支决策域阈值<i>α</i>、 <i>β</i>的判断范围,便于三支决策。</p>
                </div>
                <div class="p1">
                    <p id="108">对2.1节中实例使用定义5中评价函数<i>λ</i>(<i>C</i><sup><i>m</i></sup>)进行三支决策。其中计算方法为:</p>
                </div>
                <div class="p1">
                    <p id="109">首先根据定义4,<i>C</i><sup>1</sup>的类簇平均熵可计算为:<mathml id="298"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mi>μ</mi></msub><mo stretchy="false">(</mo><mi>C</mi><msup><mrow></mrow><mn>1</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>3</mn></munderover><mi>Η</mi></mstyle><msub><mrow></mrow><mi>Π</mi></msub><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mn>1</mn></msubsup><mo stretchy="false">)</mo><mo>/</mo><mn>3</mn><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>.</mo><mn>7</mn><mn>3</mn><mn>5</mn><mtext> </mtext><mn>1</mn><mo>+</mo><mn>1</mn><mo>.</mo><mn>7</mn><mn>3</mn><mn>2</mn><mtext> </mtext><mn>7</mn><mo>+</mo><mn>1</mn><mo>.</mo><mn>7</mn><mn>3</mn><mn>5</mn><mtext> </mtext><mn>1</mn><mo stretchy="false">)</mo><mo>/</mo><mn>3</mn><mo>=</mo><mn>1</mn><mo>.</mo><mn>7</mn><mn>3</mn><mn>4</mn><mtext> </mtext><mn>1</mn></mrow></math></mathml>。同理可得,<i>H</i><sub><i>μ</i></sub>(<i>C</i><sup>2</sup>)=1.156 3,<i>H</i><sub><i>μ</i></sub>(<i>C</i><sup>3</sup>)=1.271 9。</p>
                </div>
                <div class="p1">
                    <p id="110">其次根据定义5可得,<i>C</i><sup>1</sup>、<i>C</i><sup>2</sup>、<i>C</i><sup>3</sup>的聚类质量的三支决策评价函数如表3所示。</p>
                </div>
                <div class="area_img" id="111">
                    <p class="img_tit"><b>表</b>3 <b>基聚类质量评价指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Quality evaluation index of basic clustering</p>
                    <p class="img_note"></p>
                    <table id="111" border="1"><tr><td><br />基聚类</td><td>基聚类质量</td></tr><tr><td><br /><i>C</i><sup>1</sup></td><td><i>λ</i>(<i>C</i><sup>1</sup>)=0.176 6</td></tr><tr><td><br /><i>C</i><sup>2</sup></td><td><i>λ</i>(<i>C</i><sup>2</sup>)=0.314 6</td></tr><tr><td><br /><i>C</i><sup>3</sup></td><td><i>λ</i>(<i>C</i><sup>3</sup>)=0.280 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="112">由定义4可得,<i>H</i><sub><i>μ</i></sub>(<i>c</i><mathml id="299"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>m</mi></msubsup></mrow></math></mathml>)∈[0,+∞),因此用于三支决策的评价函数<i>λ</i>(<i>C</i><sup><i>m</i></sup>)∈(0,1]。显然,当基聚类<i>C</i><sup><i>m</i></sup>的不确定性较小时,<i>λ</i>(<i>C</i><sup><i>m</i></sup>)值更大。当基聚类<i>C</i><sup><i>m</i></sup>的不确定度达到最小值,即<i>H</i>(<i>C</i><sup><i>m</i></sup>)=0时,其<i>λ</i>(<i>C</i><sup><i>m</i></sup>)将达到最大值,即<i>λ</i>(<i>C</i><sup><i>m</i></sup>)=1。当基聚类不确定性接近无穷大时,基聚类的<i>λ</i>(<i>C</i><sup><i>m</i></sup>)接近0。</p>
                </div>
                <div class="p1">
                    <p id="113">基于上述基聚类以及三支决策思想,构造如下基聚类三支筛选方法:</p>
                </div>
                <div class="p1">
                    <p id="114">首先设定基聚类质量筛选阈值为(<i>α</i>, <i>β</i>),并且0≤<i>β</i>&lt;<i>α</i>≤1,对任一基聚类<i>C</i><sup><i>m</i></sup>∈<i>Π</i>,根据三支评价函数为<i>λ</i>(<i>C</i><sup><i>m</i></sup>)进行如下三支划分。</p>
                </div>
                <div class="p1">
                    <p id="115">1)若<i>α</i>≤<i>λ</i>(<i>C</i><sup><i>m</i></sup>),则将基聚类<i>C</i><sup><i>m</i></sup>划分到正域区间(优质域),记为<i>C</i><sup><i>m</i></sup>∈<i>POS</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>);</p>
                </div>
                <div class="p1">
                    <p id="116">2)若<i>λ</i>(<i>C</i><sup><i>m</i></sup>)&lt;<i>β</i>,则将基聚类<i>C</i><sup><i>m</i></sup>划分到负域区间(劣质域),记为<i>C</i><sup><i>m</i></sup>∈<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>);</p>
                </div>
                <div class="p1">
                    <p id="117">3)若<i>β</i>≤(<i>C</i><sup><i>m</i></sup>)&lt;<i>α</i>,则将基聚类<i>C</i><sup><i>m</i></sup>划分到延迟域区间(不确定域),记为<i>C</i><sup><i>m</i></sup>∈<i>BND</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)。</p>
                </div>
                <div class="p1">
                    <p id="118">经过上述三支划分后可以确定:<i>POS</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)集合中的基聚类为高质量聚类集合;<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)集合中的基聚类为低质量聚类集合;<i>BND</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)集合中的基聚类的聚类质量无法确定,需要进一步判断决策。</p>
                </div>
                <div class="p1">
                    <p id="119">因此本文将保留<i>POS</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)域中的优质基聚类,删除<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)域中的劣质基聚类,同时更新<i>Π</i>=<i>Π</i>-<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)。而对<i>BND</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)域中的基聚类元素,即所有更新后的<i>Π</i>=<i>Π</i>-<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)重新计算基聚类质量,并再次三支决策。</p>
                </div>
                <div class="p1">
                    <p id="120">通过上述三支分类步骤的多次迭代直至|<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)|=0(<i>NEG</i><sub>(</sub><sub><i>α</i></sub><sub>, </sub><sub><i>β</i></sub><sub>)</sub>(<i>Π</i>)中无元素)或达到指定迭代次数,则此时获得的<i>Π</i>为最优基聚类集合。</p>
                </div>
                <div class="p1">
                    <p id="121">基于上述面向基聚类的三支决策筛选思想可获得如下算法。</p>
                </div>
                <div class="area_img" id="329">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911004_32900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="165" name="165" class="anchor-tag">3 实验结果</h3>
                <div class="p1">
                    <p id="166">本章将使用8组数据集对所提算法进行实验,并通过2种不同的聚类算法评估指标对聚类集成进行评估。本章所有实验在python3.6环境下进行,其中工作站环境为Ubuntu18.04lts,Intel i7-7820X,32 GB内存,IDE环境为pyCharm professional 2017.11。</p>
                </div>
                <h4 class="anchor-tag" id="167" name="167">3.1 <b>基数据集和评价方法</b></h4>
                <h4 class="anchor-tag" id="168" name="168">3.1.1 数据集与实验准备</h4>
                <div class="p1">
                    <p id="169">实验通过选取来自UCI machine learning repositor(http://archive.ics.uci.edu/ml)的8个真实数据集,分别是图像分割(Image Segmentation, IS)、字母识别(Letter Recognition, LR)、地球资源卫星(Landsat Satellite, LS)、笔迹(Pen Digit, PD)、手写数字识别(Multiple Features, MF)、光学数字识别(Optical Digit Recognition, ODR)、钢板故障(Steel Plates Faults, SPF)、纹理(Texture)。上述数据集的详细描述如表4所示。</p>
                </div>
                <div class="area_img" id="170">
                    <p class="img_tit"><b>表</b>4 <b>数据集描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Details of datasets</p>
                    <p class="img_note"></p>
                    <table id="170" border="1"><tr><td><br />数据集</td><td>#Object</td><td>#Attribute</td><td>#Class</td></tr><tr><td><br />IS</td><td>2 310</td><td>19</td><td>7</td></tr><tr><td><br />LR</td><td>20 000</td><td>16</td><td>26</td></tr><tr><td><br />LS</td><td>6 435</td><td>36</td><td>6</td></tr><tr><td><br />PD</td><td>10 992</td><td>16</td><td>10</td></tr><tr><td><br />MF</td><td>2 000</td><td>649</td><td>10</td></tr><tr><td><br />ODR</td><td>5 620</td><td>64</td><td>10</td></tr><tr><td><br />SPF</td><td>1 941</td><td>27</td><td>7</td></tr><tr><td><br />Texture</td><td>5 500</td><td>40</td><td>11</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="171" name="171">3.1.2 评价标准</h4>
                <div class="p1">
                    <p id="172">为了合理评估不同算法的效果,本实验采用F检验(F-measure)<citation id="399" type="reference"><link href="380" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>和标准化互信息(Normalized Mutual Information, NMI)<citation id="400" type="reference"><link href="350" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>两个指标来对聚类结果进行评估。</p>
                </div>
                <h4 class="anchor-tag" id="173" name="173">1)F检验。</h4>
                <div class="p1">
                    <p id="174">F-measure是一种准确度评估指标。基于数据集的标准聚类<i>C</i><sup><i>g</i></sup>中各类簇标签来计算某个被测试聚类<i>C</i>′的准确度<i>P</i>以及召回率<i>R</i>,并以此来进一步算出F-检验值。</p>
                </div>
                <div class="p1">
                    <p id="175">测试聚类<i>C</i>′中类簇<i>c</i><sub><i>j</i></sub>′相对标准聚类<i>C</i><sup><i>g</i></sup>中类簇<i>c</i><mathml id="300"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup></mrow></math></mathml>的准确率<i>P</i>和召回率<i>R</i>计算为:</p>
                </div>
                <div class="p1">
                    <p id="176" class="code-formula">
                        <mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup><mstyle displaystyle="true"><mo>∩</mo><mi>c</mi></mstyle><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">|</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>R</mi><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup><mstyle displaystyle="true"><mo>∩</mo><mi>c</mi></mstyle><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup><mo stretchy="false">|</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="177">其中:<i>c</i><mathml id="301"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup></mrow></math></mathml>为标准聚类<i>C</i><sup><i>g</i></sup>中拥有第<i>i</i>类标签的类簇;<i>c</i><sub><i>j</i></sub>′为聚类<i>C</i>′中的第<i>j</i>个类簇。</p>
                </div>
                <div class="p1">
                    <p id="178">类簇<i>c</i><sub><i>j</i></sub>′中匹配标准类簇<i>c</i><mathml id="302"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>g</mi></msubsup></mrow></math></mathml>的元素的百分比计算为:</p>
                </div>
                <div class="p1">
                    <p id="179" class="code-formula">
                        <mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mi>Μ</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo><mo>×</mo><mi>R</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo><mo>+</mo><mi>R</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="180">聚类结果<i>C</i>′相对标准聚类<i>C</i><sup><i>g</i></sup>准确度计算为:</p>
                </div>
                <div class="p1">
                    <p id="181" class="code-formula">
                        <mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mi>Μ</mi><mo stretchy="false">(</mo><msup><mi>C</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>F</mi></mstyle><mi>Μ</mi><mo stretchy="false">(</mo><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub><mo stretchy="false">)</mo></mrow><mi>k</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="182">其中<i>k</i>为<i>C</i>′的类簇数量<mathml id="303"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><msup><mi>C</mi><mo>′</mo></msup><mo>|</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="183" name="183">2)标准化互信息。</h4>
                <div class="p1">
                    <p id="184">NMI检验提供了一组随机变量间的信息互通指数(关联程度),可以通过NMI 进行常规的聚类评价。假设某基数为<i>τ</i>的数据集,若<i>C</i><sup><i>g</i></sup>为该数据集标准聚类,<i>C</i>′为待分析的某个聚类,那么<i>C</i>′相当于<i>C</i><sup><i>g</i></sup>的NMI指标得分公式为:</p>
                </div>
                <div class="p1">
                    <p id="185" class="code-formula">
                        <mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>Μ</mi><mi>Ι</mi><mo stretchy="false">(</mo><msup><mi>C</mi><mo>′</mo></msup><mo>,</mo><mi>C</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>μ</mi><mo>′</mo></msup></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>μ</mi><msup><mrow></mrow><mi>g</mi></msup></mrow></munderover><mi>υ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mspace width="0.25em" /><mi>log</mi><mspace width="0.25em" /><mfrac><mrow><mi>υ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>τ</mi></mrow><mrow><mi>ω</mi><msub><mrow></mrow><mi>i</mi></msub><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>μ</mi><mo>′</mo></msup></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mi>log</mi><mspace width="0.25em" /><mfrac><mrow><mi>ω</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>μ</mi><msup><mrow></mrow><mi>g</mi></msup></mrow></munderover><mi>θ</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mspace width="0.25em" /><mi>log</mi><mspace width="0.25em" /><mfrac><mrow><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mi>τ</mi></mfrac></mrow></msqrt></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="186">其中:<i>μ</i>′为基聚类<i>C</i>′中的类簇数量<mathml id="304"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><msup><mi>C</mi><mo>′</mo></msup><mo>|</mo></mrow><mo>,</mo><mi>μ</mi><msup><mrow></mrow><mi>g</mi></msup></mrow></math></mathml>为真实聚类<i>C</i><sup><i>g</i></sup>中的类簇数量<mathml id="305"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>C</mi><msup><mrow></mrow><mi>g</mi></msup></mrow><mo>|</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="187"><i>ω</i><sub><i>i</i></sub>为元素出现在聚类<i>C</i>′中第<i>i</i>个类簇中元素的基数<mathml id="306"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>c</mi><msub><mrow></mrow><msup><mi>i</mi><mo>′</mo></msup></msub></mrow><mo>|</mo></mrow><mo>,</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>为标准聚类<i>C</i><sup><i>g</i></sup>中第<i>j</i>个类簇中元素的基数<mathml id="307"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>c</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="188">另外,<i>υ</i><sub><i>ij</i></sub>为基聚类<i>C</i>′中第<i>i</i>个类簇和标准聚类<i>C</i><sup><i>g</i></sup>中第<i>j</i>个类簇中的公共元素个数<mathml id="308"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>c</mi><msub><mrow></mrow><msup><mi>i</mi><mo>′</mo></msup></msub><mstyle displaystyle="true"><mo>∩</mo><mi>c</mi></mstyle><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="189">上述F-检验与NMI指标的取值范围均为[0,1],且当取值越接近1聚类算法性能越好。</p>
                </div>
                <h4 class="anchor-tag" id="190" name="190">3.2 <b>对比实验分析</b></h4>
                <div class="p1">
                    <p id="191">本文拟从不同角度设计对比实验,分析不同算法在数据集上的表现。选取<i>k</i>均值(<i>k</i>-means)、证据累积聚类(Evidence Accumulation Clustering, EAC)<citation id="401" type="reference"><link href="352" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、局部加权证据累积 (Locally Weighted Evidence Accumulation, LWEA)<citation id="402" type="reference"><link href="382" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>、局部加权图划分(Locally Weighted Graph Partitioning, LWGP)<citation id="403" type="reference"><link href="382" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>作为参与对比的基准算法。使用本文提出的三支筛选算法(3WDSA)优化EAC、LWEA、LWGP得到的3WDSA-EAC、3WDSA-LWEA、3WDSA-LWGP算法与其他传统方法<i>k</i>-means、超图分割算法(HyperGraph Partitioning Algorithm, HGPA)进行对比实验。实验迭代次数<i>R</i>设置为5,并在阈值<i>α</i>和<i>β</i>的值域[0,1]上分别选取100个不同的阈值<i>α</i>和<i>β</i>,实验选取基准数据集为DS1。其中100个<i>α</i>和100个<i>β</i>组成的阈值对(<i>α</i>,<i>β</i>)对算法影响如图1所示。</p>
                </div>
                <div class="area_img" id="192">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911004_192.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 阈值对算法性能的影响" src="Detail/GetImg?filename=images/JSJY201911004_192.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 阈值对算法性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911004_192.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Influence of thresholds on algorithm performance</p>

                </div>
                <div class="p1">
                    <p id="193">图1中<i>XOY</i>平面的<i>X</i>轴为自然增长的<i>α</i>值,<i>Y</i>轴为自然增长的<i>β</i>值,纵轴为不同阈值下聚类集成算法相较于未筛选结果的提升率。不同阈值调节模型产生优质基础聚类的比率,从而使得最终聚类结果拥有更好的效果。如图1所示,随着阈值变化,算法的提升率发生改变。算法的提升率随阈值对的增加而上升,直至达到最高,随后算法的提升率随阈值对的增加而下降。</p>
                </div>
                <div class="p1">
                    <p id="194">阈值<i>α</i>和<i>β</i>在各数据集下最佳取值结果见表5。通过100轮实验,最佳阈值在[0,1]中获得。阈值<i>α</i>和<i>β</i>影响筛选模型的效果,只有取合适阈值时,提出的三支筛选算法才比基准算法有更好的促进作用。</p>
                </div>
                <div class="area_img" id="195">
                    <p class="img_tit"><b>表</b>5 <b>不同数据集的阈值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 5 Thresholds for different datasets</p>
                    <p class="img_note"></p>
                    <table id="195" border="1"><tr><td><br />数据集</td><td><i>α</i></td><td><i>β</i></td></tr><tr><td><br />DS1</td><td>0.25±0.02</td><td>0.55±0.02</td></tr><tr><td><br />DS2</td><td>0.23±0.02</td><td>0.57±0.01</td></tr><tr><td><br />DS3</td><td>0.26±0.03</td><td>0.51±0.02</td></tr><tr><td><br />DS4</td><td>0.27±0.01</td><td>0.53±0.02</td></tr><tr><td><br />DS5</td><td>0.22±0.01</td><td>0.56±0.02</td></tr><tr><td><br />DS6</td><td>0.21±0.01</td><td>0.52±0.02</td></tr><tr><td><br />DS7</td><td>0.25±0.02</td><td>0.55±0.01</td></tr><tr><td><br />DS8</td><td>0.24±0.01</td><td>0.54±0.02</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="196">根据表5中的数据,发现8个数据集的阈值<i>α</i>约为0.25,阈值<i>β</i>约为0.55, 所以,用该阈值对进行其他的实验。基于所有基准数据集的性能,本文推荐使用阈值<i>α</i>∈[0.20,0.29]和阈值<i>β</i>∈[0.49,0.58]。</p>
                </div>
                <div class="p1">
                    <p id="197">为了验证本文提出的三支筛选算法(3WDSA)的有效性,对比实验设计如下:</p>
                </div>
                <div class="p1">
                    <p id="198">1)3WDSA-EAC、3WDSA-LWEA算法与基础<i>k</i>-means算法的性能对比;</p>
                </div>
                <div class="p1">
                    <p id="199">2)3WDSA-EAC、3WDSA-LWEA、3WDSA-LWGP与EAC、LWEA、LWGP、HGPA之间的性能对比;</p>
                </div>
                <div class="p1">
                    <p id="200">最后为了验证不同基聚类集合基数对3WDSA算法的有效性影响,进而实施第3个实验:</p>
                </div>
                <div class="p1">
                    <p id="201">3)不同基聚类集合基数<i>M</i>对3WDSA-EAC、3WDSA-LWEA、3WDSA-LWGP、EAC、LWEA、LWGP、HGPA算法的影响。</p>
                </div>
                <h4 class="anchor-tag" id="202" name="202">3.2.1 与基聚类对比</h4>
                <div class="p1">
                    <p id="203">为了验证3WDSA对聚类集成算法的提升效果,本节对比3WDSA-EAC、3WDSA-LWEA与基础<i>k</i>-means等算法的性能得分。实验方法为,分别使用3WDSA-EAC、3WDSA-LWEA算法运行100次实验数据,同时计算这100次实验的NMI得分均值作为算法性能得分; 也分别执行了100次基础<i>k</i>-means、EAC、LWEA算法,并计算各自的NMI平均得分作为基准参考。</p>
                </div>
                <div class="p1">
                    <p id="204">实验结果如图2所示, 在所有测试数据集上3WDSA-EAC和3WDSA-LWEA效果显著优于基准<i>k</i>-means算法; 特别是3WDSA-LWEA在所有测试数据集上获得了最好的NMI均值得分。在对聚类集成算法不友好的SPF数据集上,3WDSA-EAC和3WDSA-LWEA的算法表现仍然能够优于基准<i>k</i>-means算法,且效果明显高于基准EAC和LWEA算法。</p>
                </div>
                <div class="p1">
                    <p id="205">3WDSA-EAC和3WDSA-LWEA在LR数据集上的NMI均值得分提升效果最为显著,较基准EAC和LWEA分别上升了1.12%和1.36%;在IS、LS、PD等数据集上,3WDSA-EAC和3WDSA-LWEA在基准EAC和LWEA上有明显的效果提升。而在测试数据集MF上,3WDSA-EAC和3WDSA-LWEA比较基准EAC和LWEA效果提升不明显。综上所述,实验数据表明,3WDSA能够提升聚类集成的效果。</p>
                </div>
                <div class="area_img" id="206">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911004_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 各方法在基准数据集上的性能比较" src="Detail/GetImg?filename=images/JSJY201911004_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 各方法在基准数据集上的性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911004_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Performance comparison of various methods on benchmark data sets</p>

                </div>
                <h4 class="anchor-tag" id="207" name="207">3.2.2 与其他聚类集成方法对比</h4>
                <div class="p1">
                    <p id="208">为了进一步验证3WDSA在聚类集成方法上的提升效果,本节对比3WDSA-EAC、3WDSA-LWEA、3WDSA-LWGP算法与EAC、LWEA、LWGP、HGPA算法之间的聚类F-检验与NMI性能得分。其中HGPA为用于衡量对照组准确性的算法。</p>
                </div>
                <div class="p1">
                    <p id="209">同时,设定实验在基聚类基数<i>M</i>相同的前提下执行每个算法50次,然后计算平均F-检验和NMI得分。</p>
                </div>
                <div class="p1">
                    <p id="210">实验结果如表6所示,每个数据集下获得的最好效果均已加粗显示。3WDSA-EAC、3WDSA-LWEA、3WDSA-LWGP在LR数据集上平均提升效果最好,Texture数据集次之。即使LWEA和LWGP采用了局部权重策略,一定程度上降低了低质量聚类对聚类集成的影响,经过3WDSA优化的3WDSA-LWEA和3WDSA-LWGP算法在各数据集上仍有1%～2%的算法效果提升。上述聚类效果的提升是因为3WDSA消除了低质量基聚类对聚类集成结果的消极影响,从而提升了高质量基聚类对聚类集成结果的积极影响。本实验进一步证明了3WDSA在提升聚类集成算法性能上的有效性。</p>
                </div>
                <div class="area_img" id="211">
                    <p class="img_tit"><b>表</b>6 <b>不同聚类集成方法效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 6 Performance comparison of different ensemble clustering methods</p>
                    <p class="img_note"></p>
                    <table id="211" border="1"><tr><td rowspan="2"><br />数据集</td><td rowspan="2">评价指标</td><td colspan="7"><br />聚类集成方法</td></tr><tr><td><br />EAC</td><td>LWEA</td><td>LWGP</td><td>HGPA</td><td>3WDSA-EAC</td><td>3WDSA-LWEA</td><td>3WDSA-LWGP</td></tr><tr><td rowspan="2"><br />IS</td><td><br />F-检验</td><td>0.570 3</td><td>0.592 5</td><td>0.599 4</td><td>0.424 3</td><td>0.597 7</td><td>0.607 9</td><td>0.611 7</td></tr><tr><td><br />NMI</td><td>0.599 3</td><td>0.621 5</td><td>0.629 4</td><td>0.446 3</td><td>0.618 7</td><td>0.632 9</td><td>0.637 7</td></tr><tr><td rowspan="2"><br />LR</td><td><br />F-检验</td><td>0.404 2</td><td>0.394 8</td><td>0.397 3</td><td>0.345 1</td><td>0.426 9</td><td>0.436 3</td><td>0.442 2</td></tr><tr><td><br />NMI</td><td>0.431 2</td><td>0.416 8</td><td>0.411 3</td><td>0.359 1</td><td>0.452 9</td><td>0.463 3</td><td>0.461 2</td></tr><tr><td rowspan="2"><br />LS</td><td><br />F-检验</td><td>0.546 5</td><td>0.591 3</td><td>0.622 2</td><td>0.363 1</td><td>0.549 7</td><td>0.608 9</td><td>0.636 1</td></tr><tr><td><br />NMI</td><td>0.559 5</td><td>0.616 3</td><td>0.644 2</td><td>0.386 1</td><td>0.570 7</td><td>0.629 9</td><td>0.653 1</td></tr><tr><td rowspan="2"><br />PD</td><td><br />F-检验</td><td>0.671 1</td><td>0.759 3</td><td>0.756 6</td><td>0.548 2</td><td>0.689 6</td><td>0.743 3</td><td>0.767 7</td></tr><tr><td><br />NMI</td><td>0.697 1</td><td>0.7693</td><td>0.774 6</td><td>0.560 2</td><td>0.700 6</td><td>0.773 3</td><td>0.781 7</td></tr><tr><td rowspan="2"><br />MF</td><td><br />F-检验</td><td>0.582 1</td><td>0.645 7</td><td>0.672 6</td><td>0.526 1</td><td>0.572 2</td><td>0.631 1</td><td>0.653 3</td></tr><tr><td><br />NMI</td><td>0.597 1</td><td>0.659 7</td><td>0.682 6</td><td>0.538 1</td><td>0.597 2</td><td>0.660 1</td><td>0.678 3</td></tr><tr><td rowspan="2"><br />ODR</td><td><br />F-检验</td><td>0.753 4</td><td>0.807 6</td><td>0.787 3</td><td>0.608 3</td><td>0.787 6</td><td>0.818 4</td><td>0.808 6</td></tr><tr><td><br />NMI</td><td>0.781 4</td><td>0.829 6</td><td>0.816 3</td><td>0.621 3</td><td>0.801 6</td><td>0.834 4</td><td>0.825 6</td></tr><tr><td rowspan="2"><br />SPF</td><td><br />F-检验</td><td>0.087 8</td><td>0.135 3</td><td>0.123 7</td><td>0.099 3</td><td>0.102 4</td><td>0.148 3</td><td>0.135 5</td></tr><tr><td><br />NMI</td><td>0.114 8</td><td>0.151 3</td><td>0.152 7</td><td>0.121 3</td><td>0.130 4</td><td>0.159 3</td><td>0.161 5</td></tr><tr><td rowspan="2"><br />Texture</td><td><br />F-检验</td><td>0.670 6</td><td>0.757 3</td><td>0.718 7</td><td>0.467 3</td><td>0.671 9</td><td>0.778 2</td><td>0.743 3</td></tr><tr><td><br />NMI</td><td>0.694 6</td><td>0.778 3</td><td>0.743 7</td><td>0.496 3</td><td>0.701 9</td><td>0.789 2</td><td>0.770 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="212" name="212" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="213">本文提出了一种基聚类三支决策筛选方法。该方法在使用信息熵构建基聚类质量度量的基础上进行三支筛选,并且可与任意聚类集成算法相融合。通过多组对比实验证明基聚类三支筛选方法能够有效提升经典聚类集成方法的聚类效果。该研究显示三支决策理论是提升无监督学习效果的一种有效策略。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="330">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018050909.nh&amp;v=MDYwMzh0R0ZyQ1VSN3FmWnVac0Z5bm5WTHZNVkYyNkZyTzlIdGpNcHBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 宋敬环.聚类集成算法研究[D].哈尔滨:哈尔滨工程大学,2015:1.(SONG J H.Research on clustering ensemble method[D].Harbin:Harbin Engineering University,2015:1).
                            </a>
                        </p>
                        <p id="332">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cluster ensembles - A knowledge reuse framework for combining multiple partitions">

                                <b>[2]</b> STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining partitionings[J].Journal of Machine Learning Research,2003,3(3):583-617.
                            </a>
                        </p>
                        <p id="334">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive noise immune cluster ensemble using affinity propagation">

                                <b>[3]</b> YU Z,LI L,LIU J,et al.Adaptive noise immune cluster ensemble using affinity propagation[J].IEEE Transactions on Knowledge and Data Engineering,2015,27(12):3176-3189.
                            </a>
                        </p>
                        <p id="336">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES57E07D6381E7F3CC59F9C03CAB0A7BF6&amp;v=MjQxNzlCckxVMDV0cGh4YnE0eEt3PU5pZk9mYmEvYTlITDI0bEdiT3A2Q3dvNnZHVVc0MGwwTzMvaDMyTkhlY09UTjh5WkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> HUANG D,LAI J,WANG C.Combining multiple clusterings via crowd agreement estimation and multi-granularity link analysis[J].Neurocomputing,2015,170:240-250.
                            </a>
                        </p>
                        <p id="338">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800006060&amp;v=MTgxOTAvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlWd1RiaFk9TmpuQmFySzdIdGZPcDQ5RlpPc0pESG81b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> YANG Y.Elements of information theory[J].Journal of the American Statistical Association,2008,103(3):429-429.
                            </a>
                        </p>
                        <p id="340">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Link-Based Approach to the Cluster Ensemble Problem">

                                <b>[6]</b> IAM-ON N,BOONGOEN T,GARRETT S,et al.A link-based approach to the cluster ensemble problem[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2396-2409.
                            </a>
                        </p>
                        <p id="342">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CA-Tree: A hierarchical structure for efficient and scalable coassociation-based cluster ensembles">

                                <b>[7]</b> WANG T.CA-Tree:a hierarchical structure for efficient and scalable coassociation-based cluster ensembles[J].IEEE Transactions on Systems,Man,and Cybernetics,Part B:Cybernetics,2011,41(3):686-698.
                            </a>
                        </p>
                        <p id="344">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414231&amp;v=Mjk2NTd0RE9ySTlGWU9vTERuODRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVndUYmhZPU5pZk9mYks3SA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> TUMER K,AGOGINO A K.Ensemble clustering with voting active clusters[J].Pattern Recognition Letters,2008,29(14):1947-1953.
                            </a>
                        </p>
                        <p id="346">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200411010&amp;v=MDc5NTh0R0ZyQ1VSN3FmWnVac0Z5bm5WTHZNTHo3U1pMRzRIdFhOcm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 董彩云,杜韬,郭春燕,等.聚类后的关联规则快速更新算法研究[J].计算机应用研究,2004,21(11):30-32.(DONG C Y,DU T,GUO C Y,et al.Research on fast adapting algorithm of association rules after clustering[J].Application Research of Computers,2004,21(11):30-32.)
                            </a>
                        </p>
                        <p id="348">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering Ensembles: Models of Consensus and Weak Partitions">

                                <b>[10]</b> TOPCHY A,JAIN A K,PUNCH W.Clustering ensembles:models of consensus and weak partitions [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(12):1866-1881.
                            </a>
                        </p>
                        <p id="350">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cluster ensembles-a knowledge reuse framework for combining partitions">

                                <b>[11]</b> STREHL A,GHOSH J.Cluster ensembles:a knowledge reuse framework for combining multiple partitions [J].Journal of Machine Learning Research,2002,3:583-617.
                            </a>
                        </p>
                        <p id="352">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining multiple clusterings using evidence accumulation">

                                <b>[12]</b> FRED A L,JAIN A K.Combining multiple clusterings using evidence accumulation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2005,27(6):835-850.
                            </a>
                        </p>
                        <p id="354">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Random Projection for High Dimensional Data Clustering:A Cluster Ensemble Approach">

                                <b>[13]</b> FERN X Z,BRODLEY C E.Random projection for high dimensional data clustering:a cluster ensemble approach[C]// Proceedings of the 20th International Conference on Machine Learning.Palo Alto:AAAI Press,2003:187-192.
                            </a>
                        </p>
                        <p id="356">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evaluation of stability of k-means cluster ensembles with respect to random initialization">

                                <b>[14]</b> KUNCHEVA L I,VETRO D P.Evaluation of stability of k-means cluster ensembles with respect to random initialization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1798-1808.
                            </a>
                        </p>
                        <p id="358">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensembles of Partitions via Data Resampling">

                                <b>[15]</b> MINAEIBIDGOLI B,TOPCHY A,PUNCH W F.Ensembles of partitions via data resampling[C]// Proceedings of the 2004 International Conference on Information Technology:Coding and Computing.Washington,DC:IEEE Computer Society,2004:188-192.
                            </a>
                        </p>
                        <p id="360">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bagging to improve the accuracy of a clustering procedure">

                                <b>[16]</b> DUDOIT S,FRIDLYAND J.Bagging to improve the accuracy of a clustering procedure[J].Bioinformatics,2003,19(9):1090-1099.
                            </a>
                        </p>
                        <p id="362">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hybrid sampling-based clustering ensemble with global and local constitutions">

                                <b>[17]</b> YANG Y,JIANG J.Hybrid sampling-based clustering ensemble with global and local constitutions[J].IEEE Transactions on Neural Networks and Learning Systems,2017,27(5):952-965.
                            </a>
                        </p>
                        <p id="364">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning a robust consensus matrix for clustering ensemble via KullbackLeibler divergence minimization">

                                <b>[18]</b> ZHOU P,DU L,WANG H,et al.Learning a robust consensus matrix for clustering ensemble via Kullback-Leibler divergence minimization[C]// Proceedings of the 24th International Conference on Artificial Intelligence.Palo Alto:AAAI Press,2015:4112-4118.
                            </a>
                        </p>
                        <p id="366">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incremental Semi-supervised Clustering Ensemble for High Dimensional Data Clustering">

                                <b>[19]</b> YU Z,LUO P,YOU J,et al.Incremental semi-supervised clustering ensemble for high dimensional data clustering[J].IEEE Transactions on Knowledge and Data Engineering,2016,28(3):701-714.
                            </a>
                        </p>
                        <p id="368">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An outline of a theory of three-way decisions">

                                <b>[20]</b> YAO Y.An outline of a theory of three-way decisions[C]// Proceedings of the 8th International Conference on Rough Sets and Current Trends in Computing.Heidelberg:Springer,2012:1-17.
                            </a>
                        </p>
                        <p id="370">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Chinese Emotion Recognition Based on Three-Way Decisions">

                                <b>[21]</b> WANG L,MIAO D,ZHAO C.Chinese emotion recognition based on three-way decisions[C]// Proceedings of the 10th International Conference on Rough Sets and Knowledge Technology.Heidelberg:Springer,2015:299-308.
                            </a>
                        </p>
                        <p id="372">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES62AFECD5B0FF5B88459339A613EBB01C&amp;v=MDYxOTFYN3paK1MzYVRxaE0yRE1EbVJidnNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4YnE0eEt3PU5pZk9mYlc2YjZlNTNQdEFGdXQ1ZW5sTHh4NA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> XU J,MIAO D,ZHANG Y,et al.A three-way decisions model with probabilistic rough sets for stream computing[J].International Journal of Approximate Reasoning,2017,88:1-22.
                            </a>
                        </p>
                        <p id="374">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15120801000203&amp;v=MTk4MTVUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVndUYmhZPU5pZk9mYks5SDlQTXA0OUVaT3NQRG53Nm9CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> LI W,XU W H.Double-quantitative decisiontheoretic rough set[J].Information Sciences,2015,316:54-67.
                            </a>
                        </p>
                        <p id="376">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900044842&amp;v=MjI4ODhlcnFRVE1ud1plWnRGaW5sVXIzSUlWd1RiaFk9TmlmT2ZiSzdIdFRNcG85RlpPOExCSGc3b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> QIAN Y,ZHANG H,SANG Y,et al.Multi-granulation decisiontheoretic rough sets[J].International Journal of Approximate Reasoning,2014,55(1) :225-237.
                            </a>
                        </p>
                        <p id="378">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201202015&amp;v=MTkxNTZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVkx2TUx6N0Jkckc0SDlQTXJZOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 苗夺谦,徐菲菲,姚一豫,等.粒计算的集合论描述[J].计算机学报,2012,35(2):351-363.(MIAO D Q,XU F F,YAO Y Y,et al.Set-theoretic formulation of granular computing[J].Chinese Journal of Computers,2012,35(2):351-363.)
                            </a>
                        </p>
                        <p id="380">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES367A1B1D3C9427BB902687649427E30A&amp;v=MTE1MTFOM1k0eFo1Z0dDSDQrdldRYTZqMTdRSGprcUJzeGU3WGhScnJ1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJxNHhLdz1OaWZPZmJDK0dhRA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> ABUALIGAH L M,KHADER A T,AL-BETAR M A,et al.Text feature selection with a robust weight scheme and dynamic dimension reduction to text document clustering[J].Expert Systems with Applications,2017,84(C):24-36.
                            </a>
                        </p>
                        <p id="382">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locally weighted ensemble clustering">

                                <b>[27]</b> HUANG D,WANG C,LAI J.Locally weighted ensemble clustering[J].IEEE Transactions on Cybernetics,2016,48(5):1460-1473.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201911004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911004&amp;v=MTk3OTZWTHZNTHo3QmQ3RzRIOWpOcm85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
