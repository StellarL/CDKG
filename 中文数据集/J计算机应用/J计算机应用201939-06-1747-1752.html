<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136685934221250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906033%26RESULT%3d1%26SIGN%3dIdscgo3kmbbWWORXnetJKwkxo8c%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906033&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906033&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906033&amp;v=MDc0NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnk3bFdyN01MejdCZDdHNEg5ak1xWTlHWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="1 数据处理 ">1 数据处理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="1.1 &lt;b&gt;空间坐标系统&lt;/b&gt;">1.1 <b>空间坐标系统</b></a></li>
                                                <li><a href="#54" data-title="1.2 &lt;b&gt;欧拉角法&lt;/b&gt;">1.2 <b>欧拉角法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="2 基于支持向量机的身份识别 ">2 基于支持向量机的身份识别</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#98" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="3.1 &lt;b&gt;实验数据采集&lt;/b&gt;">3.1 <b>实验数据采集</b></a></li>
                                                <li><a href="#108" data-title="3.2 &lt;b&gt;实验特征选取&lt;/b&gt;">3.2 <b>实验特征选取</b></a></li>
                                                <li><a href="#115" data-title="3.3 &lt;b&gt;实验过程与分析&lt;/b&gt;">3.3 <b>实验过程与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="图1 声音和头骨指纹相结合的高端生物识别技术">图1 声音和头骨指纹相结合的高端生物识别技术</a></li>
                                                <li><a href="#40" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;各生物识别技术指标比较&lt;/b&gt;"><b>表</b>1 <b>各生物识别技术指标比较</b></a></li>
                                                <li><a href="#42" data-title="图2 基于生理特征的生物识别工作流程">图2 基于生理特征的生物识别工作流程</a></li>
                                                <li><a href="#47" data-title="图3 所提方法基本思路">图3 所提方法基本思路</a></li>
                                                <li><a href="#52" data-title="图4 手机坐标系与世界坐标系示例">图4 手机坐标系与世界坐标系示例</a></li>
                                                <li><a href="#58" data-title="图5 坐标分解旋转">图5 坐标分解旋转</a></li>
                                                <li><a href="#103" data-title="图6 &lt;i&gt;Android&lt;/i&gt;传感器管理系统">图6 <i>Android</i>传感器管理系统</a></li>
                                                <li><a href="#107" data-title="图7 不同用户步态数据信息比对">图7 不同用户步态数据信息比对</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;步态特征身份识别所用的部分特征&lt;/b&gt;"><b>表</b>2 <b>步态特征身份识别所用的部分特征</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;选用的特征与识别准确率关系&lt;/b&gt;"><b>表</b>3 <b>选用的特征与识别准确率关系</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="141">


                                    <a id="bibliography_1" title="李鹏飞, 淡美俊, 姚宇颤.生物识别技术综述[J].电子制作, 2018 (10) :89-90. (LI P F, DAN M J, YAO Y Z.Overview of biometric identification technology[J].Practical Electronics, 2018 (10) :89-90.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZZZ201810042&amp;v=MDE5MzM0OUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I3TUlUZlJkTEc0SDluTnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        李鹏飞, 淡美俊, 姚宇颤.生物识别技术综述[J].电子制作, 2018 (10) :89-90. (LI P F, DAN M J, YAO Y Z.Overview of biometric identification technology[J].Practical Electronics, 2018 (10) :89-90.) 
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_2" title="王俊山, 张文明.生物识别技术的类别及其在身份识别中的应用[J].河南科技, 2017 (15) :34-35. (WANG J S, ZHANG W M.The category of biometric chip and its application in identity[J].Journal of Henan Science and Technology, 2017 (15) :34-35.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKJ201715021&amp;v=MjUyOTdCdEdGckNVUjdxZlp1WnNGeTdsV3I3TUxTUEFaTEc0SDliTnFvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        王俊山, 张文明.生物识别技术的类别及其在身份识别中的应用[J].河南科技, 2017 (15) :34-35. (WANG J S, ZHANG W M.The category of biometric chip and its application in identity[J].Journal of Henan Science and Technology, 2017 (15) :34-35.) 
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_3" title="陈虹旭, 李晓坤, 郑永亮, 等.基于深度学习的指纹识别方法研究[J].智能计算机与应用, 2018, 8 (3) :64-69. (CHEN H X, LI X K, ZHENG Y L, et al.Research on fingerprint recognition method based on deep learning[J].Intelligent Computer and Applications, 2008, 8 (3) :64-69.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXZ201803016&amp;v=MDM2NTBac0Z5N2xXcjdNSVNIVGRMRzRIOW5Nckk5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        陈虹旭, 李晓坤, 郑永亮, 等.基于深度学习的指纹识别方法研究[J].智能计算机与应用, 2018, 8 (3) :64-69. (CHEN H X, LI X K, ZHENG Y L, et al.Research on fingerprint recognition method based on deep learning[J].Intelligent Computer and Applications, 2008, 8 (3) :64-69.) 
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_4" title="张笛.人脸识别现状与发展趋势研究[J].广东通信技术, 2018, 38 (6) :43-48. (ZHANG D.Research on the status quo and development trend of face recognition[J].Guangdong Communication Technology, 2008, 38 (06) :43-48.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUDO201806014&amp;v=MjgxOTg3TUlqalBZYkc0SDluTXFZOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        张笛.人脸识别现状与发展趋势研究[J].广东通信技术, 2018, 38 (6) :43-48. (ZHANG D.Research on the status quo and development trend of face recognition[J].Guangdong Communication Technology, 2008, 38 (06) :43-48.) 
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_5" title="马璐璐, 朱雪珍.虹膜识别专利技术综述[J].河南科技, 2017 (16) :55-57. (MA L L, ZHU X Z.Review on the patent technology of iris recognition[J].Journal of Henan Science and Technology, 2017 (16) :55-57.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKJ201716028&amp;v=MDY2NTlNTFNQQVpMRzRIOWJOcVk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5N2xXcjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        马璐璐, 朱雪珍.虹膜识别专利技术综述[J].河南科技, 2017 (16) :55-57. (MA L L, ZHU X Z.Review on the patent technology of iris recognition[J].Journal of Henan Science and Technology, 2017 (16) :55-57.) 
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_6" title="AILISTO H J, LINDHOLM M, MANTYJARVI J, et al.Identifying people from gait pattern with accelerometers[C]//Proceedings of SPIE 5779-the International Society for Optical Engineering, Biometric Technology for Human Identification II.Bellingham:SPIE, 2005:7-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Identifying people from gait pattern with accelerometers">
                                        <b>[6]</b>
                                        AILISTO H J, LINDHOLM M, MANTYJARVI J, et al.Identifying people from gait pattern with accelerometers[C]//Proceedings of SPIE 5779-the International Society for Optical Engineering, Biometric Technology for Human Identification II.Bellingham:SPIE, 2005:7-14.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_7" title="DERAWI M O, NICKEL C, BOURS P, et al.Unobtrusive user-authentication on mobile phones using biometric gait recognition[C]//Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing.Washington, DC:IEEE Computer Society, 2010:474-479." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unobtrusive User-authentication onmobile phones using Biometric gait recognition">
                                        <b>[7]</b>
                                        DERAWI M O, NICKEL C, BOURS P, et al.Unobtrusive user-authentication on mobile phones using biometric gait recognition[C]//Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing.Washington, DC:IEEE Computer Society, 2010:474-479.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_8" title="THANG H M, VIET V Q, THUC N D, et al.Gait identification using accelerometer on mobile phone[C]//Proceedings of the2012 International Conference on Control, Automation and Information Sciences.Piscataway, NJ:IEEE, 2012:344-348." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gait identification using accelerometer on mobile phone">
                                        <b>[8]</b>
                                        THANG H M, VIET V Q, THUC N D, et al.Gait identification using accelerometer on mobile phone[C]//Proceedings of the2012 International Conference on Control, Automation and Information Sciences.Piscataway, NJ:IEEE, 2012:344-348.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_9" title="NICKEL C, DERAWI M O, BOURS P, et al.Scenario test of accelerometer-based biometric gait recognition[C]//Proceedings of the 2014 Third International Workshop on Security&amp;amp;Communication Networks.Piscataway, NJ:IEEE, 2014:167-174." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scenario test of accelerometer-based biometric gait recognition">
                                        <b>[9]</b>
                                        NICKEL C, DERAWI M O, BOURS P, et al.Scenario test of accelerometer-based biometric gait recognition[C]//Proceedings of the 2014 Third International Workshop on Security&amp;amp;Communication Networks.Piscataway, NJ:IEEE, 2014:167-174.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_10" title="HOANG T, NGUYEN T, LUONG C, et al.Adaptive cross-device gait recognition using a mobile accelerometer[J].Journal of Information Processing Systems, 2013, 9 (2) :333-348." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Cross-Device Gait Recognition Using a Mobile Accelerometer">
                                        <b>[10]</b>
                                        HOANG T, NGUYEN T, LUONG C, et al.Adaptive cross-device gait recognition using a mobile accelerometer[J].Journal of Information Processing Systems, 2013, 9 (2) :333-348.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_11" title="刘冠群, 罗桂琼, 谭平.基于类Haar特征模板匹配的多镜头步态识别算法[J].计算机工程, 2017, 43 (12) :231-236. (LIU GQ, LUO G Q, TAN P.Multiple Lens gait recognition algorithm based on category Haar feature template matching[J].Computer Engineering, 2017, 43 (12) :231-236.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712042&amp;v=MDc0ODFyQ1VSN3FmWnVac0Z5N2xXcjdNTHo3QmJiRzRIOWJOclk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        刘冠群, 罗桂琼, 谭平.基于类Haar特征模板匹配的多镜头步态识别算法[J].计算机工程, 2017, 43 (12) :231-236. (LIU GQ, LUO G Q, TAN P.Multiple Lens gait recognition algorithm based on category Haar feature template matching[J].Computer Engineering, 2017, 43 (12) :231-236.) 
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_12" title="佟苏洋, 和焕胤, 汤澄清.基于足底压力分析系统对青年人行走步态特征稳定性的研究[J].四川警察学院学报, 2017, 29 (6) :77-83. (TONG S Y, HE H Y, TANG C Q.Stability of the youth&#39;s gait characteristics in walking based on the plantar pressure analysis system[J].Journal of Sichuan Police College, 2017, 29 (6) :77-83.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCJG201706011&amp;v=MDA3MzZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I3TU5pN0JhYkc0SDliTXFZOUU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        佟苏洋, 和焕胤, 汤澄清.基于足底压力分析系统对青年人行走步态特征稳定性的研究[J].四川警察学院学报, 2017, 29 (6) :77-83. (TONG S Y, HE H Y, TANG C Q.Stability of the youth&#39;s gait characteristics in walking based on the plantar pressure analysis system[J].Journal of Sichuan Police College, 2017, 29 (6) :77-83.) 
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_13" title="KOMARINENI S, MACLEAN D, HASHIMI S.精通Android 3[M].杨越, 译.北京:人民邮电出版社, 2011:728-733. (KOMARINE-NI S, MACLEAN D.Pro Android 3[M].YANG Y, translated.Beijing:Post&amp;amp;Telecom Press, 2011:728-733.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115266026001&amp;v=MTQ1OTRxekdiSzVHOVBLcVk5SFl1c1BEUk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bm5VN25JS1Y4UVhG&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        KOMARINENI S, MACLEAN D, HASHIMI S.精通Android 3[M].杨越, 译.北京:人民邮电出版社, 2011:728-733. (KOMARINE-NI S, MACLEAN D.Pro Android 3[M].YANG Y, translated.Beijing:Post&amp;amp;Telecom Press, 2011:728-733.) 
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_14" title="张勇, 夏家莉, 陈滨, 等.Google Android开发技术[M].西安:西安电子科技大学出版社, 2011:124-127. (ZHANG Y, XIA JL, CHEN B, et al.Google Android Development Technology[M].Xi&#39;an:Xidian University Press, 2011:124-127.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787560626673001&amp;v=MDA2NDl0Zk9xWWxDWitzUERSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3bklLVjhRWEZxekdiYStI&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        张勇, 夏家莉, 陈滨, 等.Google Android开发技术[M].西安:西安电子科技大学出版社, 2011:124-127. (ZHANG Y, XIA JL, CHEN B, et al.Google Android Development Technology[M].Xi&#39;an:Xidian University Press, 2011:124-127.) 
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_15" title="PHAN D-T, DAM N N-T, NGUYEN M-P, et al.Smart kiosk with gait-based continuous authentication[C]//Proceedings of the 2015International Conference on Distributed, Ambient, and Pervasive Interactions, LNCS 9189.Cham:Springer, 2015:110-115." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Smart kiosk with gait-based continuous authentication">
                                        <b>[15]</b>
                                        PHAN D-T, DAM N N-T, NGUYEN M-P, et al.Smart kiosk with gait-based continuous authentication[C]//Proceedings of the 2015International Conference on Distributed, Ambient, and Pervasive Interactions, LNCS 9189.Cham:Springer, 2015:110-115.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_16" title="侯东谷.基于智能手机的人体步态识别及其应用[D].成都:电子科技大学, 2018:58-71. (HOU D G.Human gait recognition and its application based on smart phones[D].Chengdu:U-niversity of Electronic Science and Technology of China, 2018:58-71.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991575.nh&amp;v=MTYwMzJxcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnk3bFdyN01WRjI2RnJxeEg5VEw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        侯东谷.基于智能手机的人体步态识别及其应用[D].成都:电子科技大学, 2018:58-71. (HOU D G.Human gait recognition and its application based on smart phones[D].Chengdu:U-niversity of Electronic Science and Technology of China, 2018:58-71.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-31 09:53</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1747-1752 DOI:10.11772/j.issn.1001-9081.2018102161            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于智能手机运动传感器的步态特征身份识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%94%E8%8F%81&amp;code=40788934&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孔菁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%B8%8A%E5%8D%9A&amp;code=20283043&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭渊博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%98%A5%E8%BE%89&amp;code=40788935&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘春辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%80%E4%B8%B0&amp;code=40788936&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王一丰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6&amp;code=0199248&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息工程大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>利用行为特征进行身份验证是生物识别的前沿技术。为优化基于步态特征的身份识别研究中对数据的处理并改进识别的方式, 提出利用智能手机运动传感器数据提取步态特征用于身份识别的方法。首先, 应用空间转换算法解决传感器坐标系漂移问题, 使数据可以完整准确地刻画行为特征;然后, 利用支持向量机 (SVM) 算法对用户切换所导致的步态特征变化进行分类识别。实验结果表明, 经过欧拉角法处理后, 所提方法识别准确率达到95.5%, 在有效识别用户变换的同时降低了空间开销和实现难度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA%E9%97%B4%E5%9D%90%E6%A0%87%E8%BD%AC%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空间坐标转换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A5%E6%80%81%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">步态特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9F%E5%BA%A6%E4%BC%A0%E6%84%9F%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速度传感器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AC%A7%E6%8B%89%E8%A7%92%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">欧拉角法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *孔菁 (1993—) , 女, 辽宁营口人, 硕士, 主要研究方向:网络安全、异常检测;1226116158@qq.com;
                                </span>
                                <span>
                                    郭渊博 (1975—) , 男, 陕西周至人, 教授, 博士生导师, 博士, 主要研究方向:大数据安全、态势感知;;
                                </span>
                                <span>
                                    刘春辉 (1990—) , 男, 山东安丘人, 硕士, 主要研究方向:网络安全、用户画像;;
                                </span>
                                <span>
                                    王一丰 (1994—) , 男, 江苏泰兴人, 硕士研究生, 主要研究方向:多步网络安全、深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61602515, 61501515);</span>
                    </p>
            </div>
                    <h1><b>Gait feature identification method based on motion sensor in smartphone</b></h1>
                    <h2>
                    <span>KONG Jing</span>
                    <span>GUO Yuanbo</span>
                    <span>LIU Chunhui</span>
                    <span>WANG Yifeng</span>
            </h2>
                    <h2>
                    <span>Information Engineering University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The identification based on behavior features is a leading technology of biometric recognition. In order to optimize the process of data processing and the way of recognition in the existing studies of identification based on gait feature, a method of extracting gait features from the data of smart phone motion sensors for identification was proposed. Firstly, a spatial transformation algorithm was used to solve the problem of sensor coordinate system drift, making the data to describe the behavior features completely and accurately. Then, Support Vector Machine (SVM) algorithm was used to classify and identify gait features change caused by user transformation. The experimental results show that, the identification accuracy of the proposed method is 95.5%. It can be used to effectively identify user transformation with reduction of space cost and implementation difficulty.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial%20coordinate%20transformation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial coordinate transformation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=gait%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">gait feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=acceleration%20sensor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">acceleration sensor;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Euler%20angle%20method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Euler angle method;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Support%20Vector%20Machine%20(SVM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Support Vector Machine (SVM) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    KONG Jing, born in 1993, M. S. Her research interests include network security, abnormal detection. ;
                                </span>
                                <span>
                                    GUO Yuanbo, born in 1975, Ph. D. , professor. His research interests include big data security, situational awareness. ;
                                </span>
                                <span>
                                    LIU Chunhui, born in 1990, M. S. His research interests include network security, user portrait. ;
                                </span>
                                <span>
                                    WANG Yifeng, born in 1994, M. S. candidate. His research interests include multi-step network security, deep learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-26</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61602515, 61501515);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="36">生物识别是通过计算机视觉、人体生物学、生物统计学等高科技理论与手段结合, 利用人体固有的生理特性或表现出的行为特征进行身份识别与认证的过程。生物识别技术主要利用的是人类生物特征, 生物特征通常具有普遍性和唯一性。普遍性即所有用户都拥有此特征;唯一性即不同用户拥有不同但同类的特征。由于其具有与生俱来的遗传性和终身不变等特点, 目前生物识别技术较传统识别技术而言存在较大优势。</p>
                </div>
                <div class="p1">
                    <p id="37">如今全球信息化迅速发展, 网络化所引发的身份数字化与模糊化导致了普遍的个人隐私信息泄露问题, 这对身份识别与安全验证提出了更高的标准和要求。常见的传统安全认证方法包括用户名密码组合验证、特有物件验证 (如通行证、二维码、口令等) 、PIN (Personal Identification Number) 码验证等, 这些验证方式过程中人为参与因素过多而易被盗取或模仿, 无法实现高级别和高精度的安全防控。客观因素带来的危险难以避免, 但利用生物特征的认证方式即可将其解除, 因为用户的生物特征难以更改, 不容易被模仿, 被盗用可能性小, 在政府军队、银行、福利保障、电子商务等领域均有广泛应用<citation id="173" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。现有成果中较高端的生物识别技术中将两种特征结合, 利用声音和人体头骨建立图谱进行高精度身份识别认证的流程示意图如图1所示。</p>
                </div>
                <div class="area_img" id="38">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 声音和头骨指纹相结合的高端生物识别技术" src="Detail/GetImg?filename=images/JSJY201906033_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 声音和头骨指纹相结合的高端生物识别技术  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Sophisticated biometric identification technology with combination of sound and skull fingerprints</p>

                </div>
                <div class="p1">
                    <p id="39">根据国际生物识别小组 (International Biometric Group, IBG) 目前的统计结果, 已有生物识别技术主要分为针对生理特征和行为特征的两种应用, 利用人体生理特性的身份识别应用较多, 如指纹识别、掌纹识别、人脸识别、虹膜识别等<citation id="174" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>;基于用户行为特征的生物识别技术种类也有部分应用, 如笔迹识别、声音识别、步态识别等, 这些技术指标对比如表1所示。可见基于行为特征的生物识别在相同设备成本等级中拥有最高的安全等级和准确性, 同时拥有较高的便利性和稳定性, 是该研究领域的新潮流。</p>
                </div>
                <div class="area_img" id="40">
                    <p class="img_tit"><b>表</b>1 <b>各生物识别技术指标比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Comparison of different biometric identification indicators</p>
                    <p class="img_note"></p>
                    <table id="40" border="1"><tr><td>生物识别</td><td>便利性</td><td>准确性</td><td>稳定性</td><td>安全</td><td>成本</td></tr><tr><td>指纹</td><td>较高</td><td>高</td><td>较高</td><td>中等</td><td>中等</td></tr><tr><td><br />人脸</td><td>极高</td><td>高</td><td>较高</td><td>高</td><td>中等</td></tr><tr><td><br />虹膜</td><td>中等</td><td>极高</td><td>极高</td><td>极高</td><td>极高</td></tr><tr><td><br />语音</td><td>高</td><td>中等</td><td>中等</td><td>较高</td><td>较低</td></tr><tr><td><br />行为特征</td><td>较高</td><td>较高</td><td>较高</td><td>较高</td><td>中等</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="41">目前利用生物特征进行身份识别的工作原理如图2所示, 主要利用细节匹配的方法来识别用户身份。其中指纹识别是利用手指的皮肤纹理进行认证, 目前结合深度学习的相关知识广泛应用<citation id="175" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 缺点在于日常生活中手指动作频繁易造成皮肤纹理改变, 且已出现大量针对指纹窃取和更改的成熟技术出现;人脸识别利用计算机分析图像并从中提取有效个人识别信息, 最终判别出对象的身份<citation id="176" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。人脸识别虽目前已有较为成熟的应用但其运行的稳定性较差, 如拍摄角度、背景光线等均会对识别结果造成影响, 导致误报率极高, 应用性较差;虹膜识别<citation id="177" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>目前在全世界范围内被公认为是已有身份识别技术中最为精确的一种, 虹膜即人体眼睛内巩膜和瞳孔之间的环状区域包含了丰富的纹理特征, 其结构由遗传基因决定后天不能更改, 且不易窃取或伪造。但虹膜识别需要配备高端的仪器进行虹膜图像采集和专业人员提供科学技术支撑, 不适合日常工作中推广与使用。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于生理特征的生物识别工作流程" src="Detail/GetImg?filename=images/JSJY201906033_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于生理特征的生物识别工作流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Biometric identification workflow based on physiological characteristics</p>

                </div>
                <div class="p1">
                    <p id="43">根据生物学常识可知, 用户除受伤等意外发生的正常情况下步行时的步幅、步速、摆臂幅度与频率等表现出很明显且较为固定的生物特性, 为基于行为特征的身份识别技术研究提供了新思路。2005年, Ailisto等<citation id="178" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>首次提出利用独立加速度传感器采集用户行走时的数据进行步态特征提取用于身份识别, 验证了基于加速度传感器进行基于步态特征的身份识别的可行性。随着智能手机的发展与使用的推广, 其内置加速度传感器被用于步态识别更加普遍<citation id="179" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 用户在正常行走时可同时实现对身份的实时识别, 从而达到了对贵重便携式电子产品的保护<citation id="180" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。Nicel等<citation id="181" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用动态时间归整 (Dynamic Time Warping, DTW) 算法, 比较训练集和测试集的最小规整路径, 以步态周期为单一特征值, 得到的能量效率比达到20%。Hoang等<citation id="182" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将两个手机分别放置在14个不同实验参与者的大腿上, 在相同地板上进行往返走12次, 利用支持向量机来测试数据来源的准确性, 该方法展现了支持向量机分类器在处理该类数据方面的优势。</p>
                </div>
                <div class="p1">
                    <p id="44">近些年来基于步态特征的身份识别技术主要有3个数据来源:计算机视觉、压力传感器和加速度传感器。计算机视觉的方法首先利用视频录制或图片拍摄等手段采集用户行走时的图像信息建立个人数据信息库, 再通过图像识别技术进行比对从而辨别不同的用户<citation id="183" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 但存在视觉范围、障碍物遮挡、拍摄角度、光线不足等问题, 继续发展和推广应用的局限性较大;基于压力传感器的方法通常将特制的压力传感器事先在水平的地面上设置好, 然后采集用户步行通过时足底压力的分布情况<citation id="184" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 但该过程需要在特定设备上行走才能进行有效的身份验证, 实际中应用较少;加速度传感器具有可随时置于人体特定部位进行步行数据采集的优势, 不受视觉影响和场地限制, 因此基于步态特征的身份识别依赖更多是传感器采集数据。智能手机使用的普及和加速度传感器硬件的更新换代使得数据采集过程更加方便快捷, 且可更有效地保护用户的隐私信息。</p>
                </div>
                <div class="p1">
                    <p id="45">与独立可传感器相比, 手机内置加速度传感器与设备自身固定<citation id="185" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 使用自定义坐标系, 在数据采集时手机姿态的改变会导致坐标系不断发生漂移, 此情况下即使同一用户进行相同运动过程时加速度传感器的数据也难以表现出固定的数据特征。为解决该问题, 实验在对步态特征进行识别前增加了坐标系方向转换的数据处理步骤, 使得采集的数据对用户个人特征的描述更加准确。</p>
                </div>
                <div class="p1">
                    <p id="46">综上所述, 本文提出基于智能手机运动传感器数据步态特征身份识别的方法主要由两大部分组成:空间坐标系的转换和行为特征的识别分类, 基本思路如图3所示。首先, 利用空间转换算法对加速度传感器所在坐标轴进行转换, 提高数据对运动情况描述的准确性;再利用支持向量机分类算法对步态特征进行识别。该算法在人类行为识别领域公认效果较好, 本文将其推广至步态特征身份识别领域, 并通过实验验证了所提方法的有效性。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 所提方法基本思路" src="Detail/GetImg?filename=images/JSJY201906033_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 所提方法基本思路  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Basic idea of the proposed method</p>

                </div>
                <h3 id="48" name="48" class="anchor-tag">1 数据处理</h3>
                <div class="p1">
                    <p id="49">在采集和收集数据的过程中手机的位置和姿态会引起传感器所在坐标系在惯性空间中发生旋转, 从而产生严重的位置漂移, 导致数据之间映射关系发生变化, 无法准确反映运动的实际状态。为解决该问题, 在进行特征识别之前首先利用空间坐标转换算法对加速度传感器数据进行处理, 将其从手机坐标系映射至常用惯性坐标系, 不破坏原始数据特征的情况下确保训练和测试数据可以反映出用户实际的运动特征和运动状态。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">1.1 <b>空间坐标系统</b></h4>
                <div class="p1">
                    <p id="51">物理空间常用坐标系有三种:自基准坐标系 (即自定义坐标系) 、惯性坐标系和世界坐标系。智能手机加速度传感器所在的坐标系是自基准的相对坐标系<citation id="186" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 该坐标系以手机屏幕的中心点为坐标原点, 平行于屏幕短边向右为该<i>X</i>轴正方向, 平行于屏幕长边向前为<i>Y</i>轴正方向, 垂直于屏幕向上为<i>Z</i>轴正方向。世界坐标系是绝对坐标系, 通过地球表面经纬度和海拔高度对世界每个点进行详细准确的方位信息描述。常用惯性坐标系原点与手机自基准坐标系原点重合, 坐标轴与世界坐标系的坐标轴平行。因此, 从加速度传感器自基准坐标系到惯性坐标系的转换需旋转操作, 从惯性坐标系到世界坐标系的转换较为简单只需平移操作即可。手机坐标系与世界坐标系之间的关系如图4所示。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 手机坐标系与世界坐标系示例" src="Detail/GetImg?filename=images/JSJY201906033_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 手机坐标系与世界坐标系示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Examples of mobile phone coordinate system and world coordinate system</p>

                </div>
                <div class="p1">
                    <p id="53">从智能手机内置加速度传感器采集到的原始数据反映的是加速度传感器在自基准坐标系空间中的数据信息, 而不是在惯性坐标系中感知的用户真实运动信息;加速度传感器所在的自基准坐标系与惯性空间正南正北方向的夹角可由手机中其他传感器测量给出, 因此采集到的加速度传感器原始数据在进行高精度的身份识别前要利用已知角度和空间坐标转换算法将数据从手机自基准的坐标系转换到惯性坐标系上。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">1.2 <b>欧拉角法</b></h4>
                <div class="p1">
                    <p id="55">欧拉角法常用于处理在数学定义的三维空间中坐标系旋转问题, 其基本思想是将两个坐标系的变换分解为绕不同坐标轴的三次连续转动组成的序列, 从而使两坐标系重合。</p>
                </div>
                <div class="p1">
                    <p id="56">欧拉角旋转顺序规定连续两次旋转必须绕着不同的转动轴。对于加速度传感器而言, 在空间中共有12种不同旋转顺序。本实验选用最常见的<i>Z</i>-<i>Y</i>-<i>X</i>旋转顺序来描述加速度传感器所在坐标系与惯性坐标系之间的关系, 坐标分解旋转如图5所示, 三种不同的虚线分别代表不同次数加速度传感器自基准坐标系旋转后得到的结果。</p>
                </div>
                <div class="p1">
                    <p id="57">加速度传感器原始数据在空间中的角度数据处理的过程具体如下。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 坐标分解旋转" src="Detail/GetImg?filename=images/JSJY201906033_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 坐标分解旋转  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Coordinate decomposition and rotation</p>

                </div>
                <div class="p1">
                    <p id="59">设已有两坐标系<i>b</i>和坐标系<i>n</i>, 两坐标系的初始原点重合;设某向量在坐标系<i>b</i>中的坐标表达为 (<i>X</i>, <i>Y</i>, <i>Z</i>) , 在坐标系<i>n</i>中的坐标表达为 (<i>X</i>′, <i>Y</i>′, <i>Z</i>′) , 两<i>X</i>轴之间夹角为<i>θ</i>, 两<i>Y</i>轴之间夹角为ϕ, 两<i>Z</i>轴之间夹角为<i>φ</i>, 则 (<i>X</i>, <i>Y</i>, <i>Z</i>) 与 (<i>X</i>′, <i>Y</i>′, <i>Z</i>′) 的初始坐标关系为如式 (1) 、 (2) 、 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi></mtd></mtr><mtr><mtd><mi>Y</mi></mtd></mtr><mtr><mtd><mi>Ζ</mi></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><msup><mi>X</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Ζ</mi><mo>′</mo></msup></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi></mtd></mtr><mtr><mtd><mi>Y</mi></mtd></mtr><mtr><mtd><mi>Ζ</mi></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mn>0</mn></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mn>0</mn></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><msup><mi>X</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Ζ</mi><mo>′</mo></msup></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi></mtd></mtr><mtr><mtd><mi>Y</mi></mtd></mtr><mtr><mtd><mi>Ζ</mi></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi></mtd><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><msup><mi>X</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>Ζ</mi><mo>′</mo></msup></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">由此得到三个欧拉角转动后, 坐标系<i>n</i>下的向量[<i>X</i><sup><i>b</i></sup>, <i>Y</i><sup><i>b</i></sup>, <i>Z</i><sup><i>b</i></sup>]<sup>T</sup>旋转后与其对应的坐标系<i>b</i>下的向量[<i>X</i><sup><i>n</i></sup>, <i>Y</i><sup><i>n</i></sup>, <i>Z</i><sup><i>n</i></sup>]<sup>T</sup>为:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi><msup><mrow></mrow><mi>b</mi></msup></mtd></mtr><mtr><mtd><mi>Y</mi><msup><mrow></mrow><mi>b</mi></msup></mtd></mtr><mtr><mtd><mi>Ζ</mi><msup><mrow></mrow><mi>b</mi></msup></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mn>0</mn></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mn>0</mn></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi></mtd><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi><msup><mrow></mrow><mi>n</mi></msup></mtd></mtr><mtr><mtd><mi>Y</mi><msup><mrow></mrow><mi>n</mi></msup></mtd></mtr><mtr><mtd><mi>Ζ</mi><msup><mrow></mrow><mi>n</mi></msup></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">即为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">[</mo><mtable><mtr><mtd><mi>X</mi><msup><mrow></mrow><mi>b</mi></msup></mtd><mtd><mi>Y</mi><msup><mrow></mrow><mi>b</mi></msup></mtd><mtd><mi>Ζ</mi><msup><mrow></mrow><mi>b</mi></msup></mtd></mtr></mtable><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo><mi mathvariant="bold-italic">R</mi><msubsup><mrow></mrow><mi>b</mi><mi>n</mi></msubsup><mo stretchy="false">[</mo><mtable><mtr><mtd><mi>X</mi><msup><mrow></mrow><mi>n</mi></msup></mtd><mtd><mi>Y</mi><msup><mrow></mrow><mi>n</mi></msup></mtd><mtd><mi>Ζ</mi><msup><mrow></mrow><mi>n</mi></msup></mtd></mtr></mtable><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中<b><i>R</i></b><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mi>n</mi></msubsup></mrow></math></mathml>即为坐标系<i>n</i>到坐标系<i>b</i>下的变换矩阵。常定义的欧拉角形式的方向余弦矩阵为:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">R</mi><msubsup><mrow></mrow><mi>b</mi><mi>n</mi></msubsup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi><mo>-</mo><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi><mo>+</mo><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd></mtr><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi><mo>+</mo><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext><mspace width="0.25em" /><mi>sin</mi><mspace width="0.25em" /><mi>φ</mi><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mi>φ</mi></mtd></mtr><mtr><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><mspace width="0.25em" /><mi>cos</mi><mspace width="0.25em" /><mtext>ϕ</mtext></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">通过<i>Z</i>-<i>Y</i>-<i>X</i>顺序的三次旋转与计算后得到在常用惯性坐标系中可以反映运动真实状态的加速度传感器数据, 保留原有的数据特征的同时准确描述了用户的运动情况。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag">2 基于支持向量机的身份识别</h3>
                <div class="p1">
                    <p id="70">支持向量机是机器学习领域有监督学习模型的常见分类算法, 常用来进行模式识别、数据分类以及回归分析, 通过一个非线性映射把样本空间映射到一个高维乃至无穷维的特征空间中, 使得在原来的样本空间中线性不可分的问题转化为在特征空间中的线性可分的问题。该算法可用于解决的现实问题有很多:</p>
                </div>
                <div class="p1">
                    <p id="71">1) 对文本和超文本的分类效果较好, 支持向量机分类器在其中可以为应用程序显著减少对标准感应和转换设置中标记的训练实例的需求;</p>
                </div>
                <div class="p1">
                    <p id="72">2) 视频中的图像分类使用支持向量机分类器搜索精度要比传统的查询优化方案高得多, 包括使用特权方法的修改版的支持向量机系统;</p>
                </div>
                <div class="p1">
                    <p id="73">3) 支持向量机分类器可对手写的字符进行高精度的识别, 目前在国内的研究中在自然语言处理与语义消歧等领域已有广泛应用;</p>
                </div>
                <div class="p1">
                    <p id="74">4) 在生物科学领域中支持向量机分类器的引入有效提高了高分子蛋白等复杂模型的分类结果。</p>
                </div>
                <div class="p1">
                    <p id="75">该分类器的主要思想可概括为以下两点:</p>
                </div>
                <div class="p1">
                    <p id="76">1) 针对线性可分情况进行分析, 对于线性不可分的情况常通过使用非线性映射算法将低维输入空间线性不可分的样本转化为高维特征空间使其线性可分, 从而使得高维特征空间采用线性算法对样本的非线性特征进行线性分析成为可能。</p>
                </div>
                <div class="p1">
                    <p id="77">2) 在基于结构风险最小化理论之上在特征空间中构建最优超平面, 对空间中的数据点进行分类, 保证在数据训练阶段学习器可以得到全局最优化的分类结果, 且在整个样本空间的期望以某个概率满足预测的一定上界。</p>
                </div>
                <div class="p1">
                    <p id="78">传统可穿戴式的传感器产生数据后需要特殊媒介或可靠无线网络数据传输后离线进行分析和预测, 无法做到实时性的身份识别;使用智能手机内置加速度传感器进行身份认证时该识别程序可直接在手机内存空间上运行, 降低了数据传输的资源开销同时节省了识别过程总用时, 还可以有效实现对身份的实时识别。而在利用加速度传感器数据进行身份识别的传统方法中为提高结果的准确率多采用复杂度和实现难度高的算法 (如随机森林、神经网络等) 对数据进行分类处理, 由于忽略了分析数据特征的重要性导致实现难度高造成不必要的资源浪费。身份识别研究的本质可归结为二分类问题, 目前支持向量机算法在处理该类问题的算法中性能最为突出, 适合用于识别由用户切换导致的步态特征变化。</p>
                </div>
                <div class="p1">
                    <p id="79">由于加速度传感器数据是线性不可分的, 首先利用核函数将其映射到高维空间, 在高维空间非线性的问题转化为线性可分的问题。本实验选用的是线性核函数<i>K</i> (<b><i>x</i></b>, <b><i>y</i></b>) =<b><i>x</i></b><sup>T</sup><b><i>y</i></b>。设<b><i>x</i></b>为输入向量, 即样本集合中的向量;<b><i>w</i></b>为可调权值向量, 是每个向量可调权值;<b><i>b</i></b>为偏置, 即超平面相对原点的偏移。使用<i>U</i><sub>+1</sub>、<i>U</i><sub>-1</sub>分别表示两个类+1和-1, 则有需求的决策曲面方程如下:</p>
                </div>
                <div class="p1">
                    <p id="80"><b><i>w</i></b><sup>T</sup><b><i>x</i></b>+<b><i>b</i></b>=0      (6) </p>
                </div>
                <div class="p1">
                    <p id="81">设<b><i>x</i></b><sub><i>p</i></sub>为<b><i>x</i></b>在最优超平面<i>g</i> (<b><i>x</i></b>) 上的正轴投影, 因<b><i>x</i></b><sub><i>p</i></sub>在平面<i>g</i> (<b><i>x</i></b>) 上, 故有<i>g</i> (<b><i>x</i></b><sub><i>p</i></sub>) =0。则有:</p>
                </div>
                <div class="p1">
                    <p id="82"><b><i>x</i></b>=<b><i>x</i></b><sub><i>p</i></sub>+<i>r</i><b><i>w</i></b><sub>0</sub>/‖<b><i>w</i></b><sub>0</sub>‖      (7) </p>
                </div>
                <div class="p1">
                    <p id="83">将等式 (7) 代入<i>g</i> (<b><i>x</i></b>) =<b><i>w</i></b><sup>T</sup><sub>0</sub><b><i>x</i></b>+<b><i>b</i></b><sub>0</sub>, 则得到<b><i>x</i></b>点到最优超平面的代数距离<i>r</i>为:</p>
                </div>
                <div class="p1">
                    <p id="84"><i>r</i>=<i>g</i> (<b><i>x</i></b>) /‖<b><i>w</i></b>‖      (8) </p>
                </div>
                <div class="p1">
                    <p id="85">根据逻辑回归定义将式 (6) 展开得:</p>
                </div>
                <div class="p1">
                    <p id="86"><b><i>w</i></b><sub>0</sub><b><i>x</i></b><sub>0</sub>+<b><i>w</i></b><sub>1</sub><b><i>x</i></b><sub>1</sub>+<b><i>w</i></b><sub>2</sub><b><i>x</i></b><sub>2</sub>+…+<b><i>w</i></b><sub><i>n</i></sub><b><i>x</i></b><sub><i>n</i></sub>=0      (9) </p>
                </div>
                <div class="p1">
                    <p id="87">其中假设约定<b><i>x</i></b><sub>0</sub>∈<i>U</i><sub>+1</sub>, 于是有<b><i>w</i></b><sub>0</sub><b><i>x</i></b><sub>0</sub>=<b><i>w</i></b><sub>0</sub>, 将<b><i>w</i></b><sub>0</sub>替换成<b><i>b</i></b>, 则有:</p>
                </div>
                <div class="p1">
                    <p id="88"><b><i>b</i></b>+<b><i>w</i></b><sub>1</sub><b><i>x</i></b><sub>1</sub>+<b><i>w</i></b><sub>2</sub><b><i>x</i></b><sub>2</sub>+…+<b><i>w</i></b><sub><i>n</i></sub><b><i>x</i></b><sub><i>n</i></sub>=0      (10) </p>
                </div>
                <div class="p1">
                    <p id="89">将等式 (11) 整理得:</p>
                </div>
                <div class="p1">
                    <p id="90"><b><i>w</i></b><sub>1</sub><b><i>x</i></b><sub>1</sub>+<b><i>w</i></b><sub>2</sub><b><i>x</i></b><sub>2</sub>+…+<b><i>w</i></b><sub><i>n</i></sub><b><i>x</i></b><sub><i>n</i></sub>=<b><i>w</i></b><sup>T</sup><b><i>x</i></b>=-<b><i>b</i></b>      (11) </p>
                </div>
                <div class="p1">
                    <p id="91">当对任意点分类时, 有分类结果如下:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo>≥</mo><mn>0</mn><mo>;</mo><mtext> </mtext><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><msub><mrow></mrow><mrow><mo>+</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo>&lt;</mo><mn>0</mn><mo>;</mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><msub><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">通过训练力求找到参数<i>α</i>的一个向量, 使正规化损失函数式 (13) 最小:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>λ</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">[</mo></mstyle><mn>1</mn><mo>-</mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mi mathvariant="bold-italic">Κ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></msup><mi mathvariant="bold-italic">α</mi><mo stretchy="false">]</mo><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi mathvariant="bold-italic">α</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Κ</mi><mi mathvariant="bold-italic">α</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中<b><i>K</i></b>=[<b><i>K</i></b> (<b><i>x</i></b><sup> (<i>i</i>) </sup>, <b><i>x</i></b><sup> (<i>j</i>) </sup>) ]<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow></math></mathml>=[<b><i>K</i></b><sup> (1) </sup><b><i>K</i></b><sup> (2) </sup> … <b><i>K</i></b><sup> (<i>m</i>) </sup>]。</p>
                </div>
                <div class="p1">
                    <p id="97">考虑到训练数据量与计算能力的限制, 实验选择使用正则化权值参数, 在测试数据集上也得到了较好效果。测试数据点经支持向量机算法分类后归属的预测类即为该点与决策边界的标记距离最大的类。</p>
                </div>
                <h3 id="98" name="98" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="99" name="99">3.1 <b>实验数据采集</b></h4>
                <div class="p1">
                    <p id="100">在实验数据采集阶段利用<i>Android</i>系统研发工具<i>Android Studio</i>集成一个小型应用程序进行数据的采集, 根据数据特征对采样频率、记录数据对象和写入存储卡方式等进行调整。目前<i>Android</i>、<i>IOS</i>或黑莓等常见系统上均没有对无需许可的传感器进行特殊管理或保护其数据信息流的管理控制机制, 即任意应用程序都可通过访问传感器应用程序接口从而访问所有无需许可的传感器并获取其数据, 这亦是本实验数据采集框架的理论基础。</p>
                </div>
                <div class="p1">
                    <p id="101">传感器应用程序接口是一组定义程序及协议的集合, 通过该接口实现应用程序之间、应用程序与传感器硬件、传感器硬件之间的相互通信;其主要功能是提供通用功能集, 为应用程序开发人员提供可以访问的一组例程, 而又无需访问源码或理解其内部工作机制的细节, 这样程序开发人员在开发应用程序时可通过调用应用程序接口提供的函数直接对应用程序进行开发, 减轻了研发过程中的人工编程任务。应用程序接口同时也可视为一种中间件, 为不同平台的工作提供各种数据来源, 即达到资源高度利用与共享的功能。</p>
                </div>
                <div class="p1">
                    <p id="102">本文实验在<i>Android</i>系统智能手机上完成, 数据采集和处理方法经适当调整可推广到其他系统的智能手机上。在数据采集阶段首先利用<i>Android</i>智能手机内部传感器组织框架集成了一个小型应用程序用于获取实验所需的无许可传感器数据。为方便数据导出, 首先将存储卡的数据读写权限授予该应用程序, 然后导入可处理监听事件的硬件监听, 同时对实验用到的传感器逐一注册监听器, 最后利用<i>Android</i>调试工具生成<i>Android</i>应用程序安装包 (<i>Android PacKage</i>, <i>APK</i>) , 导入手机安装成功后在开启状态下即可监听传感器产生的数据并写入指定列表。图6展示了<i>Android</i>系统如何通过由用户安装的应用程序和由生产商自动安装的系统应用程序来处理来自不同的传感器访问。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Android传感器管理系统" src="Detail/GetImg?filename=images/JSJY201906033_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 <i>Android</i>传感器管理系统  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Android sensor management system</i></p>

                </div>
                <div class="p1">
                    <p id="104">系统应用程序在手机出厂时已完成安装, 通常情况下用户购买后使用时无法卸载或修改权限。而非系统应用程序在安装时首先通过开发工具包向应用程序接口平台发送访问传感器请求, 然后将应用程序注册到相应的传感器;如果多个应用程序同时尝试注册相同的传感器, 应用程序接口平台会运行多路复用程序, 使不同的应用程序可在同一个传感器中同时注册。硬件抽象层 (<i>Hardware Abstract Layer</i>, <i>HAL</i>) 是系统内的一个接口, 将传感器硬件与系统的设备驱动程序相互绑定。硬件抽象层具体由<i>Sensors</i>.<i>h</i>和<i>Sensors</i>.<i>cpp</i>两部分组成, <i>Sensors</i>.<i>h</i>是硬件抽象层的接口, <i>Sensors</i>.<i>cpp</i>为硬件抽象层实现具体指令的工作。</p>
                </div>
                <div class="p1">
                    <p id="105">通过硬件抽象层的本机库, 不同的应用程序可以与底层的<i>Linux</i>内核通信, 读取和写入与制定的传感器相关的文件。目前对于大多数无需许可的传感器而言访问这些文件是不需要任何权限的。而对于需许可的传感器则首先需要用户一个明确的授权指令, 以确保应用程序可以正确地访问一个特定文件。用户授权信息会在系统清单中具体声明, 一旦用户在安装程序之初选择接受, 后期即使在没有其他明确许可的情况下该应用程序也可以直接访问其他无许可传感器。同时<i>Android</i>系统传感器框架可用来访问设备的内置传感器, 并提供了有助于完成数据采集工作的大量接口, 这些接口可用于在采集中确定内置传感器种类, 并在注册和注销传感器权限时执行监听。</p>
                </div>
                <div class="p1">
                    <p id="106">图7为采集的三个用户手持手机步行时<i>Y</i>轴的数据信息, 可见存在极强的个体差异性, 身份表示性明显。由于该应用程序未通过专业评估系统的应用安全认证与重点病毒排查等检测, 不适合于广泛的安装与使用, 故实验数据采集的过程均在同一部三星Note 3智能手机上进行。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同用户步态数据信息比对" src="Detail/GetImg?filename=images/JSJY201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同用户步态数据信息比对  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison of gait data information among different users</p>

                </div>
                <h4 class="anchor-tag" id="108" name="108">3.2 <b>实验特征选取</b></h4>
                <div class="p1">
                    <p id="109">正常成年人的步行过程是按照规律性动作进行的, 左脚和右脚各向前一步称为一个完整的步态周期。在本文中, 通过加速度传感器<i>Y</i>轴极小值将数据划分成多个小周期, 即可方便定位出数据所对应的每个步态周期。根据统计显示, 一个步态周期的平均时间约为1 s, 为实验计算方便起见将加速度传感器的采样设置频率为50 Hz, 即1 s取数值50次。对步态特征的选取包括时域特征、频域特征和数据统计特征, 这些特征都是以一个完整的步态周期为单位的。</p>
                </div>
                <div class="p1">
                    <p id="110">实验中所用的主要特征如表2所示。</p>
                </div>
                <div class="area_img" id="111">
                    <p class="img_tit"><b>表</b>2 <b>步态特征身份识别所用的部分特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Some features used in gait feature identification</p>
                    <p class="img_note"></p>
                    <table id="111" border="1"><tr><td><br />特征</td><td>描述</td></tr><tr><td><br />极大值</td><td>一个步态周期内<i>X</i>、<i>Y</i>、<i>Z</i>上的最大值</td></tr><tr><td><br />极小值</td><td>一个步态周期内<i>X</i>、<i>Y</i>、<i>Z</i>上的最小值</td></tr><tr><td><br />标准偏差</td><td><i>X</i>、<i>Y</i>、<i>Z</i>三个方向的数值在1 s内误差上下波动的幅度</td></tr><tr><td><br />均方根</td><td><i>X</i>、<i>Y</i>、<i>Z</i>三个方向数值的平方和除以3后开平方的结果</td></tr><tr><td><br />能量</td><td>在<i>X</i>、<i>Y</i>、<i>Z</i>三个方向所做的功</td></tr><tr><td><br />直方图分布</td><td>统计样本和该样本与对应属性之间的度量关系</td></tr><tr><td><br />百分位数值</td><td>数据集中此样本值以下的样本数占总样本数的百分比</td></tr><tr><td><br />平均绝对<br />偏差</td><td>每个数值与其算术平均值的偏差的绝对值的平均</td></tr><tr><td><br />步频</td><td>1 min内所含完整步态周期的个数</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="112">其中, 均方根 (Root Mean Square, RMS) 在电力学中较常见, 是交流电波的有效电压或电流的一种普遍的数学表示方法;标准偏差即标准差, 在概率统计论中常作统计分布程度 (statistical dispersion) 上的测量, 定义为方差的算术平方根, 反映组内个体间的离散程度, 该概念是由卡尔·皮尔逊 (Karl Pearson) 引入到统计学中的。标准差和方差都可反映出一个数据集的离散程度, 当样本的平均数相同时标准差却未必相同。</p>
                </div>
                <div class="p1">
                    <p id="113">根据研究本文引入了一个在身份识别领域不常用的特征:梅尔频率倒谱系数 (Mel-Frequency Cepstral Coefficients, MFCCs) 。梅尔频率倒谱系数 (MFCCs) 即组成梅尔频率倒谱的系数。梅尔频率是基于人耳听觉特性提出的, 与赫兹频率成非线性对应关系, 主要用于语音数据特征的提取和降低运算维度。在本文中梅尔频率倒谱系数用于表示离散的余弦变换相关参数组, 通过对计算输出能量的变换后再次进行计算而得到的, 这些能量是计算机系统经过自动的特殊处理通过集合的形式导出的。与时域特征相同的是, 梅尔频率倒谱系数需要对每个方向上的梅尔频率分别进行计算。</p>
                </div>
                <div class="p1">
                    <p id="114">为得到理想的识别效果, 本文利用不同特征组合进行多次实验, 利用平均准确率来测评不同特征组合通过支持向量机训练后对用户步态特征变化的识别情况, 测试的实验过程及具体结果将在下面具体描述。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">3.3 <b>实验过程与分析</b></h4>
                <div class="p1">
                    <p id="116">数据采集阶段共有20名不同年龄、不同身高、不同性别、不同职业的志愿者参与, 每名志愿者手持手机步行的时间大约为15 <i>min</i> (去除步行起始与结束导致的不平稳段数据) , 统一在光线、摩擦系数等客观因素均相同的光滑大理石走廊进行手持手机步行的行为。每个志愿者的步行数据前70%用于训练, 形成个人独有的步态特征数据画像, 后30%用于后续的实验测试部分。</p>
                </div>
                <div class="p1">
                    <p id="117">为保护这些志愿者的个人隐私, 将他们的个人信息隐去, 在实验中进行1～20的编号, 故在数据训练阶段结束后将得到20个独立的用户步行数据特征画像。在实验测试的准备阶段, 将1号画像数据取2 <i>s</i>分别与2～20号画像的2 <i>s</i>数据进行拼接作为输入 (以此类推至最后一组19号与20号) , 完成一次测试后将两组拼接的数据进行位置互换然后再重复实验, 用于检测支持向量机是否能准确检测出用户的切换。故实验的测试阶段共有 (19+18+…+2+1) ×2=380小组的实验。</p>
                </div>
                <div class="p1">
                    <p id="118">根据对特征的分析, 将7个特征首先由少至多组合, 然后分别对支持向量机分类器进行训练和测试, 所选用的特征数量与识别准确率关系如表3所示。可见测试实验从“<i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量”3个特征组合逐个增加, 至“<i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量+<i>Z</i>轴均方根+步频+<i>Z</i>轴梅尔频率倒谱系数+<i>X</i>轴梅尔频率倒谱系数”7个特征的组合。根据表3所示, 实验结果显示增加步频后识别准确率大幅度提升, 表明步频对用户步态特征具有很强的代表性。</p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit"><b>表</b>3 <b>选用的特征与识别准确率关系</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Relationship between features selected and recognition accuracy</p>
                    <p class="img_note"></p>
                    <table id="119" border="1"><tr><td><br />特征组合</td><td>准确率/%</td></tr><tr><td><br /><i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量</td><td>47.26</td></tr><tr><td><br /><i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量+<i>Z</i>轴均方根</td><td>53.84</td></tr><tr><td><br /><i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量+<br /><i>Z</i>轴均方根+步频</td><td>87.26</td></tr><tr><td><br /><i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量+<br /><i>Z</i>轴均方根+步频+<i>Z</i>轴梅尔频率倒谱系数</td><td>89.95</td></tr><tr><td><br /><i>Y</i>轴极小值+<i>Z</i>轴极大值+<i>Z</i>轴能量+<i>Z</i>轴均方根+<br />步频+<i>Z</i>轴梅尔频率倒谱系数+<i>X</i>轴梅尔频率倒谱系数</td><td>95.53</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="120">从测试结果看, 本文利用数据特征对个人步态进行的描述越具体, 最后的识别准确率越高, 7个特征的组合可达到95.53%的识别准确率, 验证了该方法的有效性。由于数据集规模的限制, 增加特征后识别时间随之递增但空间占用增加不大, 后续可适当增加特征的数量, 扩展训练样本数据集, 寻找对用户步态特征描述更加准确的数据特征。</p>
                </div>
                <div class="p1">
                    <p id="121">对比国内外相似的研究, 文献<citation id="187" type="reference">[<a class="sup">15</a>]</citation>没有对手机自定义坐标轴的数据进行处理, 得到92%左右的识别准确率, 过程中数据处理难度高且空间开销大;文献<citation id="188" type="reference">[<a class="sup">16</a>]</citation>集成的客户端加入了计步功能, 其中识别部分利用了四元数的空间转换方法, 其实现复杂程度大于欧拉角法, 但效果上无明显改善。</p>
                </div>
                <h3 id="122" name="122" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="123">本文提出了基于智能手机加速度传感器数据的步态身份识别方法, 并通过实验验证了其有效性, 在用户发生变换时可准确识别出特征值的变化, 达到了身份识别的自动预警功能, 可在改进优化后在其他型号的智能手机上推广使用。在资源条件允许的情况下应适当增加训练数据集的数据量, 可更准确地对用户进行行为特征画像, 进一步提高了识别的准确率。目前个人手机内存储了大量隐私相关的信息与数据, 一旦遗失不仅会对生活与工作造成麻烦, 还有可能泄露个人隐私甚至是商业机密。基于步态特征识别技术的发展与推广使用还可促进智能手机防盗功能的发展, 如为用户建立个人传感器行为数据画像, 当识别出当前时间段的运动或使用行为与正常模式下的特性发生变化时, 系统可自动预告与预警 (如通知紧急联系人) , 或开启数据保护功能 (如长久锁屏、禁用<i>USB</i>接口等) 。</p>
                </div>
                <div class="p1">
                    <p id="124">目前指纹识别、人脸识别等基于生物特征的生物识别技术在日常生活的多领域已有广泛应用, 虹膜识别、<i>DNA</i>识别等需要高端科技配合的手段仍处于实验阶段;随着研究成果的出现和数据来源的丰富, 基于行为特征的身份识别技术正蓬勃发展, 将成为该领域的新热点。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="141">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZZZ201810042&amp;v=Mjc0MDFyQ1VSN3FmWnVac0Z5N2xXcjdNSVRmUmRMRzRIOW5OcjQ5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>李鹏飞, 淡美俊, 姚宇颤.生物识别技术综述[J].电子制作, 2018 (10) :89-90. (LI P F, DAN M J, YAO Y Z.Overview of biometric identification technology[J].Practical Electronics, 2018 (10) :89-90.) 
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKJ201715021&amp;v=MDA5NDU3cWZadVpzRnk3bFdyN01MU1BBWkxHNEg5Yk5xbzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>王俊山, 张文明.生物识别技术的类别及其在身份识别中的应用[J].河南科技, 2017 (15) :34-35. (WANG J S, ZHANG W M.The category of biometric chip and its application in identity[J].Journal of Henan Science and Technology, 2017 (15) :34-35.) 
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXZ201803016&amp;v=MjQ2NDFyQ1VSN3FmWnVac0Z5N2xXcjdNSVNIVGRMRzRIOW5Nckk5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>陈虹旭, 李晓坤, 郑永亮, 等.基于深度学习的指纹识别方法研究[J].智能计算机与应用, 2018, 8 (3) :64-69. (CHEN H X, LI X K, ZHENG Y L, et al.Research on fingerprint recognition method based on deep learning[J].Intelligent Computer and Applications, 2008, 8 (3) :64-69.) 
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUDO201806014&amp;v=MDU3MzR6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I3TUlqalBZYkc0SDluTXFZOUVZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>张笛.人脸识别现状与发展趋势研究[J].广东通信技术, 2018, 38 (6) :43-48. (ZHANG D.Research on the status quo and development trend of face recognition[J].Guangdong Communication Technology, 2008, 38 (06) :43-48.) 
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKJ201716028&amp;v=MDQ2NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I3TUxTUEFaTEc0SDliTnFZOUhiSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>马璐璐, 朱雪珍.虹膜识别专利技术综述[J].河南科技, 2017 (16) :55-57. (MA L L, ZHU X Z.Review on the patent technology of iris recognition[J].Journal of Henan Science and Technology, 2017 (16) :55-57.) 
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Identifying people from gait pattern with accelerometers">

                                <b>[6]</b>AILISTO H J, LINDHOLM M, MANTYJARVI J, et al.Identifying people from gait pattern with accelerometers[C]//Proceedings of SPIE 5779-the International Society for Optical Engineering, Biometric Technology for Human Identification II.Bellingham:SPIE, 2005:7-14.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unobtrusive User-authentication onmobile phones using Biometric gait recognition">

                                <b>[7]</b>DERAWI M O, NICKEL C, BOURS P, et al.Unobtrusive user-authentication on mobile phones using biometric gait recognition[C]//Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing.Washington, DC:IEEE Computer Society, 2010:474-479.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gait identification using accelerometer on mobile phone">

                                <b>[8]</b>THANG H M, VIET V Q, THUC N D, et al.Gait identification using accelerometer on mobile phone[C]//Proceedings of the2012 International Conference on Control, Automation and Information Sciences.Piscataway, NJ:IEEE, 2012:344-348.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scenario test of accelerometer-based biometric gait recognition">

                                <b>[9]</b>NICKEL C, DERAWI M O, BOURS P, et al.Scenario test of accelerometer-based biometric gait recognition[C]//Proceedings of the 2014 Third International Workshop on Security&amp;Communication Networks.Piscataway, NJ:IEEE, 2014:167-174.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Cross-Device Gait Recognition Using a Mobile Accelerometer">

                                <b>[10]</b>HOANG T, NGUYEN T, LUONG C, et al.Adaptive cross-device gait recognition using a mobile accelerometer[J].Journal of Information Processing Systems, 2013, 9 (2) :333-348.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712042&amp;v=MzI1NzQ3bFdyN01MejdCYmJHNEg5Yk5yWTlCWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>刘冠群, 罗桂琼, 谭平.基于类Haar特征模板匹配的多镜头步态识别算法[J].计算机工程, 2017, 43 (12) :231-236. (LIU GQ, LUO G Q, TAN P.Multiple Lens gait recognition algorithm based on category Haar feature template matching[J].Computer Engineering, 2017, 43 (12) :231-236.) 
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCJG201706011&amp;v=MDk3NTh0R0ZyQ1VSN3FmWnVac0Z5N2xXcjdNTmk3QmFiRzRIOWJNcVk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>佟苏洋, 和焕胤, 汤澄清.基于足底压力分析系统对青年人行走步态特征稳定性的研究[J].四川警察学院学报, 2017, 29 (6) :77-83. (TONG S Y, HE H Y, TANG C Q.Stability of the youth's gait characteristics in walking based on the plantar pressure analysis system[J].Journal of Sichuan Police College, 2017, 29 (6) :77-83.) 
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115266026001&amp;v=MzExMTM5UEtxWTlIWXVzUERSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3bklLVjhRWEZxekdiSzVH&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>KOMARINENI S, MACLEAN D, HASHIMI S.精通Android 3[M].杨越, 译.北京:人民邮电出版社, 2011:728-733. (KOMARINE-NI S, MACLEAN D.Pro Android 3[M].YANG Y, translated.Beijing:Post&amp;Telecom Press, 2011:728-733.) 
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787560626673001&amp;v=MTIyNDh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3bklLVjhRWEZxekdiYStIdGZPcVlsQ1orc1BEUk04&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>张勇, 夏家莉, 陈滨, 等.Google Android开发技术[M].西安:西安电子科技大学出版社, 2011:124-127. (ZHANG Y, XIA JL, CHEN B, et al.Google Android Development Technology[M].Xi'an:Xidian University Press, 2011:124-127.) 
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Smart kiosk with gait-based continuous authentication">

                                <b>[15]</b>PHAN D-T, DAM N N-T, NGUYEN M-P, et al.Smart kiosk with gait-based continuous authentication[C]//Proceedings of the 2015International Conference on Distributed, Ambient, and Pervasive Interactions, LNCS 9189.Cham:Springer, 2015:110-115.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991575.nh&amp;v=MDg0ODg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeTdsV3I3TVZGMjZGcnF4SDlUTHFwRWJQSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>侯东谷.基于智能手机的人体步态识别及其应用[D].成都:电子科技大学, 2018:58-71. (HOU D G.Human gait recognition and its application based on smart phones[D].Chengdu:U-niversity of Electronic Science and Technology of China, 2018:58-71.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906033" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906033&amp;v=MDc0NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnk3bFdyN01MejdCZDdHNEg5ak1xWTlHWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
