<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136763025283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201905006%26RESULT%3d1%26SIGN%3dmtMiTWHQocWdUPy2t5WJhOBC3lM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905006&amp;v=MTk3Mjl1WnNGeURtVnJ2Qkx6N0JkN0c0SDlqTXFvOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#43" data-title="1 鲁棒非负矩阵分解 ">1 鲁棒非负矩阵分解</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="2 稀疏限制的增量式鲁棒非负矩阵分解 ">2 稀疏限制的增量式鲁棒非负矩阵分解</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="3 实验结果及其结论 ">3 实验结果及其结论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#131" data-title="3.1 &lt;b&gt;数据描述及参数设置&lt;/b&gt;">3.1 <b>数据描述及参数设置</b></a></li>
                                                <li><a href="#139" data-title="3.2 &lt;b&gt;收敛效果对比&lt;/b&gt;">3.2 <b>收敛效果对比</b></a></li>
                                                <li><a href="#147" data-title="3.3 &lt;b&gt;聚类准确率对比&lt;/b&gt;">3.3 <b>聚类准确率对比</b></a></li>
                                                <li><a href="#157" data-title="3.4 &lt;b&gt;运行时间对比&lt;/b&gt;">3.4 <b>运行时间对比</b></a></li>
                                                <li><a href="#160" data-title="3.5 &lt;b&gt;稀疏限制的度量&lt;/b&gt;">3.5 <b>稀疏限制的度量</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#169" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#135" data-title="图1 2组人脸数据库中的部分图像示例">图1 2组人脸数据库中的部分图像示例</a></li>
                                                <li><a href="#141" data-title="图2 三种算法在两个人脸数据库中的收敛性对比">图2 三种算法在两个人脸数据库中的收敛性对比</a></li>
                                                <li><a href="#144" data-title="图3 IRNMFSC在基向量个数&lt;i&gt;r&lt;/i&gt;取不同值时的收敛情况">图3 IRNMFSC在基向量个数<i>r</i>取不同值时的收敛情况</a></li>
                                                <li><a href="#153" data-title="图4 三种算法在YALE人脸数据库中随着新增样本个数增加时的收敛情况">图4 三种算法在YALE人脸数据库中随着新增样本个数增加时的收敛情况</a></li>
                                                <li><a href="#154" data-title="图5 三种算法在ORL人脸数据库中随着新增样本个数增加时的收敛情况">图5 三种算法在ORL人脸数据库中随着新增样本个数增加时的收敛情况</a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;人脸数据库在不同算法的聚类精确率&lt;/b&gt;"><b>表</b>1 <b>人脸数据库在不同算法的聚类精确率</b></a></li>
                                                <li><a href="#166" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;人脸数据库随着新增不同量训练样本时算法所消耗的时间&lt;/b&gt;"><b>表</b>2 <b>人脸数据库随着新增不同量训练样本时算法所消耗的时间</b></a></li>
                                                <li><a href="#167" data-title="图6 YALE人脸数据集的基图像 (&lt;i&gt;r&lt;/i&gt;=20) ">图6 YALE人脸数据集的基图像 (<i>r</i>=20) </a></li>
                                                <li><a href="#168" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;几种算法得到的因子矩阵稀疏度&lt;/b&gt;"><b>表</b>3 <b>几种算法得到的因子矩阵稀疏度</b></a></li>
                                                <li><a href="#171" data-title="图7 &lt;i&gt;ORL&lt;/i&gt;人脸数据集的基图像 (r=30) ">图7 <i>ORL</i>人脸数据集的基图像 (r=30) </a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" &lt;i&gt;PARDALOS P M&lt;/i&gt;.&lt;i&gt;Approximate Dynamic Programming&lt;/i&gt;:&lt;i&gt;Solving the Curses of Dimensionality&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;Wiley&lt;/i&gt;, 2009:39-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Approximate Dynamic Programming:Solving the Curses of Dimensionality">
                                        <b>[1]</b>
                                         &lt;i&gt;PARDALOS P M&lt;/i&gt;.&lt;i&gt;Approximate Dynamic Programming&lt;/i&gt;:&lt;i&gt;Solving the Curses of Dimensionality&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;Wiley&lt;/i&gt;, 2009:39-50.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 史卫亚, 郭跃飞, 薛向阳.一种解决大规模数据集问题的核主成分分析算法[&lt;i&gt;J&lt;/i&gt;].软件学报, 2009, 8 (20) :2153-2159. (&lt;i&gt;SHI W Y&lt;/i&gt;, &lt;i&gt;GUO Y F&lt;/i&gt;, &lt;i&gt;XUE X Y&lt;/i&gt;.&lt;i&gt;A kernel principal component analysis algorithm for solving large scale data sets problem&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Software&lt;/i&gt;, 2009, 8 (20) :2153-2159.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200908015&amp;v=MDI0NDdmWnVac0Z5RG1WcnZCTnlmVGJMRzRIdGpNcDQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         史卫亚, 郭跃飞, 薛向阳.一种解决大规模数据集问题的核主成分分析算法[&lt;i&gt;J&lt;/i&gt;].软件学报, 2009, 8 (20) :2153-2159. (&lt;i&gt;SHI W Y&lt;/i&gt;, &lt;i&gt;GUO Y F&lt;/i&gt;, &lt;i&gt;XUE X Y&lt;/i&gt;.&lt;i&gt;A kernel principal component analysis algorithm for solving large scale data sets problem&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Software&lt;/i&gt;, 2009, 8 (20) :2153-2159.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 张燕平, 窦蓉蓉, 赵姝, 等.基于集成学习的规范化&lt;i&gt;LDA&lt;/i&gt;人脸识别[&lt;i&gt;J&lt;/i&gt;].计算机工程, 2010, 36 (14) :144-146. (&lt;i&gt;ZHANG Y P&lt;/i&gt;, &lt;i&gt;DOU R R&lt;/i&gt;, &lt;i&gt;ZHAO S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Regularized linear discriminant analysis for face recognition based on ensemble learning&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Computer Engineering&lt;/i&gt;, 2010, 36 (14) :144-146.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201014055&amp;v=MTIyNzMzenFxQnRHRnJDVVI3cWZadVpzRnlEbVZydkJMejdCYmJHNEg5SE5xNDlBWVlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         张燕平, 窦蓉蓉, 赵姝, 等.基于集成学习的规范化&lt;i&gt;LDA&lt;/i&gt;人脸识别[&lt;i&gt;J&lt;/i&gt;].计算机工程, 2010, 36 (14) :144-146. (&lt;i&gt;ZHANG Y P&lt;/i&gt;, &lt;i&gt;DOU R R&lt;/i&gt;, &lt;i&gt;ZHAO S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Regularized linear discriminant analysis for face recognition based on ensemble learning&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Computer Engineering&lt;/i&gt;, 2010, 36 (14) :144-146.) 
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" &lt;i&gt;KOLDOVSKY Z&lt;/i&gt;, &lt;i&gt;TICHAVSKY P&lt;/i&gt;.&lt;i&gt;Efficient variant of algorithm fastica for independent component analysis attaining the cramer&lt;/i&gt;-&lt;i&gt;RAO lower bound&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2005 &lt;i&gt;IEEE&lt;/i&gt;/&lt;i&gt;SP Workshop on Statistical Signal Processing&lt;/i&gt;.&lt;i&gt;Piscataway&lt;/i&gt;, &lt;i&gt;NJ&lt;/i&gt;:&lt;i&gt;IEEE&lt;/i&gt;, 2005:1090-1095." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient variant of algorithm Fast ICA for independent component analysis attaining the Cramer-RAO lower bound">
                                        <b>[4]</b>
                                         &lt;i&gt;KOLDOVSKY Z&lt;/i&gt;, &lt;i&gt;TICHAVSKY P&lt;/i&gt;.&lt;i&gt;Efficient variant of algorithm fastica for independent component analysis attaining the cramer&lt;/i&gt;-&lt;i&gt;RAO lower bound&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2005 &lt;i&gt;IEEE&lt;/i&gt;/&lt;i&gt;SP Workshop on Statistical Signal Processing&lt;/i&gt;.&lt;i&gt;Piscataway&lt;/i&gt;, &lt;i&gt;NJ&lt;/i&gt;:&lt;i&gt;IEEE&lt;/i&gt;, 2005:1090-1095.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" &lt;i&gt;GOLUB G H&lt;/i&gt;, &lt;i&gt;REINSCH C&lt;/i&gt;.&lt;i&gt;Singular Value Decomposition and&lt;/i&gt;&lt;i&gt;Least Squares Solutions&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Berlin&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 1971:403-420." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Singular Value Decomposition and Least Squares Solutions">
                                        <b>[5]</b>
                                         &lt;i&gt;GOLUB G H&lt;/i&gt;, &lt;i&gt;REINSCH C&lt;/i&gt;.&lt;i&gt;Singular Value Decomposition and&lt;/i&gt;&lt;i&gt;Least Squares Solutions&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Berlin&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 1971:403-420.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" &lt;i&gt;PAATERO P&lt;/i&gt;, &lt;i&gt;TAPPER U&lt;/i&gt;.&lt;i&gt;Positive matrix factorization&lt;/i&gt;:&lt;i&gt;a non&lt;/i&gt;-&lt;i&gt;negative factor model with optimal utilization of error estimates of data values&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Environmental Surveying&lt;/i&gt;, 1994, 5 (2) :111-126." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Positive matrix factorization: a non-negative factor model with optimal utilization of error estimates of data values">
                                        <b>[6]</b>
                                         &lt;i&gt;PAATERO P&lt;/i&gt;, &lt;i&gt;TAPPER U&lt;/i&gt;.&lt;i&gt;Positive matrix factorization&lt;/i&gt;:&lt;i&gt;a non&lt;/i&gt;-&lt;i&gt;negative factor model with optimal utilization of error estimates of data values&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Environmental Surveying&lt;/i&gt;, 1994, 5 (2) :111-126.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" &lt;i&gt;LEE D D&lt;/i&gt;, &lt;i&gt;SEUNG H S&lt;/i&gt;.&lt;i&gt;Learning the parts of objects with non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Nature&lt;/i&gt;, 1999, 401 (6755) :788-791." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning the parts of objects by non-negative matrix factorization">
                                        <b>[7]</b>
                                         &lt;i&gt;LEE D D&lt;/i&gt;, &lt;i&gt;SEUNG H S&lt;/i&gt;.&lt;i&gt;Learning the parts of objects with non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Nature&lt;/i&gt;, 1999, 401 (6755) :788-791.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" &lt;i&gt;LEE D D&lt;/i&gt;.&lt;i&gt;Algorithms for non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt;, 2001, 13 (6) :556-562." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Algorithms for non-negative matrix factorization">
                                        <b>[8]</b>
                                         &lt;i&gt;LEE D D&lt;/i&gt;.&lt;i&gt;Algorithms for non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt;, 2001, 13 (6) :556-562.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" &lt;i&gt;BUCAK S S&lt;/i&gt;, &lt;i&gt;GUNSEL B&lt;/i&gt;.&lt;i&gt;Incremental subspace learning via non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Pattern Recognition&lt;/i&gt;, 2009, 42 (5) :788-797." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738944&amp;v=MDUwOTdocz1OaWZPZmJLN0h0RE5xWTlGWStnSEJYZzlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lLRjBSYg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         &lt;i&gt;BUCAK S S&lt;/i&gt;, &lt;i&gt;GUNSEL B&lt;/i&gt;.&lt;i&gt;Incremental subspace learning via non&lt;/i&gt;-&lt;i&gt;negative matrix factorization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Pattern Recognition&lt;/i&gt;, 2009, 42 (5) :788-797.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" &lt;i&gt;YU Z Z&lt;/i&gt;, &lt;i&gt;LIU Y H&lt;/i&gt;, &lt;i&gt;LI B&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Incremental graph regulated non&lt;/i&gt;-&lt;i&gt;negative matrix factorization for face recognition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Applied Mathematics&lt;/i&gt;, 2014, 2014 (1) :&lt;i&gt;Article ID&lt;/i&gt; 928051." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD14060600000502&amp;v=MjUyMzZIdGZNcVk5RlpPc1BDWHc3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJS0YwUmJocz1OaWZEYXJLOA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         &lt;i&gt;YU Z Z&lt;/i&gt;, &lt;i&gt;LIU Y H&lt;/i&gt;, &lt;i&gt;LI B&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Incremental graph regulated non&lt;/i&gt;-&lt;i&gt;negative matrix factorization for face recognition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Applied Mathematics&lt;/i&gt;, 2014, 2014 (1) :&lt;i&gt;Article ID&lt;/i&gt; 928051.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" &lt;i&gt;KONG D&lt;/i&gt;, &lt;i&gt;HUANG H&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization using L&lt;/i&gt;21-&lt;i&gt;norm&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 20&lt;i&gt;th ACM International Conference on Information and Knowledge Management&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2011:673-682." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization using L21-norm">
                                        <b>[11]</b>
                                         &lt;i&gt;KONG D&lt;/i&gt;, &lt;i&gt;HUANG H&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization using L&lt;/i&gt;21-&lt;i&gt;norm&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 20&lt;i&gt;th ACM International Conference on Information and Knowledge Management&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2011:673-682.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" &lt;i&gt;HUANG S&lt;/i&gt;, &lt;i&gt;WANG H&lt;/i&gt;, &lt;i&gt;LI T&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust graph regularized non&lt;/i&gt;-&lt;i&gt;negative matrix factorization for clustering&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;ACM Transactions on Knowledge Discovery from Data&lt;/i&gt;, 2017, 11 (3) :&lt;i&gt;Article No&lt;/i&gt;.33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM0200EE102329DF63926D0493227B71A3&amp;v=MTgxOTB1SFlmT0dRbGZCckxVMDV0cGh6THU2eEtFPU5pZklZN082SHRHNTJvNUZadWdOQlFoUHlSVWE2RGtKU0h2cnJ4QTNmc0NUUk11Y0NPTnZGU2lXV3I3SklGcG1hQg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         &lt;i&gt;HUANG S&lt;/i&gt;, &lt;i&gt;WANG H&lt;/i&gt;, &lt;i&gt;LI T&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust graph regularized non&lt;/i&gt;-&lt;i&gt;negative matrix factorization for clustering&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;ACM Transactions on Knowledge Discovery from Data&lt;/i&gt;, 2017, 11 (3) :&lt;i&gt;Article No&lt;/i&gt;.33.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" &lt;i&gt;DAI L Y&lt;/i&gt;, &lt;i&gt;FENG C M&lt;/i&gt;, &lt;i&gt;LIU J X&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization via joint graph laplacian and discriminative information for identifying differentially expressed genes&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Complexity&lt;/i&gt;, 2017, 2017 (40) :&lt;i&gt;Article ID&lt;/i&gt; 4216797." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization via joint graph laplacian and discriminative information for identifying differentially expressed genes">
                                        <b>[13]</b>
                                         &lt;i&gt;DAI L Y&lt;/i&gt;, &lt;i&gt;FENG C M&lt;/i&gt;, &lt;i&gt;LIU J X&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization via joint graph laplacian and discriminative information for identifying differentially expressed genes&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Complexity&lt;/i&gt;, 2017, 2017 (40) :&lt;i&gt;Article ID&lt;/i&gt; 4216797.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" &lt;i&gt;YANG S&lt;/i&gt;, &lt;i&gt;HOU C&lt;/i&gt;, &lt;i&gt;ZHANG C&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization via joint sparse and graph regularization&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2013 &lt;i&gt;International Joint Conference on Neural Networks&lt;/i&gt;.&lt;i&gt;Piscataway&lt;/i&gt;, &lt;i&gt;NJ&lt;/i&gt;:&lt;i&gt;IEEE&lt;/i&gt;, 2014:541-559." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization via joint sparse and graph regularization">
                                        <b>[14]</b>
                                         &lt;i&gt;YANG S&lt;/i&gt;, &lt;i&gt;HOU C&lt;/i&gt;, &lt;i&gt;ZHANG C&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Robust non&lt;/i&gt;-&lt;i&gt;negative matrix factorization via joint sparse and graph regularization&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2013 &lt;i&gt;International Joint Conference on Neural Networks&lt;/i&gt;.&lt;i&gt;Piscataway&lt;/i&gt;, &lt;i&gt;NJ&lt;/i&gt;:&lt;i&gt;IEEE&lt;/i&gt;, 2014:541-559.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" &lt;i&gt;DU S&lt;/i&gt;, &lt;i&gt;SHI Y&lt;/i&gt;, &lt;i&gt;WANG W&lt;/i&gt;.&lt;i&gt;L&lt;/i&gt;&lt;sub&gt; (3/2) &lt;/sub&gt; sparsity constrained graph non-negative matrix factorization for image representation[C]// Proceedings of the 26th Chinese Control and Decision Conference.Piscataway, NJ:IEEE, 2014:2962-2965." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=L (3/2) sparsity constrained graph non-negative matrix factorization for image representation">
                                        <b>[15]</b>
                                         &lt;i&gt;DU S&lt;/i&gt;, &lt;i&gt;SHI Y&lt;/i&gt;, &lt;i&gt;WANG W&lt;/i&gt;.&lt;i&gt;L&lt;/i&gt;&lt;sub&gt; (3/2) &lt;/sub&gt; sparsity constrained graph non-negative matrix factorization for image representation[C]// Proceedings of the 26th Chinese Control and Decision Conference.Piscataway, NJ:IEEE, 2014:2962-2965.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" CAI D, HE X, WU X, et al.Non-negative matrix factorization on manifold[C]// Proceedings of the 8th IEEE International Conference on Data Mining.Piscataway, NJ:IEEE, 2008:63-72." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-negative Matrix Factorization onManifold">
                                        <b>[16]</b>
                                         CAI D, HE X, WU X, et al.Non-negative matrix factorization on manifold[C]// Proceedings of the 8th IEEE International Conference on Data Mining.Piscataway, NJ:IEEE, 2008:63-72.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" XU W, LIU X, GONG Y.Document clustering based on non-negative matrix factorization[C]// Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM, 2003:267-273." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Document-Clustering Based on Non-Negative Matrix Factorization">
                                        <b>[17]</b>
                                         XU W, LIU X, GONG Y.Document clustering based on non-negative matrix factorization[C]// Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM, 2003:267-273.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 汪金涛, 曹玉东, 孙福明.稀疏约束图正则非负矩阵分解的增量学习算法[J].计算机应用, 2017, 37 (4) :1071-1074. (WANG J T, CAO Y D, SUN F M.Incremental learning algorithm based on graph regularized non-negative matrix factorization with sparseness constraints[J].Journal of Computer Applications, 2017, 37 (4) :1071-1074.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201704029&amp;v=MTAxNDc0SDliTXE0OUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURtVnJ2Qkx6N0JkN0c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         汪金涛, 曹玉东, 孙福明.稀疏约束图正则非负矩阵分解的增量学习算法[J].计算机应用, 2017, 37 (4) :1071-1074. (WANG J T, CAO Y D, SUN F M.Incremental learning algorithm based on graph regularized non-negative matrix factorization with sparseness constraints[J].Journal of Computer Applications, 2017, 37 (4) :1071-1074.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-04 09:52</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(05),1275-1281 DOI:10.11772/j.issn.1001-9081.2018092032            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>稀疏限制的增量式鲁棒非负矩阵分解及其应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E4%BA%AE%E4%B8%9C&amp;code=41746642&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨亮东</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E5%BF%97%E9%9C%9E&amp;code=09252667&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨志霞</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E7%96%86%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%B3%BB%E7%BB%9F%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0181515&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新疆大学数学与系统科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对鲁棒非负矩阵分解 (RNMF) 的运算规模随训练样本数量逐渐增多而不断增大的问题, 提出一种稀疏限制的增量式鲁棒非负矩阵分解算法。首先, 对初始数据进行鲁棒非负矩阵分解;然后, 将其分解结果参与到后续迭代运算;最后, 在对系数矩阵增加稀疏限制的情况下与增量式学习相结合, 使目标函数值在迭代求解时下降地更快。该算法在节省运算时间的同时提高了分解后数据的稀疏度。在数值实验中, 将所提算法与鲁棒非负矩阵分解算法、稀疏限制的鲁棒非负矩阵分解 (RNMFSC) 算法进行了比较。在ORL和YALE人脸数据库上的实验结果表明, 所提算法在运算时间和分解后数据的稀疏度等方面均优于其他两个算法, 并且还具有较好的聚类效果, 尤其在YALE人脸数据库上当聚类类别数为3时该算法的聚类准确率达到了91.67%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A2%9E%E9%87%8F%E5%BC%8F%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">增量式学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非负矩阵分解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E9%99%90%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏限制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸识别;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨亮东 (1990—) , 男, 甘肃陇南人, 硕士研究生, 主要研究方向:机器学习;;
                                </span>
                                <span>
                                    *杨志霞 (1977—) , 女, 新疆奎屯人, 教授, 博士, 主要研究方向:最优化方法、机器学习。电子邮箱xjyangzhx@sina.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (11561066);</span>
                    </p>
            </div>
                    <h1><b>Incremental robust non-negative matrix factorization with sparseness constraints and its application</b></h1>
                    <h2>
                    <span>YANG Liangdong</span>
                    <span>YANG Zhixia</span>
            </h2>
                    <h2>
                    <span>College of Mathematics and System Science, Xinjiang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem that the operation scale of Robust Non-negative Matrix Factorization (RNMF) increases with the number of training samples, an incremental robust non-negative matrix factorization algorithm with sparseness constraints was proposed. Firstly, robust non-negative matrix factorization was performed on initial data. Then, the factorized result participated in the subsequent iterative operation. Finally, with sparseness constraints, the coefficient matrix was combined with incremental learning, which made the objective function value fall faster in the iterative solution. The cost of computation was reduced and the sparseness of data after factorization was improved. In the numerical experiments, the proposed algorithm was compared with RNMF algorithm and RNMF with Sparseness Constraints (RNMFSC) algorithm. The experimental results on ORL and YALE face databases show that the proposed algorithm is superior to the other two algorithms in terms of operation time and sparseness of factorized data, and has better clustering effect, especially in YALE face database, when the clustering number is 3, the clustering accuracy of the proposed algorithm reaches 91.67%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=incremental%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">incremental learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Non-negative%20Matrix%20Factorization%20(NMF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Non-negative Matrix Factorization (NMF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparseness%20constraint&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparseness constraint;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">face recognition;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YANG Liangdong, born in 1990, M. S. candidate. His research interest includes machine learning. ;
                                </span>
                                <span>
                                    YANG Zhixia, born in 1977, Ph. D. , professor. Her research interests include optimization method, machine learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (11561066);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">图像处理已经广泛应用于生活中各个行业, 涉及机器学习、模式识别、数据挖掘等领域, 也与人类大脑的认知原理紧密相关, 受到了国内外学者的广泛关注。在处理图像过程中子空间降维是一种最为常见的方法, 主要思路是将高维空间的原始数据 (包括向量数据、矩阵数据、张量数据) 映射到低维子空间进行处理, 有效避免了维度灾难<citation id="172" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>所带来的困难。为了处理矩阵中的数据信息以达到降维的目的, 通常将矩阵进行分解, 典型的矩阵分解方法主要包括:主成分分析<citation id="173" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、线性判别分析<citation id="174" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、独立分量分析<citation id="175" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、奇异值分解<citation id="176" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等。通常这些方法是在一定的限制下对原始数据矩阵进行线性变换或分解, 从而实现了对原始矩阵降维, 但是这些方法的共同点是在求解时有可能会出现负值。 然而在许多应用中, 负值是与客观现实相矛盾的, 不具有可解释性。</p>
                </div>
                <div class="p1">
                    <p id="41">因此, 非负矩阵分解 (Non-negative Matrix Factorization, NMF) <citation id="177" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>这种新的矩阵分解方法被提出, 它最早由Lee等<citation id="181" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation> 于1999年在《Nature》杂志上发表的。它不同于上述典型的矩阵分解算法, 其独特之处是通过添加非负限制, 不但保证了分解结果的可解释性, 还使分解后的数据具有局部表达的特性。后来一些学者在此基础上又提出了一些非负矩阵分解的改进算法, 并将它们成功地应用到人脸识别、数据挖掘等领域:文献<citation id="178" type="reference">[<a class="sup">9</a>]</citation>中提出了增量式非负矩阵分解 (Incremental NMF, INMF) 算法;进一步文献<citation id="179" type="reference">[<a class="sup">10</a>]</citation>中提出了图正则 (稀疏) 增量式非负矩阵分解算法等。这些改进算法有一个共同点是损失函数都是F-范数或K-L散度, 而文献<citation id="180" type="reference">[<a class="sup">11</a>]</citation>中在2011年提出了一种基于<i>L</i><sub>2, 1</sub>范数的非负矩阵分解——鲁棒非负矩阵分解 (Robust Non-negative Matrix Factorization, RNMF) 算法, 该算法自提出后立即得到了学术界的广泛关注, 并取得了大量的研究成果。为了达到特定的实验效果, 有些学者在基本的鲁棒非负矩阵分解算法框架中又添加各种限制, 如稀疏性、流形、正交性、判别性等, 提出了若干种改进的算法, 并将其应用于各个领域, 取得了良好的实验效果:文献<citation id="182" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>中考虑到原始数据中蕴含着几何结构, 从而将流行学习与鲁棒非负矩阵分解相结合, 提出了图正则的鲁棒非负矩阵分解 (Graph Regularized RNMF, GRNMF) 算法, 该算法在分解过程中保留了数据集携带的局部几何信息, 使得在低维能很好地表示原始样本近邻结构; 文献<citation id="183" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>]</citation>中提出了稀疏限制的鲁棒非负矩阵分解 (RNMF with Sparseness Constraints, RNMFSC) 算法, 对系数矩阵进行了稀疏限制, 使分解后人脸图像有更高的识别率。</p>
                </div>
                <div class="p1">
                    <p id="42">针对鲁棒非负矩阵分解的运算时间和分解后数据的稀疏程度来说, 随着样本个数的实时增加, 直接利用鲁棒非负矩阵分解时会出现运算规模不断增大的现象。本文就将鲁棒非负矩阵分解算法 (RNMF) 与增量式学习结合在一起, 并在此基础上增加了<i>L</i><sub>2, 1</sub>范数的稀疏限制, 从而提出了稀疏限制的增量式鲁棒非负矩阵分解 (Incremental Robust Non-negative Matrix Factorization with Sparseness Constraints, IRNMFSC) 算法。该算法不仅有效地提高了分解后数据的稀疏度, 得到图像的最佳局部表示, 而且结合增量式学习充分利用上一步对初始数据的分解结果, 避免重复计算从而降低运算时间, 提升算法迭代优化求解时的收敛速度, 使得此算法具有较好的聚类准确率。最后在多个数据库上的仿真结果表明, 本文IRNMFSC算法均优于RNMF算法和RNMFSC算法。</p>
                </div>
                <h3 id="43" name="43" class="anchor-tag">1 鲁棒非负矩阵分解</h3>
                <div class="p1">
                    <p id="44">非负矩阵分解算法<citation id="184" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的核心思想是将给定的非负矩阵分解为两个非负低秩矩阵的乘积, 假如对于给定初始样本数<b><i>V</i></b><sub><i>n</i></sub>=[<b><i>v</i></b><sub>1</sub>, <b><i>v</i></b><sub>2</sub>, …, <b><i>v</i></b><sub><i>n</i></sub>] (<b><i>V</i></b><sub><i>n</i></sub>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>) , 其中<b><i>v</i></b><sub><i>j</i></sub> (<i>j</i>=1, 2, …, <i>n</i>) 为一个样本数据, <i>n</i>为初始样本数据的个数, 则非负矩阵<b><i>V</i></b><sub><i>n</i></sub>的分解可写成如下表示:</p>
                </div>
                <div class="p1">
                    <p id="45"><b><i>V</i></b><sub><i>n</i></sub>≈<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub></p>
                </div>
                <div class="p1">
                    <p id="46">其中<b><i>W</i></b><sub><i>n</i></sub>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>r</i></sub>]∈<b>R</b><sup><i>m</i>×<i>r</i></sup> (0≤<b><i>w</i></b><sub><i>a</i></sub>∈<b>R</b><sup><i>m</i></sup>, <i>a</i>=1, 2, …, <i>r</i>) 为基矩阵, <b><i>H</i></b><sub><i>n</i></sub>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>]∈<b>R</b><sup><i>r</i>×<i>n</i></sup> (0≤<b><i>h</i></b><sub><i>j</i></sub>∈<b>R</b><sup><i>r</i></sup>, <i>j</i>=1, 2, …, <i>n</i>) 为系数矩阵, <i>r</i>为分解后基向量的个数。当<i>r</i>≪<i>nm</i>/ (<i>n</i>+<i>m</i>) 时, 就实现了对原始数据<b><i>V</i></b><sub><i>n</i></sub>的降维。</p>
                </div>
                <div class="p1">
                    <p id="47">鲁棒性非负矩阵分解 (RNMF) 算法<citation id="185" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>采用<i>L</i><sub>2, 1</sub>范数来度量<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub>与<b><i>V</i></b><sub><i>n</i></sub> 的逼近程度, 其优化问题可表示为:</p>
                </div>
                <div class="p1">
                    <p id="48">min <b><i>J</i></b><sub><i>n</i></sub>=‖<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>      (1) </p>
                </div>
                <div class="p1">
                    <p id="49">s.t. <b><i>W</i></b><sub><i>n</i></sub>≥0, <b><i>H</i></b><sub><i>n</i></sub>≥0</p>
                </div>
                <div class="p1">
                    <p id="50">其中‖·‖<sub>2, 1</sub>是矩阵的<i>L</i><sub>2, 1</sub>范数, 其定义如下:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">A</mi><mo stretchy="false">) </mo><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow></mstyle><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中<b><i>A</i></b>=[<b><i>a</i></b><sub>1</sub>, <b><i>a</i></b><sub>2</sub>, …, <b><i>a</i></b><sub><i>n</i></sub>]∈<b>R</b><sup><i>m</i>×<i>n</i></sup> (<b><i>a</i></b><sub><i>j</i></sub>∈<b>R</b><sup><i>m</i></sup>, <i>j</i>=1, 2, …, <i>n</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="53">根据<i>L</i><sub>2, 1</sub>范数的定义, 优化问题 (1) 的目标函数可转化为如下形式:</p>
                </div>
                <div class="area_img" id="55">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201905006_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="55">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201905006_05501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="56">其中‖·‖<sub>2</sub>表示一个向量的2-范数, <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">G</mi><mo>˜</mo></mover><mo>=</mo><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext></mrow></math></mathml> (<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>G</mi><mo>˜</mo></mover></math></mathml><sub>11</sub>, <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>G</mi><mo>˜</mo></mover></math></mathml><sub>22</sub>, …, <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>G</mi><mo>˜</mo></mover></math></mathml><sub>nn</sub>) 是一个对角矩阵, 并且</p>
                </div>
                <div class="area_img" id="61">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201905006_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="63">综上, 优化问题 (1) 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="64">min <i>J</i><sub><i>n</i></sub>=Tr[ (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub>) <b><i>G</i></b> (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub>) <sup>T</sup>]      (4) </p>
                </div>
                <div class="p1">
                    <p id="65">s.t. <b><i>W</i></b><sub><i>n</i></sub>≥0, <b><i>H</i></b><sub><i>n</i></sub>≥0</p>
                </div>
                <div class="p1">
                    <p id="66">这里, 为了避免对角矩阵的对角线元素出现分母为0的情形, 本文通常作如下处理:</p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup></mrow></msqrt><mo>+</mo><mi>ε</mi></mrow></mfrac></mrow></math></mathml>; <i>j</i>=1, 2, …, <i>n</i></p>
                </div>
                <div class="p1">
                    <p id="69">这里<i>ε</i>&gt;0。</p>
                </div>
                <div class="p1">
                    <p id="70">构造优化问题 (4) 的Language函数, 利用KKT条件可得到如下更新迭代法则<citation id="186" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi>G</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中, <i>i</i>=1, 2, …, <i>m</i>, <i>j</i>=1, 2, …, <i>n</i>, <i>a</i>=1, 2, …, <i>r</i>。</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag">2 稀疏限制的增量式鲁棒非负矩阵分解</h3>
                <div class="p1">
                    <p id="75">当有新增样本数据加入时, 增量样本数据问题描述如下:对给定的<i>n</i>个初始数据样本<b><i>V</i></b><sub><i>n</i></sub>=[<b><i>v</i></b><sub>1</sub>, <b><i>v</i></b><sub>2</sub>, …, <b><i>v</i></b><sub><i>n</i></sub>]∈<b>R</b><sup><i>m</i>×<i>n</i></sup>, 当有新增样本<b><i>v</i></b><sub><i>n</i>+1</sub>加入时, <b><i>V</i></b><sub><i>n</i>+1</sub>=[<b><i>V</i></b><sub><i>n</i></sub>, <b><i>v</i></b><sub><i>n</i>+1</sub>]∈<b>R</b><sup><i>m</i>× (<i>n</i>+1) </sup> (<b><i>v</i></b><sub><i>j</i></sub>∈<b>R</b><sup><i>m</i></sup>) 为了对新增后的样本数据进行稀疏的鲁棒非负矩阵分解, 本研究构建如下优化问题:</p>
                </div>
                <div class="p1">
                    <p id="76">min <i>J</i><sub><i>n</i>+1</sub>=‖<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i></sub><b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>+‖<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>‖<sub>2, 1</sub>+<i>α</i>‖<b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>+<i>α</i>‖<b><i>h</i></b><sub><i>n</i>+1</sub>‖<sub>2, 1</sub>      (7) </p>
                </div>
                <div class="p1">
                    <p id="78">s.t. <b><i>W</i></b><sub><i>n</i></sub>≥0, <b><i>W</i></b><sub><i>n</i>+1</sub>≥0, <b><i>H</i></b><sub><i>n</i></sub>≥0, <b><i>h</i></b><sub><i>n</i>+1</sub>≥0</p>
                </div>
                <div class="p1">
                    <p id="79">其中:<b><i>W</i></b><sub><i>n</i></sub>∈<b>R</b><sup><i>m</i>×<i>r</i></sup>和<b><i>H</i></b><sub><i>n</i></sub>∈<b>R</b><sup><i>r</i>×<i>n</i></sup>分别是对样本<b><i>V</i></b><sub><i>n</i></sub>分解得到的基矩阵和系数矩阵, 而<b><i>W</i></b><sub><i>n</i>+1</sub>∈<b>R</b><sup><i>m</i>×<i>r</i></sup>和<b><i>h</i></b><sub><i>n</i>+1</sub>∈<b>R</b><sup><i>r</i>×1</sup>分别是对新增样本<b><i>v</i></b><sub><i>n</i>+1</sub>后的数据<b><i>V</i></b><sub><i>n</i>+1</sub>分解得到的基矩阵和系数矩阵<b><i>H</i></b><sub><i>n</i>+1</sub>的最后一列, <i>r</i> (<i>r</i>≪<i>nm</i>/ (<i>n</i>+<i>m</i>) ) 为分解后基向量的个数, ‖<b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>和‖<b><i>h</i></b><sub><i>n</i>+1</sub>‖<sub>2, 1</sub>是稀疏限制项。值得注意地, 在优化问题 (7) 中, 将基矩阵<b><i>W</i></b><sub><i>n</i></sub>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>r</i></sub>]∈<b>R</b><sup><i>m</i>×<i>r</i></sup>的每一列<b><i>w</i></b><sub><i>a</i></sub>∈<b>R</b><sup><i>m</i></sup> (<i>a</i>=1, 2, …, <i>n</i>) 看作组成某一样本的基本元素, 而将系数矩阵<b><i>H</i></b><sub><i>n</i></sub>的每一列<b><i>h</i></b><sub><i>j</i></sub>看作每个基本元素参与重构的权重。这样可以发现, 随着初始样本数量的增加, 新增样本的表达能力会逐渐减弱。因此当初始样本数足够大时, 作为基本元素集合的基矩阵<b><i>W</i></b><sub><i>n</i></sub>并不会因新样本的加入而产生太大变化。同样, 初始样本<b><i>v</i></b><sub><i>j</i></sub>所对应的系数向量<b><i>h</i></b><sub><i>j</i></sub> (<i>j</i>=1, 2, …, <i>n</i>) 也基本不变。</p>
                </div>
                <div class="p1">
                    <p id="80">基于以上假设, 优化问题 (7) 可近似为:</p>
                </div>
                <div class="p1">
                    <p id="81">min <b><i>F</i></b><sub><i>n</i>+1</sub>=‖<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>+‖<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>‖<sub>2, 1</sub>+<i>α</i>‖<b><i>H</i></b><sub><i>n</i></sub>‖<sub>2, 1</sub>+<i>α</i>‖<b><i>h</i></b><sub><i>n</i>+1</sub>‖<sub>2, 1</sub>      (8) </p>
                </div>
                <div class="p1">
                    <p id="84">s.t. <b><i>W</i></b><sub><i>n</i>+1</sub>≥0, <b><i>h</i></b><sub><i>n</i>+1</sub>≥0</p>
                </div>
                <div class="p1">
                    <p id="85">其中:<b><i>W</i></b><sub><i>n</i>+1</sub>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>r</i></sub>]∈<b>R</b><sup><i>m</i>×<i>r</i></sup> (<b><i>w</i></b><sub><i>a</i></sub>∈<b>R</b><sup><i>m</i></sup>, <i>a</i>=1, 2, …, <i>r</i>) 是基矩阵, <b><i>H</i></b><sub><i>n</i></sub>是当初始样本为<b><i>V</i></b><sub><i>n</i></sub>时通过迭代法则式 (5) ～ (6) 计算得出, 因此最终要求解的系数矩阵为<b><i>H</i></b><sub><i>n</i>+1</sub>=[<b><i>H</i></b><sub><i>n</i></sub>, <b><i>h</i></b><sub><i>n</i>+1</sub>]∈<b>R</b><sup><i>r</i>× (<i>n</i>+1) </sup>, 可见求解问题 (8) 就近似对新增一个样本后的数据矩阵<b><i>V</i></b><sub><i>n</i>+1</sub>作了分解。</p>
                </div>
                <div class="p1">
                    <p id="86">事实上, 本文将优化问题 (8) 的目标函数可写为矩阵迹的形式, 其具体如下所示:</p>
                </div>
                <div class="p1">
                    <p id="87"><b><i>F</i></b><sub><i>n</i>+1</sub>=Tr[ (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub>) <b><i>D</i></b> (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub>) <sup>T</sup>]+Tr[ (<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>) <i>M</i> (<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>) <sup>T</sup>]+<i>α</i>Tr (<b><i>H</i></b><sub><i>n</i></sub><b><i>K</i></b><b><i>H</i></b><sub><i>n</i></sub><sup>T</sup>) +<i>α</i>Tr (<b><i>h</i></b><sub><i>n</i>+1</sub><b><i>U</i></b><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="89">其中:<b><i>D</i></b>=diag (<i>D</i><sub>11</sub>, <i>D</i><sub>22</sub>, …, <i>D</i><sub><i>nn</i></sub>) 和<b><i>K</i></b>=diag (<i>K</i><sub>11</sub>, <i>K</i><sub>22</sub>, …, <i>K</i><sub><i>nn</i></sub>) 其元素分别为:</p>
                </div>
                <div class="area_img" id="90">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201905006_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="92">而式 (9) 中的<i>M</i>和<i>U</i>都是常数, 其形式为:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>+</mo><mi>ε</mi></mrow></mfrac><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi>ε</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>U</mi><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>a</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msubsup><mrow></mrow><mi>a</mi><mn>2</mn></msubsup></mrow></msqrt><mo>+</mo><mi>ε</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi>ε</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中式 (10) ～ (12) 中<i>ε</i>&gt;0。</p>
                </div>
                <div class="p1">
                    <p id="95">因此, 可将优化问题 (8) 等价为:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></munder><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mtext>Τ</mtext><mtext>r</mtext></mrow></math></mathml>[ (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub>) <b><i>D</i></b> (<b><i>V</i></b><sub><i>n</i></sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub>) <sup>T</sup>]+Tr[ (<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>) <i>M</i> (<b><i>v</i></b><sub><i>n</i>+1</sub>-<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub>) <sup>T</sup>]+<i>α</i>Tr (<b><i>h</i></b><sub><i>n</i>+1</sub><i>U</i><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +<i>α</i>Tr (<b><i>H</i></b><sub><i>n</i></sub><b><i>K</i></b><b><i>H</i></b><sub><i>n</i></sub><sup>T</sup>)      (13) </p>
                </div>
                <div class="p1">
                    <p id="100">s.t. <b><i>W</i></b><sub><i>n</i>+1</sub>≥0, <b><i>h</i></b><sub><i>n</i>+1</sub>≥0</p>
                </div>
                <div class="p1">
                    <p id="101">为了求解带约束的优化问题 (13) , 对约束条件 (<b><i>W</i></b><sub><i>n</i>+1</sub>) <sub><i>ja</i></sub>≥0, (<b><i>h</i></b><sub><i>n</i>+1</sub>) <sub><i>a</i></sub>≥0, 引入Lagrange乘子<i>Ψ</i>=[<i>ψ</i><sub>1</sub>, <i>ψ</i><sub>2</sub>, …, <i>ψ</i><sub><i>r</i></sub>] (<i>ψ</i><sub><i>a</i></sub>∈<b>R</b><sup><i>m</i></sup>, <i>a</i>=1, 2, …, <i>r</i>) , <i>Φ</i>=[<i>φ</i><sub>1</sub>, <i>φ</i><sub>2</sub>, …, <i>φ</i><sub><i>r</i></sub>]<sup>T</sup>∈<b>R</b><sup><i>r</i></sup> 构造Lagrange函数:</p>
                </div>
                <div class="p1">
                    <p id="102"><i>L</i>=Tr (<b><i>V</i></b><sub><i>n</i></sub><b><i>D</i></b><b><i>V</i></b><sub><i>n</i></sub><sup>T</sup>) -2Tr (<b><i>V</i></b><sub><i>n</i></sub><b><i>DH</i></b><sub><i>n</i></sub><sup>T</sup><b><i>W</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +Tr (<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>H</i></b><sub><i>n</i></sub><b><i>D</i></b><b><i>H</i></b><sub><i>n</i></sub><sup>T</sup><b><i>W</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +<i>α</i>Tr (<b><i>H</i></b><sub><i>n</i></sub><b><i>K</i></b><b><i>H</i></b><sub><i>n</i></sub><sup>T</sup>) +Tr (<b><i>v</i></b><sub><i>n</i>+1</sub><i>M</i><b><i>v</i></b><sub><i>n</i>+1</sub><sup>T</sup>) -2Tr (<b><i>v</i></b><sub><i>n</i>+1</sub><i>M</i><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup><b><i>W</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +Tr (<b><i>W</i></b><sub><i>n</i>+1</sub><b><i>h</i></b><sub><i>n</i>+1</sub><i>M</i><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup><b><i>W</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +<i>α</i>Tr (<b><i>h</i></b><sub><i>n</i>+1</sub><i>U</i><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +Tr (<i>Ψ</i><b><i>W</i></b><sub><i>n</i>+1</sub><sup>T</sup>) +Tr (<i>Φ</i><b><i>h</i></b><sub><i>n</i>+1</sub><sup>T</sup>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="107">分别对式 (14) 中 (<b><i>W</i></b><sub><i>n</i>+1</sub>) <sub><i>ia</i></sub>和 (<b><i>h</i></b><sub><i>n</i>+1</sub>) <sub><i>a</i></sub>求偏导, 并令其等于零, 即:</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">L</mi></mrow><mrow><mo>∂</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow></mfrac><mo>=</mo><mo>-</mo><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>+</mo><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>+</mo><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>+</mo><mi>ψ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>=</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">L</mi></mrow><mrow><mo>∂</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac><mo>=</mo><mo>-</mo><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>U</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mn>2</mn><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo><mi>φ</mi><msub><mrow></mrow><mi>a</mi></msub><mo>=</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109">对式 (15) 和 (16) 两边分别乘以 (<b><i>W</i></b><sub><i>n</i>+1</sub>) <sub><i>ia</i></sub>和 (<b><i>h</i></b><sub><i>n</i>+1</sub>) <sub><i>a</i>1</sub>, 利用KKT条件以及互补松弛条件:<i>ψ</i><sub><i>ia</i></sub> (<b><i>W</i></b><sub><i>n</i>+1</sub>) <sub><i>ia</i></sub>=0, <i>φ</i><sub><i>a</i></sub> (<b><i>h</i></b><sub><i>n</i>+1</sub>) <sub><i>a</i></sub>=0, 可得到如下的更新迭代法则:</p>
                </div>
                <div class="area_img" id="111">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201905006_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>⋅</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo>+</mo><mi>α</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>U</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">根据式 (17) ～ (18) 更新交替迭代得到当前新增样本加入后的最终系数矩阵增量部分<b><i>h</i></b><sub><i>n</i>+1</sub>, 和新的基矩阵<b><i>W</i></b><sub><i>n</i>+1</sub>, 从而得到系数矩阵<b><i>H</i></b><sub><i>n</i>+1</sub>=[<b><i>H</i></b><sub><i>n</i></sub>, <b><i>h</i></b><sub><i>n</i>+1</sub>]。</p>
                </div>
                <div class="p1">
                    <p id="114">综上, 归纳基于稀疏限制的增量式鲁棒非负矩阵分解 (IRNMFSC) 算法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="115">输入 初始样本<b><i>V</i></b><sub><i>n</i></sub>, 新增样本<b><i>v</i></b><sub><i>n</i>+1</sub>;</p>
                </div>
                <div class="p1">
                    <p id="116">输出 基矩阵<b><i>W</i></b><sub><i>n</i>+1</sub>和系数矩阵<b><i>H</i></b><sub><i>n</i>+1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="117">1) 初始化参数。设定参数<i>α</i>∈ (0, 1) , 分解维数<i>r</i>和迭代收敛精度<i>ε</i> (最大迭代次数<i>iter</i>) , 对非负矩阵<b><i>W</i></b><sub><i>n</i></sub>和<b><i>H</i></b><sub><i>n</i></sub>进行随机初始化。</p>
                </div>
                <div class="p1">
                    <p id="118">2) 对初始样本<b><i>V</i></b><sub><i>n</i></sub>按如下迭代规则进行迭代更新<b><i>W</i></b><sub><i>n</i></sub>和<b><i>H</i></b><sub><i>n</i></sub>, 直至收敛:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>a</mi><mi>j</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">G</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">其中<b><i>G</i></b>是一个对角矩阵, 其对角元素如下所示:</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msubsup><mrow></mrow><mrow><mi>j</mi><mi>i</mi></mrow><mn>2</mn></msubsup></mrow></msqrt><mo>+</mo><mi>ε</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi>ε</mi></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">3) 每增加一个新的训练样本<b><i>v</i></b><sub><i>n</i>+1</sub>时, 随机初始化<b><i>h</i></b><sub><i>n</i>+1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="124">4) 按如下迭代规则进行更新<b><i>W</i></b><sub><i>n</i>+1</sub>和<b><i>h</i></b><sub><i>n</i>+1</sub>直至收敛:</p>
                </div>
                <div class="p1">
                    <p id="125" class="code-formula">
                        <mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo>+</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>a</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mo>←</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>Μ</mi><mo>+</mo><mi>α</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>U</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">其中:<b><i>D</i></b>和<b><i>K</i></b>是对角矩阵, 其元素如式 (10) 所示;<i>M</i>和<i>U</i>都是常数, 其元素分别为如式 (11) 和 (12) 所示。</p>
                </div>
                <div class="p1">
                    <p id="128">5) 将更新后的<b><i>h</i></b><sub><i>n</i>+1</sub>加入当前系数矩阵<b><i>H</i></b><sub><i>n</i></sub>的未列, 即<b><i>H</i></b><sub><i>n</i>+1</sub>=[<b><i>H</i></b><sub><i>n</i></sub>, <b><i>h</i></b><sub><i>n</i>+1</sub>]。</p>
                </div>
                <div class="p1">
                    <p id="129">6) 返回基矩阵<b><i>W</i></b><sub><i>n</i>+1</sub>和系数矩阵<b><i>H</i></b><sub><i>n</i>+1</sub>。</p>
                </div>
                <h3 id="130" name="130" class="anchor-tag">3 实验结果及其结论</h3>
                <h4 class="anchor-tag" id="131" name="131">3.1 <b>数据描述及参数设置</b></h4>
                <div class="p1">
                    <p id="132">实验分别采用<i>ORL</i>和<i>YALE</i>两个标准人脸数据库进行实验及验证。</p>
                </div>
                <div class="p1">
                    <p id="133">1) 图1 (<i>a</i>) 中给出了<i>ORL</i>人脸数据集中的部分样本的图片形式, 该数据库包含40人共400张人脸图像, 同一人脸图像在姿态、表情以及面部饰物上均有一定程度的变化, 每张图像的分辨率为92×119像素。本实验是通过预处理将图像的分辨率统一裁剪压缩为32×32像素, 在进行实验时取前30人面部图像, 每个类取6张共180张作为初始样本。</p>
                </div>
                <div class="p1">
                    <p id="134">2) 图1 (b) 中给出了YALE人脸数据集中的部分样本的图片形式, 该数据包含15人共165张人脸图像, 同一人脸图像在姿势、表情和光照等方面均有不同程度的变化, 每张图像的分辨率是100×100像素。 本实验是通过预处理将图像的分辨率统一裁剪压缩为32×32像素, 在进行实验时每个类取6张共90张作为初始样本。</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 2组人脸数据库中的部分图像示例" src="Detail/GetImg?filename=images/JSJY201905006_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 2组人脸数据库中的部分图像示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Some image examples in two face databases</p>

                </div>
                <div class="p1">
                    <p id="136">在每次运算中使用随机初值对RNMF<citation id="187" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、RNMFSC<citation id="188" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和IRNMFSC进行数值实验, 如果 ( (<i>F</i><sub><i>n</i>+1</sub>) <sub><i>t</i>+1</sub>- (<i>F</i><sub><i>n</i>+1</sub>) <sub><i>t</i></sub>) / (<i>F</i><sub><i>n</i>+1</sub>) <sub><i>t</i>+1</sub>≤10<sup>-5</sup> (<i>t</i>为迭代步数) 时, 算法终止。</p>
                </div>
                <div class="p1">
                    <p id="137">RNMFSC算法和本文IRNMFSC算法中有两个关键性的参数:稀疏限制<i>α</i><sub>1</sub>和<i>α</i><sub>2</sub>, <i>α</i><sub>1</sub>、<i>α</i><sub>2</sub>∈ (0, 1) , 若稀疏系数的值太大会使图像过于稀疏而不能很好地表达, 通过对比实验, 在ORL数据集上RNMFSC和本文IRNMFSC算法稀疏限制参数<i>α</i><sub>1</sub>和<i>α</i><sub>2</sub>分别取0.2 和0.1;YALE 数据集上RNMFSC和IRNMFSC算法稀疏限制参数<i>α</i><sub>1</sub>和<i>α</i><sub>2</sub>分别取0.25 和0.1。</p>
                </div>
                <div class="p1">
                    <p id="138">实验环境 使用Windows10操作系统, CPU为2.0 GHz, 内存4 GB, 程序环境为Matlab R2014b。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">3.2 <b>收敛效果对比</b></h4>
                <div class="p1">
                    <p id="140">在<i>YALE</i>人脸数据库和<i>ORL</i>人脸数据库上比较<i>RNMF</i><citation id="189" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、<i>RNMFSC</i><citation id="190" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>以及本文<i>IRNMFSC</i>算法的收敛效果, 设本文<i>IRNMFSC</i>算法的迭代精度为10<sup>-5</sup>, 其目标函数值随着迭代次数的增加函数曲线的变化如图2～5所示。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 三种算法在两个人脸数据库中的收敛性对比" src="Detail/GetImg?filename=images/JSJY201905006_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 三种算法在两个人脸数据库中的收敛性对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Convergence comparison of three algorithms in two face databases</p>

                </div>
                <div class="p1">
                    <p id="142">图2表示在人脸数据库YALE和ORL上三种算法的收敛情况, 当初始样本数, 新增样本数和基向量个数<i>r</i>值给定时, 这三种算法在达到本文算法的收敛精度下的收敛情况, 可知, 本文提出的IRNMFSC算法的收敛性强于RNMF 算法和RNMFSC算法, 目标函数值下降得最快, 收敛速度最快, 最先达到平衡, 收敛效果较好。</p>
                </div>
                <div class="p1">
                    <p id="143">图3所示, 本文IRNMFSC算法通过对人脸数据库进行实验, 在初始样本和新增样本一定的情况下, 随着基向量个数<i>r</i>的变化, 显示了本文提出的算法收敛变化趋势。实验发现:<i>r</i>取得越大, 则目标函数值就下降得越快, 分解的精度越高, 但是提高了运算的复杂度, 从而增长了运算时间。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 IRNMFSC在基向量个数r取不同值时的收敛情况" src="Detail/GetImg?filename=images/JSJY201905006_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 IRNMFSC在基向量个数<i>r</i>取不同值时的收敛情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Convergence of IRNMFSC with different number of base vectors <i>r</i></p>

                </div>
                <div class="p1">
                    <p id="145">如图4所示, 通过对YALE人脸数据进行实验, 图4 (a) ～ (d) 是随着新增样本个数的增加, RNMF算法、RNMFSC算法以及本文IRNMFSC算法的收敛情况, 可知, 当新增样本个数增加时, 本文算法收敛效果保持不变, 依然具有较快的收敛速度, 新增样本的增加对算法的收敛速度影响不大。</p>
                </div>
                <div class="p1">
                    <p id="146">图5所示, 通过对ORL人脸数据进行实验, 图5 (a) ～ (d) 是随着新增样本个数的增加, RNMF算法、RNMFSC算法以及本文IRNMFSC算法的收敛情况, 可知, 与对比算法相比, 当新增样本个数增加时, 本文算法收敛效果不变, 收敛速度较快, 依然保持较好收敛效果。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147">3.3 <b>聚类准确率对比</b></h4>
                <div class="p1">
                    <p id="148">本文采取分类精确度 (<i>Accuracy</i>, <i>AC</i>) 来度量聚类性能<citation id="191" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>, 这个度量标准被广泛用于聚类的标准度量, <i>AC</i>定义如下:</p>
                </div>
                <div class="p1">
                    <p id="149" class="code-formula">
                        <mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>C</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false"> (</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mtext>m</mtext><mtext>a</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>c</mi><msub><mrow></mrow><msup><mi>i</mi><mo>′</mo></msup></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mi>n</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="150">其中: <i>n</i>表示数据集所包含的样本图像的个数, <i>c</i><sub><i>i</i></sub>表示数据集所提供的标签, <i>c</i><sub><i>i</i></sub>′表示通过用本文的算法得到的样本<b><i>V</i></b>的聚类标签, map (·) 是从聚类后数据集标签到每个聚类标签的排列映射。<i>δ</i> (<i>A</i>, <i>B</i>) 是一个函数:</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><mo stretchy="false"> (</mo><mi>A</mi><mo>, </mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>, </mo></mtd><mtd><mi>A</mi><mo>=</mo><mi>B</mi></mtd><mtd></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo></mtd><mtd><mi>A</mi><mo>≠</mo><mi>B</mi></mtd><mtd></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">在这一节中, 本文对YALE人脸数据集和ORL人脸数据集进行聚类分析。在YALE和ORL人脸数据集中取前11 人面部图像, 每个类取8个共88张人脸进行数值实验, 并将本文提出的IRNMFSC算法用于聚类数据分析, 以显示其与算法RNMF<citation id="192" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和算法RNMFSC<citation id="193" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>相比较的有效性, 其聚类准确率 (<i>AC</i>) 如表1所示。</p>
                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 三种算法在YALE人脸数据库中随着新增样本个数增加时的收敛情况" src="Detail/GetImg?filename=images/JSJY201905006_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 三种算法在YALE人脸数据库中随着新增样本个数增加时的收敛情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Convergence of three algorithms in YALE face database as number of new samples increases</p>

                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 三种算法在ORL人脸数据库中随着新增样本个数增加时的收敛情况" src="Detail/GetImg?filename=images/JSJY201905006_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 三种算法在ORL人脸数据库中随着新增样本个数增加时的收敛情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Convergence of three algorithms in ORL face database as number of new samples increases</p>

                </div>
                <div class="p1">
                    <p id="155">由表1可知, 通过对YALE和ORL人脸数据集进行聚类分析:本文IRNMFSC算法与其他几个算法相比聚类准确率的值相差不大, 但总体变化趋势 (如表1) 较好; 但在表1的ORL数据集中, 当<i>K</i>=2时, RNMFSC算法所得到的聚类准确率比其他两个算法均偏高或几乎相等, 导致这个问题产生的原因可能是在迭代过程中对<b><i>W</i></b><sub><i>n</i>+1</sub>和<b><i>H</i></b><sub><i>n</i>+1</sub>初值的选取。如表1所示, 虽然在同一<i>K</i>值下, 有些算法的聚类准确率的值几乎相等, 如当<i>K</i>=6时, RNMF算法和本文IRNMFSC算法的聚类准确率相等, 但是本文算法的收敛速度、运行效率和稀疏度均优于RNMF和RNMFSC算法。</p>
                </div>
                <div class="area_img" id="156">
                                            <p class="img_tit">
                                                <b>表</b>1 <b>人脸数据库在不同算法的聚类精确率</b>
                                                    <br />
                                                Tab. 1 Clustering accuracy of different algorithms in face database
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201905006_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note">%</p>
                                <p class="img_note">%</p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 人脸数据库在不同算法的聚类精确率" src="Detail/GetImg?filename=images/JSJY201905006_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="157" name="157">3.4 <b>运行时间对比</b></h4>
                <div class="p1">
                    <p id="158">对<i>YALE</i>人脸数据库进行实验, 初始样本为90时, <i>RNMF</i><citation id="194" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、<i>RNMFSC</i><citation id="195" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和本文<i>IRNMFSC</i>算法随着新增样本数量的增加而消耗的时间情况如表2所示;对<i>ORL</i>人脸数据库进行实验时, 初始样本为180时, <i>RNMF</i><citation id="196" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、<i>RNMFSC</i><citation id="197" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和本文<i>IRNMFSC</i>算法随着新增样本数量的增加而消耗的时间情况如表2所示, eps=10<sup>-5</sup>。</p>
                </div>
                <div class="p1">
                    <p id="159">由表2可知, 本文<i>IRNMFSC</i>算法与其他几个算法相比, 本文算法在运行时间上有明显优势, 而且随着新增样本的增加, 本文<i>IRNMFSC</i>算法仍能保持相对高的运算效率。</p>
                </div>
                <h4 class="anchor-tag" id="160" name="160">3.5 <b>稀疏限制的度量</b></h4>
                <div class="p1">
                    <p id="161">先定义稀疏度的函数为:</p>
                </div>
                <div class="p1">
                    <p id="162" class="code-formula">
                        <mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mrow><mo>[</mo><mrow><mi>n</mi><mo>-</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="163">其中:<i>n</i>是向量<b><i>x</i></b>的维数, ‖·‖<sub>1</sub>是向量<b><i>x</i></b>的1范数, ‖·‖<sub>2</sub>是向量<b><i>x</i></b>的2范数, 0≤<i>sparseness</i>≤1。当<i>x</i>仅有一个非零元素时, 函数值为1;当所有元素都不为零且相等时, 函数值为0。</p>
                </div>
                <div class="p1">
                    <p id="164">用式 (20) 作为稀疏度度量标准, 则经过RNMF<citation id="198" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、RNMFSC<citation id="199" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和本文IRNMFSC算法分解后得到的基矩阵<b><i>W</i></b>和系数矩阵<b><i>H</i></b>的稀疏度如表3所示。</p>
                </div>
                <div class="p1">
                    <p id="165">由表3可知, 本文IRNMFSC算法分解后得到的基矩阵<b><i>W</i></b>和系数矩阵<b><i>H</i></b>均较RNMF算法和RNMFSC算法所得到的更为稀疏, 有效地提高了存储效率。其中, YALE数据集的基矩阵特征维数取<i>r</i>为20, ORL数据集的基矩阵<b><i>W</i></b>特征维数取<i>r</i>为30。将<i>r</i>维的基矩阵<b><i>W</i></b>重构成<i>r</i>个人脸基图像, 如图6～7所示, RNMF算法的基向量最接近原图像, 容易得到原始样本的最优表示, 但是它的稀疏度较差, 存储率低, 同其他的RNMF改进算法相比, 本文IRNMFSC算法能得到更稀疏的基图像, 由此表明算法得到了图像的最佳的局部表示。</p>
                </div>
                <div class="area_img" id="166">
                    <p class="img_tit"><b>表</b>2 <b>人脸数据库随着新增不同量训练样本时算法所消耗的时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Time cost of different algorithms with addition of different training samples on face database </p>
                    <p class="img_note">s</p>
                    <table id="166" border="1"><tr><td colspan="4"><br />YALE数据库</td><td rowspan="2"></td><td colspan="4"><br />ORL数据库</td></tr><tr><td><br />新增样本个数</td><td>RNMF</td><td>RNMFSC</td><td>IRNMFSC</td><td><br />新增样本个数</td><td>RNMF</td><td>RNMFSC</td><td>IRNMFSC</td></tr><tr><td>1</td><td>10.308 0</td><td>9.789 0</td><td>7.338 0</td><td></td><td>1</td><td>16.937 0</td><td>16.290 0</td><td>15.156 0</td></tr><tr><td><br />20</td><td>10.823 0</td><td>10.458 0</td><td>8.751 0</td><td></td><td>30</td><td>18.886 0</td><td>18.606 0</td><td>16.289 0</td></tr><tr><td><br />40</td><td>11.725 0</td><td>11.434 0</td><td>9.621 0</td><td></td><td>60</td><td>22.395 0</td><td>21.859 0</td><td>18.907 0</td></tr><tr><td><br />60</td><td>12.320 0</td><td>12.004 0</td><td>10.992 0</td><td></td><td>90</td><td>24.882 0</td><td>24.495 0</td><td>21.206 0</td></tr><tr><td><br />75</td><td>13.274 0</td><td>13.011 0</td><td>12.009 0</td><td></td><td>120</td><td>27.654 0</td><td>27.331 0</td><td>23.417 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="167">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 YALE人脸数据集的基图像 (r=20)" src="Detail/GetImg?filename=images/JSJY201905006_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 YALE人脸数据集的基图像 (<i>r</i>=20)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Base images learned on YALE database (<i>r</i>=20) </p>

                </div>
                <div class="area_img" id="168">
                    <p class="img_tit"><b>表</b>3 <b>几种算法得到的因子矩阵稀疏度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Sparsity of factor matrix obtained by several algorithms</p>
                    <p class="img_note"></p>
                    <table id="168" border="1"><tr><td rowspan="2"><br />对比<br />算法</td><td colspan="2"><br />YALE数据库</td><td rowspan="2"></td><td colspan="2"><br />ORL数据库</td></tr><tr><td><br />基矩阵<b><i>W</i></b></td><td>系数矩阵<b><i>H</i></b></td><td><br />基矩阵<b><i>W</i></b></td><td>系数矩阵<b><i>H</i></b></td></tr><tr><td><br />RNMF</td><td>0.344 5</td><td>0.371 1</td><td></td><td>0.238 1</td><td>0.232 8</td></tr><tr><td><br />RNMFSC</td><td>0.345 2</td><td>0.372 2</td><td></td><td>0.239 3</td><td>0.233 1</td></tr><tr><td><br />IRNMFC</td><td>0.350 2</td><td>0.423 6</td><td></td><td>0.242 5</td><td>0.246 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="169" name="169" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="170">本文提出了稀疏限制的增量式鲁棒非负矩阵分解 (<i>IRNMFSC</i>) , 并给出了相应的迭代法则和算法步骤, 该算法随着新增样本个数的增加依然保持较好的收敛速度。通过对<i>YALE</i>人脸数据和<i>ORL</i>人脸数据进行数值实验, 结果显示本文算法在迭代过程中收敛速度更快, 寻优效果更好, 不仅缩短了运算时间, 而且使分解后的数据更为稀疏, 能得到局部表达能力更强的基图像和比较高的聚类准确率。但是, 算法中依然存在着不足, 如迭代初值和稀疏参数的选取等, 目前依然没有一个统一的标准, 这些问题都将成为今后要研究的重点。</p>
                </div>
                <div class="area_img" id="171">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905006_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 ORL人脸数据集的基图像 (r=30)" src="Detail/GetImg?filename=images/JSJY201905006_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 <i>ORL</i>人脸数据集的基图像 (r=30)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905006_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 7 <i>Base images learned on ORL database</i> (r=30) </p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Approximate Dynamic Programming:Solving the Curses of Dimensionality">

                                <b>[1]</b> <i>PARDALOS P M</i>.<i>Approximate Dynamic Programming</i>:<i>Solving the Curses of Dimensionality</i>[<i>M</i>].<i>New York</i>:<i>Wiley</i>, 2009:39-50.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200908015&amp;v=MDc1NTh2Qk55ZlRiTEc0SHRqTXA0OUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURtVnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 史卫亚, 郭跃飞, 薛向阳.一种解决大规模数据集问题的核主成分分析算法[<i>J</i>].软件学报, 2009, 8 (20) :2153-2159. (<i>SHI W Y</i>, <i>GUO Y F</i>, <i>XUE X Y</i>.<i>A kernel principal component analysis algorithm for solving large scale data sets problem</i>[<i>J</i>].<i>Journal of Software</i>, 2009, 8 (20) :2153-2159.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201014055&amp;v=Mjg2NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURtVnJ2Qkx6N0JiYkc0SDlITnE0OUFZWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 张燕平, 窦蓉蓉, 赵姝, 等.基于集成学习的规范化<i>LDA</i>人脸识别[<i>J</i>].计算机工程, 2010, 36 (14) :144-146. (<i>ZHANG Y P</i>, <i>DOU R R</i>, <i>ZHAO S</i>, <i>et al</i>.<i>Regularized linear discriminant analysis for face recognition based on ensemble learning</i>[<i>J</i>].<i>Computer Engineering</i>, 2010, 36 (14) :144-146.) 
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient variant of algorithm Fast ICA for independent component analysis attaining the Cramer-RAO lower bound">

                                <b>[4]</b> <i>KOLDOVSKY Z</i>, <i>TICHAVSKY P</i>.<i>Efficient variant of algorithm fastica for independent component analysis attaining the cramer</i>-<i>RAO lower bound</i>[<i>C</i>]// <i>Proceedings of the</i> 2005 <i>IEEE</i>/<i>SP Workshop on Statistical Signal Processing</i>.<i>Piscataway</i>, <i>NJ</i>:<i>IEEE</i>, 2005:1090-1095.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Singular Value Decomposition and Least Squares Solutions">

                                <b>[5]</b> <i>GOLUB G H</i>, <i>REINSCH C</i>.<i>Singular Value Decomposition and</i><i>Least Squares Solutions</i>[<i>M</i>].<i>Berlin</i>:<i>Springer</i>, 1971:403-420.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Positive matrix factorization: a non-negative factor model with optimal utilization of error estimates of data values">

                                <b>[6]</b> <i>PAATERO P</i>, <i>TAPPER U</i>.<i>Positive matrix factorization</i>:<i>a non</i>-<i>negative factor model with optimal utilization of error estimates of data values</i>[<i>J</i>].<i>Environmental Surveying</i>, 1994, 5 (2) :111-126.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning the parts of objects by non-negative matrix factorization">

                                <b>[7]</b> <i>LEE D D</i>, <i>SEUNG H S</i>.<i>Learning the parts of objects with non</i>-<i>negative matrix factorization</i>[<i>J</i>].<i>Nature</i>, 1999, 401 (6755) :788-791.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Algorithms for non-negative matrix factorization">

                                <b>[8]</b> <i>LEE D D</i>.<i>Algorithms for non</i>-<i>negative matrix factorization</i>[<i>J</i>].<i>Advances in Neural Information Processing Systems</i>, 2001, 13 (6) :556-562.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738944&amp;v=MTEyMTk9TmlmT2ZiSzdIdEROcVk5RlkrZ0hCWGc5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJS0YwUmJocw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> <i>BUCAK S S</i>, <i>GUNSEL B</i>.<i>Incremental subspace learning via non</i>-<i>negative matrix factorization</i>[<i>J</i>].<i>Pattern Recognition</i>, 2009, 42 (5) :788-797.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD14060600000502&amp;v=MTI2MjJxUVRNbndaZVp0RmlubFVyM0lLRjBSYmhzPU5pZkRhcks4SHRmTXFZOUZaT3NQQ1h3N29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> <i>YU Z Z</i>, <i>LIU Y H</i>, <i>LI B</i>, <i>et al</i>.<i>Incremental graph regulated non</i>-<i>negative matrix factorization for face recognition</i>[<i>J</i>].<i>Journal of Applied Mathematics</i>, 2014, 2014 (1) :<i>Article ID</i> 928051.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization using L21-norm">

                                <b>[11]</b> <i>KONG D</i>, <i>HUANG H</i>.<i>Robust non</i>-<i>negative matrix factorization using L</i>21-<i>norm</i>[<i>C</i>]// <i>Proceedings of the</i> 20<i>th ACM International Conference on Information and Knowledge Management</i>.<i>New York</i>:<i>ACM</i>, 2011:673-682.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM0200EE102329DF63926D0493227B71A3&amp;v=MTU4MzYybzVGWnVnTkJRaFB5UlVhNkRrSlNIdnJyeEEzZnNDVFJNdWNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh6THU2eEtFPU5pZklZN082SHRHNQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> <i>HUANG S</i>, <i>WANG H</i>, <i>LI T</i>, <i>et al</i>.<i>Robust graph regularized non</i>-<i>negative matrix factorization for clustering</i>[<i>J</i>].<i>ACM Transactions on Knowledge Discovery from Data</i>, 2017, 11 (3) :<i>Article No</i>.33.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization via joint graph laplacian and discriminative information for identifying differentially expressed genes">

                                <b>[13]</b> <i>DAI L Y</i>, <i>FENG C M</i>, <i>LIU J X</i>, <i>et al</i>.<i>Robust non</i>-<i>negative matrix factorization via joint graph laplacian and discriminative information for identifying differentially expressed genes</i>[<i>J</i>].<i>Complexity</i>, 2017, 2017 (40) :<i>Article ID</i> 4216797.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust non-negative matrix factorization via joint sparse and graph regularization">

                                <b>[14]</b> <i>YANG S</i>, <i>HOU C</i>, <i>ZHANG C</i>, <i>et al</i>.<i>Robust non</i>-<i>negative matrix factorization via joint sparse and graph regularization</i>[<i>C</i>]// <i>Proceedings of the</i> 2013 <i>International Joint Conference on Neural Networks</i>.<i>Piscataway</i>, <i>NJ</i>:<i>IEEE</i>, 2014:541-559.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=L (3/2) sparsity constrained graph non-negative matrix factorization for image representation">

                                <b>[15]</b> <i>DU S</i>, <i>SHI Y</i>, <i>WANG W</i>.<i>L</i><sub> (3/2) </sub> sparsity constrained graph non-negative matrix factorization for image representation[C]// Proceedings of the 26th Chinese Control and Decision Conference.Piscataway, NJ:IEEE, 2014:2962-2965.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-negative Matrix Factorization onManifold">

                                <b>[16]</b> CAI D, HE X, WU X, et al.Non-negative matrix factorization on manifold[C]// Proceedings of the 8th IEEE International Conference on Data Mining.Piscataway, NJ:IEEE, 2008:63-72.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Document-Clustering Based on Non-Negative Matrix Factorization">

                                <b>[17]</b> XU W, LIU X, GONG Y.Document clustering based on non-negative matrix factorization[C]// Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM, 2003:267-273.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201704029&amp;v=MTAwMTVtVnJ2Qkx6N0JkN0c0SDliTXE0OUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeUQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 汪金涛, 曹玉东, 孙福明.稀疏约束图正则非负矩阵分解的增量学习算法[J].计算机应用, 2017, 37 (4) :1071-1074. (WANG J T, CAO Y D, SUN F M.Incremental learning algorithm based on graph regularized non-negative matrix factorization with sparseness constraints[J].Journal of Computer Applications, 2017, 37 (4) :1071-1074.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201905006" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905006&amp;v=MTk3Mjl1WnNGeURtVnJ2Qkx6N0JkN0c0SDlqTXFvOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
