<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136455363721250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910006%26RESULT%3d1%26SIGN%3dQiI0Fns%252bWKGZgi%252bPA9yhPKQ%252b7kg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910006&amp;v=Mjg3NDU3RzRIOWpOcjQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bmhVTC9NTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="1.1 PU&lt;b&gt;学习&lt;/b&gt;">1.1 PU<b>学习</b></a></li>
                                                <li><a href="#49" data-title="1.2 &lt;b&gt;基于间谍技术的&lt;/b&gt;PU&lt;b&gt;学习&lt;/b&gt;">1.2 <b>基于间谍技术的</b>PU<b>学习</b></a></li>
                                                <li><a href="#63" data-title="1.3 &lt;b&gt;半监督自训练学习&lt;/b&gt;">1.3 <b>半监督自训练学习</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="2 本文算法 ">2 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="2.1 SPYST">2.1 SPYST</a></li>
                                                <li><a href="#103" data-title="2.2 ISPYST">2.2 ISPYST</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="3 仿真实验与分析 ">3 仿真实验与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="3.1 &lt;b&gt;实验说明&lt;/b&gt;">3.1 <b>实验说明</b></a></li>
                                                <li><a href="#129" data-title="3.2 &lt;b&gt;实验结果及分析&lt;/b&gt;">3.2 <b>实验结果及分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="图1 PU学习分类过程">图1 PU学习分类过程</a></li>
                                                <li><a href="#62" data-title="图2 间谍技术分类效果图">图2 间谍技术分类效果图</a></li>
                                                <li><a href="#77" data-title="图3 间谍技术在有噪声或离群点干扰下的分类效果图">图3 间谍技术在有噪声或离群点干扰下的分类效果图</a></li>
                                                <li><a href="#79" data-title="图4 SPYST学习框架">图4 SPYST学习框架</a></li>
                                                <li><a href="#106" data-title="图5 随机间谍样本在训练集中的分布效果图">图5 随机间谍样本在训练集中的分布效果图</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验数据集信息&lt;/b&gt;"><b>表</b>1 <b>实验数据集信息</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;算法&lt;/b&gt;&lt;i&gt;SPYST&lt;/i&gt;&lt;b&gt;和&lt;/b&gt;&lt;i&gt;ISPYST&lt;/i&gt;&lt;b&gt;与传统间谍技术分类效果对比&lt;/b&gt;"><b>表</b>2 <b>算法</b><i>SPYST</i><b>和</b><i>ISPYST</i><b>与传统间谍技术分类效果对比</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;六组算法的平均分类准确率与平均&lt;/b&gt;F-&lt;b&gt;值的对比&lt;/b&gt;"><b>表</b>3 <b>六组算法的平均分类准确率与平均</b>F-<b>值的对比</b></a></li>
                                                <li><a href="#136" data-title="图6 6种算法在9组数据集上的分类准确率与初始正例样本比率的关系">图6 6种算法在9组数据集上的分类准确率与初始正例样本比率的关系</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="158">


                                    <a id="bibliography_1" title="du PLESSIS M C,NIU G,SUGIYAMA M.Class-prior estimation for learning from positive and unlabeled data[J].Machine Learning,2017,106(4):463-492." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD8D70971A953B1966F4D25E08B0B5C284&amp;v=MjY5MjRJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynk4d0t3PU5qN0JhcnZNR2RIRnFJNDBiZTRNZm4wd3lSQmw3a3QvVFFyaXBHQTFDN2ZuUjdLYkNPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        du PLESSIS M C,NIU G,SUGIYAMA M.Class-prior estimation for learning from positive and unlabeled data[J].Machine Learning,2017,106(4):463-492.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_2" title="SANSONE E,de NATALE F G B,ZHOU Z.Efficient training for positive unlabeled learning[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2018,38(7):99-113." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient training for positive unlabeled learning">
                                        <b>[2]</b>
                                        SANSONE E,de NATALE F G B,ZHOU Z.Efficient training for positive unlabeled learning[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2018,38(7):99-113.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_3" title="NIKDELFAZ O,JALILI S.Disease genes prediction by HMMbased PU-learning using gene expression profiles[J].Journal of Biomedical Informatics,2018,81:102-111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1C143F6FEE5BF724134745CCB3FEB24D&amp;v=MTkwNzI2VHQ2VEhxUjMyQTJEOGZtUjc3ckNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhieTh3S3c9TmlmT2ZiTExIOVhQMllrekVaNEtmZ28relJJUw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        NIKDELFAZ O,JALILI S.Disease genes prediction by HMMbased PU-learning using gene expression profiles[J].Journal of Biomedical Informatics,2018,81:102-111.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_4" title="FREY N C,WANG J,BELLIDO G I V,et al.Prediction of synthesis of 2D metal carbides and nitrides(MXenes)and their precursors with positive and unlabeled machine learning[J].ACSNano,2019,13(3):3031-3041." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Prediction of synthesis of 2D metal carbides and nitrides (MXenes)and their precursors with positive and unlabeled machine learning">
                                        <b>[4]</b>
                                        FREY N C,WANG J,BELLIDO G I V,et al.Prediction of synthesis of 2D metal carbides and nitrides(MXenes)and their precursors with positive and unlabeled machine learning[J].ACSNano,2019,13(3):3031-3041.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_5" title="甘洪啸.基于PU学习和贝叶斯网的不确定数据分类研究[D].咸阳:西北农林科技大学,2017:1-61.(GAN H X.Research on uncertain data classification based on PU learning and Bayesian network[D].Xianyang:Northwest A&amp;amp;F University,2017:1-61.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017073749.nh&amp;v=MDYyNzA1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluaFVML01WRjI2R2JPL0hkYklwcEViUElRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        甘洪啸.基于PU学习和贝叶斯网的不确定数据分类研究[D].咸阳:西北农林科技大学,2017:1-61.(GAN H X.Research on uncertain data classification based on PU learning and Bayesian network[D].Xianyang:Northwest A&amp;amp;F University,2017:1-61.)
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_6" title="WU Z,CAO J,WANG Y,et al.h PSD:a hybrid PU-learningbased spammer detection model for product reviews[J].IEEETransactions on Cybernetics,2018(99):1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=h PSD:a hybrid PU-learningbased spammer detection model for product reviews">
                                        <b>[6]</b>
                                        WU Z,CAO J,WANG Y,et al.h PSD:a hybrid PU-learningbased spammer detection model for product reviews[J].IEEETransactions on Cybernetics,2018(99):1-12.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_7" title="VILLATORO-TELLO E,ANGUIANO E,MONTES-Y-GMEZ M,et al.Enhancing semi-supevised text classification using document summaries[C]//Proceedings of the 2016 Ibero-American Conference on Artificial Intelligence,LNCS 10022.Berlin:Springer,2016:115-126." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancing semi-supevised text classification using document summaries">
                                        <b>[7]</b>
                                        VILLATORO-TELLO E,ANGUIANO E,MONTES-Y-GMEZ M,et al.Enhancing semi-supevised text classification using document summaries[C]//Proceedings of the 2016 Ibero-American Conference on Artificial Intelligence,LNCS 10022.Berlin:Springer,2016:115-126.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_8" title="HAN D,LI S,WEI F,et al.Two birds with one stone:classifying positive and unlabeled examples on uncertain data streams[J].Neurocomputing,2018,277:149-160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAD47B1EE8EEA230E16EF2283DB5F095B&amp;v=MDU4MjluM3FyMlpIZk1TVVRML3RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynk4d0t3PU5pZk9mY0xNR3RhK3J2b3diSjU2Zlg0NnoyTVM3RW9MUw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        HAN D,LI S,WEI F,et al.Two birds with one stone:classifying positive and unlabeled examples on uncertain data streams[J].Neurocomputing,2018,277:149-160.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_9" title="ZENG X,LIAO Y,LIU Y,et al.Prediction and validation of disease genes using Hete Sim scores[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics,2017,14(3):687-695." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCMB8EE5F078DFD48021E9B79C66BCA8C3D&amp;v=MjY3Nzc4R3dhNlRKMlk5Q2JKOTVlSGd4enhRU256WVBUM2FScWhSSENzT2NOcm5yQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJ5OHdLdz1OaWZJWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        ZENG X,LIAO Y,LIU Y,et al.Prediction and validation of disease genes using Hete Sim scores[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics,2017,14(3):687-695.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_10" title="YU K,LIU Y,QIN L,et al.Positive and unlabeled learning for user behavior analysis based on mobile Internet traffic data[J].IEEE Access,2018,6:37568-37580." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Positive and unlabeled learning for user behavior analysis based on mobile Internet traffic data">
                                        <b>[10]</b>
                                        YU K,LIU Y,QIN L,et al.Positive and unlabeled learning for user behavior analysis based on mobile Internet traffic data[J].IEEE Access,2018,6:37568-37580.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_11" title="ZHANG Y,LI L,ZHOU J,et al.POSTER:a PU learning based system for potential malicious URL detection[C]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security.New York:ACM,2017:2599-2601." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=POSTER:A PU Learning based System for Potential Malicious URL Detection">
                                        <b>[11]</b>
                                        ZHANG Y,LI L,ZHOU J,et al.POSTER:a PU learning based system for potential malicious URL detection[C]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security.New York:ACM,2017:2599-2601.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_12" title="张璞,刘畅,李逍.基于PU学习的建议语句分类方法[J].计算机应用,2019,39(3):639-643.(ZHANG P,LIU C,LIX.Suggestion sentence classification method based on PU learning[J].Journal of Computer Applications,2019,39(3):639-643.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903005&amp;v=MTU1NzMzenFxQnRHRnJDVVI3cWZadVpzRnluaFVML01MejdCZDdHNEg5ak1ySTlGWVlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        张璞,刘畅,李逍.基于PU学习的建议语句分类方法[J].计算机应用,2019,39(3):639-643.(ZHANG P,LIU C,LIX.Suggestion sentence classification method based on PU learning[J].Journal of Computer Applications,2019,39(3):639-643.)
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_13" title="JUN N L,QING S Z.Semi-Supervised self-training method based on an optimum-path forest[J].IEEE Access,2019,7(1):2169-3536." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised self-training method based on an optimum-path forest">
                                        <b>[13]</b>
                                        JUN N L,QING S Z.Semi-Supervised self-training method based on an optimum-path forest[J].IEEE Access,2019,7(1):2169-3536.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                    TANHA J,van SOMEREN M,AFSARMANESH H.Semi-supervised self-training for decision tree classifiers[J].International Journal of Machine Learning&amp;amp;Cybernetics,2017,8(1):355-370.</a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_15" title="罗云松,吕佳.结合密度峰值优化模糊聚类的自训练方法[J].重庆师范大学学报(自然科学版),2019,36(2):96-102.(LUO Y S,LYU J.Self-training algorithm combined with density peak optimization fuzzy clustering[J].Journal of Chongqing Normal University(Natural Science Edition),2019,36(2):96-102.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CQSF201902016&amp;v=MDUwOTdML01KanpZYUxHNEg5ak1yWTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluaFU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        罗云松,吕佳.结合密度峰值优化模糊聚类的自训练方法[J].重庆师范大学学报(自然科学版),2019,36(2):96-102.(LUO Y S,LYU J.Self-training algorithm combined with density peak optimization fuzzy clustering[J].Journal of Chongqing Normal University(Natural Science Edition),2019,36(2):96-102.)
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_16" title="CAP&lt;image id=&quot;207&quot; type=&quot;formula&quot; href=&quot;images/JSJY201910006_20700.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;M,P&lt;image id=&quot;208&quot; type=&quot;formula&quot; href=&quot;images/JSJY201910006_20800.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;REZ A,LOZANO J A.An efficient approximation to the K-means clustering for massive data[J].Knowledge-Based Systems,2017,117:56-69." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient approximation to the K-means clustering for massive data">
                                        <b>[16]</b>
                                        CAP&lt;image id=&quot;207&quot; type=&quot;formula&quot; href=&quot;images/JSJY201910006_20700.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;M,P&lt;image id=&quot;208&quot; type=&quot;formula&quot; href=&quot;images/JSJY201910006_20800.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;REZ A,LOZANO J A.An efficient approximation to the K-means clustering for massive data[J].Knowledge-Based Systems,2017,117:56-69.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_17" title="FUSILIER D H,MONTES-Y-GMEZ M,ROSSO P,et al.Detecting positive and negative deceptive opinions using PU-learning[J].Information Processing&amp;amp;Management,2015,51(4):433-443." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200048549&amp;v=MTY1MTJVcjNJSVZvWGFoWT1OaWZPZmJLOEg5UE5yWTlGWk84SENYZ3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        FUSILIER D H,MONTES-Y-GMEZ M,ROSSO P,et al.Detecting positive and negative deceptive opinions using PU-learning[J].Information Processing&amp;amp;Management,2015,51(4):433-443.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-08-19 08:55</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),2822-2828 DOI:10.11772/j.issn.1001-9081.2019040606            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于新型间谍技术的半监督自训练正例无标记学习</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%A9%B7%E5%A9%B7&amp;code=23607645&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李婷婷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%95%E4%BD%B3&amp;code=10106201&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕佳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8C%83%E4%BC%9F%E4%BA%9A&amp;code=42248638&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">范伟亚</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0124704&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆师范大学计算机与信息科学学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E5%B8%82%E6%95%B0%E5%AD%97%E5%86%9C%E4%B8%9A%E6%9C%8D%E5%8A%A1%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83(%E9%87%8D%E5%BA%86%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆市数字农业服务工程技术研究中心(重庆师范大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>正例无标记(PU)学习中的间谍技术极易受噪声和离群点干扰,导致划分的可靠正例不纯,且在初始正例中随机选择间谍样本的机制极易造成划分可靠负例时效率低下,针对这些问题提出一种结合新型间谍技术和半监督自训练的PU学习框架。首先,该框架对初始有标记样本进行聚类并选取离聚类中心较近的样本来取代间谍样本,这些样本能有效地映射出无标记样本的分布结构,从而更好地辅助选取可靠负例;然后对间谍技术划分后的可靠正例进行自训练提纯,采用二次训练的方式取回被误分为正例样本的可靠负例。该框架有效地解决了传统间谍技术在PU学习中分类效率易受数据分布干扰以及随机间谍样本影响的问题。通过9个标准数据集上的仿真实验结果表明,所提框架的平均分类准确率和F-值均高于基本PU学习算法(Basic<sub>P</sub>U)、基于间谍技术的PU学习算法(SPY)、基于朴素贝叶斯的自训练PU学习算法(NBST)和基于迭代剪枝的PU学习算法(Pruning)。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A3%E4%BE%8B%E6%97%A0%E6%A0%87%E8%AE%B0%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">正例无标记学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%97%B4%E8%B0%8D%E6%8A%80%E6%9C%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">间谍技术;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8A%E7%9B%91%E7%9D%A3%E8%87%AA%E8%AE%AD%E7%BB%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">半监督自训练;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%AF%E9%9D%A0%E8%B4%9F%E4%BE%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">可靠负例;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%AF%E9%9D%A0%E6%AD%A3%E4%BE%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">可靠正例;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李婷婷(1994—),女,重庆人,硕士研究生,主要研究方向:机器学习、数据挖掘;;
                                </span>
                                <span>
                                    *吕佳(1978—),女,四川达州人,教授,博士,CCF会员,主要研究方向:机器学习、数据挖掘;电子邮箱jia-lun@163.com;
                                </span>
                                <span>
                                    范伟亚(1993—),男,河南开封人,硕士研究生,主要研究方向:数据挖掘、深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>重庆市自然科学基金资助项目(cstc2014jcyjA40011);</span>
                                <span>重庆市教委科技项目(KJ1400513);</span>
                                <span>重庆师范大学科研项目(YKC19018);</span>
                    </p>
            </div>
                    <h1><b>Semi-supervised self-training positive and unlabeled learning based on new spy technology</b></h1>
                    <h2>
                    <span>LI Tingting</span>
                    <span>LYU Jia</span>
                    <span>FAN Weiya</span>
            </h2>
                    <h2>
                    <span>College of Computer and Information Sciences, Chongqing Normal University</span>
                    <span>Chongqing Digital Agricultural Service Engineering Technology Research Center (Chongqing Normal University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Spy technology in Positive and Unlabeled(PU) learning is easily susceptible to noise and outliers, which leads to the impurity of reliable positive instances, and the mechanism of selecting spy instances in the initial positive instances randomly tends to cause inefficiency in dividing reliable negative instances. To solve these problems, a PU learning framework combining new spy technology and semi-supervised self-training was proposed. Firstly, the initial labeled instances were clustered and the instances closer to the cluster center were selected to replace the spy instances. These instances were able to map the distribution structure of unlabeled instances effectively, so as to better assist to the selection of reliable negative instances. Then, the reliable positive instances divided by spy technology were purified by self-training, and the reliable negative instances which were divided as positive instances mistakenly were corrected by secondary training. The proposed framework can solve the problem of PU learning that the classification efficiency of traditional spy technology is susceptible to data distribution and random spy instances. The experiments on nine standard data sets show that the average classification accuracy and F-measure of the proposed framework are higher than those of Basic PU-learning algorithm(Basic<sub>P</sub>U), PU-learning algorithm based on spy technology(SPY), Self-Training PU learning algorithm based on Naive Bayes(NBST) and Iterative pruning based PU learning(Pruning) algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Positive%20and%20Unlabeled(PU)%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Positive and Unlabeled(PU) learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spy%20technology&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spy technology;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=semi-supervised%20self-training&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">semi-supervised self-training;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reliable%20negative%20instance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reliable negative instance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reliable%20positive%20instance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reliable positive instance;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Tingting,born in 1994,M.S.candidate.Her research interests include machine learning,data mining.;
                                </span>
                                <span>
                                    LYU Jia,born in 1978,Ph.D.,professor.Her research interests include machine learning,data mining.;
                                </span>
                                <span>
                                    FAN Weiya,born in 1993,M.S.candidate.His research interests include data mining,deep learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Natural Science Foundation of Chongqing(csts2014jcyj A40011);</span>
                                <span>the Science and Technology Project of Chongqing Education Commission(KJ1400513);</span>
                                <span>the Scientific Research Project of Chongqing Normal University(YKC19018);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="38">正例无标记(Positive and Unlabeled, PU)学习是指训练集在仅含正例样本和无标记样本的情况下训练分类器的过程<citation id="192" type="reference"><link href="158" rel="bibliography" /><link href="160" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。从正例样本和无标记样本中学习分类器是实际应用中一类重要的分类问题,常见于在用户提供的大量数据中检索相似样本、网络评论中的欺骗性意见检测以及医疗行业中疾病基因预测等领域<citation id="193" type="reference"><link href="162" rel="bibliography" /><link href="164" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="39">PU学习的特点是初始有标记样本中没有已标注的负例样本,常见的监督学习或者半监督学习方法在这样的场景中往往失效<citation id="194" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。近年来已有学者展开了相应的研究,即通过找出无标记样本中的可靠负例来扩充初始有标记样本集,进而在重新初始化后的标记样本集上训练分类器对无标记样本进行分类,但该方法得出的可靠负例往往包含较多被误分为负例的正例样本<citation id="195" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。对此,Villatoro-Tello等<citation id="196" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>通过选出无标记样本集中分布较好的负例样本迭代添加到初始已标记样本集中的训练分类器,降低了算法对已标记样本中噪声的敏感性,有效地选出了无标记样本中的可靠负例,并成功地将该方法运用于文本分类领域。Han等<citation id="197" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>进一步研究发现,在选出无标记样本中可靠负例的同时,也可以对应选出无标记样本中的可靠正例,由此提出了一种基于聚类提取可靠正负例样本的方法,并用加权极值学习机对分类器进行训练。实验结果表明,该方法能够有效地对仅含正样本和无标记样本的不确定数据流进行分类。以上方法都是在重新初始化后的已标记样本集上训练分类器,但重新初始化后的已标记样本集中正例样本是绝对可靠的,而负例样本则是相对可靠的,初始化强烈倾向于正例样本,这在一定程度上影响了算法的分类效果。</p>
                </div>
                <div class="p1">
                    <p id="40">为了解决PU学习中重新初始化后的标记样本强烈倾向于正例的问题,Zeng等<citation id="198" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>采用一种能平衡倾向性的间谍技术来重新初始化标记样本,该技术通过将初始正例中部分样本看作间谍样本发送到无标记样本中,通过间谍样本推断出无标记样本中未知正例的行为,同时有效地选出了可靠负例。文献<citation id="199" type="reference">[<a class="sup">10</a>]</citation>将间谍技术应用于移动互联网流量数据的用户行为分析上,提出了基于二分网络特征的PU学习方法用于用户行为分类和预测,利用实际的QQ流量数据和移动视频流量数据验证了该方法的有效性。类似地,文献<citation id="200" type="reference">[<a class="sup">11</a>]</citation>描述了现实获取的数据只包含少量已知的被攻击的统一资源定位符(Uniform Resource Locator, URL)和大量未标记实例,文中将此形式化为PU问题。通过将间谍技术与成本敏感策略相结合,提出一种基于间谍技术的PU学习算法(PU learning algorithm based on spy technology, SPY),用于检测潜在URL攻击。实验结果表明,该方法能够有效地发现潜在的URL攻击。张璞等<citation id="201" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了一种基于间谍技术的PU学习的建议语句分类方法,该方法为了降低特征维度、缓解数据稀疏性,在自编码神经网络特征空间中使用间谍技术划分可靠反例无标注样例进行分类。由此可见,嵌入间谍技术的PU学习方法有效地平衡了初始正负例样本,使其在分类过程中具有更好的泛化性,从而更好地对无标记样本进行分类。</p>
                </div>
                <div class="p1">
                    <p id="41">然而,传统间谍技术极易受噪声和离群点干扰,分类过程中很少考虑到划分结果的纯净度问题,且随机选择间谍样本的机制也给分类结果带来一定的不稳定性。本文鉴于半监督自训练方法可以迭代选取高质量无标记样本对分类器进行更新,更新后的分类器能产生更精准的分类效果,从而提出了间谍技术结合半监督自训练的PU学习方法(PU learning method combining spy technology and semi-supervised Self-Training, SPYST),SPYST通过将间谍技术的分类结果用半监督自训练方法进行二次提纯取得了更有效的分类效果,但SPYST尚未解决间谍样本选择的随机性带来的分类误差。因此,在SPYST的基础上从数据的空间结构出发,将初始正例的空间结构展露出来,然后挑选更具代表性的间谍样本,进一步提出了改进间谍技术后结合半监督自训练的PU学习方法(Improved SPYST, ISPYST)。</p>
                </div>
                <div class="p1">
                    <p id="42">本文的主要工作为:</p>
                </div>
                <div class="p1">
                    <p id="43">1)对PU学习中间谍技术展开研究,结合自训练方法对间谍技术的粗糙分类结果进行二次提纯。现有的国内外文献对间谍技术的研究主要集中于将该技术应用于文本分类、网络意见检测等方面,极少对间谍技术分类结果的纯净度进行研究。</p>
                </div>
                <div class="p1">
                    <p id="44">2) 间谍技术中间谍样本的随机选取给分类结果带来一定的不稳定性,本文通过对初始正例的空间结构进行研究,选取了离聚类中心较近的样本作为间谍样本,这些样本更具代表性,能更好地反映无标记样本中未知正例的行为方式。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="46" name="46">1.1 PU<b>学习</b></h4>
                <div class="p1">
                    <p id="47">PU学习是指在仅包含少量正例样本和无标记样本中进行分类的一种特殊半监督学习,常见的PU学习过程是把无标记样本全部看作负类结合初始正例构造分类器再对无标记样本进行分类,找出无标记样本中隐藏的可靠负例,进而将可靠负例加入初始正例样本重新初始化有标记样本集。分类过程如图1所示,其中<i>P</i>表示初始正例样本,<i>U</i>表示无标记样本,<i>C</i>表示分类器,<i>RN</i>表示可靠负例,<i>P</i>′表示划分出的正例样本,<i>N</i>′表示划分出的负例样本。但该方法获得的标记样本中正例样本是绝对可靠的,所包含的样本信息也绝对准确;而标记样本中负例样本却只是相对可靠,所包含的样本信息的无法达到绝对真实。所以,重新初始化后的标记样本更倾向于正例样本,在后续的分类过程中更利于无标记样本中未知正例的划分,这就造成的分类结果的不平衡性。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 PU学习分类过程" src="Detail/GetImg?filename=images/JSJY201910006_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 PU学习分类过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Classification process of PU learning</p>

                </div>
                <h4 class="anchor-tag" id="49" name="49">1.2 <b>基于间谍技术的</b>PU<b>学习</b></h4>
                <div class="p1">
                    <p id="50">间谍技术是基于解决常见PU学习中重新初始化后标记样本强烈倾向于正例样本而提出,该方法能有效地平衡初始化后标记样本的倾向性问题,同时辅助识别无标记样本中的可靠负例。间谍技术是指通过从初始有标记样本中随机选出部分正例发送到无标记样本集,这些选出的正例样本被称之为间谍样本,它与无标记样本中的未知正例样本的行为是一致的,从而能够可靠地对未知正例样本行为进行评估。混合间谍样本的无标记样本集在分类算法训练完成后,根据间谍样本的后验概率设置阈值<i>θ</i>,当无标记样本属于正类的概率小于<i>θ</i>时,该样本被视为可靠负例,其余样本则被视为可靠正例<citation id="202" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation><sup>2599-2600</sup>。通过间谍技术划分数据类别的详细算法过程如下。</p>
                </div>
                <div class="p1">
                    <p id="51">输入 初始正例样本集<i>P</i>={<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>,…, <i>p</i><sub><i>n</i></sub>},无标记样本集<i>U</i>={<i>u</i><sub>1</sub>,<i>u</i><sub>2</sub>,…,<i>u</i><sub><i>m</i></sub>},标记集合{+1,-1},分类器<i>C</i>。</p>
                </div>
                <div class="p1">
                    <p id="52">输出 可靠负例<i>RN</i>和可靠正例<i>RP</i>。</p>
                </div>
                <div class="p1">
                    <p id="53">Step1:<i>RN</i>=∅,<i>RP</i>=∅;</p>
                </div>
                <div class="p1">
                    <p id="54">Step2:在<i>P</i>中随机选取<i>t</i>个样本组成间谍样本集<i>S</i>,<i>S</i>={<i>s</i><sub>1</sub>,<i>s</i><sub>2</sub>,…,<i>s</i><sub><i>t</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="55">Step3:<i>P</i>=<i>P</i>-<i>S</i>,<i>U</i>=<i>U</i>+<i>S</i>;</p>
                </div>
                <div class="p1">
                    <p id="56">Step4:在<i>P</i>和<i>U</i>上训练<i>C</i>,将训练完成的<i>C</i>对<i>U</i>进行分类;</p>
                </div>
                <div class="p1">
                    <p id="57">Step5:得出<i>S</i>属于正类的后验概率Pr(<i>C</i><sub>1</sub>|<i>S</i>);</p>
                </div>
                <div class="p1">
                    <p id="58">Step6:根据<i>S</i>的后验概率决定概率阈值<i>θ</i>;</p>
                </div>
                <div class="p1">
                    <p id="59">Step7:当Pr(<i>C</i><sub>1</sub>|<i>u</i><sub><i>i</i></sub>)&lt;<i>θ</i>(<i>i</i>=1,2,…,<i>m</i>),<i>RN</i>=<i>RN</i>+<i>u</i><sub><i>i</i></sub>,<i>RP</i>=<i>U</i>-<i>RN</i>;</p>
                </div>
                <div class="p1">
                    <p id="60">Step8:输出<i>RN</i>和<i>RP</i>,算法结束。</p>
                </div>
                <div class="p1">
                    <p id="61">间谍技术中阈值<i>θ</i>的确定是一个关键点,间谍样本集<i>S</i>={<i>s</i><sub>1</sub>,<i>s</i><sub>2</sub>,…,<i>s</i><sub><i>t</i></sub>}在Step5后分配给每个<i>s</i><sub><i>t</i></sub>的后验概率为Pr(<i>C</i><sub>1</sub>|<i>s</i><sub><i>t</i></sub>)。然后,选取<i>S</i>属于正类的最小概率值作为阈值<i>θ</i>,这也就意味着在召回间谍样本的同时找出了隐藏在无标记样本中的可靠负例,即<i>θ</i>=min{Pr(<i>C</i><sub>1</sub>|<i>s</i><sub>1</sub>),Pr(<i>C</i><sub>1</sub>|<i>s</i><sub>2</sub>),…,Pr(<i>C</i><sub>1</sub>|<i>s</i><sub><i>t</i></sub>)}。PU学习中间谍技术实现了图2中给出的效果,其中<i>C</i><sub>1</sub>代表在分类过程中被当作正类的样本集,<i>C</i><sub>-1</sub>代表在分类过程中被当作负类的样本集。间谍技术选取<i>RN</i>时,将<i>S</i>和<i>U</i>的合集看作负类,结合初始正例<i>P</i>对无标记样本进行分类,进而得出<i>RN</i>与<i>RP</i>。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 间谍技术分类效果图" src="Detail/GetImg?filename=images/JSJY201910006_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 间谍技术分类效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Classification result graph of spy technology</p>

                </div>
                <h4 class="anchor-tag" id="63" name="63">1.3 <b>半监督自训练学习</b></h4>
                <div class="p1">
                    <p id="64">半监督自训练是指在无标记样本中选取高质量样本给初始标记样本学习,底层分类器被重新训练,直至无标记样本被全部划分。半监督自训练算法在循环迭代的过程中,不断更新分类器划分无标记样本,使得无标记样本每一次都能在分类器状态最好的情况下被提纯,确保了无标记样本的分类准确率<citation id="203" type="reference"><link href="182" rel="bibliography" /><link href="184" rel="bibliography" /><link href="186" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。半监督自训练算法的一般流程如下:</p>
                </div>
                <div class="p1">
                    <p id="65">输入 初始有标记样本集<i>L</i>,初始无标记样本集<i>U</i>,底层分类器<i>C</i>,迭代次数<i>f</i>,用于选择下一次迭代的无标记样本个数<i>H</i>,选择度量<i>M</i>,选择函数<i>E</i>(<i>U</i><sub><i>f</i></sub>,<i>H</i>,<i>C</i>,<i>M</i>),最大迭代次数<i>Maxlteration</i>。</p>
                </div>
                <div class="p1">
                    <p id="66">输出 分类完成的<i>U</i>。</p>
                </div>
                <div class="p1">
                    <p id="67">Step1:  <i>f</i>=0,<i>L</i><sub><i>f</i></sub>=<i>L</i>,<i>U</i><sub><i>f</i></sub>=<i>U</i>,其中<i>L</i><sub><i>f</i></sub>和<i>U</i><sub><i>f</i></sub>是在第<i>f</i>次迭代时已标记数据和未标记数据的样本集;</p>
                </div>
                <div class="p1">
                    <p id="68">Step2:在<i>L</i><sub><i>f</i></sub>上训练<i>C</i>;</p>
                </div>
                <div class="p1">
                    <p id="69">Step3:<i>E</i><sub><i>f</i></sub>=<i>E</i>(<i>U</i><sub><i>f</i></sub>,<i>H</i>,<i>C</i>,<i>M</i>),<i>E</i><sub><i>f</i></sub>为选出的无标记样本集;</p>
                </div>
                <div class="p1">
                    <p id="70">Step4:<i>U</i><sub><i>f</i></sub><sub>+1</sub>=<i>U</i><sub><i>f</i></sub>-<i>E</i><sub><i>f</i></sub>;<i>L</i><sub><i>f</i></sub><sub>+1</sub>=<i>L</i><sub><i>f</i></sub>+<i>E</i><sub><i>f</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="71">Step5: <i>f</i>= <i>f</i>+1;</p>
                </div>
                <div class="p1">
                    <p id="72">Step6:直到<i>U</i><sub><i>f</i></sub>是空集或达到最大迭代次数<i>Maxlteration</i>,<i>U</i>被分类完成。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag">2 本文算法</h3>
                <h4 class="anchor-tag" id="74" name="74">2.1 SPYST</h4>
                <h4 class="anchor-tag" id="75" name="75">2.1.1 算法思想</h4>
                <div class="p1">
                    <p id="76">在初始数据集分布较好且无噪声或离群点干扰的环境中使用间谍技术识别可靠负例和可靠正例能取得令人满意的效果,然而,大多数真实的数据集都含有噪声或离群点,这样的数据集通过传统间谍技术分类变得不再可靠。原因是:间谍样本中离群点的后验概率Pr(<i>C</i><sub>1</sub>|<i>s</i><sub><i>t</i></sub>)可能比大多数甚至所有的实际的负例样本要小得多。在这种情况下,通过间谍样本的概率值Pr(<i>C</i><sub>1</sub>|<i>s</i><sub><i>t</i></sub>)来确定阈值<i>θ</i>,就无法在召回间谍样本的同时对无标记样本进行有效分类,导致了选出的可靠正例往往不纯,可靠负例过少甚至没有。图3表示在噪声干扰的环境中的分类结果,其中<i>C</i><sub>1</sub>代表在分类过程中被当作正类的样本集,<i>C</i><sub>-1</sub>代表在分类过程中被当作负类的样本集。由图3可知,在有噪声或离群点的环境中通过间谍技术选出可靠负例时效率不高,得出的可靠正例包含较多被误分为正类的负例样本。所以,在数据分布较差的环境中用间谍技术进行PU学习的方法变得不尽人意。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 间谍技术在有噪声或离群点干扰下的分类效果图" src="Detail/GetImg?filename=images/JSJY201910006_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 间谍技术在有噪声或离群点干扰下的分类效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Classification result graph of spy technology with noise and outliers</p>

                </div>
                <div class="p1">
                    <p id="78">因此,本文提出了一种结合间谍技术与半监督自训练的PU学习方法SPYST。SPYST在间谍技术对无标记样本首次分类完成后,将<i>RP</i>看作新的无标记样本<i>U</i>′,并对新的无标记样本进行自训练提纯,此处选用稳定性较强的朴素贝叶斯作为分类器。SPYST首先对新的无标记样本做朴素贝叶斯分类,然后将分类置信度从高到低排序,选出置信度较高的无标记样本及其相应的类标签添加到初始正例样本与<i>RN</i>的合集中,这主要是因为高置信度样本携带更多有效分布信息,利于分类器的重新训练。循环迭代上述过程直至新的无标记样本被全部划分完成。这也就达到了对间谍技术的粗糙分类结果进行精细化提纯的目的,从而得出了分类效率更高的PU学习框架。SPYST整体学习框架如图4所示,其中<i>P</i>表示初始正例样本,<i>U</i>表示无标记样本,<i>S</i>表示选出的间谍样本,<i>C</i>表示朴素贝叶斯分类器,<i>RN</i>表示可靠负例,<i>RP</i>表示可靠正例,<i>topf</i>表示选出的前<i>f</i>个高置信度样本。</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SPYST学习框架" src="Detail/GetImg?filename=images/JSJY201910006_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SPYST学习框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Learning framework of SPYST</p>

                </div>
                <h4 class="anchor-tag" id="80" name="80">2.1.2 SPYST算法流程</h4>
                <div class="p1">
                    <p id="81">输入 初始正例样本集<i>P</i>={<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>,…, <i>p</i><sub><i>n</i></sub>},初始无标记样本集<i>U</i>={<i>u</i><sub>1</sub>,<i>u</i><sub>2</sub>,…,<i>u</i><sub><i>m</i></sub>},间谍样本集<i>S</i>=∅,可靠负例集<i>RN</i>=∅,可靠正例集<i>RP</i>=∅,标记集合{+1,-1},分类器<i>C</i>为朴素贝叶斯分类器。</p>
                </div>
                <div class="p1">
                    <p id="82">输出 训练完成的分类器SPYST。</p>
                </div>
                <div class="p1">
                    <p id="83">Step1 用传统间谍技术重新初始化<i>P</i>和<i>U</i>。</p>
                </div>
                <div class="p1">
                    <p id="84">Step1.1 在<i>P</i>中随机选出<i>t</i>个样本作间谍样本,即<i>S</i>={<i>s</i><sub>1</sub>,<i>s</i><sub>2</sub>,…,<i>s</i><sub><i>t</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="85">Step1.2 隐藏<i>S</i>的类标签,并将<i>S</i>发送至<i>U</i>;</p>
                </div>
                <div class="p1">
                    <p id="86">Step1.3 得出<i>P</i>=<i>P</i>-<i>S</i>,<i>U</i>=<i>U</i>+<i>S</i>。</p>
                </div>
                <div class="p1">
                    <p id="87">Step2 将包含间谍样本的<i>U</i>看作负类。</p>
                </div>
                <div class="p1">
                    <p id="88">Step3 在<i>P</i>和<i>U</i>上训练<i>C</i>。</p>
                </div>
                <div class="p1">
                    <p id="89">Step4 将训练好的<i>C</i>对<i>U</i>进行分类,并得出<i>U</i>属于正类的后验概率Pr(<i>C</i><sub>1</sub>|<i>U</i>)。</p>
                </div>
                <div class="p1">
                    <p id="90">Step5 计算出<i>S</i>属于正类的后验概率Pr(<i>C</i><sub>1</sub>|<i>S</i>)。</p>
                </div>
                <div class="p1">
                    <p id="91">Step6 根据<i>S</i>的后验概率决定概率阈值</p>
                </div>
                <div class="p1">
                    <p id="92"><i>θ</i>=min{Pr(<i>C</i><sub>1</sub>|<i>s</i><sub>1</sub>),Pr(<i>C</i><sub>1</sub>|<i>s</i><sub>2</sub>),…,Pr(<i>C</i><sub>1</sub>|<i>s</i><sub><i>t</i></sub>)}</p>
                </div>
                <div class="p1">
                    <p id="93">Step7 当Pr(<i>C</i><sub>1</sub>|<i>u</i><sub><i>i</i></sub>)&lt;<i>θ</i>(<i>i</i>=1,2,…,<i>m</i>),<i>RN</i>=<i>RN</i>+<i>u</i><sub><i>i</i></sub>,<i>RP</i>=<i>U</i>-<i>RN</i>。</p>
                </div>
                <div class="p1">
                    <p id="94">Step8 输出<i>RN</i>和<i>RP</i>。</p>
                </div>
                <div class="p1">
                    <p id="95">Step9 召回所有的间谍样本<i>P</i>=<i>P</i>+<i>S</i>。</p>
                </div>
                <div class="p1">
                    <p id="96">Step10 重新赋予<i>P</i>正例标号,赋予<i>RN</i>负类标号,并隐藏<i>RP</i>类标签,将<i>RP</i>看作新的无标记样本集<i>U</i>′。</p>
                </div>
                <div class="p1">
                    <p id="97">Step11 在<i>P</i>和<i>RN</i>上再次训练<i>C</i>,将训练好的<i>C</i>对<i>U</i>′进行分类,得出<i>U</i>′中样本所属类别的后验概率最大值<i>P</i><sub><i>r</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="98">Step12 将<i>P</i><sub><i>r</i></sub>做降序排序,并选出前<i>f</i>个高置信度样本。</p>
                </div>
                <div class="p1">
                    <p id="99">Step13 将选出的<i>f</i>个高置信度样本以及其对应的类标签加入<i>P</i>和<i>RN</i>中,然后重新训练<i>C</i>。</p>
                </div>
                <div class="p1">
                    <p id="100">Step14 将<i>U</i>′减去挑选出的<i>f</i>个高置信度样本后,形成新的<i>U</i>′。</p>
                </div>
                <div class="p1">
                    <p id="101">Step15 重复Step10到Step14,直到<i>U</i>′为空。</p>
                </div>
                <div class="p1">
                    <p id="102">Step16 循环结束,初始无标记<i>U</i>全部分类完成。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">2.2 ISPYST</h4>
                <h4 class="anchor-tag" id="104" name="104">2.2.1 算法思想</h4>
                <div class="p1">
                    <p id="105">在SPYST算法流程的Step1中,通过随机选取的机制选出了初始正例中的间谍样本,但这种随机性就可能导致间谍样本处于类簇的边界位置,如图5所示,图中圈出了初始正例中随机选取的间谍样本,并赋予间谍样本1～11的编号。从图5可看出:编号为1和11的两个间谍样本对于初始正例集来说,属于离群点,而编号为3的间谍样本属于噪声点,这些间谍样本与无标记样本中未知正例的空间结构相似度较低,无法有效地对无标记样本的空间结构进行评估。在随机选择间谍样本时,若大量的噪声或离群点被选作间谍样本,会极大地影响分类器对无标记样本的评估,这种随机选择的机制直接导致了分类效率的降低。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 随机间谍样本在训练集中的分布效果图" src="Detail/GetImg?filename=images/JSJY201910006_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 随机间谍样本在训练集中的分布效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Distribution effect graph of random spy instances in training set</p>

                </div>
                <div class="p1">
                    <p id="107">因此,本文在算法SPYST的基础上提出了一种结合改进的间谍技术与自训练方法的PU学习算法ISPYST,有效地降低间谍样本的随机性带来的分类误差。ISPYST通过挖掘出初始正例样本的空间分布信息来改进SPYST算法,在把握空间结构的基础上计算正例样本的聚类中心,并找出距离聚类中心较近的样本作为间谍样本。这些样本在空间结构上离聚类中心更近,所包含正例样本的真实信息量也更大,当这样的样本被选作间谍样本时,更能有效地体现无标记样本中未知正例的分布情况。在此,本文选用了简单实用且收敛速度较快的<i>K</i>-Means聚类算法对初始正例进行聚类,<i>K</i>-Means算法的思想很简单,对于给定的样本集<i>X</i>,按照样本之间的距离大小,将样本集划分为<i>K</i>个簇,让簇内的点尽量紧密地连在一起,而让簇间的距离尽量地大,将离聚类中心较近的正例样本选作间谍样本<citation id="204" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108">2.2.2 ISPYST算法流程</h4>
                <div class="p1">
                    <p id="109">ISPYST仅对SPYST算法流程的Step 1进行替换,即ISPYST通过找出初始正例集上离聚类中心较近的样本代替传统随机选择的间谍样本,而SPYST其余步骤Step2至Step16不变,替换完成后形成新算法ISPYST。具体替换步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="110">Step1 用改进后的间谍技术重新初始化<i>P</i>和<i>U</i>。</p>
                </div>
                <div class="p1">
                    <p id="111">Step1.1 在<i>P</i>中随机一个样本作为初始质心向量<i>μ</i>;</p>
                </div>
                <div class="p1">
                    <p id="112">Step1.2 初始化簇<i>Cluster</i>=∅;</p>
                </div>
                <div class="p1">
                    <p id="113">Step1.3 对于<i>j</i>=1,2,…,<i>n</i>,计算样本<i>P</i><sub><i>j</i></sub>和质心向量<i>μ</i>的距离<i>D</i><sub><i>j</i></sub>=‖<i>P</i><sub><i>j</i></sub>-<i>μ</i>‖<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="114">Step1.4 更新<i>Cluster</i>=<i>Cluster</i>∪{<i>P</i><sub><i>j</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="115">Step1.5 对<i>Cluster</i>中所有样本点重新计算新的质心<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">μ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>C</mi><mi>l</mi><mi>u</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ρ</mi><mo>∈</mo><mi>C</mi><mi>l</mi><mi>u</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi></mrow></munder><mi>Ρ</mi></mstyle><mo>;</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="116">Step1.6 重复Step 1.2到Step 1.5直到质心向量<i>μ</i>不再发生变化时,输出质心向量<i>μ</i>;</p>
                </div>
                <div class="p1">
                    <p id="117">Step1.7 计算出<i>P</i>中所有样本与质心的距离<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>,并将<i>d</i>做升序排序,并选出距离较近的前<i>t</i>个样本作为间谍样本,<i>S</i>={<i>s</i><sub>1</sub>,<i>s</i><sub>2</sub>,…,<i>s</i><sub><i>t</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="118">Step1.8 更新<i>P</i>=<i>P</i>-<i>S</i>,<i>U</i>=<i>U</i>+<i>S</i>。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag">3 仿真实验与分析</h3>
                <h4 class="anchor-tag" id="120" name="120">3.1 <b>实验说明</b></h4>
                <div class="p1">
                    <p id="121">为了验证算法<i>SPYST</i>以及<i>ISPYST</i>的有效性,选用以下算法进行对比实验:</p>
                </div>
                <div class="p1">
                    <p id="122">1)基本<i>PU</i>学习算法(<i>Basic PU</i>-<i>learning algorithm</i>, <i>Basic</i>_<i>PU</i>)。</p>
                </div>
                <div class="p1">
                    <p id="123">2)基于间谍技术的<i>PU</i>学习算法(<i>SPY</i>)<citation id="205" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation><sup>2600</sup>。</p>
                </div>
                <div class="p1">
                    <p id="124">3)基于朴素贝叶斯的自训练<i>PU</i>学习算法(<i>Self</i>-<i>Training PU learning algorithm based on Naive Bayes</i>, <i>NBST</i>)。</p>
                </div>
                <div class="p1">
                    <p id="125">4)基于迭代剪枝的<i>PU</i>学习(<i>iterative Pruning based PU learning</i>, <i>Pruning</i>)<citation id="206" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="126">对比实验所用数据集来自于<i>UCI</i>和<i>Kaggle</i>数据库,总共选用9组二分类数据进行实验说明,数据集名称、规模以及属性数见表1。</p>
                </div>
                <div class="p1">
                    <p id="127">实验过程中,把数据集随机划分成训练集和测试集两部分,其中训练集占80%,测试集占20%。首先选出训练集中20%的正例样本作为初始有标记样本,然后将剩余80%的正例样本以及训练集中全部的负例样本除去标签后作为无标记样本集。所有算法重复实验50次,以平均分类准确率以及<i>F</i>-值作为算法性能评价指标。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表</b>1 <b>实验数据集信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Information of experimental datasets</i></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td><br />数据集</td><td>规模</td><td>属性数</td></tr><tr><td><br /><i>Wholesale customers</i></td><td>440</td><td>7</td></tr><tr><td><br /><i>Somerville Happiness Survey</i></td><td>143</td><td>6</td></tr><tr><td><br /><i>Balance Scale</i></td><td>625</td><td>4</td></tr><tr><td><br /><i>Vertebral Column</i></td><td>310</td><td>6</td></tr><tr><td><br /><i>Electrical Grid Stability Simulated</i></td><td>10 000</td><td>13</td></tr><tr><td><br /><i>Breast Cancer Wisconsin Prognostic</i>(<i>wdbc</i>)</td><td>516</td><td>30</td></tr><tr><td><br /><i>Haberman</i>'<i>s Survival</i></td><td>306</td><td>3</td></tr><tr><td><br /><i>pima</i></td><td>768</td><td>8</td></tr><tr><td><br /><i>Banknote authentication</i></td><td>1 372</td><td>4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">3.2 <b>实验结果及分析</b></h4>
                <div class="p1">
                    <p id="130">为了证明本文算法较传统间谍技术的分类性能有所提升,设置了如表2 所示的实验。表2显示了当初始有标记样本占全部正例样本的20%,且间谍样本占初始正例的15%时,本文算法与传统间谍技术的分类效果提升率。</p>
                </div>
                <div class="p1">
                    <p id="131">由表2可知,改进后的算法<i>SPYST</i>对比传统的间谍技术在进行<i>PU</i>学习的过程中整体上具有更好的分类性能。传统的间谍技术在数据集<i>Somerville Happiness Survey</i>和<i>Vertebral Column</i>上分类效果极其异常,说明<i>SPY</i>根本无法在这样的数据集上做<i>PU</i>分类。通过分析得知这两组数据集初始分布不均匀,且其中包含大量噪声和离群点,而<i>SPY</i>对噪声和离群点异常敏感,且<i>SPY</i>在初始正例过少的情况下极难捕捉有效信息,导致了该方法分类效率低下。本文所提算法<i>SPYST</i>通过对<i>SPY</i>的分类结果做深度自训练,不断迭代提纯可靠正例,从而取得了更高的分类效率。由于<i>SPYST</i>采用随机选取间谍样本的机制,导致分类结果存在一定的不稳定性,针对这一问题,本文提出了改进后的算法<i>ISPYST</i>,该方法基于初始正例的空间结构选取最具代表性的正例作间谍样本,有效地减小了随机性带来的分类误差,从而提高了分类效率。从表2可以看出,<i>ISPYST</i>的分类效果在<i>SPYST</i>的基础上整体得到了进一步的提升。而在数据集<i>Banknote authentication</i>上,算法<i>ISPYST</i>的分类提升率相对低于算法<i>SPYST</i>,这是因为该数据集的数据分布过于集中,导致选出的间谍样本结构极其相似,所含的样本信息不能很好地对无标记样本中的未知正例进行评估。因此,算法<i>ISPYST</i>在空间分布过于密集的数据集上还存在一定的局限性。</p>
                </div>
                <div class="p1">
                    <p id="132">为了进一步验证本文所提算法<i>SPYST</i>与<i>ISPYST</i>的有效性,表3给出了当初始有标记样本占全部正例样本的20%,且间谍样本占初始正例的15%时,本文算法与4组对比算法的实验结果。</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表</b>2 <b>算法</b><i>SPYST</i><b>和</b><i>ISPYST</i><b>与传统间谍技术分类效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.2 <i>Classification effects of SPYST</i>, <i>ISPYST and traditional spy technology</i></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td rowspan="3">数据集</td><td rowspan="2" colspan="2"><br /><i>SPY</i></td><td rowspan="3"></td><td rowspan="2" colspan="2"><br /><i>SPYST</i></td><td rowspan="3"></td><td rowspan="2" colspan="2"><br /><i>ISPYST</i></td><td rowspan="3"></td><td colspan="5"><br />相对变化百分点</td></tr><tr><td colspan="2"><br /><i>SPYST</i>与<i>SPY</i>比</td><td rowspan="2"></td><td colspan="2"><br /><i>ISPYST</i>与<i>SPYST</i>比</td></tr><tr><td><br />准确率/%</td><td>F-值/%</td><td><br />准确率/%</td><td>F-值/%</td><td><br />准确率/%</td><td>F-值/%</td><td><br />准确率</td><td>F-值</td><td><br />准确率</td><td>F-值</td></tr><tr><td><i>Wholesale customers</i></td><td>82.05</td><td>88.56</td><td></td><td>85.23</td><td>88.96</td><td></td><td>86.82</td><td>89.73</td><td></td><td>3.18</td><td>0.40</td><td></td><td>1.59</td><td>0.77</td></tr><tr><td><br /><i>Somerville Happiness Survey</i></td><td>49.66</td><td>14.11</td><td></td><td>54.14</td><td>48.78</td><td></td><td>56.07</td><td>54.77</td><td></td><td>4.48</td><td>34.67</td><td></td><td>1.93</td><td>5.99</td></tr><tr><td><br /><i>Balance Scale</i></td><td>57.44</td><td>11.24</td><td></td><td>71.60</td><td>71.19</td><td></td><td>79.89</td><td>73.85</td><td></td><td>14.16</td><td>59.95</td><td></td><td>8.29</td><td>2.66</td></tr><tr><td><br /><i>Vertebral Column</i></td><td>40.65</td><td>22.75</td><td></td><td>66.52</td><td>73.26</td><td></td><td>67.45</td><td>68.98</td><td></td><td>25.87</td><td>50.51</td><td></td><td>0.93</td><td>-4.28</td></tr><tr><td><br /><i>Electrical Grid Stability</i><br /><i>Simulated</i></td><td>83.61</td><td>68.87</td><td></td><td>97.73</td><td>96.88</td><td></td><td>98.06</td><td>97.08</td><td></td><td>14.12</td><td>28.01</td><td></td><td>0.33</td><td>0.20</td></tr><tr><td><br /><i>Breast Cancer Wisconsin</i><br /><i>Prognostic</i>(<i>wdbc</i>)</td><td>86.74</td><td>78.81</td><td></td><td>90.64</td><td>86.45</td><td></td><td>91.53</td><td>86.69</td><td></td><td>3.90</td><td>7.64</td><td></td><td>0.89</td><td>0.24</td></tr><tr><td><br /><i>Haberman</i>'<i>s Survival</i></td><td>51.15</td><td>49.40</td><td></td><td>68.33</td><td>77.38</td><td></td><td>69.08</td><td>77.50</td><td></td><td>17.18</td><td>27.98</td><td></td><td>0.75</td><td>0.12</td></tr><tr><td><br /><i>pima</i></td><td>56.34</td><td>49.84</td><td></td><td>68.23</td><td>78.08</td><td></td><td>70.45</td><td>78.53</td><td></td><td>11.89</td><td>28.24</td><td></td><td>2.22</td><td>0.45</td></tr><tr><td><br /><i>Banknote authentication</i></td><td>63.11</td><td>29.45</td><td></td><td>70.67</td><td>58.32</td><td></td><td>69.28</td><td>53.11</td><td></td><td>7.56</td><td>28.87</td><td></td><td>-1.39</td><td>-5.21</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:表中数值均为平均值。</p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表</b>3 <b>六组算法的平均分类准确率与平均</b>F-<b>值的对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.3 <i>Comparison of average classification accuracy and</i> F-<i>measure of six algorithms</i></p>
                    <p class="img_note">单位:%</p>
                    <table id="134" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="6"><br />平均分类准确率</td><td rowspan="2"></td><td colspan="6"><br />平均F-值</td></tr><tr><td><br /><i>Basic</i>_<i>PU</i></td><td><i>SPY</i></td><td><i>NBST</i></td><td><i>Pruning</i></td><td><i>SPYST</i></td><td><i>ISPYST</i></td><td><br /><i>Basic</i>_<i>PU</i></td><td><i>SPY</i></td><td><i>NBST</i></td><td><i>Pruning</i></td><td><i>SPYST</i></td><td><i>ISPYST</i></td></tr><tr><td><i>Wholesale customers</i></td><td>78.00</td><td>82.05</td><td>76.86</td><td>81.77</td><td>85.23</td><td>86.82</td><td></td><td>80.46</td><td>88.56</td><td>79.24</td><td>86.86</td><td>88.96</td><td>89.73</td></tr><tr><td><br /><i>Somerville Happiness</i><br /><i>Survey</i></td><td>48.28</td><td>49.66</td><td>52.41</td><td>48.97</td><td>54.14</td><td>56.07</td><td></td><td>14.75</td><td>14.11</td><td>17.26</td><td>28.70</td><td>48.78</td><td>54.77</td></tr><tr><td><br /><i>Balance Scale</i></td><td>60.08</td><td>57.44</td><td>59.12</td><td>62.16</td><td>71.60</td><td>79.89</td><td></td><td>25.66</td><td>11.24</td><td>15.32</td><td>27.14</td><td>71.19</td><td>73.85</td></tr><tr><td><br /><i>Vertebral Column</i></td><td>43.06</td><td>40.65</td><td>45.32</td><td>54.52</td><td>66.52</td><td>67.45</td><td></td><td>34.45</td><td>22.75</td><td>30.48</td><td>51.89</td><td>73.26</td><td>68.98</td></tr><tr><td><br /><i>Electrical Grid</i><br /><i>Stability Simulated</i></td><td>93.86</td><td>83.61</td><td>95.92</td><td>96.88</td><td>97.73</td><td>98.06</td><td></td><td>90.62</td><td>68.87</td><td>94.00</td><td>95.53</td><td>96.88</td><td>97.08</td></tr><tr><td><br /><i>Breast Cancer Wisconsin</i><br /><i>Prognostic</i>(<i>wdbc</i>)</td><td>89.01</td><td>86.74</td><td>85.86</td><td>90.49</td><td>90.64</td><td>91.53</td><td></td><td>83.78</td><td>78.81</td><td>77.95</td><td>86.65</td><td>86.45</td><td>86.69</td></tr><tr><td><br /><i>Haberman</i>'<i>s Survival</i></td><td>51.15</td><td>51.15</td><td>55.19</td><td>44.81</td><td>68.33</td><td>69.08</td><td></td><td>49.41</td><td>49.40</td><td>55.54</td><td>44.14</td><td>77.38</td><td>77.50</td></tr><tr><td><br /><i>pima</i></td><td>63.94</td><td>56.34</td><td>57.45</td><td>60.81</td><td>68.23</td><td>70.45</td><td></td><td>63.90</td><td>49.84</td><td>54.21</td><td>63.70</td><td>78.08</td><td>78.53</td></tr><tr><td><br /><i>Banknote authentication</i></td><td>66.72</td><td>63.11</td><td>66.02</td><td>65.42</td><td>70.67</td><td>69.28</td><td></td><td>40.98</td><td>29.45</td><td>42.35</td><td>45.77</td><td>58.32</td><td>53.11</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">从表3可看出,当初始有标记样本占全部正例样本的20%时,本文所提算法<i>SPYST</i>与<i>ISPYST</i>整体性能均优于对比算法。在数据集<i>Somerville Happiness Survey</i>、<i>Balance Scale</i>、<i>Vertebral Column</i>以及<i>Haberman</i>'<i>s Survival</i>上有较好的体现,这主要是因为这四个数据集初始分布太差,对比算法易受噪声干扰,无法有效地利用少量初始正例中的有用信息,导致分类误判率过高;而<i>SPYST</i>通过对间谍技术的分类结果进行再次的精细化提纯,得出了更好的分类效果;<i>ISPYST</i>在<i>SPYST</i>的基础上对初始正例样本的空间结构做深入剖析,选出更具代表性的间谍样本,使得<i>SPYST</i>的分类效果得以进一步提升。在数据集<i>Breast Cancer Wisconsin Prognostic</i>(<i>wdbc</i>)和<i>Electrical Grid Stability Simulated</i>上,本文算法和对比算法分类效果整体相差不大,这是因为这两组数据集原始分布较为均匀,没有噪声和离群点的干扰,本文算法在这样的数据集上进行分类时,提升效果不明显。</p>
                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 6种算法在9组数据集上的分类准确率与初始正例样本比率的关系" src="Detail/GetImg?filename=images/JSJY201910006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 6种算法在9组数据集上的分类准确率与初始正例样本比率的关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.6 <i>Relationship between classification accuracy and initial positive instance proportion of</i> 6 <i>algorithms on</i> 9 <i>datasets</i></p>

                </div>
                <div class="p1">
                    <p id="137">为了说明初始正例样本占比对各个算法的影响,图6通过逐步提高初始正例样本的占比进行分类实验,得出不同算法在初始样本数量不同情况下的准确率。从图6可看出,本文所提算法<i>SPYST</i>与<i>ISPYST</i>分类准确率整体上高于对比算法,尤其是在<i>Wholesale customers</i>、<i>Somerville Happiness Survey</i>、<i>Vertebral Column</i>、<i>Haberman</i>'<i>s Survival</i>、 <i>pima</i>以及<i>Banknote authentication</i>这6个数据集上,本文算法在初始正例占比极小的情况下相对于对比算法有较好的分类性能。这是因为<i>SPYST</i>对间谍技术的粗糙分类结果进行自训练加工,能得到更高的分类准确率。此外,<i>ISPYST</i>将少量初始正例的空间结构清晰地展示出来,选出了最能体现无标记样本中未知正例行为的样本作为间谍样本,解决了传统间谍技术随机选择间谍样本所带来的分类误差。而随着初始正例占比的不断增加,本文所提算法的分类优势逐渐减弱,在数据集<i>Breast Cancer Wisconsin Origina</i>、<i>Electrical Grid Stability Simulated</i>、 <i>pima</i>以及<i>Habermans Survival</i>上表现得尤为明显,这主要是因为在初始正例足够多的情况下,样本包含的有用信息更全面,所有算法都能有效地捕捉样本信息,从而达到较好的分类效果。<i>SPYST</i>与<i>ISPYST</i>倾向于在初始正例极其缺失的情况下做<i>PU</i>学习,当初始正例较多的情况下,本文所提算法并不占优势,甚至可能处于劣势。在数据集<i>Banknote authentication</i>上,改进后的算法<i>ISPYST</i>比<i>SPYST</i>分类效果差,这是因为该数据集的原始数据分布过于密集,在找出离聚类中心较近的样本作间谍样本时,间谍样本相互之间的区分度并不明显,导致间谍样本无法有效地提取无标记样本中正例样本的信息。算法<i>ISPYST</i>在空间分布过于密集的数据集上进行<i>PU</i>学习时会出现过拟合现象,降低了算法的分类性能。</p>
                </div>
                <h3 id="138" name="138" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="139">针对<i>PU</i>学习方法在初始正例过少的环境中难以有效地获取样本空间结构信息,且传统间谍技术易受噪声和离群点干扰,导致划分可靠负例时效率不高、得出的可靠正例不纯等问题,提出了两种学习框架,即间谍技术结合自训练的<i>PU</i>学习方法(<i>SPYST</i>)以及改进间谍技术后结合自训练的<i>PU</i>学习方法(<i>ISPYST</i>)。<i>SPYST</i>通过对间谍技术的分类结果进行二次训练,选取高置信度样本加入已标记样本集迭代自训练,解决了部分样本被误标记的问题;<i>ISPYST</i>在<i>SPYST</i>的基础上利用初始正例空间结构所包含的潜在信息,选出距离簇中心较近的样本作为间谍样本,这些间谍样本更能体现正例的行为特征,从而有效地划分出可靠正例与可靠负例。在9组标准数据集上的对比实验证实了本文所提算法在仅含少量初始正例的环境中也能捕获全面的数据分布信息,进而得出更好的分类效果。但本文算法在数据分布过于密集的数据集上还存在一定的局限性,因此,在后续工作中,将讨论如何通过挖掘数据集原始分布特征来获取有用信息,从而选出可靠负例来扩充初始有标记样本集,进而提高<i>PU</i>学习的分类性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="158">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD8D70971A953B1966F4D25E08B0B5C284&amp;v=MjM5ODZ1SFlmT0dRbGZCckxVMDV0cGh4Ynk4d0t3PU5qN0JhcnZNR2RIRnFJNDBiZTRNZm4wd3lSQmw3a3QvVFFyaXBHQTFDN2ZuUjdLYkNPTnZGU2lXV3I3SklGcG1hQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>du PLESSIS M C,NIU G,SUGIYAMA M.Class-prior estimation for learning from positive and unlabeled data[J].Machine Learning,2017,106(4):463-492.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient training for positive unlabeled learning">

                                <b>[2]</b>SANSONE E,de NATALE F G B,ZHOU Z.Efficient training for positive unlabeled learning[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2018,38(7):99-113.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1C143F6FEE5BF724134745CCB3FEB24D&amp;v=MTMyOTBmbVI3N3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynk4d0t3PU5pZk9mYkxMSDlYUDJZa3pFWjRLZmdvK3pSSVM2VHQ2VEhxUjMyQTJEOA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>NIKDELFAZ O,JALILI S.Disease genes prediction by HMMbased PU-learning using gene expression profiles[J].Journal of Biomedical Informatics,2018,81:102-111.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Prediction of synthesis of 2D metal carbides and nitrides (MXenes)and their precursors with positive and unlabeled machine learning">

                                <b>[4]</b>FREY N C,WANG J,BELLIDO G I V,et al.Prediction of synthesis of 2D metal carbides and nitrides(MXenes)and their precursors with positive and unlabeled machine learning[J].ACSNano,2019,13(3):3031-3041.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017073749.nh&amp;v=MDkxNjFyQ1VSN3FmWnVac0Z5bmhVTC9NVkYyNkdiTy9IZGJJcHBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>甘洪啸.基于PU学习和贝叶斯网的不确定数据分类研究[D].咸阳:西北农林科技大学,2017:1-61.(GAN H X.Research on uncertain data classification based on PU learning and Bayesian network[D].Xianyang:Northwest A&amp;F University,2017:1-61.)
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=h PSD:a hybrid PU-learningbased spammer detection model for product reviews">

                                <b>[6]</b>WU Z,CAO J,WANG Y,et al.h PSD:a hybrid PU-learningbased spammer detection model for product reviews[J].IEEETransactions on Cybernetics,2018(99):1-12.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancing semi-supevised text classification using document summaries">

                                <b>[7]</b>VILLATORO-TELLO E,ANGUIANO E,MONTES-Y-GMEZ M,et al.Enhancing semi-supevised text classification using document summaries[C]//Proceedings of the 2016 Ibero-American Conference on Artificial Intelligence,LNCS 10022.Berlin:Springer,2016:115-126.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAD47B1EE8EEA230E16EF2283DB5F095B&amp;v=MTg2MzZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhieTh3S3c9TmlmT2ZjTE1HdGErcnZvd2JKNTZmWDQ2ejJNUzdFb0xTbjNxcjJaSGZNU1VUTC90Q09Odg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>HAN D,LI S,WEI F,et al.Two birds with one stone:classifying positive and unlabeled examples on uncertain data streams[J].Neurocomputing,2018,277:149-160.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCMB8EE5F078DFD48021E9B79C66BCA8C3D&amp;v=MjIzNTU9TmlmSVk4R3dhNlRKMlk5Q2JKOTVlSGd4enhRU256WVBUM2FScWhSSENzT2NOcm5yQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJ5OHdLdw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>ZENG X,LIAO Y,LIU Y,et al.Prediction and validation of disease genes using Hete Sim scores[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics,2017,14(3):687-695.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Positive and unlabeled learning for user behavior analysis based on mobile Internet traffic data">

                                <b>[10]</b>YU K,LIU Y,QIN L,et al.Positive and unlabeled learning for user behavior analysis based on mobile Internet traffic data[J].IEEE Access,2018,6:37568-37580.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=POSTER:A PU Learning based System for Potential Malicious URL Detection">

                                <b>[11]</b>ZHANG Y,LI L,ZHOU J,et al.POSTER:a PU learning based system for potential malicious URL detection[C]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security.New York:ACM,2017:2599-2601.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903005&amp;v=MjQ3NjdmWnVac0Z5bmhVTC9NTHo3QmQ3RzRIOWpNckk5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>张璞,刘畅,李逍.基于PU学习的建议语句分类方法[J].计算机应用,2019,39(3):639-643.(ZHANG P,LIU C,LIX.Suggestion sentence classification method based on PU learning[J].Journal of Computer Applications,2019,39(3):639-643.)
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised self-training method based on an optimum-path forest">

                                <b>[13]</b>JUN N L,QING S Z.Semi-Supervised self-training method based on an optimum-path forest[J].IEEE Access,2019,7(1):2169-3536.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                TANHA J,van SOMEREN M,AFSARMANESH H.Semi-supervised self-training for decision tree classifiers[J].International Journal of Machine Learning&amp;Cybernetics,2017,8(1):355-370.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CQSF201902016&amp;v=MjM2NTVFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluaFVML01KanpZYUxHNEg5ak1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>罗云松,吕佳.结合密度峰值优化模糊聚类的自训练方法[J].重庆师范大学学报(自然科学版),2019,36(2):96-102.(LUO Y S,LYU J.Self-training algorithm combined with density peak optimization fuzzy clustering[J].Journal of Chongqing Normal University(Natural Science Edition),2019,36(2):96-102.)
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient approximation to the K-means clustering for massive data">

                                <b>[16]</b>CAP<image id="207" type="formula" href="images/JSJY201910006_20700.jpg" display="inline" placement="inline"><alt></alt></image>M,P<image id="208" type="formula" href="images/JSJY201910006_20800.jpg" display="inline" placement="inline"><alt></alt></image>REZ A,LOZANO J A.An efficient approximation to the K-means clustering for massive data[J].Knowledge-Based Systems,2017,117:56-69.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200048549&amp;v=MTU1NzRmT2ZiSzhIOVBOclk5RlpPOEhDWGd3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZvWGFoWT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>FUSILIER D H,MONTES-Y-GMEZ M,ROSSO P,et al.Detecting positive and negative deceptive opinions using PU-learning[J].Information Processing&amp;Management,2015,51(4):433-443.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910006" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910006&amp;v=Mjg3NDU3RzRIOWpOcjQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bmhVTC9NTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
