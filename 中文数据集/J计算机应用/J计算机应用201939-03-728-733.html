<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991981822500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903019%26RESULT%3d1%26SIGN%3dDl8NY%252bDXWPdaRgJgxZLBPfmvrJ0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903019&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903019&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903019&amp;v=MjkyNTVxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3ZCTHo3QmQ3RzRIOWpNckk5RWJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#51" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="1 基本概念 ">1 基本概念</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="1.1 TEAM&lt;b&gt;模型&lt;/b&gt;">1.1 TEAM<b>模型</b></a></li>
                                                <li><a href="#71" data-title="1.2 CHNN&lt;b&gt;基本结构&lt;/b&gt;">1.2 CHNN<b>基本结构</b></a></li>
                                                <li><a href="#81" data-title="1.3 &lt;b&gt;关联规则挖掘基本概念&lt;/b&gt;">1.3 <b>关联规则挖掘基本概念</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="2 基于HNN的最大频繁项集挖掘算法 ">2 基于HNN的最大频繁项集挖掘算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="2.1 &lt;b&gt;网络结构设计&lt;/b&gt;">2.1 <b>网络结构设计</b></a></li>
                                                <li><a href="#93" data-title="2.2 &lt;b&gt;确定最大频繁项集&lt;/b&gt;">2.2 <b>确定最大频繁项集</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="3 基于MHNN的最大频繁项集挖掘算法 ">3 基于MHNN的最大频繁项集挖掘算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#137" data-title="3.1 &lt;b&gt;电路结构设计&lt;/b&gt;">3.1 <b>电路结构设计</b></a></li>
                                                <li><a href="#147" data-title="3.2 &lt;b&gt;突触权值和偏置的映射&lt;/b&gt;">3.2 <b>突触权值和偏置的映射</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#155" data-title="4 最大频繁项集生成关联规则算法 ">4 最大频繁项集生成关联规则算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#222" data-title="5 仿真实验结果分析 ">5 仿真实验结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#223" data-title="5.1 &lt;b&gt;设计生成随机分布事务集算法&lt;/b&gt;">5.1 <b>设计生成随机分布事务集算法</b></a></li>
                                                <li><a href="#240" data-title="5.2 1 000&lt;b&gt;次仿真实验的关联规则挖掘结果分析&lt;/b&gt;">5.2 1 000<b>次仿真实验的关联规则挖掘结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#244" data-title="6 结语 ">6 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="&lt;b&gt;表&lt;/b&gt;1 TEAM&lt;b&gt;模型参数&lt;/b&gt;"><b>表</b>1 TEAM<b>模型参数</b></a></li>
                                                <li><a href="#68" data-title="图1 TEAM模型仿真结果">图1 TEAM模型仿真结果</a></li>
                                                <li><a href="#91" data-title="图2 具有2行3列神经元的HNN抽象结构">图2 具有2行3列神经元的HNN抽象结构</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表&lt;/b&gt;2 HNN&lt;b&gt;参数&lt;/b&gt;"><b>表</b>2 HNN<b>参数</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;测试事务集&lt;/b&gt;"><b>表</b>3 <b>测试事务集</b></a></li>
                                                <li><a href="#139" data-title="图3 MHNN的单个神经元电路原理图">图3 MHNN的单个神经元电路原理图</a></li>
                                                <li><a href="#144" data-title="图4 忆阻值与权值的变化关系">图4 忆阻值与权值的变化关系</a></li>
                                                <li><a href="#146" data-title="图5 MHNN电路结构">图5 MHNN电路结构</a></li>
                                                <li><a href="#243" data-title="图6 HNN和MHNN的挖掘结果准确率对比">图6 HNN和MHNN的挖掘结果准确率对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="280">


                                    <a id="bibliography_1" title="CHUA L O.Memristor-the missing circuit element[J].IEEETransactions on Circuit Theory, 1971, 18 (5) :507-519." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Memristor-the missing circuit element">
                                        <b>[1]</b>
                                        CHUA L O.Memristor-the missing circuit element[J].IEEETransactions on Circuit Theory, 1971, 18 (5) :507-519.
                                    </a>
                                </li>
                                <li id="282">


                                    <a id="bibliography_2" title="STRUKOV D B, SNIDER G S, STEWART D R, et al.The missing memristor found[J].Nature, 2008, 453 (7191) :80-83." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The missing memristor found">
                                        <b>[2]</b>
                                        STRUKOV D B, SNIDER G S, STEWART D R, et al.The missing memristor found[J].Nature, 2008, 453 (7191) :80-83.
                                    </a>
                                </li>
                                <li id="284">


                                    <a id="bibliography_3" title="DU C, CAI F, ZIDAN M A, et al.Reservoir computing using dynamic memristors for temporal information processing[J].Nature Communications, 2017, 8:Article No.2204." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reservoir computing using dynamic memristors for temporal information processing">
                                        <b>[3]</b>
                                        DU C, CAI F, ZIDAN M A, et al.Reservoir computing using dynamic memristors for temporal information processing[J].Nature Communications, 2017, 8:Article No.2204.
                                    </a>
                                </li>
                                <li id="286">


                                    <a id="bibliography_4" title="JO S H, CHANG T, EBONG I, et al.Nanoscale memristor device as synapse in neuromorphic systems[J].Nano Letters, 2010, 10 (4) :1297-1301." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nanoscale memristor device as synapse in neuromorphic systems">
                                        <b>[4]</b>
                                        JO S H, CHANG T, EBONG I, et al.Nanoscale memristor device as synapse in neuromorphic systems[J].Nano Letters, 2010, 10 (4) :1297-1301.
                                    </a>
                                </li>
                                <li id="288">


                                    <a id="bibliography_5" title="KVATINSKY S, FRIEDMAN E G, KOLODNY A, et al.TEAM:ThrEshold Adaptive Memristor model[J].IEEE Transactions on Circuits and Systems I:Regular Papers, 2013, 60 (1) :211-221." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=TEAM: ThrEshold Adaptive Memristor Model">
                                        <b>[5]</b>
                                        KVATINSKY S, FRIEDMAN E G, KOLODNY A, et al.TEAM:ThrEshold Adaptive Memristor model[J].IEEE Transactions on Circuits and Systems I:Regular Papers, 2013, 60 (1) :211-221.
                                    </a>
                                </li>
                                <li id="290">


                                    <a id="bibliography_6" title="江之源.基于阈值自适应忆阻模型的分析及应用研究[D].重庆:西南大学, 2016:11-12. (JIANG Z Y.Analysis and application research based on threshold adaptive memristor model[D].Chongqing:Southwestern University, 2016:11-12.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016767688.nh&amp;v=MTUzODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3ZCVkYyNkdMUytHZGZFcDVFYlBJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        江之源.基于阈值自适应忆阻模型的分析及应用研究[D].重庆:西南大学, 2016:11-12. (JIANG Z Y.Analysis and application research based on threshold adaptive memristor model[D].Chongqing:Southwestern University, 2016:11-12.) 
                                    </a>
                                </li>
                                <li id="292">


                                    <a id="bibliography_7" title="代祥光.忆阻神经网络的应用[D].重庆:重庆大学, 2012:1-3. (DAI X G.Application of memristive neural network[D].Chongqing:Chongqing University, 2012:1-3.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012048147.nh&amp;v=MjAyODZPOEZ0RElxSkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkJWRjI2SEw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        代祥光.忆阻神经网络的应用[D].重庆:重庆大学, 2012:1-3. (DAI X G.Application of memristive neural network[D].Chongqing:Chongqing University, 2012:1-3.) 
                                    </a>
                                </li>
                                <li id="294">


                                    <a id="bibliography_8" title="ALIBART F, ZAMANIDOOST E, STRUKOV D B.Pattern classification by memristive crossbar circuits using ex situ and in situ training[J].Nature Communications, 2013, 4 (3) :131-140." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pattern classification by memristive crossbar circuits using ex situ and in situ training">
                                        <b>[8]</b>
                                        ALIBART F, ZAMANIDOOST E, STRUKOV D B.Pattern classification by memristive crossbar circuits using ex situ and in situ training[J].Nature Communications, 2013, 4 (3) :131-140.
                                    </a>
                                </li>
                                <li id="296">


                                    <a id="bibliography_9" title="PARK S, SHERI A, KIM J, et al.Neuromorphic speech systems using advanced ReRAM-based synapse[C]//Proceedings of 2013IEEE International Electron Devices Meeting.Piscataway, NJ:IEEE, 2013:25.6.1-25.6.4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neuromorphic speech systems using advanced ReRAM-based synapse">
                                        <b>[9]</b>
                                        PARK S, SHERI A, KIM J, et al.Neuromorphic speech systems using advanced ReRAM-based synapse[C]//Proceedings of 2013IEEE International Electron Devices Meeting.Piscataway, NJ:IEEE, 2013:25.6.1-25.6.4.
                                    </a>
                                </li>
                                <li id="298">


                                    <a id="bibliography_10" title="ZIEGLER M, SONI R, PATELCZYK T, et al.An electronic version of Pavlov&#39;s dog[J].Advanced Functional Materials, 2012, 22 (13) :2744-2749." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An electronic version of Pavlov&amp;#39;s Dog">
                                        <b>[10]</b>
                                        ZIEGLER M, SONI R, PATELCZYK T, et al.An electronic version of Pavlov&#39;s dog[J].Advanced Functional Materials, 2012, 22 (13) :2744-2749.
                                    </a>
                                </li>
                                <li id="300">


                                    <a id="bibliography_11" title="HU S G, LIU Y, LIU Z, et al.Associative memory realized by a reconfigurable memristive Hopfield neural network[J].Nature Communications, 2015, 6:Article number 7522." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Associative memory realized by a reconfigurable memristive Hopfield neural network">
                                        <b>[11]</b>
                                        HU S G, LIU Y, LIU Z, et al.Associative memory realized by a reconfigurable memristive Hopfield neural network[J].Nature Communications, 2015, 6:Article number 7522.
                                    </a>
                                </li>
                                <li id="302">


                                    <a id="bibliography_12" title="HOPFIELD J J.Neural networks and physical systems with emergent collective computational abilities[J].Proceedings of the National Academy of Sciences of the United States of America, 1982, 79 (8) :2554-2558." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural Networks and Physical Systems Emergent Collective Computational Abilities">
                                        <b>[12]</b>
                                        HOPFIELD J J.Neural networks and physical systems with emergent collective computational abilities[J].Proceedings of the National Academy of Sciences of the United States of America, 1982, 79 (8) :2554-2558.
                                    </a>
                                </li>
                                <li id="304">


                                    <a id="bibliography_13" title="HOPFIELD J J, TANK D W.Neuralcomputation of decisions in optimization problems[J].Biological Cybernetics, 1985, 52 (3) :141-145." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003237169&amp;v=MzExMDhhck80SHRIUHJZeENaZTBHWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaS9rVzcvQUpGYz1OajdC&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        HOPFIELD J J, TANK D W.Neuralcomputation of decisions in optimization problems[J].Biological Cybernetics, 1985, 52 (3) :141-145.
                                    </a>
                                </li>
                                <li id="306">


                                    <a id="bibliography_14" title="AGRAWAL R, IMIELINSKI T, SWAMI A N.Mining association rules between sets of items in large databases[C]//Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data.New York:ACM, 1993:207-216." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining Association Rules between Sets of Items in Large Databases">
                                        <b>[14]</b>
                                        AGRAWAL R, IMIELINSKI T, SWAMI A N.Mining association rules between sets of items in large databases[C]//Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data.New York:ACM, 1993:207-216.
                                    </a>
                                </li>
                                <li id="308">


                                    <a id="bibliography_15" title="AGRAWAL R, SRIKANT R.Fast algorithms for mining association rules in large databases[C]//VLDB&#39;94:Proceedings of the20th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1994:487-499." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast algorithms for mining association rules">
                                        <b>[15]</b>
                                        AGRAWAL R, SRIKANT R.Fast algorithms for mining association rules in large databases[C]//VLDB&#39;94:Proceedings of the20th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1994:487-499.
                                    </a>
                                </li>
                                <li id="310">


                                    <a id="bibliography_16" title="王爱平, 王占凤, 陶嗣干, 等.数据挖掘中常用关联规则挖掘算法[J].计算机技术与发展, 2010, 20 (4) :105-108. (WANG AP, WANG Z F, TAO S G, et al.Common algorithms of association rules mining in data mining[J].Computer Technology and Development, 2010, 20 (4) :105-108.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201004028&amp;v=Mjg0MzZXN3ZCTWlmTmRMRzRIOUhNcTQ5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        王爱平, 王占凤, 陶嗣干, 等.数据挖掘中常用关联规则挖掘算法[J].计算机技术与发展, 2010, 20 (4) :105-108. (WANG AP, WANG Z F, TAO S G, et al.Common algorithms of association rules mining in data mining[J].Computer Technology and Development, 2010, 20 (4) :105-108.) 
                                    </a>
                                </li>
                                <li id="312">


                                    <a id="bibliography_17" title="PARK J S, CHEN M S, YU P S.An effective hash-based algorithm for mining association rules[J].ACM SIGMOD Record, 1995, 24 (2) :175-186." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000068566&amp;v=MDQ2NDlCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSktGNGNiaHM9TmlmSVk3SzdIdGpOcjQ5RlpPMEhDWG8vbw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        PARK J S, CHEN M S, YU P S.An effective hash-based algorithm for mining association rules[J].ACM SIGMOD Record, 1995, 24 (2) :175-186.
                                    </a>
                                </li>
                                <li id="314">


                                    <a id="bibliography_18" title="JI C R, DENG Z H.Mining frequent ordered patterns without candidate generation[C]//Proceedings of the 4th IEEE International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway, NJ:IEEE, 2007, 1:402-406." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining frequent ordered patterns without candidate generation">
                                        <b>[18]</b>
                                        JI C R, DENG Z H.Mining frequent ordered patterns without candidate generation[C]//Proceedings of the 4th IEEE International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway, NJ:IEEE, 2007, 1:402-406.
                                    </a>
                                </li>
                                <li id="316">


                                    <a id="bibliography_19" title="SAVASERE A, OMIECINSKI E, NAVATHE S B, et al.An efficient algorithm for mining association rules in large databases[C]//VLDB&#39;95:Proceedings of the 21st International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1995:432-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for mining association rules">
                                        <b>[19]</b>
                                        SAVASERE A, OMIECINSKI E, NAVATHE S B, et al.An efficient algorithm for mining association rules in large databases[C]//VLDB&#39;95:Proceedings of the 21st International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1995:432-444.
                                    </a>
                                </li>
                                <li id="318">


                                    <a id="bibliography_20" title="TOIVONEN H.Sampling large databases for association rules[C]//VLDB&#39;96:Proceedings of the 22th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1996:134-145." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sampling large databases for association rules">
                                        <b>[20]</b>
                                        TOIVONEN H.Sampling large databases for association rules[C]//VLDB&#39;96:Proceedings of the 22th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1996:134-145.
                                    </a>
                                </li>
                                <li id="320">


                                    <a id="bibliography_21" title="AGRAWAL R, SHAFER J C.Parallel mining of association rules[J].IEEE Transactions on Knowledge and Data Engineering, 2007, 8 (6) :962-969." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallel mining of association rules">
                                        <b>[21]</b>
                                        AGRAWAL R, SHAFER J C.Parallel mining of association rules[J].IEEE Transactions on Knowledge and Data Engineering, 2007, 8 (6) :962-969.
                                    </a>
                                </li>
                                <li id="322">


                                    <a id="bibliography_22" title="GABER K, BAHI J M, EL-GHAZAWI T A.Parallel mining of association rules with a Hopfield type neural network[C]//ICTAI&#39;00:Proceedings of the 12th IEEE International Conference on Tools with Artificial Intelligence.Washington, DC:IEEE Computer Society, 2000:90-93." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallel mining of association rules with a Hopfield type neural network">
                                        <b>[22]</b>
                                        GABER K, BAHI J M, EL-GHAZAWI T A.Parallel mining of association rules with a Hopfield type neural network[C]//ICTAI&#39;00:Proceedings of the 12th IEEE International Conference on Tools with Artificial Intelligence.Washington, DC:IEEE Computer Society, 2000:90-93.
                                    </a>
                                </li>
                                <li id="324">


                                    <a id="bibliography_23" title="ABDALLA H, PICKETT M D.SPICE modeling of memristors[C]//Proceedings of the 2011 IEEE International Symposium on Circuits and Systems.Piscataway, NJ:IEEE, 2011:1832-1835." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SPICE modeling of memristors">
                                        <b>[23]</b>
                                        ABDALLA H, PICKETT M D.SPICE modeling of memristors[C]//Proceedings of the 2011 IEEE International Symposium on Circuits and Systems.Piscataway, NJ:IEEE, 2011:1832-1835.
                                    </a>
                                </li>
                                <li id="326">


                                    <a id="bibliography_24" title="徐开勇, 龚雪容, 成茂才.基于改进Apriori算法的审计日志关联规则挖掘[J].计算机应用, 2016, 36 (7) :1847-1851. (XU KY, GONG X R, CHENG M C.Audit log association rule mining based on improved apriori algorithm[J].Journal of Computer Applications, 2016, 36 (7) :1847-1851.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607018&amp;v=MTUwNTBacEZpRGxXN3ZCTHo3QmQ3RzRIOWZNcUk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        徐开勇, 龚雪容, 成茂才.基于改进Apriori算法的审计日志关联规则挖掘[J].计算机应用, 2016, 36 (7) :1847-1851. (XU KY, GONG X R, CHENG M C.Audit log association rule mining based on improved apriori algorithm[J].Journal of Computer Applications, 2016, 36 (7) :1847-1851.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-09-29 09:53</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),728-733 DOI:10.11772/j.issn.1001-9081.2018071497            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于阈值自适应忆阻器Hopfield神经网络的关联规则挖掘算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E6%B0%B8%E6%96%8C&amp;code=06548806&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于永斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%88%9A%E6%95%8F%E6%83%A0&amp;code=41275792&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">戚敏惠</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%BC%E7%8E%9B%E6%89%8E%E8%A5%BF&amp;code=09194628&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尼玛扎西</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%90%B3&amp;code=06570217&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王琳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0178313&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子科技大学信息与软件工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E8%97%8F%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0030019&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西藏大学信息科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对基于Hopfield神经网络的最大频繁项集挖掘 (HNNMFI) 算法存在的挖掘结果不准确的问题, 提出基于电流阈值自适应忆阻器 (TEAM) 模型的Hopfield神经网络的改进关联规则挖掘算法。首先, 使用TEAM模型设计实现突触, 利用阈值忆阻器的忆阻值随方波电压连续变化的能力来设定和更新突触权值, 自适应关联规则挖掘算法的输入。其次, 改进原算法的能量函数以对齐标准能量函数, 并用忆阻值表示权值, 放大权值和偏置。最后, 设计由最大频繁项集生成关联规则的算法。使用10组大小在30以内的随机事务集进行1 000次仿真实验, 实验结果表明, 与HNNMFI算法相比, 所提算法在关联挖掘结果准确率上提高33.9个百分点以上, 说明忆阻器能够有效提高Hopfield神经网络在关联规则挖掘中的结果准确率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%B5%E6%B5%81%E9%98%88%E5%80%BC%E8%87%AA%E9%80%82%E5%BA%94%E5%BF%86%E9%98%BB%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电流阈值自适应忆阻器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hopfield%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hopfield神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E5%A4%A7%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最大频繁项集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关联规则挖掘;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量函数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    于永斌 (1975—) , 男, 四川遂宁人, 副教授, 博士, 主要研究方向:忆阻神经网络;;
                                </span>
                                <span>
                                    *戚敏惠 (1996—) , 女, 四川眉山人, 硕士研究生, 主要研究方向:忆阻神经网络;电子邮箱qmh19961007@qq.com;
                                </span>
                                <span>
                                    尼玛扎西 (1964—) , 男, 西藏察隅人, 教授, 博士, 主要研究方向:计算机网络与信息系统、自然语言处理;;
                                </span>
                                <span>
                                    王琳 (1967—) , 女, 四川成都人, 副教授, 硕士, 主要研究方向:忆阻神经网络。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-19</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61550110248);</span>
                    </p>
            </div>
                    <h1><b>Association rule mining algorithm for Hopfield neural network based on threshold adaptive memristor</b></h1>
                    <h2>
                    <span>YU Yongbin</span>
                    <span>QI Minhui</span>
                    <span>Nyima Tashi</span>
                    <span>WANG Lin</span>
            </h2>
                    <h2>
                    <span>School of Information and Software Engineering, University of Electronic Science and Technology of China</span>
                    <span>College of Information Science and Technology, Tibet University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the inaccurate mining results of the Maximum Frequent Itemset mining algorithm based on Hopfield Neural Network (HNNMFI) , an improved association rule mining algorithm for Hopfield neural network based on current ThrEshold Adaptive Memristor (TEAM) model was proposed. Firstly, TEAM model was used to design and implement synapses whose weights were set and updated by the ability of that threshold memristor continuously changes memristance value with square-wave voltage, and the input of association rule mining algorithm was self-adapted by the neural network. Secondly, the energy function was improved to align with standard energy function, and the memristance values were used to represent the weights, then the weights and bias were amplified. Finally, an algorithm of generating association rules from the maximum frequent itemsets was designed. A total of 1 000 simulation experiments using 10 random transaction sets with size less than 30 were performed. Experimental results show that compared with HNNMFI algorithm, the proposed algorithm improves the result accuracy of association mining by more than 33.9 %, which indicates that the memristor can effectively improve the result accuracy of Hopfield neural network in association rule mining.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=current%20ThrEshold%20Adaptive%20Memristor%20(TEAM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">current ThrEshold Adaptive Memristor (TEAM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hopfield%20Neural%20Network%20(HNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hopfield Neural Network (HNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=maximum%20frequent%20itemset&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">maximum frequent itemset;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=association%20rule%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">association rule mining;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=energy%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">energy function;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YU Yongbin, born in 1975, Ph. D. , associate professor. His research interests include memristive neural network.;
                                </span>
                                <span>
                                    QI Minhui, born in 1996, M. S. candidate. Her research interests include memristive neural network.;
                                </span>
                                <span>
                                    Nyima Tashi, born in 1964, Ph. D. , professor. His research interests include computer network and information system, natural language processing.;
                                </span>
                                <span>
                                    WANG Lin, born in 1967, M. S. , associate professor. Her research interests include memristive neural network.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-19</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61550110248);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="51" name="51" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="52">忆阻器的概念由蔡绍棠教授在1971年提出<citation id="328" type="reference"><link href="280" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 2008年惠普实验室的研究人员Strukov等<citation id="329" type="reference"><link href="282" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>首次做出实物模型, 此后掀起忆阻器的研究热潮。忆阻器具有非线性和记忆特性<citation id="330" type="reference"><link href="284" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 用来模拟人工神经网络中的突触<citation id="331" type="reference"><link href="286" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 能够实现突触权值的连续更新并且在断电之后也能保存权值。近年来, 许多忆阻器的数学模型相继被提出, 其中Kvatinsky等提出电流阈值自适应忆阻器 (ThrEshold Adaptive Memristor, TEAM) 模型<citation id="332" type="reference"><link href="288" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 该模型可通过调整系数以匹配其他忆阻器的数学模型, 是一种非常精确且很有潜力的数学模型<citation id="333" type="reference"><link href="290" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。目前忆阻器的国内外研究方向主要包括神经网络、存储器、混沌电路、交叉阵列等<citation id="334" type="reference"><link href="292" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。忆阻器在神经网络中的研究取得很多进展<citation id="336" type="reference"><link href="294" rel="bibliography" /><link href="296" rel="bibliography" /><link href="298" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 如电子科技大学的Hu等使用可重构忆阻离散Hopfield神经网络实现单联想和多联想记忆<citation id="335" type="reference"><link href="300" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="53">Hopfield神经网络 (Hopfield Neural Network, HNN) 由Hopfield等在1982年提出, 该模型又分为离散型 (Discrete Hopfield Neural Network, DHNN) <citation id="337" type="reference"><link href="302" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和连续型 (Continuous Hopfield Neural Network, CHNN) <citation id="338" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。能量函数的概念被首次引入到人工神经网络中, 为解决优化计算问题提供新的方法。能量函数的标准形式已由Hopfield给出, 不同的优化问题对应的能量函数形式不同, 但都由约束条件和目标解两个部分组成, 只要能将其转化为标准形式便可从能量函数中导出权重和偏置。CHNN随时间演变, 始终向能量函数降低的方向移动, 最后达到能量函数的极小值点, 即稳定平衡状态。将优化问题的目标函数与网络的能量函数相对应, 则问题的求解过程可以看作CHNN向能量函数极小值点移动的过程。目前HNN的应用领域主要包括联想记忆和优化计算等<citation id="339" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="54">关联规则的概念最初是Agrawal等<citation id="340" type="reference"><link href="306" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>在1993年针对购物篮分析问题 (Market Basket Analysis) 提出的, 且于1994年提出经典的关联规则挖掘算法Apriori算法<citation id="341" type="reference"><link href="308" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。目前常见的关联规则挖掘算法<citation id="342" type="reference"><link href="310" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>大致可分为:宽度优先算法如DHP (Direct Hashing and Pruning) 算法<citation id="343" type="reference"><link href="312" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>;深度优先算法如FP-growth (Frequent-Pattern growth) 算法<citation id="344" type="reference"><link href="314" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>;数据集划分算法如Partition算法<citation id="345" type="reference"><link href="316" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>;采样算法如Sampling算法<citation id="346" type="reference"><link href="318" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>;并行挖掘算法如CD (Count Distribution) 、DD (Data Distribution) 、CaD算法 (Candidate Distribution) <citation id="347" type="reference"><link href="320" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>等。其中FP-growth算法对Apriori算法的改进效果最显著。</p>
                </div>
                <div class="p1">
                    <p id="55">Gaber等<citation id="348" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出基于Hopfield神经网络的最大频繁项集挖掘 (Maximum Frequent Itemset mining based on Hopfield Neural Network, HNNMFI) 算法, 该算法属于并行挖掘算法, 为CHNN在关联规则挖掘领域中的应用提供可行的思路。但该算法定义的能量函数与标准形式不太符合, 权值和偏置较小, 导致挖掘到的频繁项集范围小, 无法适应不同大小的事务集。</p>
                </div>
                <div class="p1">
                    <p id="56">本文针对上述问题, 提出基于忆阻Hopfield神经网络 (Memristive Hopfield Neural Network, MHNN) 的关联规则算法, 主要贡献概括如下:</p>
                </div>
                <div class="p1">
                    <p id="57">1) 提出改进的MHNN。</p>
                </div>
                <div class="p1">
                    <p id="58">MHNN使用忆阻器和电阻组成的分压电阻作为突触, 通过开关阵列实现正负突触权值的选择。该网络不仅结构简单, 而且能够自适应关联规则挖掘算法的事务矩阵。</p>
                </div>
                <div class="p1">
                    <p id="59">2) 提出新的基于MHNN的关联规则挖掘算法。</p>
                </div>
                <div class="p1">
                    <p id="60">新算法对HNNMFI算法的能量函数、权值以及偏置进行了修改, 并设计由最大频繁项集生成关联规则的算法, 在软件仿真上能够有效提高关联规则挖掘结果准确度。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag">1 基本概念</h3>
                <h4 class="anchor-tag" id="62" name="62">1.1 TEAM<b>模型</b></h4>
                <div class="p1">
                    <p id="63">TEAM模型对Abdalla等<citation id="349" type="reference"><link href="324" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>提出的Simmons隧道结模型进行简化, 不仅保留Simmons模型准确捕捉阈值的特点和简化Simmons模型的数学表达式, 还可通过调整系数以匹配其他忆阻器的数学模型, 是一种非常精确且具有潜力的数学模型。该模型的状态变量微分方程、窗函数表达式和忆阻值表达式<citation id="350" type="reference"><link href="288" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>分别如下:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mtext>d</mtext><mi>x</mi></mrow><mrow><mtext>d</mtext><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>k</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo stretchy="false"> (</mo><mfrac><mrow><mi>i</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub></mrow></mfrac><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>α</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub></mrow></msup><mi>f</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mn>0</mn><mo>&lt;</mo><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo>&lt;</mo><mi>i</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo>&lt;</mo><mi>i</mi><mo>&lt;</mo><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub></mtd></mtr><mtr><mtd><mi>k</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mfrac><mrow><mi>i</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub></mrow></mfrac><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>α</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub></mrow></msup><mi>f</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>i</mi><mo>&lt;</mo><mi>i</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>f</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">[</mo><mo>-</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mi>x</mi><mo>-</mo><mi>a</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>f</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">[</mo><mo>-</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mrow><mi>x</mi><mo>-</mo><mi>a</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mi>R</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo>+</mo><mfrac><mrow><mi>R</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo>-</mo><mi>R</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub></mrow><mrow><mi>x</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>f</mtext><mtext>f</mtext></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub></mrow></mfrac><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>k</i><sub>off</sub>、<i>k</i><sub>on</sub>表示幅度参数, <i>k</i><sub>off</sub>为正, <i>k</i><sub>on</sub>为负。<i>α</i><sub>on</sub>和<i>α</i><sub>off</sub>为匹配参数, 均为常数。<i>i</i><sub>on</sub>和<i>i</i><sub>off</sub>分别表示开关时的电流阈值, <i>a</i><sub>on</sub>和 <i>a</i><sub>off</sub>为内部状态阈值, <i>R</i><sub>off</sub>和 <i>R</i><sub>on</sub>表示TEAM模型的最大和最小忆阻值。</p>
                </div>
                <div class="p1">
                    <p id="66">本文只考虑TEAM模型的忆阻值为线性关系, 如式 (4) 所示。在外部电流正弦信号5sin (2π<i>t</i>) mA的激励下, 对TEAM模型按照表1的参数设定进行代码仿真, 得到图1的仿真结果。</p>
                </div>
                <div class="area_img" id="67">
                    <p class="img_tit"><b>表</b>1 TEAM<b>模型参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Parameters of TEAM model</p>
                    <p class="img_note"></p>
                    <table id="67" border="1"><tr><td>参数</td><td>值</td><td></td><td>参数</td><td>值</td><td></td><td>参数</td><td>值</td></tr><tr><td><i>R</i><sub>off </sub>/kΩ</td><td>1</td><td></td><td><i>a</i><sub>on</sub></td><td>1.8</td><td></td><td><i>x</i><sub>off</sub></td><td>2.4</td></tr><tr><td><br /><i>R</i><sub>on </sub>/Ω</td><td>50</td><td></td><td><i>i</i><sub>off </sub>/μA</td><td>115</td><td></td><td><i>x</i><sub>on</sub></td><td>0</td></tr><tr><td><br /><i>k</i><sub>off </sub>/ (nm·s<sup>-1</sup>) </td><td>1.46E-09</td><td></td><td><i>i</i><sub>on </sub>/μA</td><td>-8.9</td><td></td><td><i>w</i><sub><i>c</i></sub></td><td>0.1</td></tr><tr><td><br /><i>k</i><sub>on </sub>/ (nm·s<sup>-1</sup>) </td><td>-4.68E-13</td><td></td><td><i>α</i><sub>off</sub></td><td>10</td><td></td><td></td><td></td></tr><tr><td><br /><i>a</i><sub>off</sub></td><td>1.2</td><td></td><td><i>α</i><sub>on</sub></td><td>10</td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 TEAM模型仿真结果" src="Detail/GetImg?filename=images/JSJY201903019_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 TEAM模型仿真结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Simulation results of TEAM model</p>

                </div>
                <div class="p1">
                    <p id="69">图1 (a) 是外部正弦电流信号的波形图, 从图1 (c) 中可以看出, 正向电流得到更大电压, 验证了TEAM模型的开关变化的非对称性。向该模型中加入图1 (d) 所示窗函数后, 得到了图1 (b) 所示忆阻值随时间变化的曲线, 从图1 (b) 中可以看出, 在电流未达到阈值电流<i>i</i><sub>off </sub>时, 忆阻值保持不变, 达到之后忆阻值开始变化。</p>
                </div>
                <div class="p1">
                    <p id="70">重新调整TEAM模型的参数, 为TEAM模型输入幅值为2 V, 周期为1 s的方波电压, 保证此时通过忆阻器的电流大于阈值电流<i>i</i><sub>off</sub>, 能够使忆阻值发生改变。从仿真结果中可以得出忆阻值随方波电压连续变化, 且成上升趋势, 说明方波电压对TEAM模型忆阻器起到阻值编程作用, 使TEAM模型忆阻器非常适合作电子突触。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">1.2 CHNN<b>基本结构</b></h4>
                <div class="p1">
                    <p id="72">DHNN和CHNN的区别在于神经元输出不同, 前者是二值的网络, 神经元的取值为{0, 1}或{-1, 1}, 后者的神经元输出在某个区间内连续取值。本文只针对CHNN进行分析, 网络中神经元的输入和输出之间呈现sigmoid函数关系<citation id="351" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 该函数的一种常见表达形式<citation id="352" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>如下:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi>λ</mi><mi>u</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中:<i>V</i>、<i>u</i>表示神经元的输入和输出, <i>λ</i>是常系数。网络的动态方程和能量函数分别定义如 (6) 、 (7) <citation id="353" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mtext>d</mtext><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mtext>d</mtext><mi>t</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mfrac><mrow><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>τ</mi></mfrac><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>Τ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>Τ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>V</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">其中:<i>u</i><sub><i>i</i></sub>、<i>I</i><sub><i>i</i></sub>分别表示神经元<i>i</i>的输入和偏置;<i>V</i><sub><i>j</i></sub>表示神经元<i>j</i>的输出;<i>N</i>是神经元个数;<i>τ</i>是常数;<i>T</i><sub><i>ij</i></sub>表示神经元<i>i</i>与神经元<i>j</i>的连接权重;<i>E</i> (<i>v</i>) 是能量函数。Hopfield网络解决组合优化问题的步骤为:</p>
                </div>
                <div class="p1">
                    <p id="77">1) 对于待求解的问题, 提供一种合理的解释方案能够使网络的输出表示被求解问题的解。</p>
                </div>
                <div class="p1">
                    <p id="78">2) 构造能量函数, 使能量函数对应被求解问题的目标函数, 能量函数向极小值点移动的过程就是问题的求解过程。</p>
                </div>
                <div class="p1">
                    <p id="79">3) 从能量函数中导出权重<i>T</i><sub><i>ij</i></sub>和偏置电流<i>I</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="80">4) 运行Hopfield神经网络, 当网络达到稳定状态时的输出就是一定条件下问题的最优解。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">1.3 <b>关联规则挖掘基本概念</b></h4>
                <div class="p1">
                    <p id="82"><b>定义</b>1 关联规则。设<i>I</i>={<i>i</i><sub>1</sub>, <i>i</i><sub>2</sub>, …, <i>i</i><sub><i>n</i></sub>}是<i>n</i>个项目的集合, 也称<i>n</i>项集。假设有一个事务集<i>D</i>, <i>D</i>中的每一行代表一个事务, 用<i>T</i>表示。<i>T</i>是<i>I</i>中一组项目的集合。关联规则是一个类似<i>X</i>⇒<i>Y</i>的蕴涵式, 其中<i>X</i>⊂<i>I</i>, <i>Y</i>⊂<i>I</i>且<i>X</i>∩<i>Y</i>=∅。<i>X</i>⇒<i>Y</i>满足支持度和置信度分别大于用户定义的最小支持度与置信度的要求, 称为强关联规则, 否则称弱关联规则。</p>
                </div>
                <div class="p1">
                    <p id="83"><b>定义</b>2 支持度。规则<i>X</i>⇒<i>Y</i>的支持度为<i>X</i>和<i>Y</i>在<i>D</i>的每个事务中一起出现的概率, 记为<i>support</i> (<i>X</i>⇒<i>Y</i>) =<i>P</i> (<i>XY</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="84"><b>定义</b>3 置信度。规则<i>X</i>⇒<i>Y</i>的置信度表示为<i>D</i>中包含项集<i>X</i>的事务中项集<i>Y</i>的百分比, 即项集<i>Y</i>出现的条件概率, 记作<i>confidence</i> (<i>X</i>⇒<i>Y</i>) =<i>P</i> (<i>Y</i>|<i>X</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="85"><b>定义</b>4 频繁项集。若项集<i>X</i>的支持度大等于用户定义的最小支持度, 则称<i>X</i>为频繁项集, 否则称<i>X</i>为非频繁项集。</p>
                </div>
                <div class="p1">
                    <p id="86"><b>定义</b>5 最大频繁项集。如果频繁项集<i>X</i>上的所有超集都不是频繁项集, 则称<i>X</i>为局部最大频繁项集, 所有局部最大频繁项集组成的集合称最大频繁项集。</p>
                </div>
                <div class="p1">
                    <p id="87">关联规则挖掘算法遵循两个步骤<citation id="354" type="reference"><link href="326" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>:第一步是找到所有的频繁项集;第二步是在上一步的基础上产生关联规则。考虑到最大频繁项集已经隐含所有频繁项集信息, 因此本文只需考虑挖掘最大频繁项集问题。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">2 基于HNN的最大频繁项集挖掘算法</h3>
                <h4 class="anchor-tag" id="89" name="89">2.1 <b>网络结构设计</b></h4>
                <div class="p1">
                    <p id="90">HNN的神经元分布同事务矩阵<b><i>D</i></b>一样, 共有<i>n</i>*<i>p</i>个神经元且呈二维数组形式排列。由于每个神经元接收到的突触数量都是一样的, 因此该网络可抽象为1行<i>n</i>*<i>p</i>列的单层网络结构。以一个具有2行3列神经元的HNN为例, 本文设计的HNN结构如图2所示。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 具有2行3列神经元的HNN抽象结构" src="Detail/GetImg?filename=images/JSJY201903019_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 具有2行3列神经元的HNN抽象结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 HNN abstract structure with 2 rows and 3 columns of neurons</p>

                </div>
                <div class="p1">
                    <p id="92">图2 (a) 中<i>T</i><sub><i>Ai</i>, <i>Bj</i></sub>, <i>A</i>, <i>B</i>∈{1, 2}, <i>i</i>, <i>j</i>∈{1, 2, 3}代表第<i>A</i>行第<i>i</i>列的神经元与第<i>B</i>行第<i>j</i>列的神经元之间的互联权值。<i>I</i><sub><i>Ai</i></sub>, <i>A</i>∈{1, 2}, <i>i</i>∈{1, 2, 3}是输入的偏置电流, <i>V</i><sub><i>ij</i></sub>, <i>i</i>∈{1, 2}, <i>j</i>∈{1, 2, 3}表示第<i>i</i>行第<i>j</i>列的神经元的输出, 黑色和白色分别代表第一、二行神经元。为了满足稳定性要求, 权值矩阵需要满足网络结构对称, 且自身无连接, 因此图2 (a) 中对角线上的突触权值为0, 即图中灰色部分, 其余权值沿对角线对称分布。图2 (b) 中的神经元接收包括自身在内的 6 个神经元传来的输入 {<i>U</i><sub>11</sub>, <i>U</i><sub>12</sub>, <i>U</i><sub>13</sub>, <i>U</i><sub>21</sub>, <i>U</i><sub>22</sub>, <i>U</i><sub>23</sub>}, 输入的加权和为<i>U</i><sub><i>Ai</i></sub>×<i>T</i><sub><i>Ai</i>, <i>Bj</i></sub>, , 神经元对输入加权和进行累加, 在加上偏置<i>I</i><sub>11</sub>, 最后通过激励函数得到输出。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">2.2 <b>确定最大频繁项集</b></h4>
                <div class="p1">
                    <p id="94">本文对Gaber等提出的HNNMFI算法的能量函数进行修改:首先为了同能量函数的标准式对齐, 将原能量函数的第二项 (偏置部分) 前面的符号由加变为减;其次, 将第三项中<i>k</i>的累加上限由<i>p</i>改为<i>n</i>。修改后的能量函数能够适用大小不同的事务集, 而原能量函数只能适用行数 (<i>n</i>) 和列数 (<i>p</i>) 相同的事务集, 修改后的能量函数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo>=</mo><mo>-</mo><mfrac><mi>A</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>Τ</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>p</mi></munderover><mi>V</mi></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>Τ</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>Τ</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mi>V</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mi>C</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>Τ</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>p</mi></munderover><mi>V</mi></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>Τ</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mtext>e</mtext><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中:<i>A</i>、<i>B</i>和<i>C</i>是正的常数, 代表各个约束项的重要程度, <i>n</i>和<i>p</i>分别代表事务数和项目数, <i>V</i><sub><i>Ti</i></sub>代表第<i>T</i>笔事务中第<i>i</i>个神经元的输出, <i>min</i>是用户定义的最小支持度, <i>b</i><sub><i>Ti</i></sub>表示项目<i>i</i>是否出现在第<i>T</i>笔事务中, 是为1, 否为0。公式中的前两项确保每行生成一个有效解, 该解具有该行表示事务包含的最大项集, 第三项确保输出的解是频繁项集, 即该解的支持度大于用户定义的最小支持度。</p>
                </div>
                <div class="p1">
                    <p id="97">根据图2 (a) 所示结构, 将下标<i>T</i>用<i>A</i>, <i>B</i>代替, 重写 (6) 、 (7) 和 (8) 得:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mtext>d</mtext><mi>u</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub></mrow><mrow><mtext>d</mtext><mi>t</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mfrac><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub></mrow><mi>τ</mi></mfrac><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>B</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>Τ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi><mo>, </mo><mi>B</mi><mi>j</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>A</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>B</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>Τ</mi></mstyle></mrow></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi><mo>, </mo><mi>B</mi><mi>j</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>j</mi></mrow></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>A</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Ι</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>E</mi><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>A</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>B</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>p</mi></munderover><mi>V</mi></mstyle></mrow></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mi>V</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mi>A</mi><mo>-</mo><mi>C</mi><mo>⋅</mo><mi>Μ</mi><mo>⋅</mo><mi>e</mi><msup><mrow></mrow><mi>Μ</mi></msup><mo stretchy="false">) </mo><mo>-</mo><mi>B</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>A</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mi>V</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mo>;</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mo>=</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">将式 (11) 和 (10) 进行比较, 可以得出权值和偏置如下:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi><mo>, </mo><mi>B</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>A</mi><mo>-</mo><mi>C</mi><mo>⋅</mo><mo stretchy="false"> (</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mtext>e</mtext><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo>=</mo><mi>B</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">网络参数的选取将会影响网络的效率以及结果准确性, 目前对于网络参数的选择尚无理论依据。在实验和经验的基础上, HNN的参数设定如表2所示。</p>
                </div>
                <div class="p1">
                    <p id="103">由于网络的迭代次数和步长与事务集所得的权值矩阵有关, 使用多个事务集对HNN进行测试后在实验的基础上, 总结出网络的权值矩阵同迭代次数<i>Count</i>和步长<i>step</i>的关系如下, 其中<i>x</i>是权值矩阵中绝对值最大数的指数。</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mn>0</mn><msup><mrow></mrow><mrow><mo>-</mo><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mtext> </mtext><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>1</mn><mn>5</mn><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>x</mi><mo>&gt;</mo><mn>4</mn></mtd></mtr><mtr><mtd><mn>1</mn><mn>0</mn><msup><mrow></mrow><mrow><mo>-</mo><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>5</mn><mn>0</mn><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>x</mi><mo>≤</mo><mn>4</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表</b>2 HNN<b>参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Parameters of HNN</p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td>参数</td><td>值</td><td></td><td>参数</td><td>值</td><td></td><td>参数</td><td>值</td></tr><tr><td><i>A</i></td><td>350</td><td></td><td><i>C</i></td><td>110</td><td></td><td><i>λ</i></td><td>3</td></tr><tr><td><br /><i>B</i></td><td>100</td><td></td><td><i>τ</i></td><td>1</td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="106">从能量函数中得到权重和偏置以及确定网络参数后, 按照第1章提出的HNN求解组合优化问题的步骤, 只需建立并运行HNN, 等网络达到稳定状态, 便可以求解出最大频繁项集, 具体描述如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="107">算法1 HNN挖掘最大频繁项集 (HNNMFI) 算法。</p>
                </div>
                <div class="p1">
                    <p id="108">输入:事务集</p>
                </div>
                <div class="p1">
                    <p id="109">输出:最大频繁项集数组<b><i>F</i></b>、能量函数矩阵<b><i>E</i></b>。</p>
                </div>
                <div class="area_img" id="275">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903019_27500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="132">使用表3所示的事务集对该算法进行测试, <i>minSup</i>和<i>minConf</i>均设置为0.5, 网络的迭代次数<i>Count</i>和步长<i>step</i>由式 (14) 计算后分别为500和10<sup>-5</sup>, 按照算法1流程运行网络, 得到编码规则数组<i>code</i>为{beer, bread, cook, diaper, egg, <image id="276" type="formula" href="images/JSJY201903019_27600.jpg" display="inline" placement="inline"><alt></alt></image>使用<i>code</i>翻译出来是{beer, bread, diaper, milk}, 而使用Apriori算法得到的最大频繁项集是{{beer, bread}, {beer, diaper}, {beer, milk}, {diaper, milk}}。可见HNNMFI算法得到的最大频繁项集是定义5中的所有局部最大频繁项集的并集。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表</b>3 <b>测试事务集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Test transaction set</p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />TID</td><td>Items</td><td></td><td>TID</td><td>Items</td></tr><tr><td>1</td><td>bread, milk, beer</td><td></td><td>4</td><td>milk, diaper</td></tr><tr><td><br />2</td><td>bread, diaper, beer, egg, milk</td><td></td><td>5</td><td>bread diaper cook beer</td></tr><tr><td><br />3</td><td>milk, diaper, beer, cook</td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="136" name="136" class="anchor-tag">3 基于MHNN的最大频繁项集挖掘算法</h3>
                <h4 class="anchor-tag" id="137" name="137">3.1 <b>电路结构设计</b></h4>
                <div class="p1">
                    <p id="138">本文参考Hu等<citation id="355" type="reference"><link href="300" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>设计的忆阻离散Hopfiled神经网络中单个神经元电路原理图, 设计同图2 (b) 对应的MHNN中单个神经元电路原理图, 如图3所示。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 MHNN的单个神经元电路原理图" src="Detail/GetImg?filename=images/JSJY201903019_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 MHNN的单个神经元电路原理图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Schematic diagram for single neuron circuit of MHNN</p>

                </div>
                <div class="p1">
                    <p id="140">图3中{<i>U</i><sub>11</sub>, <i>U</i><sub>12</sub>, …, <i>U</i><sub>23 </sub>}为输入的方波电压, 电阻<i>R</i>与忆阻器<i>M</i><sub><i>Ai</i>, <i>Bj</i></sub> (<i>A</i>, <i>B</i>∈{1, 2}, <i>i</i>, <i>j</i>∈{1, 2, 3}) 组成的分压电路作为突触权值<i>W</i><sub><i>r</i>, <i>c</i></sub> (<i>r</i>, <i>c</i>∈{1, 2, …, 6}) 。<i>B</i><sub>1</sub>, <i>B</i><sub>2</sub>, …, <i>B</i><sub>6</sub>是传输门, 能够在不修改信号极性的情况下传输信号, <i>L</i><sub>1</sub>, <i>L</i><sub>2</sub>, …, <i>L</i><sub>6</sub>是非门, 用来实现负的突触权值, 开关阵列 (Switch Array) 的作用选择正负突触权值。<i>U</i><sub>I11</sub>是偏置电压, 运算放大器用来计算输入的加权累加和, 模拟神经元的非线性特性。由图3中的忆阻器和电阻的分压电路可以得出忆阻值和突触的关系如下:</p>
                </div>
                <div class="p1">
                    <p id="141"><i>W</i><sub><i>r</i>, <i>c</i></sub>=±<i>M</i><sub><i>Ai</i>, <i>Bj</i></sub>/ (<i>M</i><sub><i>Ai</i>, <i>Bj</i></sub>+<i>R</i>)      (15) </p>
                </div>
                <div class="p1">
                    <p id="142">其中<i>r</i>, <i>c</i>∈{1, 2, …, <i>n</i>×<i>p</i>}, <i>A</i>, <i>B</i>∈{1, 2, …, <i>n</i>}, <i>i</i>, <i>j</i>∈{1, 2, …, <i>p</i>}, <i>R</i>=30 kΩ。重新调整表1中TEAM模型的参数, 令<i>R</i><sub>off</sub>和<i>R</i><sub>on</sub>分别为3×10<sup>6</sup> Ω和100 Ω以及<i>α</i><sub>on</sub>和<i>α</i><sub>off </sub>均为12。在外部电流正弦信号5 sin (2π<i>t</i>) mA的激励下, 对该模型进行代码仿真得到忆阻值和权值的变化关系如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="143">图4 (a) 表明了忆阻值的变化范围是100 Ω～3 MΩ, 图4 (b) 表明了随着忆阻值改变, 突触权值在 (0, 1) 范围内连续变化。由式 (15) 可知, 权重的变化范围在 (-1, 1) , 但实际的权值矩阵的范围更大, 在电路中需要通过运算放大器对权值进行放大, 才能得到正确的输出。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 忆阻值与权值的变化关系" src="Detail/GetImg?filename=images/JSJY201903019_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 忆阻值与权值的变化关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Relationship between memristance value and weight</p>

                </div>
                <div class="p1">
                    <p id="145">本文设计的MHNN电路结构如图5所示, 该网络是单层的反馈网络, 每个神经元接收到<i>N</i> (<i>n</i>*<i>p</i>) 个突触权重和一个外部的偏置电流<i>I</i>, 输出电压<i>V</i>又反馈到输入, 具体结构如左边大的最深色阴影部分所示, 该部分也是图3的扩展。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 MHNN电路结构" src="Detail/GetImg?filename=images/JSJY201903019_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 MHNN电路结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Circuit structure of MHNN</p>

                </div>
                <h4 class="anchor-tag" id="147" name="147">3.2 <b>突触权值和偏置的映射</b></h4>
                <div class="p1">
                    <p id="148">本文的MHNN主要是通过软件仿真实现的, 为了对应图5的单个神经元电路, 首先将HNN中的权值矩阵<b><i>W</i></b><sub><i>rc</i></sub>′按照式 (16) 进行归一化, 使归一化之后的权值矩阵范围在 (-1, 1) 。</p>
                </div>
                <div class="p1">
                    <p id="149" class="code-formula">
                        <mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>r</mi><mo>, </mo><mi>c</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>r</mi><mi>c</mi></mrow></msub><mo>´</mo></mrow><mrow><mi>max</mi><mo stretchy="false"> (</mo><mi>max</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>r</mi><mi>c</mi></mrow></msub><mo>´</mo></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn><mn>0</mn></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="150">在对权值矩阵进行归一化之后, 为了保证MHNN挖掘最大频繁项集算法的结果准确性, 还需要将归一化后的权值矩阵按照式 (17) 进行放大。</p>
                </div>
                <div class="p1">
                    <p id="151"><b><i>W</i></b><sub><i>r</i>, <i>c</i></sub>″=<b><i>W</i></b><sub><i>r</i>, <i>c</i></sub>×10<sup><i>x</i></sup>+10<sup><i>x</i>-2</sup>      (17) </p>
                </div>
                <div class="p1">
                    <p id="152">其中:<b><i>W</i></b><sub><i>r</i>, <i>c</i></sub>″是MHNN的突触权值, <i>x</i>是<b><i>W</i></b><sub><i>rc</i></sub>′中绝对值最大数的指数。除了放大权值之外, 偏置矩阵<b><i>I</i></b><sub><i>Ai</i></sub>也要适当地放大, 对<b><i>I</i></b><sub><i>Ai</i></sub>的放大公式如式 (18) 所示:</p>
                </div>
                <div class="p1">
                    <p id="153" class="code-formula">
                        <mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo>´</mo><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo>*</mo><mn>1</mn><mn>0</mn><msup><mrow></mrow><mrow><mi>x</mi><mo>-</mo><mn>2</mn></mrow></msup><mo>, </mo><mtext> </mtext><mi>x</mi><mo>&gt;</mo><mn>4</mn></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo>´</mo><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>i</mi></mrow></msub><mo>*</mo><mn>1</mn><mn>0</mn><msup><mrow></mrow><mrow><mi>x</mi><mo>-</mo><mn>3</mn></mrow></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>x</mi><mo>≤</mo><mn>4</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="154">其中<b><i>I</i></b><sub><i>Ai</i></sub>′为MHNN的偏置, <i>x</i>的含义同上。除权值和偏置之外, MHNN的其余参数均参照表2中的HNN参数进行设置。</p>
                </div>
                <h3 id="155" name="155" class="anchor-tag">4 最大频繁项集生成关联规则算法</h3>
                <div class="p1">
                    <p id="156">本文设计的由最大频繁项集生成关联规则的算法分为两步。第一步生成所有频繁项集的支持度数组, 主要通过最大频繁项集的组合运算, 产生所有的非空子集 (子频繁项集) , 求出每个子集的支持度, 存入支持度数组, 具体描述如算法2所示。</p>
                </div>
                <div class="p1">
                    <p id="157">算法2 生成所有频繁项集的支持度数组算法。</p>
                </div>
                <div class="p1">
                    <p id="158">输入:事务矩阵<b><i>D</i></b>, 最大频繁项集数组<i>F</i>, 最小支持度<i>minSup</i>。</p>
                </div>
                <div class="p1">
                    <p id="159">输出:支持度数组<i>S</i>。</p>
                </div>
                <div class="area_img" id="277">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903019_27700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="188">第二步从支持度数组中生成满足用户定义的最小支持度与最小置信度的关联规则。首先遍历支持度数组, 取频繁项集, 作为关联规则<i>X</i>⇒<i>Y</i>中的<i>X</i>, 再取支持度数组中与<i>X</i>不相交的频繁项集作为关联规则的<i>Y</i>, 计算<i>X</i>⇒<i>Y</i>的支持度和置信度, 满足要求则填入关联规则, 具体描述如算法3所示。</p>
                </div>
                <div class="p1">
                    <p id="189">算法3 由支持度数组生成关联规则算法。</p>
                </div>
                <div class="p1">
                    <p id="190">输入:支持度数组<i>S</i>, 编码规则数组<i>code</i>, 最小置信度<i>minConf</i>;</p>
                </div>
                <div class="p1">
                    <p id="191">输出:关联规则数组<i>R</i>。</p>
                </div>
                <div class="area_img" id="278">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903019_27800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="222" name="222" class="anchor-tag">5 仿真实验结果分析</h3>
                <h4 class="anchor-tag" id="223" name="223">5.1 <b>设计生成随机分布事务集算法</b></h4>
                <div class="p1">
                    <p id="224">由于HNN求解大规模的组合优化问题十分困难, 处理小范围的数据集比较容易, 所以本文提出的MHNN目前只适用于小规模的事务集, 加上关联规则挖掘的测试数据集都比较大, 不适用于本文的测试, 故本文设计生成随机分布事务集算法来对比两种网络的挖掘结果准确率。该算法具体描述如算法4所示, 可通过设置传入事务集的行数<i>n</i>, 列数<i>p</i>以及1出现的概率<i>p</i>1来控制随机生成事务集的大小和疏密程度。</p>
                </div>
                <div class="p1">
                    <p id="225">算法4 生成随机分布事务集算法。</p>
                </div>
                <div class="p1">
                    <p id="226">输入:事务矩阵的行数<i>n</i>、列数<i>p</i>, 1出现的概率<i>p</i>1;</p>
                </div>
                <div class="p1">
                    <p id="227">输出:事务矩阵<b><i>D</i></b>, 编码规则数组<i>code</i>。</p>
                </div>
                <div class="area_img" id="279">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903019_27900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="240" name="240">5.2 1 000<b>次仿真实验的关联规则挖掘结果分析</b></h4>
                <div class="p1">
                    <p id="241">本文设定算法4的输入<i>n</i>=<i>p</i>, <i>p</i>1=0.5, 最小支持度和最小置信度均设置为0.5。设置10种不同大小的事务集, 分别为4, 6, 8, 10, 12, 14, 16, 18, 20, 22。对每种事务集分别使用Apriori算法、HNN和MHNN进行100次实验, 以Apriori算法的结果为标准, 统计两种网络的挖掘结果准确率, 结果如图6所示。</p>
                </div>
                <div class="p1">
                    <p id="242">从图6中可以看出, 当事务集的大小低于10时, 两种网络的挖掘结果准确率相差不大, 但随着事务集的增大, 两种网络的准确率曲线差距均在0.27以上。通过计算两条曲线差值之和的均值, 可得出MHNN在HNN的基础上提升约35.3个百分点的挖掘结果准确率。在上述情况下, 又进行多组实验, 其中最好结果为36%, 最坏结果为33.9%, 得出改进后的算法在关联挖掘结果准确率上提高33.9个百分点以上。</p>
                </div>
                <div class="area_img" id="243">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903019_243.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 HNN和MHNN的挖掘结果准确率对比" src="Detail/GetImg?filename=images/JSJY201903019_243.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 HNN和MHNN的挖掘结果准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903019_243.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Accuracy comparison of mining results between HNN and MHNN</p>

                </div>
                <h3 id="244" name="244" class="anchor-tag">6 结语</h3>
                <div class="p1">
                    <p id="245">本文在软件仿真上为忆阻器在HNN处理关联规则挖掘的问题中的应用提出了一种可行的思路。本文设计的MHNN能够处理较小规模的关联规则挖掘问题, 但仍然存在容易陷入局部最优点的问题, 后续可以考虑使用遗传算法对该网络进行改进。</p>
                </div>
                <div class="p1">
                    <p id="246">在硬件实现上, 随着关联规则挖掘问题复杂度的增加, 需要设计的电路的规模也相应增大, 对网络的集成度、能耗以及并行处理能力的要求也越来越高。本文设计的MHNN电路结构可以降低电路设计难度, 提高电路自适应关联规则挖掘算法输入的能力, 可有效解决传统人工神经网络的瓶颈。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="280">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Memristor-the missing circuit element">

                                <b>[1]</b>CHUA L O.Memristor-the missing circuit element[J].IEEETransactions on Circuit Theory, 1971, 18 (5) :507-519.
                            </a>
                        </p>
                        <p id="282">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The missing memristor found">

                                <b>[2]</b>STRUKOV D B, SNIDER G S, STEWART D R, et al.The missing memristor found[J].Nature, 2008, 453 (7191) :80-83.
                            </a>
                        </p>
                        <p id="284">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reservoir computing using dynamic memristors for temporal information processing">

                                <b>[3]</b>DU C, CAI F, ZIDAN M A, et al.Reservoir computing using dynamic memristors for temporal information processing[J].Nature Communications, 2017, 8:Article No.2204.
                            </a>
                        </p>
                        <p id="286">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nanoscale memristor device as synapse in neuromorphic systems">

                                <b>[4]</b>JO S H, CHANG T, EBONG I, et al.Nanoscale memristor device as synapse in neuromorphic systems[J].Nano Letters, 2010, 10 (4) :1297-1301.
                            </a>
                        </p>
                        <p id="288">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=TEAM: ThrEshold Adaptive Memristor Model">

                                <b>[5]</b>KVATINSKY S, FRIEDMAN E G, KOLODNY A, et al.TEAM:ThrEshold Adaptive Memristor model[J].IEEE Transactions on Circuits and Systems I:Regular Papers, 2013, 60 (1) :211-221.
                            </a>
                        </p>
                        <p id="290">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016767688.nh&amp;v=Mjk2MjU3cWZadVpwRmlEbFc3dkJWRjI2R0xTK0dkZkVwNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>江之源.基于阈值自适应忆阻模型的分析及应用研究[D].重庆:西南大学, 2016:11-12. (JIANG Z Y.Analysis and application research based on threshold adaptive memristor model[D].Chongqing:Southwestern University, 2016:11-12.) 
                            </a>
                        </p>
                        <p id="292">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012048147.nh&amp;v=MTQxMTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3ZCVkYyNkhMTzhGdERJcUpFYlA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>代祥光.忆阻神经网络的应用[D].重庆:重庆大学, 2012:1-3. (DAI X G.Application of memristive neural network[D].Chongqing:Chongqing University, 2012:1-3.) 
                            </a>
                        </p>
                        <p id="294">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pattern classification by memristive crossbar circuits using ex situ and in situ training">

                                <b>[8]</b>ALIBART F, ZAMANIDOOST E, STRUKOV D B.Pattern classification by memristive crossbar circuits using ex situ and in situ training[J].Nature Communications, 2013, 4 (3) :131-140.
                            </a>
                        </p>
                        <p id="296">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neuromorphic speech systems using advanced ReRAM-based synapse">

                                <b>[9]</b>PARK S, SHERI A, KIM J, et al.Neuromorphic speech systems using advanced ReRAM-based synapse[C]//Proceedings of 2013IEEE International Electron Devices Meeting.Piscataway, NJ:IEEE, 2013:25.6.1-25.6.4.
                            </a>
                        </p>
                        <p id="298">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An electronic version of Pavlov&amp;#39;s Dog">

                                <b>[10]</b>ZIEGLER M, SONI R, PATELCZYK T, et al.An electronic version of Pavlov's dog[J].Advanced Functional Materials, 2012, 22 (13) :2744-2749.
                            </a>
                        </p>
                        <p id="300">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Associative memory realized by a reconfigurable memristive Hopfield neural network">

                                <b>[11]</b>HU S G, LIU Y, LIU Z, et al.Associative memory realized by a reconfigurable memristive Hopfield neural network[J].Nature Communications, 2015, 6:Article number 7522.
                            </a>
                        </p>
                        <p id="302">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural Networks and Physical Systems Emergent Collective Computational Abilities">

                                <b>[12]</b>HOPFIELD J J.Neural networks and physical systems with emergent collective computational abilities[J].Proceedings of the National Academy of Sciences of the United States of America, 1982, 79 (8) :2554-2558.
                            </a>
                        </p>
                        <p id="304">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003237169&amp;v=MjAwMDNScnhveGNNSDdSN3FkWitadUZpL2tXNy9BSkZjPU5qN0Jhck80SHRIUHJZeENaZTBHWTNrNXpCZGg0ajk5U1hx&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>HOPFIELD J J, TANK D W.Neuralcomputation of decisions in optimization problems[J].Biological Cybernetics, 1985, 52 (3) :141-145.
                            </a>
                        </p>
                        <p id="306">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining Association Rules between Sets of Items in Large Databases">

                                <b>[14]</b>AGRAWAL R, IMIELINSKI T, SWAMI A N.Mining association rules between sets of items in large databases[C]//Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data.New York:ACM, 1993:207-216.
                            </a>
                        </p>
                        <p id="308">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast algorithms for mining association rules">

                                <b>[15]</b>AGRAWAL R, SRIKANT R.Fast algorithms for mining association rules in large databases[C]//VLDB'94:Proceedings of the20th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1994:487-499.
                            </a>
                        </p>
                        <p id="310">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201004028&amp;v=MDg1OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkJNaWZOZExHNEg5SE1xNDlIYkk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>王爱平, 王占凤, 陶嗣干, 等.数据挖掘中常用关联规则挖掘算法[J].计算机技术与发展, 2010, 20 (4) :105-108. (WANG AP, WANG Z F, TAO S G, et al.Common algorithms of association rules mining in data mining[J].Computer Technology and Development, 2010, 20 (4) :105-108.) 
                            </a>
                        </p>
                        <p id="312">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000068566&amp;v=MjY5ODRVcmpKS0Y0Y2Jocz1OaWZJWTdLN0h0ak5yNDlGWk8wSENYby9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>PARK J S, CHEN M S, YU P S.An effective hash-based algorithm for mining association rules[J].ACM SIGMOD Record, 1995, 24 (2) :175-186.
                            </a>
                        </p>
                        <p id="314">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining frequent ordered patterns without candidate generation">

                                <b>[18]</b>JI C R, DENG Z H.Mining frequent ordered patterns without candidate generation[C]//Proceedings of the 4th IEEE International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway, NJ:IEEE, 2007, 1:402-406.
                            </a>
                        </p>
                        <p id="316">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for mining association rules">

                                <b>[19]</b>SAVASERE A, OMIECINSKI E, NAVATHE S B, et al.An efficient algorithm for mining association rules in large databases[C]//VLDB'95:Proceedings of the 21st International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1995:432-444.
                            </a>
                        </p>
                        <p id="318">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sampling large databases for association rules">

                                <b>[20]</b>TOIVONEN H.Sampling large databases for association rules[C]//VLDB'96:Proceedings of the 22th International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1996:134-145.
                            </a>
                        </p>
                        <p id="320">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallel mining of association rules">

                                <b>[21]</b>AGRAWAL R, SHAFER J C.Parallel mining of association rules[J].IEEE Transactions on Knowledge and Data Engineering, 2007, 8 (6) :962-969.
                            </a>
                        </p>
                        <p id="322">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallel mining of association rules with a Hopfield type neural network">

                                <b>[22]</b>GABER K, BAHI J M, EL-GHAZAWI T A.Parallel mining of association rules with a Hopfield type neural network[C]//ICTAI'00:Proceedings of the 12th IEEE International Conference on Tools with Artificial Intelligence.Washington, DC:IEEE Computer Society, 2000:90-93.
                            </a>
                        </p>
                        <p id="324">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SPICE modeling of memristors">

                                <b>[23]</b>ABDALLA H, PICKETT M D.SPICE modeling of memristors[C]//Proceedings of the 2011 IEEE International Symposium on Circuits and Systems.Piscataway, NJ:IEEE, 2011:1832-1835.
                            </a>
                        </p>
                        <p id="326">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607018&amp;v=MjY5MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3ZCTHo3QmQ3RzRIOWZNcUk5RWJJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>徐开勇, 龚雪容, 成茂才.基于改进Apriori算法的审计日志关联规则挖掘[J].计算机应用, 2016, 36 (7) :1847-1851. (XU KY, GONG X R, CHENG M C.Audit log association rule mining based on improved apriori algorithm[J].Journal of Computer Applications, 2016, 36 (7) :1847-1851.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903019" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903019&amp;v=MjkyNTVxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3ZCTHo3QmQ3RzRIOWpNckk5RWJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
