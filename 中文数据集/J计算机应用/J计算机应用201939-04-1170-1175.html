<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779469033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904038%26RESULT%3d1%26SIGN%3dzACxzGjg0ZQH5g5u5Libzl38ND0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904038&amp;v=MjYwMjZxZlp1WnNGeURoVUx6TEx6N0JkN0c0SDlqTXE0OUdiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="1 RPCA模型 ">1 RPCA模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 本文模型的建立 ">2 本文模型的建立</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="2.1 &lt;b&gt;前景建模&lt;/b&gt;">2.1 <b>前景建模</b></a></li>
                                                <li><a href="#78" data-title="2.2 &lt;b&gt;背景建模&lt;/b&gt;">2.2 <b>背景建模</b></a></li>
                                                <li><a href="#85" data-title="2.3 &lt;b&gt;加权&lt;/b&gt;Schatten-&lt;i&gt;p&lt;/i&gt;&lt;b&gt;范数与&lt;/b&gt;3D&lt;b&gt;全变分模型的建立&lt;/b&gt;">2.3 <b>加权</b>Schatten-<i>p</i><b>范数与</b>3D<b>全变分模型的建立</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="3 模型的求解 ">3 模型的求解</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="4.1 &lt;b&gt;仿真实验&lt;/b&gt;">4.1 <b>仿真实验</b></a></li>
                                                <li><a href="#134" data-title="4.2 &lt;b&gt;量化对比以及结果分析&lt;/b&gt;">4.2 <b>量化对比以及结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#146" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#132" data-title="图1 不同算法针对不同视频序列的实验结果比较">图1 不同算法针对不同视频序列的实验结果比较</a></li>
                                                <li><a href="#133" data-title="图2 不同帧下不同算法的实验结果比较 (&lt;i&gt;SnowFall&lt;/i&gt;视频序列) ">图2 不同帧下不同算法的实验结果比较 (<i>SnowFall</i>视频序列) </a></li>
                                                <li><a href="#141" data-title="图3 Fall视频序列代表帧在不同算法下的客观指标对比">图3 Fall视频序列代表帧在不同算法下的客观指标对比</a></li>
                                                <li><a href="#142" data-title="图4 Fall视频序列代表帧在不同算法下的客观指标对比">图4 Fall视频序列代表帧在不同算法下的客观指标对比</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同算法前景检测客观结果对比&lt;/b&gt;"><b>表</b>1 <b>不同算法前景检测客观结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="173">


                                    <a id="bibliography_1" title="BOUWMANS T, ZAHZAH E H.Robust PCA via principal component pursuit:a review for a comparative evaluation in video surveillance[J].Computer Vision and Image Understanding, 2014, 122:22-34." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700238312&amp;v=MDg5NjRVcjNJS0ZvWGFSRT1OaWZPZmJLOEh0Zk5xSTlGWnVnSEQzMDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        BOUWMANS T, ZAHZAH E H.Robust PCA via principal component pursuit:a review for a comparative evaluation in video surveillance[J].Computer Vision and Image Understanding, 2014, 122:22-34.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_2" title="ZHOU X, YANG C, ZHAO H, et al.Low-rank modeling and its applications in image analysis[J].ACM Computing Surveys, 2014, 47 (2) :1-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM59B372F9DC8CB6FC5F5D7668E983E196&amp;v=MTM0NTlXbkRvSlQzbmtwR2M4Y2JIaFJMT1pDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh6THk4dzZzPU5pZklZN2F4Yk5MTHJmbE1FSmdIZnc0L3VXVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        ZHOU X, YANG C, ZHAO H, et al.Low-rank modeling and its applications in image analysis[J].ACM Computing Surveys, 2014, 47 (2) :1-33.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_3" title="REZAEI B, OSTADABBAS S.Background subtraction via fast robust matrix completion[C]//Proceeding of the 2017 IEEE International Conference on Computer Vision Workshop.Piscataway, NJ:IEEE, 2017:1871-1879." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Background subtraction via fast robust matrix completion">
                                        <b>[3]</b>
                                        REZAEI B, OSTADABBAS S.Background subtraction via fast robust matrix completion[C]//Proceeding of the 2017 IEEE International Conference on Computer Vision Workshop.Piscataway, NJ:IEEE, 2017:1871-1879.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_4" title="XIE Y, GU S, LIU Y, et al.Weighted Schatten p-Norm minimization for image denoising and background subtraction[J].IEEETransactions on Image Processing, 2016, 25 (10) :4842-4 857." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weighted schatten p-norm minimization for image denoising and background subtraction">
                                        <b>[4]</b>
                                        XIE Y, GU S, LIU Y, et al.Weighted Schatten p-Norm minimization for image denoising and background subtraction[J].IEEETransactions on Image Processing, 2016, 25 (10) :4842-4 857.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_5" title="LU C, FENG J, CHEN Y, et al.Tensor robust principal component analysis with a new tensor nuclear norm[EB/OL].[2018-05-10].http://adsabs.harvard.edu/abs/2018ar Xiv180403728L." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor robust principal component analysis with a new tensor nuclear norm">
                                        <b>[5]</b>
                                        LU C, FENG J, CHEN Y, et al.Tensor robust principal component analysis with a new tensor nuclear norm[EB/OL].[2018-05-10].http://adsabs.harvard.edu/abs/2018ar Xiv180403728L.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_6" title="GOLDFARB D, QIN Z.Robust low-rank tensor recovery:models and algorithms[J].SIAM Journal on Matrix Analysis&amp;amp;Applications, 2013, 35 (1) :225-253." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust low-rank tesnor recovery:Models and algorithms">
                                        <b>[6]</b>
                                        GOLDFARB D, QIN Z.Robust low-rank tensor recovery:models and algorithms[J].SIAM Journal on Matrix Analysis&amp;amp;Applications, 2013, 35 (1) :225-253.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_7" title="PANG Y, YE L, LI X, et al.Incremental learning with saliency map for moving object detection[J].IEEE Transactions on Circuits and Systems for Video Technology, 2018, 28 (3) :640-651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incremental learning with saliency map for moving object detection">
                                        <b>[7]</b>
                                        PANG Y, YE L, LI X, et al.Incremental learning with saliency map for moving object detection[J].IEEE Transactions on Circuits and Systems for Video Technology, 2018, 28 (3) :640-651.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_8" title="EBADI S E, IZQUIERDO E.Foreground segmentation with treestructured sparse RPCA[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (9) :2273-2280." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Foreground segmentation with treestructured sparse RPCA">
                                        <b>[8]</b>
                                        EBADI S E, IZQUIERDO E.Foreground segmentation with treestructured sparse RPCA[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (9) :2273-2280.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_9" title="BHATTACHARYA S, VENKATSH K S, GUPTA S.Background estimation and motion saliency detection using total variation-based video decomposition[J].Signal, Image and Video Processing, 2017, 11 (1) :113-121." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Background estimation and motion saliency detection using total variation-based video decomposition">
                                        <b>[9]</b>
                                        BHATTACHARYA S, VENKATSH K S, GUPTA S.Background estimation and motion saliency detection using total variation-based video decomposition[J].Signal, Image and Video Processing, 2017, 11 (1) :113-121.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_10" title="CAO X, YANG L, GUO X.Total variation regularized RPCA for irregularly moving object detection under dynamic background[J].IEEE Transactions on Cybernetics, 2017, 46 (4) :1014-1027." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Total variation regularized RPCA for irregularly moving object detection under dynamic background">
                                        <b>[10]</b>
                                        CAO X, YANG L, GUO X.Total variation regularized RPCA for irregularly moving object detection under dynamic background[J].IEEE Transactions on Cybernetics, 2017, 46 (4) :1014-1027.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_11" title="CHAN S H, KHOSHABEH R, GIBSON K B, et al.An augmented lagrangian method for total variation video restoration[J].IEEETransactions on Image Processing, 2011, 20 (11) :3097-3111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Augmented Lagrangian Method for Total Variation Video Restoration">
                                        <b>[11]</b>
                                        CHAN S H, KHOSHABEH R, GIBSON K B, et al.An augmented lagrangian method for total variation video restoration[J].IEEETransactions on Image Processing, 2011, 20 (11) :3097-3111.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_12" title="CAO W, WANG Y, SUN J, et al.Total variation regularized tensor RPCA for background subtraction from compressive measurements[J].IEEE Transactions on Image Processing, 2016, 25 (9) :4075-4090." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Total Variation Regularized Tensor RPC A for Background Subtraction From Compressive Measurements">
                                        <b>[12]</b>
                                        CAO W, WANG Y, SUN J, et al.Total variation regularized tensor RPCA for background subtraction from compressive measurements[J].IEEE Transactions on Image Processing, 2016, 25 (9) :4075-4090.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_13" title="BOYD S, PARIKH N, CHU E, et al.Distributed optimization and statistical learning via the alternating direction method of multipliers[J].Foundations and Trends in Machine Learning, 2011, 3 (1) :1-122." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed optimization and statistical learning via the alternating direction method of multipliers">
                                        <b>[13]</b>
                                        BOYD S, PARIKH N, CHU E, et al.Distributed optimization and statistical learning via the alternating direction method of multipliers[J].Foundations and Trends in Machine Learning, 2011, 3 (1) :1-122.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_14" title="DENG W, YIN W.On the global and linear convergence of the generalized alternating direction method of multipliers[J].Journal of Scientific Computing, 2016, 66 (3) :889-916." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the global and linear convergence of the generalized alternating direction method of multipliers">
                                        <b>[14]</b>
                                        DENG W, YIN W.On the global and linear convergence of the generalized alternating direction method of multipliers[J].Journal of Scientific Computing, 2016, 66 (3) :889-916.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_15" title="ZUO W, MENG D, ZHANG L, et al.A generalized iterated shrinkage algorithm for non-convex sparse coding[C]//Proceedings of the IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2013:217-224." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A generalized iterated shrinkage algorithm for non-convex sparse coding">
                                        <b>[15]</b>
                                        ZUO W, MENG D, ZHANG L, et al.A generalized iterated shrinkage algorithm for non-convex sparse coding[C]//Proceedings of the IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2013:217-224.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_16" title="WANG Y, JODOIN P M, PORIKLI F, et al.CDnet 2014:an expanded change detection benchmark dataset[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington, DC:IEEE Computer Society, 2014:387-394." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CDnet 2014:An expanded change detection benchmark dataset">
                                        <b>[16]</b>
                                        WANG Y, JODOIN P M, PORIKLI F, et al.CDnet 2014:an expanded change detection benchmark dataset[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington, DC:IEEE Computer Society, 2014:387-394.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_17" title="常侃, 张智勇, 陈诚, 等.采用低秩与加权稀疏分解的视频前景检测算法[J].电子学报, 2017, 45 (9) :2272-2280. (CHANG K, ZHANG Z Y, CHEN C, et al.Video foreground detection by low-rank and reweighted sparse decomposition[J].Acta Electronica Sinica, 2017, 45 (9) :2272-2280.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201709031&amp;v=MDg4OTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUx6TElUZlRlN0c0SDliTXBvOUc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        常侃, 张智勇, 陈诚, 等.采用低秩与加权稀疏分解的视频前景检测算法[J].电子学报, 2017, 45 (9) :2272-2280. (CHANG K, ZHANG Z Y, CHEN C, et al.Video foreground detection by low-rank and reweighted sparse decomposition[J].Acta Electronica Sinica, 2017, 45 (9) :2272-2280.) 
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_18" title="刘仲民, 何胜皎, 胡文瑾, 等.基于背景减除法的视频序列运动目标检测[J].计算机应用, 2017, 37 (6) :1777-1781. (LIU Z M, HE S J, HU W J, et al.Moving object detection based on background subtraction for video sequence[J].Journal of Computer Applications, 2017, 37 (6) :1777-1781.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201706045&amp;v=MTI0NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTHpMTHo3QmQ3RzRIOWJNcVk5QllZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        刘仲民, 何胜皎, 胡文瑾, 等.基于背景减除法的视频序列运动目标检测[J].计算机应用, 2017, 37 (6) :1777-1781. (LIU Z M, HE S J, HU W J, et al.Moving object detection based on background subtraction for video sequence[J].Journal of Computer Applications, 2017, 37 (6) :1777-1781.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-18 09:31</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1170-1175 DOI:10.11772/j.issn.1001-9081.2018092038            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合加权Schatten-<i>p</i>范数与</b>3<b>D全变分的前景检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%88%A9%E9%9C%9E&amp;code=21759414&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈利霞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E4%BF%8A%E4%B8%BD&amp;code=38226633&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘俊丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%AD%A6%E6%96%87&amp;code=26233701&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王学文</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E8%AE%A1%E7%AE%97%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学数学与计算科学学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对低秩与稀疏方法一般将前景看作背景中存在的异常像素点, 从而使得在复杂场景中前景检测精确度下降的问题, 提出一种结合加权Schatten-<i>p</i>范数与3D全变分 (3D-TV) 的前景检测模型。该模型首先将观测数据三分为低秩背景、运动前景和动态干扰;然后利用3D全变分来约束运动前景, 并加强对前景目标时空连续性的先验考虑, 有效抑制了不连续动态背景异常点的随机扰动;最后利用加权Schatten-<i>p</i>范数约束视频背景的低秩性能, 去除噪声干扰。实验结果表明, 与鲁棒主成分分析 (RPCA) 、高阶RPCA (HoRPCA) 和张量RPCA (TRPCA) 等模型相比, 所提模型的综合衡量指标F-measure值是最高的, 查全率与查准率也处于最优或次优状态。由此可知, 所提模型在动态背景、恶劣天气等复杂场景中能有效提高运动目标的提取精确度, 且提取的前景目标视觉效果较好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E7%A7%A9%E7%A8%80%E7%96%8F%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低秩稀疏分解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%89%8D%E6%99%AF%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">前景检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E6%9D%83Schatten-%3Ci%3Ep%3C%2Fi%3E%E8%8C%83%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加权Schatten-<i>p</i>范数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%E5%85%A8%E5%8F%98%E5%88%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D全变分;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈利霞 (1979—) , 女, 湖北浠水人, 教授, 博士, 主要研究方向:数字图像处理中的数学理论与算法;;
                                </span>
                                <span>
                                    刘俊丽 (1992—) , 女, 河南周口人, 硕士研究生, 主要研究方向:数字图像处理中的数学理论与算法;;
                                </span>
                                <span>
                                    *王学文 (1979—) , 男, 湖北浠水人, 讲师, 硕士, 主要研究方向:数字图像处理。电子邮箱befine@aliyun.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>桂林电子科技大学研究生科研创新项目 (2017YJCX84);</span>
                                <span>广西高等教育本科教学改革工程项目 (2017JGB230);</span>
                    </p>
            </div>
                    <h1><b>Foreground detection with weighted Schatten-<i>p</i> norm and</b> 3<b>D total variation</b></h1>
                    <h2>
                    <span>CHEN Lixia</span>
                    <span>LIU Junli</span>
                    <span>WANG Xuewen</span>
            </h2>
                    <h2>
                    <span>College of Mathematics and Computing Science, Guilin University of Electronic Technology</span>
                    <span>College of Computer and Information Security, Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In view of the fact that the low rank and sparse methods generally regard the foreground as abnormal pixels in the background, which makes the foreground detection precision decrease in the complex scene, a new foreground detection method combining weighted Schatten-<i>p</i> norm with 3 D Total Variation (3 D-TV) was proposed. Firstly, the observed data were divided into low rank background, moving foreground and dynamic disturbance. Then 3 D total variation was used to constrain the moving foreground and strengthen the prior consideration of the spatio-temporal continuity of the foreground objects, effectively suppressing the random disturbance of the anomalous pixels in the discontinuous dynamic background. Finally, the low rank performance of video background was constrained by weighted Schatten-<i>p</i> norm to remove noise interference. The experimental results show that, compared with Robust Principal Component Analysis (RPCA) , Higher-order RPCA (HoRPCA) and Tensor RPCA (TRPCA) , the proposed model has the highest F-measure value, and the optimal or sub-optimal values of recall and precision. It can be concluded that the proposed model can better overcome the interference in complex scenes, such as dynamic background and severe weather, and its extraction accuracy as well as visual effect of moving objects is improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=low-rank%20and%20sparse%20decomposition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">low-rank and sparse decomposition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=foreground%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">foreground detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=weighted%20Schatten-%3Ci%3Ep%3C%2Fi%3E%20norm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">weighted Schatten-<i>p</i> norm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20total%20variation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D total variation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHEN Lixia, born in 1979, Ph. D. , professor. Her research interests include mathematical theory and algorithm in digital image processing.;
                                </span>
                                <span>
                                    LIU Junli, born in 1992, M. S. candidate. Her research interests include mathematical theory and algorithm in digital image processing.;
                                </span>
                                <span>
                                    WANG Xuewen, born in 1979, M. S. , lecturer. His research interests include digital image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Innovation Project of GUET Graduate Education (2017YJCX84);</span>
                                <span>the Guangxi Higher Education Undergraduate Teaching Reform Project (2017JGB230);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="50">视频中运动目标检测在计算机视觉、目标跟踪以及监控安防等领域有极其重要的作用。由于现实场景的复杂多变, 使得前景目标检测变得很有挑战性。近期, 低秩和稀疏表示方法在前景检测领域应用很广泛, 鲁棒主成分分析 (Robust Principal Component Analysis, RPCA) <citation id="215" type="reference"><link href="173" rel="bibliography" /><link href="175" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>就是其中的一种。该模型将视频数据分为低秩背景和稀疏前景两部分, 模型简单且求解高效, 因此被广泛应用于运动目标检测领域。但是RPCA模型的前提假设是背景静止或几乎静止, 而当背景中出现动态变化时, 提取效果就会减弱。近年来学者们对该模型进行了有效的改进:Rezaei等<citation id="209" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出一种快速稳定的矩阵填充模型 (Fast Robust Matrix Completion, FRMC) , 极大地提高了对背景建模问题的求解速度;Xie等<citation id="210" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了加权Schatten-<i>p</i>范数最小化 (Weighted Schatten <i>p</i>-Norm Minimization, WSNM) 模型, 进一步提高了背景建模在复杂场景中的稳定性;Lu等<citation id="211" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出张量RPCA (Tensor RPCA, TRPCA) 模型, 利用一种新的张量核范数对背景建模, 能精确恢复背景;Goldfarb等<citation id="212" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出高阶鲁棒主成分分析 (Higher-order RPCA, HoRPCA) 模型, 考虑了不同张量模展开矩阵的内部相关性;Pang等<citation id="213" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>将显著性图与RPCA结合, 提出一种基于增量低秩的方法;Ebadi等<citation id="214" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出用动态树结构的稀疏矩阵去建模前景;Bhattacharya等<citation id="216" type="reference"><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>提出全变分正则化的RPCA方法, 加强了对前景的约束。虽然这些基于矩阵和基于张量的方法均取得了一定的成果, 但RPCA模型对含有动态背景的视频处理仍有缺陷, 许多方法还不够成熟, 稳定性不高。在复杂场景中构建有效的前背景模型仍具有一定的难度。</p>
                </div>
                <div class="p1">
                    <p id="51">基于以上方法的讨论, 本文充分利用前景的时空连续性和背景的高度相关性, 提出一种结合加权Schatten-<i>p</i>范数和3D全变分 (3D Total Variation, 3D-TV) 的视频前景检测模型。该模型利用3D全变分在时空中的光滑特性来建模前景目标, 考虑了运动目标在时间和空间上的持续性, 有效地抑制了离散动态背景对连续运动前景造成的干扰, 提高了前背景在动态场景中的分离精确度;同时利用加权Schatten-<i>p</i>范数替代RPCA中的秩函数对背景进行低秩约束, 从而有效地重构背景, 使得其在动态复杂背景中具有较好的鲁棒性。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">1 RPCA模型</h3>
                <div class="p1">
                    <p id="53">假定给出的视频图像序列包含<i>T</i>帧, 然后将所有帧向量化作为列向量得到矩阵<b><i>X</i></b>∈<b>R</b><sup><i>MN</i>×<i>T</i></sup>, 其中<i>M</i>和<i>N</i>分别表示视频帧的高和宽。检测运动目标可以通过求解如下RPCA模型来获取低秩背景矩阵<b><i>X</i></b><sub>1</sub>∈<b>R</b><sup><i>MN</i>×<i>T</i></sup>以及稀疏前景<b><i>X</i></b><sub>2</sub>∈<b>R</b><sup><i>MN</i>×<i>T</i></sup>:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">X</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中:‖<b><i>X</i></b><sub>1</sub>‖<sub>*</sub>表示矩阵<b><i>X</i></b><sub>1</sub>的核范数;‖<b><i>X</i></b><sub>2</sub>‖<sub>1</sub>表示矩阵<b><i>X</i></b><sub>2</sub>的<i>l</i><sub>1</sub>范数; <i>λ</i>是一个正的权衡参数。</p>
                </div>
                <div class="p1">
                    <p id="56">但在实际生活中, 视频中的背景往往并不仅仅是静态的, 例如水波、树叶摇晃等, 这些都会对前景提取造成干扰。因此可将式 (1) 扩展为:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">E</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>μ</mi><mi>γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">X</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi mathvariant="bold-italic">E</mi></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">其中: <i>μ</i>为权衡参数; <i>γ</i> (<b><i>E</i></b>) 为干扰信号, 通常用1/2‖<b><i>E</i></b>‖<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>或‖<b><i>E</i></b>‖<sub>1</sub>来表示。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 本文模型的建立</h3>
                <div class="p1">
                    <p id="61">本文利用3<i>D</i>全变分正则化方法增强前景的时空连续性, 提高了动态背景与运动前景的分离效果, 同时利用比核范数具有更佳低秩逼近的加权<i>Schatten</i>-p范数来对背景作低秩约束, 从而有效地检测复杂背景下的运动目标。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">2.1 <b>前景建模</b></h4>
                <div class="p1">
                    <p id="63">视频前景可以看作为视频中的显著性运动目标, 占据了视频帧中小部分的空间连续区域。另外, 前景目标的运动轨迹在时间上是光滑的, 因此可以得知需要检测的视频前景目标在时空域上具有连续性和光滑性的特征。视频中显著但却很小的物体运动, 例如飘落的雪花、晃动的树叶等, 在时空域分布上呈现为类似噪声特性, 是不需要检测的。在数学上, 全变分具有平滑信号的功能, 对信号中存在的不连续变化具有较强的抑制性能, 全变分正则项在图像和视频去噪方面应用广泛<citation id="217" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。因此, 通过3<i>D</i>全变分模型<citation id="218" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>可以有效地抑制由动态背景造成的随机扰动。视频序列可以通过3维张量来表示, 即<i>χ</i><sub>2</sub>∈<b>R</b><sup><i>M</i>×<i>N</i>×<i>T</i></sup>, 对于<i>χ</i><sub>2</sub>中的每个体素可表示为<i>χ</i><sub>2</sub> (<i>m</i>, <i>n</i>, <i>t</i>) , 其中:<i>m</i>=1, 2, …, <i>M</i>;<i>n</i>=1, 2, …, <i>N</i>;<i>t</i>=1, 2, …, <i>T</i>。</p>
                </div>
                <div class="p1">
                    <p id="64">定义下述标量来描述其时空连续性:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><mi>V</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi><mo>.</mo><mi>t</mi></mrow></msub><mo stretchy="false"> (</mo><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mrow><mo>:</mo><mo>=</mo></mrow><mrow><mo>|</mo><mrow><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">可见3D全变分正则项是将<i>TV</i><sub><i>m</i>, <i>n</i>.<i>t</i></sub>相加得到, 即</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mn>3</mn><mtext>D</mtext><mo>-</mo><mtext>Τ</mtext><mtext>V</mtext></mrow></msub><mrow><mo>:</mo><mo>=</mo></mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi></mrow></munder><mi>Τ</mi></mstyle><mi>V</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">为了更好地说明3D全变分, 进一步介绍以下差分算子。令<i>χ</i> (<i>m</i>, <i>n</i>, <i>t</i>) 表示体素 (<i>m</i>, <i>n</i>, <i>t</i>) 的强度, 令</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mi>h</mi></msub><mrow><mo>:</mo><mo>=</mo></mrow><mrow><mo>|</mo><mrow><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mtd></mtr><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mi>v</mi></msub><mrow><mo>:</mo><mo>=</mo></mrow><mrow><mo>|</mo><mrow><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mtd></mtr><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mi>t</mi></msub><mrow><mo>:</mo><mo>=</mo></mrow><mrow><mo>|</mo><mrow><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">分别表示体素 (<i>m</i>, <i>n</i>, <i>t</i>) 沿水平方向、垂直方向以及时间方向的差分算子。则可以通过下述向量差分算子来定义‖<b><i>X</i></b><sub>2</sub>‖<sub>3D-TV</sub>:</p>
                </div>
                <div class="p1">
                    <p id="71"><b><i>D</i></b><sub><i>h</i></sub><b><i>x</i></b>:=Vec (<i>χ</i><sub><i>h</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="72"><b><i>D</i></b><sub><i>v</i></sub><b><i>x</i></b>:=Vec (<i>χ</i><sub><i>v</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="73"><b><i>D</i></b><sub><i>t</i></sub><b><i>x</i></b>:=Vec (<i>χ</i><sub><i>t</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="74">这里所有帧表示为列向量<b><i>x</i></b>:=Vec (<i>χ</i>) , Vec (·) 表示将张量向量化。令<b><i>Dx</i></b>:=[ (<b><i>D</i></b><sub><i>h</i></sub><b><i>x</i></b>) <sup>T</sup>, (<b><i>D</i></b><sub><i>v</i></sub><b><i>x</i></b>) <sup>T</sup>, (<b><i>D</i></b><sub><i>t</i></sub><b><i>x</i></b>) <sup>T</sup>]<sup>T</sup>表示3个差分算子的级联, 则有3D全变分相当于向量差分的<i>l</i><sub>1</sub>范数:</p>
                </div>
                <div class="p1">
                    <p id="75">‖<b><i>X</i></b><sub>2</sub>‖<sub>3D-TV</sub>=‖<b><i>Dx</i></b><sub>2</sub>‖<sub>1</sub>=‖<b><i>D</i></b><sub><i>h</i></sub><b><i>x</i></b><sub>2</sub>‖<sub>1</sub>+‖<b><i>D</i></b><sub><i>v</i></sub><b><i>x</i></b><sub>2</sub>‖<sub>1</sub>+‖<b><i>D</i></b><sub><i>t</i></sub><b><i>x</i></b><sub>2</sub>‖<sub>1</sub>      (3) </p>
                </div>
                <div class="p1">
                    <p id="77">全变分将视频图像中因动态背景产生的随机变化判为噪声去除, 提高了模型在复杂场景中的稳定性, 能更精确地提取前景。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.2 <b>背景建模</b></h4>
                <div class="p1">
                    <p id="79">由于视频背景具有很高的相关性, 因此对背景部分<b><i>X</i></b><sub>1</sub>可作低秩约束, 传统的RPCA模型利用核范数来凸松弛矩阵的低秩部分, 但核范数定义为矩阵的所有奇异值之和, 没有考虑到每个奇异值对秩的不同影响。加权Schatten-<i>p</i>范数<citation id="219" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>是通过融合Schatten-<i>p</i>范数与加权核范数得到的更一般的秩近似函数, 考虑了不同秩的实际物理意义, 因此本文利用加权Schatten-<i>p</i>范数进行低秩矩阵估计, 其表达形式为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow></msub><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>min</mi><mo stretchy="false">{</mo><mi>Μ</mi><mi>Ν</mi><mo>, </mo><mi>Τ</mi><mo stretchy="false">}</mo></mrow></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mi>p</mi></mfrac></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其中:<b><i>w</i></b>= (<i>ω</i><sub>1</sub>, <i>ω</i><sub>2</sub>, …, <i>ω</i><sub>min{<i>MN</i>, <i>T</i>}</sub>) 为对应奇异值的权重组成的一个非负向量;<i>σ</i><sub><i>i</i></sub>表示背景部分<b><i>X</i></b><sub>1</sub>的第<i>i</i>个奇异值; <i>p</i> (0&lt;<i>p</i>≤1) 为加权Schatten-<i>p</i>范数的参数。不同的<i>p</i>值下加权Schatten-<i>p</i>范数的取值也不同, 本文实验中<i>p</i>均取值为0.7<citation id="220" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="82">根据文献<citation id="221" type="reference">[<a class="sup">4</a>]</citation>, 权重的更新方程如下:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>C</mi><msqrt><mrow><mi>Μ</mi><mi>Ν</mi><mi>Τ</mi></mrow></msqrt></mrow><mrow><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>+</mo><mi>ε</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中:<i>C</i>和<i>ε</i>为常数。本文设<i>C</i>=2max ( (<i>MN</i>) <sup>2</sup>, <i>T</i><sup>2</sup>) , <i>ε</i>=10<sup>-5</sup>。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2.3 <b>加权</b>Schatten-<i>p</i><b>范数与</b>3D<b>全变分模型的建立</b></h4>
                <div class="p1">
                    <p id="86">综上所述, 将前景模型式 (3) 和背景模型式 (4) 整合到式 (2) 中, 可得到基于加权<i>Schatten</i>-p范数结合3<i>D</i>全变分的模型, 该模型如下:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">E</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow><mi>p</mi></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mn>3</mn><mtext>D</mtext><mo>-</mo><mtext>Τ</mtext><mtext>V</mtext></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">X</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi mathvariant="bold-italic">E</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">干扰项<i>γ</i> (<b><i>E</i></b>) 选取<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>, 根据3D全变分的定义式 (3) , 则新模型可改写为:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">E</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow><mi>p</mi></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">X</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi mathvariant="bold-italic">E</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">3 模型的求解</h3>
                <div class="p1">
                    <p id="92">引入辅助变量<b><i>f</i></b>, 将式 (7) 变为:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">E</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow><mi>p</mi></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">f</mi><mo>=</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi mathvariant="bold-italic">X</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mi mathvariant="bold-italic">E</mi></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">则其增广拉格朗日函数为:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">E</mi><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">f</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow><mi>p</mi></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mspace width="0.25em" /><mo>-</mo></mtd></mtr><mtr><mtd><mo>〈</mo><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">f</mi></msub><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">f</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>〉</mo><mo>+</mo><mfrac><mrow><mi>β</mi><msub><mrow></mrow><mi mathvariant="bold-italic">f</mi></msub></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">f</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo></mtd></mtr><mtr><mtd><mo>〈</mo><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">X</mi></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi mathvariant="bold-italic">E</mi><mo>〉</mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>β</mi><msub><mrow></mrow><mi mathvariant="bold-italic">X</mi></msub></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中:<i>λ</i><sub><b><i>f</i></b></sub>、<i>λ</i><sub><b><i>X</i></b></sub>为拉格朗日乘子, <i>β</i><sub><b><i>f</i></b></sub>和<i>β</i><sub><b><i>X</i></b></sub>为惩罚参数。为求解式 (9) , 利用交替方向乘子法 (Alternating Direction Multiplier Method, ADMM) <citation id="222" type="reference"><link href="197" rel="bibliography" /><link href="199" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>对其进行变量分离, 式 (9) 可转换为如下子问题, 迭代初始时, 令<b><i>X</i></b><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>0</mn></msubsup></mrow></math></mathml>=<b><i>X</i></b><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>0</mn></msubsup></mrow></math></mathml>=<b><i>E</i></b><sup>0</sup>=0, 迭代次数<i>k</i>=0。</p>
                </div>
                <div class="p1">
                    <p id="99">1) 固定其他参数, 更新<b><i>X</i></b><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>, 则其更新表达式可写为:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mtext>S</mtext><mtext>p</mtext></mrow><mi>p</mi></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mfrac><mrow><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">根据文献<citation id="223" type="reference">[<a class="sup">4</a>]</citation>可知, 通过广义软阈值 (Generalized Soft-Thresholding, GST) 算法<citation id="224" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>可求解式 (10) 。</p>
                </div>
                <div class="p1">
                    <p id="103">2) 固定其他参数, 更新<b><i>E</i></b><sup><i>k</i>+1</sup>, 则其可通过式 (11) 求得:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mfrac><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup><mo>-</mo><mfrac><mrow><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow></mfrac><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">3) 固定其他参数, 更新<b><i>X</i></b><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>, 则其更新表达式可写为:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false"> (</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup><mi>Ι</mi><mo>+</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup><mi mathvariant="bold-italic">D</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">D</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mi>Q</mi></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi>r</mi><mi>e</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中:<i>Q</i>= <i>β</i><sup><i>k</i></sup><sub><b><i>X</i></b></sub>Vec (<b><i>X</i></b>-<b><i>X</i></b><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>-<b><i>E</i></b><sup><i>k</i>+1</sup>) -<i>λ</i><sup><i>k</i></sup><sub><b><i>X</i></b></sub>+<b><i>D</i></b><sup>T</sup> (<i>β</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub><b><i>f</i></b><sup><i>k</i></sup>-<i>λ</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub>) ;<i>reshape</i> (·) 表示将向量<b><i>x</i></b><sub>2</sub>调整其为3D形式。由于矩阵在算子<b><i>D</i></b><sup>T</sup><b><i>D</i></b>下的块循环, 解可以通过3D FFT (Fast Fourier Transform) 求得<citation id="225" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。因此<b><i>x</i></b><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>可以计算为:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>i</mi><mi>f</mi><mi>f</mi><mi>t</mi><mi>n</mi><mo stretchy="false"> (</mo><mfrac><mrow><mi>f</mi><mi>f</mi><mi>t</mi><mi>n</mi><mo stretchy="false"> (</mo><mi>Q</mi><mo stretchy="false">) </mo></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup><mi>Ι</mi><mo>+</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>f</mi><mi>f</mi><mi>t</mi><mi>n</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo>|</mo><mrow><mi>f</mi><mi>f</mi><mi>t</mi><mi>n</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo>|</mo><mrow><mi>f</mi><mi>f</mi><mi>t</mi><mi>n</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow></mfrac><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">其中: <i>fftn</i>和<i>ifftn</i>分别表示3D傅里叶变换和它的逆变换;<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow></mrow></math></mathml>表示元素的绝对值, 除法为相对应元素之除。注意到公式 (13) 中的各分部可以在外部循环中提前求得, 因此降低了计算复杂度。</p>
                </div>
                <div class="p1">
                    <p id="114">4) 固定其他参数, 更新<b><i>f</i></b><sup><i>k</i>+1</sup>, 则其更新表达式可写为:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi mathvariant="bold-italic">f</mi><mtext> </mtext></mrow><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">f</mi></munder><mspace width="0.25em" /><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mfrac><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">f</mi><mo>-</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>+</mo><mfrac><mrow><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">该子问题可以通过软阈值算子求得:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi mathvariant="bold-italic">f</mi><mtext> </mtext></mrow><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>s</mi><mi>o</mi><mi>l</mi><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>+</mo><mfrac><mrow><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow></mfrac><mo>, </mo><mfrac><mi>λ</mi><mrow><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中:<i>solf</i> (<i>a</i>, <i>τ</i>) :=sgn (<i>a</i>) ·max (|<i>a</i>|-<i>τ</i>, 0) <citation id="226" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 根据实验, <i>λ</i>取值范围为[0.01, 0.1]。</p>
                </div>
                <div class="p1">
                    <p id="119">5) 更新乘子<i>λ</i><sup><i>k</i>+1</sup><sub><b><i>f</i></b></sub>、<i>λ</i><sup><i>k</i>+1</sup><sub><b><i>X</i></b></sub>:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup><mo>-</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mi>k</mi></msubsup><mo stretchy="false"> (</mo><mrow><mi mathvariant="bold-italic">f</mi><mtext> </mtext></mrow><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup><mo>-</mo><mi>β</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">X</mi><mi>k</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">其中:惩罚参数<i>β</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub>、 <i>β</i><sup><i>k</i></sup><sub><b><i>X</i></b></sub>遵循自适应更新的机制。以<i>β</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub>为例, 令<i>Res</i>=‖<b><i>f</i></b><sup><i>k</i></sup>-<b><i>Dx</i></b><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup></mrow></math></mathml>‖, <i>Res</i><sub>pre</sub>为最后一次迭代的值, <i>β</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub>初始值设为<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mn>1</mn><mn>0</mn><msup><mrow></mrow><mrow><mo>-</mo><mn>5</mn></mrow></msup></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>n</mtext><mo stretchy="false"> (</mo><mtext>a</mtext><mtext>b</mtext><mtext>s</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, 则其更新机制为:</p>
                </div>
                <div class="p1">
                    <p id="124"><i>β</i><sup><i>k</i>+1</sup><sub><b><i>f</i></b></sub>=<i>c</i><sub>1</sub>·<i>β</i><sup><i>k</i></sup><sub><b><i>f</i></b></sub>; <i>Res</i>&gt;<i>c</i><sub>2</sub>·<i>Res</i><sub>pre</sub>      (17) </p>
                </div>
                <div class="p1">
                    <p id="125">其中:<i>c</i><sub>1</sub>和<i>c</i><sub>2</sub>可以分别取为1.15和0.95<citation id="227" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <h3 id="126" name="126" class="anchor-tag">4 实验与结果分析</h3>
                <h4 class="anchor-tag" id="127" name="127">4.1 <b>仿真实验</b></h4>
                <div class="p1">
                    <p id="128">为验证本文算法的性能, 从<i>CD</i>.<i>net</i>测试数据集<citation id="228" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>中选取5组128×128×128的视频序列<i>Fall</i>、<i>Overpass</i>、<i>Fountain</i>02、<i>Blizzard</i>、<i>SnowFall</i>进行测试, 并在相同条件下与<i>HoRPCA</i><citation id="229" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、<i>RPCA</i><citation id="230" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、 <i>FRMC</i><citation id="231" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>和<i>TRPCA</i>算法<citation id="232" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>从主观和客观两方面进行比较。所有实验的运行环境为<i>Matlab</i> 2014<i>a</i>, <i>Inter Core i</i>5-6500处理器, 8 <i>GB</i>的内存, <i>Windows</i> 10 64位操作系统。得到的视觉实验结果如图1～2所示。</p>
                </div>
                <div class="p1">
                    <p id="129">从图1～2可看出, 视频<i>Fall</i>和<i>Overpass</i>为背景中有树叶大幅度晃动的场景;<i>Fountain</i>02中有动态喷泉遮挡且检测目标离监控摄像机较远;<i>Blizzard</i>和<i>SnowFall</i>为雨雪天气, 覆盖的白雪使得前背景分离变得困难, 而飘落的雪花也易被检测为运动目标。选取的5组实验视频均为生活中常见的复杂场景。</p>
                </div>
                <div class="p1">
                    <p id="130">分析比较可知, 在图1中, <i>HoRPCA</i>提取的运动目标受动态背景干扰较大, 提取的前景目标中含有的动态背景部分是最多的;<i>RPCA</i>和<i>TRPCA</i>提取前景精确度较差, 运动目标中存在的空洞现象最为严重;<i>FRMC</i>与本文算法提取的运动目标都较为完整, 但本文算法对动态背景的干扰去除更为明显, 同时提取的运动目标精确度较高, 整体取得最佳的检测效果。</p>
                </div>
                <div class="p1">
                    <p id="131">图2给出了3段不同帧的<i>SnowFall</i>视频测试, 从中可看出:<i>HoRPCA</i>、<i>RPCA</i>与<i>TRPCA</i>将飘落的雪花误判为运动前景, 使得背景中存在较多的噪点, 同时由于白雪的覆盖降低了前背景区分度, 使得提取的目标也较为空洞;<i>FRMC</i>模型有效降低了飘落的雪花造成的误判, 但却将邻近背景错分为运动区域而降低了前景目标的提取精度;本文算法在整个视频处理中较好地分离出前景与背景, 去除了动态背景产生的噪声, 提高了前景运动目标的提取精确度。</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904038_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同算法针对不同视频序列的实验结果比较" src="Detail/GetImg?filename=images/JSJY201904038_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 不同算法针对不同视频序列的实验结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904038_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Experimental results comparison with different video sequences among different algorithms</i></p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904038_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同帧下不同算法的实验结果比较 (SnowFall视频序列)" src="Detail/GetImg?filename=images/JSJY201904038_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同帧下不同算法的实验结果比较 (<i>SnowFall</i>视频序列)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904038_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Experimental results comparison with different frame among different algorithms</i> (<i>SnowFall video sequences</i>) </p>

                </div>
                <h4 class="anchor-tag" id="134" name="134">4.2 <b>量化对比以及结果分析</b></h4>
                <div class="p1">
                    <p id="135">在客观上为了更准确地评估算法之间的性能, 本文参考文献<citation id="233" type="reference">[<a class="sup">17</a>,<a class="sup">18</a>]</citation>, 用三种客观指标:查全率、查准率, 以及它们的综合评价指标<i>F</i>-<i>measure</i>来评价视频前景检测的效果。查全率和查准率的定义分别为:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mtext>查</mtext><mtext>全</mtext><mtext>率</mtext><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>n</mi></mrow></mfrac></mtd></mtr><mtr><mtd><mtext>查</mtext><mtext>准</mtext><mtext>率</mtext><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>p</mi></mrow></mfrac></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">其中:<i>tp</i>表示检测出的正确前景像素点; <i>fn</i>表示错检为背景的前景像素点; <i>fp</i>表示错检为前景的背景像素点。由于查全率只能反映丢失运动目标的内部信息的相关性, 查准率只能反映丢失目标外部信息的相关性, 且两者指标值有时会出现矛盾的情况, 因此采用它们的调和平均值<i>F</i>-<i>measure</i>来综合判断提取效果:</p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>s</mi><mi>u</mi><mi>r</mi><mi>e</mi><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mtable columnalign="left"><mtr><mtd><mtext>查</mtext><mtext>准</mtext><mtext>率</mtext><mo>×</mo><mtext>查</mtext><mtext>全</mtext><mtext>率</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>查</mtext><mtext>准</mtext><mtext>率</mtext><mo>+</mo><mtext>查</mtext><mtext>全</mtext><mtext>率</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139">所有的评价指标都在0～1, 且指标值越高, 得到的结果越精确。</p>
                </div>
                <div class="p1">
                    <p id="140">本文算法和其他4种对比算法进行实验, 得出的相关指标如图3～4和表1所示。图3和图4分别选取视频Fall和</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Fall视频序列代表帧在不同算法下的客观指标对比" src="Detail/GetImg?filename=images/JSJY201904038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Fall视频序列代表帧在不同算法下的客观指标对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Comparison of objective indicator values on Fall video sequence by different algorithms</p>

                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904038_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Fall视频序列代表帧在不同算法下的客观指标对比" src="Detail/GetImg?filename=images/JSJY201904038_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Fall视频序列代表帧在不同算法下的客观指标对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904038_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison of objective indicator on Blizzard video sequence by different algorithms</p>

                </div>
                <div class="p1">
                    <p id="143">视频Blizzard中12个代表帧, 每个相隔8帧, 计算各个代表帧的查全率、查准率和综合指标<i>F</i>-<i>measure</i>值。由图3 (a) 可看出, 本文算法的查全率与FRMC大致相同, 但远远高于其他3种算法;图3 (b) 中FRMC和HoRPCA的查准率低于本文算法, RPCA与TRPCA的查准率稍高于本文算法;由图3 (c) 可看出本文算法的综合指标<i>F</i>-<i>measure</i>值均高于其他算法。从图4 (b) 可看出除HoRPCA的查准率较低以外, 其他算法查准率相差不大, 但从图4 (a) 、 (c) 中看出本文算法的查全率和<i>F</i>-<i>measure</i>值均高于其他算法。因此本文算法的综合检测效果最好。</p>
                </div>
                <div class="p1">
                    <p id="144">表1中给出5个视频的查全率、查准率、<i>F</i>-<i>measure</i>和平均每帧的运行时间。可看出, 本文算法的查全率均处于次优, 查准率 (除Blizzard处于次优外) 和<i>F</i>-<i>measure</i>均处于最优。说明本文算法在抑制动态背景产生的噪声以及目标提取的完整度和精确度方面的综合效果较好;但是由于本文模型在计算中较为耗时, 因此在耗时方面仅低于HoRPCA算法。</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表</b>1 <b>不同算法前景检测客观结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Comparison of foreground detection objective results among different algorithms</p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />视频名称</td><td>算法</td><td>查全率</td><td>查准率</td><td><i>F</i>-<i>measure</i></td><td>每帧耗时/s</td></tr><tr><td rowspan="5"><br />Fall</td><td>HoRPCA</td><td>0.761</td><td>0.430</td><td>0.550</td><td>5.48</td></tr><tr><td><br />RPCA</td><td>0.591</td><td>0.590</td><td>0.591</td><td><u>0.02</u></td></tr><tr><td><br />FRMC</td><td><b>0.895</b></td><td>0.570</td><td><u>0.696</u></td><td><b>0.01</b></td></tr><tr><td><br />TRPCA</td><td>0.512</td><td><u>0.743</u></td><td>0.606</td><td>0.71</td></tr><tr><td><br />本文算法</td><td><u>0.867</u></td><td><b>0.934</b></td><td><b>0.899</b></td><td>2.51</td></tr><tr><td rowspan="5"><br />Overpass</td><td><br />HoRPCA</td><td>0.290</td><td>0.612</td><td>0.393</td><td>5.74</td></tr><tr><td><br />RPCA</td><td>0.246</td><td>0.824</td><td>0.379</td><td><u>0.02</u></td></tr><tr><td><br />FRMC</td><td><b>0.604</b></td><td><u>0.860</u></td><td><u>0.709</u></td><td><b>0.01</b></td></tr><tr><td><br />TRPCA</td><td>0.224</td><td>0.829</td><td>0.353</td><td>0.67</td></tr><tr><td><br />本文算法</td><td><u>0.588</u></td><td><b>0.919</b></td><td><b>0.717</b></td><td>2.73</td></tr><tr><td rowspan="5"><br />Fountain02</td><td><br />HoRPCA</td><td><b>0.750</b></td><td>0.682</td><td>0.714</td><td>4.51</td></tr><tr><td><br />RPCA</td><td>0.686</td><td>0.839</td><td>0.755</td><td><u>0.02</u></td></tr><tr><td><br />FRMC</td><td>0.727</td><td><u>0.994</u></td><td><u>0.840</u></td><td><b>0.01</b></td></tr><tr><td><br />TRPCA</td><td>0.491</td><td>0.964</td><td>0.651</td><td>0.67</td></tr><tr><td><br />本文算法</td><td><u>0.746</u></td><td><b>1.000</b></td><td><b>0.854</b></td><td>2.33</td></tr><tr><td rowspan="5"><br />Blizzard</td><td><br />HoRPCA</td><td>0.401</td><td>0.625</td><td>0.489</td><td>3.26</td></tr><tr><td><br />RPCA</td><td>0.392</td><td>0.903</td><td>0.547</td><td><u>0.02</u></td></tr><tr><td><br />FRMC</td><td><b>0.526</b></td><td>0.684</td><td><u>0.595</u></td><td><b>0.01</b></td></tr><tr><td><br />TRPCA</td><td>0.243</td><td><b>0.948</b></td><td>0.387</td><td>0.68</td></tr><tr><td><br />本文算法</td><td><u>0.490</u></td><td><u>0.894</u></td><td><b>0.633</b></td><td>2.03</td></tr><tr><td rowspan="5"><br />SnowFall</td><td><br />HoRPCA</td><td>0.369</td><td>0.656</td><td>0.473</td><td>4.18</td></tr><tr><td><br />RPCA</td><td>0.438</td><td>0.724</td><td>0.545</td><td><u>0.02</u></td></tr><tr><td><br />FRMC</td><td><b>0.659</b></td><td>0.703</td><td><u>0.680</u></td><td><b>0.01</b></td></tr><tr><td><br />TRPCA</td><td>0.342</td><td><u>0.768</u></td><td>0.473</td><td>0.71</td></tr><tr><td><br />本文算法</td><td><u>0.653</u></td><td><b>0.874</b></td><td><b>0.748</b></td><td>2.18</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:加粗部分为最优值, 加下划线部分为次优值。</p>
                    <p class="img_note"></p>
                </div>
                <h3 id="146" name="146" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="147">本文提出一种结合加权Schatten-<i>p</i>范数与3D全变分的视频前景检测模型。该模型以RPCA理论为基础, 用加权Schatten-<i>p</i>范数替代秩函数对视频背景作低秩约束, 又利用全变分正则项约束运动目标在时间和空间上的连续性, 有效地抑制由动态背景造成的随机扰动, 降低了背景误判, 提高了前景检测的精确度。实验结果表明, 与经典算法以及目前最新算法相比, 本文算法的性能从主观和客观两方面都显示出不同程度的优势, 可以达到预期的检测效果;但在总耗时的问题上, 本文算法需要进一步提升。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="173">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700238312&amp;v=MzE1MjdRVE1ud1plWnRGaW5sVXIzSUtGb1hhUkU9TmlmT2ZiSzhIdGZOcUk5Rlp1Z0hEMzA3b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>BOUWMANS T, ZAHZAH E H.Robust PCA via principal component pursuit:a review for a comparative evaluation in video surveillance[J].Computer Vision and Image Understanding, 2014, 122:22-34.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM59B372F9DC8CB6FC5F5D7668E983E196&amp;v=MDE5NTUvdVdVV25Eb0pUM25rcEdjOGNiSGhSTE9aQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoekx5OHc2cz1OaWZJWTdheGJOTExyZmxNRUpnSGZ3NA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>ZHOU X, YANG C, ZHAO H, et al.Low-rank modeling and its applications in image analysis[J].ACM Computing Surveys, 2014, 47 (2) :1-33.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Background subtraction via fast robust matrix completion">

                                <b>[3]</b>REZAEI B, OSTADABBAS S.Background subtraction via fast robust matrix completion[C]//Proceeding of the 2017 IEEE International Conference on Computer Vision Workshop.Piscataway, NJ:IEEE, 2017:1871-1879.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weighted schatten p-norm minimization for image denoising and background subtraction">

                                <b>[4]</b>XIE Y, GU S, LIU Y, et al.Weighted Schatten p-Norm minimization for image denoising and background subtraction[J].IEEETransactions on Image Processing, 2016, 25 (10) :4842-4 857.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor robust principal component analysis with a new tensor nuclear norm">

                                <b>[5]</b>LU C, FENG J, CHEN Y, et al.Tensor robust principal component analysis with a new tensor nuclear norm[EB/OL].[2018-05-10].http://adsabs.harvard.edu/abs/2018ar Xiv180403728L.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust low-rank tesnor recovery:Models and algorithms">

                                <b>[6]</b>GOLDFARB D, QIN Z.Robust low-rank tensor recovery:models and algorithms[J].SIAM Journal on Matrix Analysis&amp;Applications, 2013, 35 (1) :225-253.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incremental learning with saliency map for moving object detection">

                                <b>[7]</b>PANG Y, YE L, LI X, et al.Incremental learning with saliency map for moving object detection[J].IEEE Transactions on Circuits and Systems for Video Technology, 2018, 28 (3) :640-651.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Foreground segmentation with treestructured sparse RPCA">

                                <b>[8]</b>EBADI S E, IZQUIERDO E.Foreground segmentation with treestructured sparse RPCA[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (9) :2273-2280.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Background estimation and motion saliency detection using total variation-based video decomposition">

                                <b>[9]</b>BHATTACHARYA S, VENKATSH K S, GUPTA S.Background estimation and motion saliency detection using total variation-based video decomposition[J].Signal, Image and Video Processing, 2017, 11 (1) :113-121.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Total variation regularized RPCA for irregularly moving object detection under dynamic background">

                                <b>[10]</b>CAO X, YANG L, GUO X.Total variation regularized RPCA for irregularly moving object detection under dynamic background[J].IEEE Transactions on Cybernetics, 2017, 46 (4) :1014-1027.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Augmented Lagrangian Method for Total Variation Video Restoration">

                                <b>[11]</b>CHAN S H, KHOSHABEH R, GIBSON K B, et al.An augmented lagrangian method for total variation video restoration[J].IEEETransactions on Image Processing, 2011, 20 (11) :3097-3111.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Total Variation Regularized Tensor RPC A for Background Subtraction From Compressive Measurements">

                                <b>[12]</b>CAO W, WANG Y, SUN J, et al.Total variation regularized tensor RPCA for background subtraction from compressive measurements[J].IEEE Transactions on Image Processing, 2016, 25 (9) :4075-4090.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed optimization and statistical learning via the alternating direction method of multipliers">

                                <b>[13]</b>BOYD S, PARIKH N, CHU E, et al.Distributed optimization and statistical learning via the alternating direction method of multipliers[J].Foundations and Trends in Machine Learning, 2011, 3 (1) :1-122.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the global and linear convergence of the generalized alternating direction method of multipliers">

                                <b>[14]</b>DENG W, YIN W.On the global and linear convergence of the generalized alternating direction method of multipliers[J].Journal of Scientific Computing, 2016, 66 (3) :889-916.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A generalized iterated shrinkage algorithm for non-convex sparse coding">

                                <b>[15]</b>ZUO W, MENG D, ZHANG L, et al.A generalized iterated shrinkage algorithm for non-convex sparse coding[C]//Proceedings of the IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2013:217-224.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CDnet 2014:An expanded change detection benchmark dataset">

                                <b>[16]</b>WANG Y, JODOIN P M, PORIKLI F, et al.CDnet 2014:an expanded change detection benchmark dataset[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington, DC:IEEE Computer Society, 2014:387-394.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201709031&amp;v=MDExMjFyQ1VSN3FmWnVac0Z5RGhVTHpMSVRmVGU3RzRIOWJNcG85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>常侃, 张智勇, 陈诚, 等.采用低秩与加权稀疏分解的视频前景检测算法[J].电子学报, 2017, 45 (9) :2272-2280. (CHANG K, ZHANG Z Y, CHEN C, et al.Video foreground detection by low-rank and reweighted sparse decomposition[J].Acta Electronica Sinica, 2017, 45 (9) :2272-2280.) 
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201706045&amp;v=MTMxODU3cWZadVpzRnlEaFVMekxMejdCZDdHNEg5Yk1xWTlCWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>刘仲民, 何胜皎, 胡文瑾, 等.基于背景减除法的视频序列运动目标检测[J].计算机应用, 2017, 37 (6) :1777-1781. (LIU Z M, HE S J, HU W J, et al.Moving object detection based on background subtraction for video sequence[J].Journal of Computer Applications, 2017, 37 (6) :1777-1781.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904038" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904038&amp;v=MjYwMjZxZlp1WnNGeURoVUx6TEx6N0JkN0c0SDlqTXE0OUdiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
