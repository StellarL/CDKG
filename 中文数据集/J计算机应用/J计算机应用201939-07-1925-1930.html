<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136662014846250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907010%26RESULT%3d1%26SIGN%3d9PR%252fop72Up7EWGtXmWuodYmlDbA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907010&amp;v=MDcwMDdmWnVac0Z5L25WTHJQTHo3QmQ3RzRIOWpNcUk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#61" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="2 基于层次注意力机制的神经网络模型 ">2 基于层次注意力机制的神经网络模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="2.1 &lt;b&gt;总体框架&lt;/b&gt;">2.1 <b>总体框架</b></a></li>
                                                <li><a href="#75" data-title="2.2 &lt;b&gt;长短期记忆网络&lt;/b&gt;">2.2 <b>长短期记忆网络</b></a></li>
                                                <li><a href="#84" data-title="2.3 &lt;b&gt;用户注意力机制&lt;/b&gt;">2.3 <b>用户注意力机制</b></a></li>
                                                <li><a href="#118" data-title="2.4 &lt;b&gt;产品注意力机制&lt;/b&gt;">2.4 <b>产品注意力机制</b></a></li>
                                                <li><a href="#127" data-title="2.5 &lt;b&gt;文档表示&lt;/b&gt;">2.5 <b>文档表示</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="3 实验设置 ">3 实验设置</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#144" data-title="3.1 &lt;b&gt;数据集&lt;/b&gt;">3.1 <b>数据集</b></a></li>
                                                <li><a href="#148" data-title="3.2 &lt;b&gt;超参数&lt;/b&gt;">3.2 <b>超参数</b></a></li>
                                                <li><a href="#150" data-title="3.3 &lt;b&gt;基准模型&lt;/b&gt;">3.3 <b>基准模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#155" data-title="4 实验结果 ">4 实验结果</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#156" data-title="4.1 &lt;b&gt;结果比较&lt;/b&gt;">4.1 <b>结果比较</b></a></li>
                                                <li><a href="#159" data-title="4.2 &lt;b&gt;模型分析&lt;/b&gt;">4.2 <b>模型分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#175" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="图1 所提模型的整体框架">图1 所提模型的整体框架</a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;数据集的统计信息&lt;/b&gt;"><b>表</b>1 <b>数据集的统计信息</b></a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同模型的准确率对比&lt;/b&gt;"><b>表</b>2 <b>不同模型的准确率对比</b></a></li>
                                                <li><a href="#166" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同模型的评价指标对比&lt;/b&gt;"><b>表</b>3 <b>不同模型的评价指标对比</b></a></li>
                                                <li><a href="#167" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;不同加权损失的影响&lt;/b&gt;"><b>表</b>4 <b>不同加权损失的影响</b></a></li>
                                                <li><a href="#171" data-title="图2 单词级别的用户和产品注意力可视化">图2 单词级别的用户和产品注意力可视化</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="211">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     OTT M, CHOI Y, CARDIE C, et al.Finding deceptive opinion spam by any stretch of the imagination [C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2011:309-319.</a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     JINDAL N, LIU B.Opinion spam and analysis [C]// Proceedings of the 2008 International Conference on Web Search and Data Mining.New York:ACM, 2008:219-230.</a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     REN Y F, ZHANG Y.Deceptive opinion spam detection using neural network [C]// COLING 2016:Proceedings of the 26th International Conference on Computational Linguistics:Technical Papers.Osaka, Japan:COLING, 2016:140-150.</a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                     YOO K H, GRETZEL U.Comparison of deceptive and truthful travel reviews [C]// Proceedings of the 2009 International Conference on Information and Communication Technologies.Berlin:Springer, 2009:37-47.</a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     FENG S, BANERJEE R, CHOI Y.Syntactic stylometry for deception detection [C]// Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:Short Papers-Volume 2.Stroudsburg, PA:Association for Computational Linguistics, 2012:171-175.</a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     FENG V W, HIRST G.Detecting deceptive opinions with profile compatibility [C]// Proceedings of the 6th International Joint Conference on Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:338-346.</a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     MUKHERJEE A, VENKATARAMAN V, LIU B, et al.Fake review detection:classification and analysis of real and pseudo reviews [R].Chicago:University of Illinois, Department of Computer Science, 2013:3.</a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     MUKHERJEE A, KUMAR A, LIU B, et al.Spotting opinion spammers using behavioral footprints [C]// Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2013:632-640.</a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     QIAN T Y, LIU B.Identifying multiple userids of the same author [C]// Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:1124-1135.</a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_10" title=" 任亚峰, 姬东鸿, 尹兰.基于半监督学习算法的虚假评论识别研究[J].计算机科学与探索, 2014, 46 (3) :62-69. (REN Y F, JI D H, YIN L.Deceptive reviews detection based on semi-supervised learning algorithm [J].Advanced Engineering Sciences, 2014, 46 (3) :62-69.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201403010&amp;v=MDk3NTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHJQTmk3SFpyRzRIOVhNckk5RVpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         任亚峰, 姬东鸿, 尹兰.基于半监督学习算法的虚假评论识别研究[J].计算机科学与探索, 2014, 46 (3) :62-69. (REN Y F, JI D H, YIN L.Deceptive reviews detection based on semi-supervised learning algorithm [J].Advanced Engineering Sciences, 2014, 46 (3) :62-69.) 
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     ROUT J K, SINGH S, JENA S K, et al.Deceptive review detection using labeled and unlabeled data [J].Multimedia Tools and Applications, 2017, 76 (3) :1-25.</a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_12" title=" REN Y F, JI D H, YIN L, et al.Finding deceptive opinion spam by correcting the mislabeled instances [J].Chinese Journal of Electronics, 2015, 24 (1) :52-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=EDZX201501009&amp;v=MTkxMTlHRnJDVVI3cWZadVpzRnkvblZMclBJQ25SZHJHNEg5VE1ybzlGYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         REN Y F, JI D H, YIN L, et al.Finding deceptive opinion spam by correcting the mislabeled instances [J].Chinese Journal of Electronics, 2015, 24 (1) :52-57.
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     KIM S, CHANG H, LEE S, et al.Deep semantic frame-based deceptive opinion spam analysis [C]// Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.New York:ACM, 2015:1131-1140.</a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     WANG X P, LIU K, HE S Z, et al.Learning to represent review with tensor decomposition for spam detection [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:866-875.</a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_15" title=" 任亚峰, 尹兰, 姬东鸿.基于语言结构和情感极性的虚假评论识别[J].计算机科学与探索, 2014, 8 (3) :313-320. (REN Y F, YIN L, JI D H.Deceptive reviews detection based on language structure and sentiment polarity [J].Journal of Frontiers of Computer Science and Technology, 2014, 8 (3) :313-320.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201403007&amp;v=MDc4MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkxyUExqWGZmYkc0SDlYTXJJOUZZNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         任亚峰, 尹兰, 姬东鸿.基于语言结构和情感极性的虚假评论识别[J].计算机科学与探索, 2014, 8 (3) :313-320. (REN Y F, YIN L, JI D H.Deceptive reviews detection based on language structure and sentiment polarity [J].Journal of Frontiers of Computer Science and Technology, 2014, 8 (3) :313-320.) 
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_16" title=" ZHANG W, DU Y H, YOSHIDA T, et al.DRI-RCNN:an approach to deceptive review identification using recurrent convolutional neural network [J].Information Processing and Management, 2018, 54 (4) :576-592." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEDA6628822F5E0C0AB475577E7541A2C&amp;v=MjgyMDBDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3E0eGE4PU5pZk9mY2JNYjlmS3JZZE5adWw1Q1FrNXZCWmltRHQ2VFhybHEyY3lmTGFWTkxqcw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         ZHANG W, DU Y H, YOSHIDA T, et al.DRI-RCNN:an approach to deceptive review identification using recurrent convolutional neural network [J].Information Processing and Management, 2018, 54 (4) :576-592.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_17" title=" NOEKHAH S, SALIM N B, ZAKARIA N H.A novel model for opinion spam detection based on multi-iteration network structure [J].Advanced Science Letters, 2018, 24 (2) :1437-1442." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH70B4AD5E7498F090DD9ADE5DF39B6314&amp;v=MTE1NDhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3E0eGE4PU5pZktaclM0Yk5XOTI0b3dZKzhHQkFvNXhoWm5uallNUEFybjJHUTJjTUNTUnJ1Yg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         NOEKHAH S, SALIM N B, ZAKARIA N H.A novel model for opinion spam detection based on multi-iteration network structure [J].Advanced Science Letters, 2018, 24 (2) :1437-1442.
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     REN Y F, ZHANG Y, ZHANG M S, et al.Context-sensitive twitter sentiment classification using neural network [C]// Proceedings of the 13th AAAI Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2016:215-221.</a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     REN Y F, ZHANG Y, ZHANG M S, et al.Improving twitter sentiment classification using topic-enriched multi-prototype word embeddings [C]// Proceedings of the 13th AAAI Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2016:3038-3044.</a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     YESSENALI A A, CARDIE C.Compositional matrix-space models for sentiment analysis [C]// Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2011:172-182.</a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_21" >
                                        <b>[21]</b>
                                     LE Q, MIKOLOV T.Distributed representations of sentences and documents [J].Journal of Machine Learning Research, 2014, 32 (2) :1188-1196.</a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     SOCHER R, PERELYGIN A, WU J, et al.Recursive deep models for semantic compositionality over a sentiment treebank [C]// Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:1631-1642.</a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                     JOHNSON R, ZHANG T.Effective use of word order for text categorization with convolutional neural networks [C]// Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2015:103-112.</a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_24" >
                                        <b>[24]</b>
                                     LI J W, LUONG M T, JURAFSKY D, et al.When are tree structures necessary for deep learning of representations [EB/OL].[2017- 08- 04].http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP278.pdf.</a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_25" >
                                        <b>[25]</b>
                                     BAHDANAU D, CHO K, BENGIO Y.Neural machine translation by jointly learning to align and translate [EB/OL].[2017- 10- 20].https://arxiv.org/abs/1409.0473.</a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_26" >
                                        <b>[26]</b>
                                     YANG Z C, YANG D Y, DYER C, et al.Hierarchical attention networks for document classification [C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2016:1480-1489.</a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_27" >
                                        <b>[27]</b>
                                     CHEN H M, SUN M S, TU C C, et al.Neural sentiment classification with user and product attention [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:1650-1659.</a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_28" >
                                        <b>[28]</b>
                                     MUKHERJEE A, VENKATARAMAN V, LIU B, et al.What yelp fake review filter might be doing [C]// Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media.Menlo Park, CA:AAAI, 2013:409-418.</a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_29" >
                                        <b>[29]</b>
                                     RAYANA S, AKOGLU L.Collective opinion spam detection:bridging review networks and metadata [C]// Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2015:985-994.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-02-28 15:45</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),1925-1930 DOI:10.11772/j.issn.1001-9081.2018112340            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于层次注意力机制神经网络模型的虚假评论识别</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A2%9C%E6%A2%A6%E9%A6%99&amp;code=42202186&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜梦香</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%AC%E4%B8%9C%E9%B8%BF&amp;code=09004523&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姬东鸿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%BB%E4%BA%9A%E5%B3%B0&amp;code=40731609&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">任亚峰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6%E5%9B%BD%E5%AE%B6%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0009404&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉大学国家网络安全学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%A4%96%E8%AF%AD%E5%A4%96%E8%B4%B8%E5%A4%A7%E5%AD%A6%E5%A4%96%E8%AF%AD%E7%A0%94%E7%A9%B6%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%9C%8D%E5%8A%A1%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=0090875&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东外语外贸大学外语研究与语言服务协同创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对虚假评论识别任务中传统离散模型难以捕捉到整个评论文本的全局语义信息的问题, 提出了一种基于层次注意力机制的神经网络模型。首先, 采用不同的神经网络模型对评论文本的篇章结构进行建模, 探讨哪种神经网络模型能够获得最好的篇章表示;然后, 基于用户视图和产品视图的两种注意力机制对评论文本进行建模, 用户视图关注评论文本中用户的偏好, 而产品视图关注评论文本中产品的特征;最后, 将两个视图学习的评论表示拼接以作为预测虚假评论的最终表示。以准确率作为评估指标, 在Yelp数据集上进行了实验。实验结果表明, 所提出的层次注意力机制的神经网络模型表现最好, 其准确率超出了传统离散模型和现有的神经网络基准模型1至4个百分点。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%99%9A%E5%81%87%E8%AF%84%E8%AE%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">虚假评论;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A6%BB%E6%95%A3%E7%89%B9%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">离散特性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    颜梦香 (1993—) , 女, 湖北孝感人, 硕士研究生, 主要研究方向:自然语言处理;;
                                </span>
                                <span>
                                    姬东鸿 (1967—) , 男, 河南驻马店人, 教授, 博士生导师, 博士, 主要研究方向:自然语言处理、机器学习、数据挖掘;;
                                </span>
                                <span>
                                    *任亚峰 (1986—) , 男, 河南焦作人, 副研究员, 博士, 主要研究方向:自然语言处理、机器学习。电子邮箱tengchong@whu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61702121, 61772378);</span>
                    </p>
            </div>
                    <h1><b>Deceptive review detection via hierarchical neural network model with attention mechanism</b></h1>
                    <h2>
                    <span>YAN Mengxiang</span>
                    <span>JI Donghong</span>
                    <span>REN Yafeng</span>
            </h2>
                    <h2>
                    <span>School of Cyber Science and Engineering, Wuhan University</span>
                    <span>Collaborative Innovation Center for Language Research and Service, Guangdong University of Foreign Studies</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Concerning the problem that traditional discrete models fail to capture global semantic information of whole comment text in deceptive review detection, a hierarchical neural network model with attention mechanism was proposed. Firstly, different neural network models were adopted to model the structure of text, and which model was able to obtain the best semantic representation was discussed. Then, the review was modeled by two attention mechanisms respectively based on user view and product view. The user view focused on the user's preferences in comment text and the product view focused on the product feature in comment text. Finally, two representations learned from user and product views were combined as final semantic representation for deceptive review detection. The experiments were carried out on Yelp dataset with accuracy as the evaluation indicator. The experimental results show that the proposed hierarchical neural network model with attention mechanism performs the best with the accuracy higher than traditional discrete methods and existing neural benchmark models by 1 to 4 percentage points.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attention%20mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attention mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deceptive%20review&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deceptive review;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=discrete%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">discrete feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20Short-Term%20Memory%20(LSTM)%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long Short-Term Memory (LSTM) network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YAN Mengxiang, born in 1993, M. S. candidate. Her research interests include natural language processing. ;
                                </span>
                                <span>
                                    JI Donghong, born in 1967, Ph. D. , professor. His research interests include natural language processing, machine learning, data mining. ;
                                </span>
                                <span>
                                    REN Yafeng, born in 1986, Ph. D. , associate research fellow. His research interests include natural language processing, machine learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-26</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61702121, 61772378);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="61" name="61" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="62">随着电子商务的兴起, 越来越多的个人和商业组织开始阅读和参考在线评论来作出购买决策, 例如, 在哪里住宿, 去哪里就医, 购买哪些产品, 去哪个餐厅, 等等。积极的评论可以为企业和个人带来显著的经济收益和名声, 这为虚假评论的产生提供了强大的动力。在过去几年中, 虚假评论的问题已经变得极为普遍, 新闻中也报道了众多引人注目的案例。许多企业已经开始通过现金、优惠券和促销活动等手段刺激虚假评论的产生, 用以增加销售, 获取经济效益。虚假评论检测是一个紧迫而且重要的话题, 它对于确保网络平台上信息的可信度至关重要, 如果不识别它们, 线上商城就可能成为谎言、假货和欺骗的地方, 因此, 设计有效的模型来自动检测虚假评论是非常必要的。</p>
                </div>
                <div class="p1">
                    <p id="63">虚假评论识别通常被建模为一个文本分类问题<citation id="269" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。基于标记的真实和虚假样例, 利用监督学习来构建分类器, 然后将未标记评论预测为虚假评论或真实评论。现有大多数方法遵循Jindal等<citation id="270" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的开创性工作, 采用全监督学习来构建分类器。这些研究主要侧重于设计有效特征以提高分类性能, 如语言学和心理语言学相关的典型特征, 但未能从全局篇章结构的角度有效地表示文档。例如, Ott等<citation id="271" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>使用了一元词组 (Unigram) 、词性 (Part Of Speech, POS) 和LIWC (Linguistic Inquiry and Word Count) 特征。尽管这些特征给出了良好的性能, 但是它们的稀疏性使得难以在篇章层面捕获全局的语义信息。</p>
                </div>
                <div class="p1">
                    <p id="64">最近, 神经网络模型已被广泛用于自然语言处理 (Natural Language Processing, NLP) 众多任务的语义表示, 并取得优异的性能。神经网络应用在虚假评论检测方面有两点潜在的优势。首先, 神经网络模型使用隐藏层进行自动特征组合, 可以捕获到传统离散特征难以表达的复杂全局语义信息, 这可以解决离散模型的限制;其次, 神经网络模型采用分布式词向量作为输入, 词向量可以从大规模原始文本中训练得到, 从而在一定程度上缓解标注数据的稀缺性。基于这个方向, 一些创新性的工作已经被提出, 例如, Ren等<citation id="272" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出使用神经网络模型来学习评论文本的表示, 用以识别虚假评论。具体的, 他们采用卷积神经网络 (Convolutional Neural Network, CNN) 模型从单词向句子层面建模, 使用长短期记忆 (Long Short-Term Memory, LSTM) 网络模型从句子向文档层面建模, 实验结果证明了所提模型的有效性。</p>
                </div>
                <div class="p1">
                    <p id="65">本文发现, 一个评论文本通常包括两部分信息:一部分信息表达用户的偏好, 另一部分信息表达产品的特性。基于此, 本文探索了一种基于层次注意力机制的神经网络模型, 从用户和产品两个角度来对评论文本进行建模, 并对两部分信息进行整合, 将其用于虚假评论识别任务。基于Yelp数据集的实验证实了所提算法的有效性。同时, 对样例的可视化分析也验证了本文所提方法的有效性和可解释性。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="67">Jindal等<citation id="273" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>最先引入虚假评论识别问题, 他们抽取评论内容、评论者和产品本身的特征来训练模型识别虚假评论;Yoo等<citation id="274" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>收集了40条真实和42条虚假的酒店评论, 并手动比较了它们之间的语言差异;Ott等<citation id="275" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>通过亚马逊众包平台, 雇用Turkers撰写虚假评论构建了一个基准数据集。该数据也被一系列后续研究工作所采用<citation id="279" type="reference"><link href="219" rel="bibliography" /><link href="221" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。例如, Feng等<citation id="276" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>研究了上下文无关语法解析树的语法特征, 以提高识别性能。Feng等<citation id="277" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>从评论集合中建立了酒店简介, 衡量了客户评论与酒店简介的兼容性, 并将其用作虚假评论检测的一个特征。Mukherjee等<citation id="278" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>认为基于众包平台构建的虚假评论跟现实中虚假评论的真实分布存在一定差异, 基于分布更真实的Yelp评论, 他们使用Boolean、词频 (Term Frequency, TF) 、词频-逆文本频率指数 (Term Frequency-Inverse Document Frequency, TF-IDF) 等特征来对虚假评论进行了分类和分析, 由于该数据集中虚假评论的分布更为真实, 后续的一些工作都是基于该数据集进行研究和分析。</p>
                </div>
                <div class="p1">
                    <p id="68">上述工作主要集中于评论文本进行特征建模, 也有工作研究了评论内容本身之外的特征。除了Jindal等<citation id="280" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, Mukherjee等<citation id="281" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>研究了客户行为的特征来识别欺骗。Qian等<citation id="282" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>确定了同一作者生成的多个用户ID, 因为这些作者更有可能产生欺骗性评论。任亚峰等<citation id="283" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和Rout等<citation id="284" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了一种半监督学习方法, 并建立了一个准确的分类器来识别欺骗性评论。此外, Ren等<citation id="285" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了一种新方法, 从纠正错误标记样例的角度发现虚假评论。Kim等<citation id="286" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>引入了基于FrameNet框架的语义特征, 实验结果表明语义框架特征可以提高分类精度。Wang等<citation id="287" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>建议学习评论的表示, 而不是以数据驱动的方式识别欺骗性的垃圾评论。任亚峰等<citation id="288" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>基于遗传算法对评论的语言结构及情感极性特征进行优化选择, 并使用两种简单的聚类方法进行虚假评论识别。Zhang等<citation id="289" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了一种称为递归卷积神经网络识别欺骗性评论 (Deceptive Review Identification by Recurrent Convolutional Neural Network, DRI-RCNN) 的方法, 通过使用单词上下文和深度学习来识别欺骗性评论。最近, Noekhah等<citation id="290" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出了一种新颖的多重迭代网络结构, 该结构考虑了亚马逊上实体之间最有效的特征以及内部和内部关系。不同于这些工作, 本文关注对评论文本内容进行建模, 但上述模型的功能可在本文提出的模型中进行扩展。</p>
                </div>
                <div class="p1">
                    <p id="69">现有方法大多使用传统的离散特征, 这些特征是稀疏的并且不能有效地编码来自整个文档的语义信息。最近, 神经网络模型已被用于各种NLP任务中<citation id="291" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。分布式词表示已被大多数NLP模型用作基本构建块<citation id="292" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。同时, 众多方法已被提出用于学习短语和较大文本片段的表示。例如, Yessenalina等<citation id="293" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>使用迭代矩阵乘法从词表示中学出短语表示。Le等<citation id="294" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>引入段落向量来学习文档表示。Socher等<citation id="295" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>引入了一系列递归神经网络来表示句子级语义组合。后来, 这项工作从不同方面进行了扩展, 其中包含全局反馈机制、深度递归层、特征权重调整、自适应组合函数和组合分类语法。CNN已被广泛用于语义合成<citation id="296" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 自动捕获语法信息。序列模型, 如循环神经网络 (Recurrent Neural Network, RNN) 或LSTM也被用于语义合成<citation id="297" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。同时, 受人类视觉注意的启发, Bahdanau等<citation id="298" type="reference"><link href="259" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>在机器翻译中提出了注意力机制, 将其引入编码器—解码器框架, 以选择目标语言中单词的源语言参考词。它也用于图像标题生成、解析、自然语言问答。此外, Yang等<citation id="299" type="reference"><link href="261" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>和Chen等<citation id="300" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>探索层次注意力机制, 为文档的语义选择信息性词语或句子。</p>
                </div>
                <div class="p1">
                    <p id="70">不同于上述工作, 基于Yelp数据集, 本文提出一种基于层次注意力机制的神经网络模型, 从用户和产品两个角度来对评论文本进行建模, 并将其用于虚假评论识别任务。</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag">2 基于层次注意力机制的神经网络模型</h3>
                <div class="p1">
                    <p id="72">一个评论文本通常包含两种信息:一部分信息表达用户的偏好, 另一部分信息表达产品的特性。如何对这两种信息进行建模, 对学习评论文本的篇章表示至关重要。本文探索了一种基于层次注意力机制的神经网络模型, 从用户和产品两个角度分别对评论文本进行建模, 学习评论文本的篇章表示, 用于识别虚假评论。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.1 <b>总体框架</b></h4>
                <div class="p1">
                    <p id="74">本文所提的模型称为HNNUPA (Hierarchical Neural Network with User and Product Attention) 。如图1所示, 所提框架主要由四部分组成:长短期记忆网络、用户注意力网络、产品注意力网络和篇章表示。首先, 实验地探讨了不同神经网络结构 (CNN、RNN和LSTM) 对评论文本的篇章结构建模, 即哪种神经网络模型能获得最好的篇章表示;然后, 基于用户视图和产品视图的两种注意力机制, 用户视图关注评论文本中用户的偏好, 而产品视图关注评论文本中产品的重要特性;最后, 将两个视图学习的评论表示拼接, 整合两种视图的信息, 作为预测虚假评论的最终表示进行预测。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75">2.2 <b>长短期记忆网络</b></h4>
                <div class="p1">
                    <p id="76">LSTM因其在序列建模方面的出色表现而被广泛用于文本建模。为了解决长距离依赖的问题, LSTM架构引入了能够长时间保持单元状态的存储器单元。具体地, 每个LSTM单元有三个门来保护和控制单元状态, 分别是“遗忘门”“输入门”和“输出门”。在每个时间周期<i>t</i>, 给定输入向量<b><i>x</i></b><sub><i>t</i></sub>, 则当前单元状态<b><i>c</i></b><sub><i>t</i></sub>和隐藏状态<b><i>h</i></b><sub><i>t</i></sub>可由之前的单元状态<b><i>c</i></b><sub><i>t</i>-1</sub>和隐藏状态<b><i>h</i></b><sub><i>t</i>-1</sub>更新如下:</p>
                </div>
                <div class="area_img" id="77">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201907010_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="79"><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math></mathml>;<b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><b><i>c</i></b></sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">这里<b><i>i</i></b><sub><i>t</i></sub>, <b><i>f</i></b><sub><i>t</i></sub>和<b><i>o</i></b><sub><i>t</i></sub>是门激活, <i>σ</i>是sigmoid函数, ⊙代表元素乘法。直观地, 忘记门<b><i>f</i></b><sub><i>t</i></sub>控制前一存储器单元的遗忘程度, 输入门<b><i>i</i></b><sub><i>t</i></sub>控制每个单元的更新程度, 输出门<b><i>o</i></b><sub><i>t</i></sub>控制内部存储器状态的输出。隐藏状态<b><i>h</i></b><sub><i>t</i></sub>表示LSTM单元的内部存储器单元的输出信息。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 所提模型的整体框架" src="Detail/GetImg?filename=images/JSJY201907010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 所提模型的整体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Overall architecture of the proposed model</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84">2.3 <b>用户注意力机制</b></h4>
                <div class="p1">
                    <p id="85">从用户的角度来看, 并非所有单词都能反映用户的偏好或情绪, 为此本文设计用户注意力机制来选取对句子含义有重要意义的用户特定词。形式上, 句子表示<b><i>s</i></b><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow><mi>u</mi></msubsup></mrow></math></mathml>是用户视图中的词级隐藏状态的加权和:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mi>α</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中:<b><i>h</i></b><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>是第<i>i</i>个句子中第<i>j</i>个单词的隐藏状态;<i>α</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>是<b><i>h</i></b><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>的注意力权重, 用于衡量第<i>j</i>个单词对当前用户的重要性。将每个用户<i>u</i>映射到连续的实值向量<b><i>u</i></b>∈<b>R</b><sup><i>d</i><sub><i>u</i></sub></sup>, 其中<i>d</i><sub><i>u</i></sub>表示用户嵌入的维度。具体地, 每个隐藏状态的注意权重<i>α</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>定义为:</p>
                </div>
                <div class="p1">
                    <p id="93"><i>e</i> (<b><i>h</i></b><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>, <b><i>u</i></b>) = (<b><i>v</i></b><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>w</mi><mi>u</mi></msubsup></mrow></math></mathml>) <sup>T</sup> tanh (<b><i>W</i></b><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>w</mi><mi>h</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml><b><i>h</i></b><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>+<b><i>W</i></b><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>w</mi><mi>u</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml><b><i>u</i></b>+<b><i>b</i></b><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>w</mi><mi>u</mi></msubsup></mrow></math></mathml>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mi>e</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>u</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mrow><mi>exp</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>e</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mi>u</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">其中:<b><i>v</i></b><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>w</mi><mi>u</mi></msubsup></mrow></math></mathml>是权重向量, 而 (<b><i>v</i></b><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>w</mi><mi>u</mi></msubsup></mrow></math></mathml>) <sup>T</sup>代表其转置, <b><i>W</i></b><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>w</mi><mi>h</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>和<b><i>W</i></b><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>w</mi><mi>u</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>是权重矩阵, <i>e</i> (·) 是得分函数, 对组成当前用户的句子表示中单词的重要性进行评分。</p>
                </div>
                <div class="p1">
                    <p id="106"><i>e</i> (<b><i>h</i></b><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup></mrow></math></mathml>, <b><i>u</i></b>) = (<b><i>v</i></b><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>u</mi></msubsup></mrow></math></mathml>) <sup>T</sup> tanh (<b><i>W</i></b><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>s</mi><mi>h</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml><b><i>h</i></b><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup></mrow></math></mathml>+<b><i>W</i></b><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>s</mi><mi>u</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml><b><i>u</i></b>+<b><i>b</i></b><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>u</mi></msubsup></mrow></math></mathml>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>β</mi><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mi>e</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>exp</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>e</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>k</mi><mi>u</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">d</mi><msup><mrow></mrow><mi>u</mi></msup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>β</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">其中:<b><i>h</i></b><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup></mrow></math></mathml>是评论文档中第<i>i</i>个句子的隐藏状态; <i>β</i><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup></mrow></math></mathml>是句子级别中隐藏状态<b><i>h</i></b><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>u</mi></msubsup></mrow></math></mathml>的权重, 其计算方式类似于单词级别的计算。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118">2.4 <b>产品注意力机制</b></h4>
                <div class="p1">
                    <p id="119">对于不同的产品, 每个单词或句子对文本语义贡献度也不同。基于常识可知, 产品注意力机制可将产品信息整合到类似于用户注意力机制类似的评论表示中。在产品视图中, 评论的句子表示<b><i>s</i></b><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup></mrow></math></mathml>和文档表示<b><i>d</i></b><sup><i>p</i></sup>可计算如下:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mi>α</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">d</mi><msup><mrow></mrow><mi>p</mi></msup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>β</mi></mstyle><mtext> </mtext><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">这里<i>α</i><mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>和<i>β</i><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup></mrow></math></mathml>分别是单词级隐藏状态<b><i>h</i></b><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>和句子级<b><i>h</i></b><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup></mrow></math></mathml>的权重, 其计算方式跟用户注意力机制中的权重计算一样, 不需要人工调节和干预。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">2.5 <b>文档表示</b></h4>
                <div class="p1">
                    <p id="128"><b><i>d</i></b><sup><i>u</i></sup>和<b><i>d</i></b><sup><i>p</i></sup>分别表示用户视图和产品视图学习的表示, 为了获得较为全局的篇章表示, 首先整合这两个视图的表示, 将其拼接在一起作为一个最终的评论表示:</p>
                </div>
                <div class="p1">
                    <p id="129"><b><i>d</i></b>=[<b><i>d</i></b><sup><i>u</i></sup>;<b><i>d</i></b><sup><i>p</i></sup>]      (13) </p>
                </div>
                <div class="p1">
                    <p id="130">拼接后, 可以直接使用线性层和softmax层将评论表示<b><i>d</i></b>投影到<i>C</i>类的评论类别分布中:</p>
                </div>
                <div class="p1">
                    <p id="131"><i>p</i>=softmax (<b><i>W</i></b><b><i>d</i></b>+<b><i>b</i></b>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="132">在提出的模型中, 评论类别的基本事实分布与<i>p</i>之间的交叉熵误差被定义为:</p>
                </div>
                <div class="p1">
                    <p id="133" class="code-formula">
                        <mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">d</mi><mo>∈</mo><mi>Τ</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mi>c</mi><mi>g</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="134">其中:<i>p</i><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>c</mi><mi>g</mi></msubsup></mrow></math></mathml>表示分类标签<i>c</i>的概率, <i>T</i>代表训练集。</p>
                </div>
                <div class="p1">
                    <p id="136">之前, 对两个视图的表示直接进行了拼接作为最终表示, 但是, 这种表示不一定能给出最优的全局篇章表示, 因为两个表示的构造方式基本相同, 因此, 为了获得更优的篇章表示, 在损失1中以一定权重整合评论表示<b><i>d</i></b><sup><i>u</i></sup>和<b><i>d</i></b><sup><i>p</i></sup>, 具体地, 分别在<b><i>d</i></b><sup><i>u</i></sup>和<b><i>d</i></b><sup><i>p</i></sup>中添加softmax分类器, 其相应的损失定义如下:</p>
                </div>
                <div class="p1">
                    <p id="137"><i>p</i><sup><i>u</i></sup>=softmax (<b><i>W</i></b><sup><i>u</i></sup><b><i>d</i></b><sup><i>u</i></sup>+<b><i>b</i></b><sup><i>u</i></sup>)      (16) </p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>d</mi><mo>∈</mo><mi>Τ</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mi>c</mi><mi>g</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mi>p</mi><msubsup><mrow></mrow><mi>c</mi><mi>u</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>p</mi><msup><mrow></mrow><mi>p</mi></msup><mo>=</mo><mtext>s</mtext><mtext>o</mtext><mtext>f</mtext><mtext>t</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>p</mi></msup><mi mathvariant="bold-italic">d</mi><msup><mrow></mrow><mi>p</mi></msup><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>p</mi></msup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>d</mi><mo>∈</mo><mi>Τ</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mi>c</mi><mi>g</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mi>p</mi><msubsup><mrow></mrow><mi>c</mi><mi>p</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="140">其中:<i>p</i><sup><i>u</i></sup>是用户视图的预测结果分布, <i>p</i><sup><i>p</i></sup>是产品视图的预测结果分布, 因此, 模型的最终损失可以表示为损失1, 损失2和损失3的加权和:</p>
                </div>
                <div class="p1">
                    <p id="141"><i>L</i>=<i>λ</i><sub>1</sub><i>loss</i><sub>1</sub>+<i>λ</i><sub>2</sub><i>loss</i><sub>2</sub>+<i>λ</i><sub>3</sub><i>loss</i><sub>3</sub>      (20) </p>
                </div>
                <div class="p1">
                    <p id="142">损失2和损失3作为监督信息引入, 以帮助进一步从用户视图和产品视图来探索虚假评论识别, 因此, 最终根据分布<i>p</i>预测评论分类标签, 因为它包含用户信息和产品信息。</p>
                </div>
                <h3 id="143" name="143" class="anchor-tag">3 实验设置</h3>
                <h4 class="anchor-tag" id="144" name="144">3.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="145">本文使用来自美国最大点评网站<i>Yelp</i>.<i>com</i>收集到的三个数据集, 表1是三个数据集的统计信息。这三个数据集都是非平衡数据集。第一个数据集是<i>YelpChi</i>, 它包含对芝加哥地区餐馆和酒店的评论, 该数据集最早来自于文献<citation id="301" type="reference">[<a class="sup">28</a>]</citation>。另外两个数据集分别是<i>YelpNYC</i>和<i>YelpZip</i>。<i>YelpNYC</i>包含位于纽约市的餐馆的评论;<i>YelpZip</i>数据量更大, 提供了美国部分区域的餐馆的评论, 这些地区包括<i>NJ</i>、<i>VT</i>、<i>CT</i>和<i>PA</i>。这两个数据集最早来自于文献<citation id="302" type="reference">[<a class="sup">29</a>]</citation>。</p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表</b>1 <b>数据集的统计信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Statistical information of datasets</i></p>
                    <p class="img_note"></p>
                    <table id="146" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="3"><br />评论</td><td rowspan="2"></td><td colspan="3"><br />评论者</td><td rowspan="2"><i>restaurant</i>和<i>hotel</i><br />领域中提及的<br />产品总数</td></tr><tr><td colspan="2"><br />总数</td><td>虚假评论<br />占比/%</td><td colspan="2"><br />总数</td><td>虚假评论<br />者占比/%</td></tr><tr><td><i>YelpChi</i></td><td>67 395</td><td colspan="2">13.23</td><td></td><td>38 063</td><td colspan="2">20.33</td><td>201</td></tr><tr><td><br /><i>YelpNYC</i></td><td>359 052</td><td colspan="2">10.27</td><td></td><td>160 225</td><td colspan="2">17.79</td><td>923</td></tr><tr><td><br /><i>YelpZip</i></td><td>608 598</td><td colspan="2">13.22</td><td></td><td>260 277</td><td colspan="2">23.91</td><td>5 044</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="147">在实验过程中, 每个数据集以80/10/10的比例被划分为训练/测试/开发集。开发集用于优化神经网络结构的超参数。实验中, 采取<i>Accuracy</i>、<i>F</i>1值和均方根误差 (<i>Root Mean Square Error</i>, <i>RMSE</i>) 来评价算法的性能。</p>
                </div>
                <h4 class="anchor-tag" id="148" name="148">3.2 <b>超参数</b></h4>
                <div class="p1">
                    <p id="149">在实验中, 使用<i>Skip</i>-<i>Gram</i>模型学到200维的词向量。用户词向量的维度和产品词向量的维度都设置为200, 使用均匀分布<i>U</i> (-0.01, 0.01) 对其随机初始化。<i>LSTM</i>单元格中隐藏状态的维度设置为100, 因此, 双向<i>LSTM</i>输出单词/句子表示为200维。这里, 限制每个评论文本最多有40个句子, 每个句子不超过50个单词。使用<i>Adam</i>更新参数, 初始学习率设置为0.005。最后, 根据开发集上的性能选择最佳参数, 用于测试集中。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">3.3 <b>基准模型</b></h4>
                <div class="p1">
                    <p id="151">支持向量机 (<i>Support Vector Machine</i>, <i>SVM</i>) : 支持向量机在众多文本分类任务中获得了优异的性能, 也被用于虚假评论识别工作中。这里, 不仅整合<i>SVM</i>和传统的词袋特征, 也使用了<i>Bigram</i>、<i>POS</i>、<i>LIWC</i>等各种语言学和心理语言学的特征。</p>
                </div>
                <div class="p1">
                    <p id="152"><i>CNN</i>:从词到句子, 句子到篇章, 采用<i>CNN</i>模型来搭建。</p>
                </div>
                <div class="p1">
                    <p id="153"><i>RNN</i>:类似于<i>CNN</i>模型, 采用<i>RNN</i>对评论文本进行建模。</p>
                </div>
                <div class="p1">
                    <p id="154">双向<i>LSTM</i> (<i>Bidirectional LSTM</i>, <i>BiLSTM</i>) :使用<i>BiLSTM</i>对评论文本进行建模。</p>
                </div>
                <h3 id="155" name="155" class="anchor-tag">4 实验结果</h3>
                <h4 class="anchor-tag" id="156" name="156">4.1 <b>结果比较</b></h4>
                <div class="p1">
                    <p id="157">基于<i>Yelp</i>的数据集, 表2给出了不同模型的实验结果。以<i>YelpNYC</i>数据集为例, 传统的离散模型<i>SVM</i>, 结合<i>unigram</i>特征, 仅仅给出了69.63%准确率, 当融合<i>POS</i>、<i>LIWC</i>等更多更复杂的语言学和心理语言学特征后, 识别准确率被提升到74.18%, 这展示了丰富的特征建模对虚假评论识别的重要性。对于神经网络的基准模型, <i>CNN</i>完成了83.84%的准确率, 远远地超出了离散的<i>SVM</i>模型, 显示了神经网络模型的有效性。<i>RNN</i>给出了78.96%的准确率, <i>BiLSTM</i>给出了85.55%的准确率, 远远地超过了<i>RNN</i>模型, 主要原因是因为<i>RNN</i>受长距离依赖问题的困扰, 而<i>BiLSTM</i>通过门机制的设置, 可以避免长距离依赖导致的梯度弥散问题, 从而完成了较好的性能。基于<i>BiLSTM</i>模型, 从用户视图和产品视图两个角度分别整合了注意力机制, 即本文提出的<i>HNNUPA</i>模型, 完成了90%的准确率, 超出了离散的<i>SVM</i>模型和神经网络的基准模型<i>CNN</i>和<i>BiLSTM</i>。基于数据集<i>YelpZip</i>和<i>YelpChi</i>上, 模型间的性能比较可以观察到同样的趋势, 上述分析证实了本文所提算法的有效性。</p>
                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表</b>2 <b>不同模型的准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Accuracy comparison of different models</i></p>
                    <p class="img_note">%</p>
                    <table id="158" border="1"><tr><td><br />模型</td><td><i>YelpNYC</i></td><td><i>YelpZip</i></td><td><i>YelpChi</i></td></tr><tr><td><br /><i>SVM</i>+<i>Unigram</i></td><td>69.63</td><td>68.57</td><td>67.75</td></tr><tr><td><br /><i>SVM</i>+<i>ALL</i></td><td>74.18</td><td>73.29</td><td>72.48</td></tr><tr><td><br /><i>CNN</i></td><td>83.84</td><td>82.35</td><td>81.72</td></tr><tr><td><br /><i>RNN</i></td><td>78.96</td><td>78.61</td><td>77.04</td></tr><tr><td><br /><i>BiLSTM</i></td><td>85.55</td><td>83.76</td><td>84.23</td></tr><tr><td><br /><i>HNNUPA</i></td><td><b>90.00</b></td><td><b>86.71</b></td><td><b>85.23</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="159" name="159">4.2 <b>模型分析</b></h4>
                <h4 class="anchor-tag" id="160" name="160">4.2.1 用户注意力和产品注意力的影响</h4>
                <div class="p1">
                    <p id="161">为了证明同时使用用户注意力和产品注意力的有效性, 这里, 独立地实现了两个注意力机制并进行探讨。具体地, 首先实现了独立的用户注意力网络 (Hierarchical Neural Network with User Attention, HNNUA) , 然后实现了独立的产品注意力网络 (Hierarchical Neural Network with Product Attention, HNNPA) 。表3给出了不同模型的具体结果。基于表3可知, 与未使用注意力机制的普通神经网络模型BiLSTM相比, HNNUA和HNNPA对模型的性能有一定的提升, 这验证了通过注意力机制将用户和产品纳入虚假评论识别的合理性。结果还表明, 无论从用户视图还是产品视图来对评论文本进行建模都是有效的。</p>
                </div>
                <div class="p1">
                    <p id="162">同时, 本文发现, 比起产品角度, 从用户视图的角度对文本进行建模更有效。原因可能归结于评论中的一些单词或句子虽然一定程度上描述了产品的特征, 但对产品的态度描述最终由用户主观决定。比起单独的用户视图或者产品角度建模, 对两者进行整合获得了更好的性能, 主要原因是因为一个评论文本通常由两种信息构成, 一部分信息表达用户的偏好, 另一部分信息表达产品的特性, 对这两种信息同时建模才是获得全局表示的关键。本文的实验结果也证实了这一点。</p>
                </div>
                <div class="p1">
                    <p id="163">另外, 在表3中, 本文也统计了模型的F1值和RMSE, 这里F1值是两个类别的宏平均。本文发现比起模型的Accuracy, F值相对较低, 进一步分析了每个类别的Precision和Recall, 发现真实评论这个类别的Precision和Recall都很高, 而虚假评论类别的Precision较高, Recall只有0.4左右, 这说明模型在虚假评论这个类别上性能要差于真实评论类别, 其主要原因是数据集不均衡导致的, 基于表1中的数据集统计信息可知。在未来的工作中, 也将探索更好的模型来解决这个问题。</p>
                </div>
                <h4 class="anchor-tag" id="164" name="164">4.2.2 不同加权损失的影响</h4>
                <div class="p1">
                    <p id="165"><i>λ</i><sub>1</sub>、<i>λ</i><sub>2</sub>和<i>λ</i><sub>3</sub>分别代表损失1、损失2和损失3的权重。通过调整它们的比例来验证不同加权损失对最终结果的影响。当<i>λ</i><sub>2</sub>设置为0时, 表示不使用损失2来增强评论表示。类似地, 将<i>λ</i><sub>3</sub>设置为0, 表示不单独使用损失3。实验结果如表4。</p>
                </div>
                <div class="area_img" id="166">
                    <p class="img_tit"><b>表</b>3 <b>不同模型的评价指标对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Comparison of evaluation indexes of different models</p>
                    <p class="img_note"></p>
                    <table id="166" border="1"><tr><td rowspan="2">模型</td><td colspan="3"><br />YelpNYC</td><td rowspan="2"></td><td colspan="3"><br />YelpZip</td><td rowspan="2"></td><td colspan="3"><br />YelpChi</td></tr><tr><td><br />Acc/%</td><td>RMSE</td><td>F1</td><td><br />Acc/%</td><td>RMSE</td><td>F1</td><td><br />Acc/%</td><td>RMSE</td><td>F1</td></tr><tr><td>BiLSTM</td><td>85.55</td><td>0.335 4</td><td>0.682 4</td><td></td><td>83.76</td><td>0.381 2</td><td>0.654 1</td><td></td><td>84.23</td><td>0.378 1</td><td>0.584 3</td></tr><tr><td><br />HNNUA</td><td>88.99</td><td>0.285 6</td><td>0.701 9</td><td></td><td>85.99</td><td>0.326 1</td><td>0.673 8</td><td></td><td>85.10</td><td>0.339 5</td><td>0.604 0</td></tr><tr><td><br />HNNPA</td><td>86.50</td><td>0.321 3</td><td>0.475 9</td><td></td><td>84.96</td><td>0.363 8</td><td>0.507 8</td><td></td><td>84.77</td><td>0.367 7</td><td>0.513 2</td></tr><tr><td><br />HNNUPA</td><td><b>90.00</b></td><td><b>0.276</b><b>8</b></td><td><b>0.706</b><b>5</b></td><td><b></b></td><td><b>86.71</b></td><td><b>0.319</b><b>9</b></td><td><b>0.694</b><b>5</b></td><td><b></b></td><td><b>85.23</b></td><td><b>0.337</b><b>9</b></td><td><b>0.630</b><b>9</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="167">
                    <p class="img_tit"><b>表</b>4 <b>不同加权损失的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Influences of different weighted losses</p>
                    <p class="img_note"></p>
                    <table id="167" border="1"><tr><td rowspan="2"><i>λ</i><sub>1</sub></td><td rowspan="2"><i>λ</i><sub>2</sub></td><td rowspan="2"><i>λ</i><sub>3</sub></td><td colspan="3"><br />YelpNYC</td><td rowspan="2"></td><td colspan="3"><br />YelpZip</td><td rowspan="2"></td><td colspan="3"><br />YelpChi</td></tr><tr><td><br />Acc/%</td><td>RMSE</td><td>F1</td><td><br />Acc/%</td><td>RMSE</td><td>F1</td><td><br />Acc/%</td><td>RMSE</td><td>F1</td></tr><tr><td>1.0</td><td>0.0</td><td>0.0</td><td>86.72</td><td>0.318 2</td><td>0.707 0</td><td></td><td>83.97</td><td>0.375 6</td><td>0.687 3</td><td></td><td>84.26</td><td>0.369 5</td><td>0.632 4</td></tr><tr><td><br />0.7</td><td>0.0</td><td>0.3</td><td>88.67</td><td>0.287 2</td><td>0.701 3</td><td></td><td>85.59</td><td>0.329 6</td><td>0.680 0</td><td></td><td>84.82</td><td>0.365 6</td><td>0.645 9</td></tr><tr><td><br />0.7</td><td>0.3</td><td>0.0</td><td>88.56</td><td>0.288 5</td><td>0.698 1</td><td></td><td>84.43</td><td>0.332 6</td><td>0.690 5</td><td></td><td>84.72</td><td>0.367 0</td><td>0.635 1</td></tr><tr><td><br />0.4</td><td>0.3</td><td>0.3</td><td><b>90.00</b></td><td><b>0.276</b><b>8</b></td><td><b>0.706</b><b>5</b></td><td><b></b></td><td><b>86.71</b></td><td><b>0.319</b><b>9</b></td><td><b>0.694</b><b>5</b></td><td><b></b></td><td><b>85.23</b></td><td><b>0.337</b><b>9</b></td><td><b>0.630</b><b>9</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="168">从表4可知, 三个数据集上的实验结果给出了一致的趋势, 即缺乏损失2或者损失3都会影响模型最终的性能, 而本文提出的HNNUPA模型, 从用户和产品两个角度建模, 同时考虑两方面的损失。获得了性能上的一些提升。很明显, 完整的HNNUPA模型可以获得最佳性能。结果表明, 通过设计的组合策略, 可以从篇章角度实现更好的评论表示, 用于虚假评论识别中。</p>
                </div>
                <h4 class="anchor-tag" id="169" name="169">4.2.3 样例可视化</h4>
                <div class="p1">
                    <p id="170">为了验证本文所提的注意力机制的有效性, 以YelpNYC数据集为例进行分析。基于提出的HNNUPA模型, 这里分析单词级别的注意力权重。两个样例如图2所示。注意, 颜色越深意味着权重越大。</p>
                </div>
                <div class="area_img" id="171">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907010_171.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 单词级别的用户和产品注意力可视化" src="Detail/GetImg?filename=images/JSJY201907010_171.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 单词级别的用户和产品注意力可视化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907010_171.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Visualization of word-level user and product attentions</p>

                </div>
                <div class="p1">
                    <p id="172">评论1是虚假评论, “love”一词在用户视图上具有最高权重, “love”表达出了作者对食物的喜爱, 说明作者试图鼓吹、夸大该产品;“casual”和“surrounding”等词在产品视图上具有较高的权重, 其中“surrounding”一词描述了餐馆空间特征, 表示评论作者本身也许并未有真实的消费经历, 缺乏真实的体验, 所以选择使用抽象的表示空间方位的词。</p>
                </div>
                <div class="p1">
                    <p id="173">评论2是虚假评论, “disappointed”一词在用户视图上具有最高权重, “disappointed”表达出了作者的负面情感, 说明作者试图通过这种消极情绪来诋毁该产品, “bland”一词在产品视图上具有较高的权重, “bland”意为乏味的, 是贬低食物的一种通用词汇, 作者可能根本就没有吃过这家店的意大利面, 试图通过“bland”来诋毁该产品。</p>
                </div>
                <div class="p1">
                    <p id="174">现实中的情况正是如此。为了鼓吹产品的质量, 虚假评论者会使用积极正面的情感词;同理, 在贬低产品时, 必然会使用消极负面的情感词。另外, 由于对产品或服务缺乏真实的消费体验或经历, 虚假评论者往往会使用抽象的词来描述空间信息或者地理位置, 因为过于具体的词汇可能会由于跟事实不符而暴露其欺骗意图。</p>
                </div>
                <h3 id="175" name="175" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="176">本文提出了一种基于层次注意力机制的神经网络模型, 从用户和产品两个角度分别来学习评论文本的表示, 将两个表示进行整合作为评论文本的最终表示, 用于虚假评论识别。基于Yelp数据集的实验结果表明, 本文所提模型超过了传统的离散模型和神经网络基准模型。未来的工作中, 将探索更有效的模型, 提升非平衡数据下的虚假评论识别效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="211">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 OTT M, CHOI Y, CARDIE C, et al.Finding deceptive opinion spam by any stretch of the imagination [C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2011:309-319.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 JINDAL N, LIU B.Opinion spam and analysis [C]// Proceedings of the 2008 International Conference on Web Search and Data Mining.New York:ACM, 2008:219-230.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 REN Y F, ZHANG Y.Deceptive opinion spam detection using neural network [C]// COLING 2016:Proceedings of the 26th International Conference on Computational Linguistics:Technical Papers.Osaka, Japan:COLING, 2016:140-150.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                 YOO K H, GRETZEL U.Comparison of deceptive and truthful travel reviews [C]// Proceedings of the 2009 International Conference on Information and Communication Technologies.Berlin:Springer, 2009:37-47.
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 FENG S, BANERJEE R, CHOI Y.Syntactic stylometry for deception detection [C]// Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:Short Papers-Volume 2.Stroudsburg, PA:Association for Computational Linguistics, 2012:171-175.
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 FENG V W, HIRST G.Detecting deceptive opinions with profile compatibility [C]// Proceedings of the 6th International Joint Conference on Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:338-346.
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 MUKHERJEE A, VENKATARAMAN V, LIU B, et al.Fake review detection:classification and analysis of real and pseudo reviews [R].Chicago:University of Illinois, Department of Computer Science, 2013:3.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 MUKHERJEE A, KUMAR A, LIU B, et al.Spotting opinion spammers using behavioral footprints [C]// Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2013:632-640.
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 QIAN T Y, LIU B.Identifying multiple userids of the same author [C]// Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:1124-1135.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201403010&amp;v=MzA5MThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMclBOaTdIWnJHNEg5WE1ySTlFWkk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 任亚峰, 姬东鸿, 尹兰.基于半监督学习算法的虚假评论识别研究[J].计算机科学与探索, 2014, 46 (3) :62-69. (REN Y F, JI D H, YIN L.Deceptive reviews detection based on semi-supervised learning algorithm [J].Advanced Engineering Sciences, 2014, 46 (3) :62-69.) 
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 ROUT J K, SINGH S, JENA S K, et al.Deceptive review detection using labeled and unlabeled data [J].Multimedia Tools and Applications, 2017, 76 (3) :1-25.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=EDZX201501009&amp;v=MDE4MzE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkxyUElDblJkckc0SDlUTXJvOUZiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> REN Y F, JI D H, YIN L, et al.Finding deceptive opinion spam by correcting the mislabeled instances [J].Chinese Journal of Electronics, 2015, 24 (1) :52-57.
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 KIM S, CHANG H, LEE S, et al.Deep semantic frame-based deceptive opinion spam analysis [C]// Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.New York:ACM, 2015:1131-1140.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 WANG X P, LIU K, HE S Z, et al.Learning to represent review with tensor decomposition for spam detection [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:866-875.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201403007&amp;v=MTAwMTBac0Z5L25WTHJQTGpYZmZiRzRIOVhNckk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 任亚峰, 尹兰, 姬东鸿.基于语言结构和情感极性的虚假评论识别[J].计算机科学与探索, 2014, 8 (3) :313-320. (REN Y F, YIN L, JI D H.Deceptive reviews detection based on language structure and sentiment polarity [J].Journal of Frontiers of Computer Science and Technology, 2014, 8 (3) :313-320.) 
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEDA6628822F5E0C0AB475577E7541A2C&amp;v=MTg1NDJOdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzdxNHhhOD1OaWZPZmNiTWI5ZktyWWROWnVsNUNRazV2QlppbUR0NlRYcmxxMmN5ZkxhVk5ManNDTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> ZHANG W, DU Y H, YOSHIDA T, et al.DRI-RCNN:an approach to deceptive review identification using recurrent convolutional neural network [J].Information Processing and Management, 2018, 54 (4) :576-592.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH70B4AD5E7498F090DD9ADE5DF39B6314&amp;v=MzExMjlBcm4yR1EyY01DU1JydWJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3E0eGE4PU5pZktaclM0Yk5XOTI0b3dZKzhHQkFvNXhoWm5uallNUA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> NOEKHAH S, SALIM N B, ZAKARIA N H.A novel model for opinion spam detection based on multi-iteration network structure [J].Advanced Science Letters, 2018, 24 (2) :1437-1442.
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 REN Y F, ZHANG Y, ZHANG M S, et al.Context-sensitive twitter sentiment classification using neural network [C]// Proceedings of the 13th AAAI Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2016:215-221.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 REN Y F, ZHANG Y, ZHANG M S, et al.Improving twitter sentiment classification using topic-enriched multi-prototype word embeddings [C]// Proceedings of the 13th AAAI Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2016:3038-3044.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 YESSENALI A A, CARDIE C.Compositional matrix-space models for sentiment analysis [C]// Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2011:172-182.
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_21" >
                                    <b>[21]</b>
                                 LE Q, MIKOLOV T.Distributed representations of sentences and documents [J].Journal of Machine Learning Research, 2014, 32 (2) :1188-1196.
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 SOCHER R, PERELYGIN A, WU J, et al.Recursive deep models for semantic compositionality over a sentiment treebank [C]// Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2013:1631-1642.
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                 JOHNSON R, ZHANG T.Effective use of word order for text categorization with convolutional neural networks [C]// Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2015:103-112.
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_24" >
                                    <b>[24]</b>
                                 LI J W, LUONG M T, JURAFSKY D, et al.When are tree structures necessary for deep learning of representations [EB/OL].[2017- 08- 04].http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP278.pdf.
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_25" >
                                    <b>[25]</b>
                                 BAHDANAU D, CHO K, BENGIO Y.Neural machine translation by jointly learning to align and translate [EB/OL].[2017- 10- 20].https://arxiv.org/abs/1409.0473.
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_26" >
                                    <b>[26]</b>
                                 YANG Z C, YANG D Y, DYER C, et al.Hierarchical attention networks for document classification [C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2016:1480-1489.
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_27" >
                                    <b>[27]</b>
                                 CHEN H M, SUN M S, TU C C, et al.Neural sentiment classification with user and product attention [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:1650-1659.
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_28" >
                                    <b>[28]</b>
                                 MUKHERJEE A, VENKATARAMAN V, LIU B, et al.What yelp fake review filter might be doing [C]// Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media.Menlo Park, CA:AAAI, 2013:409-418.
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_29" >
                                    <b>[29]</b>
                                 RAYANA S, AKOGLU L.Collective opinion spam detection:bridging review networks and metadata [C]// Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2015:985-994.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907010&amp;v=MDcwMDdmWnVac0Z5L25WTHJQTHo3QmQ3RzRIOWpNcUk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
