<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136763165752500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201905009%26RESULT%3d1%26SIGN%3d8dSrarF9P%252fH4CeuYzEHV%252blgZUSs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905009&amp;v=MDE2NTdCdEdGckNVUjdxZlp1WnNGeURtVjcvTEx6N0JkN0c0SDlqTXFvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="1 总体框架 ">1 总体框架</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="2 司法文书领域知识模型 ">2 司法文书领域知识模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="3 司法文档知识块摘要 ">3 司法文档知识块摘要</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="3.1 &lt;b&gt;客观方面的抽取&lt;/b&gt;">3.1 <b>客观方面的抽取</b></a></li>
                                                <li><a href="#119" data-title="3.2 &lt;b&gt;基于规则的信息抽取、标准化及知识添加&lt;/b&gt;">3.2 <b>基于规则的信息抽取、标准化及知识添加</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="4 基于WMD模型的司法文档分类 ">4 基于WMD模型的司法文档分类</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="4.1 &lt;b&gt;基于&lt;/b&gt;Word2Vec&lt;b&gt;的词向量模型构建&lt;/b&gt;">4.1 <b>基于</b>Word2Vec<b>的词向量模型构建</b></a></li>
                                                <li><a href="#127" data-title="4.2 &lt;b&gt;基于&lt;/b&gt;WMD&lt;b&gt;模型的文本相似度计算&lt;/b&gt;">4.2 <b>基于</b>WMD<b>模型的文本相似度计算</b></a></li>
                                                <li><a href="#135" data-title="4.3 &lt;b&gt;基于&lt;/b&gt;&lt;i&gt;K&lt;/i&gt;NN&lt;b&gt;的文档分类&lt;/b&gt;">4.3 <b>基于</b><i>K</i>NN<b>的文档分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#137" data-title="5 司法文档分类实验与结果分析 ">5 司法文档分类实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#138" data-title="5.1 &lt;b&gt;司法文档数据集&lt;/b&gt;">5.1 <b>司法文档数据集</b></a></li>
                                                <li><a href="#140" data-title="5.2 &lt;b&gt;司法文档&lt;/b&gt;&lt;i&gt;Word&lt;/i&gt;2&lt;i&gt;Vec&lt;/i&gt;&lt;b&gt;词向量训练语料库&lt;/b&gt;">5.2 <b>司法文档</b><i>Word</i>2<i>Vec</i><b>词向量训练语料库</b></a></li>
                                                <li><a href="#142" data-title="5.3 &lt;b&gt;实验设置与实验指标&lt;/b&gt;">5.3 <b>实验设置与实验指标</b></a></li>
                                                <li><a href="#150" data-title="5.4 &lt;b&gt;实验结果分析&lt;/b&gt;">5.4 <b>实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#162" data-title="6 结语 ">6 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 本文方法总体框架">图1 本文方法总体框架</a></li>
                                                <li><a href="#66" data-title="图2 危险驾驶罪的判决书本体领域模型">图2 危险驾驶罪的判决书本体领域模型</a></li>
                                                <li><a href="#153" data-title="图3 不同&lt;i&gt;k&lt;/i&gt;值下的分类准确率">图3 不同<i>k</i>值下的分类准确率</a></li>
                                                <li><a href="#154" data-title="图4 针对危险驾驶和交通肇事两种罪名的准确率比较">图4 针对危险驾驶和交通肇事两种罪名的准确率比较</a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;知识块摘要前后判决书文档中词的平均数目&lt;/b&gt;"><b>表</b>1 <b>知识块摘要前后判决书文档中词的平均数目</b></a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;知识块摘要前后司法文书分类平均时间&lt;/b&gt;"><b>表</b>2 <b>知识块摘要前后司法文书分类平均时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" title=" 马建刚.检察实务中的大数据[&lt;i&gt;M&lt;/i&gt;].北京:中国检察出版社, 2017:17-23. (&lt;i&gt;MA J G&lt;/i&gt;.&lt;i&gt;Procuratorial Big Data&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Beijing&lt;/i&gt;:&lt;i&gt;China Procurational Press&lt;/i&gt;, 2017:17-23.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787510219306000&amp;v=MzA2MDdGWXVzUERCTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3ZkxKRjRYWEZxekdiYTVIdFBOcG94&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         马建刚.检察实务中的大数据[&lt;i&gt;M&lt;/i&gt;].北京:中国检察出版社, 2017:17-23. (&lt;i&gt;MA J G&lt;/i&gt;.&lt;i&gt;Procuratorial Big Data&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Beijing&lt;/i&gt;:&lt;i&gt;China Procurational Press&lt;/i&gt;, 2017:17-23.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" &lt;i&gt;ZHANG N&lt;/i&gt;, &lt;i&gt;PU Y&lt;/i&gt;, &lt;i&gt;YANG S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;An ontological Chinese legal consultation system&lt;/i&gt; [&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Access&lt;/i&gt;, 2017, 5:18250-18261." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An ontological Chinese legal consultation system">
                                        <b>[2]</b>
                                         &lt;i&gt;ZHANG N&lt;/i&gt;, &lt;i&gt;PU Y&lt;/i&gt;, &lt;i&gt;YANG S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;An ontological Chinese legal consultation system&lt;/i&gt; [&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Access&lt;/i&gt;, 2017, 5:18250-18261.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" &lt;i&gt;CASARI A&lt;/i&gt;, &lt;i&gt;ZHENG A&lt;/i&gt;.&lt;i&gt;Feature Engineering for Machine Learning&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Sebastopol&lt;/i&gt;, &lt;i&gt;CA&lt;/i&gt;:&lt;i&gt;O&lt;/i&gt;&#39;&lt;i&gt;Reilly Media&lt;/i&gt;, 2018:247-251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature Engineering for Machine Learning">
                                        <b>[3]</b>
                                         &lt;i&gt;CASARI A&lt;/i&gt;, &lt;i&gt;ZHENG A&lt;/i&gt;.&lt;i&gt;Feature Engineering for Machine Learning&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;Sebastopol&lt;/i&gt;, &lt;i&gt;CA&lt;/i&gt;:&lt;i&gt;O&lt;/i&gt;&#39;&lt;i&gt;Reilly Media&lt;/i&gt;, 2018:247-251.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" &lt;i&gt;LI C L&lt;/i&gt;, &lt;i&gt;SU Y C&lt;/i&gt;, &lt;i&gt;LIN T W&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Combination of feature engineering and ranking models for paper&lt;/i&gt;-&lt;i&gt;author identification in KDD Cup&lt;/i&gt; 2013[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2013 &lt;i&gt;KDD Cup&lt;/i&gt; 2013 &lt;i&gt;Workshop&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2013:&lt;i&gt;Article No&lt;/i&gt;.2." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combination of Feature Engineering and Ranking Models for Paper-author Identification in Kdd Cup 2013">
                                        <b>[4]</b>
                                         &lt;i&gt;LI C L&lt;/i&gt;, &lt;i&gt;SU Y C&lt;/i&gt;, &lt;i&gt;LIN T W&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Combination of feature engineering and ranking models for paper&lt;/i&gt;-&lt;i&gt;author identification in KDD Cup&lt;/i&gt; 2013[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2013 &lt;i&gt;KDD Cup&lt;/i&gt; 2013 &lt;i&gt;Workshop&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2013:&lt;i&gt;Article No&lt;/i&gt;.2.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" title=" &lt;i&gt;XU Y&lt;/i&gt;, &lt;i&gt;HONG K&lt;/i&gt;, &lt;i&gt;TSUJII J&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Feature engineering combined with machine learning and rule&lt;/i&gt;-&lt;i&gt;based methods for structured information extraction from narrative clinical discharge summaries&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of the American Medical Informatics Association&lt;/i&gt;, 2012, 19 (5) :824-832." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries">
                                        <b>[5]</b>
                                         &lt;i&gt;XU Y&lt;/i&gt;, &lt;i&gt;HONG K&lt;/i&gt;, &lt;i&gt;TSUJII J&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Feature engineering combined with machine learning and rule&lt;/i&gt;-&lt;i&gt;based methods for structured information extraction from narrative clinical discharge summaries&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of the American Medical Informatics Association&lt;/i&gt;, 2012, 19 (5) :824-832.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" title=" &lt;i&gt;GALGANI F&lt;/i&gt;, &lt;i&gt;COMPTON P&lt;/i&gt;, &lt;i&gt;HOFFMANN A&lt;/i&gt;.&lt;i&gt;LEXA&lt;/i&gt;:&lt;i&gt;building&lt;/i&gt;&lt;i&gt;knowledge bases for automatic legal citation classification&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Expert Systems with Applications&lt;/i&gt;, 2015, 42 (17) :6391-6407." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7020C9A37D58E13774EFD52F52322A49&amp;v=MTI0NjFyQ1dOTDZXQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoekx1N3dLcz1OaWZPZmJTNEhORy9wdjVHWTU4S0JBazR6QkVVN2tvTFBIcmcyaGMzZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         &lt;i&gt;GALGANI F&lt;/i&gt;, &lt;i&gt;COMPTON P&lt;/i&gt;, &lt;i&gt;HOFFMANN A&lt;/i&gt;.&lt;i&gt;LEXA&lt;/i&gt;:&lt;i&gt;building&lt;/i&gt;&lt;i&gt;knowledge bases for automatic legal citation classification&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Expert Systems with Applications&lt;/i&gt;, 2015, 42 (17) :6391-6407.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" title=" &lt;i&gt;SALTON G&lt;/i&gt;, &lt;i&gt;WONG A&lt;/i&gt;, &lt;i&gt;YANG C S&lt;/i&gt;.&lt;i&gt;A vector space model for automatic indexing&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Communications of the ACM&lt;/i&gt;, 1975, 18 (11) :613-620." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000024403&amp;v=MjU5NTV3WmVadEZpbmxVcjNJS0YwUWFoRT1OaWZJWTdLN0h0ak5yNDlGWk9rTENIdzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         &lt;i&gt;SALTON G&lt;/i&gt;, &lt;i&gt;WONG A&lt;/i&gt;, &lt;i&gt;YANG C S&lt;/i&gt;.&lt;i&gt;A vector space model for automatic indexing&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Communications of the ACM&lt;/i&gt;, 1975, 18 (11) :613-620.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" title=" &lt;i&gt;HAMMOUDA K&lt;/i&gt;, &lt;i&gt;KAMEL M&lt;/i&gt;.&lt;i&gt;Phrase&lt;/i&gt;-&lt;i&gt;based document similarity&lt;/i&gt;&lt;i&gt;based on an index graph model&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2002 &lt;i&gt;IEEE International Conference on Data Mining&lt;/i&gt;.&lt;i&gt;Washington&lt;/i&gt;, &lt;i&gt;DC&lt;/i&gt;:&lt;i&gt;IEEE Computer Society&lt;/i&gt;, 2002:203-210." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Phrase-based document similarity based on an index graph model">
                                        <b>[8]</b>
                                         &lt;i&gt;HAMMOUDA K&lt;/i&gt;, &lt;i&gt;KAMEL M&lt;/i&gt;.&lt;i&gt;Phrase&lt;/i&gt;-&lt;i&gt;based document similarity&lt;/i&gt;&lt;i&gt;based on an index graph model&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 2002 &lt;i&gt;IEEE International Conference on Data Mining&lt;/i&gt;.&lt;i&gt;Washington&lt;/i&gt;, &lt;i&gt;DC&lt;/i&gt;:&lt;i&gt;IEEE Computer Society&lt;/i&gt;, 2002:203-210.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" title=" &lt;i&gt;BLEI D M&lt;/i&gt;, &lt;i&gt;NG A Y&lt;/i&gt;, &lt;i&gt;JORDAN M I&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Latent Dirichlet allocation&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Machine Learning Research&lt;/i&gt;, 2003, 3 (4/5) :993-1022." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Latent Dirichlet allocation">
                                        <b>[9]</b>
                                         &lt;i&gt;BLEI D M&lt;/i&gt;, &lt;i&gt;NG A Y&lt;/i&gt;, &lt;i&gt;JORDAN M I&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Latent Dirichlet allocation&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Machine Learning Research&lt;/i&gt;, 2003, 3 (4/5) :993-1022.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" title=" &lt;i&gt;ROITBLAT H L&lt;/i&gt;, &lt;i&gt;KERSHAW A&lt;/i&gt;, &lt;i&gt;OOT P&lt;/i&gt;.&lt;i&gt;Document categorization in legal electronic discovery&lt;/i&gt;:&lt;i&gt;computer classification vs&lt;/i&gt;.&lt;i&gt;manual review&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of the Association for Information Science and Technology&lt;/i&gt;, 2010, 61 (1) :70-80." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Document categorization in legal electronic discovery: Computer classification vs. manual review">
                                        <b>[10]</b>
                                         &lt;i&gt;ROITBLAT H L&lt;/i&gt;, &lt;i&gt;KERSHAW A&lt;/i&gt;, &lt;i&gt;OOT P&lt;/i&gt;.&lt;i&gt;Document categorization in legal electronic discovery&lt;/i&gt;:&lt;i&gt;computer classification vs&lt;/i&gt;.&lt;i&gt;manual review&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of the Association for Information Science and Technology&lt;/i&gt;, 2010, 61 (1) :70-80.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" title=" &lt;i&gt;NOORTWIJK K V&lt;/i&gt;, &lt;i&gt;NOORTWIJK K C&lt;/i&gt;.&lt;i&gt;Automatic document classification in integrated legal content collections&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 16&lt;i&gt;th International Conference on Artificial Intelligence and Law&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2017:129-134." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic document classification in integrated legal content collections">
                                        <b>[11]</b>
                                         &lt;i&gt;NOORTWIJK K V&lt;/i&gt;, &lt;i&gt;NOORTWIJK K C&lt;/i&gt;.&lt;i&gt;Automatic document classification in integrated legal content collections&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 16&lt;i&gt;th International Conference on Artificial Intelligence and Law&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;ACM&lt;/i&gt;, 2017:129-134.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" title=" &lt;i&gt;SULEA O&lt;/i&gt;, &lt;i&gt;ZAMPIERI M&lt;/i&gt;, &lt;i&gt;MALMASI S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Exploring the use of text classification in the legal domain&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].&lt;i&gt;arXiv Preprint&lt;/i&gt;, 2017, 2017:&lt;i&gt;arXiv&lt;/i&gt;:1710.09306 [2017- 10- 25].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;arxiv&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;/&lt;i&gt;abs&lt;/i&gt;/1710.09306." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploring the use of text classification in the legal domain">
                                        <b>[12]</b>
                                         &lt;i&gt;SULEA O&lt;/i&gt;, &lt;i&gt;ZAMPIERI M&lt;/i&gt;, &lt;i&gt;MALMASI S&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Exploring the use of text classification in the legal domain&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].&lt;i&gt;arXiv Preprint&lt;/i&gt;, 2017, 2017:&lt;i&gt;arXiv&lt;/i&gt;:1710.09306 [2017- 10- 25].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;arxiv&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;/&lt;i&gt;abs&lt;/i&gt;/1710.09306.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" title=" &lt;i&gt;SARIC F&lt;/i&gt;, &lt;i&gt;DALBELO B&lt;/i&gt;, &lt;i&gt;MOENS M F&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Multi&lt;/i&gt;-&lt;i&gt;label classification of croatian legal documents using eurovoc thesaurus&lt;/i&gt;[&lt;i&gt;EB&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].[2018- 03- 20].&lt;i&gt;http&lt;/i&gt;://&lt;i&gt;core&lt;/i&gt;.&lt;i&gt;ac&lt;/i&gt;.&lt;i&gt;uk&lt;/i&gt;/&lt;i&gt;download&lt;/i&gt;/&lt;i&gt;pdf&lt;/i&gt;/34600531.&lt;i&gt;pdf&lt;/i&gt;." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-label classification of croatian legal documents using eurovoc thesaurus">
                                        <b>[13]</b>
                                         &lt;i&gt;SARIC F&lt;/i&gt;, &lt;i&gt;DALBELO B&lt;/i&gt;, &lt;i&gt;MOENS M F&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Multi&lt;/i&gt;-&lt;i&gt;label classification of croatian legal documents using eurovoc thesaurus&lt;/i&gt;[&lt;i&gt;EB&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].[2018- 03- 20].&lt;i&gt;http&lt;/i&gt;://&lt;i&gt;core&lt;/i&gt;.&lt;i&gt;ac&lt;/i&gt;.&lt;i&gt;uk&lt;/i&gt;/&lt;i&gt;download&lt;/i&gt;/&lt;i&gt;pdf&lt;/i&gt;/34600531.&lt;i&gt;pdf&lt;/i&gt;.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" title=" &lt;i&gt;BAJWA I S&lt;/i&gt;, &lt;i&gt;KARIM F&lt;/i&gt;, &lt;i&gt;NAEEM M A&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;A semi&lt;/i&gt;-&lt;i&gt;supervised approach for catchphrase classification in legal text documents&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Computers&lt;/i&gt;, 2017, 12 (5) :451-461." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A semi-supervised approach for catchphrase classification in legal text documents">
                                        <b>[14]</b>
                                         &lt;i&gt;BAJWA I S&lt;/i&gt;, &lt;i&gt;KARIM F&lt;/i&gt;, &lt;i&gt;NAEEM M A&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;A semi&lt;/i&gt;-&lt;i&gt;supervised approach for catchphrase classification in legal text documents&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Computers&lt;/i&gt;, 2017, 12 (5) :451-461.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_15" title=" &lt;i&gt;SILVESTRO L D&lt;/i&gt;, &lt;i&gt;SPAMPINATO D&lt;/i&gt;, &lt;i&gt;TORRISI A&lt;/i&gt;.&lt;i&gt;Automatic classification of legal textual documents using C&lt;/i&gt;4.5[&lt;i&gt;EB&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].[2018- 03- 20].&lt;i&gt;http&lt;/i&gt;://&lt;i&gt;www&lt;/i&gt;.&lt;i&gt;ittig&lt;/i&gt;.&lt;i&gt;cnr&lt;/i&gt;.&lt;i&gt;it&lt;/i&gt;/&lt;i&gt;Ricerca&lt;/i&gt;/&lt;i&gt;Testi&lt;/i&gt;/&lt;i&gt;Spampinato&lt;/i&gt;-&lt;i&gt;Di&lt;/i&gt;_&lt;i&gt;Silvestro&lt;/i&gt;-&lt;i&gt;Torrisi&lt;/i&gt;2009.&lt;i&gt;pdf&lt;/i&gt;." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic classification of legal textual documents using C4.5">
                                        <b>[15]</b>
                                         &lt;i&gt;SILVESTRO L D&lt;/i&gt;, &lt;i&gt;SPAMPINATO D&lt;/i&gt;, &lt;i&gt;TORRISI A&lt;/i&gt;.&lt;i&gt;Automatic classification of legal textual documents using C&lt;/i&gt;4.5[&lt;i&gt;EB&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].[2018- 03- 20].&lt;i&gt;http&lt;/i&gt;://&lt;i&gt;www&lt;/i&gt;.&lt;i&gt;ittig&lt;/i&gt;.&lt;i&gt;cnr&lt;/i&gt;.&lt;i&gt;it&lt;/i&gt;/&lt;i&gt;Ricerca&lt;/i&gt;/&lt;i&gt;Testi&lt;/i&gt;/&lt;i&gt;Spampinato&lt;/i&gt;-&lt;i&gt;Di&lt;/i&gt;_&lt;i&gt;Silvestro&lt;/i&gt;-&lt;i&gt;Torrisi&lt;/i&gt;2009.&lt;i&gt;pdf&lt;/i&gt;.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_16" title=" &lt;i&gt;KUSNER M J&lt;/i&gt;, &lt;i&gt;SUN Y&lt;/i&gt;, &lt;i&gt;KOLKIN N I&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;From word embeddings to document distances&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 32&lt;i&gt;nd International Conference on Machine Learning&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;JMLR&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;, 2015:957-966." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=From word embeddings to document distances">
                                        <b>[16]</b>
                                         &lt;i&gt;KUSNER M J&lt;/i&gt;, &lt;i&gt;SUN Y&lt;/i&gt;, &lt;i&gt;KOLKIN N I&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;From word embeddings to document distances&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 32&lt;i&gt;nd International Conference on Machine Learning&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;JMLR&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;, 2015:957-966.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_17" title=" &lt;i&gt;MIKOLOV T&lt;/i&gt;, &lt;i&gt;CHEN K&lt;/i&gt;, &lt;i&gt;CORRADO G&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Efficient estimation of word representations in vector space&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].&lt;i&gt;arXiv Preprint&lt;/i&gt;, 2013, 2013:&lt;i&gt;arXiv&lt;/i&gt;:1301.3781 (2013- 01- 16) [2013- 09- 07].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;arxiv&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;/&lt;i&gt;abs&lt;/i&gt;/1301.3781." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">
                                        <b>[17]</b>
                                         &lt;i&gt;MIKOLOV T&lt;/i&gt;, &lt;i&gt;CHEN K&lt;/i&gt;, &lt;i&gt;CORRADO G&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Efficient estimation of word representations in vector space&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;].&lt;i&gt;arXiv Preprint&lt;/i&gt;, 2013, 2013:&lt;i&gt;arXiv&lt;/i&gt;:1301.3781 (2013- 01- 16) [2013- 09- 07].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;arxiv&lt;/i&gt;.&lt;i&gt;org&lt;/i&gt;/&lt;i&gt;abs&lt;/i&gt;/1301.3781.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_18" title=" &lt;i&gt;MIKOLOV T&lt;/i&gt;, &lt;i&gt;SUTSKEVER I&lt;/i&gt;, &lt;i&gt;CHEN K&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Distributed representations of words and phrases and their compositionality&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 26&lt;i&gt;th International Conference on Neural Information Processing Systems&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;Curran Associates&lt;/i&gt;, 2013:3111-3119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed Representations of Words and Phrases and their Compositionality">
                                        <b>[18]</b>
                                         &lt;i&gt;MIKOLOV T&lt;/i&gt;, &lt;i&gt;SUTSKEVER I&lt;/i&gt;, &lt;i&gt;CHEN K&lt;/i&gt;, &lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Distributed representations of words and phrases and their compositionality&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 26&lt;i&gt;th International Conference on Neural Information Processing Systems&lt;/i&gt;.&lt;i&gt;New York&lt;/i&gt;:&lt;i&gt;Curran Associates&lt;/i&gt;, 2013:3111-3119.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_19" title=" &lt;i&gt;ZEILER M D&lt;/i&gt;, &lt;i&gt;FERGUS R&lt;/i&gt;.&lt;i&gt;Visualizing and understanding convolutional networks&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 13&lt;i&gt;th European Conference on Computer Vision&lt;/i&gt;.&lt;i&gt;London&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 2014:818-833." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">
                                        <b>[19]</b>
                                         &lt;i&gt;ZEILER M D&lt;/i&gt;, &lt;i&gt;FERGUS R&lt;/i&gt;.&lt;i&gt;Visualizing and understanding convolutional networks&lt;/i&gt;[&lt;i&gt;C&lt;/i&gt;]// &lt;i&gt;Proceedings of the&lt;/i&gt; 13&lt;i&gt;th European Conference on Computer Vision&lt;/i&gt;.&lt;i&gt;London&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 2014:818-833.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_20" title=" &lt;i&gt;GOMEZ&lt;/i&gt;-&lt;i&gt;PEREZ A&lt;/i&gt;, &lt;i&gt;FERNANDEZ&lt;/i&gt;-&lt;i&gt;LOPEZ M&lt;/i&gt;, &lt;i&gt;CORCHO O&lt;/i&gt;.&lt;i&gt;Ontological Engineering&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;London&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 2004:173-182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ontological Engineering">
                                        <b>[20]</b>
                                         &lt;i&gt;GOMEZ&lt;/i&gt;-&lt;i&gt;PEREZ A&lt;/i&gt;, &lt;i&gt;FERNANDEZ&lt;/i&gt;-&lt;i&gt;LOPEZ M&lt;/i&gt;, &lt;i&gt;CORCHO O&lt;/i&gt;.&lt;i&gt;Ontological Engineering&lt;/i&gt;[&lt;i&gt;M&lt;/i&gt;].&lt;i&gt;London&lt;/i&gt;:&lt;i&gt;Springer&lt;/i&gt;, 2004:173-182.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_21" title=" &lt;i&gt;SUN J J&lt;/i&gt;.&lt;i&gt;Jieba Chinese word segmentation tool&lt;/i&gt;[&lt;i&gt;CP&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;]. (2018- 01- 21) [2018- 06- 25].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;github&lt;/i&gt;.&lt;i&gt;com&lt;/i&gt;/&lt;i&gt;fxsjy&lt;/i&gt;/&lt;i&gt;jieba&lt;/i&gt;." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Jieba Chinese word segmentation tool[CP/OL]">
                                        <b>[21]</b>
                                         &lt;i&gt;SUN J J&lt;/i&gt;.&lt;i&gt;Jieba Chinese word segmentation tool&lt;/i&gt;[&lt;i&gt;CP&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;]. (2018- 01- 21) [2018- 06- 25].&lt;i&gt;https&lt;/i&gt;://&lt;i&gt;github&lt;/i&gt;.&lt;i&gt;com&lt;/i&gt;/&lt;i&gt;fxsjy&lt;/i&gt;/&lt;i&gt;jieba&lt;/i&gt;.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_22" title=" &lt;i&gt;LEVENSHTEIN V I&lt;/i&gt;.&lt;i&gt;Binary codes capable of correcting deletions&lt;/i&gt;, &lt;i&gt;insertions&lt;/i&gt;, &lt;i&gt;and reversals&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Soviet Physics Doklady&lt;/i&gt;, 1966, 10 (8) :707-710." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Binary Codes Capable of Correcting Deletions, Insertions and Reversals">
                                        <b>[22]</b>
                                         &lt;i&gt;LEVENSHTEIN V I&lt;/i&gt;.&lt;i&gt;Binary codes capable of correcting deletions&lt;/i&gt;, &lt;i&gt;insertions&lt;/i&gt;, &lt;i&gt;and reversals&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Soviet Physics Doklady&lt;/i&gt;, 1966, 10 (8) :707-710.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-21 10:13</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(05),1293-1298 DOI:10.11772/j.issn.1001-9081.2018102085            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于知识块摘要和词转移距离的高效司法文档分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">马建刚</a>
                                <a href="javascript:;">张鹏</a>
                                <a href="javascript:;">马应龙</a>
                </h2>
                    <h2>

                    <span>中国人民大学法学院</span>
                    <span>国家检察官学院</span>
                    <span>河南省人民检察院</span>
                    <span>华北电力大学控制与计算机工程学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着全国司法机关智能化建设的深入推进, 通过信息化建设应用所积累的海量司法文书为开展司法智能服务提供了司法数据分析基础。通过司法文书的相似性分析实现类案推送, 可以为司法人员提供智能辅助办案决策支持, 从而提高办案的质量和效率。针对面向通用领域的文本分类方法因没有考虑特定司法领域文本的复杂结构和知识语义而导致司法文本分类的效能低问题, 提出一种基于司法知识块摘要和词转移距离 (WMD) 的高效司法文档分类方法。首先为司法文书构建领域本体知识模型, 进而基于领域本体, 利用信息抽取技术获取司法文档中核心知识块摘要;然后基于司法文本的知识块摘要利用WMD进行司法文档相似度计算;最后利用<i>K</i>最近邻算法进行司法文本分类。以两个典型罪名的案件文档集作为实验数据, 与传统的WMD文档相似度计算方法进行对比, 实验结果表明, 所提方法能明显提高司法文本分类的正确率 (分别有5.5和9.9个百分点的提升) , 同时也降低了文档分类所需的时间 (速度分别提升到原来的52.4和89.1倍) 。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E6%85%A7%E6%A3%80%E5%8A%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智慧检务;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%86%E5%9F%9F%E6%9C%AC%E4%BD%93%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">领域本体模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相似度计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E5%9D%97%E6%91%98%E8%A6%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识块摘要;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E8%BD%AC%E7%A7%BB%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词转移距离;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    马建刚 (1977—) , 男, 河南郑州人, 高级工程师, 博士, CCF高级会员, 主要研究方向:大数据、智慧检务、智慧司法;;
                                </span>
                                <span>
                                    张鹏 (1995—) , 男, 河南周口人, 硕士研究生, CCF会员, 主要研究方向:自然语言处理、知识图谱;;
                                </span>
                                <span>
                                    *马应龙 (1976—) , 男, 陕西咸阳人, 教授, 博士生导师, 博士, CCF高级会员, 主要研究方向:人工智能、知识工程、大数据分析、服务计算、服务协同。电子邮箱yinglongma@gmail.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (2018YFC0830605, 2018YFC0831404);</span>
                                <span>中国博士后科学基金资助项目 (2016M591317);</span>
                    </p>
            </div>
                    <h1>Efficient judicial document classification based on knowledge block summarization and word mover's distance</h1>
                    <h2>
                    <span>MA Jiangang</span>
                    <span>ZHANG Peng</span>
                    <span>MA Yinglong</span>
            </h2>
                    <h2>
                    <span>School of Law, Renmin University of China</span>
                    <span>National Prosecutor College</span>
                    <span>People's Procuratorate of Henan Province</span>
                    <span>School of Control and Computer Engineering, North China Electric Power University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the deepening of intelligence construction of the national judicial organization, massive judicial documents accumulated through years of information technology application provide data analysis basis for developing judicial intelligent service. The quality and efficiency of case handling can be greatly improved through the analysis of the similarity of judicial documents, which realizes the push of similar cases to provide the judicial officials with intelligent assistant case handling decision support. Aiming at the low efficiency of most document classification approach for common domains in judicial document classification due to the lack of consideration of complex structure and knowledge semantics of specific judicial documents, an efficient judicial document classification approach based on knowledge block summarization and Word Mover's Distance (WMD) was proposed. Firstly, a domain ontology knowledge model was built for judicial documents. Secondly, based on domain ontology, the core knowledge block summarization of judicial documents was obtained by information extraction technology. Thirdly, WMD algorithm was used to calculate judicial document similarity based on knowledge block summary of judicial text. Finally, <i>K</i>-Nearest Neighbors (<i>K</i>NN) algorithm was used to realize judicial document classification. With the documents of two typical crimes used as experimental data, the experimental results show that the proposed approach greatly improves the accuracy of judicial document classification by 5.5 and 9.9 percentage points respectively with the speed of 52.4 and 89.1 times respectively compared to traditional WMD similarity computation algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=smart%20procuratorate&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">smart procuratorate;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=domain%20ontology%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">domain ontology model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=document%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">document classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=similarity%20computation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">similarity computation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=knowledge%20block%20summarization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">knowledge block summarization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Word%20Mover&#39;s%20Distance%20(WMD)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Word Mover's Distance (WMD) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    MA Jiangang, born in 1977, Ph. D. , senior engineer. His research interests include big data, smart procuratorate, wisdom justice. ;
                                </span>
                                <span>
                                    ZHANG Peng, born in 1995, M. S. candidate. His research interests include nature language processing, knowledge graph. ;
                                </span>
                                <span>
                                    MA Yinglong, born in 1976, Ph. D. , professor. His research interests include artificial intelligence, knowledge engineering, big data analysis, service computing, service collaboration.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Key R&amp;D Program of China (2018YFC0831404);</span>
                                <span>the China Postdoctoral Science Foundation (2016M591317);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="50">随着全国司法机关大数据战略的深入实施, 国家检察机关的“智慧检务”、法院系统的“智慧法院”等智能化建设正在逐步推进<citation id="164" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。首先是2014年1月统一业务应用系统部署上线以来积累了海量的数据, 截至2016年12月31日, 统一业务应用系统中的全国检察机关案件数据量已突破1 100万件、电子卷宗200余万卷、各类法律文书达1亿多份;全国各级检察机关在人民检察院案件信息公开网发布案件程序性信息4 494 548条、重要案件信息204 738条、法律文书1 587 940份。司法机关通过多年的信息化建设应用已经积累了海量的司法文书, 如最高检察院检察信息公开网2016年一年就发布起诉书779 478份, 最高法院的中国裁判文书网截止2018年6月已发布判决书4 677万份, 为开展司法智能服务提供了数据基础。</p>
                </div>
                <div class="p1">
                    <p id="51">海量的司法文书包含着丰富的有价值的信息, 通过挖掘分析为检察官和法官提供智能辅助办案服务。对法院来说, 可以为法官提供与当前案件相似的以往案件的判决文档, 通过类案推送为当前案件的审判提供参考;对检察院而言, 可以为公诉人对办理案件的量刑建议提供参考, 有效防止同案不同诉<citation id="165" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52">基于文本相似度计算的海量司法文本自动化分类技术为辅助办案提供了必要的、高效的智能化手段, 可以将相同判决结果的司法文档分成一类。当法官和检察官处理一个案件的司法文档时, 可以将其自动分类的结果与他们给出的人工的判决结果进行比较, 避免“同案不同判”现象的发生, 进而给法官裁判提供智能辅助, 也为法院的院庭长履行监管职责、统一裁判尺度提供技术支撑。</p>
                </div>
                <div class="p1">
                    <p id="53">文本自动分类在自然语言处理领域中是一个比较经典的问题。在传统文本分类方法中, 文本分类问题通常采用特征工程和分类器等方法<citation id="166" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。特征工程分为文本预处理、特征提取、文本表示三个部分, 最终目的是把文本转换成计算机可理解的格式, 并封装足够用于分类的信息, 即很强的特征表达能力<citation id="173" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。常用的方法有词频-逆文档频率 (Term Frequency-Inverse Document Frequency, TF-IDF) 、词袋模型 (Bag Of Words, BOW) <citation id="167" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、向量空间模型 (Vector Space Model, VSM) <citation id="174" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>、潜在狄利克雷分布 (Latent Dirichlet Allocation, LDA) <citation id="168" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>主题模型等。然而这些方法往往由于其文本表示通常是高维度高稀疏而导致特征表达能力很弱, 因此针对司法文本的分类结果并不理想。许多研究基于机器学习方法的分类器来分类司法文档<citation id="175" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 如<i>K</i>最近邻 (<i>K</i>-Nearest Neighbors, <i>K</i>NN) 、支持向量机 (Support Vector Machine, SVM) <citation id="176" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>、最大熵<citation id="169" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、决策树<citation id="170" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>等。虽然词向量 (Word to Vector, Word2Vec) <citation id="171" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>分布表示模型可以通过神经网络模型训练和重构词的语义环境<citation id="177" type="reference"><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>, 能以向量形式表示词且可以表达词之间相似度的差异, 但是它无法清晰表达文档级别的语义<citation id="172" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="54">传统的面向通用领域的文本分类方法因没有考虑特定司法领域文本的复杂结构和知识语义而导致司法文本分类的效能很低, 很难直接应用到面向特定司法领域的司法文书分类服务中。一方面, 司法文书的文本分类应用涉及到刑事量刑等利益密切攸关的问题, 因此对分类结果的准确率有着极高的要求 (如至少90%以上的分类准确率甚至更高) , 因此需要结合司法领域的特定知识对传统的方法进行性能改进; 另一方面, 司法领域文本数量大且文本结构复杂。现有司法文书中涉及到各种各样的不同案件, 不同的案件涉及到不同的犯罪情节和量刑判决;在事实认定和量刑判决方面也存在较大差异;不同犯罪的司法文档在情节特征和法律文书书写规范上存在较大差异。</p>
                </div>
                <div class="p1">
                    <p id="55">针对上述问题, 本文提出一种基于司法知识块摘要和词转移距离 (Word Mover’s Distance, WMD) 模型<citation id="178" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的高效司法文档分类方法, 其关键在于通过信息抽取技术获取司法文档的核心知识块摘要。一方面, 知识块摘要尽可能地保留了司法文档核心语义知识, 去除了与分类不相关的噪声信息, 从而试图提升分类准确率; 另一方面, 知识块摘要与其原始的司法文本相比, 在文档容量上大幅降低了, 这也无疑会减少后续文本相似度计算和文本分类算法的执行时间, 从而提升总体的文本分类效率。</p>
                </div>
                <div class="p1">
                    <p id="56">本文首先为司法文书构建领域本体知识模型, 进而基于领域本体, 利用信息抽取技术获取司法文档中核心知识块摘要; 然后基于司法文本的知识块摘要利用WMD算法进行司法文档相似度计算; 最后利用<i>K</i>NN算法进行司法文本分类。本文以两个典型罪名的案件数据进行了相关实验验证, 实验结果表明, 同传统的WMD文档相似度计算方法相比较而言, 本文方法能明显提高司法文本分类的正确率, 同时也大幅降低了文档分类所需的时间。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">1 总体框架</h3>
                <div class="p1">
                    <p id="58">本文采用方法的总体框架如图1所示。首先, 通过司法领域专家与领域模型知识表示专家共同合作, 着眼于司法领域已有的业务知识和数据信息, 为司法文书构建领域本体知识模型。本体知识模型从两个角度进行构建:一方面, 考虑到司法文书领域的共同特征为其构建顶层本体, 包含了各种司法文书的一些共有属性;另一方面, 针对不同类型的司法文书为其构建领域具体本体, 包含该类型文书特有的一些属性。然后领域本体和顶层本体可以一种可扩展方式进行无缝集成, 最终形成完整的司法文书领域知识模型。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法总体框架" src="Detail/GetImg?filename=images/JSJY201905009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法总体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Overall architecture of the proposed approach</p>

                </div>
                <div class="p1">
                    <p id="60">基于领域本体, 利用信息抽取技术获取司法文档中核心知识块摘要。一个司法文档的知识块摘要, 实际上指的是从该司法文档中提取的最能反映该文档内容和特征的某种特定类型的元素所组成的文本集合。组成元素类型可以是短语、句子或段落等。不失一般性, 本文的司法知识块摘要基于段落类型进行抽取。另外, 考虑到司法文档中的数字信息对于定罪和量刑至关重要, 因此需要根据现有中国法律, 采用基于规则的方法添加一些附加知识到知识块。</p>
                </div>
                <div class="p1">
                    <p id="61">接下来, 首先将司法文档和中文维基百科文本作为语料库, 采用基于人工神经网络的方法为语料库中的每个词构建对应Word2Vec向量; 然后, 基于司法文本的知识块摘要, 将每一个文档知识块摘要看成是一个词的集合, 进一步利用WMD模型, 计算任意两个司法文档的知识块摘要之间的相似度; 基于该相似度, 最后利用<i>K</i>NN算法进行司法文本分类。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">2 司法文书领域知识模型</h3>
                <div class="p1">
                    <p id="63">一个司法文书中包含大量信息, 但文档中不同部分的信息价值对分析司法文档是不一样的, 因此, 构造一个司法文书领域的知识模型对分析司法文书有很大帮助。于是基于犯罪构成理论构建司法文书领域知识模型, 并利用本体知识表示技术<citation id="179" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>进行领域知识建模。本体是一种形式化共享概念化的规范, 可以显式地表示领域知识用于知识重用、共享和推理等服务。司法领域本体知识模型从两个角度进行构建:一个是顶层本体, 用于描述据司法文书领域的共同特征和共有属性; 另一个是领域具体本体, 它是针对不同类型的司法文书应用的, 包含该类型文书特有的一些属性。领域本体和顶层本体可以一种可扩展方式进行无缝集成, 可以为具体领域的司法文书知识提供共享概念化模型。</p>
                </div>
                <div class="p1">
                    <p id="64">对于司法判决书这一文书类型, 以危险驾驶罪判决书作为其具体领域, 如图2所示。对于判决书来说, 其顶层本体模型包含主体、客体、主观方面、客观方面、判决结果、刑事管辖权等方面。客观方面又包括危害行为和危害结果;同时还包括文书基本信息 (如文号) 和判决结果信息。刑法规定刑罚分为主刑和附加刑。主刑是对犯罪分子适用的主要刑罚, 它只能独立使用, 不能相互附加适用。任何判决书都具有这些基本特征, 无论其涉及危险驾驶还是交通肇事等其他的具体领域。</p>
                </div>
                <div class="p1">
                    <p id="65">对于领域具体本体而言, 其内容特征较顶层本体而言则更为具体。比如, 主刑可以根据具体案例的不同可以是管制、拘役、有期徒刑、无期徒刑和死刑等类型。附加刑可能包括罚金、剥夺政治权利、没收财产和驱逐出境。文档基本信息、主体、客观方面、判决结果等部分类似的也都更为具体, 如文档基本信息包括判决书文号、审判机关、公诉机关、审判员和审判时间等信息。主体和客观方面这两个概念来自刑法中的犯罪构成要件: 主体则会具体指被告人的信息, 包括姓名、职业、年龄、出生日期、是否有前科、是否累犯等信息; 客观方面会涉及机动车辆类型、案发道路类型, 其中机动车辆类型包括客车、货车、轿车和摩托车等, 道路类型包括公路、广场、公共停车场等, 危害行为包括醉酒驾驶、追逐竞驶等。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905009_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 危险驾驶罪的判决书本体领域模型" src="Detail/GetImg?filename=images/JSJY201905009_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 危险驾驶罪的判决书本体领域模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905009_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Domain ontology model for judgment documents of dangerous driving</p>

                </div>
                <h3 id="67" name="67" class="anchor-tag">3 司法文档知识块摘要</h3>
                <div class="p1">
                    <p id="68">本文的分类标准依据是司法文档中的客观方面事实和判决结果, 而文档基本信息等内容对于分类而言是一种无效的信息, 过多的无效信息无疑会增加噪声而对分类的准确性造成影响, 而且分类算法也会因为这些无效信息而大幅增加了不必要的分类执行时间, 因此排除无效信息对分类的准确度和效率有重要的意义。</p>
                </div>
                <div class="p1">
                    <p id="69">司法文档的知识块摘要包括两个步骤: 一是抽取出客观方面部分, 客观方面部分的内容主要决定了案件的判决结果; 二是抽取出司法文书中的判决结果部分, 并将标准化判决结果添加到知识块摘要中, 依此为司法文书分类, 获得可供实验用的带标签的数据集。因为司法文书在书写规范和书写风格上因人而异、没有统一规定, 因此核心知识块的内容散布在文档的不同位置, 需要通过信息抽取技术进行摘要。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">3.1 <b>客观方面的抽取</b></h4>
                <div class="p1">
                    <p id="71">司法文书作为特定领域的半结构化文档, 其用词和行文方式都有某种规律, 因此本文采用基于规则匹配的方法来抽取客观方面部分, 并构造了所需的规则库。</p>
                </div>
                <div class="p1">
                    <p id="72">具体知识块摘要过程利用领域具体本体同顶层本体结合的方式进行信息抽取。首先, 通过领域具体本体中与客观方面和判决结果对应的相关的概念术语, 通过基于这些概念术语的统计分析从司法文档中找出与之最相关的段落。</p>
                </div>
                <div class="p1">
                    <p id="73">具体来说, 文中使用符号<i>C</i><sub>oa</sub>、 <i>C</i><sub>sa</sub>和<i>C</i><sub>jr</sub>分别代表司法文档中的客观方面、主观方面以及判决结果的集合。 以危险驾驶判决书为例, <i>C</i><sub>oa</sub>={公交汽车, …, 公共停车场, 竞逐驾驶, …, 醉驾}。一个初始的危险驾驶判决书文档<i>D</i>, 记为<i>D</i>={<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub>, …, <i>P</i><sub><i>n</i></sub>}, 其中<i>P</i><sub><i>i</i></sub> (1≤<i>i</i>≤<i>n</i>) 指的是<i>D</i>中的每一个段落。</p>
                </div>
                <div class="p1">
                    <p id="74">本文提出一个知识块摘要方法, 如算法1所示, 其中, <i>C</i> 代表和知识块相关的所有叶子概念的集合, <i>C</i><sub>oa</sub>、 <i>C</i><sub>sa</sub>和<i>C</i><sub>jr</sub>指的是本体中所有和客观方面、主观方面以及判决结果相关的叶子概念的集合, 符号<i>count</i><sub><i>i</i></sub>用于记录第<i>i</i>个段落中与<i>C</i><sub><i>x</i></sub>相关的术语的个数。每一个知识块<i>B</i><sub><i>x</i></sub>包含了针对<i>C</i><sub><i>x</i></sub>的最大数量的段落的集合, <i>x</i>属于集合{oa, sa, jr}。</p>
                </div>
                <div class="p1">
                    <p id="75">值得注意的是, 中文句子需要进行分词。本文采用一个较为优秀的JieBa分析工具<citation id="180" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>进行中文分词。算法1中, WORD_SEG () 指代一个分词函数, <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>w</mi><mo>|</mo></mrow></mrow></math></mathml>代表字符串<i>w</i>的长度。</p>
                </div>
                <div class="p1">
                    <p id="77">函数LEV () 用于计算两个字符串之间的Levenshtein编辑距离<citation id="181" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 主要目的是考虑到中文字之间的近义词和同义词计算问题, 编辑距离定义如式 (1) 所示:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>l</mi><mi>e</mi><mi>v</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>max</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>min</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>min</mi><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>l</mi><mi>e</mi><mi>v</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>l</mi><mi>e</mi><mi>v</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>l</mi><mi>e</mi><mi>v</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≠</mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></msub></mtd></mtr></mtable></mrow><mo>, </mo><mtext> </mtext><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中, <i>lev</i><sub><i>a</i>, <i>b</i></sub> (<i>i</i>, <i>j</i>) 表示字符串<i>a</i>的第<i>i</i>个字同串<i>b</i>的第<i>j</i>个字的距离。如果<i>a</i>和<i>b</i>是相同的, 那么距离为0, 完全不相同则为1。在算法1中, 函数<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>E</mi><mi>V</mi><mo stretchy="false"> (</mo><mi>w</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>l</mi><mi>e</mi><mi>v</mi><msub><mrow></mrow><mrow><mi>w</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false"> (</mo><mo stretchy="false">|</mo><mi>w</mi><mo stretchy="false">|</mo><mo>, </mo><mo stretchy="false">|</mo><mi>t</mi><mo stretchy="false">|</mo><mo stretchy="false">) </mo></mrow><mrow><mi>max</mi><mo stretchy="false"> (</mo><mo stretchy="false">|</mo><mi>w</mi><mo stretchy="false">|</mo><mo>, </mo><mo stretchy="false">|</mo><mi>t</mi><mo stretchy="false">|</mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>。本文进一步设定一个阈值<i>δ</i>, 如果<i>LEV</i> (|<i>w</i>|, |<i>t</i>|) &lt;<i>δ</i>, 那么, 字符串<i>w</i>能匹配上字符串<i>t</i>。</p>
                </div>
                <div class="p1">
                    <p id="81">算法1 知识块摘要 (Knowledge Block Summarization) 。</p>
                </div>
                <div class="area_img" id="182">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201905009_18200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="119" name="119">3.2 <b>基于规则的信息抽取、标准化及知识添加</b></h4>
                <div class="p1">
                    <p id="120">本文采用基于规则的方法抽取审判结果, 通过大量的正则表达式规则进行相关的信息抽取。例如, 在司法文档中, 审判结果具有固定的用语和结构, 即被告人+姓名+犯+罪名+判处+判决结果, 利用这个规则, 很容易就能提取出判决结果。再比如, 不同的文书包含“导致…死亡…人”“致…人死亡”等涵义相同表达方式不同的用语。通过调研大量的判决书文本, 找出一些通用表达方式并为其建立正则表达式。</p>
                </div>
                <div class="p1">
                    <p id="121">另外, 本文所抽取的审判结果主要是主刑部分, 这样就能得到形如“有期徒刑五年六个月”的判决结果部分。这里的“五年六个月”中的五和六在文档中是汉字而不是阿拉伯数字, 审判结果的标准化指的是将汉字转化为阿拉伯数字, 同时将月转换为年, 即将“五年六个月”转化为5.5年, 添加到知识块摘要中。这样做是为了方便根据刑期对司法文档进行分类。</p>
                </div>
                <h3 id="122" name="122" class="anchor-tag">4 基于WMD模型的司法文档分类</h3>
                <div class="p1">
                    <p id="123">本文对司法文档分类采用了三个步骤:首先, 通过语料库进行中文分词并训练其词向量;然后, 利用WMD模型计算每个司法文档的知识块摘要之间的相似度距离;最后, 使用<i>K</i>NN模型对知识块摘要进行文本分类从而间接地确定初始文档的分类。</p>
                </div>
                <div class="p1">
                    <p id="124">WMD模型是一种最近被提出来的用于度量文本相似度的算法, 其作者在论文中将之与几种常用的相似度度量算法, 如BOW、TF-IDF、LDA、潜在语义索引 (Latent Semantic Index, LSI) 等进行了比较, 实验结果显示, WMD模型在文本分类任务中, 分类准确率明显优于其他几种算法, 因此本文选择WMD模型进行文本的相似度度量。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">4.1 <b>基于</b>Word2Vec<b>的词向量模型构建</b></h4>
                <div class="p1">
                    <p id="126">本文采用Word2Vec模型为司法文档构建词向量模型。所训练的语料库结合一部分司法文档以及来自中文维基百科文本。词向量具有良好的语义特性, 也是表示词语特征的常用方式。Word2Vec模型可以将所有的词向量化, 以表示、度量和挖掘词与词之间的定量关系。利用深度较浅的双层神经网络进行训练可以为语料库中的每个词产生对应的词向量。利用Word2Vec词向量模型, 可以进一步分析计算词与词之间的语义相关性。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">4.2 <b>基于</b>WMD<b>模型的文本相似度计算</b></h4>
                <div class="p1">
                    <p id="128">WMD是一种距离度量的定义模型, 可以用于自然语言处理领域的文本向量的相似度计算。在计算两个文档之间的WMD距离时, 首先, 使用JieBa分词工具对中文司法文档进行分词, 将一个汉字序列切分成一个一个单独的词。</p>
                </div>
                <div class="p1">
                    <p id="129">WMD使用正则化的词袋模型 (normalized BOW, nBOW) 表示文档, 使用<b><i>d</i></b>∈<b>R</b><sup><i>n</i></sup>表示一篇文档, 其中<i>n</i>表示nBOW模型的长度, 即数据集中不同词的数目 (去除停用词) , 代表文档中第<i>i</i>个词的<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>c</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>, 其中<i>c</i><sub><i>i</i></sub>是第<i>i</i>个词在该文档中出现的次数。同时, WMD使用了词向量技术, 这样两个词<i>i</i>和<i>j</i>之间的距离可以自然地用二者在词向量空间的欧氏距离表示, 即<i>c</i> (<i>i</i>, <i>j</i>) =‖<b><i>x</i></b><sub><i>i</i></sub>-<b><i>x</i></b><sub><i>j</i></sub>‖<sub>2</sub>, 为了避免混淆词距离与文档距离, 将<i>c</i> (<i>i</i>, <i>j</i>) 称为词转移代价。然后通过词转移代价可以进一步计算文档之间的距离。具体做法是:分别用<b><i>d</i></b>和<b><i>d</i></b>′表示两篇不同的文档, 令<b><i>d</i></b>中的每个词都可以部分或全部的转化为<b><i>d</i></b>′中的任何词, 那么将<b><i>d</i></b>中的全部词转化为<b><i>d</i></b>′中的全部词所花费的最小代价即是两个文档之间的距离。这里用一个流量矩阵<b><i>T</i></b>∈<b>R</b><sup><i>n</i>×<i>n</i></sup>表示<b><i>d</i></b>中的词向<b><i>d</i></b>′中的词的转化情况, <i>T</i><sub><i>ij</i></sub>表示<b><i>d</i></b>中第<i>i</i>个词向<b><i>d</i></b>′中第<i>j</i>个词的转化量, 为了保证<b><i>d</i></b>完全地转化为了<b><i>d</i></b>′, 需要满足<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>Τ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>, 即词<i>i</i>转化到<b><i>d</i></b>′中各词的量的总和等于<i>d</i><sub><i>i</i></sub>, 同样地, 还需令<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Τ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>d</mi><msub><mrow></mrow><msup><mi>j</mi><mo>′</mo></msup></msub></mrow></math></mathml>, 这是为了满足<b><i>d</i></b>中各词转化到词<i>j</i>的量的总和等于<i>d</i><sub><i>j</i></sub>′。在满足以上两个约束同时, 两个文档之间的距离可表示为:</p>
                </div>
                <div class="p1">
                    <p id="133" class="code-formula">
                        <mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>Τ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>Τ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mi>c</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="134">这样计算得到的两个文档之间的距离可以表示文档的相似度;而且距离越小, 文档之间越相似。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">4.3 <b>基于</b><i>K</i>NN<b>的文档分类</b></h4>
                <div class="p1">
                    <p id="136">本文使用K<i>NN</i>算法进行司法文档分类, 考虑到K<i>NN</i>算法简单高效。其核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别, 则该样本也属于这个类别, 并具有这个类别上样本的特性。通过<i>WMD</i>计算文档之间的距离, 来找到待分类文档的k个最相邻的文档, 从而实现文档分类, 在分类中只需要优化K<i>NN</i>算法中的k, 除此之外没有其他需要优化的参数。</p>
                </div>
                <h3 id="137" name="137" class="anchor-tag">5 司法文档分类实验与结果分析</h3>
                <h4 class="anchor-tag" id="138" name="138">5.1 <b>司法文档数据集</b></h4>
                <div class="p1">
                    <p id="139">实验所用司法文档为刑事案件判决书, 来源于中国裁判文书网 (<i>http</i>://<i>wenshu</i>.<i>court</i>.<i>gov</i>.<i>cn</i>/) , 共1 302份文档, 其中交通肇事罪有615份, 危险驾驶罪687份。危险驾驶罪的判决书中主刑部分有两种:拘役和有期徒刑 (数罪并发情况) 。因此根据主刑分类将危险驾驶罪文档分成两类, 各类文档数量分别是340份和337份。交通肇事罪的主刑分为有期徒刑和拘役两种, 但在交通肇事罪中若出现被告人逃逸致人死亡的情节时, 则有期徒刑的刑期必然超过七年, 因此将交通肇事罪文档分为三类, 即拘役、有期徒刑刑期七年以下和有期徒刑七年以上, 各类文档数量分别是250份、250份和115份。这样使得数据集预先就整理成了带标签的实验数据。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140">5.2 <b>司法文档</b><i>Word</i>2<i>Vec</i><b>词向量训练语料库</b></h4>
                <div class="p1">
                    <p id="141"><i>WMD</i>算法将文档中的词用词向量表示, 本文在一份由一万份包括各种罪名的司法文档和中文维基百科语料库组成的语料库上训练了一个词向量模型。在训练之前, 移除了停用词, 最终在包括总共超过3百万不同词的数据集上训练并得到了一个维度为400的词向量模型。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142">5.3 <b>实验设置与实验指标</b></h4>
                <div class="p1">
                    <p id="143">本实验使用<i>Python</i>语言进行编程, 在单核性能3.6 <i>GHz</i>的<i>CPU</i>上进行司法文档分类实验。实验指标则分别用来比较知识块摘要前后分类算法的分类准确率、词的平均数目以及平均执行时间。</p>
                </div>
                <div class="p1">
                    <p id="144">论文进行如下4组实验:</p>
                </div>
                <div class="p1">
                    <p id="145">1) 基于危险驾驶罪原始判决书文档, 进行<i>WMD</i>计算和K<i>NN</i>分类。</p>
                </div>
                <div class="p1">
                    <p id="146">2) 基于交通肇事罪原始判决书文档, 进行<i>WMD</i>计算和K<i>NN</i>分类。</p>
                </div>
                <div class="p1">
                    <p id="147">3) 基于危险驾驶罪文档的知识块摘要, 进行<i>WMD</i>计算和K<i>NN</i>分类。</p>
                </div>
                <div class="p1">
                    <p id="148">4) 基于交通肇事罪文档的知识块摘要, 进行<i>WMD</i>计算和K<i>NN</i>分类。</p>
                </div>
                <div class="p1">
                    <p id="149">对于每组实验, 使用了重复随机子抽样验证的方法, 每次将数据集随机以4 ∶1的比例分为训练集和验证集, 得出每次的实验结果, 共重复5次, 之后算得平均实验结果。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">5.4 <b>实验结果分析</b></h4>
                <div class="p1">
                    <p id="151">图3展示了使用K<i>NN</i>算法进行司法文档分类时, 不同的<i>k</i>值所取得的分类准确率, 本文在4组实验中分别记录了<i>k</i>值取2～20时的分类结果, 在各组实验中, 取使分类准确率最高的值为相应的<i>k</i>值, 因为数据集的不同以及经过知识块摘要后数据的变化, 各组实验的<i>k</i>值是不同的。4组实验具体如5.3节所述, 其<i>k</i>值分别取7, 19, 4, 17。</p>
                </div>
                <div class="p1">
                    <p id="152">图4展示了算法在分类准确率方面的实验结果, 可以看出, 在原始的司法文档上使用WMD算法已经取得了一个较高的正确率, 危险驾驶罪上的分类准确率达到了84.8%, 交通肇事罪上的分类准确率达到了82.4%, 证明了这种分类方法的可行性。在WMD算法的基础上加入领域知识之后, 两个司法文档数据集上的分类准确率都获得了很大的提高, 其中危险驾驶罪上的分类准确率达到了90.3% (提高了5.5个百分点) , 交通肇事罪上的分类准确率达到了92.3% (提高了9.9个百分点) , 这证明了本文建立的司法文书领域知识模型对改善分类效果是有显著帮助的。</p>
                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905009_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同k值下的分类准确率" src="Detail/GetImg?filename=images/JSJY201905009_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同<i>k</i>值下的分类准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905009_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Classification accuracy under different <i>k</i> values</p>

                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905009_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 针对危险驾驶和交通肇事两种罪名的准确率比较" src="Detail/GetImg?filename=images/JSJY201905009_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 针对危险驾驶和交通肇事两种罪名的准确率比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905009_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Accuracy comparison for two crimes of dangerous driving and traffic accident</p>

                </div>
                <div class="p1">
                    <p id="155">表1比较了知识块摘要前后司法问文所包含的词的平均数目, 可以发现本文的基于信息抽取的知识块摘要方法可以有效减小待训练文本的规模。例如, 危险驾驶罪判决书文档从平均每个文档包含278词在知识块摘要后变成包含98个词, 交通肇事罪判决书文档从平均每个文档包含304词在知识块摘要后变成包含94个词。</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表</b>1 <b>知识块摘要前后判决书文档中词的平均数目</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Average number of Chinese words after knowledge block summarization</p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td rowspan="2"><br />罪名</td><td colspan="2"><br />平均词数</td><td rowspan="2"> (<i>n</i><sub>2</sub>/<i>n</i><sub>1</sub>) /%</td></tr><tr><td><br />原始文档<i>n</i><sub>1</sub></td><td>知识块摘要<i>n</i><sub>2</sub></td></tr><tr><td><br />危险驾驶罪</td><td>278</td><td>98</td><td>35.2</td></tr><tr><td><br />交通肇事罪</td><td>304</td><td>94</td><td>30.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">另外, 结合图4和表1也可以发现, 在交通肇事罪文档分类上, 基于知识块摘要的文本分类准确率获得了比在危险驾驶罪文档上更大的提高, 这极有可能与原始文档中的无效信息的比重有关。交通肇事罪经知识抽取之后得到的词的数目占原文档的30.9%, 而危险驾驶罪占原文档的35.2%, 这意味着交通肇事罪原始文档中含有更多的无效信息。</p>
                </div>
                <div class="p1">
                    <p id="158">表2记录了完成一次分类所需的平均时间, 可以看到在结合领域知识之后, 危险驾驶罪文档的分类速度提高到原来的52.4倍, 交通肇事罪文档的分类速度更是提高到原来的89.1倍, 如此巨大的速度提升, 对司法文档分类具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="159">基于知识块摘要的司法文档分类对分类效果的提升不仅反映在更高的分类准确率上, 更显著的优点是对分类效率的提升, 大幅节约了分类算法的执行时间。究其原因, 考虑到WMD模型的平均计算复杂度<i>O</i> (<i>p</i><sup>3</sup> log <i>p</i>) 是相当高的, 其中<i>p</i>是文档中不相同的词的数目;而基于知识块摘要进行计算, 根据表1可以发现, <i>p</i>值会减少到原来的1/3左右, 因此带来了高达几十倍的速度提升。</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表</b>2 <b>知识块摘要前后司法文书分类平均时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Average running time of document classification before and after knowledge block summarization</p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />罪名</td><td>原始文档<i>t</i><sub>1</sub>/s</td><td>知识块摘要<i>t</i><sub>2</sub>/s</td><td><i>t</i><sub>1</sub>/<i>t</i><sub>2</sub></td></tr><tr><td><br />危险驾驶罪</td><td>155 190</td><td>2 961</td><td>52.4</td></tr><tr><td><br />交通肇事罪</td><td>177 704</td><td>1 994</td><td>89.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="161">WMD模型的作者在其论文中, 选取了7种常用且效果较好的相似度度量算法与WMD模型进行比较, 这7种算法分别是Best Match25、TF-IDF、BOW、边缘降噪自编码器 (Marginalized Stacked Denoising Autoencoder, mSDA) 、LDA、LSI、Componential Counting Grid。实验结果显示WMD算法的分类准确率优于这7种常用算法, 证明了WMD算法相对于当前其他算法的优势, 因此本文中不再与这些算法进行比较, 而是将结合知识块摘要的WMD模型与原WMD模型进行比较, 实验结果显示, 本文提出的结合知识块摘要的WMD模型在分类准确率和效率方面均优于原WMD模型。</p>
                </div>
                <h3 id="162" name="162" class="anchor-tag">6 结语</h3>
                <div class="p1">
                    <p id="163">本文针对司法文书的相似性分析实现类案推送并为司法人员提供智能辅助办案服务的应用场景, 建立了司法文书的领域本体知识模型以及司法文书语义信息抽取方法, 并基于该模型将<i>WMD</i>算法应用到司法领域的文档分类, 进行了两个典型罪名的案件数据的验证, 实验结果表明该方法明显提高了分类的正确率, 且大幅降低了分类所需的时间。下一步将把该领域知识模型扩展到盗窃罪、故意伤害罪等常用罪名并进行系统验证。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787510219306000&amp;v=MjIzOTlYWEZxekdiYTVIdFBOcG94Rll1c1BEQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bm5VN2ZMSkY0&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 马建刚.检察实务中的大数据[<i>M</i>].北京:中国检察出版社, 2017:17-23. (<i>MA J G</i>.<i>Procuratorial Big Data</i>[<i>M</i>].<i>Beijing</i>:<i>China Procurational Press</i>, 2017:17-23.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An ontological Chinese legal consultation system">

                                <b>[2]</b> <i>ZHANG N</i>, <i>PU Y</i>, <i>YANG S</i>, <i>et al</i>.<i>An ontological Chinese legal consultation system</i> [<i>J</i>].<i>IEEE Access</i>, 2017, 5:18250-18261.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature Engineering for Machine Learning">

                                <b>[3]</b> <i>CASARI A</i>, <i>ZHENG A</i>.<i>Feature Engineering for Machine Learning</i>[<i>M</i>].<i>Sebastopol</i>, <i>CA</i>:<i>O</i>'<i>Reilly Media</i>, 2018:247-251.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combination of Feature Engineering and Ranking Models for Paper-author Identification in Kdd Cup 2013">

                                <b>[4]</b> <i>LI C L</i>, <i>SU Y C</i>, <i>LIN T W</i>, <i>et al</i>.<i>Combination of feature engineering and ranking models for paper</i>-<i>author identification in KDD Cup</i> 2013[<i>C</i>]// <i>Proceedings of the</i> 2013 <i>KDD Cup</i> 2013 <i>Workshop</i>.<i>New York</i>:<i>ACM</i>, 2013:<i>Article No</i>.2.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries">

                                <b>[5]</b> <i>XU Y</i>, <i>HONG K</i>, <i>TSUJII J</i>, <i>et al</i>.<i>Feature engineering combined with machine learning and rule</i>-<i>based methods for structured information extraction from narrative clinical discharge summaries</i>[<i>J</i>].<i>Journal of the American Medical Informatics Association</i>, 2012, 19 (5) :824-832.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7020C9A37D58E13774EFD52F52322A49&amp;v=MzI1NTBmQnJMVTA1dHBoekx1N3dLcz1OaWZPZmJTNEhORy9wdjVHWTU4S0JBazR6QkVVN2tvTFBIcmcyaGMzZXJDV05MNldDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> <i>GALGANI F</i>, <i>COMPTON P</i>, <i>HOFFMANN A</i>.<i>LEXA</i>:<i>building</i><i>knowledge bases for automatic legal citation classification</i>[<i>J</i>].<i>Expert Systems with Applications</i>, 2015, 42 (17) :6391-6407.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000024403&amp;v=MTY5NDF0ak5yNDlGWk9rTENIdzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lLRjBRYWhFPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> <i>SALTON G</i>, <i>WONG A</i>, <i>YANG C S</i>.<i>A vector space model for automatic indexing</i>[<i>J</i>].<i>Communications of the ACM</i>, 1975, 18 (11) :613-620.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Phrase-based document similarity based on an index graph model">

                                <b>[8]</b> <i>HAMMOUDA K</i>, <i>KAMEL M</i>.<i>Phrase</i>-<i>based document similarity</i><i>based on an index graph model</i>[<i>C</i>]// <i>Proceedings of the</i> 2002 <i>IEEE International Conference on Data Mining</i>.<i>Washington</i>, <i>DC</i>:<i>IEEE Computer Society</i>, 2002:203-210.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Latent Dirichlet allocation">

                                <b>[9]</b> <i>BLEI D M</i>, <i>NG A Y</i>, <i>JORDAN M I</i>, <i>et al</i>.<i>Latent Dirichlet allocation</i>[<i>J</i>].<i>Journal of Machine Learning Research</i>, 2003, 3 (4/5) :993-1022.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Document categorization in legal electronic discovery: Computer classification vs. manual review">

                                <b>[10]</b> <i>ROITBLAT H L</i>, <i>KERSHAW A</i>, <i>OOT P</i>.<i>Document categorization in legal electronic discovery</i>:<i>computer classification vs</i>.<i>manual review</i>[<i>J</i>].<i>Journal of the Association for Information Science and Technology</i>, 2010, 61 (1) :70-80.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic document classification in integrated legal content collections">

                                <b>[11]</b> <i>NOORTWIJK K V</i>, <i>NOORTWIJK K C</i>.<i>Automatic document classification in integrated legal content collections</i>[<i>C</i>]// <i>Proceedings of the</i> 16<i>th International Conference on Artificial Intelligence and Law</i>.<i>New York</i>:<i>ACM</i>, 2017:129-134.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploring the use of text classification in the legal domain">

                                <b>[12]</b> <i>SULEA O</i>, <i>ZAMPIERI M</i>, <i>MALMASI S</i>, <i>et al</i>.<i>Exploring the use of text classification in the legal domain</i>[<i>J</i>/<i>OL</i>].<i>arXiv Preprint</i>, 2017, 2017:<i>arXiv</i>:1710.09306 [2017- 10- 25].<i>https</i>://<i>arxiv</i>.<i>org</i>/<i>abs</i>/1710.09306.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-label classification of croatian legal documents using eurovoc thesaurus">

                                <b>[13]</b> <i>SARIC F</i>, <i>DALBELO B</i>, <i>MOENS M F</i>, <i>et al</i>.<i>Multi</i>-<i>label classification of croatian legal documents using eurovoc thesaurus</i>[<i>EB</i>/<i>OL</i>].[2018- 03- 20].<i>http</i>://<i>core</i>.<i>ac</i>.<i>uk</i>/<i>download</i>/<i>pdf</i>/34600531.<i>pdf</i>.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A semi-supervised approach for catchphrase classification in legal text documents">

                                <b>[14]</b> <i>BAJWA I S</i>, <i>KARIM F</i>, <i>NAEEM M A</i>, <i>et al</i>.<i>A semi</i>-<i>supervised approach for catchphrase classification in legal text documents</i>[<i>J</i>].<i>Journal of Computers</i>, 2017, 12 (5) :451-461.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic classification of legal textual documents using C4.5">

                                <b>[15]</b> <i>SILVESTRO L D</i>, <i>SPAMPINATO D</i>, <i>TORRISI A</i>.<i>Automatic classification of legal textual documents using C</i>4.5[<i>EB</i>/<i>OL</i>].[2018- 03- 20].<i>http</i>://<i>www</i>.<i>ittig</i>.<i>cnr</i>.<i>it</i>/<i>Ricerca</i>/<i>Testi</i>/<i>Spampinato</i>-<i>Di</i>_<i>Silvestro</i>-<i>Torrisi</i>2009.<i>pdf</i>.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=From word embeddings to document distances">

                                <b>[16]</b> <i>KUSNER M J</i>, <i>SUN Y</i>, <i>KOLKIN N I</i>, <i>et al</i>.<i>From word embeddings to document distances</i>[<i>C</i>]// <i>Proceedings of the</i> 32<i>nd International Conference on Machine Learning</i>.<i>New York</i>:<i>JMLR</i>.<i>org</i>, 2015:957-966.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">

                                <b>[17]</b> <i>MIKOLOV T</i>, <i>CHEN K</i>, <i>CORRADO G</i>, <i>et al</i>.<i>Efficient estimation of word representations in vector space</i>[<i>J</i>/<i>OL</i>].<i>arXiv Preprint</i>, 2013, 2013:<i>arXiv</i>:1301.3781 (2013- 01- 16) [2013- 09- 07].<i>https</i>://<i>arxiv</i>.<i>org</i>/<i>abs</i>/1301.3781.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed Representations of Words and Phrases and their Compositionality">

                                <b>[18]</b> <i>MIKOLOV T</i>, <i>SUTSKEVER I</i>, <i>CHEN K</i>, <i>et al</i>.<i>Distributed representations of words and phrases and their compositionality</i>[<i>C</i>]// <i>Proceedings of the</i> 26<i>th International Conference on Neural Information Processing Systems</i>.<i>New York</i>:<i>Curran Associates</i>, 2013:3111-3119.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">

                                <b>[19]</b> <i>ZEILER M D</i>, <i>FERGUS R</i>.<i>Visualizing and understanding convolutional networks</i>[<i>C</i>]// <i>Proceedings of the</i> 13<i>th European Conference on Computer Vision</i>.<i>London</i>:<i>Springer</i>, 2014:818-833.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ontological Engineering">

                                <b>[20]</b> <i>GOMEZ</i>-<i>PEREZ A</i>, <i>FERNANDEZ</i>-<i>LOPEZ M</i>, <i>CORCHO O</i>.<i>Ontological Engineering</i>[<i>M</i>].<i>London</i>:<i>Springer</i>, 2004:173-182.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Jieba Chinese word segmentation tool[CP/OL]">

                                <b>[21]</b> <i>SUN J J</i>.<i>Jieba Chinese word segmentation tool</i>[<i>CP</i>/<i>OL</i>]. (2018- 01- 21) [2018- 06- 25].<i>https</i>://<i>github</i>.<i>com</i>/<i>fxsjy</i>/<i>jieba</i>.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Binary Codes Capable of Correcting Deletions, Insertions and Reversals">

                                <b>[22]</b> <i>LEVENSHTEIN V I</i>.<i>Binary codes capable of correcting deletions</i>, <i>insertions</i>, <i>and reversals</i>[<i>J</i>].<i>Soviet Physics Doklady</i>, 1966, 10 (8) :707-710.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201905009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905009&amp;v=MDE2NTdCdEdGckNVUjdxZlp1WnNGeURtVjcvTEx6N0JkN0c0SDlqTXFvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
