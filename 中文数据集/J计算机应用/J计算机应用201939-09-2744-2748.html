<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136482527158750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909044%26RESULT%3d1%26SIGN%3dstjpxkWqBV5EVC1EXDDmwTxOBp8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909044&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909044&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909044&amp;v=MTAwMjU3RzRIOWpNcG85QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WYnpCTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 卷积神经网络 ">1 卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="1.1 &lt;b&gt;二维卷积神经网络&lt;/b&gt;">1.1 <b>二维卷积神经网络</b></a></li>
                                                <li><a href="#53" data-title="1.2 &lt;b&gt;三维卷积神经网络&lt;/b&gt;">1.2 <b>三维卷积神经网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#58" data-title="2 基于3D CNN的检测方法 ">2 基于3D CNN的检测方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="2.1 &lt;b&gt;方法概述&lt;/b&gt;">2.1 <b>方法概述</b></a></li>
                                                <li><a href="#61" data-title="2.2 &lt;b&gt;数据来源和预处理&lt;/b&gt;">2.2 <b>数据来源和预处理</b></a></li>
                                                <li><a href="#65" data-title="2.3 &lt;b&gt;特征提取&lt;/b&gt;">2.3 <b>特征提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="3 CNN结构 ">3 CNN结构</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="3.1 3D CNN">3.1 3D CNN</a></li>
                                                <li><a href="#74" data-title="3.2 2D CNN">3.2 2D CNN</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="4.1 &lt;b&gt;实验平台&lt;/b&gt;">4.1 <b>实验平台</b></a></li>
                                                <li><a href="#79" data-title="4.2 &lt;b&gt;评估指标&lt;/b&gt;">4.2 <b>评估指标</b></a></li>
                                                <li><a href="#82" data-title="4.3 &lt;b&gt;参数选择&lt;/b&gt;">4.3 <b>参数选择</b></a></li>
                                                <li><a href="#84" data-title="4.4 &lt;b&gt;不同分帧长度的网络性能&lt;/b&gt;">4.4 <b>不同分帧长度的网络性能</b></a></li>
                                                <li><a href="#88" data-title="4.5 &lt;b&gt;与&lt;/b&gt;2D CNN&lt;b&gt;的比较&lt;/b&gt;">4.5 <b>与</b>2D CNN<b>的比较</b></a></li>
                                                <li><a href="#93" data-title="4.6 &lt;b&gt;实验讨论与可视化&lt;/b&gt;">4.6 <b>实验讨论与可视化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="图1 3D CNN详细结构">图1 3D CNN详细结构</a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同分帧长度的网络性能&lt;/b&gt;"><b>表</b>1 <b>不同分帧长度的网络性能</b></a></li>
                                                <li><a href="#87" data-title="图2 不同分帧长度&lt;i&gt;n&lt;/i&gt;的ROC曲线">图2 不同分帧长度<i>n</i>的ROC曲线</a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;表&lt;/b&gt;2 2D CNN&lt;b&gt;与&lt;/b&gt;3D CNN&lt;b&gt;的详细结构&lt;/b&gt;"><b>表</b>2 2D CNN<b>与</b>3D CNN<b>的详细结构</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表&lt;/b&gt;3 2D CNN&lt;b&gt;与&lt;/b&gt;3D CNN&lt;b&gt;性能比较&lt;/b&gt;"><b>表</b>3 2D CNN<b>与</b>3D CNN<b>性能比较</b></a></li>
                                                <li><a href="#92" data-title="图3 2D CNN和3D CNN的ROC曲线">图3 2D CNN和3D CNN的ROC曲线</a></li>
                                                <li><a href="#101" data-title="图4 类激活图可视化">图4 类激活图可视化</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="188">


                                    <a id="bibliography_1" title=" 李瑞法,张学勤,陈莹,等.我国进境原木主要疫情分析[J].中国森林病虫,2015,34(5):8-11.(LI R F,ZHANG X Q,CHEN Y,et al.Analysis on main epidemic situation of pests in imported logs [J].Forest Pest and Disease,2015,34(5):8-11.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLBC201505003&amp;v=MTg3NTR6cXFCdEdGckNVUjdxZlp1WnNGeWpuVmJ6Qk5pSEpiYkc0SDlUTXFvOUZaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李瑞法,张学勤,陈莹,等.我国进境原木主要疫情分析[J].中国森林病虫,2015,34(5):8-11.(LI R F,ZHANG X Q,CHEN Y,et al.Analysis on main epidemic situation of pests in imported logs [J].Forest Pest and Disease,2015,34(5):8-11.)
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_2" title=" 娄定风,许小芳,李嘉,等.6种木材钻蛀性昆虫的声学特征与比较[J].植物检疫,2013,27(1):6-10.(LOU D F,XU X F,LI J,et al.Acoustic characteristics and their comparison of six species of wood borers [J].Plant Quarantine,2013,27(1):6-10.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZWJY201301004&amp;v=MDU2NDRkN0c0SDlMTXJvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVmJ6QlB6ckI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         娄定风,许小芳,李嘉,等.6种木材钻蛀性昆虫的声学特征与比较[J].植物检疫,2013,27(1):6-10.(LOU D F,XU X F,LI J,et al.Acoustic characteristics and their comparison of six species of wood borers [J].Plant Quarantine,2013,27(1):6-10.)
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_3" title=" SUTIN A,FLYNN T,SALLOUM,H,et al.Vibro-acoustic methods of insect detection in agricultural shipments and wood packing materials[C]// Proceedings of the 2017 IEEE International Symposium on Technologies for Homeland Security.Piscataway,NJ:IEEE,2017:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vibro-acoustic methods of insect detection in agricultural shipments and wood packing materials">
                                        <b>[3]</b>
                                         SUTIN A,FLYNN T,SALLOUM,H,et al.Vibro-acoustic methods of insect detection in agricultural shipments and wood packing materials[C]// Proceedings of the 2017 IEEE International Symposium on Technologies for Homeland Security.Piscataway,NJ:IEEE,2017:1-6.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_4" title=" 祁骁杰,卜宇飞,许志春,等.杨树木段内光肩星天牛幼虫数量的声学检测[J].环境昆虫学报,2016,38(3):529-534.(QI X J,BU Y F,XU Z C,et al.Using acoustic technology detect the different numbers of anoplophora glabripennis larvae in poplar [J].Journal of Environmental Entomology,2016,38(3):529-534.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KCTD201603012&amp;v=MTc1NjU3cWZadVpzRnlqblZiekJMaTdmYXJHNEg5Zk1ySTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         祁骁杰,卜宇飞,许志春,等.杨树木段内光肩星天牛幼虫数量的声学检测[J].环境昆虫学报,2016,38(3):529-534.(QI X J,BU Y F,XU Z C,et al.Using acoustic technology detect the different numbers of anoplophora glabripennis larvae in poplar [J].Journal of Environmental Entomology,2016,38(3):529-534.)
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_5" title=" PARSONS S,JONES G.Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks [J].Journal of Experimental Biology,2000,203(17):2641-2656." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks">
                                        <b>[5]</b>
                                         PARSONS S,JONES G.Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks [J].Journal of Experimental Biology,2000,203(17):2641-2656.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_6" title=" YAZGA&#199; B G,KIRCI M,KIVAN M.Detection of sunn pests using sound signal processing methods [C]// Proceedings of the 2016 5th International Conference on Agro-Geoinformatics (Agro-Geoinformatics).Piscataway,NJ:IEEE,2016:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detection of sunn pests using sound signal processing methods">
                                        <b>[6]</b>
                                         YAZGA&#199; B G,KIRCI M,KIVAN M.Detection of sunn pests using sound signal processing methods [C]// Proceedings of the 2016 5th International Conference on Agro-Geoinformatics (Agro-Geoinformatics).Piscataway,NJ:IEEE,2016:1-6.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_7" title=" ZILLI D,PARSON O,MERRETT G,et al.A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring[C]// Proceedings of the 23rd International Joint Conference on Artificial Intelligence.Palo Alto,CA:AAAI Press,2013:2945-2951." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring">
                                        <b>[7]</b>
                                         ZILLI D,PARSON O,MERRETT G,et al.A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring[C]// Proceedings of the 23rd International Joint Conference on Artificial Intelligence.Palo Alto,CA:AAAI Press,2013:2945-2951.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_8" title=" LIKITHA M S,GUPTA S R R,HASITHA K,et al.Speech based human emotion recognition using MFCC [C]// Proceedings of the 2017 International Conference on Wireless Communications,Signal Processing and Networking.Piscataway,NJ:IEEE,2017:2257-2260." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speech based human emotion recognition using MFCC">
                                        <b>[8]</b>
                                         LIKITHA M S,GUPTA S R R,HASITHA K,et al.Speech based human emotion recognition using MFCC [C]// Proceedings of the 2017 International Conference on Wireless Communications,Signal Processing and Networking.Piscataway,NJ:IEEE,2017:2257-2260.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_9" title=" POTAMITIS I,GANCHEV T,FAKOTAKIS N.Automatic acoustic identification of crickets and cicadas[C]// Proceedings of the 9th International Symposium on Signal Processing and Its Applications.Piscataway,NJ:IEEE,2007:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic acoustic identification of crickets and cicadas">
                                        <b>[9]</b>
                                         POTAMITIS I,GANCHEV T,FAKOTAKIS N.Automatic acoustic identification of crickets and cicadas[C]// Proceedings of the 9th International Symposium on Signal Processing and Its Applications.Piscataway,NJ:IEEE,2007:1-4.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_10" title=" DONG X,YAN N,WEI Y.Insect sound recognition based on convolutional neural network [C]// Proceedings of the IEEE 3rd International Conference on Image,Vision and Computing.Piscataway,NJ:IEEE,2018:855-859." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Insect sound recognition based on convolutional neural network">
                                        <b>[10]</b>
                                         DONG X,YAN N,WEI Y.Insect sound recognition based on convolutional neural network [C]// Proceedings of the IEEE 3rd International Conference on Image,Vision and Computing.Piscataway,NJ:IEEE,2018:855-859.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_11" title=" KISKIN I,ZILLI D,LI Y,et al.Bioacoustic detection with wavelet-conditioned convolutional neural networks [EB/OL].[2018- 12- 28].https://link.springer.com/article/10.1007/s00521-018-3626-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bioacoustic detection with wavelet-conditioned convolutional neural networks">
                                        <b>[11]</b>
                                         KISKIN I,ZILLI D,LI Y,et al.Bioacoustic detection with wavelet-conditioned convolutional neural networks [EB/OL].[2018- 12- 28].https://link.springer.com/article/10.1007/s00521-018-3626-7.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_12" title=" ZHOU X,LI J,ZHOU X.Cascaded CNN-resBiLSTM-CTC:an end-to-end acoustic model for speech recognition [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1810.12001.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cascaded CNN-resBiLSTM-CTC:an end-to-end acoustic model for speech recognition">
                                        <b>[12]</b>
                                         ZHOU X,LI J,ZHOU X.Cascaded CNN-resBiLSTM-CTC:an end-to-end acoustic model for speech recognition [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1810.12001.pdf.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_13" title=" SCHMIDHUBER J.Deep learning in neural networks:an overview[J].Neural Networks,2015,61:85-117." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700296012&amp;v=MTIxNzRmT2ZiSzhIOURNcUk5Rlp1SUpESDA3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSUZ3U2FScz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         SCHMIDHUBER J.Deep learning in neural networks:an overview[J].Neural Networks,2015,61:85-117.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_14" title=" HUANG J,ZHOU W,LI H,et al.Sign language recognition using 3D convolutional neural networks[C]// Proceedings of the 2015 IEEE International Conference on Multimedia and Expo.Piscataway,NJ:IEEE,2015:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sign language recognition using 3D convolutional neural networks">
                                        <b>[14]</b>
                                         HUANG J,ZHOU W,LI H,et al.Sign language recognition using 3D convolutional neural networks[C]// Proceedings of the 2015 IEEE International Conference on Multimedia and Expo.Piscataway,NJ:IEEE,2015:1-6.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_15" title=" IOFFE S,SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift [C]// Proceedings of the 32nd International Conference on International Conference on Machine Learning.Brookline,MA:JMLR,2015,37:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift">
                                        <b>[15]</b>
                                         IOFFE S,SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift [C]// Proceedings of the 32nd International Conference on International Conference on Machine Learning.Brookline,MA:JMLR,2015,37:448-456.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     SRIVASTAVA N,HINTON G,KRIZHEVSKY A,et al.Dropout:a simple way to prevent neural networks from overfitting [J].Journal of Machine Learning Research,2014,15(1):1929-1958.</a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_17" title=" ABADI M,BARHAM P,CHEN J,et al.TensorFlow:a system for large-scale machine learning [C]// Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation.Berkeley,CA:USENIX Association,2016:265-283." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=TensorFlow:a system for large-scale machine learning">
                                        <b>[17]</b>
                                         ABADI M,BARHAM P,CHEN J,et al.TensorFlow:a system for large-scale machine learning [C]// Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation.Berkeley,CA:USENIX Association,2016:265-283.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_18" title=" DOWNEY T J,MEYER D J,PRICE R K,et al.Using the receiver operating characteristic to asses the performance of neural classifiers [C]// Proceedings of the 1999 International Joint Conference on Neural Networks.Piscataway,NJ:IEEE,1999:3642-3646." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using the receiver operating characteristic to assess the performance of neural classifiers">
                                        <b>[18]</b>
                                         DOWNEY T J,MEYER D J,PRICE R K,et al.Using the receiver operating characteristic to asses the performance of neural classifiers [C]// Proceedings of the 1999 International Joint Conference on Neural Networks.Piscataway,NJ:IEEE,1999:3642-3646.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_19" title=" ZEILER M D.ADADELTA:an adaptive learning rate method [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1212.5701.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ADADELTA:an adaptive learning rate method">
                                        <b>[19]</b>
                                         ZEILER M D.ADADELTA:an adaptive learning rate method [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1212.5701.pdf.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_20" title=" SELVARAJU R R,COGSWELL M,DAS A,et al.Grad-CAM:visual explanations from deep networks via gradient-based localization [C]// Proceedings of the 2017 IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2017,1:618-626." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Grad-CAM:visual explanations from deep networks via gradient-based localization">
                                        <b>[20]</b>
                                         SELVARAJU R R,COGSWELL M,DAS A,et al.Grad-CAM:visual explanations from deep networks via gradient-based localization [C]// Proceedings of the 2017 IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2017,1:618-626.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-29 09:35</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2744-2748 DOI:10.11772/j.issn.1001-9081.2019030481            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于三维卷积神经网络的虫音特征识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E6%B0%B8%E8%8F%81&amp;code=07529248&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万永菁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%8D%9A%E7%8E%AE&amp;code=42444408&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王博玮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A8%84%E5%AE%9A%E9%A3%8E&amp;code=42779661&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">娄定风</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0024290&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东理工大学信息科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B7%B1%E5%9C%B3%E6%B5%B7%E5%85%B3&amp;code=0702414&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深圳海关</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>进口木材蛀虫检疫是海关的一项重要工作,但其存在着虫声检测算法准确率低、鲁棒性差等问题。针对这些问题,提出了一种基于三维卷积神经网络(3D CNN)的虫音检测方法以实现虫音特征的识别。首先,对原始虫音音频进行交叠分帧预处理,并使用短时傅里叶变换得到虫音音频的语谱图;然后,将语谱图作为3D CNN的输入,使其通过包含三层卷积层的3D CNN以判断音频中是否存在虫音特征。通过设置不同分帧长度下的输入进行网络训练及测试;最后以准确率、F<sub>1</sub>分数以及ROC曲线作为评估指标进行性能分析。结果表明,在交叠分帧长度取5 s时,训练及测试效果最佳。此时,3D CNN模型在测试集上的准确率达到96.0%,F<sub>1</sub>分数为0.96,且比二维卷积神经网络(2D CNN)模型准确率提高近18%。说明所提算法能准确地从音频信号中提取虫音特征并完成蛀虫识别任务,为海关检验检疫提供有力保障。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%AD%E6%97%B6%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">短时傅里叶变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AD%E8%B0%B1%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">语谱图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%99%AB%E9%9F%B3%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">虫音识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A3%B0%E5%AD%A6%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">声学信号处理;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    万永菁(1975—),女,江西南昌人,副教授,博士,主要研究方向:智能信息处理、图像处理、模式识别、音频信号处理;;
                                </span>
                                <span>
                                    *王博玮(1997—),男,湖南益阳人,主要研究方向:信号处理、数据挖掘、机器学习;电子邮箱kevinwang@mail.ecust.edu.cn;
                                </span>
                                <span>
                                    娄定风(1960—),男,江西南昌人,研究员,主要研究方向:昆虫声学。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61872143);</span>
                                <span>国家大学生创新创业训练计划项目(201810251064);</span>
                    </p>
            </div>
                    <h1><b>Insect sound feature recognition method based on three-dimensional convolutional neural network</b></h1>
                    <h2>
                    <span>WAN Yongjing</span>
                    <span>WANG Bowei</span>
                    <span>LOU Dingfeng</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Engineering, East China University of Science and Technology</span>
                    <span>Shenzhen Customs</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The quarantine of imported wood is an important task for the customs, but there are problems such as low accuracy and poor robustness in the insect sound detection algorithm. To solve these problems, an insect sound detection method based on Three-Dimensional Convolutional Neural Network(3 D CNN) was proposed to detect the presence of insect sound features. Firstly, the original insect audio was framed and pre-processed, and Short-Time Fourier Transform(STFT) was operated to obtain the spectrogram of the insect audio. Then, the spectrogram was used as the input of the 3 D CNN consisting three convolutional layers. Network training and testing were conducted by setting inputs with different framing lengths. Finally, the analysis of performance was carried out using metrics like accuracy, F<sub>1</sub> score and ROC curve. The experiments showed that the test results were best when the overlap framing length was 5 seconds. The best result of the 3 D CNN model on the test set achieved an accuracy of 96.0% and an F<sub>1</sub> score of 0.96. The accuracy was increased by nearly 18% compared with that of the two-dimensional convolutional neural network(2 D CNN) model. It shows that the proposed model can extract the insect sound features from the audio signal more accurately and complete the insect identification task, which provides an engineering solution for customs inspection and quarantine.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Three-Dimensional%20Convolutional%20Neural%20Network(3D%20CNN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Three-Dimensional Convolutional Neural Network(3D CNN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Short-Time%20Fourier%20Transform(STFT)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Short-Time Fourier Transform(STFT);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spectrogram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spectrogram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=insect%20sound%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">insect sound detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=acoustic%20signal%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">acoustic signal processing;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WAN Yongjing, born in 1975, Ph. D. , associate professor. Her research interests include intelligent information processing, image processing, pattern recognition, audio signal processing. ;
                                </span>
                                <span>
                                    WANG Bowei, born in 1997. His research interests include signal processing, data mining, machine learning. ;
                                </span>
                                <span>
                                    LOU Dingfeng, born in 1960, research fellow. His research interests include entomological bioacoustics.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-22</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61872143);</span>
                                <span>the National Undergraduate Innovation and Entrepreneurship Training Program of China(201810251064);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="44">我国进口原木的数量逐年上升,其携带的有害生物造成的疫情也不断加重,其中小蠹科、长小蠹科、天牛科、吉丁虫科、长蠹科等钻蛀性昆虫为进口原木中的主要害虫<citation id="228" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。进口原木中的这些害虫对我国的生态环境、林业生产和公众生活构成极大的威胁。在口岸检疫时,通常采用破坏性的检查方法对原木进行目视和剖检,其检出效率不高,费工费时<citation id="229" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。近年来,随着声学、信号处理、计算机技术的发展,出现了无损的检测方法。如Sutin等<citation id="230" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>利用震动传感器获得木材表面的振动信号,提出了一套基于时域的害虫检测方法;害虫在进食、活动和交流时都会有声音信号的产生,所以利用声音信号来检测也是一个不错的选择:祁骁杰等<citation id="231" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>通过采集声音信号,采用时频结合的方法对木材内的害虫数量进行识别。尽管以上研究取得了不错的效果,但使用的方法均基于时频域手工提取的特征,带来的设备成本和对环境的要求都严重限制了其在边境检疫中的推广。随着近些年来深度学习的快速发展,它在图像处理、语音识别、自然语言处理等领域的成功应用也为解决这个问题带来了新的研究方法和思路。</p>
                </div>
                <div class="p1">
                    <p id="45">将深度学习应用在动物的声学识别和分类最早可以追溯到本世纪初期蝙蝠回声定位的相关研究中<citation id="232" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。随后也不断涌现出了许多基于传统特征提取的识别方法。利用动物的声音信号来进行识别在害虫控制<citation id="233" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、物种多样性检测<citation id="234" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等方面都有着重要的作用。传统的声音识别主要包括三个阶段:首先是预处理,然后是特征提取,最后是模式识别。预处理通常包括标准化、降噪等,虽然目前降噪技术在某些数据集上能够有效工作,但是在复杂环境下的处理仍然是一个挑战。然后会进入到特征提取环节,将数据转换为适合分类器输入的形式进入到最后的判决阶段。通常,特征提取指的是应用信号处理的不同方法提取时频域的各种特征。常见的提取方法包括梅尔频率倒频系数(Mel Frequency Cepstral Coefficients, MFCC)<citation id="235" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,线性频率倒频系数(Linear Frequency Cepstral Coefficients, LFCC)<citation id="236" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。这些方法不仅在语音识别领域均取得了不错的效果,在其他音频信号处理中也得到了广泛的应用。除此之外,利用短时傅里叶变换(Short-Time Fourier Transform, STFT)、小波变换(Wavelet Transform, WT)以及希尔伯特黄变换(Hilbert-Huang Transform, HHT)等方法得到语谱图的特征提取也有着不错的效果<citation id="237" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。常见的分类方法包括支持向量机(Support Vector Machine, SVM)、隐马尔可夫模型(Hidden Markov Model, HMM)、高斯混合模型(Gaussian Mixture Model, GMM),以及最近的深度神经网络(Deep Neural Network, DNN)。深度神经网络通过使用视觉上的某些信息进行相关的训练。音频通过二维的语谱图作为输入,卷积神经网络(Convolutional Neural Network, CNN)模型能够捕获时域和频域的某些能量变换从而实现分类判决任务。但是使用二维输入将会使CNN模型更多地关注背景噪声而不是声音事件,且其性能受数据集大小影响较大。</p>
                </div>
                <div class="p1">
                    <p id="46">为了解决传统信号处理在高噪声背景下难以提取微弱信号以及二维卷积神经网络(Two-Dimensional Convolutional Neural Network, 2D CNN)不能充分利用时频信息的问题,本文提出了基于声学的三维卷积神经网络(Three-Dimensional Convolutional Neural Network, 3D CNN)以识别木材中的害虫。CNN在各种视觉识别任务中都有着出色的性能。最近,CNN在声学信号处理方面有了一些新的尝试:牛津大学的Kiskin等<citation id="238" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出基于小波变换的2D CNN以识别热带家蚊且达到了0.925的F<sub>1</sub>分数,该方法也同样被证实在鸟类的分类任务中有着出色的表现;Zhou等<citation id="239" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>通过快速傅里叶变换(Fast Fourier Transform, FFT)和<i>n</i>-gram语言模型提取特征,使用CNN混合模型在自动语言识别(Automatic Speech Recognition, ASR)上也取得了不错的成果。考虑到木制品中害虫活动规律的周期性,本文提出了基于3D CNN的虫声检测方法。该方法相比二维能够更好地提取虫音特征,在F<sub>1</sub>分数和准确率两个指标上均优于2D CNN模型,在低信噪比环境下也能够实现较高的准确率,为边境检验检疫部门提供检测害虫的有效工具。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 卷积神经网络</h3>
                <h4 class="anchor-tag" id="48" name="48">1.1 <b>二维卷积神经网络</b></h4>
                <div class="p1">
                    <p id="49">卷积神经网络是一种典型的深度学习方法,近年来的飞速发展使得其在图像识别领域有了巨大的进步。深度卷积神经网络通过模仿生物神经网络,低层表示细节,高层表示语义,能够通过大量的数据自动地训练出模型<citation id="240" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。二维卷积神经网络的计算公式如式(1)所示:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>w</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">其中:<i>y</i><sub><i>xy</i></sub>是位置(<i>x</i>,<i>y</i>)的特征图,<i>w</i><sub><i>ij</i></sub>是卷积核的权重,<i>v</i><sub>(</sub><i>x</i>+<i>i</i>)(<i>y</i>+<i>j</i>)是在(<i>x</i>+<i>i</i>,<i>y</i>+<i>j</i>)的输入值,<i>b</i>是偏差<citation id="241" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52">一个典型的神经网络通常包括卷积层、池化层和全连接层。CNN网络的核心功能在卷积层完成,在每一层都会计算输入与当前层权重的点积。在图像处理中,为了确保能从图像信息中得到所有的颜色信息,接受层的深度必须和颜色通道个数一致。卷积层的输出叫作特征图,而特征图的个数也由深度决定。卷积层后会有激活层,通常会使用非线性函数对上一层数据进行激活。在卷积层后通常也会有池化层,池化层的作用是在保证输入不变的情况下进行降采样以减少计算量。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53">1.2 <b>三维卷积神经网络</b></h4>
                <div class="p1">
                    <p id="54">三维卷积神经网络和二维卷积神经网络类似,是二维卷积神经网络的一种拓展。在二维卷积神经网络中,卷积层的输入是二维的空间信息;而在三维卷积神经网络中,时间和频域信息能够被更加充分地利用。三维神经网络的卷积核有三个维度,有时还考虑颜色通道为第四个维度。其计算公式如式(2)所示:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>w</mi></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">其中:<i>y</i><sub><i>xyt</i></sub>是在(<i>x</i>,<i>y</i>,<i>t</i>)处的特征图,<i>f</i>是激活函数,<i>w</i><sub><i>ijk</i></sub>是核权重,<i>v</i><sub>(</sub><i>x</i>+<i>i</i>)(<i>y</i>+<i>j</i>)(<i>t</i>+<i>k</i>)是在(<i>x</i>+<i>i</i>,<i>y</i>+<i>j</i>,<i>t</i>+<i>k</i>)位置的输入值,<i>b</i>是偏差<citation id="242" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="57">正如前面所描述的那样,三维卷积神经网络是对二维卷积神经网络的一种拓展。模型的输入也会根据需要修改为合适的三维形式。</p>
                </div>
                <h3 id="58" name="58" class="anchor-tag">2 基于3D CNN的检测方法</h3>
                <h4 class="anchor-tag" id="59" name="59">2.1 <b>方法概述</b></h4>
                <div class="p1">
                    <p id="60">本文以短时傅里叶变换(STFT)得到的语谱图作为3D CNN的输入搭建了模型,应用到害虫的声学识别中。首先,对获取到的音频数据进行标准化的预处理;其次,需要提取音频数据的特征,本文利用短时傅里叶变换(STFT)提取虫声的时频特征并进行分帧处理;最后,将二维的频谱特征数据变换到合适的三维形式作为3D CNN的输入进行训练。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">2.2 <b>数据来源和预处理</b></h4>
                <div class="p1">
                    <p id="62">本文的音频数据来源于深圳市出入境检验检疫局,覆盖了在2017年到2018年期间不同环境下录制的67段音频。其中785个片段为31种害虫在木材中活动和进食的音频,1 534个片段为各种实际检疫环境中的非虫音(分帧长度<i>n</i>=5 s时)。存在害虫的音频被标记为1,包括环境噪声在内的非虫音被标记为0。木材中的害虫已经通过昆虫分类专家鉴定,因此可以认为数据标定是准确的。</p>
                </div>
                <div class="p1">
                    <p id="63">同时,特征的提取还受到录音设备、发声响度的影响,本文使用了式(3)对音频进行标准化处理,其中<i>x</i>[<i>k</i>]表示声音序列,<i>K</i>表示音频的长度。</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo><mo>=</mo><mfrac><mrow><mi>x</mi><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>x</mi></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo><mo>/</mo><mi>Κ</mi></mrow></msqrt></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="65" name="65">2.3 <b>特征提取</b></h4>
                <div class="p1">
                    <p id="66">为了将训练数据转换为适合神经网络训练的形式,本文采用短时傅里叶变换(STFT)提取时频特征。离散短时傅里叶变换方法如式(4)所示:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>Τ</mi><mi>F</mi><mi>Τ</mi><mo stretchy="false">{</mo><mi>x</mi><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mo>≡</mo><mi>X</mi><mo stretchy="false">(</mo><mi>m</mi><mo>,</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></munderover><mi>x</mi></mstyle><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo><mi>w</mi><mo stretchy="false">[</mo><mi>k</mi><mo>-</mo><mi>m</mi><mo stretchy="false">]</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mo>-</mo><mtext>j</mtext><mi>ω</mi><mi>k</mi></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">根据害虫的发声规律,对音频信号作短时傅里叶变换得到语谱图,然后将语谱图以50%的重叠分帧为<i>n</i>秒的片段,其中<i>n</i>取3、4、5、6、7、8,在不影响原始数据的基础上扩大了实验样本。因为数据集的采样频率<i>f</i><sub><i>s</i></sub>=44 100 Hz,最大可辨识频率被限制在22 050 Hz。本文选择了20 ms的Hanning窗,重叠率为50%,1 024点的FFT来计算短时傅里叶变换。最后,原始语谱图(80×100×<i>n</i>)作为2D CNN的输入并将原始语谱图规范化为80×100×<i>n</i>作为3D CNN的输入。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag">3 CNN结构</h3>
                <h4 class="anchor-tag" id="70" name="70">3.1 3D CNN</h4>
                <div class="p1">
                    <p id="71">本文使用的三维CNN是对二维CNN的一种扩展。具体而言,3D CNN包括三个卷积层(Kernel):第一层卷积层包括8个3×3×3的卷积核;第二层卷积层有32个3×3×3的卷积核;第三层卷积层有40个3×3×3的卷积核。均采用SAME的补零方式,步长为1。</p>
                </div>
                <div class="p1">
                    <p id="72">另外在每层卷积层后还包括批规范层<citation id="243" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、激活函数层、最大池化层(Max Pooling)和Dropout<citation id="244" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>层。其中批规范层将前一层的值重新规范化,使得其输出数据的均值接近0,标准差接近1,在提高学习速率的同时防止其过拟合。批规范层的参数设置均相同,动量参数为0.99,epsilon为0.001。而激活层的激活函数均选用线性整流函数(Rectified Linear Unit,ReLu)。最大池化层均采用SAME补零方式,池化层各层的窗口大小分别为1×2×2、2×2×2、3×2×2,步长与窗口大小相同。为了防止过拟合,将Dropout层速率均设置为0.5。在进入全连接层之前,Flatten层将特征向量整合为一维。最后一层节点个数为2,用Softmax函数激活以预测有虫或无虫。详细结构如图1所示(<i>n</i>=5时)。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909044_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3D CNN详细结构" src="Detail/GetImg?filename=images/JSJY201909044_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 3D CNN详细结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909044_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Specific architecture of 3D CNN</p>

                </div>
                <h4 class="anchor-tag" id="74" name="74">3.2 2D CNN</h4>
                <div class="p1">
                    <p id="75">为了准确评估3D CNN的性能,本文搭建了与3D CNN类似的2D CNN模型。不同之处在于,2D CNN均采用二维的卷积核和池化窗口。卷积核大小均为3×3,步长为1;池化层窗口大小均为2×2,步长为2。其他参数设置与3D CNN相同。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="77" name="77">4.1 <b>实验平台</b></h4>
                <div class="p1">
                    <p id="78">所有的实验均是在Google Colab平台上完成的。该平台搭载有一颗Intel Xeon @2.20 GHz的处理器,13 GB RAM以及一块20 GB的Nvidia Tesla K80图形处理器,操作系统为Ubuntu。深度学习框架是以Python和Tensorflow<citation id="245" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>为后端的Keras。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">4.2 <b>评估指标</b></h4>
                <div class="p1">
                    <p id="80">本文的性能通过准确率、F<sub>1</sub>分数以及受试者工作特征(Receiver Operating Characteristic, ROC)曲线<citation id="246" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>来进行评估。F<sub>1</sub>分数能够综合准确率(Precision)和召回率(Recall)两个性能指标综合评判,F<sub>1</sub>分数越高,则模型的效果越好。准确率、召回率和F<sub>1</sub>分数的计算方法如式(5)(6)(7)所示。所有的指标均在测试集上计算。</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>=</mo><mfrac><mrow><mtext>正</mtext><mtext>确</mtext><mtext>有</mtext><mtext>虫</mtext><mtext>标</mtext><mtext>签</mtext><mtext>数</mtext></mrow><mrow><mtext>预</mtext><mtext>测</mtext><mtext>有</mtext><mtext>虫</mtext><mtext>标</mtext><mtext>签</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext><mo>=</mo><mfrac><mrow><mtext>正</mtext><mtext>确</mtext><mtext>有</mtext><mtext>虫</mtext><mtext>标</mtext><mtext>签</mtext><mtext>数</mtext></mrow><mrow><mtext>实</mtext><mtext>际</mtext><mtext>有</mtext><mtext>虫</mtext><mtext>标</mtext><mtext>签</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>F</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>×</mo><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow><mrow><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>+</mo><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">4.3 <b>参数选择</b></h4>
                <div class="p1">
                    <p id="83">训练过程中,2D CNN和3D CNN模型均使用了AdaDelta优化器<citation id="247" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>,损失函数为分类交叉熵(Categorical Crossentropy)函数。其中AdaDelta学习速率设置为1.0,epsilon参数设置为10<sup>-8</sup>。将整个数据集按90%、5%、5%的比例分为训练集、验证集和测试集。验证集用于超参数调节以及筛选最后的模型,测试集用于对模型最后的评估。为了避免训练过程中的过拟合现象,在训练66代(epoch)后停止训练。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">4.4 <b>不同分帧长度的网络性能</b></h4>
                <div class="p1">
                    <p id="85">本文首先研究了不同分帧长度的输入对网络性能的影响。选择合适的分帧长度在本文中至关重要:过长会导致可训练的数据集减少,网络容易出现过拟合现象;过短则不能保证帧内有虫,从而导致标签错误。不同的分帧长度的网络性能以准确率、F<sub>1</sub>分数、真阳率(True Positive Rate,TPR)和真阴率(True Negative Rate,TNR)来表示(表1);6种分帧长度的ROC曲线如图2所示。结果表明在<i>n</i>=4、5、6时,网络性能较好。本文将准确率、F<sub>1</sub>分数和ROC曲线折中考虑,在<i>n</i>=5时模型性能达到最佳。</p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit"><b>表</b>1 <b>不同分帧长度的网络性能</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Network performance with different framing length</p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td><br />输入维度</td><td>准确率</td><td>F<sub>1</sub>分数</td><td>TPR</td><td>TNR</td></tr><tr><td><br />80×100×3</td><td>0.837</td><td>0.813</td><td>0.69</td><td>1.00</td></tr><tr><td><br />80×100×4</td><td>0.949</td><td>0.948</td><td>0.90</td><td>1.00</td></tr><tr><td><br />80×100×5</td><td>0.960</td><td>0.960</td><td>0.94</td><td>0.98</td></tr><tr><td><br />80×100×6</td><td>0.918</td><td>0.913</td><td>0.84</td><td>1.00</td></tr><tr><td><br />80×100×7</td><td>0.861</td><td>0.844</td><td>0.73</td><td>1.00</td></tr><tr><td><br />80×100×8</td><td>0.742</td><td>0.783</td><td>0.92</td><td>0.56</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909044_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同分帧长度n的ROC曲线" src="Detail/GetImg?filename=images/JSJY201909044_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同分帧长度<i>n</i>的ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909044_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 ROC curves with framing length <i>n</i></p>

                </div>
                <h4 class="anchor-tag" id="88" name="88">4.5 <b>与</b>2D CNN<b>的比较</b></h4>
                <div class="p1">
                    <p id="89">本文将3D CNN模型与2D CNN模型从准确率、F<sub>1</sub>分数和ROC曲线三个指标进行了比较。两种模型的详细配置如表2所示(“—”表示该层没有这个参数)。从表3可以看出,在准确率和F<sub>1</sub>分数两个指标上,3D CNN模型均胜过2D CNN模型。图3给出了两种方法的ROC曲线,可以看到3D CNN模型效果较好。</p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"><b>表</b>2 2D CNN<b>与</b>3D CNN<b>的详细结构</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Specific architectures of 2D CNN and 3D CNN</p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td rowspan="2"><br />层</td><td colspan="2"><br />2D CNN</td><td rowspan="2"></td><td colspan="2"><br />3D CNN</td></tr><tr><td><br />参数</td><td>输入维度</td><td><br />参数</td><td>输入维度</td></tr><tr><td>conv3d</td><td>8@(3,3)</td><td>80×500</td><td></td><td>8@(3,3,3)</td><td>80×100×5</td></tr><tr><td><br />batchnorm</td><td>—</td><td>80×500</td><td></td><td>—</td><td>80×100×5</td></tr><tr><td><br />activation</td><td>—</td><td>80×500</td><td></td><td>—</td><td>80×100×5</td></tr><tr><td><br />maxpooling3d</td><td>2,2</td><td>80×500</td><td></td><td>1,2,2</td><td>80×100×5</td></tr><tr><td><br />dropout</td><td>—</td><td>40×250</td><td></td><td>—</td><td>80×50×3</td></tr><tr><td><br />conv3d</td><td>32@(3,3)</td><td>40×250</td><td></td><td>32@(3,3,3)</td><td>80×50×3</td></tr><tr><td><br />batchnorm</td><td>—</td><td>40×250</td><td></td><td>—</td><td>80×50×3</td></tr><tr><td><br />activation</td><td>—</td><td>40×250</td><td></td><td>—</td><td>80×50×3</td></tr><tr><td><br />maxpooling3d</td><td>2,2</td><td>40×250</td><td></td><td>2,2,2</td><td>80×50×3</td></tr><tr><td><br />dropout</td><td>—</td><td>20×125</td><td></td><td>—</td><td>40×25×2</td></tr><tr><td><br />conv3d</td><td>40@(3,3)</td><td>20×125</td><td></td><td>40@(3,3,3)</td><td>40×25×2</td></tr><tr><td><br />batchnorm</td><td>—</td><td>20×125</td><td></td><td>—</td><td>40×25×2</td></tr><tr><td><br />activation</td><td>—</td><td>20×125</td><td></td><td>—</td><td>40×25×2</td></tr><tr><td><br />maxpooling3d</td><td>2,2</td><td>20×125</td><td></td><td>3,2,2</td><td>40×25×2</td></tr><tr><td><br />dropout</td><td>—</td><td>10×62</td><td></td><td>—</td><td>14×13×1</td></tr><tr><td><br />flatten</td><td>40</td><td>10×62</td><td></td><td>40</td><td>14×13×1</td></tr><tr><td><br />dense</td><td>2</td><td>24 800</td><td></td><td>2</td><td>7 280</td></tr><tr><td><br />activation</td><td>Softmax</td><td>2</td><td></td><td>Softmax</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表</b>3 2D CNN<b>与</b>3D CNN<b>性能比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Performance comparison of 2D CNN and 3D CNN</p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td><br />方法</td><td>准确率</td><td>F<sub>1</sub>分数</td><td>TPR</td><td>TNR</td></tr><tr><td><br />3D CNN</td><td>0.960</td><td>0.960</td><td>0.94</td><td>0.98</td></tr><tr><td><br />2D CNN</td><td>0.781</td><td>0.820</td><td>0.97</td><td>0.57</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909044_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 2D CNN和3D CNN的ROC曲线" src="Detail/GetImg?filename=images/JSJY201909044_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 2D CNN和3D CNN的ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909044_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 ROC curves of 2D CNN and 3D CNN</p>

                </div>
                <h4 class="anchor-tag" id="93" name="93">4.6 <b>实验讨论与可视化</b></h4>
                <div class="p1">
                    <p id="94">为了评估3D CNN在虫声识别任务中的优势,本文将3D CNN模型与2D CNN模型进行了比较。表3的结果显示3D CNN在准确率和F<sub>1</sub>分数上均优于2D CNN。这表明3D CNN除了能学习到虫声的时频特征,同时能更有效地学习到虫音长序列在第三个维度上的害虫活动规律的特征。在不同分帧长度的比较中,分帧长度<i>n</i>=4、5、6时,模型性能较好,这也与害虫在木材中活动周期有关。</p>
                </div>
                <div class="p1">
                    <p id="95">另外,为了评估本文模型在低信噪比环境下的分类效果,选取了一些背景噪声较大的数据进行测试。结果显示,本文方法对此类数据仍能进行较好的分类。但是,对于少虫的情况,虫声信号非常微弱,本文的方法会将其判断为无虫,因此本文的方法还需要进一步研究。</p>
                </div>
                <div class="p1">
                    <p id="96">为了验证CNN模型学习到了害虫的某些发声规律,本文使用了基于梯度的类激活图(Gradient-weighted Class Activation Map, Grad-CAM)<citation id="248" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>来了解语谱图中的哪一部分影响了神经网络的判决。具体地讲,对某一卷积层的输出特征图,用类别相对于通道的梯度对这个特征图的每个通道进行加权就可以得到类激活图。类激活图中颜色越深的部分代表其对判决影响越大。运算方法如式(8)、(9)所示:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">α</mi><msubsup><mrow></mrow><mi>k</mi><mi>c</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>Ζ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mi>c</mi></msup></mrow><mrow><mo>∂</mo><mi>A</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow></mfrac></mrow></mstyle></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">L</mi><msubsup><mrow></mrow><mrow><mtext>G</mtext><mtext>r</mtext><mtext>a</mtext><mtext>d</mtext><mo>-</mo><mtext>C</mtext><mtext>A</mtext><mtext>Μ</mtext></mrow><mi>c</mi></msubsup><mo>=</mo><mspace width="0.25em" /><mtext>R</mtext><mtext>e</mtext><mtext>L</mtext><mtext>u</mtext><mo stretchy="false">(</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi mathvariant="bold-italic">α</mi></mstyle><msubsup><mrow></mrow><mi>k</mi><mi>c</mi></msubsup><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">其中:<i>α</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>c</mi></msubsup></mrow></math></mathml>代表权重,<i>c</i>代表目标类别,<b><i>y</i></b><sup><i>c</i></sup>代表模型输出结果,<b><i>A</i></b><sup><i>k</i></sup>代表卷积层特征图。</p>
                </div>
                <div class="p1">
                    <p id="100">本文将最后一个卷积层作为目标计算类激活图。基于梯度的类激活图(Grad-CAM)方法与常规的类激活图(Class Activation Mapping, CAM)方法不同,不需要对网络进行调整或重新训练。图4(a)展示了一个被标记为有虫的片段的类激活图,可以看到颜色较深部分集中在高频段,图4(b)是虫声的梅尔谱图。这也和在安静环境下手工提取到的特征<citation id="249" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>高度吻合,表明CNN网络是在基于学到的正确特征上作出的判断。</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909044_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 类激活图可视化" src="Detail/GetImg?filename=images/JSJY201909044_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 类激活图可视化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909044_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Class activation map visualization</p>

                </div>
                <h3 id="102" name="102" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="103">本文将<i>CNN</i>用于木材钻蛀性害虫的声学检测,是一种典型的将信号处理和深度学习结合的应用,基于3<i>D CNN</i>的虫音识别对于海关检测出进口木材中的害虫有着重要作用。尽管目前已经有一些基于深度学习的动物声学检测方法,但在钻蛀性害虫的检测上的应用尚属首次。传统方法往往需要复杂的消噪、滤波器及算法设计过程,而与传统信号处理方法不同的<i>CNN</i>能有效地从虫声中提取特征,无需手工进行相关的滤波器和算法设计。具体地讲,<i>CNN</i>可以提取语谱图中害虫发声的时频特征,训练出合适的卷积滤波器,从而完成害虫的自动检测任务。表1和表3表明本文提出的3<i>D CNN</i>模型能够有效、准确地解决这个问题。同时与2<i>D CNN</i>的比较也表明,3<i>D CNN</i>能够学习和利用到长序列中2<i>D CNN</i>无法学习到的高层信息,更准确地识别害虫。本文为将深度学习应用到海关检疫中的初步研究。尽管使用了31种害虫活动和进食的数据,仍然无法充分反映检疫现场的复杂环境。在未来,随着更多数据的获得,将能够构建更有效的判决模型,甚至对害虫的类别进行区分。此外,如何将降噪网络和<i>CNN</i>结合以实现更高的准确率,也是下一步的工作重点。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="188">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLBC201505003&amp;v=MTA4NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVmJ6Qk5pSEpiYkc0SDlUTXFvOUZaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李瑞法,张学勤,陈莹,等.我国进境原木主要疫情分析[J].中国森林病虫,2015,34(5):8-11.(LI R F,ZHANG X Q,CHEN Y,et al.Analysis on main epidemic situation of pests in imported logs [J].Forest Pest and Disease,2015,34(5):8-11.)
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZWJY201301004&amp;v=MjY0NDl1WnNGeWpuVmJ6QlB6ckJkN0c0SDlMTXJvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 娄定风,许小芳,李嘉,等.6种木材钻蛀性昆虫的声学特征与比较[J].植物检疫,2013,27(1):6-10.(LOU D F,XU X F,LI J,et al.Acoustic characteristics and their comparison of six species of wood borers [J].Plant Quarantine,2013,27(1):6-10.)
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vibro-acoustic methods of insect detection in agricultural shipments and wood packing materials">

                                <b>[3]</b> SUTIN A,FLYNN T,SALLOUM,H,et al.Vibro-acoustic methods of insect detection in agricultural shipments and wood packing materials[C]// Proceedings of the 2017 IEEE International Symposium on Technologies for Homeland Security.Piscataway,NJ:IEEE,2017:1-6.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KCTD201603012&amp;v=MTc2OTBac0Z5am5WYnpCTGk3ZmFyRzRIOWZNckk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 祁骁杰,卜宇飞,许志春,等.杨树木段内光肩星天牛幼虫数量的声学检测[J].环境昆虫学报,2016,38(3):529-534.(QI X J,BU Y F,XU Z C,et al.Using acoustic technology detect the different numbers of anoplophora glabripennis larvae in poplar [J].Journal of Environmental Entomology,2016,38(3):529-534.)
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks">

                                <b>[5]</b> PARSONS S,JONES G.Acoustic identification of twelve species of echolocating bat by discriminant function analysis and artificial neural networks [J].Journal of Experimental Biology,2000,203(17):2641-2656.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detection of sunn pests using sound signal processing methods">

                                <b>[6]</b> YAZGAÇ B G,KIRCI M,KIVAN M.Detection of sunn pests using sound signal processing methods [C]// Proceedings of the 2016 5th International Conference on Agro-Geoinformatics (Agro-Geoinformatics).Piscataway,NJ:IEEE,2016:1-6.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring">

                                <b>[7]</b> ZILLI D,PARSON O,MERRETT G,et al.A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring[C]// Proceedings of the 23rd International Joint Conference on Artificial Intelligence.Palo Alto,CA:AAAI Press,2013:2945-2951.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speech based human emotion recognition using MFCC">

                                <b>[8]</b> LIKITHA M S,GUPTA S R R,HASITHA K,et al.Speech based human emotion recognition using MFCC [C]// Proceedings of the 2017 International Conference on Wireless Communications,Signal Processing and Networking.Piscataway,NJ:IEEE,2017:2257-2260.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic acoustic identification of crickets and cicadas">

                                <b>[9]</b> POTAMITIS I,GANCHEV T,FAKOTAKIS N.Automatic acoustic identification of crickets and cicadas[C]// Proceedings of the 9th International Symposium on Signal Processing and Its Applications.Piscataway,NJ:IEEE,2007:1-4.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Insect sound recognition based on convolutional neural network">

                                <b>[10]</b> DONG X,YAN N,WEI Y.Insect sound recognition based on convolutional neural network [C]// Proceedings of the IEEE 3rd International Conference on Image,Vision and Computing.Piscataway,NJ:IEEE,2018:855-859.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bioacoustic detection with wavelet-conditioned convolutional neural networks">

                                <b>[11]</b> KISKIN I,ZILLI D,LI Y,et al.Bioacoustic detection with wavelet-conditioned convolutional neural networks [EB/OL].[2018- 12- 28].https://link.springer.com/article/10.1007/s00521-018-3626-7.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cascaded CNN-resBiLSTM-CTC:an end-to-end acoustic model for speech recognition">

                                <b>[12]</b> ZHOU X,LI J,ZHOU X.Cascaded CNN-resBiLSTM-CTC:an end-to-end acoustic model for speech recognition [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1810.12001.pdf.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700296012&amp;v=MjIzODRxSTlGWnVJSkRIMDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRndTYVJzPU5pZk9mYks4SDlETQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> SCHMIDHUBER J.Deep learning in neural networks:an overview[J].Neural Networks,2015,61:85-117.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sign language recognition using 3D convolutional neural networks">

                                <b>[14]</b> HUANG J,ZHOU W,LI H,et al.Sign language recognition using 3D convolutional neural networks[C]// Proceedings of the 2015 IEEE International Conference on Multimedia and Expo.Piscataway,NJ:IEEE,2015:1-6.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift">

                                <b>[15]</b> IOFFE S,SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift [C]// Proceedings of the 32nd International Conference on International Conference on Machine Learning.Brookline,MA:JMLR,2015,37:448-456.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 SRIVASTAVA N,HINTON G,KRIZHEVSKY A,et al.Dropout:a simple way to prevent neural networks from overfitting [J].Journal of Machine Learning Research,2014,15(1):1929-1958.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=TensorFlow:a system for large-scale machine learning">

                                <b>[17]</b> ABADI M,BARHAM P,CHEN J,et al.TensorFlow:a system for large-scale machine learning [C]// Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation.Berkeley,CA:USENIX Association,2016:265-283.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using the receiver operating characteristic to assess the performance of neural classifiers">

                                <b>[18]</b> DOWNEY T J,MEYER D J,PRICE R K,et al.Using the receiver operating characteristic to asses the performance of neural classifiers [C]// Proceedings of the 1999 International Joint Conference on Neural Networks.Piscataway,NJ:IEEE,1999:3642-3646.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ADADELTA:an adaptive learning rate method">

                                <b>[19]</b> ZEILER M D.ADADELTA:an adaptive learning rate method [EB/OL].[2019- 02- 01].https://arxiv.org/pdf/1212.5701.pdf.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Grad-CAM:visual explanations from deep networks via gradient-based localization">

                                <b>[20]</b> SELVARAJU R R,COGSWELL M,DAS A,et al.Grad-CAM:visual explanations from deep networks via gradient-based localization [C]// Proceedings of the 2017 IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2017,1:618-626.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909044" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909044&amp;v=MTAwMjU3RzRIOWpNcG85QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WYnpCTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
