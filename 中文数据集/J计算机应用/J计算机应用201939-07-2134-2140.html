<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136667140940000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907046%26RESULT%3d1%26SIGN%3dtLckA2gziTGkYU8TQRMXI8RkaOg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907046&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907046&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907046&amp;v=MjM2MzBac0Z5L2dWNy9BTHo3QmQ3RzRIOWpNcUk5QllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 本文方法 ">2 本文方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="2.1 &lt;b&gt;预处理&lt;/b&gt;">2.1 <b>预处理</b></a></li>
                                                <li><a href="#69" data-title="2.2 &lt;b&gt;局部熵&lt;/b&gt;">2.2 <b>局部熵</b></a></li>
                                                <li><a href="#74" data-title="2.3 &lt;b&gt;结合局部熵和&lt;/b&gt;RPCA&lt;b&gt;的检测方法&lt;/b&gt;">2.3 <b>结合局部熵和</b>RPCA<b>的检测方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="3.1 &lt;b&gt;实验数据及评价指标&lt;/b&gt;">3.1 <b>实验数据及评价指标</b></a></li>
                                                <li><a href="#113" data-title="3.2 &lt;b&gt;实验结果与分析&lt;/b&gt;">3.2 <b>实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="图1 本文方法流程">图1 本文方法流程</a></li>
                                                <li><a href="#65" data-title="图2 含病变的眼底图像">图2 含病变的眼底图像</a></li>
                                                <li><a href="#67" data-title="图3 预处理">图3 预处理</a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;基于病灶水平上不同颜色通道检测比较&lt;/b&gt;"><b>表</b>1 <b>基于病灶水平上不同颜色通道检测比较</b></a></li>
                                                <li><a href="#122" data-title="图4 亮度和局部熵检测结果对比">图4 亮度和局部熵检测结果对比</a></li>
                                                <li><a href="#126" data-title="图5 不同&lt;i&gt;λ&lt;/i&gt;值的HE检测结果">图5 不同<i>λ</i>值的HE检测结果</a></li>
                                                <li><a href="#127" data-title="图6 不同方法在e-ophtha EX和DIARETDB1数据库的检测结果">图6 不同方法在e-ophtha EX和DIARETDB1数据库的检测结果</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同方法在&lt;/b&gt;e-ophtha EX&lt;b&gt;数据库上检测结果&lt;/b&gt;"><b>表</b>2 <b>不同方法在</b>e-ophtha EX<b>数据库上检测结果</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同方法的评价指标结果比较&lt;/b&gt;"><b>表</b>3 <b>不同方法的评价指标结果比较</b></a></li>
                                                <li><a href="#138" data-title="图7 本文视盘错误分割及HE检测结果">图7 本文视盘错误分割及HE检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="173">


                                    <a id="bibliography_1" title=" 肖志涛, 王雯, 耿磊, 等.基于背景估计和SVM分类器的眼底图像硬性渗出物检测方法[J].中国生物医学工程学报, 2015, 34 (6) :720-728. (XIAO Z T, WANG W, GENG L, et al.Hard exudates detection method based on background-estimation and SVM classifier[J].Chinese Journal of Biomedical Engineering, 2015, 34 (6) :720-728.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSWY201506012&amp;v=MDkxODRkN0c0SDlUTXFZOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVjcvQVB6N2M=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         肖志涛, 王雯, 耿磊, 等.基于背景估计和SVM分类器的眼底图像硬性渗出物检测方法[J].中国生物医学工程学报, 2015, 34 (6) :720-728. (XIAO Z T, WANG W, GENG L, et al.Hard exudates detection method based on background-estimation and SVM classifier[J].Chinese Journal of Biomedical Engineering, 2015, 34 (6) :720-728.) 
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_2" title=" WELFER D, SCHARCANSKI J, MARINHO D R.A coarse-to-fine strategy for automatically detecting exudates in color eye fundus images[J].Computerized Medical Imaging Graphics, 2010, 34 (3) :228-235." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300048989&amp;v=MTQ0NTdycVFUTW53WmVadEZpbmxVcjNJSjFzUWFobz1OaWZPZmJLN0h0RE9ySTlGWk84SEJYUXdvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         WELFER D, SCHARCANSKI J, MARINHO D R.A coarse-to-fine strategy for automatically detecting exudates in color eye fundus images[J].Computerized Medical Imaging Graphics, 2010, 34 (3) :228-235.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_3" title=" WALTER T, KLEIN J C, MASSIN P, et al.A contribution of image processing to the diagnosis of diabetic retinopathy detection of exudates in color fundus images of the human retina[J].IEEE Transactions on Medical Imaging, 2002, 21 (10) :1236-1243." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A contribution of image processing to the diagnosis of diabetic retinopathy - Detection of exudates in color fundus images of the human retina">
                                        <b>[3]</b>
                                         WALTER T, KLEIN J C, MASSIN P, et al.A contribution of image processing to the diagnosis of diabetic retinopathy detection of exudates in color fundus images of the human retina[J].IEEE Transactions on Medical Imaging, 2002, 21 (10) :1236-1243.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_4" title=" QI F C, LI G, ZHENG S B.Automatic exudate detection in color fundus images[J].Digital TV and Wireless Multimedia Communication, 2017, 685:155-165." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic exudate detection in color fundus images">
                                        <b>[4]</b>
                                         QI F C, LI G, ZHENG S B.Automatic exudate detection in color fundus images[J].Digital TV and Wireless Multimedia Communication, 2017, 685:155-165.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_5" title=" SANTHI D, MANIMEGALAI D, PARVATHI S, et al.Segmentation and classification of bright lesions to diagnose diabetic retinopathy in retinal images[J].Biomedizinische Technik (BIOMED TECH) , 2016, 61 (4) :443-453." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJDG&amp;filename=SJDG91E91735DF15FEB6C356C7CCDB3D539E&amp;v=MDk1MThhUlJyUHFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3NzI3d0tBPU5pZlBhYnE1YTlqTnFJeEFFSjBPQ1FwTXZSQmc2VHA3TzNpUjMyWkhlcw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         SANTHI D, MANIMEGALAI D, PARVATHI S, et al.Segmentation and classification of bright lesions to diagnose diabetic retinopathy in retinal images[J].Biomedizinische Technik (BIOMED TECH) , 2016, 61 (4) :443-453.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_6" title=" 曹新容, 林嘉雯, 薛岚燕, 等.邻域约束模型的眼底图像硬性渗出聚类检测方法[J].计算机辅助设计与图形学学报, 2018, 30 (11) :2093-2100. (CAO X R, LIN J W, XUE L Y, et al.Clustering detection method of hard exudates in fundus image based on neighborhood constraint model[J].Journal of Computer-Aided Design and Computer Graphics, 2018, 30 (11) :2093-2100.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201811013&amp;v=MjMxMDhIOW5Ocm85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWNy9BTHo3QmFMRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         曹新容, 林嘉雯, 薛岚燕, 等.邻域约束模型的眼底图像硬性渗出聚类检测方法[J].计算机辅助设计与图形学学报, 2018, 30 (11) :2093-2100. (CAO X R, LIN J W, XUE L Y, et al.Clustering detection method of hard exudates in fundus image based on neighborhood constraint model[J].Journal of Computer-Aided Design and Computer Graphics, 2018, 30 (11) :2093-2100.) 
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_7" title=" SOPHARAK A, UYYANONVARA B, BARMAN S, et al.Comparative analysis of automatic exudate detection algorithms [C]// WCE 2010:Proceedings of the 2010 World Congress on Engineering.London:[s.n.], 2010:738-741." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparative Analysis of Automatic Exudate Detection Algorithms">
                                        <b>[7]</b>
                                         SOPHARAK A, UYYANONVARA B, BARMAN S, et al.Comparative analysis of automatic exudate detection algorithms [C]// WCE 2010:Proceedings of the 2010 World Congress on Engineering.London:[s.n.], 2010:738-741.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_8" title=" BIYANI R S, PATRE B M.A clustering approach for exudates detection in screening of diabetic retinopathy[C]// Proceedings of the 2016 International Conference on Signal and Information Processing.Washington, DC:IEEE Computer Society, 2016:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A clustering approach for exudates detection in screening of diabetic retinopathy">
                                        <b>[8]</b>
                                         BIYANI R S, PATRE B M.A clustering approach for exudates detection in screening of diabetic retinopathy[C]// Proceedings of the 2016 International Conference on Signal and Information Processing.Washington, DC:IEEE Computer Society, 2016:1-5.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_9" title=" ASHA P R, KARPAGAVALLI S.Diabetic retinal exudates detection using machine learning techniques[C]// Proceedings of the 2015 International Conference on Advanced Computing and Communication System.Piscataway, NJ:IEEE, 2015:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Diabetic retinal exudates detection using machine learning techniques">
                                        <b>[9]</b>
                                         ASHA P R, KARPAGAVALLI S.Diabetic retinal exudates detection using machine learning techniques[C]// Proceedings of the 2015 International Conference on Advanced Computing and Communication System.Piscataway, NJ:IEEE, 2015:1-5.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_10" title=" ADEM K.Exudate detection for diabetic retinopathy with circular Hough transformation and convolutional neural networks[J].Expert Systems with Applications, 2018, 11:289-295." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF2D615501C32C5A200F1151249A8CFBE&amp;v=MDY0ODdxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzcyN3dLQT1OaWZPZmNXNmF0Zk5xb3BGWlpnTURnODh2aFFUNmtsOFNYcmpyaFk4Q0xybk04ag==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         ADEM K.Exudate detection for diabetic retinopathy with circular Hough transformation and convolutional neural networks[J].Expert Systems with Applications, 2018, 11:289-295.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_11" title=" PARHAM K, PASSOS J L A, TIAGO C, et al.Exudate detection in fundus images using deeply-learnable features [J].Computers in Biology and Medicine, 2018, 104:62-69." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8DC7925AB90BC12C1C8F4EF000B78B39&amp;v=MDQ0MjVkYkZyWW8wRnVJUGZnODR6V1VTbVRjTFRBcVVyQkkxQzdXY043bVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3NzI3d0tBPU5pZk9mYnZNYg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         PARHAM K, PASSOS J L A, TIAGO C, et al.Exudate detection in fundus images using deeply-learnable features [J].Computers in Biology and Medicine, 2018, 104:62-69.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_12" title=" AMIN J, SHARIF M, YASMIN M, et al.A method for the detection and classification of diabetic retinopathy using structural predictors of bright lesions [J].Journal of Computational Science, 2017, 19:153-164." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES17276F6D0BCA387DD198AF1CADDF845F&amp;v=MjI4NzdGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3Mjd3S0E9TmlmT2ZiSy9ITmJLMllreFpKbDhmWDh4eUdKbjZ6WjFPUW5qMzJOQkRjU2NRYi9wQ09OdkZTaVdXcjdKSQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         AMIN J, SHARIF M, YASMIN M, et al.A method for the detection and classification of diabetic retinopathy using structural predictors of bright lesions [J].Journal of Computational Science, 2017, 19:153-164.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_13" title=" WRIGHT J, GANESH A, RAO S, et al.Robust principal component analysis:exact recovery of corrupted low-rank matrices via convex optimization [EB/OL].[2018- 12- 10].https://arxiv.org/pdf/0905.0233v1.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust principal component analysis:exact recovery of corrupted low-rank matrices via convex optimization">
                                        <b>[13]</b>
                                         WRIGHT J, GANESH A, RAO S, et al.Robust principal component analysis:exact recovery of corrupted low-rank matrices via convex optimization [EB/OL].[2018- 12- 10].https://arxiv.org/pdf/0905.0233v1.pdf.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_14" title=" XIAO L, FANG B, LIU L H, et al.Extracting sparse error of robust PCA for face recognition in the presence of varying illumination and occlusion[J].Pattern Recognition, 2014, 47 (2) :495-508." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300161977&amp;v=MTcxNzZlcnFRVE1ud1plWnRGaW5sVXIzSUoxc1FhaG89TmlmT2ZiSzlIOVBPckk5RlplME9CWHMrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         XIAO L, FANG B, LIU L H, et al.Extracting sparse error of robust PCA for face recognition in the presence of varying illumination and occlusion[J].Pattern Recognition, 2014, 47 (2) :495-508.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_15" title=" YAN J C, ZHU M Y, LIU H X, et al.Visual saliency detection via sparsity pursuit [J].IEEE Signal Processing Letters, 2010, 17 (8) :739-742." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual Saliency Detection via Sparsity Pursuit">
                                        <b>[15]</b>
                                         YAN J C, ZHU M Y, LIU H X, et al.Visual saliency detection via sparsity pursuit [J].IEEE Signal Processing Letters, 2010, 17 (8) :739-742.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_16" title=" 仓园园, 孙玉宝, 刘青山.基于分层鲁棒主成分分析的运动目标检测[J].计算机辅助设计与图形学学报, 2014, 23 (4) :537-544. (CANG Y Y, SUN Y B, LIU Q S.Moving object detection based on hierarchical robust principal component analysis [J].Journal of Computer-Aided Design and Computer Graphics, 2014, 23 (4) :537-544.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201404004&amp;v=MDI4MDU3cWZadVpzRnkvZ1Y3L0FMejdCYUxHNEg5WE1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         仓园园, 孙玉宝, 刘青山.基于分层鲁棒主成分分析的运动目标检测[J].计算机辅助设计与图形学学报, 2014, 23 (4) :537-544. (CANG Y Y, SUN Y B, LIU Q S.Moving object detection based on hierarchical robust principal component analysis [J].Journal of Computer-Aided Design and Computer Graphics, 2014, 23 (4) :537-544.) 
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_17" title=" CAND&#201;S E J, LI X, MA Y, et al.Robust principal component analysis?[J].Journal of the ACM, 2011, 58 (3) :Article No.11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001869&amp;v=MDA4Njd0RmlubFVyM0lKMXNRYWhvPU5pZklZN0s3SHRqTnI0OUZaT3NPQkhvd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         CAND&#201;S E J, LI X, MA Y, et al.Robust principal component analysis?[J].Journal of the ACM, 2011, 58 (3) :Article No.11.
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_18" title=" AZIZI S, SAMAVI S, MOHREKESH M, et al.Cascaded transform space watermarking based on analysis of local entropy variation[C]// Proceedings of the 2013 International Conference on Multimedia and Expo Workshops.Piscataway, NJ:IEEE, 2013:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cascaded transform space watermarking based on analysis of local entropy variation">
                                        <b>[18]</b>
                                         AZIZI S, SAMAVI S, MOHREKESH M, et al.Cascaded transform space watermarking based on analysis of local entropy variation[C]// Proceedings of the 2013 International Conference on Multimedia and Expo Workshops.Piscataway, NJ:IEEE, 2013:1-6.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_19" title=" 付晓薇, 代芸, 陈黎, 等.基于局部熵的量子衍生医学超声图像去斑[J].电子与信息学报, 2015, 37 (3) :560-566. (FU X W, DAI Y, CHEN L, et al.Quantum-inspired despeckling of medical ultrasound images based on local entropy[J].Journal of Electronics and Information Technology, 2015, 37 (3) :560-566.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201503008&amp;v=MTk1NzVGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y3L0FJVGZTZHJHNEg5VE1ySTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         付晓薇, 代芸, 陈黎, 等.基于局部熵的量子衍生医学超声图像去斑[J].电子与信息学报, 2015, 37 (3) :560-566. (FU X W, DAI Y, CHEN L, et al.Quantum-inspired despeckling of medical ultrasound images based on local entropy[J].Journal of Electronics and Information Technology, 2015, 37 (3) :560-566.) 
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_20" title=" MASSIN P, CHABOUIS A, ERGINAY A, et al.OPHDIAT&#169;:A telemedical network screening system for diabetic retinopathy in the &#206;le-de-France [J].Diabetes and Metabolism, 2008, 34 (3) :227-234." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300890436&amp;v=MTMwMDlIOC9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXNRYWhvPU5pZk9mYks3SHRETnJJOUZiT0lQQw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         MASSIN P, CHABOUIS A, ERGINAY A, et al.OPHDIAT&#169;:A telemedical network screening system for diabetic retinopathy in the &#206;le-de-France [J].Diabetes and Metabolism, 2008, 34 (3) :227-234.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_21" title=" DECENCIERE E, CAZUGUEL G, ZHANG X W, et al.TeleOphta:machine learning and image processing methods for teleophthalmology[J].Innovation and Research in BioMedical Engineering, 2013, 34 (2) :196-203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900002323&amp;v=Mjg5MTZaT3NORDM0Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxc1FhaG89TmlmT2ZiSzdIdFRNcG85Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         DECENCIERE E, CAZUGUEL G, ZHANG X W, et al.TeleOphta:machine learning and image processing methods for teleophthalmology[J].Innovation and Research in BioMedical Engineering, 2013, 34 (2) :196-203.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_22" title=" ZHANG X W, THIBAULT G, DECENCI&#200;RE E, et al.Exudate detection in color retinal images for mass screening of diabetic retinopathy[J].Medical Image Analysis, 2014, 18 (7) :1026-1043." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700254868&amp;v=MDAyOTNIb3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXNRYWhvPU5pZk9mYks4SHRmTnFJOUZadTRMQg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         ZHANG X W, THIBAULT G, DECENCI&#200;RE E, et al.Exudate detection in color retinal images for mass screening of diabetic retinopathy[J].Medical Image Analysis, 2014, 18 (7) :1026-1043.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-28 15:28</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),2134-2140 DOI:10.11772/j.issn.1001-9081.2019010208            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合局部熵和鲁棒主成分分析的眼底图像硬性渗出物检测方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E8%8E%89&amp;code=15579767&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈莉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%99%93%E4%BA%91&amp;code=06680401&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈晓云</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A6%8F%E5%BB%BA%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%8C%BB%E5%AD%A6%E9%99%A2&amp;code=0085099&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">福建医科大学基础医学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A6%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0094575&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">福州大学数学与计算机科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对眼科医生诊断眼底图像工作耗时且易出错的问题, 提出一种无监督的眼底图像硬性渗出物检测方法。首先, 通过形态学的背景估计方法去除血管、暗病变区域和视盘;然后, 以图像亮度通道为初始图像, 利用硬性渗出物在眼底图像中的局部性和稀疏性, 结合局部熵和鲁棒主成分分析方法分解得到低秩矩阵和稀疏矩阵;最后, 归一化稀疏矩阵得到硬性渗出物区域。实验结果显示, 在e-ophtha EX和DIARETDB1公开数据库上, 所提方法在病灶水平上灵敏性为91.13%和特异性为90%, 在图像水平上准确率为99.03%, 平均运行时间0.5 s;与支持向量机 (SVM) 和<i>K</i>-means方法相比灵敏性高且耗时少。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A1%AC%E6%80%A7%E6%B8%97%E5%87%BA%E7%89%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">硬性渗出物;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%B2%81%E6%A3%92%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁棒主成分分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E7%86%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部熵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E6%99%AF%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背景估计;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A9%E8%89%B2%E7%9C%BC%E5%BA%95%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彩色眼底图像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈莉 (1980—) , 女, 福建福清人, 讲师, 硕士, 主要研究方向:模式识别、医学图像处理;;
                                </span>
                                <span>
                                    *陈晓云 (1970—) , 女, 福建福州人, 教授, 博士, 主要研究方向:机器学习、模式识别。电子邮箱c_xiaoyun@fzu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (71273053, 11571074);</span>
                                <span>福建省自然科学基金资助项目 (2018J01666);</span>
                    </p>
            </div>
                    <h1><b>Detection method of hard exudates in fundus images by combining local entropy and robust principal components analysis</b></h1>
                    <h2>
                    <span>CHEN Li</span>
                    <span>CHEN Xiaoyun</span>
            </h2>
                    <h2>
                    <span>School of Basic Medical Sciences, Fujian Medical University</span>
                    <span>College of Mathematics and Computer Science, Fuzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the time-consuming and error-prone problem in the diagnosis of fundus images by the ophthalmologists, an unsupervised automatic detection method for hard exudates in fundus images was proposed. Firstly, the blood vessels, dark lesion regions and optic disc were removed by using morphological background estimation in preprocessing phase. Then, with the image luminosity channel taken as the initial image, the low rank matrix and sparse matrix were obtained by combining local entropy and Robust Principal Components Analysis (RPCA) based on the locality and sparsity of hard exudates in fundus images. Finally, the hard exudates regions were obtained by the normalized sparse matrix. The performance of the proposed method was tested on the fundus images databases e-ophtha EX and DIARETDB1. The experimental results show that the proposed method can achieve 91.13% of sensitivity and 90% of specificity in the lesional level and 99.03% of accuracy in the image level and 0.5 s of average running time. It can be seen that the proposed method has higher sensitivity and shorter running time compared with Support Vector Machine (SVM) method and <i>K</i>-means method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hard%20exudate&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hard exudate;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Robust%20Principal%20Components%20Analysis%20(RPCA)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Robust Principal Components Analysis (RPCA) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=local%20entropy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">local entropy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=background%20estimation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">background estimation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20fundus%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color fundus image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHEN Li, born in 1980, M. S. , lecturer. Her research interests include pattern recognition, medical image processing. ;
                                </span>
                                <span>
                                    CHEN Xiaoyun, born in 1970, Ph. D. , professor. Her research interests include data mining, pattern recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-28</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (71273053, 11571074);</span>
                                <span>the Natural Science Foundation of Fujian Province (2018J01666);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="50">糖尿病视网膜病变 (Diabetic Retinopathy, DR) 是糖尿病最严重的并发症之一, 而硬性渗出物 (Hard Exudates, HE) 是糖尿病视网膜病变最重要的早期症状之一, 也是糖尿病患者视力损伤或致盲的主要原因。在彩色眼底图像中HE是一种亮的病变区域, 表现为边界清晰的蜡样黄白色斑点或斑块, 其形状大小各不同<citation id="217" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 而视盘呈近似椭圆形状的亮黄色斑块, 微动脉瘤呈暗红色近似小圆点形状, 在颜色、结构和纹理上HE与视盘、血管和微动脉瘤等暗红色病变具有相似特征, 这导致在眼科医生诊断大量的眼底图像容易出错且耗时, 因此快速准确地检测HE是计算机辅助眼底图像筛查和诊断技术一个艰难而关键的问题。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">1 相关研究</h3>
                <div class="p1">
                    <p id="52">目前, 关于眼底图像中HE的检测主要分为四类方法。</p>
                </div>
                <div class="p1">
                    <p id="53">第一类是基于形态学的检测方法。如Welfer等<citation id="218" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>将彩色眼底图像RGB转换为LUV (CIE 1976 (L<sup>*</sup>, u<sup>*</sup>, v<sup>*</sup>) , CIELUV) 彩色空间, 在L通道上采用顶帽变换和底帽变换来增强图像的对比度, 再利用形态学重建完成HE提取;Walter等<citation id="219" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>先利用形态学闭运算去除血管, 然后根据局部阈值得到候选区域, 同时去除视盘区域, 最后利用形态学重建完成HE的提取。</p>
                </div>
                <div class="p1">
                    <p id="54">第二类是基于阈值分割或区域生长的检测方法。如Qi等<citation id="220" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>将RGB眼底图像转为YIQ彩色图像, 利用阈值和Krisch边缘算子检测HE;Santhi等<citation id="221" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出基于背景修正的自适应区域生长法分割HE亮病变区域。</p>
                </div>
                <div class="p1">
                    <p id="55">第三类是基于无监督的检测方法。如曹新容等<citation id="222" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出基于邻域约束模型的聚类检测方法, 将邻域的最大灰度变化作为约束条件判定是否有HE;Sopharak等<citation id="223" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提取彩色眼底图像的强度、强度的标准差、色调和边缘等4维特征进行模糊C均值 (Fuzzy C Means, FCM) 聚类, 并且与支持向量机 (Support Vector Machine, SVM) 、最近邻 (Nearest Neighbors, NN) 、朴素贝叶斯分类器 (Naive Bayes, NB) 分别进行对比分析, 实验结果显示FCM的检测方法在灵敏性优于有监督的分类方法。Biyani等<citation id="224" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>先从HSI (Hue Saturation Intensity) 彩色空间的强度通道采用Ostu阈值分割出视盘, 接着用<i>K</i>-means方法分割出候选HE, 提取相应的颜色、强度、纹理、中值滤波和像素局部变化五个特征进行<i>K</i>-means聚类得到分割结果, 最后用形态学重建完成最后的HE提取。</p>
                </div>
                <div class="p1">
                    <p id="56">第四类是基于有监督的分类方法。如肖志涛等<citation id="225" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>先通过背景估计和Kirsch算子的边缘信息确定HE的候选区域, 提取灰度、形状和相位一致性等特征采用SVM分类器对候选区域进行分类得到HE的提取。Asha等<citation id="226" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>从LUV彩色空间中提取均值、方差、质心和边缘等18维特征分别采用NB、多层感知机 (MultiLayer Perceptron, MLP) 和极限学习机 (Extreme Learning Machine, ELM) 分类器进行HE检测, 实验结果显示ELM优于其他两种分类器。Adem<citation id="227" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将霍夫变换和卷积神经网络 (Convolutional Neural Network, CNN) 相结合用于检测HE, Parham等<citation id="228" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>比较多个深度学习的模型, 实验表明ResNet (Residual Network) 的深度学习模型结合SVM效果最好。Amin等<citation id="229" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将RGB图像转成灰度图像, 利用Gabor滤波增强病变的对比度, 通过高斯滤波、阈值和形态学重建去除视盘得到候选HE区域, 提取这些区域的面积、周长、环状和直径四个特征采用SVM、NB等多种分类器在DIARETDB1 (Standard Diabetic Retinopathy Database Calibration level 1) 、e-ophtha (e-ophtha Color Fundus Image Database) 、DRIVE (Digital Retinal Images for Vessel Extraction) 、MESSIDOR (Methods To Evaluate Segmentation And Indexing Techniques In The Field Of Retinal Ophthalmology) 、HRF (High Resolution Fundus) 等多个公开数据库上进行分类。</p>
                </div>
                <div class="p1">
                    <p id="57">尽管已有的检测方法能较好地检测眼底图像中的HE, 但以上所述的形态学或阈值等检测方法针对不同的数据库需要调整阈值参数, 不具有普遍性;有监督的检测方法 (如SVM、NB、ELM等) 需专家手动标记HE病变区域为标准, 这给临床检测带来很大的困难;CNN检测方法虽不需要选取特征且检测效果好, 但需要大量的训练样本且耗时, 因此迫切需要一个快速、有效的检测方法来实现眼底图像HE的自动分割。</p>
                </div>
                <div class="p1">
                    <p id="58">鲁棒主成分分析 (Robust Principal Components Analysis, RPCA) 方法, 又称低秩矩阵恢复, 最早是由Wright等<citation id="230" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出, 其思想是当矩阵的某些元素被严重破坏后, 能自动识别被破坏的元素并恢复其原始矩阵。将含被破坏的数据矩阵<b><i>D</i></b>分解为两个矩阵相加的形式, 即<b><i>D</i></b>=<b><i>L</i></b>+<b><i>S</i></b>, 其中:<b><i>L</i></b>是低秩矩阵, 逼近原始数据矩阵;<b><i>S</i></b>是稀疏矩阵, 即含噪声的数据矩阵。近年来, 基于矩阵低秩稀疏分解的鲁棒主成分分析方法被成功应用于图像人脸识别<citation id="231" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、显著性目标检测<citation id="235" type="reference"><link href="201" rel="bibliography" /><link href="203" rel="bibliography" /><link href="205" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>等计算机视觉领域。从认知科学的角度看, 图像信息可以分为背景部分和显著性目标。背景部分代表冗余信息, 而显著性目标则代表图像中人们视觉注意的部分<citation id="232" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。从子空间分析角度看, 图像的背景具有较强的相关性, 近似位于同一低秩的子空间;而显著性目标与背景差异性较大, 偏离该低秩空间, 是稀疏分布的。Xiao等<citation id="233" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>将RPCA方法用于人脸识别, 将人脸图像分解成低秩矩阵和稀疏矩阵, 其中稀疏矩阵代表人脸的局部特征, 如眼镜、围巾等面部显著性特征, 低秩矩阵则代表去除面部特征的人脸图像。Candes等<citation id="234" type="reference"><link href="205" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>将RPCA方法用于视频监控的背景建模, 稳定的背景部分表示低秩部分, 运动的显著性目标代表视频的前景, 即稀疏部分。不论是动态的视频还是静态的图像, RPCA都能较好地将图像分解成低秩的背景和稀疏的显著性目标两个部分。</p>
                </div>
                <div class="p1">
                    <p id="59">考虑彩色眼底图像的背景在颜色、强度、亮度等像素特征上具有很强的相似性, 而HE病变区域与背景差异较大, 是局部且稀疏分布的, 因此本文将RPCA的思想应用于HE病变区域检测, 即将彩色眼底图像通过RPCA方法分解得到的低秩矩阵代表图像背景, 稀疏矩阵表示为HE病变区域, 提出一种无监督的彩色眼底图像硬性渗出物检测方法, 利用形态学的背景估计方法去除血管、暗病变区域和视盘等伪目标, 以图像亮度通道<i>Y</i>为初始图像, 利用HE病变在眼底图像中的局部性和稀疏性, 结合局部熵和RPCA方法得到HE病变区域。该方法不需要专家手动标记HE为标准, 不需要选取多个特征且耗时少, 给眼科临床筛查和诊断带来很大的便利。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 本文方法</h3>
                <div class="p1">
                    <p id="61">本文方法流程如图1所示。首先采用形态学的背景估计方法去除血管及暗病变区域等伪目标, 并在亮度通道上通过形态学重建和自适应阈值方法分割视盘, 然后提取预处理后的亮度通道作为初始图像, 结合局部熵和<i>RPCA</i>低秩稀疏分解得到<i>HE</i>病变区域二值图。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法流程" src="Detail/GetImg?filename=images/JSJY201907046_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Flow chart of the proposed method</i></p>

                </div>
                <h4 class="anchor-tag" id="63" name="63">2.1 <b>预处理</b></h4>
                <div class="p1">
                    <p id="64">如图2所示, 眼底图像中血管、视盘及暗病变区域 (包含微动脉瘤和出血点) 与<i>HE</i>区域有相似的颜色、亮度和纹理结构特征, 为了去除这些伪目标, 本文采用背景估计的方法<citation id="236" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>增强<i>HE</i>区域和背景像素 (包含血管、暗病变区域等) 的对比度。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 含病变的眼底图像" src="Detail/GetImg?filename=images/JSJY201907046_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 含病变的眼底图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Fundus image with lesions</i></p>

                </div>
                <div class="p1">
                    <p id="66">先对灰度图像<b><i>I</i></b><sub>gray</sub> (如图3 (b) ) 进行大小为原始图像大小的1/30的中值滤波处理, 构建一个灰度图像和中值滤波图像<b><i>I</i></b><sub><i>m</i></sub> (如图3 (c) ) 求最大值的掩膜图像<b><i>I</i></b><sub>mask</sub> (如图3 (d) ) ;在此基础上以中值滤波图像为标记图像, 利用形态学重建提取眼底图像的背景<b><i>I</i></b><sub><i>bj</i></sub> (如图3 (e) ) ;将灰度图像与估计的背景图像相减, 得到差值矩阵<b><i>I</i></b> (如图3 (f) ) , 差值小于零的像素即对应灰度图像中的暗区域 (包含血管、其他暗红色病变区域) 。将这些像素置为零, 即去除包含血管和暗红色病变区域等伪目标。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 预处理" src="Detail/GetImg?filename=images/JSJY201907046_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 预处理  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Preprocessing</p>

                </div>
                <div class="p1">
                    <p id="68">去除血管及暗病变区域等伪目标后仍然存在与HE病变区域相似的亮区域 (视盘、邻近血管的神经纤维区域等) , 因此去除视盘是有必要的。由于视盘在眼底图像中呈亮黄色近椭圆形状, 采用形态学重建和自适应阈值的方法分割视盘。先将RGB彩色眼底图像转为YCbCr (Y′CBCR) 彩色眼底图像, 在亮度通道Y (如图3 (g) ) 上进行CLAHE (Contrast Limited Adaptive Histogram Equalization) 增强 (如图3 (h) ) 后作为掩膜图像, 采用大小25×25的中值滤波处理 (如图3 (i) ) 后作为标记图像, 将形态学重建 (如图3 (j) ) 后的图像灰度值范围进行调整, 取其最大面积的连通区域进行膨胀处理 (采用圆盘结构元素 (′disk′, 5) ) 为视盘分割结果 (如图3 (k) ) , 经过多次实验, 图像灰度值范围由[0, 1]调整为[0.55, 0.65]分割效果最好, 最后将视盘的像素置为零作为预处理后图像 (如图3 (l) ) 。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2 <b>局部熵</b></h4>
                <div class="p1">
                    <p id="70">信息熵是图像信息论中用来度量信息量的一个概念, 局部熵反映图像某个区域所含信息量的多少。在图像中某个区域含有的信息量越多, 则图像对比度越好, 更好地突出细节部分;反之, 图像灰度变化不大, 对比度越差<citation id="237" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。对于图像的背景, 相当于无序的噪声, 其局部熵值较均匀且具有较大熵值;对于<i>HE</i>病变区域, 灰度起伏较大, 信息量较大, 其熵值较小。因此局部熵比颜色灰度值更能很好地反映<i>HE</i>病变区域的局部性和显著性。本文定义局部熵<citation id="238" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>为:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mspace width="0.25em" /><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mi>p</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">以像素点 (<i>i</i>, <i>j</i>) 为中心的<i>n</i>×<i>n</i>区域进行熵计算, 得到局部熵特征。其中<i>p</i><sub><i>i</i>, <i>j</i></sub>为图像中像素点 (<i>i</i>, <i>j</i>) 灰度占局部总灰度的概率。</p>
                </div>
                <div class="p1">
                    <p id="73">由于人的肉眼对YCbCr彩色空间中亮度通道Y更敏感, 因此本文在预处理后的亮度通道上以像素点 (<i>i</i>, <i>j</i>) 为中心的9×9区域提取局部熵, 能更好地反映HE病变区域的局部性。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">2.3 <b>结合局部熵和</b>RPCA<b>的检测方法</b></h4>
                <div class="p1">
                    <p id="75">利用<i>HE</i>病变区域在眼底图像中的局部性和稀疏性, 参照传统的<i>RPCA</i><citation id="239" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>方法, 结合局部熵和<i>RPCA</i>低秩稀疏分解方法可表示为下面凸优化的求解模型:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi></mrow></munder><mspace width="0.25em" /><mtext>r</mtext><mtext>a</mtext><mtext>n</mtext><mtext>k</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">) </mo><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Η</mi><mo>=</mo><mi mathvariant="bold-italic">A</mi><mo>+</mo><mi mathvariant="bold-italic">S</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中根据式 (1) 计算眼底图的局部熵<b><i>H</i></b>, <b><i>A</i></b>代表低秩矩阵, <b><i>S</i></b>代表稀疏矩阵, <i>λ</i>是正则化参数, 用于平衡低秩项和稀疏项的效果。rank (·) 是秩函数, 表示非零奇异值的个数, <i>l</i><sub>0</sub>范数‖·‖<sub>0</sub>表示非零元素的个数, 约束稀疏项。由于式 (2) 是NP难题, 可将范数优化问题松弛为<i>l</i><sub>1</sub>范数优化问题, rank函数松弛为核范数, 所以上述模型变为:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Η</mi><mo>=</mo><mi mathvariant="bold-italic">A</mi><mo>+</mo><mi mathvariant="bold-italic">S</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中核范数‖·‖<sub>*</sub> (矩阵所有奇异值之和) 和<i>l</i><sub>1</sub>范数 (矩阵所有元素绝对值之和) 分别是秩函数和<i>l</i><sub>0</sub>范数的最小凸近似。式 (3) 求解问题可转变为对应的增广拉格朗日函数:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo>, </mo><mspace width="0.25em" /><mi>μ</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo></mtd></mtr><mtr><mtd><mo>〈</mo><mi mathvariant="bold-italic">Y</mi><mo>, </mo><mi mathvariant="bold-italic">Η</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">S</mi><mo>〉</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Η</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其中<b><i>Y</i></b>是拉格朗日乘子, <i>μ</i>&gt;0是惩罚参数, 〈·〉表示内积运算, ‖·‖<sub>F</sub>为F范数。采用不精确拉格朗日乘子法 (Inexact Augmented Lagrange Multiplier, IALM) 求解式 (4) 过程中, 当<b><i>Y</i></b>=<b><i>Y</i></b><sub><i>t</i></sub>, <i>μ</i>=<i>μ</i><sub><i>t</i></sub>时, 使用交替式方法求解块优化问题<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi></mrow></munder><mspace width="0.25em" /><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>。固定其余变量, 交替更新其中一个变量, 直到满足收敛条件为止。具体更新过程如下。</p>
                </div>
                <div class="p1">
                    <p id="83">1) 固定<b><i>S</i></b><sub><i>t</i></sub>, <b><i>Y</i></b><sub><i>t</i></sub>, <i>μ</i><sub><i>t</i></sub>更新<b><i>A</i></b><sub><i>t</i>+1</sub>:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">A</mi></munder><mspace width="0.25em" /><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>, </mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">A</mi></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Η</mi><mo>-</mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub><mo>+</mo><mfrac><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">2) 固定<b><i>A</i></b><sub><i>t</i></sub>, <b><i>Y</i></b><sub><i>t</i></sub>, <i>μ</i><sub><i>t</i></sub>更新<b><i>S</i></b><sub><i>t</i>+1</sub>:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">S</mi></munder><mspace width="0.25em" /><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">S</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">S</mi></munder><mspace width="0.25em" /><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub></mrow><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><mo>-</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Η</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub><mo>+</mo><mfrac><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mrow><msup><mrow></mrow><mi>t</mi></msup></mrow></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">3) 固定<b><i>A</i></b><sub><i>t</i></sub>, <b><i>S</i></b><sub><i>t</i></sub>, <i>μ</i><sub><i>t</i></sub>更新<b><i>Y</i></b><sub><i>t</i>+1</sub>:</p>
                </div>
                <div class="p1">
                    <p id="88"><b><i>Y</i></b><sub><sup><i>t</i>+1</sup></sub>=<b><i>Y</i></b><sub><sup><i>t</i></sup></sub>+<i>μ</i><sub><i>t</i></sub> (<b><i>H</i></b>-<b><i>A</i></b><sub><i>t</i>+1</sub>-<b><i>S</i></b><sub><i>t</i>+1</sub>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="89">4) 固定<b><i>A</i></b><sub><i>t</i></sub>, <b><i>S</i></b><sub><i>t</i></sub>, <b><i>Y</i></b><sub><i>t</i></sub>更新<i>μ</i><sub><i>t</i>+1</sub>:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>ρ</mi><mspace width="0.25em" /><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mspace width="0.25em" /><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mtext>F</mtext></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Η</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mtext>F</mtext></msub></mrow></mfrac><mo>&lt;</mo><mi>ε</mi></mtd></mtr><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">其中<i>ρ</i>&gt;1为常数, <i>ε</i>&gt;0为较小正数, 参数<i>μ</i>初始值0.1, <i>ρ</i>=1.5, <i>μ</i><sub><i>k</i></sub>随着迭代的更新增长速度越快, 收敛速度越快。在以上更新过程中, 更新<b><i>A</i></b>时, 矩阵<b><i>H</i></b>-<b><i>S</i></b><sub><sup><i>t</i></sup></sub>+<b><i>Y</i></b><sub><i>t</i></sub>/<i>μ</i><sub><i>t</i></sub>需进行奇异值分解 (Singular Value Decomposition, SVD) 。算法最后得到背景矩阵<b><i>A</i></b>和稀疏矩阵<b><i>S</i></b>, 然后根据得到的矩阵<b><i>S</i></b>进行归一化得到最后的HE病变区域图像。</p>
                </div>
                <div class="p1">
                    <p id="92">本文方法步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="93">输入:预处理后眼底图像<i>f</i><sub><i>d</i>×<i>n</i></sub>、参数<i>λ</i>。</p>
                </div>
                <div class="p1">
                    <p id="94">输出:含HE病变区域二值图像<b><i>NS</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="95">初始化:<b><i>A</i></b><sub>0</sub>=0, <b><i>S</i></b><sub>0</sub>=0, <b><i>Y</i></b><sub>0</sub>=0, <i>μ</i><sub>0</sub>=0.1, <i>μ</i><sub>max</sub>=3 000, <i>ρ</i>=1.5, <i>t</i>=0, <i>ε</i>=10<sup>-5</sup>。</p>
                </div>
                <div class="p1">
                    <p id="96">While not converged do</p>
                </div>
                <div class="p1">
                    <p id="97">1) 计算<b><i>H</i></b></p>
                </div>
                <div class="p1">
                    <p id="98">2) <i>svd</i> (<b><i>H</i></b>-<b><i>S</i></b><sub><sup><i>t</i></sup></sub>+<b><i>Y</i></b><sub><i>t</i></sub>/<i>μ</i><sub><i>t</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="99">3) 利用式 (5) 更新<b><i>A</i></b><sub><i>t</i>+1</sub></p>
                </div>
                <div class="p1">
                    <p id="100">4) 利用式 (6) 更新<b><i>S</i></b><sub><i>t</i>+1</sub></p>
                </div>
                <div class="p1">
                    <p id="101">5) 利用式 (7) 更新<b><i>Y</i></b><sub><i>t</i>+1</sub></p>
                </div>
                <div class="p1">
                    <p id="102">6) 利用式 (8) 更新<i>μ</i><sub><i>t</i>+1</sub></p>
                </div>
                <div class="p1">
                    <p id="103">end while</p>
                </div>
                <div class="p1">
                    <p id="104">输出:<b><i>NS</i></b></p>
                </div>
                <h3 id="105" name="105" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="106" name="106">3.1 <b>实验数据及评价指标</b></h4>
                <div class="p1">
                    <p id="107">目前给出<i>HE</i>病变区域专家标记的公开数据库有<i>e</i>-<i>ophtha EX</i>和<i>DIARETDB</i>1。<i>DIARETDB</i>1数据库含有89幅分辨率为1 500×1 150的彩色眼底图像和不同病变的标记, 其中含有<i>HE</i>的图像有48幅, 这些图像同时存在出血点、软性渗出物和微动脉瘤等病变。<i>e</i>-<i>ophtha EX</i>数据库是专门用于糖尿病视网膜病变研究的彩色眼底图像数据库, 是由法国国家科研署资助的远程<i>DR</i>筛查项目<i>OPHDIAT</i> (<i>OPHthalmology DIAbetes Telemedicine</i>) <citation id="240" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>中建立的<i>e</i>-<i>ophtha</i>数据库中的一个子库, <i>HE</i>病变图像的标记是由<i>TeleOphta</i> (<i>TeleOphtalmology</i>) <citation id="241" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>项目中<i>ADCIS</i> (<i>ADvanced Concepts in Imaging Software</i>) 研发的标注软件结合眼科专家的修改意见共同完成的。该库包含103幅彩色眼底图像 (包含四种不同尺寸:1 440 <i>pixels</i>×960 <i>pixels</i>、1 504 <i>pixels</i>×1 000 <i>pixels</i>、2 048 <i>pixels</i>×1 360 <i>pixels</i>、2 544 <i>pixels</i>×1 696 <i>pixels</i>) , 其中有47幅含<i>HE</i>病变图像和56幅正常图像。与其他公开的彩色眼底图像数据库如<i>HEI</i>-<i>MED</i> (<i>Hamilton Eye Institute Macular Edema Dataset</i>) 、<i>MESSIDOR</i>、<i>DIARETDB</i>0 (<i>standard DIAbetic RETinopathy DataBase calibration Level</i> 0) 、<i>DIARETDB</i>1、<i>STARE</i> (<i>STructured Analysis of the REtina</i>) 等数据库相比, <i>e</i>-<i>ophtha EX</i>数据库的<i>HE</i>病变标记更精准, 可作为<i>HE</i>检测结果的病灶水平评价标准<citation id="242" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="108">对于<i>HE</i>检测方法性能的评价标准主要有基于病灶水平和基于图像水平。基于病灶水平的评价标准:每幅眼底图像若检测出的病变区域 (像素) 与专家标记的病变区域 (像素) 一致则为真阳性 (<i>True Positive</i>, <i>TP</i>) , 否则为假阴性 (<i>False Negative</i>, <i>FN</i>) ;同理检测出的非病变区域 (像素) 与专家标记的非病变区域 (像素) 一致为真阴性 (<i>True Negative</i>, <i>TN</i>) , 否则为假阳性 (<i>False Positive</i>, <i>FP</i>) 。本文选用区分度较高的灵敏性和特异性作为基于病灶水平的主要评价标准;基于图像水平的评价标准是以图像中含有<i>HE</i>病变区域 (像素) , 则为异常图像 (<i>TP</i>) , 否则为正常图像 (<i>TN</i>) 。本文则选用准确度、灵敏性和特异性作为基于图像水平的主要评价标准。在此基础上, 给出灵敏性、特异性等三个评价标准:</p>
                </div>
                <div class="p1">
                    <p id="109"><i>SEN</i>=<i>TP</i>/ (<i>TP</i>+<i>FN</i>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="110"><i>SPE</i>=<i>TN</i>/ (<i>TN</i>+<i>FP</i>)      (10) </p>
                </div>
                <div class="p1">
                    <p id="111"><i>ACC</i>= (<i>TP</i>+<i>TN</i>) / (<i>TP</i>+<i>TN</i>+<i>FN</i>+<i>FP</i>)      (11) </p>
                </div>
                <div class="p1">
                    <p id="112">其中:<i>SEN</i> (SENsitivity) 为灵敏度, <i>SPE</i> (SPEcificity) 为特异性, <i>ACC</i> (ACCuracy) 为准确率。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">3.2 <b>实验结果与分析</b></h4>
                <div class="p1">
                    <p id="114">在32位<i>Windows</i> 7操作系统上, 编程环境为<i>Matlab R</i>2015<i>b</i>、<i>CPU</i>主频为2.10 <i>GHz</i>以及4 <i>GB</i>内存条件下实现本文方法。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">3.2.1 不同颜色通道检测结果分析</h4>
                <div class="p1">
                    <p id="116"><i>YCbCr</i>彩色空间中<i>Y</i>是指亮度通道, <i>Cb</i>指蓝色色度通道, 而<i>Cr</i>指红色色度通道。人的肉眼对<i>Y</i>通道更敏感, 因此本文在<i>YCbCr</i>的亮度通道 (<i>Luminance</i>, <i>Y</i>) 、<i>RGB</i>的绿色通道 (<i>Green</i>, <i>G</i>) 、<i>HSI</i>的强度通道 (<i>Intensity</i>, <i>I</i>) 和<i>HSV</i> (<i>Hue Saturation Value</i>) 的亮度通道 (<i>Value</i>, <i>V</i>) 上提取局部熵分别检测, 从表1所示的实验结果可以看出在病灶水平上<i>YCbCr</i>亮度通道的检测结果灵敏性和特异性比其他颜色通道好。</p>
                </div>
                <div class="area_img" id="117">
                    <p class="img_tit"><b>表</b>1 <b>基于病灶水平上不同颜色通道检测比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Comparison of different color channel detection based on lesion level</i></p>
                    <p class="img_note"></p>
                    <table id="117" border="1"><tr><td><br />通道</td><td>SEN/%</td><td>SPE/%</td></tr><tr><td><br /><i>YCbCr</i>的亮度通道<i>Y</i></td><td><b>91.13</b></td><td><b>90.00</b></td></tr><tr><td><br />RGB的绿色通道G</td><td>92.94</td><td>85.38</td></tr><tr><td><br />HSI的强度通道I</td><td>91.04</td><td>86.70</td></tr><tr><td><br />HSV的亮度通道V</td><td>87.93</td><td>84.55</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="118" name="118">3.2.2 局部熵检测结果分析</h4>
                <div class="p1">
                    <p id="119">由于局部熵比颜色灰度能更很好地反映HE病变区域的局部性和显著性, 本文分别提取亮度灰度 (如图4 (b) ) 和局部熵 (如图4 (c) ) 检测HE病变区域实验, 实验结果从图4 (e) 和 (f) 可以看出提取局部熵检测结果比亮度灰度检测结果更接近专家标记。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120">3.2.3 参数选择分析</h4>
                <div class="p1">
                    <p id="121">RPCA检测方法中平衡参数<i>λ</i>用于平衡低秩矩阵和稀疏矩阵, <i>λ</i>取值大小影响最后HE的检测结果好坏。本文取<i>λ</i>=[0.1 0.2 0.4 0.8 0.01 0.02 0.04 0.08 0.001 0.002 0.004 0.008 0.000 1 0.000 2 0.000 4 0.000 8]共16个值分别进行实验。实验结果如图5所示, <i>λ</i>≥0.001时对稀疏矩阵的影响较小, 灵敏性和特异性普遍较高, 当<i>λ</i>=0.004时灵敏性最高, 特异性较高, 视为最优。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 亮度和局部熵检测结果对比" src="Detail/GetImg?filename=images/JSJY201907046_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 亮度和局部熵检测结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison of luminosity and local entropy detection results</p>

                </div>
                <h4 class="anchor-tag" id="123" name="123">3.2.4 对比分析</h4>
                <div class="p1">
                    <p id="124">本文在病灶水平的评价标准上验证本文方法的有效性且耗时少, 分别采用SVM、<i>K</i>-means和本文方法进行实验。</p>
                </div>
                <div class="p1">
                    <p id="125">SVM实验 由于一幅眼底图像大小为1 440×960, HE病变区域像素样本数约占整幅眼底图像3%, 为避免样本失衡, 采用交叉验证法选取e-ophtha EX数据库中像素样本作为训练集, 正负比例1∶1, e-ophtha EX数据库47幅含病变图像作为测试集。实验结果如表2所示, 平均灵敏性为77.92%, 特异性为96.59%, 训练时间为128 502.15 s, 每幅图像平均测试时间为1.79 s。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同λ值的HE检测结果" src="Detail/GetImg?filename=images/JSJY201907046_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同<i>λ</i>值的HE检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 HE detection results of different <i>λ</i> value</p>

                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同方法在e-ophtha EX和DIARETDB1数据库的检测结果" src="Detail/GetImg?filename=images/JSJY201907046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同方法在e-ophtha EX和DIARETDB1数据库的检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Detection results of different methods on e-ophtha EX and DIARETDB1 databases</p>

                </div>
                <div class="p1">
                    <p id="128"><i>K</i>-means实验 采用SVM相同的测试集数据。为避免随机性, 以每幅图像为测试样本分别迭代30次, 平均灵敏性和特异性为53.41%和53.55%, 每幅图像平均耗时41.43 s。</p>
                </div>
                <div class="p1">
                    <p id="129">本文方法在相同的测试集数据上的检测结果为灵敏性91.13%和特异性90.00%, 从表2看出本文方法的灵敏性均高于SVM和<i>K</i>-means方法的检测结果, 特异性低于SVM方法的检测结果, 原因是视盘等亮区域去除不精确造成的。每幅图像平均运行时间0.5 s, 远少于以上两种方法的运行时间。</p>
                </div>
                <div class="p1">
                    <p id="130">图6为选取两个数据库上眼底图像采用SVM、<i>K</i>-means方法和本文方法的检测结果与专家标记比对。图6第三、四列为SVM、<i>K</i>-means方法的检测结果, 图6第五列为本文方法的检测结果, 可以看出本文方法均能检测出HE病变区域, 且本文方法检测HE病变区域比SVM、<i>K</i>-means方法的检测结果更接近专家标记, 造成假阳性高的亮区域较少。</p>
                </div>
                <div class="p1">
                    <p id="131">为了进一步验证本文方法的有效性, 将本文方法与现有方法进行比较, 如表3所示。文献<citation id="243" type="reference">[<a class="sup">4</a>]</citation>、文献<citation id="244" type="reference">[<a class="sup">6</a>]</citation>分别用阈值法、聚类方法, 文献<citation id="245" type="reference">[<a class="sup">1</a>]</citation>、<citation id="246" type="reference">[<a class="sup">11</a>]</citation>、分别用SVM和CNN方法。根据图像水平的评价标准, 图像中只要含有HE病变区域 (像素) 就判别为异常图像, 否则为正常图像。从表3可以看出, 本文方法在DIARETDB1数据库的检测结果准确度为100%, 灵敏性为100%, 特异性100%, 在e-ophtha EX数据库上的检测结果准确度为99.03%, 灵敏性为100%, 特异性98.21%, 与文献<citation id="247" type="reference">[<a class="sup">1</a>]</citation>相比, 本文方法具有较高的准确度。需要说明的是, 仅文献<citation id="248" type="reference">[<a class="sup">1</a>]</citation>给出在图像水平上的检测结果, 其余文献均未提到。在病灶水平上本文方法在DIARETDB1数据库的检测结果灵敏性低于其他方法, 因为e-ophtha EX数据库含有精准的专家标记图 (如图6 (b) 第一、二行) , 而DIARETDB1数据库含有的专家标记图 (如图6 (b) 第三、四行) 较不精准, 表3所示文献<citation id="249" type="reference">[<a class="sup">1</a>]</citation>、<citation id="250" type="reference">[<a class="sup">6</a>]</citation>中有眼科专业医生对DIARETDB1数据库进行精准标记。虽然本文方法在DIARETDB1数据库的检测结果灵敏性不高, 但是从图6 (e) 第三、四行中可看出本文方法的检测结果比专家标记更接近真实的HE病变区域, 在e-ophtha EX数据库上的检测结果显示灵敏性达到91.13%, 高于其他方法, 特异性比其他方法略优, 特异性偏低的原因是视盘等亮区域去除不精确造成的。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表</b>2 <b>不同方法在</b>e-ophtha EX<b>数据库上检测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Detection results of different methods on e-ophtha EX database</p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="4"><br />基于病灶水平</td></tr><tr><td><br /><i>SEN</i>/%</td><td><i>SPE</i>/%</td><td>训练时间/s</td><td>测试时间/s</td></tr><tr><td><br />SVM</td><td>77.92</td><td><b>96.59</b></td><td>128 502.15</td><td>1.79</td></tr><tr><td><br /><i>K</i>-means</td><td>53.41</td><td>53.55</td><td>—</td><td>41.43</td></tr><tr><td><br />本文方法</td><td><b>91.13</b></td><td><b>90.00</b></td><td>—</td><td><b>0.50</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表</b>3 <b>不同方法的评价指标结果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Comparison of evaluation index results among different methods</p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td rowspan="2">数据库</td><td rowspan="2">方法</td><td colspan="2"><br />基于病灶水平</td><td rowspan="2"></td><td colspan="3"><br />基于图像水平</td></tr><tr><td><br /><i>SEN</i>/%</td><td><i>SPE</i>/%</td><td><br /><i>SEN</i>/%</td><td><i>SPE</i>/%</td><td><i>ACC</i>/%</td></tr><tr><td rowspan="4"><br />DIARETDB1</td><td>文献[1]</td><td>84.60</td><td><b>94.40</b></td><td></td><td>97.30</td><td>90.00</td><td>93.70</td></tr><tr><td><br />文献[6]</td><td>87.00</td><td>80.00</td><td></td><td>—</td><td>—</td><td>—</td></tr><tr><td><br />文献[11]</td><td>90.00</td><td>91.00</td><td></td><td>—</td><td>—</td><td>—</td></tr><tr><td><br />本文方法</td><td>14.87</td><td><b>94.77</b></td><td><b></b></td><td><b>100.00</b></td><td><b>100.00</b></td><td><b>100.00</b></td></tr><tr><td rowspan="4"><br />e-ophtha EX</td><td><br />文献[6]</td><td>78.00</td><td>73.00</td><td></td><td>—</td><td>—</td><td>—</td></tr><tr><td><br />文献[4]</td><td>75.17</td><td><b>97.98</b></td><td></td><td>—</td><td>—</td><td>—</td></tr><tr><td><br />文献[11]</td><td>89.00</td><td>91.00</td><td></td><td>—</td><td>—</td><td>—</td></tr><tr><td><br />本文方法</td><td><b>91.13</b></td><td><b>90.00</b></td><td><b></b></td><td><b>100.00</b></td><td><b>98.21</b></td><td><b>99.03</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">3.2.5 本文方法不足</h4>
                <div class="p1">
                    <p id="135">本文方法检测结果中在病灶水平上特异性较低的原因是预处理过程中不能精确去除亮区域 (如视盘、邻近血管的神经纤维区域等) , 这些伪目标与HE病变区域有相似的形状和边缘特征, 在提取局部熵特征中两者的熵值相近, 因此在RPCA低秩稀疏分解过程中这些亮区域被误判为HE病变区域, 造成假阳性 (FP) 太高, 特异性不高。如图7显示, 整幅图像光照不均, 图中视盘位于眼球边缘且亮度较暗, 邻近血管的神经纤维和视盘具有与HE病变区域相似的亮度特征, 去除这些伪目标不精确导致检测结果出现假阳性偏高的现象。</p>
                </div>
                <h3 id="136" name="136" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="137">本文提出一种无监督的HE自动检测方法, 运用形态学重建的背景估计方法去除血管、暗病变区域和视盘, 在亮度通道上根据HE病变区域的局部性和稀疏性, 结合局部熵和RPCA方法得到HE病变区域。该方法不需要专家手动标记为标准, 自动检测HE病变区域, 实验结果表明该方法具有较高的灵敏度和特异性, 且快速有效, 给眼科临床筛查和诊断带来很大的便利, 具有较好的临床可行性;但本文采用RPCA方法未能较好地处理视盘去除不精确或邻近血管的神经纤维区域造成的假阳性偏高的问题, 在后续的研究中可考虑加入噪声项或增加稀疏权重等优化RPCA的办法来降低假阳性。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907046_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 本文视盘错误分割及HE检测结果" src="Detail/GetImg?filename=images/JSJY201907046_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 本文视盘错误分割及HE检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907046_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Error segmentation of optic disc and detection result of HE</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="173">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSWY201506012&amp;v=MjIwNjdmWnVac0Z5L2dWNy9BUHo3Y2Q3RzRIOVRNcVk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 肖志涛, 王雯, 耿磊, 等.基于背景估计和SVM分类器的眼底图像硬性渗出物检测方法[J].中国生物医学工程学报, 2015, 34 (6) :720-728. (XIAO Z T, WANG W, GENG L, et al.Hard exudates detection method based on background-estimation and SVM classifier[J].Chinese Journal of Biomedical Engineering, 2015, 34 (6) :720-728.) 
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300048989&amp;v=MjE5NzZySTlGWk84SEJYUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXNRYWhvPU5pZk9mYks3SHRETw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> WELFER D, SCHARCANSKI J, MARINHO D R.A coarse-to-fine strategy for automatically detecting exudates in color eye fundus images[J].Computerized Medical Imaging Graphics, 2010, 34 (3) :228-235.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A contribution of image processing to the diagnosis of diabetic retinopathy - Detection of exudates in color fundus images of the human retina">

                                <b>[3]</b> WALTER T, KLEIN J C, MASSIN P, et al.A contribution of image processing to the diagnosis of diabetic retinopathy detection of exudates in color fundus images of the human retina[J].IEEE Transactions on Medical Imaging, 2002, 21 (10) :1236-1243.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic exudate detection in color fundus images">

                                <b>[4]</b> QI F C, LI G, ZHENG S B.Automatic exudate detection in color fundus images[J].Digital TV and Wireless Multimedia Communication, 2017, 685:155-165.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJDG&amp;filename=SJDG91E91735DF15FEB6C356C7CCDB3D539E&amp;v=Mjc0OThwaHc3Mjd3S0E9TmlmUGFicTVhOWpOcUl4QUVKME9DUXBNdlJCZzZUcDdPM2lSMzJaSGVzYVJSclBxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> SANTHI D, MANIMEGALAI D, PARVATHI S, et al.Segmentation and classification of bright lesions to diagnose diabetic retinopathy in retinal images[J].Biomedizinische Technik (BIOMED TECH) , 2016, 61 (4) :443-453.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201811013&amp;v=MzEzMjhIOW5Ocm85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWNy9BTHo3QmFMRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 曹新容, 林嘉雯, 薛岚燕, 等.邻域约束模型的眼底图像硬性渗出聚类检测方法[J].计算机辅助设计与图形学学报, 2018, 30 (11) :2093-2100. (CAO X R, LIN J W, XUE L Y, et al.Clustering detection method of hard exudates in fundus image based on neighborhood constraint model[J].Journal of Computer-Aided Design and Computer Graphics, 2018, 30 (11) :2093-2100.) 
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparative Analysis of Automatic Exudate Detection Algorithms">

                                <b>[7]</b> SOPHARAK A, UYYANONVARA B, BARMAN S, et al.Comparative analysis of automatic exudate detection algorithms [C]// WCE 2010:Proceedings of the 2010 World Congress on Engineering.London:[s.n.], 2010:738-741.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A clustering approach for exudates detection in screening of diabetic retinopathy">

                                <b>[8]</b> BIYANI R S, PATRE B M.A clustering approach for exudates detection in screening of diabetic retinopathy[C]// Proceedings of the 2016 International Conference on Signal and Information Processing.Washington, DC:IEEE Computer Society, 2016:1-5.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Diabetic retinal exudates detection using machine learning techniques">

                                <b>[9]</b> ASHA P R, KARPAGAVALLI S.Diabetic retinal exudates detection using machine learning techniques[C]// Proceedings of the 2015 International Conference on Advanced Computing and Communication System.Piscataway, NJ:IEEE, 2015:1-5.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF2D615501C32C5A200F1151249A8CFBE&amp;v=MzA0NDR3NzI3d0tBPU5pZk9mY1c2YXRmTnFvcEZaWmdNRGc4OHZoUVQ2a2w4U1hyanJoWThDTHJuTThqcUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> ADEM K.Exudate detection for diabetic retinopathy with circular Hough transformation and convolutional neural networks[J].Expert Systems with Applications, 2018, 11:289-295.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8DC7925AB90BC12C1C8F4EF000B78B39&amp;v=MzE2NjFZbzBGdUlQZmc4NHpXVVNtVGNMVEFxVXJCSTFDN1djTjdtV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3Mjd3S0E9TmlmT2Zidk1iZGJGcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> PARHAM K, PASSOS J L A, TIAGO C, et al.Exudate detection in fundus images using deeply-learnable features [J].Computers in Biology and Medicine, 2018, 104:62-69.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES17276F6D0BCA387DD198AF1CADDF845F&amp;v=MjMwODF0cGh3NzI3d0tBPU5pZk9mYksvSE5iSzJZa3haSmw4Zlg4eHlHSm42eloxT1FuajMyTkJEY1NjUWIvcENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> AMIN J, SHARIF M, YASMIN M, et al.A method for the detection and classification of diabetic retinopathy using structural predictors of bright lesions [J].Journal of Computational Science, 2017, 19:153-164.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust principal component analysis:exact recovery of corrupted low-rank matrices via convex optimization">

                                <b>[13]</b> WRIGHT J, GANESH A, RAO S, et al.Robust principal component analysis:exact recovery of corrupted low-rank matrices via convex optimization [EB/OL].[2018- 12- 10].https://arxiv.org/pdf/0905.0233v1.pdf.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300161977&amp;v=MDkzOTBLOUg5UE9ySTlGWmUwT0JYcytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXNRYWhvPU5pZk9mYg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> XIAO L, FANG B, LIU L H, et al.Extracting sparse error of robust PCA for face recognition in the presence of varying illumination and occlusion[J].Pattern Recognition, 2014, 47 (2) :495-508.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual Saliency Detection via Sparsity Pursuit">

                                <b>[15]</b> YAN J C, ZHU M Y, LIU H X, et al.Visual saliency detection via sparsity pursuit [J].IEEE Signal Processing Letters, 2010, 17 (8) :739-742.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201404004&amp;v=MjAxMzMzenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y3L0FMejdCYUxHNEg5WE1xNDlGWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 仓园园, 孙玉宝, 刘青山.基于分层鲁棒主成分分析的运动目标检测[J].计算机辅助设计与图形学学报, 2014, 23 (4) :537-544. (CANG Y Y, SUN Y B, LIU Q S.Moving object detection based on hierarchical robust principal component analysis [J].Journal of Computer-Aided Design and Computer Graphics, 2014, 23 (4) :537-544.) 
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001869&amp;v=MTY4NTcxc1FhaG89TmlmSVk3SzdIdGpOcjQ5RlpPc09CSG93b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> CANDÉS E J, LI X, MA Y, et al.Robust principal component analysis?[J].Journal of the ACM, 2011, 58 (3) :Article No.11.
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cascaded transform space watermarking based on analysis of local entropy variation">

                                <b>[18]</b> AZIZI S, SAMAVI S, MOHREKESH M, et al.Cascaded transform space watermarking based on analysis of local entropy variation[C]// Proceedings of the 2013 International Conference on Multimedia and Expo Workshops.Piscataway, NJ:IEEE, 2013:1-6.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201503008&amp;v=MTEyMzVGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y3L0FJVGZTZHJHNEg5VE1ySTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 付晓薇, 代芸, 陈黎, 等.基于局部熵的量子衍生医学超声图像去斑[J].电子与信息学报, 2015, 37 (3) :560-566. (FU X W, DAI Y, CHEN L, et al.Quantum-inspired despeckling of medical ultrasound images based on local entropy[J].Journal of Electronics and Information Technology, 2015, 37 (3) :560-566.) 
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300890436&amp;v=MDc2ODZmT2ZiSzdIdEROckk5RmJPSVBDSDgvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSjFzUWFobz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> MASSIN P, CHABOUIS A, ERGINAY A, et al.OPHDIAT©:A telemedical network screening system for diabetic retinopathy in the Île-de-France [J].Diabetes and Metabolism, 2008, 34 (3) :227-234.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900002323&amp;v=MDEzNTVRYWhvPU5pZk9mYks3SHRUTXBvOUZaT3NORDM0Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxcw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> DECENCIERE E, CAZUGUEL G, ZHANG X W, et al.TeleOphta:machine learning and image processing methods for teleophthalmology[J].Innovation and Research in BioMedical Engineering, 2013, 34 (2) :196-203.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700254868&amp;v=Mjc0MjhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXNRYWhvPU5pZk9mYks4SHRmTnFJOUZadTRMQkhveA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> ZHANG X W, THIBAULT G, DECENCIÈRE E, et al.Exudate detection in color retinal images for mass screening of diabetic retinopathy[J].Medical Image Analysis, 2014, 18 (7) :1026-1043.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907046" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907046&amp;v=MjM2MzBac0Z5L2dWNy9BTHo3QmQ3RzRIOWpNcUk5QllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
