<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136481847783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909036%26RESULT%3d1%26SIGN%3dyUHr4Uy7D%252bgW4ESvohwzNxJgqWs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909036&amp;v=MjA1NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVkx6Skx6N0JkN0c0SDlqTXBvOUdZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="1.1 &lt;b&gt;图割算法&lt;/b&gt;">1.1 <b>图割算法</b></a></li>
                                                <li><a href="#61" data-title="1.2 &lt;b&gt;随机游走算法&lt;/b&gt;">1.2 <b>随机游走算法</b></a></li>
                                                <li><a href="#76" data-title="1.3 &lt;b&gt;拉普拉斯坐标算法&lt;/b&gt;">1.3 <b>拉普拉斯坐标算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="2 本文算法 ">2 本文算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#110" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="3.1 &lt;b&gt;定性比较&lt;/b&gt;">3.1 <b>定性比较</b></a></li>
                                                <li><a href="#119" data-title="3.2 &lt;b&gt;定量比较&lt;/b&gt;">3.2 <b>定量比较</b></a></li>
                                                <li><a href="#125" data-title="3.3 &lt;b&gt;多目标分割&lt;/b&gt;">3.3 <b>多目标分割</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="4 参数设置 ">4 参数设置</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#133" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#117" data-title="图1 五种算法的比较结果">图1 五种算法的比较结果</a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;三种数据集中五种算法的平均&lt;/b&gt;&lt;i&gt;IoU&lt;/i&gt;&lt;b&gt;和平均运行时间&lt;/b&gt;"><b>表</b>1 <b>三种数据集中五种算法的平均</b><i>IoU</i><b>和平均运行时间</b></a></li>
                                                <li><a href="#123" data-title="图2 5种算法在&lt;i&gt;MSRC&lt;/i&gt;数据集50幅测试图像上的分割错误率的比较结果">图2 5种算法在<i>MSRC</i>数据集50幅测试图像上的分割错误率的比较结果</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;本文算法在&lt;/b&gt;&lt;i&gt;MSRC&lt;/i&gt;&lt;b&gt;数据集上&lt;/b&gt;50&lt;b&gt;幅图像的分割错误率&lt;/b&gt;"><b>表</b>2 <b>本文算法在</b><i>MSRC</i><b>数据集上</b>50<b>幅图像的分割错误率</b></a></li>
                                                <li><a href="#127" data-title="图4 不同参数下的分割结果">图4 不同参数下的分割结果</a></li>
                                                <li><a href="#129" data-title="图3 多目标分割结果">图3 多目标分割结果</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同参数下的平均错误率&lt;/b&gt;"><b>表</b>3 <b>不同参数下的平均错误率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="157">


                                    <a id="bibliography_1" title=" SONKA M,HLAVAC V,BOYLE R.Image Processing,Analysis and Machine Vision [M].Berlin:Springer,2003:175-176." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Processing,Analysis and Machine Vision">
                                        <b>[1]</b>
                                         SONKA M,HLAVAC V,BOYLE R.Image Processing,Analysis and Machine Vision [M].Berlin:Springer,2003:175-176.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_2" title=" XIA G,SUN H,FENG L,et al.Human motion segmentation via robust kernel sparse subspace clustering [J].IEEE Transactions on Image Processing,2018,27(1):135-150." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Human motion segmentation via robust kernel sparse subspace clustering">
                                        <b>[2]</b>
                                         XIA G,SUN H,FENG L,et al.Human motion segmentation via robust kernel sparse subspace clustering [J].IEEE Transactions on Image Processing,2018,27(1):135-150.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_3" title=" JI Z,XIA Y,CHEN Q,et al.Fuzzy c-means clustering with weighted image patch for image segmentation [J].Applied Soft Computing,2012,12(6):1659-1667." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300297435&amp;v=MjQ5Mzl0RmlubFVyM0lJRndUYVJNPU5pZk9mYks3SHRETnJJOUZadUlJQ0g4OG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         JI Z,XIA Y,CHEN Q,et al.Fuzzy c-means clustering with weighted image patch for image segmentation [J].Applied Soft Computing,2012,12(6):1659-1667.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_4" title=" JI Z,XIA Y,SUN Q,et al.Fuzzy local Gaussian mixture model for brain MR image segmentation [J].IEEE Transactions on Information Technology in Biomedicine,2012,16(3):339-347." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fuzzy Local Gaussian Mixture Model for Brain MR Image Segmentation">
                                        <b>[4]</b>
                                         JI Z,XIA Y,SUN Q,et al.Fuzzy local Gaussian mixture model for brain MR image segmentation [J].IEEE Transactions on Information Technology in Biomedicine,2012,16(3):339-347.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_5" title=" WANG T,JI Z,SUN Q,et al.Label propagation and higher-order constraint-based segmentation of fluid-associated regions in retinal SD-OCT images [J].Information Sciences,2016,358(C):92-111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBB4208AD544EB0B1D5F4B4EBE0CBD3A9&amp;v=MjExNzg4TGVRNDV2UmRuNzBsNU9udVgzbWMxQ3NEZ1JzdVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4THE0dzZrPU5pZk9mY0hLR3RQTXAvNHhZZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         WANG T,JI Z,SUN Q,et al.Label propagation and higher-order constraint-based segmentation of fluid-associated regions in retinal SD-OCT images [J].Information Sciences,2016,358(C):92-111.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_6" title=" KUNTIMAD G,RANGANATH H S.Perfect image segmentation using pulse coupled neural networks [J].IEEE Transactions on Neural Networks,1999,10(3):591-598." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Perfect image segmentation using pulse coupled neural networks">
                                        <b>[6]</b>
                                         KUNTIMAD G,RANGANATH H S.Perfect image segmentation using pulse coupled neural networks [J].IEEE Transactions on Neural Networks,1999,10(3):591-598.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     SHELHAMER E,LONG J,DARRELL T.Fully convolutional networks for semantic segmentation [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651.</a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_8" title=" BOYKOV Y Y,JOLLY M.Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images [C]// Proceedings of the 8th IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2001:105-112." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images">
                                        <b>[8]</b>
                                         BOYKOV Y Y,JOLLY M.Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images [C]// Proceedings of the 8th IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2001:105-112.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_9" title=" GRADY L.Random walks for image segmentation [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1768-1783." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Random walks for image segmentation">
                                        <b>[9]</b>
                                         GRADY L.Random walks for image segmentation [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1768-1783.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_10" title=" CASACA W,NONATO L G,TAUBIN G.Laplacian coordinates for seeded image segmentation [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway,NJ:IEEE,2014:384-391." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Laplacian Coordinates for Seeded Image Segmentation">
                                        <b>[10]</b>
                                         CASACA W,NONATO L G,TAUBIN G.Laplacian coordinates for seeded image segmentation [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway,NJ:IEEE,2014:384-391.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_11" title=" BAMPIS C G,MARAGOS P,BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation [J].IEEE Transactions on Image Processing,2017:26(1):35-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graph-driven diffusion and random walk schemes for image segmentation">
                                        <b>[11]</b>
                                         BAMPIS C G,MARAGOS P,BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation [J].IEEE Transactions on Image Processing,2017:26(1):35-50.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_12" title=" DONG X,SHEN J,SHAO L,et al.Sub-Markov random walk for image segmentation [J].IEEE Transactions on Image Processing,2016,25(2):516-527." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sub-Markov Random Walk for Image Segmentation">
                                        <b>[12]</b>
                                         DONG X,SHEN J,SHAO L,et al.Sub-Markov random walk for image segmentation [J].IEEE Transactions on Image Processing,2016,25(2):516-527.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_13" title=" HEIMOWITZ A,KELLER Y.Image segmentation via probabilistic graph matching [J].IEEE Transactions on Image Processing,2016,25(10):4743-4752." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Segmentation via Probabilistic Graph Matching">
                                        <b>[13]</b>
                                         HEIMOWITZ A,KELLER Y.Image segmentation via probabilistic graph matching [J].IEEE Transactions on Image Processing,2016,25(10):4743-4752.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_14" title=" JIAN M,JUNG C.Interactive image segmentation using adaptive constraint propagation [J].IEEE Transactions on Image Processing,2016,25(3):1301-1311." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using adaptive constraint propagation">
                                        <b>[14]</b>
                                         JIAN M,JUNG C.Interactive image segmentation using adaptive constraint propagation [J].IEEE Transactions on Image Processing,2016,25(3):1301-1311.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_15" title=" ZEMENE E,PELILLO M.Interactive image segmentation using constrained dominant sets [C]// Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:278-294." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using constrained dominant sets">
                                        <b>[15]</b>
                                         ZEMENE E,PELILLO M.Interactive image segmentation using constrained dominant sets [C]// Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:278-294.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_16" title=" WANG T,SUN Q,JI Z,et al.Multi-layer graph constraints for interactive image segmentation via game theory [J].Pattern Recognition,2016,55(C):28-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES903EFC6C6BEEEA0D60A57F570E2B0D78&amp;v=MTY2MzkwNXRwaHhMcTR3Nms9TmlmT2ZicTRIYVM2M0lrMllwbDZlUWxJejJJVjZrNTRUd25ucXhKQWU4Q1VNYjJYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         WANG T,SUN Q,JI Z,et al.Multi-layer graph constraints for interactive image segmentation via game theory [J].Pattern Recognition,2016,55(C):28-44.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_17" title=" BAI S,BAI X,TIAN Q,et al.Regularized diffusion process for visual retrieval [C]// Proceedings of the 31st AAAI Conference on Artificial Intelligence.Palo Alto:AAAI Press,2017:3967-3973." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regularized diffusion process for visual retrieval">
                                        <b>[17]</b>
                                         BAI S,BAI X,TIAN Q,et al.Regularized diffusion process for visual retrieval [C]// Proceedings of the 31st AAAI Conference on Artificial Intelligence.Palo Alto:AAAI Press,2017:3967-3973.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_18" title=" WANG T,YANG J,JI Z,et al.Probabilistic diffusion for interactive image segmentation [J].IEEE Transactions on Image Processing,2019,28(1):330-342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probabilistic diffusion for interactive image segmentation">
                                        <b>[18]</b>
                                         WANG T,YANG J,JI Z,et al.Probabilistic diffusion for interactive image segmentation [J].IEEE Transactions on Image Processing,2019,28(1):330-342.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_19" title=" ROTHER C,KOLMOGOROV V,BLAKE A.Grabcut:interactive foreground extraction using iterated graph cuts [C]// Proceedings of the 2004 ACM SIGGRAPH Conference.New York:ACM,2004:309-314." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Grabcut-interactive foreground extraction using iterated graph cuts">
                                        <b>[19]</b>
                                         ROTHER C,KOLMOGOROV V,BLAKE A.Grabcut:interactive foreground extraction using iterated graph cuts [C]// Proceedings of the 2004 ACM SIGGRAPH Conference.New York:ACM,2004:309-314.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_20" title=" SANTNER J,POCK T,BISCHOF H.Interactive multi-label segmentation [C]// Proceedings of the 2010 Asian Conference on Computer Vision,LNCS 6492.Berlin:Springer,2010:397-410." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive multi-label segmentation">
                                        <b>[20]</b>
                                         SANTNER J,POCK T,BISCHOF H.Interactive multi-label segmentation [C]// Proceedings of the 2010 Asian Conference on Computer Vision,LNCS 6492.Berlin:Springer,2010:397-410.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_21" title=" YAO B,YANG X,ZHU S.Introduction to a large-scale general purpose ground truth database:methodology,annotation tool and benchmarks [C]// Proceedings of the 2007 International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition,LNCS 4679.Berlin:Springer,2007:169-183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Introduction to a large scale general purpose groundtruth dataset:methodology,annotation tool,and benchmarks">
                                        <b>[21]</b>
                                         YAO B,YANG X,ZHU S.Introduction to a large-scale general purpose ground truth database:methodology,annotation tool and benchmarks [C]// Proceedings of the 2007 International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition,LNCS 4679.Berlin:Springer,2007:169-183.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_22" title=" 王涛.特征度量与信息传递的交互式图论分割方法研究[D].南京:南京理工大学,2017:17-29.(WANG T.Research on graph theory based interactive segmentation via feature measurement and information propagation [D].Nanjing:Nanjing University of Science and Technology,2017:17-29.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018080995.nh&amp;v=MjM5NDIyNkZyT3dIdGpGcXBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WTHpKVkY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         王涛.特征度量与信息传递的交互式图论分割方法研究[D].南京:南京理工大学,2017:17-29.(WANG T.Research on graph theory based interactive segmentation via feature measurement and information propagation [D].Nanjing:Nanjing University of Science and Technology,2017:17-29.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-24 10:28</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2695-2700 DOI:10.11772/j.issn.1001-9081.2019030543            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>耦合先验拉普拉斯坐标的半监督图像分割算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B9%E6%98%80%E7%82%80&amp;code=42779657&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曹昀炀</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%B6%9B&amp;code=08095139&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王涛</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E7%BB%9F%E8%AE%A1%E5%AD%A6%E9%99%A2&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东师范大学统计学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0077991&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京理工大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统半监督图像分割方法难以精确分割分散或细小区域的缺陷,提出了一种耦合标签先验和拉普拉斯坐标模型的半监督图像分割算法。首先,扩展拉普拉斯坐标(LC)模型,通过引入标签先验项进一步精确表征未标记像素点与已标记像素点之间的关系。然后,基于矩阵方程的求导优化,有效估计像素属于标签的后验概率,以实现图像目标分割的任务。得益于标签先验的引入,所提算法对分散或细小区域的分割更加鲁棒。最后,在多个公开的半监督分割数据集上实验结果表明,相比拉普拉斯坐标算法,所提算法的分割准确率获得了显著提升,验证了所提算法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彩色图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">半监督图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%9D%90%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">拉普拉斯坐标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">先验概率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    曹昀炀(1998—),男,江苏南京人,主要研究方向:应用统计、图像分割;;
                                </span>
                                <span>
                                    *王涛(1990—),男,江苏扬州人,副教授,博士,主要研究方向:计算机视觉、图像分割。电子邮箱wangtaoatnjust@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61802188);</span>
                                <span>江苏省自然科学基金资助项目(BK20180458);</span>
                                <span>江苏省博士后科研基金计划项目;</span>
                    </p>
            </div>
                    <h1><b>Semi-supervised image segmentation based on prior Laplacian coordinates</b></h1>
                    <h2>
                    <span>CAO Yunyang</span>
                    <span>WANG Tao</span>
            </h2>
                    <h2>
                    <span>School of Statistics, East China Normal University</span>
                    <span>College of Computer Science and Engineering, Nanjing University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Focusing on the issue that classic semi-supervised image segmentation methods have difficulty in accurately segmenting scattered or small regions, a semi-supervised segmentation algorithm based on label prior and Laplacian Coordinates(LC) was proposed. Firstly, the Laplacian coordinates model was extended, and further the relationship between unlabeled pixels and labeled pixels accurately characterized by introducing the label prior. Secondly, based on the derivation of matrix equation, the posterior probability that the pixel belongs to the label was able to be effectively estimated, thus achieving the segmentation of the image. Thanks to the introduction of the label prior, the algorithm was more robust to the segmentation of scattered and small regions. Lastly, the experimental results on several public semi-supervised segmentation datasets show that the segmentation accuracy of the proposed algorithm is significantly improved compared with that of the Laplacian coordinates algorithm, which verifies the effectiveness of the proposed algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=semi-supervised%20image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">semi-supervised image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Laplacian%20Coordinates(LC)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Laplacian Coordinates(LC);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=prior%20probability&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">prior probability;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CAO Yunyang, born in 1998. His research interests include applied statistics, image segmentation.;
                                </span>
                                <span>
                                     WANG Tao, born in 1990, Ph. D. , associate professor. His research interests include computer vision, image segmentation.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-03</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61802188);</span>
                                <span>the Natural Science Foundation of Jiangsu Province(BK20180458);</span>
                                <span>the Jiangsu Planned Project for Postdoctoral Research Fund;</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="48">图像分割是指在特定的相似性准则下将用户感兴趣的图像目标从复杂的背景环境中分离出来<citation id="201" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。图像分割是从图像处理到图像分析的关键步骤,分割出的图像目标具有高维语义性,是后续图像应用的基础<citation id="202" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。按照标签先验的获取方式,现有的图像分割方法一般可以分为三类:无监督方法<citation id="206" type="reference"><link href="161" rel="bibliography" /><link href="163" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、半监督方法<citation id="203" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和全监督方法<citation id="204" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。无监督图像分割方法基于预先设定的相似性准则对图像特征进行聚类分析,可以实现自动的图像分割。然而,此类方法由于缺乏足够的用户先验指导,往往缺乏通用性与准确性。全监督图像分割方法基于全标记的图像样本序列进行模型参数训练,可以实现图像的语义层分割。典型的此类方法包括当下流行的卷积神经网络方法等<citation id="205" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。此类方法的分割性能一般依赖于足够多的训练样本数据。此外,当出现训练样本中未包含的新类别时,往往无法获得正确的目标分割,导致此类方法缺乏一定的灵活性。半监督图像分割方法允许用户提供初始种子点或目标轮廓来表征标签先验信息,可以获得满足用户需求的分割结果。用户可以通过简单的人机交互方式,实现对分割过程的控制和对错误分割的有效修正,因此,半监督分割模式具有更强的通用性和灵活性。本文主要集中于半监督的分割模式展开研究工作。</p>
                </div>
                <div class="p1">
                    <p id="49">近年来,大量的半监督分割方法<citation id="214" type="reference"><link href="171" rel="bibliography" /><link href="173" rel="bibliography" /><link href="175" rel="bibliography" /><link href="177" rel="bibliography" /><link href="179" rel="bibliography" /><link href="181" rel="bibliography" /><link href="183" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>被提出。典型的方法包括图割(Graph Cut, GC)<citation id="207" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和随机游走(Random Walk,RW)<citation id="208" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。在上述方法中,用户需要首先标记一些像素点作为种子点,然后算法可以基于种子点自动地估计未标记像素点的标签。Boykov等<citation id="209" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>首次提出了半监督图割算法,并应用于医学图像分割中,利用像素之间的相似程度定义能量,将能量函数定义为区域能量和边界能量之和。该算法添加了两个虚拟的终端点,用区域能量衡量像素点和终端点之间的相似程度,边界能量衡量相邻像素点之间的相似程度,将图像分割问题转化为求取图的最小割集问题,通过最大流算法获取全局的最优解。但是传统的图割算法是在统计直方图的基础上,由于直方图的局限性,图割算法较难准确地分割包含复杂背景的图像。Grady<citation id="210" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出随机游走算法,通过构建从未标记像素点出发到种子点终止的随机游走模型,求解带有边界约束的Dirichlet问题,估计出每一个未标记像素点到种子点的到达概率。将未标记的像素点与其到达概率最大的种子点合并为目标区域。传统的随机游走算法完全依赖种子点的质量和位置,因此当种子点较少时,该算法的分割结果错误率较高。此外,随机游走算法忽视了标签的各向异性传播,对区域边界不敏感,容易出现边界拟合较差的问题。针对这些问题,Casaca等<citation id="211" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出结合拉普拉斯坐标(Laplacian_Coordinates,LC)的半监督图像分割算法改进随机游走模型。该算法对每个像素点赋值,求出最小化能量函数的最优解,之后将最优解转化为像素点属于前景或背景的概率,将像素点与其概率最大的标签合并为目标区域。相比于传统的随机游走算法最小化相邻像素点之间的距离的做法,拉普拉斯坐标算法通过最小化所有相邻像素点距离的均值来更好地控制标签的各向异性传播,同时也提高了边界拟合的准确性。此外,拉普拉斯坐标算法的能量函数包含二次型矩阵,能够降低计算成本,并确保分割结果的准确性和平滑性。但是由于忽视未标记像素点与种子点之间的特征,只依赖相邻像素点的特征,拉普拉斯坐标算法仍难以分割出分散或细小的区域。此外,近些年来为了提升随机游走模型的分割准确度,Bampis等<citation id="212" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出归一化随机游走(Normalized Random Walk, NRW)算法;Dong等<citation id="213" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出亚马尔可夫随机游走(Sub-Markov Random Walk, SMRW)算法。但是归一化随机游走算法仍难以分割出分散或细小的区域,亚马尔可夫随机游走算法会存在过度分割的问题。</p>
                </div>
                <div class="p1">
                    <p id="50">受现有标签先验建模方法<citation id="216" type="reference"><link href="171" rel="bibliography" /><link href="185" rel="bibliography" /><link href="187" rel="bibliography" /><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>的启发,本文基于拉普拉斯坐标模型<citation id="215" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出了一种半监督图像分割算法,针对拉普拉斯坐标算法难以分割分散或细小区域等缺陷,通过引入标签先验来精确表征未标记像素点与种子点之间的关系。在传统拉普拉斯坐标模型能量项中引入标签先验概率项,并有效优化各能量项之间的参数,充分利用用户交互知识,弥补传统模型的缺陷。本文提出的耦合先验拉普拉斯坐标的半监督图像分割算法从以下两个方面提升了图像分割性能:1)在分割过程中引入先验概率,对分散或细小的区域更鲁棒;2)通过合理优化参数,平衡各项约束的影响,在分割小目标区域的同时保持分割区域的边界更平滑。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">1 相关研究</h3>
                <div class="p1">
                    <p id="52">图像可以用图<i>G</i>=(<i>P</i>,<b><i>W</i></b>)来表示,其中<i>P</i>={<i>p</i><sub><i>i</i></sub>}<mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>为所有像素点的集合,<b><i>W</i></b>=[<i>W</i><sub><i>ij</i></sub>]<sub><i>N</i>×<i>N</i></sub>为像素之间的相似性矩阵,<i>W</i><sub><i>ij</i></sub>∈[0,1]表示像素<i>p</i><sub><i>i</i></sub>和<i>p</i><sub><i>j</i></sub>之间的相似性,<i>N</i>为像素点的个数。图像分割问题实质是标签划分问题,即给定一个标签集合<i>L</i>,一个图像像素集合<i>P</i>,图像分割的目标是给每一个像素点<i>p</i><sub><i>i</i></sub>∈<i>P</i>赋予对应的标签值<i>l</i><sub><i>i</i></sub>∈<i>L</i>。因此图像的分割结果即为从图像像素集合<i>P</i>到标签集合<i>L</i>的一组映射,表示为<i>l</i>={<i>l</i><sub><i>i</i></sub>|<i>l</i><sub><i>i</i></sub>∈<i>L</i>}。前景和背景的半监督图像分割问题可以看作是二值标签问题,即<i>L</i>={<i>l</i><sub>F</sub>,<i>l</i><sub>B</sub>},其中<i>l</i><sub>F</sub>代表前景的标签值,<i>l</i><sub>B</sub>代表背景的标签值,一般赋值为<i>l</i><sub>F</sub>=1,<i>l</i><sub>B</sub>=0。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">1.1 <b>图割算法</b></h4>
                <div class="p1">
                    <p id="55">基于图割的图像分割算法将标签划分问题转化为能量函数最小化的问题。能量函数一般可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="56"><i>E</i>(<i>l</i>)= <i>E</i><sub>r</sub>(<i>l</i>)+ <i>λE</i><sub>b</sub>(<i>l</i>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="57">其中:能量函数<i>E</i> (<i>l</i>)由区域能量项<i>E</i><sub>r</sub>和边界能量项<i>E</i><sub>b</sub>组成。<i>λ</i>&gt;0为平衡区域项和边界项的参数。该能量函数可以采用最大流/最小割算法来优化,有效地寻找图中的最小割集,从而获得全局最优解。其中,区域能量项表示像素点和标签之间的相似程度,是关于种子点属于前景或背景的概率的函数。文献<citation id="217" type="reference">[<a class="sup">19</a>]</citation>提出了使用高斯混合模型(Gaussian Mixture Model, GMM)估计像素点属于前景和背景的概率的方法,基于GMM的区域能量项定义如下:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">(</mo></mstyle><mo>-</mo><mrow><mi>ln</mi></mrow><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>Μ</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中:<i>P</i><sub>GMM</sub>(<b><i>C</i></b><sub><i>i</i></sub>,<i>l</i><sub><i>i</i></sub>)表示像素点<i>p</i><sub><i>i</i></sub>属于标签<i>l</i><sub><i>i</i></sub>的概率。<b><i>C</i></b><sub><i>i</i></sub>表示像素点<i>p</i><sub><i>i</i></sub>的特征强度向量,对于彩色图像分割,用RGB特征定义像素点<i>p</i><sub><i>i</i></sub>的特征强度向量<b><i>C</i></b><sub><i>i</i></sub>=(<i>R</i><sub><i>i</i></sub>,<i>G</i><sub><i>i</i></sub>,<i>B</i><sub><i>i</i></sub>);对于灰度图像分割,用灰度值代表像素点<i>p</i><sub><i>i</i></sub>的特征强度向量<b><i>C</i></b><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="60">图割算法在分割背景环境较为简单的图像时一般能获得较好的结果,当图像的背景环境较为复杂时,容易出现分割速度缓慢,错误分割小区域目标等缺陷,导致分割结果不够精确和鲁棒。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">1.2 <b>随机游走算法</b></h4>
                <div class="p1">
                    <p id="62">基于随机游走的图像分割算法是另一种实用的半监督图像分割算法。该算法基于随机游走者从每个未标记像素点到种子点的转移概率,定义未标记像素点属于种子点对应标签的概率。在基于随机游走的图像分割算法中,通常用高斯函数定义像素<i>p</i><sub><i>i</i></sub>和<i>p</i><sub><i>j</i></sub>之间的相似性<i>W</i><sub><i>ij</i></sub>,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mi>β</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>,</mo><mtext> </mtext><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中:<b><i>C</i></b><sub><i>i</i></sub>表示像素<i>p</i><sub><i>i</i></sub>的特征强度向量,<i>A</i><sub><i>i</i></sub>表示像素<i>p</i><sub><i>i</i></sub>的邻域像素集合, <i>β</i>为控制参数。进而可以根据像素属于标签<i>l</i>∈{<i>l</i><sub>F</sub>,<i>l</i><sub>B</sub>}的概率构造能量函数,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>π</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>π</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi mathvariant="bold-italic">π</mi><msubsup><mrow></mrow><mi>l</mi><mtext>Τ</mtext></msubsup><mi>L</mi><mi mathvariant="bold-italic">π</mi><msub><mrow></mrow><mi>l</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">其中,<i>π</i><sub><i>l</i></sub>=[<i>π</i><sub><i>il</i></sub>]<sub><i>N</i>×1</sub>为像素属于标签<i>l</i>的概率向量,<i>π</i><sub><i>il</i></sub>为像素<i>p</i><sub><i>i</i></sub>属于标签<i>l</i>的概率。<b><i>L</i></b>=<b><i>D</i></b>-<b><i>W</i></b>为拉普拉斯矩阵,其中<b><i>D</i></b>=diag<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>d</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">W</mi><mo>=</mo><mo stretchy="false">[</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">]</mo><msub><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>Ν</mi></mrow></msub></mrow></math></mathml>。为了降低计算复杂度,可以将拉普拉斯矩阵转变为分块矩阵,仅计算未标记的像素属于标签<i>l</i>的概率。将像素集合<i>P</i>划分为标记的像素集合<i>P</i><sub><i>M</i></sub>和未标记的像素集合<i>P</i><sub><i>U</i></sub>满足<i>P</i><sub><i>M</i></sub>∩<i>P</i><sub><i>U</i></sub>=∅,<i>P</i><sub><i>M</i></sub>∪<i>P</i><sub><i>U</i></sub>=<i>P</i>。因此未标记像素属于标签<i>l</i>的概率向量表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="68"><i>π</i><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>U</mi><mi>l</mi></msubsup></mrow></math></mathml>=-<b><i>L</i></b><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>U</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml><b><i>Q</i></b><sup>T</sup><i>π</i><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Μ</mi><mi>l</mi></msubsup></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="72">其中:<i>π</i><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>U</mi><mi>l</mi></msubsup></mrow></math></mathml>=[<i>π</i><sub><i>il</i></sub>]<sub><i>U</i>×1</sub>为未标记像素属于标签<i>l</i>的概率向量(<i>i</i>∈<i>P</i><sub><i>U</i></sub>),<b><i>L</i></b><sub><i>U</i></sub>表示未标记像素之间的关系矩阵,为<i>U</i>阶方阵,<b><i>Q</i></b>表示标记像素与未标记像素的关系矩阵,为<i>M</i>×<i>U</i>矩阵,<i>π</i><sup><i>l</i></sup><sub><i>M</i></sub>=[<i>π</i><sub><i>il</i></sub>]<sub><i>M</i>×1</sub>为标记像素属于标签<i>l</i>的概率向量(<i>i</i>∈<i>P</i><sub><i>M</i></sub>),如果像素<i>p</i><sub><i>i</i></sub>为标签<i>l</i>的种子点,<i>π</i><sub><i>il</i></sub>=1,否则为0。<i>U</i>为未标记像素的数量,<i>M</i>为标记像素的数量。</p>
                </div>
                <div class="p1">
                    <p id="74">对于分割前景和背景的问题,可以估计出像素属于前景的概率<i>π</i><sub><i>iF</i></sub>和属于背景的概率<i>π</i><sub><i>iB</i></sub>满足<i>π</i><sub><i>iF</i></sub>+<i>π</i><sub><i>iB</i></sub>=1。如果像素<i>p</i><sub><i>i</i></sub>属于前景的概率<i>π</i><sub><i>iF</i></sub>大于0.5,则将像素分配给前景,即<i>l</i><sub><i>i</i></sub>=1;否则将像素分配给背景,即<i>l</i><sub><i>i</i></sub>=0。</p>
                </div>
                <div class="p1">
                    <p id="75">随机游走算法引入拉普拉斯矩阵计算像素属于标签的概率,确保了最优解的唯一性,能够较快分割图像。然而,该算法忽视了标签的各向异性传播,对区域边界不敏感,容易出现边界拟合较差的问题。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">1.3 <b>拉普拉斯坐标算法</b></h4>
                <div class="p1">
                    <p id="77">基于拉普拉斯坐标的图像分割算法在各向异性传播和边界拟合的缺陷,通过最小化所有相邻像素点距离的均值来控制标签的各向异性传播。给定背景种子点集合<i>B</i>和前景种子点集合<i>F</i>,背景的标签值<i>l</i><sub>B</sub>=0,前景的标签值<i>l</i><sub>F</sub>=1,能量函数可以表示为关于像素属于前景的概率的向量函数,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><mo stretchy="false">)</mo><mo>=</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>B</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>k</mi><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>F</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mtext>F</mtext></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mi>k</mi><msub><mrow></mrow><mn>3</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ρ</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>π</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中:<i>π</i>=[<i>π</i><sub><i>i</i></sub>]<sub><i>N</i>×1</sub>为所有像素的概率向量,<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>、<i>k</i><sub>2</sub>、<i>k</i><sub>3</sub>为正控制参数。</p>
                </div>
                <div class="p1">
                    <p id="81">通过最小化能量函数,可以求解出像素属于前景的概率。如果像素属于前景的概率大于0.5,则将像素分配给前景;否则分配给背景。</p>
                </div>
                <div class="p1">
                    <p id="82">通过引入拉普拉斯能量项,拉普拉斯坐标算法保证了标签的各向异性传播。此外,在构建能量函数时,拉普拉斯坐标算法利用二次型矩阵,只需要求解线性方程即可最小化能量,降低了计算成本,并确保分割结果的唯一性和平滑性。然而,由于忽略未标记像素点与种子点之间的特征,只依赖相邻像素点的特征,在相邻像素点特征差别较大时,拉普拉斯坐标算法仍然对分散或细小的区域敏感。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">2 本文算法</h3>
                <div class="p1">
                    <p id="84">现有的半监督图像分割方法一般将像素分为已标记的种子点和未标记像素点,同时考虑种子点和未标记像素之间、相邻的未标记像素之间的约束条件。基于拉普拉斯坐标的图像分割算法能够确保分割结果的唯一性和平滑性,但是没有充分利用种子点和未标记像素的特征关系。本文引入未标记像素属于标签的先验概率代表种子点和未标记像素之间特征关系,改进现有算法。</p>
                </div>
                <div class="p1">
                    <p id="85">未标记像素属于标签的先验概率能够代表未标记像素与种子点的相似度,常用文献<citation id="218" type="reference">[<a class="sup">19</a>]</citation>提出的高斯混合模型估计种子点属于前景和背景的先验概率,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>F</mi></mrow></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>Μ</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mtext>F</mtext></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>B</mi></mrow></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>Μ</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">其中:<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>π</mi><mo>^</mo></mover></math></mathml><sub><i>iF</i></sub>表示像素点<i>p</i><sub><i>i</i></sub>属于前景的先验概率,<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>π</mi><mo>^</mo></mover></math></mathml><sub><i>iB</i></sub>表示像素点<i>p</i><sub><i>i</i></sub>属于背景的先验概率,<b><i>C</i></b><sub><i>i</i></sub>表示像素点<i>p</i><sub><i>i</i></sub>的特征强度向量,<i>l</i><sub>F</sub>=1和<i>l</i><sub>B</sub>=0分别表示前景和背景的标签值。对于前景和背景的分割问题,先验概率满足<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>F</mi></mrow></msub><mo>+</mo><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>B</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>,因此仅需要估计一个先验概率即可。为了简化计算,仅估计像素点<i>p</i><sub><i>i</i></sub>属于前景的先验概率<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>π</mi><mo>^</mo></mover></math></mathml><sub><i>iF</i></sub>。耦合先验拉普拉斯坐标算法的能量函数如下:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><mo stretchy="false">)</mo><mo>=</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>B</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>k</mi><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>F</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mtext>F</mtext></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mi>k</mi><msub><mrow></mrow><mn>3</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ρ</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>π</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>k</mi><msub><mrow></mrow><mn>4</mn></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ρ</mi></mrow></munder><mo stretchy="false">∥</mo></mstyle><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>π</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext>F</mtext></mrow></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">其中:<i>π</i>=[<i>π</i><sub><i>i</i></sub>]<sub><i>N</i>×1</sub>为所有像素属于前景的后验概率向量,<i>W</i><sub><i>ij</i></sub>为像素<i>p</i><sub><i>i</i></sub>和<i>p</i><sub><i>j</i></sub>之间的相似性,<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi>B</mi></mrow></math></mathml>为背景种子点集合,<i>F</i>为前景种子点集合,<i>A</i><sub><i>i</i></sub>表示像素<i>p</i><sub><i>i</i></sub>的邻域像素集合,<i>k</i><sub>1</sub>、<i>k</i><sub>2</sub>、<i>k</i><sub>3</sub>、<i>k</i><sub>4</sub>为正控制参数。</p>
                </div>
                <div class="p1">
                    <p id="95">能量函数的第一项和第二项为数据项,表示对种子点的约束,若种子点属于对应标签的概率越小,则能量越小,反之越大。第三项为拉普拉斯能量项,计算了每个像素点偏离其相邻像素点的平均值,以此控制概率值在相邻像素之间的扩散,保证标签各向异性传播的平滑性,若像素与其相邻像素的特征越相似,则能量越小,反之越大。第四项为标签先验项,表示关于先验概率的约束,若先验概率与后验概率的差值越小,则能量越小,反之越大。对于四个正控制参数,为了简化模型并不失一般性,可以给定<i>k</i><sub>3</sub>=1。假定标记的像素点均为正确标记,数据项的约束应当足够强,可以给定<i>k</i><sub>1</sub>=<i>k</i><sub>2</sub>为一充分大常数<i>m</i>。因此,能量函数仅有一个控制参数<i>k</i><sub>4</sub>=<i>k</i>。能量函数可以进一步表示为:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>h</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>π</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">其中:<i>h</i><sub><i>i</i></sub>为控制参数,当<i>p</i><sub><i>i</i></sub>∈<i>P</i><sub><i>U</i></sub>时,<i>h</i><sub><i>i</i></sub>=<i>k</i>,当<i>p</i><sub><i>i</i></sub>∈<i>P</i><sub><i>M</i></sub>时,<i>h</i><sub><i>i</i></sub>=<i>m</i>。<i>y</i><sub><i>i</i></sub>为先验概率,当<i>p</i><sub><i>i</i></sub>∈<i>P</i><sub><i>U</i></sub>时,<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>F</mi></mrow></msub></mrow></math></mathml>,当<i>p</i><sub><i>i</i></sub>∈<i>F</i>时,<i>y</i><sub><i>i</i></sub>=1,当<i>p</i><sub><i>i</i></sub>∈<i>B</i>时,<i>y</i><sub><i>i</i></sub>=0。<i>P</i><sub><i>M</i></sub>=<i>F</i>∪<i>B</i>为标记的像素集合,<i>P</i><sub><i>U</i></sub>=<i>P</i>|<i>P</i><sub><i>M</i></sub>为未标记的像素集合。进而可以将能量函数改写为矩阵形式:</p>
                </div>
                <div class="p1">
                    <p id="99"><i>E</i>(<i>π</i>)=(<i>π</i>-<b><i>Y</i></b>)<sup>T</sup><b><i>K</i></b>(<i>π</i>-<b><i>Y</i></b>)+(<b><i>L</i></b><i>π</i>)<sup>2</sup>      (11)</p>
                </div>
                <div class="p1">
                    <p id="100">其中:<b><i>Y</i></b>=[<i>y</i><sub><i>i</i></sub>]<sub><i>N</i>×1</sub>为先验概率向量,<b><i>K</i></b>=diag(<i>h</i><sub>1</sub>,<i>h</i><sub>2</sub>,…,<i>h</i><sub><i>N</i></sub>)为参数矩阵,<b><i>L</i></b>=<b><i>D</i></b>-<b><i>W</i></b>为拉普拉斯矩阵,<b><i>D</i></b>=diag(<i>d</i><sub>1</sub>,<i>d</i><sub>2</sub>,…,<i>d</i><sub><i>N</i></sub>),<b><i>W</i></b>=[<i>W</i><sub><i>ij</i></sub>]<sub><i>N</i>×<i>N</i></sub>。由于矩阵<b><i>K</i></b>和<b><i>L</i></b>均为实对称矩阵,能量函数为二次函数,存在最小值。能量函数的导函数为<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mfrac><mrow><mo>∂</mo><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">π</mi></mrow></mfrac><mo>=</mo></mrow><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">π</mi><mo>-</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mn>2</mn></msup><mi mathvariant="bold-italic">π</mi></mrow></math></mathml>,通过求解导函数为0的方程,可得函数取到最小值时的解向量,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="102"><i>π</i>=(<b><i>K</i></b>+<b><i>L</i></b><sup>2</sup>)<sup>-1</sup><b><i>KY</i></b>      (12)</p>
                </div>
                <div class="p1">
                    <p id="103">其中<b><i>K</i></b>和<b><i>L</i></b>均为正定的实对称矩阵,保证了解向量的存在性和非负性,能量函数的导函数为一次函数,保证了解向量的唯一性。因此,<i>π</i>为所有像素属于前景的后验概率向量。若像素属于前景的概率大于等于0.5,则将像素分配给前景,即<i>l</i><sub><i>i</i></sub>=1;否则将像素分配给背景,即<i>l</i><sub><i>i</i></sub>=0。根据像素<i>p</i><sub><i>i</i></sub>属于前景的后验概率<i>π</i><sub><i>i</i></sub>∈[0,1],标签值分配的表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>,</mo><mtext> </mtext><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo>.</mo><mn>5</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>5</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">对于多目标分割问题,需要分别计算所有像素属于各个标签的后验概率向量,其后验概率计算公式为前景和背景分割计算公式的高维推广,表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="106"><i>π</i><sub><i>q</i></sub>=(<b><i>K</i></b>+<b><i>L</i></b><sup>2</sup>)<sup>-1</sup><b><i>KY</i></b><sub><i>q</i></sub>      (14)</p>
                </div>
                <div class="p1">
                    <p id="107">其中:<i>π</i><sub><i>q</i></sub>=[<i>π</i><sub><i>iq</i></sub>]<sub><i>N</i>×1</sub>表示所有像素属于标签<i>l</i><sub><i>q</i></sub>的后验概率向量,<b><i>Y</i></b><sub><i>q</i></sub>=[<i>y</i><sub><i>iq</i></sub>]<sub><i>N</i>×1</sub>表示所有像素属于标签<i>l</i><sub><i>q</i></sub>先验概率向量,当<i>p</i><sub><i>i</i></sub>为未标记像素时,<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>q</mi></mrow></msub><mo>=</mo><mover accent="true"><mi>π</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>q</mi></mrow></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>Μ</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>,当<i>p</i><sub><i>i</i></sub>为属于标签<i>l</i><sub><i>q</i></sub>的种子点时,<i>y</i><sub><i>iq</i></sub>=1,当<i>p</i><sub><i>i</i></sub>为不属于标签<i>l</i><sub><i>q</i></sub>的种子点时,<i>y</i><sub><i>iq</i></sub>=0。<i>q</i>=1,2,…,<i>n</i>,<i>n</i>为标签总数。矩阵<b><i>K</i></b>和<b><i>L</i></b>的含义保持不变。最后,将像素分配给后验概率最大的标签。</p>
                </div>
                <div class="p1">
                    <p id="109">与现有的半监督图像分割算法相比,本文算法增加了标签先验项,利用了种子点与未标记像素的特征关系,在保证标签各向异性传播的同时,使得分割结果对分散或细小的区域更加敏感。</p>
                </div>
                <h3 id="110" name="110" class="anchor-tag">3 实验与结果分析</h3>
                <div class="p1">
                    <p id="111">本文实验选用的图像来自于<i>MSRC</i>数据集<citation id="219" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、<i>Graz</i>数据集<citation id="220" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>和<i>LHI</i>数据集<citation id="221" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。<i>MSRC</i>、<i>Graz</i>、<i>LHI</i>数据集提供了用户交互信息和正确分割结果,是评价半监督图像分割方法最常用的数据集。本文选用错误率、重叠度(<i>Intersection over Union</i>, <i>IoU</i>)和运行时间作为评价分割结果的定量指标。错误率的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="112">错误率<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mtext>错</mtext><mtext>分</mtext><mtext>类</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext><mtext>数</mtext></mrow><mrow><mtext>未</mtext><mtext>标</mtext><mtext>记</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="114">其中,错分类像素点和未标记像素点均不包括种子点。<i>IoU</i>是分割问题中常用的标准性能度量指标,表示估计结果与真实结果的重叠度,<i>IoU</i>值越大表示分割效果越好。本文实验基于英特尔酷睿<i>I</i>5 <i>CPU</i>以2.0 <i>GHz</i>的频率在<i>Matlab</i>进行,在同等情况下测算运行时间。本文算法将与一系列随机游走算法进行比较实验,包括随机游走(<i>RW</i>)算法、拉普拉斯坐标(<i>LC</i>)算法、归一化随机游走(<i>NRW</i>)算法、亚马尔可夫随机游走(<i>SMRW</i>)算法。根据文献<citation id="222" type="reference">[<a class="sup">10</a>]</citation>,LC算法的控制参数<i>k</i><sub>1</sub>、<i>k</i><sub>2</sub>、<i>k</i><sub>3</sub>均设为1;本文算法的常数<i>m</i>设为10<sup>5</sup>,控制参数<i>k</i>设为10<sup>-7</sup>。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">3.1 <b>定性比较</b></h4>
                <div class="p1">
                    <p id="116">本文根据分割结果的可视化对4种经典算法和本文算法进行定性评估。图1所示为5种算法的分割结果。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909036_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 五种算法的比较结果" src="Detail/GetImg?filename=images/JSJY201909036_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 五种算法的比较结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909036_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Comparison of five algorithms</i></p>

                </div>
                <div class="p1">
                    <p id="118">图1(<i>b</i>)表示种子点信息,白色的像素被标记为前景种子点,黑色的像素被标记为背景种子点,其余为未标记像素。本文基于未标记像素点的分割错误率比较分割结果。从图中可以看出,由于忽视了标签传播的各向异性,<i>RW</i>算法和<i>NRW</i>算法对细小和分散的区域不敏感。由于依赖相邻像素点之间特征强度的关系,在相邻像素点之间特征强度相差较大时,<i>LC</i>算法容易停止分割,从而导致错误分割边界。<i>SMRW</i>算法对细小区域过于敏感,分割出的边界很不平滑。本文算法改善了已有随机游走算法的缺陷,对分散或细小的目标更加敏感,获得了较好的分割结果。以第一幅图“<i>cross</i>”为例,十字架与立柱连接处的像素颜色特征与其邻域内像素的颜色特征相差较大,因此传统算法仅以连接处为目标的边界。<i>SMRW</i>算法虽然正确分割出十字架,但是房屋边界的分割结果非常不平滑。然而,本文算法引入了标签先验信息,因为十字架的颜色特征与前景种子点的颜色特征非常接近,所以十字架被分割成前景目标。因此本文算法对分散的目标更加敏感。以第二幅图“<i>sheep</i>”为例,由于绵羊腿部颜色与身体颜色相差较大,并且羊腿与身体距离较远,因此<i>RW</i>算法和<i>NRW</i>算法无法分割出羊腿。<i>LC</i>算法虽然考虑了标签的各项异性传播,能够分割出部分羊腿,但是由于羊腿区域细长并且颜色特征与邻域内像素的颜色特征相差较大,因此<i>LC</i>算法仍无法分割出全部的羊腿。由于羊腿的颜色特征与前景标签中绵羊面部的颜色特征近似,所以本文算法分割羊腿的效果更好,因此本文算法对细小的目标更加敏感。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">3.2 <b>定量比较</b></h4>
                <div class="p1">
                    <p id="120">本文在<i>MSRC</i>、<i>Graz</i>、<i>LHI</i>数据集上对5种算法作定量评估,以分割的平均错误率、平均<i>IoU</i>和平均运行时间为评估指标。对于<i>MSRC</i>数据集上的50幅测试图像,<i>RW</i>算法的平均错误率为7.46%,<i>LC</i>算法的平均错误率为5.06%,<i>NRW</i>算法的平均错误率为5.92%,<i>SMRW</i>算法的平均错误率为4.62%,本文算法的平均错误率为4.02%。可以看出本文算法的错误率相对于<i>RW</i>算法和<i>LC</i>算法具有显著下降,并明显优于近年来提出的<i>NRW</i>算法和<i>SMRW</i>算法。表1为在三种数据集上五种算法的平均<i>IoU</i>和平均运行时间,可以看出本文算法的平均<i>IoU</i>约为0.85,在各个数据集上明显高于其余四种算法,分割结果更准确。同时,本文算法每幅图的平均运行时间约3.1 <i>s</i>,明显快于近年来提出的<i>NRW</i>算法和<i>SMRW</i>算法。因此,本文算法引入标签先验项,能够进一步提升拉普拉斯坐标的算法分割的准确度,提升运算速度,具有可行性。</p>
                </div>
                <div class="p1">
                    <p id="121">图2为5种算法在<i>MSRC</i>数据集50幅测试图像的分割错误率的比较,其中图像<i>ID</i>根据本文算法的错误率由低到高排序,可以看出本文算法在大部分测试图像中获得了最优的结果。表2为本文算法在<i>MSRC</i>数据集50幅测试图像上的分割错误率。</p>
                </div>
                <div class="area_img" id="122">
                    <p class="img_tit"><b>表</b>1 <b>三种数据集中五种算法的平均</b><i>IoU</i><b>和平均运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Average IoU and average running time for</i><i>five algorithms in three datasets</i></p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td rowspan="2">算法</td><td colspan="2"><br /><i>MSRC</i></td><td rowspan="2"></td><td colspan="2"><br /><i>Graz</i></td><td rowspan="2"></td><td colspan="2"><br /><i>LHI</i></td></tr><tr><td><br /><i>IoU</i></td><td>时间/<i>s</i></td><td><br /><i>IoU</i></td><td>时间/<i>s</i></td><td><br /><i>IoU</i></td><td>时间/<i>s</i></td></tr><tr><td><i>RW</i></td><td>0.94</td><td>1.3</td><td></td><td>0.71</td><td>2.3</td><td></td><td>0.56</td><td>2.0</td></tr><tr><td><br /><i>LC</i></td><td>0.96</td><td>2.4</td><td></td><td>0.75</td><td>2.8</td><td></td><td>0.59</td><td>6.3</td></tr><tr><td><br /><i>NRW</i></td><td>0.95</td><td>10.4</td><td></td><td>0.79</td><td>10.6</td><td></td><td>0.63</td><td>15.1</td></tr><tr><td><br /><i>SMRW</i></td><td>0.96</td><td>3.3</td><td></td><td>0.78</td><td>4.9</td><td></td><td>0.65</td><td>4.9</td></tr><tr><td><br />本文算法</td><td>0.97</td><td>2.6</td><td></td><td>0.80</td><td>3.1</td><td></td><td>0.69</td><td>4.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909036_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 5种算法在MSRC数据集50幅测试图像上的分割错误率的比较结果" src="Detail/GetImg?filename=images/JSJY201909036_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 5种算法在<i>MSRC</i>数据集50幅测试图像上的分割错误率的比较结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909036_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Comparison of segmentation error rates of five algorithms in</i> 50 <i>test images in MSRC dataset</i></p>

                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表</b>2 <b>本文算法在</b><i>MSRC</i><b>数据集上</b>50<b>幅图像的分割错误率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>The proposed algorithm</i>'<i>s segmentation error rate of</i> 50 <i>images in MSRC dataset</i></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td>图像<i>ID</i></td><td>错误率/%</td><td></td><td>图像<i>ID</i></td><td>错误率/%</td><td></td><td>图像<i>ID</i></td><td>错误率/%</td></tr><tr><td><br />21077</td><td>4.41</td><td rowspan="17"><br /></td><td><br />326038</td><td>7.70</td><td rowspan="17"><br /></td><td><br /><i>memorial</i></td><td>4.22</td></tr><tr><td><br />24077</td><td>10.03</td><td><br />376043</td><td>8.74</td><td><br /><i>music</i></td><td>1.65</td></tr><tr><td><br />37073</td><td>2.99</td><td><br />388016</td><td>2.45</td><td><br /><i>person</i>1</td><td>1.94</td></tr><tr><td><br />65019</td><td>1.98</td><td><br /><i>banana</i>1</td><td>2.60</td><td><br /><i>person</i>2</td><td>4.02</td></tr><tr><td><br />69020</td><td>4.26</td><td><br /><i>banana</i>2</td><td>2.23</td><td><br /><i>person</i>3</td><td>1.45</td></tr><tr><td><br />86016</td><td>3.79</td><td><br /><i>banana</i>3</td><td>4.07</td><td><br /><i>person</i>4</td><td>3.67</td></tr><tr><td><br />106024</td><td>11.38</td><td><br /><i>book</i></td><td>9.76</td><td><br /><i>person</i>5</td><td>2.18</td></tr><tr><td><br />124084</td><td>1.47</td><td><br /><i>bool</i></td><td>4.73</td><td><br /><i>person</i>6</td><td>8.69</td></tr><tr><td><br />153077</td><td>2.83</td><td><br /><i>bush</i></td><td>7.56</td><td><br /><i>person</i>7</td><td>0.71</td></tr><tr><td><br />153093</td><td>5.07</td><td><br /><i>ceramic</i></td><td>3.37</td><td><br /><i>person</i>8</td><td>5.47</td></tr><tr><td><br />181079</td><td>6.92</td><td><br /><i>cross</i></td><td>0.10</td><td><br /><i>scissors</i></td><td>6.18</td></tr><tr><td><br />189080</td><td>2.83</td><td><br /><i>doll</i></td><td>2.81</td><td><br /><i>sheep</i></td><td>0.98</td></tr><tr><td><br />208001</td><td>3.75</td><td><br /><i>elefant</i></td><td>0.27</td><td><br /><i>stone</i>1</td><td>3.31</td></tr><tr><td><br />209070</td><td>2.43</td><td><br /><i>flower</i></td><td>0.69</td><td><br /><i>stone</i>2</td><td>0.73</td></tr><tr><td><br />227092</td><td>2.32</td><td><br /><i>fullmoon</i></td><td>1.38</td><td><br /><i>teddy</i></td><td>2.62</td></tr><tr><td><br />271008</td><td>0.78</td><td><br /><i>grave</i></td><td>2.36</td><td><br /><i>tennis</i></td><td>5.95</td></tr><tr><td><br />304074</td><td>7.22</td><td><br /><i>llama</i></td><td>12.17</td><td><br /></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">3.3 <b>多目标分割</b></h4>
                <div class="p1">
                    <p id="126">对于多目标分割问题,本文选取2幅测试图像的分割结果,定性分析本文算法的准确度。图3为多目标分割结果,测试图像的种子点需要用户手动地标记。如图3(<i>a</i>)所示,红色、绿色和蓝色的像素分别表示三种不同标签的种子点。如图3(<i>b</i>)所示,在多目标分割中,本文算法分割结果仍比较准确,并且对细小的目标敏感。以第一幅图“201080”为例,尽管种子点没有直接标记建筑物顶端的装饰,但是本文算法仍将细小的装饰正确分割,从而验证了在多目标分割问题中本文算法的有效性和可行性。</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909036_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同参数下的分割结果" src="Detail/GetImg?filename=images/JSJY201909036_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同参数下的分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909036_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>Segmentation results under different parameters</i></p>

                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909036_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 多目标分割结果" src="Detail/GetImg?filename=images/JSJY201909036_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 多目标分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909036_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Multi</i>-<i>objective segmentation results</i></p>

                </div>
                <h3 id="130" name="130" class="anchor-tag">4 参数设置</h3>
                <div class="p1">
                    <p id="131">本文通过设定合适的参数k来控制标签先验项的约束强度。图4为不同参数k下的分割结果。由图可以看出,当参数较大时,如图4(<i>c</i>)和(<i>d</i>)所示k=10<sup>-1</sup>,k=10<sup>-4</sup>时,过度考虑了未标记像素点与种子点之间的特征强度关系,导致分割结果中出现杂质点、目标区域不连通等缺陷。当参数较小时,如图4(<i>f</i>)和(<i>g</i>)所示k=10<sup>-10</sup>,k=0时,标签先验项作用不明显,分割结果更接近于拉普拉斯坐标算法的结果,容易错误分割细长的区域。当k=10<sup>-7</sup>时,本文算法在50幅测试图像上得到了较好的分割结果。为了更精确地比较不同参数下的分割精度,本文选用平均错误率定量评估。表3为不同参数下分割结果的平均错误率。可以看出在k=10<sup>-7</sup>时,平均错误率最小,分割精度最高。因此本文选择控制参数k=10<sup>-7</sup>。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表</b>3 <b>不同参数下的平均错误率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 3 <i>Average error rate under different parameters</i></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><i>k</i></td><td>错误率/%</td><td></td><td><i>k</i></td><td>错误率/%</td><td></td><td><i>k</i></td><td>错误率/%</td></tr><tr><td><br />1</td><td>10.18</td><td rowspan="4"><br /></td><td><br />10<sup>-4</sup></td><td>5.84</td><td rowspan="4"><br /></td><td><br />10<sup>-8</sup></td><td>4.16</td></tr><tr><td><br />10<sup>-1</sup></td><td>9.67</td><td><br />10<sup>-5</sup></td><td>4.62</td><td><br />10<sup>-9</sup></td><td>4.57</td></tr><tr><td><br />10<sup>-2</sup></td><td>8.98</td><td><br />10<sup>-6</sup></td><td>4.06</td><td><br />10<sup>-10</sup></td><td>4.79</td></tr><tr><td><br />10<sup>-3</sup></td><td>7.50</td><td><br />10<sup>-7</sup></td><td>4.02</td><td><br />0</td><td>5.03</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="133" name="133" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="134">本文在传统的拉普拉斯坐标算法中引入标签先验项,考虑了未标记像素点和种子点之间的特征强度关系,构造了含有二次型矩阵的能量函数,通过求解能量函数的最小值获得像素属于标签的后验概率,然后根据后验概率分割区域。本文解决了经典算法中分割结果不平滑、错误分割细小和分散的目标区域的问题。为了提高分割的精度,本文通过设置合适的控制参数平衡各项约束的影响,在分割出小目标区域的同时使分割区域的边界更平滑。最后通过对比实验以及在数据集上的定性和定量评估证实了本文算法的实用性和通用性。本文算法仍存在一些缺陷,如种子点较少时分割精度较低、控制参数需要凭经验手动设定等。如何根据不同的图像环境设定参数值,将是今后的研究工作。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="157">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Processing,Analysis and Machine Vision">

                                <b>[1]</b> SONKA M,HLAVAC V,BOYLE R.Image Processing,Analysis and Machine Vision [M].Berlin:Springer,2003:175-176.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Human motion segmentation via robust kernel sparse subspace clustering">

                                <b>[2]</b> XIA G,SUN H,FENG L,et al.Human motion segmentation via robust kernel sparse subspace clustering [J].IEEE Transactions on Image Processing,2018,27(1):135-150.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300297435&amp;v=MDIwNzNIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRndUYVJNPU5pZk9mYks3SHRETnJJOUZadUlJQ0g4OG9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> JI Z,XIA Y,CHEN Q,et al.Fuzzy c-means clustering with weighted image patch for image segmentation [J].Applied Soft Computing,2012,12(6):1659-1667.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fuzzy Local Gaussian Mixture Model for Brain MR Image Segmentation">

                                <b>[4]</b> JI Z,XIA Y,SUN Q,et al.Fuzzy local Gaussian mixture model for brain MR image segmentation [J].IEEE Transactions on Information Technology in Biomedicine,2012,16(3):339-347.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBB4208AD544EB0B1D5F4B4EBE0CBD3A9&amp;v=MDk1NTloeExxNHc2az1OaWZPZmNIS0d0UE1wLzR4WWU4TGVRNDV2UmRuNzBsNU9udVgzbWMxQ3NEZ1JzdVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> WANG T,JI Z,SUN Q,et al.Label propagation and higher-order constraint-based segmentation of fluid-associated regions in retinal SD-OCT images [J].Information Sciences,2016,358(C):92-111.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Perfect image segmentation using pulse coupled neural networks">

                                <b>[6]</b> KUNTIMAD G,RANGANATH H S.Perfect image segmentation using pulse coupled neural networks [J].IEEE Transactions on Neural Networks,1999,10(3):591-598.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 SHELHAMER E,LONG J,DARRELL T.Fully convolutional networks for semantic segmentation [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images">

                                <b>[8]</b> BOYKOV Y Y,JOLLY M.Interactive graph cuts for optimal boundary and region segmentation of objects in N-D images [C]// Proceedings of the 8th IEEE International Conference on Computer Vision.Piscataway,NJ:IEEE,2001:105-112.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Random walks for image segmentation">

                                <b>[9]</b> GRADY L.Random walks for image segmentation [J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2006,28(11):1768-1783.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Laplacian Coordinates for Seeded Image Segmentation">

                                <b>[10]</b> CASACA W,NONATO L G,TAUBIN G.Laplacian coordinates for seeded image segmentation [C]// Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway,NJ:IEEE,2014:384-391.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graph-driven diffusion and random walk schemes for image segmentation">

                                <b>[11]</b> BAMPIS C G,MARAGOS P,BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation [J].IEEE Transactions on Image Processing,2017:26(1):35-50.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sub-Markov Random Walk for Image Segmentation">

                                <b>[12]</b> DONG X,SHEN J,SHAO L,et al.Sub-Markov random walk for image segmentation [J].IEEE Transactions on Image Processing,2016,25(2):516-527.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Segmentation via Probabilistic Graph Matching">

                                <b>[13]</b> HEIMOWITZ A,KELLER Y.Image segmentation via probabilistic graph matching [J].IEEE Transactions on Image Processing,2016,25(10):4743-4752.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using adaptive constraint propagation">

                                <b>[14]</b> JIAN M,JUNG C.Interactive image segmentation using adaptive constraint propagation [J].IEEE Transactions on Image Processing,2016,25(3):1301-1311.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using constrained dominant sets">

                                <b>[15]</b> ZEMENE E,PELILLO M.Interactive image segmentation using constrained dominant sets [C]// Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:278-294.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES903EFC6C6BEEEA0D60A57F570E2B0D78&amp;v=MjQxNjlCdUhZZk9HUWxmQnJMVTA1dHBoeExxNHc2az1OaWZPZmJxNEhhUzYzSWsyWXBsNmVRbEl6MklWNms1NFR3bm5xeEpBZThDVU1iMlhDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> WANG T,SUN Q,JI Z,et al.Multi-layer graph constraints for interactive image segmentation via game theory [J].Pattern Recognition,2016,55(C):28-44.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regularized diffusion process for visual retrieval">

                                <b>[17]</b> BAI S,BAI X,TIAN Q,et al.Regularized diffusion process for visual retrieval [C]// Proceedings of the 31st AAAI Conference on Artificial Intelligence.Palo Alto:AAAI Press,2017:3967-3973.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probabilistic diffusion for interactive image segmentation">

                                <b>[18]</b> WANG T,YANG J,JI Z,et al.Probabilistic diffusion for interactive image segmentation [J].IEEE Transactions on Image Processing,2019,28(1):330-342.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Grabcut-interactive foreground extraction using iterated graph cuts">

                                <b>[19]</b> ROTHER C,KOLMOGOROV V,BLAKE A.Grabcut:interactive foreground extraction using iterated graph cuts [C]// Proceedings of the 2004 ACM SIGGRAPH Conference.New York:ACM,2004:309-314.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive multi-label segmentation">

                                <b>[20]</b> SANTNER J,POCK T,BISCHOF H.Interactive multi-label segmentation [C]// Proceedings of the 2010 Asian Conference on Computer Vision,LNCS 6492.Berlin:Springer,2010:397-410.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Introduction to a large scale general purpose groundtruth dataset:methodology,annotation tool,and benchmarks">

                                <b>[21]</b> YAO B,YANG X,ZHU S.Introduction to a large-scale general purpose ground truth database:methodology,annotation tool and benchmarks [C]// Proceedings of the 2007 International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition,LNCS 4679.Berlin:Springer,2007:169-183.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018080995.nh&amp;v=MDI0OTE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVkx6SlZGMjZGck93SHRqRnFwRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 王涛.特征度量与信息传递的交互式图论分割方法研究[D].南京:南京理工大学,2017:17-29.(WANG T.Research on graph theory based interactive segmentation via feature measurement and information propagation [D].Nanjing:Nanjing University of Science and Technology,2017:17-29.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909036" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909036&amp;v=MjA1NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVkx6Skx6N0JkN0c0SDlqTXBvOUdZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
