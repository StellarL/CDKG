<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136465106221250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909002%26RESULT%3d1%26SIGN%3dW55JOCC8pznPTAo%252fhpwduqU7sRU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909002&amp;v=MTY3MTh0R0ZyQ1VSN3FmWnVac0Z5amtXcnpQTHo3QmQ3RzRIOWpNcG85RlpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#61" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="1 知识表示学习相关工作 ">1 知识表示学习相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="2 对抗式知识表示学习 ">2 对抗式知识表示学习</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="2.1 &lt;b&gt;符号约定&lt;/b&gt;">2.1 <b>符号约定</b></a></li>
                                                <li><a href="#72" data-title="2.2 &lt;b&gt;目标知识表示模型&lt;/b&gt;">2.2 <b>目标知识表示模型</b></a></li>
                                                <li><a href="#84" data-title="2.3 &lt;b&gt;对抗式负样本生成器&lt;/b&gt;">2.3 <b>对抗式负样本生成器</b></a></li>
                                                <li><a href="#94" data-title="2.4 &lt;b&gt;对抗式训练框架&lt;/b&gt;">2.4 <b>对抗式训练框架</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="3 实验方案与结果分析 ">3 实验方案与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#129" data-title="3.1 &lt;b&gt;数据集&lt;/b&gt;">3.1 <b>数据集</b></a></li>
                                                <li><a href="#132" data-title="3.2 &lt;b&gt;实现细节&lt;/b&gt;">3.2 <b>实现细节</b></a></li>
                                                <li><a href="#135" data-title="3.3 &lt;b&gt;实验结果&lt;/b&gt;">3.3 <b>实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#146" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;分值函数&lt;/b&gt;"><b>表</b>1 <b>分值函数</b></a></li>
                                                <li><a href="#87" data-title="图1 负样本生成器架构">图1 负样本生成器架构</a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;实验中使用的数据集&lt;/b&gt;"><b>表</b>2 <b>实验中使用的数据集</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;链接预测实验结果&lt;/b&gt;"><b>表</b>3 <b>链接预测实验结果</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;三元组分类正确率 单位&lt;/b&gt;:%"><b>表</b>4 <b>三元组分类正确率 单位</b>:%</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="186">


                                    <a id="bibliography_1" title=" MILLER G A.WordNet:a lexical database for English [J].Communications of the ACM,1995,38(11):39-41." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000027180&amp;v=MDYzMzBLN0h0ak5yNDlGWk9rSURYUTVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRjhkYVJVPU5pZklZNw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         MILLER G A.WordNet:a lexical database for English [J].Communications of the ACM,1995,38(11):39-41.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_2" title=" AUER S,BIZER C,KOBILAROV G,et al.DBpedia:a nucleus for a Web of open data [C]// Proceedings of the 2007 International Semantic Web Conference,LNCS 4825.Berlin:Springer,2007:722-735." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DBpedia: ANucleus for a Web of Open Data">
                                        <b>[2]</b>
                                         AUER S,BIZER C,KOBILAROV G,et al.DBpedia:a nucleus for a Web of open data [C]// Proceedings of the 2007 International Semantic Web Conference,LNCS 4825.Berlin:Springer,2007:722-735.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_3" title=" BOLLACKER K,EVANS C,PARITOSH P,et al.Freebase:a collaboratively created graph database for structuring human knowledge [C]// Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data.New York:ACM,2008:1247-1250." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Freebase:a collaboratively created graph database for structuring human knowledge">
                                        <b>[3]</b>
                                         BOLLACKER K,EVANS C,PARITOSH P,et al.Freebase:a collaboratively created graph database for structuring human knowledge [C]// Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data.New York:ACM,2008:1247-1250.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_4" title=" BORDES A,USUNIER N,GARCIA-DUR&#193;N A,et al.Translating embeddings for modeling multi-relational data [EB/OL].[2019- 01- 06].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.6132&amp;amp;rep=rep1&amp;amp;type=pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Translating embeddings for modeling multi-relational data">
                                        <b>[4]</b>
                                         BORDES A,USUNIER N,GARCIA-DUR&#193;N A,et al.Translating embeddings for modeling multi-relational data [EB/OL].[2019- 01- 06].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.6132&amp;amp;rep=rep1&amp;amp;type=pdf.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_5" title=" WANG Z,ZHANG J,FENG J,et al.Knowledge graph embedding by translating on hyperplanes [C]// AAAI &#39;14:Proceedings of the 28th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2014:1112-1119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding by translating on hyperplanes">
                                        <b>[5]</b>
                                         WANG Z,ZHANG J,FENG J,et al.Knowledge graph embedding by translating on hyperplanes [C]// AAAI &#39;14:Proceedings of the 28th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2014:1112-1119.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_6" title=" JI G,HE S,XU L,et al.Knowledge graph embedding via dynamic mapping matrix [C]// Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg,PA:Association for Computational Linguistics,2015,1:687-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding via dynamic mapping matrix">
                                        <b>[6]</b>
                                         JI G,HE S,XU L,et al.Knowledge graph embedding via dynamic mapping matrix [C]// Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg,PA:Association for Computational Linguistics,2015,1:687-696.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_7" title=" YANG B,YIH W,HE X,et al.Embedding entities and relations for learning and inference in knowledge bases [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1412.6575.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Embedding entities and relations for learning and inference in knowledge bases">
                                        <b>[7]</b>
                                         YANG B,YIH W,HE X,et al.Embedding entities and relations for learning and inference in knowledge bases [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1412.6575.pdf.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_8" title=" TROUILLON T,WELBL J,RIEDEL S,et al.Complex embeddings for simple link prediction [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1606.06357.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Complex embeddings for simple link prediction">
                                        <b>[8]</b>
                                         TROUILLON T,WELBL J,RIEDEL S,et al.Complex embeddings for simple link prediction [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1606.06357.pdf.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_9" title=" GOODFELLOW I,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets [C]// NIPS &#39;14:Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014,2:2672-2680." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial networks">
                                        <b>[9]</b>
                                         GOODFELLOW I,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets [C]// NIPS &#39;14:Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014,2:2672-2680.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_10" title=" CAI L,WANG W Y.KBGAN:adversarial learning for knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1711.04071.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=KBGAN:adversarial learning for knowledge graph embeddings">
                                        <b>[10]</b>
                                         CAI L,WANG W Y.KBGAN:adversarial learning for knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1711.04071.pdf.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_11" title=" WANG P,LI S,PAN R.Incorporating GAN for negative sampling in knowledge representation learning [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1809.11017.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incorporating GAN for negative sampling in knowledge representation learning">
                                        <b>[11]</b>
                                         WANG P,LI S,PAN R.Incorporating GAN for negative sampling in knowledge representation learning [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1809.11017.pdf.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_12" title=" TOUTANOVA K,CHEN D.Observed versus latent features for knowledge base and text inference [EB/OL].[2019- 01- 08].http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=332E017631F63128927CF06ABF216792 doi=10.1.1.709.9449&amp;amp;rep=rep1&amp;amp;type=pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Observed versus latent features for knowledge base and text inference">
                                        <b>[12]</b>
                                         TOUTANOVA K,CHEN D.Observed versus latent features for knowledge base and text inference [EB/OL].[2019- 01- 08].http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=332E017631F63128927CF06ABF216792 doi=10.1.1.709.9449&amp;amp;rep=rep1&amp;amp;type=pdf.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_13" title=" DETTMERS T,MINERVINI P,STENETORP P,et al.Convolutional 2D knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1707.01476.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional 2D knowledge graph embeddings">
                                        <b>[13]</b>
                                         DETTMERS T,MINERVINI P,STENETORP P,et al.Convolutional 2D knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1707.01476.pdf.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_14" title=" LIN Y,LIU Z,SUN M,et al.Learning entity and relation embeddings for knowledge graph completion [C]// AAAI &#39;15:Proceedings of the 29th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2015:2181-2187." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning entity and relation embeddings for knowledge graph completion">
                                        <b>[14]</b>
                                         LIN Y,LIU Z,SUN M,et al.Learning entity and relation embeddings for knowledge graph completion [C]// AAAI &#39;15:Proceedings of the 29th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2015:2181-2187.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_15" title=" NICKEL M,TRESP V,KRIEGEL H P.A three-way model for collective learning on multi-relational data [C]// ICML &#39;11:Proceedings of the 28th International Conference on International Conference on Machine Learning.Bellevue,Washington:Omnipress,2011:809-816." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Three-Way Model for Collective Learning on Multi-Relational Data">
                                        <b>[15]</b>
                                         NICKEL M,TRESP V,KRIEGEL H P.A three-way model for collective learning on multi-relational data [C]// ICML &#39;11:Proceedings of the 28th International Conference on International Conference on Machine Learning.Bellevue,Washington:Omnipress,2011:809-816.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_16" title=" NICKEL M,ROSASCO L,POGGIO T.Holographic embeddings of knowledge graphs [EB/OL].[2018- 12- 25].https://arxiv.org/pdf/1510.04935v2.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Holographic embeddings of knowledge graphs">
                                        <b>[16]</b>
                                         NICKEL M,ROSASCO L,POGGIO T.Holographic embeddings of knowledge graphs [EB/OL].[2018- 12- 25].https://arxiv.org/pdf/1510.04935v2.pdf.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_17" title=" SOCHER R,CHEN D,MANNING C D,et al.Reasoning with neural tensor networks for knowledge base completion [C]//NIPS &#39;13:Proceedings of the 26th International Conference on Neural Information Processing Systems.Lake Tahoe,Nevada:Curran Associates,2013:926-934." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reasoning with neural tensor networks for knowledge base completion">
                                        <b>[17]</b>
                                         SOCHER R,CHEN D,MANNING C D,et al.Reasoning with neural tensor networks for knowledge base completion [C]//NIPS &#39;13:Proceedings of the 26th International Conference on Neural Information Processing Systems.Lake Tahoe,Nevada:Curran Associates,2013:926-934.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_18" title=" BOSE A J,LING H,CAO Y.Adversarial contrastive estimation [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1805.03642.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial contrastive estimation">
                                        <b>[18]</b>
                                         BOSE A J,LING H,CAO Y.Adversarial contrastive estimation [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1805.03642.pdf.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_19" title=" YU L,ZHANG W,WANG J,et al.SeqGAN:sequence generative adversarial nets with policy gradient [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1609.05473.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SeqGAN:sequence generative adversarial nets with policy gradient">
                                        <b>[19]</b>
                                         YU L,ZHANG W,WANG J,et al.SeqGAN:sequence generative adversarial nets with policy gradient [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1609.05473.pdf.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_20" title=" WANG J,YU L,ZHANG W,et al.IRGAN:a minimax game for unifying generative and discriminative information retrieval models [C]// Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM,2017:515-524." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=IRGAN:A minimax game for unifying generative and discriminative information retrieval models">
                                        <b>[20]</b>
                                         WANG J,YU L,ZHANG W,et al.IRGAN:a minimax game for unifying generative and discriminative information retrieval models [C]// Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM,2017:515-524.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_21" title=" FEDUS W,GOODFELLOW I,DAI A M.MaskGAN:better text generation via filling in the_ [EB/OL].[2019- 01- 09].http://export.arxiv.org/pdf/1801.07736." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MaskGAN:better text generation via filling in the_">
                                        <b>[21]</b>
                                         FEDUS W,GOODFELLOW I,DAI A M.MaskGAN:better text generation via filling in the_ [EB/OL].[2019- 01- 09].http://export.arxiv.org/pdf/1801.07736.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_22" title=" SUTTON R S,BARTO A G.Reinforcement learning:an introduction [EB/OL].[2019- 01- 08].http://users.umiacs.umd.edu/～hal/courses/2016F_RL/RL9.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reinforcement learning:an introduction">
                                        <b>[22]</b>
                                         SUTTON R S,BARTO A G.Reinforcement learning:an introduction [EB/OL].[2019- 01- 08].http://users.umiacs.umd.edu/～hal/courses/2016F_RL/RL9.pdf.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_23" title=" SUTSKEVER I,VINYALS O,LE Q V.Sequence to sequence learning with neural networks [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1409.3215.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sequence to sequence learning with neural networks">
                                        <b>[23]</b>
                                         SUTSKEVER I,VINYALS O,LE Q V.Sequence to sequence learning with neural networks [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1409.3215.pdf.
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_24" title=" CHO K,van MERRIENBOER B,GULCEHRE C,et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1406.1078.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Phrase Representations Using RNN Encoder-decoder for Statistical Machine Translation">
                                        <b>[24]</b>
                                         CHO K,van MERRIENBOER B,GULCEHRE C,et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1406.1078.pdf.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_25" title=" SUTTON R S,MCALLESTER D A,SINGH S P,et al.Policy gradient methods for reinforcement learning with function approximation [EB/OL].[2019- 01- 09].https://www.docin.com/p-1195188340.html." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Policy gradient methods for reinforcement learning with function approximation">
                                        <b>[25]</b>
                                         SUTTON R S,MCALLESTER D A,SINGH S P,et al.Policy gradient methods for reinforcement learning with function approximation [EB/OL].[2019- 01- 09].https://www.docin.com/p-1195188340.html.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_26" title=" WATKINS C J C H.Learning from delayed rewards [D].Cambridge:King&#39;s College,1989." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from delayed rewards">
                                        <b>[26]</b>
                                         WATKINS C J C H.Learning from delayed rewards [D].Cambridge:King&#39;s College,1989.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_27" title=" KINGMA D P,BA J L.Adam:a method for stochastic optimization [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1412.6980.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A Method for Stochastic Optimization[C/OL]">
                                        <b>[27]</b>
                                         KINGMA D P,BA J L.Adam:a method for stochastic optimization [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1412.6980.pdf.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_28" title=" DUCHI J,HAZAN E,SINGER Y.Adaptive subgradient methods for online learning and stochastic optimization [J].Journal of Machine Learning Research,2011,12:2121-2159." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive subgradient methods for online learning and stochastic optimization">
                                        <b>[28]</b>
                                         DUCHI J,HAZAN E,SINGER Y.Adaptive subgradient methods for online learning and stochastic optimization [J].Journal of Machine Learning Research,2011,12:2121-2159.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_29" title=" HAN X,CAO S,LV X,et al.OpenKE:an open toolkit for knowledge embedding [EB/OL].[2019- 01- 09].http://nlp.csai.tsinghua.edu.cn/～lzy/publications/emnlp2018_openke.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OpenKE:an open toolkit for knowledge embedding">
                                        <b>[29]</b>
                                         HAN X,CAO S,LV X,et al.OpenKE:an open toolkit for knowledge embedding [EB/OL].[2019- 01- 09].http://nlp.csai.tsinghua.edu.cn/～lzy/publications/emnlp2018_openke.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-23 15:35</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2489-2493 DOI:10.11772/j.issn.1001-9081.2019020357            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>用于知识表示学习的对抗式负样本生成</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">张钊</a>
                                <a href="javascript:;">吉建民</a>
                                <a href="javascript:;">陈小平</a>
                </h2>
                    <h2>

                    <span>中国科学技术大学计算机科学与技术学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>知识表示学习目的是将知识图谱中符号化表示的关系与实体嵌入到低维连续向量空间。知识表示模型在训练过程中需要大量负样本,但多数知识图谱只以三元组的形式存储正样本。传统知识表示学习方法中通常使用负采样方法,这种方法生成的负样本很容易被模型判别,随着训练的进行对性能提升的贡献也会越来越小。为了解决这个问题,提出了对抗式负样本生成器(ANG)模型。生成器采用编码-解码架构,编码器读入头或尾实体被替换的正样本作为上下文信息,然后解码器利用编码器提供的编码信息为三元组填充被替换的实体,从而构建负样本。训练过程采用已有的知识表示学习模型与生成器进行对抗训练以优化知识表示向量。在链接预测和三元组分类任务上评估了该方法,实验结果表明该方法对已有知识表示学习模型在FB15K237、WN18和WN18RR数据集上的链接预测平均排名与三元组分类准确度都有提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识表示学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识图谱;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成对抗网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识图谱嵌入;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张钊(1994—),男,河北衡水人,硕士研究生,主要研究方向:知识表示学习、知识图谱、自然语言处理;;
                                </span>
                                <span>
                                    *吉建民(1984—),男,甘肃定西人,副教授,博士,CCF会员,主要研究方向:认知机器人、知识表示与推理;电子邮箱jianmin@ustc.edu.cn;
                                </span>
                                <span>
                                    陈小平(1955—),男,北京人,教授,博士生导师,博士,主要研究方向:人工智能逻辑、多智能体系统、智能机器人。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-06</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(U1613216,61573386);</span>
                                <span>广东省科技计划项目(2017B010110011);</span>
                    </p>
            </div>
                    <h1><b>Adversarial negative sample generation for knowledge representation learning</b></h1>
                    <h2>
                    <span>ZHANG Zhao</span>
                    <span>JI Jianmin</span>
                    <span>CHEN Xiaoping</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, University of Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Knowledge graph embedding is to embed symbolic relations and entities of the knowledge graph into low dimensional continuous vector space. Despite the requirement of negative samples for training knowledge graph embedding models, only positive examples are stored in the form of triplets in most knowledge graphs. Moreover, negative samples generated by negative sampling of conventional knowledge graph embedding methods are easy to be discriminated by the model and contribute less and less as the training going on. To address this problem, an Adversarial Negative Generator(ANG) model was proposed. The generator applied the encoder-decoder pipeline, the encoder readed in positive triplets whose head or tail entities were replaced as context information, and then the decoder filled the replaced entity with the triplet using the encoding information provided by the encoder, so as to generate negative samples. Several existing knowledge graph embedding models were used to play an adversarial game with the proposed generator to optimize the knowledge representation vectors. By comparing with existing knowledge graph embedding models, it can be seen that the proposed method has better mean ranking of link prediction and more accurate triple classification result on FB15 K237, WN18 and WN18 RR datasets.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=knowledge%20representation%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">knowledge representation learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=knowledge%20graph&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">knowledge graph;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20adversarial%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative adversarial network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=knowledge%20graph%20embedding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">knowledge graph embedding;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Zhao, born in 1994, M. S. candidate. His research interests include knowledge representation learning, knowledge graph, natural language processing.;
                                </span>
                                <span>
                                    JI Jianmin, born in 1984, Ph. D. , associate professor. His research interests include cognitive robot, knowledge representation and reasoning.;
                                </span>
                                <span>
                                    CHEN Xiaoping, born in 1955, Ph. D. , professor. His research interests include logic based artificial intelligence, multi-agent system, intelligent robot.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-06</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(U1613216,61573386);</span>
                                <span>the Science and Technology Planning Project of Guangdong Province(2017B010110011);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="61" name="61" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="62">知识图谱(Knowledge Graph, KG)是由一系列相互关联的实体节点组成的网络,通常以三元组(头实体,关系,尾实体)的形式表示,表示头实体和尾实体之间存在一条关系。近年来有很多大型知识图谱被构建出来,比如 WordNet<citation id="244" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、DBpedia<citation id="245" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、Freebase<citation id="246" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。而大型知识图谱面临的一个主要问题就是由知识图谱中稀疏离散表示的知识导致的高计算复杂性,同时也很难衡量知识的相似性与相关性。所以近年来有大量工作关注知识表示学习(如TransE<citation id="247" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、TransH<citation id="248" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、TransD<citation id="249" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、DistMult<citation id="250" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、ComplEx<citation id="251" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等),这些工作为知识图谱补全和关系抽取等任务提供了大量便利。知识表示学习目标是将知识图谱中的实体和关系嵌入到低维连续向量空间,同时由分值函数计算知识的可信度。在训练模型时,需要正样本和负样本进行判别训练并对结果进行排序。然而考虑到存储空间利用率,大部分知识图谱仅存储正样本,所以传统的知识表示学习模型多数采用负采样<citation id="252" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的方式构建负样本。在这种方法下,三元组的头实体或者尾实体被从实体集合中随机采样得到的新实体替换,从而构成负样本。采样过程一般遵循实体集合上的均匀分布或者伯努利分布。这种方法简单而高效,但是由于知识图谱的稀疏性问题,随机采样得到的绝大部分实体很难与正样本中的关系与实体组成一个可信样本,比如对正样本(合肥,位于,安徽)通过负采样得到的负样本可以是(合肥,位于,香蕉),这些低质量的三元组可以很容易被模型判别,导致代价函数快速收敛甚至随着训练过程的进行无法对提升模型性能提供帮助。</p>
                </div>
                <div class="p1">
                    <p id="63">近年来在生成对抗网络(Generative Adversarial Network, GAN)<citation id="253" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>的启发下,部分工作开始使用对抗式训练框架生成负样本。KBGAN<citation id="254" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用两个不同的知识表示模型作为生成器与判别器进行对抗训练来优化知识表示。用于负采样的生成式对抗网络(Generative Adversarial Net For NEGative sampling, GAN4NEG)<citation id="255" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>关注基于翻译距离的知识表示学习模型中零损失的问题。本文提出了一种对抗式负样本生成器(Adversarial Negative Generator, ANG)用于生成负样本,同时使用已有知识表示学习模型作判别器在对抗式训练框架下进行对抗训练。针对链接预测和三元组分类两个任务在FB15K237<citation id="256" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、WN18<citation id="257" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、WN18RR<citation id="258" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>三个数据集上进行了实验,结果表明本文方法在链接预测(Link prediction)平均排名(Mean Ranking, MR)和三元组分类(Triple Classification)准确度上有明显提升。</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag">1 知识表示学习相关工作</h3>
                <div class="p1">
                    <p id="65">知识表示学习目标是为知识图谱中以三元组(<i>h</i>,<i>r</i>,<i>t</i>) 表示的知识建模,将其实体与关系嵌入到低维连续向量空间中。在知识表示模型中,关系被定义为头实体和尾实体之间的映射,通过一个分值函数<i>f</i>(<i>h</i>,<i>r</i>,<i>t</i>)对每个三元组计算可信度分值,存在于知识图谱中的三元组(正样本)会比不存在的三元组(负样本)分值高。</p>
                </div>
                <div class="p1">
                    <p id="66">目前主要有两类知识表示学习模型:翻译距离(Translation Distance)模型和语义匹配(Semantic Matching)模型。TransE首先引入了基于翻译距离的分值函数,在这种模型下,关系向量<i><b>r</b></i>被视作从头实体<i><b>h</b></i>到尾实体<i><b>t</b></i>的翻译,当<i><b>h</b></i>+<i><b>r</b></i>与<i><b>t</b></i>距离越小时,三元组可信度越高。TransH在其基础上作了扩展,使其更适用于一对多,多对多等复杂关系建模。另外还有很多TransE模型的变体在不同方面提升了性能,比如TransD、TransR<citation id="259" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。RESCAL<citation id="260" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>是比较早期使用基于语义匹配的分值函数的工作之一,这类模型也被称作矩阵分解模型。在这类模型中,关系向量被视为头实体与尾实体之间的映射矩阵,用<i><b>h</b></i><i>M</i><sub><i>r</i></sub><i><b>t</b></i>矩阵乘积来衡量三元组可信度,ComplEx、DistMult和HolE<citation id="261" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>是这一类方法的变体。同时也有许多其他类型的模型使用神经网络来拟合分值函数比如NTN<citation id="262" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和ConvE<citation id="263" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="67">在知识表示模型训练过程中需要正样本和负样本,模型通过对正样本和负样本打分并排序计算代价函数,同时优化知识表示向量。由于大多数知识图谱不提供负样本,上述模型都是采用负采样方法生成,但是这一方法很难生成高质量的负样本。KBGAN首先提出使用生成对抗网络进行知识表示模型训练。在KBGAN中,用预训练的语义匹配模型作为生成器,用预训练的翻译距离模型作为判别器进行对抗式训练,最终采用判别器中的知识表示向量进行评估。在GAN4NEG中,作者提出翻译距离模型中使用负采样方法会导致零损失问题,也就是随着训练的进行,由于分值较差的负样本很快被排到正确的位置,正负样本之间的区别几乎与负样本无关,导致损失函数降为零。他们使用一个两层全连接神经网络作为生成器为正样本生成相应负样本。基于类似的想法,ACE(Adversarial Constrastive Estimation)<citation id="264" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>为自然语言处理中常用的噪声对比估计方法,提出了一个更通用的对抗式负采样方法。但是由于经典生成对抗网络是为生成连续的数据设计的,在梯度反向传播时要求完全可微分,而生成实体时采样过程阻断了梯度的反向传播。为了将生成对抗网络扩展为支持生成离散自然语言词组,很多自然语言生成工作<citation id="266" type="reference"><link href="222" rel="bibliography" /><link href="224" rel="bibliography" /><link href="226" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>以及上述模型都使用REINFORCE<citation id="265" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>方法来完成梯度反向传播。</p>
                </div>
                <h3 id="68" name="68" class="anchor-tag">2 对抗式知识表示学习</h3>
                <h4 class="anchor-tag" id="69" name="69">2.1 <b>符号约定</b></h4>
                <div class="p1">
                    <p id="70">本文中使用<i>E</i>代表知识图谱中的实体集合,<i>R</i>代表关系集合,<i>ξ</i>和<i>ξ</i>′代表正样本(<b><i>h</i></b>,<b><i>r</i></b>,<b><i>t</i></b>)和对应的负样本。<i>S</i>代表一组三元组<i>ξ</i>,其中<b><i>h</i></b>,<b><i>t</i></b>∈<i>E</i>, <b><i>r</i></b>∈<i>R</i>,<i>S</i>中<i>ξ</i>对应的负样本集合表示如下:</p>
                </div>
                <div class="p1">
                    <p id="71"><i>S</i>′<sub><i>ξ</i></sub>={(<b><i>h</i></b>′,<b><i>r</i></b>,<b><i>t</i></b>)|<b><i>h</i></b>′∈<i>E</i>}∪{(<b><i>h</i></b>,<b><i>r</i></b>,<b><i>t</i></b>′)|<b><i>t</i></b>′∈<i>E</i>}</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">2.2 <b>目标知识表示模型</b></h4>
                <div class="p1">
                    <p id="73">为了检验对抗式负样本生成器的性能,本文实现了几个代表性的基于翻译距离的模型(<i>TransE</i><citation id="267" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,<i>TransH</i><citation id="268" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,<i>TransD</i><citation id="269" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>)和基于语义匹配的模型(<i>ComplEx</i><citation id="270" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, <i>DistMult</i><citation id="271" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>)作为判别器,也作为知识表示目标模型。判别器内部的知识表示向量用于模型的评估。它们的分值函数在表1中说明。</p>
                </div>
                <div class="area_img" id="74">
                                            <p class="img_tit">
                                                <b>表</b>1 <b>分值函数</b>
                                                    <br />
                                                <i>Tab</i>. 1 <i>Score functions</i>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909002_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201909002_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909002_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 分值函数" src="Detail/GetImg?filename=images/JSJY201909002_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="75">翻译距离模型使用基于距离的分值函数来估计三元组的置信度。在这类模型中关系作为头实体和尾实体之间的翻译向量,分值函数越小意味着置信度越高,同时使用Margin Ranking Loss作为损失函数:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mi>D</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>ξ</mi><mo>∈</mo><mi>S</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><msup><mi>ξ</mi><mo>′</mo></msup><mo>∈</mo><msup><mi>S</mi><mo>′</mo></msup><msub><mrow></mrow><mi>ξ</mi></msub></mrow></munder><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>f</mi><mo stretchy="false">(</mo><mi>ξ</mi><mo stretchy="false">)</mo><mo>-</mo><mi>f</mi><mo stretchy="false">(</mo><msup><mi>ξ</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo stretchy="false">]</mo><msub><mrow></mrow><mo>+</mo></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中:[<i>x</i>]<sub>+</sub> 表示<i>x</i>的绝对值,<i>γ</i>表示间隔(margin)距离。</p>
                </div>
                <div class="p1">
                    <p id="78">语义匹配模型使用基于语义相似度的分值函数。在这类模型中关系被表示为一个矩阵,代表了头实体与尾实体之间的相互关系。这类模型使用Logistic Loss作为损失函数:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mi>D</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>ξ</mi><mo>∈</mo><mi>S</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><msup><mi>ξ</mi><mo>′</mo></msup><mo>∈</mo><msup><mi>S</mi><mo>′</mo></msup><msub><mrow></mrow><mi>ξ</mi></msub></mrow></munder><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>l</mi><mo stretchy="false">(</mo><mo>+</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">(</mo><mi>ξ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>l</mi><mo stretchy="false">(</mo><mo>-</mo><mn>1</mn><mo>,</mo><mspace width="0.25em" /><mo stretchy="false">(</mo><msup><mi>ξ</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中<i>l</i>(<i>β</i>,<i>x</i>)是Softplus激活函数:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>β</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>β</mi></mfrac><mo>*</mo><mrow><mi>ln</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mi>β</mi><mo>*</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">在这两类模型的原始实现中,<i>S</i>′<sub><i>ξ</i></sub>都是使用负采样方法构建的;而在本文的对抗式训练框架中,<i>S</i>′<sub><i>ξ</i></sub>是由生成器提供的,这一生成器可以更好地利用正样本中的信息来生成置信度更高的负样本。使用上述模型作为判别器,通过对抗训练优化<i>L</i><sub><i>D</i></sub>,同时使用分值函数来估计<i>ξ</i>′的回报:</p>
                </div>
                <div class="p1">
                    <p id="83"><i>R</i><sub><i>D</i></sub>=-<i>f</i>(<i>ξ</i>′)      (4)</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">2.3 <b>对抗式负样本生成器</b></h4>
                <div class="p1">
                    <p id="85">为了给判别器提供高质量的负样本,生成器需要使用对应的正样本作为额外信息。在<i>MaskGAN</i><citation id="272" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>的启发下,本文的生成器采用了一个基于<i>Seq</i>2<i>Seq</i><citation id="273" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>的编码-解码架构,如图1。示例中实体到解码器(<i>decoder</i>)表示的是采样过程,<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">t</mi><mo>˜</mo></mover></math></mathml>是补全的尾实体,〈<i>s</i>〉表示的是开始解码的标志。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 负样本生成器架构" src="Detail/GetImg?filename=images/JSJY201909002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 负样本生成器架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Negative generator architecture</p>

                </div>
                <div class="p1">
                    <p id="88">训练过程中,对每一批正样本中的三元组,用〈<i>m</i>〉标记以相同的概率替换其头或者尾实体(非同时替换),表示为<i>m</i>(<i>ξ</i>′)。<i>m</i>(<i>ξ</i>′)作为一个由双向GRU<citation id="274" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>组成的编码器(encoder)的输入,编码成正样本的向量表示。解码器(decoder)的目的是根据标记补全<i>m</i>(<i>ξ</i>′)中缺失的部分,其为由一个单层GRU单元和一个全连接层组成的神经网络,输入是编码器编码得到的正样本隐藏表示向量以及上一个时间步中编码器输出的实体或关系标记。编码器按顺序在头实体,关系与尾实体上解构其条件分布,经过softmax激活函数后,解码器根据输出的概率分布采样得到正样本中以〈<i>m</i>〉表示的缺失的实体<i><b>t</b></i>,补全的实体在图1中用<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">t</mi><mo>˜</mo></mover></math></mathml>表示,然后补全的三元组<i>ξ</i>′作为负样本。然而,由于采样过程会导致输出不可微,从而无法进行梯度反向传播,所以需要使用策略梯度<citation id="275" type="reference"><link href="234" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>(Policy Gradients)方法进行训练。训练目标定义为最大化生成实体填充的负样本对应的回报(Reward)期望,如下:</p>
                </div>
                <div class="p1">
                    <p id="90"><b>E</b><sub><i>G</i></sub>[<i>R</i><sub><i>D</i></sub>]=<b>E</b><sub><i>ξ</i>′～<i>G</i>(<i>m</i>(<i>ξ</i>;<i>θ</i>))</sub><i>R</i><sub><i>D</i></sub>(<i>ξ</i>′)</p>
                </div>
                <div class="p1">
                    <p id="91">ᐁ<sub><i>θ</i></sub><b>E</b><sub><i>G</i></sub>[<i>R</i><sub><i>D</i></sub>]=<i>R</i><sub><i>D</i></sub>(<i>ξ</i>′)ᐁ<sub><i>θ</i></sub> ln <i>p</i>(<i>ξ</i>′|<i>ξ</i>;<i>θ</i>)=</p>
                </div>
                <div class="p1">
                    <p id="92">-<i>f</i>(<i>ξ</i>′)ᐁ<sub><i>θ</i></sub> ln <i>p</i>(<i>ξ</i>′|<i>ξ</i>;<i>θ</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="93">在标准的强化学习算法中,本文的生成器可以看作其中的策略网络,判别器可以看作值网络,生成器内部表示策略分布,输入的正样本可以看作强化学习中的状态(state),输出补全的负样本可以看作策略网络输出的动作(action)。判别器为选择的动作进行评估,给出回报(reward),然后通过策略梯度方式进行反向传播。整个训练过程优化目标是最大化策略网络输出动作的分值期望。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">2.4 <b>对抗式训练框架</b></h4>
                <div class="p1">
                    <p id="95">首先对生成器使用极大似然估计进行预训练,即最大化生成器还原输入正样本的概率。然后使用对抗式训练框架对生成器和目标知识表示学习模型进行训练,训练算法如算法 1所示。</p>
                </div>
                <div class="p1">
                    <p id="96">算法1 用于知识表示学习的生成式对抗训练算法。</p>
                </div>
                <div class="p1">
                    <p id="97">输入:预训练的生成器<i>G</i>,判别器<i>D</i>,训练集<i>S</i>={(<b><i>h</i></b>,<b><i>r</i></b>,<b><i>t</i></b>)} ;</p>
                </div>
                <div class="p1">
                    <p id="98">输出:从<i>D</i>中学习得到的知识表示向量。</p>
                </div>
                <div class="p1">
                    <p id="99">1)Loop</p>
                </div>
                <div class="p1">
                    <p id="101">2)For <i>G</i> steps do</p>
                </div>
                <div class="p1">
                    <p id="103">3)从<i>S</i>中采样一批正样本<i>S</i><sub>pos</sub></p>
                </div>
                <div class="p1">
                    <p id="105">4)For each <i>ξ</i>∈<i>S</i><sub>pos</sub></p>
                </div>
                <div class="p1">
                    <p id="107">5)通过用〈<i>m</i>〉替换<i>ξ</i>中的<i><b>h</b></i>或<i><b>t</b></i>构建<i>m</i>(<i>ξ</i>)</p>
                </div>
                <div class="p1">
                    <p id="109">6)生成器<i>G</i>通过编码<i>m</i>(<i>ξ</i>),生成负样本<i>ξ</i>′加入到负样本集合<i>S</i><sub>neg</sub>中</p>
                </div>
                <div class="p1">
                    <p id="111">7)End for</p>
                </div>
                <div class="p1">
                    <p id="113">8)判别器<i>D</i>用式(4)计算<i>R</i><sub><i>ξ</i></sub>′</p>
                </div>
                <div class="p1">
                    <p id="115">9)用式(5)更新<i>G</i><sub><i>θ</i></sub></p>
                </div>
                <div class="p1">
                    <p id="117">10)End for</p>
                </div>
                <div class="p1">
                    <p id="119">11)判别器<i>D</i>用<i>S</i><sub>pos</sub>和<i>S</i><sub>neg</sub>通过式(1)和式(2)计算<i>L</i><sub><i>D</i></sub></p>
                </div>
                <div class="p1">
                    <p id="121">12)通过ᐁ<sub><i>Dθ</i></sub><i>L</i><sub><i>D</i></sub> 更新<i>D</i><sub><i>θ</i></sub></p>
                </div>
                <div class="p1">
                    <p id="123">13)End loop</p>
                </div>
                <div class="p1">
                    <p id="125">由于生成器在整个知识库实体集合上估计条件概率分布,生成的负样本可能仍存在于知识库三元组集合中,这类负样本不能被视为错误的三元组,否则会误导目标知识表示模型的训练。在传统的负采样算法中,为了避免这种情况是通过重采样来过滤错误的负样本的,由于知识库的稀疏性,随机重采样得到的负样本为正样本的概率很小。然而在本文的方法中,由于生成负样本时考虑了正样本作为额外信息,采样得到的负样本实际为正样本的概率不可忽略,因为正样本分值函数更高,也意味着其回报更高。所以本文在训练时给此类假负样本一个较大的负的回报作为惩罚,并强制其不参与目标知识表示模型的训练。</p>
                </div>
                <div class="p1">
                    <p id="126">同时模式崩溃也是生成对抗网络中常见的问题。模式崩溃的意思是随着训练的进行,生成器所生成的候选实体很快集中到很少的几个样本,在这种情况下由于负采样方法可以采样到更大范围的样本,本文的方法可能会弱于负采样方法。为了避免这种问题,本文使用了 ε-greedy<citation id="276" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>策略来平衡生成器探索与利用负样本的过程。</p>
                </div>
                <h3 id="127" name="127" class="anchor-tag">3 实验方案与结果分析</h3>
                <div class="p1">
                    <p id="128">在链接预测(<i>Link Prediction</i>)和三元组分类(<i>Triple Classification</i>)任务上评估了本文方法,在实验中使用了三个翻译距离模型和两个语义匹配模型与生成器进行对抗式训练,实验使用判别器的实体关系表示向量进行评估。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">3.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="130">在实验中使用了3个知识表示学习中的常用数据集:<i>FB</i>15<i>K</i>237、<i>WN</i>18和<i>WN</i>18<i>RR</i>,数据集详细数据如表2。</p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表</b>2 <b>实验中使用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Statistics of datasets in experiments</i></p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td rowspan="2"><br />数据集</td><td rowspan="2">关系数</td><td rowspan="2">实体数</td><td colspan="3"><br />样本数</td></tr><tr><td><br />训练集</td><td>验证集</td><td>测试集</td></tr><tr><td><i>FB</i>15<i>K</i>237</td><td>237</td><td>14 541</td><td>272 115</td><td>17 535</td><td>20 466</td></tr><tr><td><br /><i>WN</i>18</td><td>18</td><td>40 943</td><td>141 442</td><td>5 000</td><td>5 000</td></tr><tr><td><br /><i>WN</i>18<i>RR</i></td><td>11</td><td>40 943</td><td>86 835</td><td>3 034</td><td>3 134</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">3.2 <b>实现细节</b></h4>
                <div class="p1">
                    <p id="133">在预训练阶段使用极大似然法(<i>Maximum Likelihood Estimation</i>, <i>MLE</i>)训练生成器,根据在验证集上的三元组预测准确率选择最佳模型,在<i>WN</i>18和<i>WN</i>18<i>RR</i>数据集上实体和关系向量维度为50,在<i>FB</i>15<i>K</i>237上维度为100,优化器使用<i>Adam</i><citation id="277" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="134">在对抗式训练环节,ε范围是1.0到0.4,间隔γ在<i>FB</i>15<i>K</i>237上为1.0,在<i>WN</i>18和<i>WN</i>18<i>RR</i>上为3.0,生成器优化器为<i>SGD</i>,学习率为0.01。判别器的优化器翻译距离模型选择<i>Adam</i>,使用默认参数,语义匹配模型选择<i>Adagrad</i><citation id="278" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>,<i>WN</i>18和<i>WN</i>18<i>RR</i>的学习率为0.1,<i>FB</i>15<i>K</i>237的学习率为0.01。实验运行了1 000轮,每一轮将训练集划分为100个批次训练。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">3.3 <b>实验结果</b></h4>
                <h4 class="anchor-tag" id="136" name="136">3.3.1 链接预测</h4>
                <div class="p1">
                    <p id="137">链接预测(<i>Link Prediction</i>)是知识库补全中的一项主要任务,其目的是为给定的三元组预测缺失的头或尾实体。链接预测主要是通过为一系列从知识库取出的候选实体评分并进行排序来评价模型性能。</p>
                </div>
                <div class="p1">
                    <p id="138">实验中,首先轮流将测试集三元组的头实体替换为E中的所有实体,然后为每一个生成的三元组评分并降序排列,然后在尾实体上实施相同的过程。每一组排序结果中正确的三元组被记录下来,测试完成后将正确三元组的平均排名(<i>MR</i>)以及正确三元组排序在前10%的比例(<i>HIts</i>@10)作为评价标准。由于某些生成的三元组可能也是正确的三元组(存在于<i>S</i>),这会导致某些生成的三元组会比所预测的三元组排名要高,而实际上这种情况不能说生成的三元组应该比所预测的三元组置信度更高,所以将排名中的正确三元组过滤掉作为最终结果。</p>
                </div>
                <div class="p1">
                    <p id="139">表3列出了本文模型与基准模型和相关方法(KBGAN、GAN4NEG)在链接预测任务上不同数据集的性能对比。粗体表示的是对比实验中的最优结果,下划线表示的是次优结果。</p>
                </div>
                <div class="area_img" id="140">
                                            <p class="img_tit">
                                                <b>表</b>3 <b>链接预测实验结果</b>
                                                    <br />
                                                Tab. 3 Link prediction results
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909002_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201909002_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909002_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 链接预测实验结果" src="Detail/GetImg?filename=images/JSJY201909002_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="141">表3中原始基准模型在WN18数据集上的实验结果都是从原始论文中获得,在FB15K237和WN18RR上的结果是使用OpenKE<citation id="279" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>工具包在与本实验相同的参数设置下得到,相关模型KBGAN的结果是用作者提供的代码在其预设参数下训练得到,GAN4NEG作者没有提供代码,所以仅列出其在WN18上的实验结果。KBGAN和GAN4NEG实验结果都是在有预训练的情况下得到。从结果可以看出,ANG模型在平均排名(MR)评价标准上超过了大部分基准模型与相关方法,Hits@10评价标准也在大部分实验设置中比基准模型表现好。在Hits@10标准中,由于本模型中生成器输出的采样空间为整个知识库实体集合,而KBGAN和GAN4NEG中都是在生成器输入前从实体集合中随机挑选一个较小的候选实体集合,然后生成器在候选集合中挑选条件概率最大的实体,所以其在训练过程中可以更好地对排名相近的三元组进行判别,而本文方法采样空间更大,所以对最终正样本平均排名(MR)优化效果更好。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142">3.3.2 三元组分类</h4>
                <div class="p1">
                    <p id="143">三元组分类(<i>Triple Classification</i>)目的是判断给定三元组(<i><b>h</b></i>,<i><b>r</b></i>,<i><b>t</b></i>)是正样本还是负样本,也即是否存在于知识图谱中。由于标准测试集中不存在负样本,所以本文使用了与NTN<citation id="280" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>中相同的方法来构建测试集中的负样本。首先将测试集中三元组的头尾交换,然后根据交换后的实体是否在数据集中相应位置上出现过进行过滤,得到的三元组作为负样本,然后为验证集进行同样操作得到验证集中的负样本。进行三元组分类测试时,首先在验证集上进行分类测试,为每个关系<i><b>r</b></i>最大化分类准确率得到分类阈值<i>δ</i><sub><i>r</i></sub>,测试三元组(<i><b>h</b></i>,<i><b>r</b></i>,<i><b>t</b></i>)分值大于阈值<i>δ</i><sub><i>r</i></sub>时分类为正,否则为负。训练过程中使用验证集测试模型效果,然后在测试集上给出三元组分类准确率。</p>
                </div>
                <div class="p1">
                    <p id="144">表4列出了本文模型和基准模型在三元组分类任务上的结果对比。由于相关方法KBGAN和GAN4NEG中没有给出在这三个数据集上三元组分类的结果,在此不作比较。实验表明,在大多数数据集上,ANG的表现都要明显好于基准模型。</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表</b>4 <b>三元组分类正确率 单位</b>:% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Triple classification accuracy unit: %</p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />模型</td><td>FB15K237</td><td>WN18</td><td>WN18RR</td></tr><tr><td><br />TransE</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>7</mn><mn>6</mn><mo>.</mo><mn>2</mn><mn>0</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td>92.53</td><td>77.40</td></tr><tr><td><br />TransE-ANG</td><td>75.21</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>9</mn><mn>7</mn><mo>.</mo><mn>9</mn><mn>0</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>8</mn><mn>4</mn><mo>.</mo><mn>8</mn><mn>8</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td></tr><tr><td><br />TransH</td><td>75.63</td><td>81.00</td><td>68.09</td></tr><tr><td><br />TransH-ANG</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>7</mn><mn>6</mn><mo>.</mo><mn>2</mn><mn>4</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>9</mn><mn>7</mn><mo>.</mo><mn>8</mn><mn>3</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>8</mn><mn>5</mn><mo>.</mo><mn>5</mn><mn>5</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td></tr><tr><td><br />TransD</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>7</mn><mn>6</mn><mo>.</mo><mn>0</mn><mn>7</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td>96.60</td><td>76.14</td></tr><tr><td><br />TransD-ANG</td><td>75.88</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>9</mn><mn>7</mn><mo>.</mo><mn>9</mn><mn>4</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>8</mn><mn>5</mn><mo>.</mo><mn>1</mn><mn>6</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td></tr><tr><td><br />ComplEx</td><td>73.07</td><td>96.80</td><td>77.35</td></tr><tr><td><br />ComplEx-ANG</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>7</mn><mn>9</mn><mo>.</mo><mn>7</mn><mn>3</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>9</mn><mn>7</mn><mo>.</mo><mn>1</mn><mn>3</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>8</mn><mn>2</mn><mo>.</mo><mn>7</mn><mn>9</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td></tr><tr><td><br />DistMult</td><td>73.67</td><td>96.82</td><td>78.56</td></tr><tr><td><br />DistMult-ANG</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>7</mn><mn>8</mn><mo>.</mo><mn>9</mn><mn>0</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>9</mn><mn>6</mn><mo>.</mo><mn>8</mn><mn>8</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mn>8</mn><mn>3</mn><mo>.</mo><mn>3</mn><mn>3</mn></mrow><mo stretchy="true">¯</mo></munder></mrow></math></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="146" name="146" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="147">本文提出了一种用于知识表示学习的对抗式负样本生成器(<i>ANG</i>),<i>ANG</i>可以在传统知识表示学习模型训练过程中提供高质量的负样本,避免了负采样方法导致的模型快速收敛、模型难以优化的问题,同时实现了对抗式训练框架用于训练传统知识表示学习模型,通过生成器与目标模型的对抗式训练提升模型性能。由于训练框架与模型无关,本文提出的生成器与训练框架也可扩展用于其他知识表示学习模型的训练。在链接预测和三元组分类任务上评估了本文模型,实验结果表明通过在生成负样本时使用正样本提供的信息可以有效提高负样本生成的质量,为模型优化提供更好的负样本数据。</p>
                </div>
                <div class="p1">
                    <p id="148">目前本文方法在链接预测<i>Hits</i>@10评价标准上弱于同类生成式算法,主要由于生成器采样空间较大,采样效率较低,为提高这一指标可以考虑压缩生成器实体采样空间,或者使用深度强化学习中经验池的方法对生成空间进行多次采样以加速优化生成器实体概率分布。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="186">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000027180&amp;v=MzE0NTdycVFUTW53WmVadEZpbmxVcjNJSUY4ZGFSVT1OaWZJWTdLN0h0ak5yNDlGWk9rSURYUTVvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> MILLER G A.WordNet:a lexical database for English [J].Communications of the ACM,1995,38(11):39-41.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DBpedia: ANucleus for a Web of Open Data">

                                <b>[2]</b> AUER S,BIZER C,KOBILAROV G,et al.DBpedia:a nucleus for a Web of open data [C]// Proceedings of the 2007 International Semantic Web Conference,LNCS 4825.Berlin:Springer,2007:722-735.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Freebase:a collaboratively created graph database for structuring human knowledge">

                                <b>[3]</b> BOLLACKER K,EVANS C,PARITOSH P,et al.Freebase:a collaboratively created graph database for structuring human knowledge [C]// Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data.New York:ACM,2008:1247-1250.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Translating embeddings for modeling multi-relational data">

                                <b>[4]</b> BORDES A,USUNIER N,GARCIA-DURÁN A,et al.Translating embeddings for modeling multi-relational data [EB/OL].[2019- 01- 06].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.6132&amp;rep=rep1&amp;type=pdf.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding by translating on hyperplanes">

                                <b>[5]</b> WANG Z,ZHANG J,FENG J,et al.Knowledge graph embedding by translating on hyperplanes [C]// AAAI '14:Proceedings of the 28th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2014:1112-1119.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding via dynamic mapping matrix">

                                <b>[6]</b> JI G,HE S,XU L,et al.Knowledge graph embedding via dynamic mapping matrix [C]// Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg,PA:Association for Computational Linguistics,2015,1:687-696.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Embedding entities and relations for learning and inference in knowledge bases">

                                <b>[7]</b> YANG B,YIH W,HE X,et al.Embedding entities and relations for learning and inference in knowledge bases [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1412.6575.pdf.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Complex embeddings for simple link prediction">

                                <b>[8]</b> TROUILLON T,WELBL J,RIEDEL S,et al.Complex embeddings for simple link prediction [EB/OL].[2019- 01- 06].https://arxiv.org/pdf/1606.06357.pdf.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial networks">

                                <b>[9]</b> GOODFELLOW I,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets [C]// NIPS '14:Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014,2:2672-2680.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=KBGAN:adversarial learning for knowledge graph embeddings">

                                <b>[10]</b> CAI L,WANG W Y.KBGAN:adversarial learning for knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1711.04071.pdf.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incorporating GAN for negative sampling in knowledge representation learning">

                                <b>[11]</b> WANG P,LI S,PAN R.Incorporating GAN for negative sampling in knowledge representation learning [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1809.11017.pdf.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Observed versus latent features for knowledge base and text inference">

                                <b>[12]</b> TOUTANOVA K,CHEN D.Observed versus latent features for knowledge base and text inference [EB/OL].[2019- 01- 08].http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=332E017631F63128927CF06ABF216792 doi=10.1.1.709.9449&amp;rep=rep1&amp;type=pdf.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional 2D knowledge graph embeddings">

                                <b>[13]</b> DETTMERS T,MINERVINI P,STENETORP P,et al.Convolutional 2D knowledge graph embeddings [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1707.01476.pdf.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning entity and relation embeddings for knowledge graph completion">

                                <b>[14]</b> LIN Y,LIU Z,SUN M,et al.Learning entity and relation embeddings for knowledge graph completion [C]// AAAI '15:Proceedings of the 29th AAAI Conference on Artificial Intelligence.Menlo Park,CA:AAAI Press,2015:2181-2187.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Three-Way Model for Collective Learning on Multi-Relational Data">

                                <b>[15]</b> NICKEL M,TRESP V,KRIEGEL H P.A three-way model for collective learning on multi-relational data [C]// ICML '11:Proceedings of the 28th International Conference on International Conference on Machine Learning.Bellevue,Washington:Omnipress,2011:809-816.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Holographic embeddings of knowledge graphs">

                                <b>[16]</b> NICKEL M,ROSASCO L,POGGIO T.Holographic embeddings of knowledge graphs [EB/OL].[2018- 12- 25].https://arxiv.org/pdf/1510.04935v2.pdf.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reasoning with neural tensor networks for knowledge base completion">

                                <b>[17]</b> SOCHER R,CHEN D,MANNING C D,et al.Reasoning with neural tensor networks for knowledge base completion [C]//NIPS '13:Proceedings of the 26th International Conference on Neural Information Processing Systems.Lake Tahoe,Nevada:Curran Associates,2013:926-934.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial contrastive estimation">

                                <b>[18]</b> BOSE A J,LING H,CAO Y.Adversarial contrastive estimation [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1805.03642.pdf.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SeqGAN:sequence generative adversarial nets with policy gradient">

                                <b>[19]</b> YU L,ZHANG W,WANG J,et al.SeqGAN:sequence generative adversarial nets with policy gradient [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1609.05473.pdf.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=IRGAN:A minimax game for unifying generative and discriminative information retrieval models">

                                <b>[20]</b> WANG J,YU L,ZHANG W,et al.IRGAN:a minimax game for unifying generative and discriminative information retrieval models [C]// Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval.New York:ACM,2017:515-524.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MaskGAN:better text generation via filling in the_">

                                <b>[21]</b> FEDUS W,GOODFELLOW I,DAI A M.MaskGAN:better text generation via filling in the_ [EB/OL].[2019- 01- 09].http://export.arxiv.org/pdf/1801.07736.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reinforcement learning:an introduction">

                                <b>[22]</b> SUTTON R S,BARTO A G.Reinforcement learning:an introduction [EB/OL].[2019- 01- 08].http://users.umiacs.umd.edu/～hal/courses/2016F_RL/RL9.pdf.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sequence to sequence learning with neural networks">

                                <b>[23]</b> SUTSKEVER I,VINYALS O,LE Q V.Sequence to sequence learning with neural networks [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1409.3215.pdf.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Phrase Representations Using RNN Encoder-decoder for Statistical Machine Translation">

                                <b>[24]</b> CHO K,van MERRIENBOER B,GULCEHRE C,et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation [EB/OL].[2019- 01- 08].https://arxiv.org/pdf/1406.1078.pdf.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Policy gradient methods for reinforcement learning with function approximation">

                                <b>[25]</b> SUTTON R S,MCALLESTER D A,SINGH S P,et al.Policy gradient methods for reinforcement learning with function approximation [EB/OL].[2019- 01- 09].https://www.docin.com/p-1195188340.html.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from delayed rewards">

                                <b>[26]</b> WATKINS C J C H.Learning from delayed rewards [D].Cambridge:King's College,1989.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A Method for Stochastic Optimization[C/OL]">

                                <b>[27]</b> KINGMA D P,BA J L.Adam:a method for stochastic optimization [EB/OL].[2019- 01- 09].https://arxiv.org/pdf/1412.6980.pdf.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive subgradient methods for online learning and stochastic optimization">

                                <b>[28]</b> DUCHI J,HAZAN E,SINGER Y.Adaptive subgradient methods for online learning and stochastic optimization [J].Journal of Machine Learning Research,2011,12:2121-2159.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OpenKE:an open toolkit for knowledge embedding">

                                <b>[29]</b> HAN X,CAO S,LV X,et al.OpenKE:an open toolkit for knowledge embedding [EB/OL].[2019- 01- 09].http://nlp.csai.tsinghua.edu.cn/～lzy/publications/emnlp2018_openke.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909002&amp;v=MTY3MTh0R0ZyQ1VSN3FmWnVac0Z5amtXcnpQTHo3QmQ3RzRIOWpNcG85RlpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
