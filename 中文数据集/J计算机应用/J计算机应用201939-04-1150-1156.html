<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779409190000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904035%26RESULT%3d1%26SIGN%3dSeVBGYJOnKCY8Ocu%252b83ZyzFARQQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904035&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904035&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904035&amp;v=MzE0MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTC9QTHo3QmQ3RzRIOWpNcTQ5R1lZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="1 问题分析 ">1 问题分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="2 本文算法 ">2 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="2.1 &lt;b&gt;目标模型的优化&lt;/b&gt;">2.1 <b>目标模型的优化</b></a></li>
                                                <li><a href="#79" data-title="2.2 &lt;b&gt;目标表观描述与尺度自适应&lt;/b&gt;">2.2 <b>目标表观描述与尺度自适应</b></a></li>
                                                <li><a href="#84" data-title="2.3 &lt;b&gt;模型更新策略&lt;/b&gt;">2.3 <b>模型更新策略</b></a></li>
                                                <li><a href="#106" data-title="2.4 &lt;b&gt;时间复杂度分析&lt;/b&gt;">2.4 <b>时间复杂度分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="3.1 &lt;b&gt;定量评价&lt;/b&gt;">3.1 <b>定量评价</b></a></li>
                                                <li><a href="#119" data-title="3.2 &lt;b&gt;定性评价&lt;/b&gt;">3.2 <b>定性评价</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="图2 本文算法整体框架">图2 本文算法整体框架</a></li>
                                                <li><a href="#51" data-title="图1 余弦窗效果示意图">图1 余弦窗效果示意图</a></li>
                                                <li><a href="#75" data-title="图3 部分特征通道下上下文图像块及其对偶值的点乘结果示意图">图3 部分特征通道下上下文图像块及其对偶值的点乘结果示意图</a></li>
                                                <li><a href="#78" data-title="图4 某一时刻是否利用空间结构信息得到的目标位置响应图">图4 某一时刻是否利用空间结构信息得到的目标位置响应图</a></li>
                                                <li><a href="#98" data-title="图5 不同时刻目标表观变化情况">图5 不同时刻目标表观变化情况</a></li>
                                                <li><a href="#122" data-title="图6 不同时刻不同算法在各测试序列中的中心位置误差值">图6 不同时刻不同算法在各测试序列中的中心位置误差值</a></li>
                                                <li><a href="#123" data-title="图7 不同时刻不同算法在各测试序列中的边界框重叠率">图7 不同时刻不同算法在各测试序列中的边界框重叠率</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同算法在各测试序列上的中心位置误差与边界框重叠率平均值&lt;/b&gt;"><b>表</b>1 <b>不同算法在各测试序列上的中心位置误差与边界框重叠率平均值</b></a></li>
                                                <li><a href="#128" data-title="图8 典型测试序列上部分时刻不同算法的跟踪效果">图8 典型测试序列上部分时刻不同算法的跟踪效果</a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同算法在各测试序列中的整体定量评价结果&lt;/b&gt;"><b>表</b>2 <b>不同算法在各测试序列中的整体定量评价结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="160">


                                    <a id="bibliography_1" title="WU Y, LIM J, YANG M H.Object tracking benchmark[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object tracking benchmark">
                                        <b>[1]</b>
                                        WU Y, LIM J, YANG M H.Object tracking benchmark[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_2" title="KRISTAN M, LEONARDIS A, MATAS J, et al.The visual object tracking VOT2016 challenge results[C]//ICCV 2016:Proceedings of the 2016 IEEE International Conference on Computer Vision Workshops.Washington, DC:IEEE Computer Society, 2016:98-111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Visual Object Tracking VOT2016Challenge Results">
                                        <b>[2]</b>
                                        KRISTAN M, LEONARDIS A, MATAS J, et al.The visual object tracking VOT2016 challenge results[C]//ICCV 2016:Proceedings of the 2016 IEEE International Conference on Computer Vision Workshops.Washington, DC:IEEE Computer Society, 2016:98-111.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_3" title="胡秀华.复杂场景中目标跟踪算法研究[D].西安:西北工业大学, 2017:19-28. (HU X H.Research on object tracking algorithm in complex environment[D].Xi&#39;an:Northwestern Polytechnical University, 2017:19-28.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018792656.nh&amp;v=MTY0MDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTC9QVkYyNkZyU3hITmZKcVpFYlBJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        胡秀华.复杂场景中目标跟踪算法研究[D].西安:西北工业大学, 2017:19-28. (HU X H.Research on object tracking algorithm in complex environment[D].Xi&#39;an:Northwestern Polytechnical University, 2017:19-28.) 
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_4" title="CHEN Z, HONG Z, TAO D.An experimental survey on correlation filter-based tracking[EB/OL].[2018-05-26].https://arxiv.org/pdf/1509.05520." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An experimental survey on correlation filter-based tracking">
                                        <b>[4]</b>
                                        CHEN Z, HONG Z, TAO D.An experimental survey on correlation filter-based tracking[EB/OL].[2018-05-26].https://arxiv.org/pdf/1509.05520.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_5" title="HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 2012 European Conference on Computer Vision.Berlin:Springer, 2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">
                                        <b>[5]</b>
                                        HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 2012 European Conference on Computer Vision.Berlin:Springer, 2012:702-715.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_6" title="HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">
                                        <b>[6]</b>
                                        HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_7" title="ZHANG K H, ZHANG L, LIU Q S, et al.Fast visual tracking via dense spatio-temporal context learning[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:127-141." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast tracking via dense spatio-temporal context learning">
                                        <b>[7]</b>
                                        ZHANG K H, ZHANG L, LIU Q S, et al.Fast visual tracking via dense spatio-temporal context learning[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:127-141.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_8" title="LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:254-265." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">
                                        <b>[8]</b>
                                        LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:254-265.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_9" title="DANELLJAN M, HAGER G, KHAN F, et al.Accurate scale estimation for robust visual tracking[C]//CVPR 2014:Proceedings of the 2014 Proceedings of the British Machine Vision Conference.Nottingham:British Machine Vision Association Press, 2014:65.1-65.11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">
                                        <b>[9]</b>
                                        DANELLJAN M, HAGER G, KHAN F, et al.Accurate scale estimation for robust visual tracking[C]//CVPR 2014:Proceedings of the 2014 Proceedings of the British Machine Vision Conference.Nottingham:British Machine Vision Association Press, 2014:65.1-65.11.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_10" title="钱堂慧, 罗志清, 李果家, 等.核相关滤波跟踪算法的尺度自适应改进[J].计算机应用, 2017, 37 (3) :811-816. (QIAN TH, LUO Z Q, LI G J, et al.Scale adaptive improvement of kernel correlation filter tracking algorithm[J].Journal of Computer Applications, 2017, 37 (3) :811-816.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201703036&amp;v=MTI0OTZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUwvUEx6N0JkN0c0SDliTXJJOUc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        钱堂慧, 罗志清, 李果家, 等.核相关滤波跟踪算法的尺度自适应改进[J].计算机应用, 2017, 37 (3) :811-816. (QIAN TH, LUO Z Q, LI G J, et al.Scale adaptive improvement of kernel correlation filter tracking algorithm[J].Journal of Computer Applications, 2017, 37 (3) :811-816.) 
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_11" title="胡秀华, 郭雷, 李晖晖.一种利用物体性检测的目标跟踪算法[J].西安电子科技大学学报 (自然科学版) , 2017, 44 (4) :86-94. (HU X H, GUO L, LI H H.An object tracking algorithm based on objectness detection[J].Journal of Xidian University, 2017, 44 (4) :86-94.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201704016&amp;v=MzE4MzJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTC9QUFNuQWFyRzRIOWJNcTQ5RVlvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        胡秀华, 郭雷, 李晖晖.一种利用物体性检测的目标跟踪算法[J].西安电子科技大学学报 (自然科学版) , 2017, 44 (4) :86-94. (HU X H, GUO L, LI H H.An object tracking algorithm based on objectness detection[J].Journal of Xidian University, 2017, 44 (4) :86-94.) 
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_12" title="DANELLJAN M, HAGER G, KHAN F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4310-4318." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning spatially regularized correlation filters for visual tracking">
                                        <b>[12]</b>
                                        DANELLJAN M, HAGER G, KHAN F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4310-4318.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_13" title="MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//CVPR 2017:Proceedings of the 2017 IEEEInternational Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:1387-1395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">
                                        <b>[13]</b>
                                        MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//CVPR 2017:Proceedings of the 2017 IEEEInternational Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:1387-1395.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_14" title="BIBI A, MUELLER M, GHANEM B.Target response adaptation for correlation filter tracking[C]//ECCV 2016:Proceedings of the2016 European Conference on Computer Vision.Berlin:Springer, 2016:419-433." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Target Response Adaptation for Correlation Filter Tracking">
                                        <b>[14]</b>
                                        BIBI A, MUELLER M, GHANEM B.Target response adaptation for correlation filter tracking[C]//ECCV 2016:Proceedings of the2016 European Conference on Computer Vision.Berlin:Springer, 2016:419-433.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_15" title="LUKEZIC A, VOJIR T, ZAJC L C, et al.Discriminative correlation filter with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative Correlation Filter Tracker with Channel and Spatial Reliability">
                                        <b>[15]</b>
                                        LUKEZIC A, VOJIR T, ZAJC L C, et al.Discriminative correlation filter with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_16" title="RIFKIN R, YEO G, POGGIO T.Regularized least squares classification[EB/OL].[2018-07-26].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.3463&amp;amp;rep=rep1&amp;amp;type=pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regularized least squares classification">
                                        <b>[16]</b>
                                        RIFKIN R, YEO G, POGGIO T.Regularized least squares classification[EB/OL].[2018-07-26].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.3463&amp;amp;rep=rep1&amp;amp;type=pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-07 14:22</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1150-1156 DOI:10.11772/j.issn.1001-9081.2018091884            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>利用空间结构信息的相关滤波目标跟踪算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E7%A7%80%E5%8D%8E&amp;code=38494597&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡秀华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E9%95%BF%E5%85%83&amp;code=11583081&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王长元</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%82%96%E9%94%8B&amp;code=10931532&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">肖锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BA%9A%E6%96%87&amp;code=15564452&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王亚文</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0201951&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安工业大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决在典型相关滤波框架模型中样本信息判别性低引起的跟踪漂移问题, 提出一种利用空间结构信息的相关滤波目标跟踪算法。首先, 引入空间上下文结构约束进行模型构建的优化, 同时利用正则化最小二乘与矩阵分解思想实现闭式求解;然后, 采用互补特征用于目标表观描述, 并利用尺度因子池处理目标尺度变化情况;最后, 借助目标运动连续性进行目标受遮挡影响情况的判定, 设计相应的模型更新策略。实验结果表明, 在多种典型测试场景中所提算法的准确率较传统算法提高了17.63%, 成功率提高了24.93%, 可以取得较为鲁棒的跟踪效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相关滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA%E9%97%B4%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空间结构信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">模型优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">更新策略;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *胡秀华 (1988—) , 女, 山东菏泽人, 讲师, 博士, 主要研究方向:计算机视觉、模式识别;电子邮箱huxhxatu@163.com;
                                </span>
                                <span>
                                    王长元 (1963—) , 男, 陕西宝鸡人, 教授, 博士, 主要研究方向:图像处理、模式识别、视线追踪;;
                                </span>
                                <span>
                                    肖锋 (1976—) , 男, 河南滑县人, 教授, 博士, 主要研究方向:模式识别、场景理解、智能信息处理;;
                                </span>
                                <span>
                                    王亚文 (1981—) , 男, 陕西宝鸡人, 讲师, 硕士, 主要研究方向:计算机视觉、模式识别。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61572392);</span>
                                <span>陕西省自然科学基础研究计划项目 (2017JC2-08);</span>
                                <span>西安工业大学校长基金资助项目 (XAGDXJJ17017);</span>
                    </p>
            </div>
                    <h1><b>Object tracking algorithm based on correlation filter with spatial structure information</b></h1>
                    <h2>
                    <span>HU Xiuhua</span>
                    <span>WANG Changyuan</span>
                    <span>XIAO Feng</span>
                    <span>WANG Yawen</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Engineering, Xi'an Technological University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the tracking drift problem caused by the low discriminability of sample information in typical correlation filtering framework, a correlation filter based object tracking algorithm with spatial structure information was proposed. Firstly, the spatial context structure constraint was introduced to optimize the model construction, meanwhile, the regularized least square and matrix decomposition idea were exploited to achieve the closed solution. Then, the complementary features were used for the target apparent description, and the scale factor pool was utilized to deal with target scale changing. Finally, according to the occlusion influence of target judged by motion continuity, the corresponding model updating strategy was designed. Experimental results demonstrate that compared with the traditional algorithm, the precision of the proposed algorithm is increased by 17.63%, and the success rate is improved by 24.93% in various typical test scenarios, achieving more robust tracking effect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=correlation%20filter&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">correlation filter;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial%20structure%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial structure information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=model%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">model optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=updating%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">updating strategy;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HU Xiuhua, born in 1988, Ph. D. , lecturer. Her research interests include computer vision, pattern recognition.;
                                </span>
                                <span>
                                    WANG Changyuan, born in 1963, Ph. D. , professor. His research interests include image processing, pattern recognition, sight tracking.;
                                </span>
                                <span>
                                    XIAO Feng, born in 1976, Ph. D. , professor. His research interests include pattern recognition, scene understanding, intelligent information processing.;
                                </span>
                                <span>
                                    WANG Yawen, born in 1981, M. S. , lecturer. His research interests include computer vision, pattern recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-10</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61572392);</span>
                                <span>the Natural Science Basis Research Plan of Shaanxi Province (2017JC2-08);</span>
                                <span>the Xi&#39;an University of Technology President&#39;s Fund Project (XAGDXJJ17017);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="36">作为计算机视觉领域的重要研究方向, 目标跟踪技术得到了越来越多的关注, 并广泛应用在视频监控、智能导航、远程医疗等诸多方面。尽管目前已取得多类别框架的研究成果, 但由于受到自身形变及运动变化、外界光照及相似物体干扰等复杂因素影响, 目标的表观模型持续发生变化, 研究能够有效自适应多种复杂条件的目标跟踪算法仍然是一项棘手且重要的任务<citation id="192" type="reference"><link href="160" rel="bibliography" /><link href="162" rel="bibliography" /><link href="164" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">相关滤波理论将输入特征回归为目标高斯分布来训练滤波器, 并通过分类器置信图响应值进行目标位置估计, 由于采用密集采样并将空域中的卷积操作变换为了频域中元素的点乘运算, 使得其在跟踪性能及计算效率方面具有诸多优势, 得到了研究学者越来越多的重视<citation id="193" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。Henriques等<citation id="194" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>指出通过循环位移操作可以近似得到样本采样窗口位移, 并利用二维分块循环矩阵表示样本目标周围的循环位移采样, 进而借助傅里叶变换实现高效学习与检测。在此基础上, Henriques等<citation id="195" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>又分析了模型数据与核矩阵的循环特性, 指出循环矩阵的对角化可以借助离散傅里叶变换进行高时效的处理, 并基于线性回归与核脊回归模型分别给出了线性相关与对偶相关的滤波器。Zhang等<citation id="196" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>基于贝叶斯框架建立了目标与其周围区域的时空上下文关系, 将目标跟踪问题转化为了分类器置信图的求解, 通过最大化目标位置似然函数求得最佳目标状态估计, 采用的傅里叶变换方法保证了算法的计算实时性。基于相关滤波框架, Li等<citation id="197" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>给出了一种尺度自适应跟踪策略, 利用尺度池的思想解决了典型核相关滤波跟踪算法中目标图像块搜索窗尺寸固定的问题, 同时, 采用的特征融合方法进一步增强了算法性能。通过学习状态转移和尺度估计两个相对独立的滤波器, Danelljan等<citation id="198" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>给出了尺度空间特征金字塔描述学习的判别式相关滤波模型, 能够有效用于尺度变化问题。钱堂慧等<citation id="199" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>通过采集多尺度图像训练得到多尺度分类器, 实现了目标最佳尺度检测, 一定程度上解决了基于检测的核相关滤波跟踪算法不能有效处理目标尺度变化的问题。胡秀华等<citation id="200" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>利用物体建议边界框检测原理对核相关滤波器求得的目标初步预测状态进行精处理, 同时设计了遮挡情况判定准则, 能够有效用于目标表观信息判别性低的场景, 为后续研究提供了有益思路。</p>
                </div>
                <div class="p1">
                    <p id="38">但是值得注意的是, 典型的相关滤波跟踪算法假设目标所处环境背景单一或均匀变化且运动状态变化缓慢, 当实际应用中视频序列受多种复杂因素干扰影响且目标快速运动或严重形变时, 这种假设往往不再成立, 典型相关滤波算法的跟踪效果也受到了一定程度的影响。针对相关滤波模型存在的典型边界受限问题, Danelljan等<citation id="201" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>通过引入空间正则化项对相关滤波器系数空间进行位置补偿, 在更大范围内采样得到强判别性的负样本, 同时给出了基于高斯-塞德尔方法的优化策略, 为后续研究提供了有益思路。Mueller等<citation id="202" type="reference"><link href="184" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种新的相关滤波框架, 通过增加目标块的上下左右四部分图像块进行模型约束, 增加了更多的背景信息, 可以有效处理旋转等变化, 而且新的模型框架具有闭环解, 计算效率较高。Bibi等<citation id="203" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>旨在基于精确的变换检测得分解决滤波优化与目标响应问题, 给出的模型框架侧重于处理边界影响, 更适合处理快速运动与目标遮挡情况。Lukezic等<citation id="204" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>将通道可靠性与空域可靠性引入典型判别式相关滤波框架, 并利用通道可靠性得分作为特征加权系数实现目标定位, 可以有效扩大搜索区域, 改善非矩形目标跟踪效果。</p>
                </div>
                <div class="p1">
                    <p id="39">因此, 整体看来, 相关滤波器的循环采样过程容易受图像边界限制影响, 且候选目标搜索范围大多局限在小的局部区域内, 这使得相关典型算法在目标存在快速运动或外界遮挡干扰影响时出现跟踪漂移。现有研究成果虽然在一定程度上考虑了边界受限, 但在空间结构信息的利用、样本选择与模型构建等方面还有待深入研究。</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文算法整体框架" src="Detail/GetImg?filename=images/JSJY201904035_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文算法整体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Framework of the proposed algorithm</p>

                </div>
                <h3 id="41" name="41" class="anchor-tag">1 问题分析</h3>
                <div class="p1">
                    <p id="42">在典型相关滤波算法中, 对于候选样本图像块<b><i>z</i></b>及其对应的循环采样偏移图像块, 相应的检测响应置信图<b><i>f</i></b> (<b><i>z</i></b>) 可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="43"><b><i>f</i></b> (<b><i>z</i></b>) =<i>F</i><sup>-1</sup> (<i>F</i> (<b><i>k</i></b><sup><b><i>xz</i></b></sup>) ⊙<i>F</i> (<i>α</i>) )      (1) </p>
                </div>
                <div class="p1">
                    <p id="44">其中:<mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo></mrow><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">k</mi><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup></mrow></msup><mo stretchy="false">) </mo><mo>+</mo><mi>λ</mi></mrow></mfrac></mrow></math></mathml>;<i>α</i>为系数矩阵, <i>α</i><sub><i>m</i>, <i>n</i></sub>为系数矩阵中的第 (<i>m</i>, <i>n</i>) 个元素; <b><i>y</i></b>为样本标签矩阵, <i>y</i><sub><i>m</i>, <i>n</i></sub>为样本标签矩阵中的第 (<i>m</i>, <i>n</i>) 个元素;<i>λ</i>为正则化参数;<i>F</i> (·) 表示离散傅里叶转换操作;<b><i>k</i></b> (·) 为核函数;<b><i>x</i></b>′表征图像块<b><i>x</i></b>或候选样本图像块的循环偏移图像块。 <b><i>f</i></b> (<b><i>z</i></b>) 中的最大值对应的样本块记为目标最佳预测位置。</p>
                </div>
                <div class="p1">
                    <p id="46">考虑到傅里叶变换的周期性, 为避免图像边缘的不连续性限制致使变换过程产生噪声干扰, 可以对原始目标图像块<b><i>x</i></b><mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>进行余弦窗滤波处理, 即</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>w</mtext></mrow></msubsup><mo>-</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo stretchy="false">) </mo><mrow><mi>sin</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mtext>π</mtext><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo stretchy="false">) </mo><mrow><mi>sin</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mtext>π</mtext><mi>n</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">其中:<i>m</i><sub>0</sub>=0, 1, …, <i>M</i><sub>0</sub>-1;<i>n</i><sub>0</sub>=0, 1, …, <i>N</i><sub>0</sub>-1;<i>M</i><sub>0</sub>×<i>N</i><sub>0</sub>为图像块大小。</p>
                </div>
                <div class="p1">
                    <p id="50">余弦窗滤波效果如图1所示。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 余弦窗效果示意图" src="Detail/GetImg?filename=images/JSJY201904035_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 余弦窗效果示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Schematic diagram of cosine window effect</p>

                </div>
                <div class="p1">
                    <p id="52">典型相关滤波算法在样本目标图像块循环移位至图像边缘附近时易受到边界效应影响, 由此产出的错误样本会减弱分类器的判别性能, 采用的余弦窗处理虽然在一定程度上缓解了边界影响, 但是余弦窗将图像块的边缘区域像素全部变为零, 过滤掉了大量的需要学习的背景信息, 降低了分类器的判别力。现有研究方法中采用了较大检测区域的图像块与较小作用域的滤波器来提高真实样本的比例, 虽然可以提升快速运动目标的跟踪鲁棒性, 但却大幅削弱了相关滤波类别算法的实时性优势。本文拟利用空间结构约束进行目标模型优化, 可在不降低计算有效性的同时提升样本信息的多样性, 并通过模型学习有效降低背景干扰信息的影响。</p>
                </div>
                <h3 id="53" name="53" class="anchor-tag">2 本文算法</h3>
                <div class="p1">
                    <p id="54">针对典型相关滤波算法模型容易受到图像边界范围限制的问题, 考虑到依靠余弦窗滤波处理虽然可以缓解边界受限但却降低了背景信息的利用, 本文引入空间结构约束进行模型构建的优化, 以提高样本信息的多样性与判别性;借助互补特征提高目标表观描述的有效性, 并利用尺度因子池处理目标尺度变化情况;同时, 通过目标受遮挡影响情况的判定, 设计模型更新策略, 用于改善目标在复杂场景中的跟踪性能。所提算法整体框架如图2所示。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">2.1 <b>目标模型的优化</b></h4>
                <div class="p1">
                    <p id="56">对于典型的核相关滤波跟踪算法, 分类器的训练过程可以看作岭回归问题, 即</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">q</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><mo>-</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">q</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">其中:<b><i>x</i></b><sub><i>m</i>, <i>n</i></sub>为通过循环偏移图像块<b><i>x</i></b>得到训练样本; <i>y</i><sub><i>m</i>, <i>n</i></sub>为依据偏移距离由高斯函数求得的对应样本标签, <i>y</i><sub><i>m</i>, <i>n</i></sub>∈[0, 1] (<i>m</i>=0, 1, …, <i>M</i>-1, <i>n</i>=0, 1, …, <i>N</i>-1, <i>M</i>×<i>N</i>表征图像块的大小) ;<i>λ</i>为正则化参数, <i>λ</i>≥0;<b><i>q</i></b>为分类器参数矩阵, <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">q</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></munder><mi>α</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mi>φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>;<i>φ</i> (·) 代表针对希尔伯特空间的映射;<i>α</i><sub><i>m</i>, <i>n</i></sub>为相关性系数。</p>
                </div>
                <div class="p1">
                    <p id="60">通过引入核函数, 在对偶空间, 式 (3) 中的模型可描述为:</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mo>〈</mo><mi mathvariant="bold-italic">q</mi><mo>, </mo><mi>φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><mo>〉</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><msup><mi>m</mi><mo>′</mo></msup><mo>, </mo><msup><mi>n</mi><mo>′</mo></msup></mrow></munder><mi>α</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mi mathvariant="bold-italic">k</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><msup><mi>m</mi><mo>′</mo></msup><mo>, </mo><msup><mi>n</mi><mo>′</mo></msup></mrow></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">其中:〈·〉表示内积操作;<b><i>k</i></b> (·) 为核函数;<i>m</i>′=0, 1, …, <i>M</i>-1;<i>n</i>′=0, 1, …, <i>N</i>-1。</p>
                </div>
                <div class="p1">
                    <p id="63">针对式 (3) 容易受到图像边界限制影响的问题, 考虑引入空间结构约束进行模型优化, 具体表示为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">q</mi></munder><mspace width="0.25em" /><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></munder><mrow><mrow><mo>|</mo><mrow><mo>〈</mo><mi mathvariant="bold-italic">q</mi><mo>, </mo><mi>φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><mo>〉</mo><mo>-</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">q</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mi>λ</mi><msub><mrow></mrow><mi>c</mi></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mi>c</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>e</mi><mo>, </mo><mspace width="0.25em" /><mi>f</mi></mrow></munder><mrow><mrow><mo>|</mo><mrow><mo>〈</mo><mi mathvariant="bold-italic">q</mi><mo>, </mo><mi>φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>e</mi><mo>, </mo><mspace width="0.25em" /><mi>f</mi></mrow></msub><mo stretchy="false">) </mo><mo>〉</mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>λ</i><sub><i>c</i></sub>为约束项参数, <i>c</i> (<i>c</i>=1, 2, …, <i>C</i>, <i>C</i>为在空间结构中选取的上下文图像块个数) 表示用于约束目标模型的某块上下文图像<b><i>x</i></b><sub><i>e</i>, <i>f</i></sub> (<i>e</i>, <i>f</i>∈{1, 2, …, <i>C</i>}) 。</p>
                </div>
                <div class="p1">
                    <p id="66">借鉴文献<citation id="205" type="reference">[<a class="sup">13</a>]</citation>的求解思路, 对于单通道特征, 依据正则化最小二乘理论求解思想<citation id="206" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 在对偶域可以得到式 (5) 中的系数矩阵表达式为:</p>
                </div>
                <div class="area_img" id="159">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201904035_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="69">其中:<i>Λ</i><sub>00</sub>=<i>F</i> (<b><i>k</i></b><sup><b><i>xx</i></b></sup>) ; <i>Λ</i><sub><i>ee</i></sub>=<i>λ</i><sub><i>c</i></sub><i>F</i> (<b><i>k</i></b><sup><b><i>x</i></b><sub><i>e</i></sub><b><i>x</i></b><sub><i>e</i></sub></sup>) +<i>λ</i>;<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Λ</mi><msub><mrow></mrow><mrow><mi>e</mi><mi mathvariant="bold-italic">f</mi></mrow></msub><mo>=</mo><msqrt><mrow><mi>λ</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msqrt><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">k</mi><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>e</mi></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi mathvariant="bold-italic">f</mi></msub></mrow></msup><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="71">记目标图像块循环移位产生的系数矩阵记为<b><i>F</i></b> (<i>α</i><sub>0</sub>) , 空间结构约束图像块产生的系数矩阵记为<i>F</i> (<i>α</i><sub><i>c</i></sub>) , 可得候选样本图像块<b><i>z</i></b>相应的检测响应置信图<b><i>f</i></b> (<b><i>z</i></b>) 为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">) </mo><mo>=</mo><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">k</mi><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">x</mi></mrow></msup><mo stretchy="false">) </mo><mo>⊙</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mo>+</mo><msqrt><mrow><mi>λ</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msqrt><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mi>F</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">k</mi><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msup><mo stretchy="false">) </mo><mo>⊙</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">对于多通道特征, 需要进一步利用多特征的相互独立性及共轭梯度下降方法进行求解。</p>
                </div>
                <div class="p1">
                    <p id="74">由式 (5) 可看出, 上下文图像块的选择对模型优化结果起着重要影响, 为充分利用空间结构信息, 本文拟在全局空间中选取先前帧数中被判定为干扰背景所对应的图像块及其周围区域采样得到的与先前帧跟踪结果不重叠的图像块作为上下文图像块, 可以在保证计算效率的同时增强样本的多样性和判别性。通过求解式 (5) 可以得到优化的相关滤波器训练模型, 进而用于当前帧候选图像块最佳位置预测。部分特征通道下上下文图像块及其对偶值的点乘结果示意效果如图3所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 部分特征通道下上下文图像块及其对偶值的点乘结果示意图" src="Detail/GetImg?filename=images/JSJY201904035_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 部分特征通道下上下文图像块及其对偶值的点乘结果示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Schematic diagram of dot product of context image blocks and their dual values under partial feature channels</p>

                </div>
                <div class="p1">
                    <p id="76">是否利用空间结构信息进行分类器模型优化所得到的目标响应效果如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="77">图4 (a) 给出了第39帧目标位置框信息。从图4 (b) 、 (c) 可看出:在外界物体遮挡干扰情况下, 考虑空间结构信息的目标模型得到的最大响应值受周围干扰影响相对较小, 在最佳目标状态确定时能够更好地区分目标与背景。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 某一时刻是否利用空间结构信息得到的目标位置响应图" src="Detail/GetImg?filename=images/JSJY201904035_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 某一时刻是否利用空间结构信息得到的目标位置响应图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Target location response diagram with and without spatial structure information at one moment</p>

                </div>
                <h4 class="anchor-tag" id="79" name="79">2.2 <b>目标表观描述与尺度自适应</b></h4>
                <div class="p1">
                    <p id="80">为提高样本信息的多样性与判别性, 文中采用颜色特征与方向梯度直方图 (<i>Histogram of Oriented Gradients</i>, <i>HOG</i>) 两种互补特征进行表观描述。在颜色特征提取方面, 将红绿蓝 (<i>Red Green Blue</i>, <i>RGB</i>) 三种颜色属性细化为11种基本颜色;在<i>HOG</i>特征提取方面, 对于图像块中每一个细胞单元, 提取得到31维<i>HOG</i>特征向量, 其中27维对应不同的方向通道, 4维对应不同的归一化因子;最终将提取得到的<i>HOG</i>特征与颜色特征串联起来形成具有42通道的融合特征。</p>
                </div>
                <div class="p1">
                    <p id="81">与此同时, 尺度变化是跟踪过程中不容忽视的基本问题, 对于因目标与传感器相对距离变化以及因外界遮挡或自身形变所导致的尺度变化情况, 如果不考虑尺度因子, 当目标尺度相对缩小时, 大量背景信息容易引入跟踪滤波器, 当目标尺度相对增大时, 目标局部信息便容易丢失, 这两种情况都很导致跟踪漂移乃至失败。本文利用多尺度缩放检测的思想解决目标尺度变化问题, 定义尺度因子池<i>S</i>={<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>L</i></sub>}, <i>L</i>为尺度变化数目, 假定模板尺寸为<b><i>r</i></b><sub>T</sub>, 初始目标搜索窗尺寸为<b><i>r</i></b><sub>s</sub>, 对于依据各个尺度因子<i>s</i><sub><i>l</i></sub>采集到的图像块尺寸<i>s</i><sub><i>l</i></sub><b><i>r</i></b><sub>s</sub>, 在求取响应值时将其归一化为<b><i>r</i></b><sub>T</sub>, 然后依据式 (8) 求得最佳响应值及其对应的目标尺度, 即</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>max</mi></mrow></mstyle><mi>l</mi></munder><mspace width="0.25em" /><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中:<b><i>z</i></b><sub><i>s</i><sub><i>l</i></sub></sub>为尺寸对应于<i>s</i><sub><i>l</i></sub><b><i>r</i></b><sub>s</sub>的候选样本图像块。通过在多尺度缩放的图像块集合上进行目标检测, 可以求得响应值最大的候选图像块位置及相应尺度。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">2.3 <b>模型更新策略</b></h4>
                <div class="p1">
                    <p id="85">目标表观在连续帧间动态变化, 需要对样本及分类器进行适时更新, 尤其当目标受遮挡或外界干扰影响时, 合理的更新处理才能避免出现跟踪漂移。通过研究当前帧与先前帧之间的相关性以及目标连续帧之间的时间平滑性, 可以定义目标表观变化率, 并部分描述目标表观受遮挡或干扰影响等情况<citation id="207" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="86">峰值旁瓣比 (<i>Peak to Sidelobe Ratio</i>, <i>PSLR</i>) 可用来量化相关性峰值的锐度, <i>PSLR</i>的值<i>O</i><sub>PSLR</sub>越高, 表明当前帧与先前帧之间的相关程度越高, 则在第<i>t</i>帧有</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>S</mtext><mtext>L</mtext><mtext>R</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mi>t</mi></msubsup><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mrow><mi>σ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中:<i>d</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>为置信图峰值; <i>μ</i><sub><i>t</i></sub>、<i>σ</i><sub><i>t</i></sub>分别为置信图旁瓣的均值与标准差。</p>
                </div>
                <div class="p1">
                    <p id="90">置信图平滑约束 (Smooth Constraint of Confidence Map, SCCM) 可用来描述目标连续帧之间具有的时间平滑性, SCCM的值<i>O</i><sub>SCCM</sub>越高, 表明当前帧与先前帧之间的平滑程度越差, 且有</p>
                </div>
                <div class="p1">
                    <p id="91"><i>O</i><sub>SCCM</sub>=‖<b><i>d</i></b><sub><i>t</i></sub>-<b><i>d</i></b><sub><i>t</i>-1</sub>♁<i>Δ</i>‖<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="93">其中:♁为置信图在连续帧间的偏移操作, <i>Δ</i>为连续帧间置信图最大值位置之间的偏移量, <b><i>d</i></b><sub><i>t</i>-1</sub>、<b><i>d</i></b><sub><i>t</i></sub>分别为第<i>t</i>-1与第<i>t</i>帧对应的置信响应图。</p>
                </div>
                <div class="p1">
                    <p id="94">因此, 可以定义目标表观变化率<i>η</i>, 即</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>S</mtext><mtext>L</mtext><mtext>R</mtext></mrow></msub></mrow></mfrac><mo>+</mo><mi>ζ</mi><mo>⋅</mo><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>C</mtext><mtext>C</mtext><mtext>Μ</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中:<i>ζ</i>为相关性锐度与置信图平滑度之间的平衡因子, 依据目标表观变化率及设置的表观变化阈值可以对目标受外界遮挡或背景干扰影响情况作出初步判定。</p>
                </div>
                <div class="p1">
                    <p id="97">对于某测试序列, 可以得出目标跟踪过程中各时刻的目标表观变化情况, 如图5所示。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同时刻目标表观变化情况" src="Detail/GetImg?filename=images/JSJY201904035_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同时刻目标表观变化情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Aparent change of target at different moment</p>

                </div>
                <div class="p1">
                    <p id="99">设置遮挡阈值为<i>ξ</i>, 依据当前帧最佳目标受遮挡情况完成系数矩阵与样本目标表观更新。</p>
                </div>
                <div class="p1">
                    <p id="100">分类器系数矩阵表达式<i>F</i> (<i>α</i>) 的更新方式为:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>ρ</mi><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>ρ</mi><mo stretchy="false">) </mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mi>η</mi><msub><mrow></mrow><mi>t</mi></msub><mo>&lt;</mo><mi>ξ</mi></mtd></mtr><mtr><mtd><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">目标表观<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover></math></mathml>的更新方式为:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>ρ</mi><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>ρ</mi><mo stretchy="false">) </mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mtext> </mtext><mi>η</mi><msub><mrow></mrow><mi>t</mi></msub><mo>&lt;</mo><mi>ξ</mi></mtd></mtr><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中: <i>ρ</i>为更新过程学习率, <i>η</i><sub><i>t</i></sub>为第<i>t</i>帧目标表观的遮挡率。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">2.4 <b>时间复杂度分析</b></h4>
                <div class="p1">
                    <p id="107">本文算法计算耗时主要集中在模型优化求解、目标状态估计以及模型更新方面。在模型求解方面, 计算耗时主要取决于式 (6) , 时间复杂度可表示为<i>O</i> (<i>CMN</i>) , 对于多通道特征, 则需要对所有维特征通道进行计算, 利用求和得出;在最佳目标估计方面, 需要求解检测响应置信图峰值, 计算耗时主要取决于式 (7) , 涉及点积、傅里叶变换及逆傅里叶变换等操作, 时间复杂度可表示为<i>O</i> (<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover></math></mathml><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ν</mi><mo>˜</mo></mover></math></mathml>log<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover></math></mathml><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ν</mi><mo>˜</mo></mover></math></mathml>) , 其中, <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover><mo>×</mo><mover accent="true"><mi>Ν</mi><mo>˜</mo></mover></mrow></math></mathml>为考虑尺度因子的目标跟踪区域;在模型更新方面, 计算耗时取决于式 (12) ～ (13) , 主要涉及矩阵求和运算, 时间复杂度可以记为<i>O</i> (<i>R</i><sub><i>c</i></sub><i>R</i><sub><i>l</i></sub>) , 其中<i>R</i><sub><i>c</i></sub>×<i>R</i><sub><i>l</i></sub>为模型系数矩阵大小。</p>
                </div>
                <h3 id="113" name="113" class="anchor-tag">3 实验与结果分析</h3>
                <div class="p1">
                    <p id="114">本文算法的实现环境为<i>Matlab</i>2018<i>a</i>, <i>CPU</i>为<i>i</i>5-7200<i>U</i>, 双核四线程, 主频为2.5 <i>GHz</i>, 内存为8 <i>GB</i>。设每个细胞单元大小为4×4个像素, 高斯核函数带宽<i>σ</i><sub>1</sub>=0.5, 上下文图像块采样个数为4, 多尺度因子池取为[1, 0.985, 0.99, 0.995, 1.005, 1.01, 1.015], 平衡因子为<i>ζ</i>=1, 遮挡阈值为<i>ξ</i>=0.7, 模型更新学习率为<i>ρ</i>=0.01。为验证本文算法的有效性, 选择基准库中的8组具有背景干扰、光照变化、尺度变化、旋转与形变、运动模糊及遮挡等复杂情况的视频序列进行测试, 并与6种典型算法相比, 包括:利用核的循环结构 (Circulant Structure of tracking-by-detection with Kernels, CSK) <citation id="208" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、时空上下文学习 (Spatio-Temporal Context learning, STC) <citation id="209" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、核相关滤波 (Kernelized Correlation Filter, KCF) <citation id="210" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、判别性尺度空间跟踪 (Discriminative Scale Space Tracking, DSST) <citation id="211" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、多特征尺度自适应滤波 (Scale Adaptive filter with Multiple Features, SAMF) <citation id="212" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、空间正则化判别性相关滤波 (Spatially Regularized Discriminative Correlation Filter, SRDCF) 算法<citation id="213" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 并采用中心位置误差 (Center Location Error, CLE) , 即人工手动标定给出的目标中心位置标准值与各跟踪算法得到的目标中心位置大小估计求得的值之间的距离, 以及边界框重叠率 (Bounding Box Overlap Rate, BBOR) , 即基准结果区域与跟踪算法跟踪结果区域的交与并结果中像素个数比值定量评价各跟踪算法性能。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">3.1 <b>定量评价</b></h4>
                <div class="p1">
                    <p id="116">不同时刻不同算法在各测试序列中的中心位置误差值如图6所示, 不同时刻不同算法在各测试序列中的边界框重叠率如图7所示, 不同算法在各测试序列中的中心位置误差平均值、整体跟踪准确率 (<i>Precision Rate</i>, <i>PR</i>) (依据中心位置误差阈值 (20个像素) ) 、边界框重叠率平均值、整体跟踪成功率 (<i>Success Rate</i>, <i>SR</i>) (依据边界框重叠率阈值 (0.6) ) , 以及各算法在测试序列中的每帧平均耗时 (<i>Average Time Per Frame</i>, <i>ATPF</i>) 如表1～2所示。</p>
                </div>
                <div class="p1">
                    <p id="117">由图6～7可看出, 本文算法充分利用了目标空间上下文结构信息, 在求得最佳目标状态时能够更好地区分目标与背景。通过引入的尺度因子池可以更有效地估计出目标中心位置及尺寸大小, 同时, 引入的运动连续性及模型更新过程中目标表观受遮挡影响情况的判定, 使得新算法能够更有效地适应外界遮挡及干扰等复杂情况, 适用性好。</p>
                </div>
                <div class="p1">
                    <p id="118">从表1～2可看出:本文算法可以充分利用空间结构信息优化分类器模型的构建, 并通过尺度自适应处理和遮挡情况判定提高算法对复杂场景的适应能力, 在各典型测试环境下均取得了相对较优的跟踪效果, 虽然计算实时性相对较低, 但整体跟踪性能稳定。与<i>SRDCF</i>算法相比, 本文算法的跟踪准确率提高了17.63%, 成功率提高了24.93%。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">3.2 <b>定性评价</b></h4>
                <div class="p1">
                    <p id="120">部分时刻各算法在不同典型测试序列上的部分跟踪效果如图8所示。</p>
                </div>
                <div class="p1">
                    <p id="121"><i>bird</i>2测试序列中存在目标自身的旋转运动形变和背景物体的遮挡干扰等情况, 如图8 (<i>a</i>) 所示。在第10帧, 受外界物体遮挡影响, <i>CSK</i>和<i>STC</i>算法出现了明显的跟踪漂移;在第46帧时, 目标做反方向运动, 各算法跟踪误差都有所增加, <i>DSST</i>和<i>SRDCF</i>等算法逐渐丢失了目标, 在后续的跟踪过程中也没有能够重新找回目标, 但SAMF和本文算法能够快速地找准目标, 有效实现较为完整的跟踪过程。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同时刻不同算法在各测试序列中的中心位置误差值" src="Detail/GetImg?filename=images/JSJY201904035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同时刻不同算法在各测试序列中的中心位置误差值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Center location error of different algorithms at different moment in each test sequence</i></p>

                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同时刻不同算法在各测试序列中的边界框重叠率" src="Detail/GetImg?filename=images/JSJY201904035_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同时刻不同算法在各测试序列中的边界框重叠率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 7 <i>Bounding box overlapping rate of different algorithms at different moment in each test sequence</i></p>

                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表</b>1 <b>不同算法在各测试序列上的中心位置误差与边界框重叠率平均值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Average value of center location error and bounding box overlap rate of different algorithms in each test sequence</i></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td rowspan="2">测试序列</td><td colspan="2"><br /><i>CSK</i></td><td rowspan="2"></td><td colspan="2"><br /><i>STC</i></td><td rowspan="2"></td><td colspan="2"><br /><i>KCF</i></td><td rowspan="2"></td><td colspan="2"><br /><i>DSST</i></td><td rowspan="2"></td><td colspan="2"><br /><i>SAMF</i></td><td rowspan="2"></td><td colspan="2"><br /><i>SRDCF</i></td><td rowspan="2"></td><td colspan="2"><br />本文算法</td></tr><tr><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td><td><br /><i>CLE</i>/像素</td><td><i>BBOR</i></td></tr><tr><td><i>bird</i>2</td><td>18.297</td><td>0.580</td><td></td><td>18.713</td><td>0.489</td><td></td><td>21.370</td><td>0.572</td><td></td><td>19.214</td><td>0.593</td><td></td><td><b>6.444</b><sup>1</sup></td><td><b>0.801</b><sup>1</sup></td><td></td><td>16.645</td><td>0.613</td><td></td><td><b>6.452</b><sup>2</sup></td><td><b>0.782</b><sup>2</sup></td></tr><tr><td><br />box</td><td>210.808</td><td>0.123</td><td></td><td>105.987</td><td>0.228</td><td></td><td>89.127</td><td>0.301</td><td></td><td>107.086</td><td>0.287</td><td></td><td><b>8.943</b><sup>2</sup></td><td><b>0.694</b><sup>2</sup></td><td></td><td>89.292</td><td>0.360</td><td></td><td><b>7.671</b><sup>1</sup></td><td><b>0.705</b><sup>1</sup></td></tr><tr><td><br />coke</td><td>13.644</td><td>0.570</td><td></td><td>74.321</td><td>0.106</td><td></td><td>18.653</td><td>0.550</td><td></td><td><b>12.713</b><sup>2</sup></td><td><b>0.605</b><sup>2</sup></td><td></td><td>13.223</td><td>0.593</td><td></td><td>18.900</td><td>0.513</td><td></td><td><b>7.517</b><sup>1</sup></td><td><b>0.698</b><sup>1</sup></td></tr><tr><td><br />dudek</td><td>13.394</td><td>0.716</td><td></td><td>25.595</td><td>0.587</td><td></td><td>11.382</td><td>0.728</td><td></td><td>13.315</td><td>0.714</td><td></td><td><b>10.120</b><sup>2</sup></td><td>0.804</td><td></td><td>12.631</td><td><b>0.818</b><sup>1</sup></td><td></td><td><b>8.375</b><sup>1</sup></td><td><b>0.815</b><sup>2</sup></td></tr><tr><td><br />faceocc1</td><td><b>11.932</b><sup>2</sup></td><td><b>0.795</b><sup>1</sup></td><td></td><td>250.402</td><td>0.189</td><td></td><td>15.983</td><td>0.754</td><td></td><td>14.072</td><td>0.766</td><td></td><td><b>11.877</b><sup>1</sup></td><td>0.788</td><td></td><td>14.767</td><td>0.767</td><td></td><td>12.053</td><td><b>0.789</b><sup>2</sup></td></tr><tr><td><br />jogging</td><td>134.982</td><td>0.178</td><td></td><td>149.973</td><td>0.171</td><td></td><td>87.899</td><td>0.186</td><td></td><td>111.840</td><td>0.183</td><td></td><td><b>4.643</b><sup>2</sup></td><td><b>0.788</b><sup>2</sup></td><td></td><td>4.866</td><td><b>0.800</b><sup>1</sup></td><td></td><td><b>4.299</b><sup>1</sup></td><td>0.784</td></tr><tr><td><br />suv</td><td>573.235</td><td>0.528</td><td></td><td>51.495</td><td>0.514</td><td></td><td><b>3.506</b><sup>1</sup></td><td><b>0.887</b><sup>1</sup></td><td></td><td>3.841</td><td><b>0.868</b><sup>2</sup></td><td></td><td>3.946</td><td>0.827</td><td></td><td>4.725</td><td>0.750</td><td></td><td><b>3.688</b><sup>2</sup></td><td>0.842</td></tr><tr><td><br />trellis</td><td>18.824</td><td>0.480</td><td></td><td>33.754</td><td>0.465</td><td></td><td>8.210</td><td>0.631</td><td></td><td>2.591</td><td>0.634</td><td></td><td><b>2.382</b><sup>1</sup></td><td><b>0.858</b><sup>1</sup></td><td></td><td>2.561</td><td>0.751</td><td></td><td><b>2.508</b><sup>2</sup></td><td><b>0.855</b><sup>2</sup></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:加粗数值后的上标1表示最优值, 上标2代表次优值。</p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="126">box测试序列中目标受外界遮挡影响严重, 并存在背景干扰、旋转形变与尺度变化等复杂因素, 如图8 (b) 所示。在第88帧, 目标在旋转过程中出现运动模糊, CSK算法跟踪误差明显增加并导致跟踪失败;在第447帧后, 目标逐渐被外界遮挡并移入复杂背景中, KCF和SRDCF等算法不能重新找回目标, 跟踪误差明显增加直至丢失目标, 整体看来, SAMF和本文算法能有效实现完整跟踪, 跟踪性能相对较优。</p>
                </div>
                <div class="p1">
                    <p id="127">coke测试序列中目标做持续旋转运动, 并在部分时刻被完全遮挡, 如图8 (c) 所示。在第36帧, 受外部遮挡影响, STC算法存在明显跟踪漂移乃至跟踪失败;在第56～75帧, 受目标旋转变形影响, KCF和SAMF算法跟踪误差显著增加;而在第251～273帧, 目标受外界遮挡干扰, SAMF、SRDCF和本文算法跟踪误差都有所增加, 但在遮挡情况消失时本文算法能快速重新准确估计出目标运动状态, 其中, 由于本文算法考虑了目标空间结构信息与遮挡情况判定, 跟踪性能相对较优。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 典型测试序列上部分时刻不同算法的跟踪效果" src="Detail/GetImg?filename=images/JSJY201904035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 典型测试序列上部分时刻不同算法的跟踪效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Tracking effect of different algorithms on some moments of typical test sequences</p>

                </div>
                <div class="p1">
                    <p id="129">dudek测试序列中目标受光照和背景干扰影响, 并伴随持续运动与尺寸变化, 如图8 (d) 所示。在第681～746帧, 目标在背景干扰中运动, 各算法跟踪误差都有明显增加;在第786帧之后, 目标表观变化明显, STC算法出现明显跟踪漂移, 而在第927帧, 目标面部旋转明显, KCF和SAMF等算法也出现不同程度的跟踪漂移, 而利用空间结构信息和表观变化情况判定的本文算法跟踪效果较为稳定。</p>
                </div>
                <div class="p1">
                    <p id="130">faceocc1测试序列中目标受外界遮挡与干扰情况显著, 如图8 (e) 所示。随着外界遮挡面积的逐渐增加及减小, 各跟踪算法性能出现明显波动, 而在第216帧之后, 随着遮挡物的出现与移走, STC算法跟踪误差明显增大, 并逐渐丢失目标;整体看来, SAMF和本文算法跟踪效果相对较优。</p>
                </div>
                <div class="p1">
                    <p id="131">jogging测试序列中目标受严重遮挡及相似物体干扰影响, 如图8 (f) 所示。在第62帧, 受外界遮挡物干扰影响, 各算法跟踪误差都有明显增加, 随着遮挡物的移除, KCF和DSST等算法出现明显跟踪漂移, 而SRDCF和本文算法能够快速找回目标, 跟踪效果良好。</p>
                </div>
                <div class="p1">
                    <p id="132">suv测试序列中目标受外部遮挡和背景干扰严重, 如图8 (g) 所示。在第511帧, 受严重遮挡影响, 目标逐渐淡出视野, CSK算法出现明显的跟踪偏差;在第793帧, 随着遮挡物的移除, STC算法出现明显跟踪漂移直至跟踪失败;整体看来, KCF和本文算法对目标运动趋势判定基本正确, 且KCF跟踪性能明显优于其他算法。</p>
                </div>
                <div class="p1">
                    <p id="133">trellis测试序列中目标受到强烈背景光照变化的干扰, 并存在自身旋转与尺度变化, 如图8 (h) 所示。受旋转形变与光照变化影响, 在第241～439帧, CSK算法跟踪误差相对较大;在第412帧之后, 受光照变化和背景干扰影响, STC算法出现明显跟踪漂移乃至丢失目标;整体看来, SAMF和本文算法取得了较为鲁棒的跟踪效果。</p>
                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表</b>2 <b>不同算法在各测试序列中的整体定量评价结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Overall quantitative evaluation results of different algorithms in each test sequence</p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td><br />算法</td><td>PR</td><td>SR</td><td>ATPF/s</td></tr><tr><td><br />CSK</td><td>0.562</td><td>0.463</td><td><b>0.004</b><sup>2</sup></td></tr><tr><td><br />STC</td><td>0.428</td><td>0.276</td><td><b>0.003</b><sup>1</sup></td></tr><tr><td><br />KCF</td><td>0.643</td><td>0.617</td><td>0.005</td></tr><tr><td><br />DSST</td><td>0.667</td><td>0.639</td><td>0.033</td></tr><tr><td><br />SAMF</td><td><b>0.951</b><sup>2</sup></td><td><b>0.885</b><sup>2</sup></td><td>0.069</td></tr><tr><td><br />SRDCF</td><td>0.817</td><td>0.750</td><td>0.116</td></tr><tr><td><br />本文算法</td><td><b>0.961</b><sup>1</sup></td><td><b>0.937</b><sup>1</sup></td><td>0.083</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:加粗数值后的上标1表示最优值, 上标2代表次优值。</p>
                    <p class="img_note"></p>
                </div>
                <h3 id="135" name="135" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="136">针对典型相关滤波算法中样本信息判别性不足的问题, 本文给出了一种利用空间结构信息的目标跟踪算法。通过引入空间结构约束实现了模型构建的优化, 一定程度上减少了图像边界范围受限的影响, 提高了样本信息的多样性与判别性;采用的互补特征能够有效表征目标表观描述, 引入的尺度因子池有助于处理目标尺度变化情形;此外, 依据目标受遮挡影响情况设计了模型更新策略, 可以有效适应目标表观变化。实验的定量和定性分析结果验证了所提算法在多种复杂场景中能有效解决目标跟踪性能低的问题。下一步的工作将着重研究不同通道特征之间的加权融合, 并利用分块处理解决遮挡问题。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="160">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object tracking benchmark">

                                <b>[1]</b>WU Y, LIM J, YANG M H.Object tracking benchmark[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Visual Object Tracking VOT2016Challenge Results">

                                <b>[2]</b>KRISTAN M, LEONARDIS A, MATAS J, et al.The visual object tracking VOT2016 challenge results[C]//ICCV 2016:Proceedings of the 2016 IEEE International Conference on Computer Vision Workshops.Washington, DC:IEEE Computer Society, 2016:98-111.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018792656.nh&amp;v=MjQyMjl1WnNGeURoVUwvUFZGMjZGclN4SE5mSnFaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>胡秀华.复杂场景中目标跟踪算法研究[D].西安:西北工业大学, 2017:19-28. (HU X H.Research on object tracking algorithm in complex environment[D].Xi'an:Northwestern Polytechnical University, 2017:19-28.) 
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An experimental survey on correlation filter-based tracking">

                                <b>[4]</b>CHEN Z, HONG Z, TAO D.An experimental survey on correlation filter-based tracking[EB/OL].[2018-05-26].https://arxiv.org/pdf/1509.05520.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">

                                <b>[5]</b>HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 2012 European Conference on Computer Vision.Berlin:Springer, 2012:702-715.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">

                                <b>[6]</b>HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast tracking via dense spatio-temporal context learning">

                                <b>[7]</b>ZHANG K H, ZHANG L, LIU Q S, et al.Fast visual tracking via dense spatio-temporal context learning[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:127-141.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">

                                <b>[8]</b>LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision.Berlin:Springer, 2014:254-265.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">

                                <b>[9]</b>DANELLJAN M, HAGER G, KHAN F, et al.Accurate scale estimation for robust visual tracking[C]//CVPR 2014:Proceedings of the 2014 Proceedings of the British Machine Vision Conference.Nottingham:British Machine Vision Association Press, 2014:65.1-65.11.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201703036&amp;v=MjAyODk5Yk1ySTlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVML1BMejdCZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>钱堂慧, 罗志清, 李果家, 等.核相关滤波跟踪算法的尺度自适应改进[J].计算机应用, 2017, 37 (3) :811-816. (QIAN TH, LUO Z Q, LI G J, et al.Scale adaptive improvement of kernel correlation filter tracking algorithm[J].Journal of Computer Applications, 2017, 37 (3) :811-816.) 
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201704016&amp;v=MTc0ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVML1BQU25BYXJHNEg5Yk1xNDlFWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>胡秀华, 郭雷, 李晖晖.一种利用物体性检测的目标跟踪算法[J].西安电子科技大学学报 (自然科学版) , 2017, 44 (4) :86-94. (HU X H, GUO L, LI H H.An object tracking algorithm based on objectness detection[J].Journal of Xidian University, 2017, 44 (4) :86-94.) 
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning spatially regularized correlation filters for visual tracking">

                                <b>[12]</b>DANELLJAN M, HAGER G, KHAN F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4310-4318.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">

                                <b>[13]</b>MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//CVPR 2017:Proceedings of the 2017 IEEEInternational Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:1387-1395.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Target Response Adaptation for Correlation Filter Tracking">

                                <b>[14]</b>BIBI A, MUELLER M, GHANEM B.Target response adaptation for correlation filter tracking[C]//ECCV 2016:Proceedings of the2016 European Conference on Computer Vision.Berlin:Springer, 2016:419-433.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative Correlation Filter Tracker with Channel and Spatial Reliability">

                                <b>[15]</b>LUKEZIC A, VOJIR T, ZAJC L C, et al.Discriminative correlation filter with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regularized least squares classification">

                                <b>[16]</b>RIFKIN R, YEO G, POGGIO T.Regularized least squares classification[EB/OL].[2018-07-26].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.3463&amp;rep=rep1&amp;type=pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904035" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904035&amp;v=MzE0MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTC9QTHo3QmQ3RzRIOWpNcTQ5R1lZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
