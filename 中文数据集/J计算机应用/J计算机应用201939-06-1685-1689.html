<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136675080471250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906023%26RESULT%3d1%26SIGN%3dm8FUxkObOug4%252bYvpU0iKLZ0FUIo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906023&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906023&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906023&amp;v=MTkwNzFzRnkvaFdyM0tMejdCZDdHNEg5ak1xWTlIWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#51" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="1 三维人脸模型的自动预处理 ">1 三维人脸模型的自动预处理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="2 本文算法 ">2 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#66" data-title="2.1 &lt;b&gt;多区域模板设计&lt;/b&gt;">2.1 <b>多区域模板设计</b></a></li>
                                                <li><a href="#71" data-title="2.2 &lt;b&gt;区域相似度分类&lt;/b&gt;">2.2 <b>区域相似度分类</b></a></li>
                                                <li><a href="#76" data-title="2.3 &lt;b&gt;多模板区域分类融合&lt;/b&gt;">2.3 <b>多模板区域分类融合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="3.1 &lt;b&gt;数据库及实验设置&lt;/b&gt;">3.1 <b>数据库及实验设置</b></a></li>
                                                <li><a href="#94" data-title="3.2 &lt;b&gt;阈值确定&lt;/b&gt;">3.2 <b>阈值确定</b></a></li>
                                                <li><a href="#101" data-title="3.3 FRGC v2.0&lt;b&gt;数据库实验结果&lt;/b&gt;">3.3 FRGC v2.0<b>数据库实验结果</b></a></li>
                                                <li><a href="#108" data-title="3.4 Bosphorus&lt;b&gt;数据库上实验结果&lt;/b&gt;">3.4 Bosphorus<b>数据库上实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="图1 三维人脸模型预处理">图1 三维人脸模型预处理</a></li>
                                                <li><a href="#65" data-title="图2 所提算法流程">图2 所提算法流程</a></li>
                                                <li><a href="#69" data-title="图3 所提的模板区域示意图">图3 所提的模板区域示意图</a></li>
                                                <li><a href="#97" data-title="图4 固定FAR下各模板区域识别性能和对应阈值">图4 固定FAR下各模板区域识别性能和对应阈值</a></li>
                                                <li><a href="#100" data-title="图5 多区域融合性能">图5 多区域融合性能</a></li>
                                                <li><a href="#105" data-title="图6 所提算法在FRGC v2.0数据库上的rank识别率">图6 所提算法在FRGC v2.0数据库上的rank识别率</a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表&lt;/b&gt;1 FRGC v2.0&lt;b&gt;数据库上不同算法的&lt;/b&gt;rank- 1&lt;b&gt;识别率&lt;/b&gt;"><b>表</b>1 FRGC v2.0<b>数据库上不同算法的</b>rank- 1<b>识别率</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表&lt;/b&gt;2 Bosphorus&lt;b&gt;数据库上不同算法的&lt;/b&gt;rank- 1&lt;b&gt;识别率&lt;/b&gt;"><b>表</b>2 Bosphorus<b>数据库上不同算法的</b>rank- 1<b>识别率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="147">


                                    <a id="bibliography_1" title="王跃明, 潘纲, 吴朝晖.三维人脸识别研究综述[J].计算机辅助设计与图形学学报, 2008, 20 (7) :819-829. (WANG Y M, PANG, WU Z H.A survey of 3D face recognition[J].Journal of Computer Aided design&amp;amp;Computer Graphics, 2008, 20 (7) :819-829.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF200807002&amp;v=MDMzMzJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjNLTHo3QmFMRzRIdG5NcUk5RlpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        王跃明, 潘纲, 吴朝晖.三维人脸识别研究综述[J].计算机辅助设计与图形学学报, 2008, 20 (7) :819-829. (WANG Y M, PANG, WU Z H.A survey of 3D face recognition[J].Journal of Computer Aided design&amp;amp;Computer Graphics, 2008, 20 (7) :819-829.) 
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_2" title="Al-OSAIMI F, BENNAMOUN M, MIAN A.Expression-invariant non-rigid 3D face recognition:a robust approach to expression-aware morphing[C]//Proceedings of the 4th International Symposium on3D Data Processing, Visualization, and Transmission.Piscataway, NJ:IEEE, 2008:19-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Expression-invariant non-rigid 3D face recognition:a robust approach to expression-aware morphing">
                                        <b>[2]</b>
                                        Al-OSAIMI F, BENNAMOUN M, MIAN A.Expression-invariant non-rigid 3D face recognition:a robust approach to expression-aware morphing[C]//Proceedings of the 4th International Symposium on3D Data Processing, Visualization, and Transmission.Piscataway, NJ:IEEE, 2008:19-26.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_3" title="MPIPERIS I, MALASSIOTIS S, STRINTZIS M G.Expression-compensated 3D face recognition with geodesically aligned bilinear models[C]//Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Expressioncompensated 3D face recognition with geodesically aligned bilinear models">
                                        <b>[3]</b>
                                        MPIPERIS I, MALASSIOTIS S, STRINTZIS M G.Expression-compensated 3D face recognition with geodesically aligned bilinear models[C]//Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_4" title="KAUSHIK V D, BUDHWAR A, DUBEY A, et al.An efficient 3Dface recognition algorithm[C]//NTMS 2009:Proceedings of the3rd International Conference on New Technologies, Mobility and Security.Piscataway, NJ:IEEE, 2009:259-263." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Efficient 3D Face Recognition Algorithm">
                                        <b>[4]</b>
                                        KAUSHIK V D, BUDHWAR A, DUBEY A, et al.An efficient 3Dface recognition algorithm[C]//NTMS 2009:Proceedings of the3rd International Conference on New Technologies, Mobility and Security.Piscataway, NJ:IEEE, 2009:259-263.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_5" title="BRONSTEIN A M, BRONSTEIN M M, KIMMEL R.Expressioninvariant representations of faces[J].IEEE Transactions on Image Processing, 2007, 16 (1) :188-197." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Expression-Invariant Representations of Faces">
                                        <b>[5]</b>
                                        BRONSTEIN A M, BRONSTEIN M M, KIMMEL R.Expressioninvariant representations of faces[J].IEEE Transactions on Image Processing, 2007, 16 (1) :188-197.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_6" title="JAHANBIN S, CHOI H, LIU Y, et al.Three dimensional face recognition using iso-geodesic and iso-depth curves[C]//BTAS2008:Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Three Dimensional Face RecognitionUsing Iso-Geodesic and Iso-Depth Curves">
                                        <b>[6]</b>
                                        JAHANBIN S, CHOI H, LIU Y, et al.Three dimensional face recognition using iso-geodesic and iso-depth curves[C]//BTAS2008:Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_7" title="BERRETTI S, DEL BIMBO A, PALA P.3D face recognition using isogeodesic stripes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (12) :2162-2177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D Face Recognition Using Isogeodesic Stripes">
                                        <b>[7]</b>
                                        BERRETTI S, DEL BIMBO A, PALA P.3D face recognition using isogeodesic stripes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (12) :2162-2177.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_8" title="DRIRA H, BEN AMOR B, DAOUDI M, et al.Pose and expression-invariant 3d face recognition using elastic radial curves[C]//Proceedings of the 2010 British Machine Vision Conference.Durham, UK:BMVA Press, 2010:1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pose and expression-invariant 3D face recognition using elastic radial curves">
                                        <b>[8]</b>
                                        DRIRA H, BEN AMOR B, DAOUDI M, et al.Pose and expression-invariant 3d face recognition using elastic radial curves[C]//Proceedings of the 2010 British Machine Vision Conference.Durham, UK:BMVA Press, 2010:1-11.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_9" title="BERRETTI S, del BIMBO A, PALA P, et al.A set of selected SIFT features for 3D facial expression recognition[C]//ICPR2010:Proceedings of the 2010 20th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2010:4125-4128." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A set of selected SIFT features for3D facial expression recognition">
                                        <b>[9]</b>
                                        BERRETTI S, del BIMBO A, PALA P, et al.A set of selected SIFT features for 3D facial expression recognition[C]//ICPR2010:Proceedings of the 2010 20th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2010:4125-4128.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_10" title="ALYUZ N, GOKBERK B, AKARUN L.Regional registration for expression resistant 3-D face recognition[J].IEEE Transactions on Information Forensics and Security, 2010, 5 (3) :425-440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regional registration for expression resistant 3-D face recognition">
                                        <b>[10]</b>
                                        ALYUZ N, GOKBERK B, AKARUN L.Regional registration for expression resistant 3-D face recognition[J].IEEE Transactions on Information Forensics and Security, 2010, 5 (3) :425-440.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_11" title="SMEETS D, KEUSTERMANS J, VANDERMEULEN D, et al.mesh SIFT:Local surface features for 3D face recognition under expression variations and partial data[J].Computer Vision and Image Understanding, 2013, 117 (2) :158-169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600448665&amp;v=MjE1NzA5RllPOEhDbm84b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSjFvZGFCQT1OaWZPZmJLOEh0RE1xWQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        SMEETS D, KEUSTERMANS J, VANDERMEULEN D, et al.mesh SIFT:Local surface features for 3D face recognition under expression variations and partial data[J].Computer Vision and Image Understanding, 2013, 117 (2) :158-169.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_12" title="GUO Y L, LEI Y J, LIU L, et al.EI3D:Expression-invariant 3Dface recognition based on feature and shape matching[J].Pattern Recognition Letters, 2016, 83 (Part 3) :403-412." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBA275E200C4C1FD7CB21FB846113E383&amp;v=Mjk5NzRmQnJMVTA1dHBodzd5Mndxbz1OaWZPZmNISkhOYkoybzFGWkpnTGYzMVB1eEZnbUQxOFBnM3FxQlEwZUxIaFJyS2NDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        GUO Y L, LEI Y J, LIU L, et al.EI3D:Expression-invariant 3Dface recognition based on feature and shape matching[J].Pattern Recognition Letters, 2016, 83 (Part 3) :403-412.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_13" title="EMAMBAKHSH M, EVANS A.Nasal patches and curves for expression-robust 3D face recognition[J].IEEE transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (5) :995-1007." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nasal patches and curves for expression-robust 3Dface recognition">
                                        <b>[13]</b>
                                        EMAMBAKHSH M, EVANS A.Nasal patches and curves for expression-robust 3D face recognition[J].IEEE transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (5) :995-1007.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_14" title="CHANG K I, BOWYER K W, FLYNN P J.Multiple nose region matching for 3D face recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple Nose Region Matching for 3D Face Recognition under Varying Facial Expression">
                                        <b>[14]</b>
                                        CHANG K I, BOWYER K W, FLYNN P J.Multiple nose region matching for 3D face recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_15" title="SANG G L, LI J, ZHAO Q J.Pose-invariant face recognition via RGB-D images[J].Computational Intelligence and Neuroscience, 2016 (3) :1-9." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHDCF3B9F64473AC0E149B44BF9CC9E066B&amp;v=MDE1NzNhUEYyWWxCWU93TWZRODV1aGNYNDAxNVRBMlVwV0ZHY01lVVE3enRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3kyd3FvPU5pZkRhc0RPSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        SANG G L, LI J, ZHAO Q J.Pose-invariant face recognition via RGB-D images[J].Computational Intelligence and Neuroscience, 2016 (3) :1-9.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_16" title="CHEW W J, SENG K P, ANG L M.Nose tip detection on a three-dimensional face range image invariant to head pose[C]//Proceedings of the 2009 International Multi Conference of Engineers and Computer Scientists.Hong Kong:International Association of Engineers, 2009:858-862." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nose Tip Detection on a Three-Dimensional Face Range Image Invariant to Head Pose">
                                        <b>[16]</b>
                                        CHEW W J, SENG K P, ANG L M.Nose tip detection on a three-dimensional face range image invariant to head pose[C]//Proceedings of the 2009 International Multi Conference of Engineers and Computer Scientists.Hong Kong:International Association of Engineers, 2009:858-862.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_17" title="SPREEUWERS L J, VELDHUIS R N J, SULTANALI S, et al.Fixed FAR vote fusion of regional facial classifiers[C]//BIOSIG2014:Proceedings of the 2014 International Conference of the BI-Ometrics Special Interest Group.Piscataway, NJ:IEEE, 2014:187-194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fixed FAR vote fusion of regional facial classifiers">
                                        <b>[17]</b>
                                        SPREEUWERS L J, VELDHUIS R N J, SULTANALI S, et al.Fixed FAR vote fusion of regional facial classifiers[C]//BIOSIG2014:Proceedings of the 2014 International Conference of the BI-Ometrics Special Interest Group.Piscataway, NJ:IEEE, 2014:187-194.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_18" title="尹宝才, 孙艳丰, 王成章, 等.BJUT-3D三维人脸数据库及其处理技术[J].计算机研究与发展, 2009, 46 (6) :1009-1018. (YIN B C, SUN Y F, WANG C Z, et al.BJUT-3D large scale3D face database and information processing[J].Journal of Computer Research and Development, 2009, 46 (6) :1009-1018.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200906020&amp;v=MTI5OTdCdEdGckNVUjdxZlp1WnNGeS9oV3IzS0x5dlNkTEc0SHRqTXFZOUhaSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        尹宝才, 孙艳丰, 王成章, 等.BJUT-3D三维人脸数据库及其处理技术[J].计算机研究与发展, 2009, 46 (6) :1009-1018. (YIN B C, SUN Y F, WANG C Z, et al.BJUT-3D large scale3D face database and information processing[J].Journal of Computer Research and Development, 2009, 46 (6) :1009-1018.) 
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_19" title="AMBERG B, ROMDHANI S, VETTER T.Optimal step nonrigid ICP algorithms for surface registration[C]//CVPR 2007:Proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimal Step Nonrigid ICP Algorithms for Surface Registration">
                                        <b>[19]</b>
                                        AMBERG B, ROMDHANI S, VETTER T.Optimal step nonrigid ICP algorithms for surface registration[C]//CVPR 2007:Proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1-8.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_20" title="WANG Y M, PAN G, WU Z H.3D face recognition in the presence of expression:a guidance-based constraint deformation approach[C]//CVPR 2007:Proceedings of the 2007 Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1180-1187." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D face recognition in the presence of expression:a guidance-based constraint deformation approach">
                                        <b>[20]</b>
                                        WANG Y M, PAN G, WU Z H.3D face recognition in the presence of expression:a guidance-based constraint deformation approach[C]//CVPR 2007:Proceedings of the 2007 Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1180-1187.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_21" title="SAVRAN A, ALYUZ N, DIBEKLIOGLU H, et al.Bosphorus database for 3D face analysis[C]//Proceedings of the 2008 European Workshop on Biometrics and Identity Management, LNCS5372.Berlin:Springer, 2008:47-56." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bosphorus database for3D face analysis">
                                        <b>[21]</b>
                                        SAVRAN A, ALYUZ N, DIBEKLIOGLU H, et al.Bosphorus database for 3D face analysis[C]//Proceedings of the 2008 European Workshop on Biometrics and Identity Management, LNCS5372.Berlin:Springer, 2008:47-56.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_22" title="DENG X, DA F P, SHAO H J.Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition[J].Signal, Image and Video Processing, 2017, 11 (7) :1305-1312." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6A425D751D6FDC505959BC5CF2D001FB&amp;v=MDc3MjhOajdCYXJYSkd0UEoyNGhBWlo4SmVnaEt5aFlXNHpwME9nem4zMlEzRGJLVVJNenRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3kyd3FvPQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        DENG X, DA F P, SHAO H J.Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition[J].Signal, Image and Video Processing, 2017, 11 (7) :1305-1312.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_23" title="BAGCHI P, BHATTACHARJEE D, NASIPURI M.Robust 3Dface recognition in presence of pose and partial occlusions or missing parts[J].International Journal in Foundations of Computer Science&amp;amp;Technology, 2014, 4 (4) :21-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust 3Dface recognition in presence of pose and partial occlusions or missing parts">
                                        <b>[23]</b>
                                        BAGCHI P, BHATTACHARJEE D, NASIPURI M.Robust 3Dface recognition in presence of pose and partial occlusions or missing parts[J].International Journal in Foundations of Computer Science&amp;amp;Technology, 2014, 4 (4) :21-35.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_24" title="GANGULY S, BHATTACHARJEE D, NASIPURI M.Depth based occlusion detection and localization from 3D face image[J].International Journal of Image, Graphics&amp;amp;Signal Processing, 2015, 7 (5) :20-31." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJMS&amp;filename=SJMSFA8BE2896B68CEF35DB3135C068C32B8&amp;v=MDU2MzFKQkE5TXVSVVduazErU1h6bjN4SXpjY0dYUjhpWENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3eTJ3cW89TmlmR2ZjWEpGcU81cllkTVlwaw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        GANGULY S, BHATTACHARJEE D, NASIPURI M.Depth based occlusion detection and localization from 3D face image[J].International Journal of Image, Graphics&amp;amp;Signal Processing, 2015, 7 (5) :20-31.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-22 15:10</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1685-1689 DOI:10.11772/j.issn.1001-9081.2018112301            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多区域融合的表情鲁棒三维人脸识别算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A1%91%E9%AB%98%E4%B8%BD&amp;code=38859871&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桑高丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%97%AB%E8%B6%85&amp;code=27403852&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">闫超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E8%93%89&amp;code=07752126&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱蓉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%98%89%E5%85%B4%E5%AD%A6%E9%99%A2%E6%95%B0%E7%90%86%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0137300&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">嘉兴学院数理与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0054367&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了实现三维人脸识别算法对表情变化的鲁棒性, 提出一种基于语义对齐的多区域模板融合三维人脸识别算法。首先, 为了实现三维人脸在语义上的对齐, 将所有三维人脸模型与预定义标准参考模型做稠密对齐。然后, 根据人脸表情具有区域性的特点, 为了不受限于区域划分的精准度, 提出基于多区域模板的相似度预测方法。最后, 采用多数投票法将多个分类器的预测结果融合得到最终识别结果。实验结果表明, 在FRGC v2.0表情三维人脸数据库上所提算法可以达到98.69%的rank-1识别率, 在含有遮挡变化的Bosphorus数据库上该算法达到84.36%的rank-1识别率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A1%A8%E6%83%85%E5%8F%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">表情变化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%8C%BA%E5%9F%9F%E6%A8%A1%E6%9D%BF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多区域模板;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%95%B0%E6%8A%95%E7%A5%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多数投票;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *桑高丽 (1986—) , 女, 河南鹿邑人, 讲师, 博士, 主要研究方向:模式识别、人工智能;sanggaoli@ 126. com;
                                </span>
                                <span>
                                    闫超 (1985—) , 男, 山东菏泽人, 高级工程师, 硕士, 主要研究方向:人工智能;;
                                </span>
                                <span>
                                    朱蓉 (1973—) , 女, 浙江嘉兴人, 教授, 博士, 主要研究方向:数据挖掘、智能计算。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61703183);</span>
                                <span>浙江省自然科学基金资助项目 (LY15F020039, LQ18F020007, LQ18F020006);</span>
                    </p>
            </div>
                    <h1><b>Expression-insensitive three-dimensional face recognition algorithm based on multi-region fusion</b></h1>
                    <h2>
                    <span>SANG Gaoli</span>
                    <span>YAN Chao</span>
                    <span>ZHU Rong</span>
            </h2>
                    <h2>
                    <span>College of Mathematics and Information Engineering, Jiaxing University</span>
                    <span>College of Computer Science, Sichuan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to realize the robustness of three-Dimensional (3 D) face recognition algorithm to expression variations, a multi-region template fusion 3 D face recognition algorithm based on semantic alignment was proposed. Firstly, in order to guarantee the semantic alignment of 3 D faces, all the 3 D face models were densely aligned with a pre-defined standard reference 3 D face model. Then, considering the expressions were regional, to be robust to region division, a multi-region template based similarity prediction method was proposed. Finally, all the prediction results of multiple classifiers were fused by majority voting method. The experimental results show that, the proposed algorithm can achieve the rank-1 face recognition rate of 98.69% on FRGC (the Face Recognition Grand Challenge) v2.0 expression 3 D face database and rank-1 face recognition rate of 84.36% on Bosphorus database with occlusion change.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=expression%20variation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">expression variation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-Dimensional%20(3D)%20face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-Dimensional (3D) face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-region%20template&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-region template;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=majority%20voting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">majority voting;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SANG Gaoli, born in 1986, Ph. D. , lecturer. Her research interests include pattern recognition, artificial intelligence. ;
                                </span>
                                <span>
                                    YAN Chao, born in 1985, M. S. , senior engineer. His research interests include artificial intelligence. ;
                                </span>
                                <span>
                                    ZHU Rong, born in 1973, Ph. D. , professor. Her research interests include data mining, intelligent computing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-17</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61703183);</span>
                                <span>the Natural Science Foundation of Zhejiang Province (LY15F020039, LQ18F020007, LQ18F020006);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="51" name="51" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="52">人脸识别在公安刑侦、国家安全、市场金融等诸多领域具有广泛的应用前景。然而, 鉴于三维 (three-Dimensional, 3D) 人脸本身的可形变特性以及易受不同表情变化的影响, 研究对表情鲁棒的人脸识别算法一直都是三维人脸识别领域的研究热点和难点问题<citation id="195" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="53">目前, 表情鲁棒的三维人脸识别方法主要分为统计模型方法 (Statistical methods) <citation id="197" type="reference"><link href="149" rel="bibliography" /><link href="151" rel="bibliography" /><link href="153" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、同等形变模型方法 (Isometric deformation modeling) <citation id="198" type="reference"><link href="155" rel="bibliography" /><link href="157" rel="bibliography" /><link href="159" rel="bibliography" /><link href="161" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>和基于区域的方法 (region-based methods) <citation id="199" type="reference"><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><link href="169" rel="bibliography" /><link href="171" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。统计模型方法即通过构建统计模型对表情变化引起的面部软组织形变关系进行刻画, 算法的精度和鲁棒程度受训练统计模型所采用的三维人脸库的表情变化多样性、数据质量等影响。同等形变模型方法即将表情变化引起的三维人脸形变转化为等距形变问题建模<citation id="196" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 将表情变化近似为等距形变, 用等距形变特征近似表情变化特征。同等形变的方法通过弱化表情变化引起的三维形变达到表情鲁棒;然而, 同等形变一定程度上也弱化了人脸原有三维结构。由于表情变化呈现局部性, 相较上述整体类方法, 基于区域类方法表现出更多的灵活性和稳定性。基于区域的表情不变三维人脸识别方法即结合人脸表情的分布特点, 将人脸区域划分为表情易变和表情不变区域, 然后分别针对表情不变和表情易变区域设计不同的相似度匹配策略。传统基于区域类方法<citation id="200" type="reference"><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><link href="169" rel="bibliography" /><link href="171" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>如依据关键特征点位置进行人脸区域划分。此类方法将表情不变区域和表情易变区域分开处理, 对表情变化具有较强的适应性, 但是前提是表情不变和表情易变区域的划分要准确, 否则将直接影响此类方法的整体准确度。</p>
                </div>
                <div class="p1">
                    <p id="54">针对基于区域算法存在的比较依赖区域划分精准度以及没有充分利用整个人脸区域的问题, 本文提出了基于语义对齐的多区域融合三维人脸识别方法。相较于以往基于区域类表情不变人脸识别方法, 首先, 本文提出的基于多模板区域划分方法不需要面部特征点辅助, 同时多模板区域相互独立进行相似度预测, 也缓解了算法对单一区域精准划分的依赖性;另外, 基于多区域模板共同投票策略, 不光对表情鲁棒, 对其他受区域影响因素 (如遮挡) 也具有一定的鲁棒性。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">1 三维人脸模型的自动预处理</h3>
                <div class="p1">
                    <p id="56">人脸识别主要针对人脸区域, 因此, 首先要获得精准的人脸区域。为了获得较为可靠的人脸区域, 首先介绍本文采用的三维人脸模型的预处理过程, 如图1所示, 主要包括鼻尖点自动检测、三维人脸切割, 以及姿态矫正和点云稠密对齐等。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 三维人脸模型预处理" src="Detail/GetImg?filename=images/JSJY201906023_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 三维人脸模型预处理  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Preprocessing of 3D face model</p>

                </div>
                <div class="p1">
                    <p id="58">针对三维人脸鼻尖点的自动检测算法有很多。早期, 采集三维人脸模型多为正面姿态, 可根据采集对象与三维扫描仪之间的位置关系, 将距离扫描仪最近的点即人脸上最高的点视为鼻尖点, 如Chang等<citation id="201" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、Sang等<citation id="202" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。对于更一般的情况, Chew等<citation id="203" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了基于曲率的鼻尖点自动检测方法。该鼻尖点检测方法<citation id="204" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>不依赖某一点的曲率, 对鼻尖数据偶有缺失具有较强的鲁棒性。本文采用Chew等<citation id="205" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出的方法自动检测鼻尖点。</p>
                </div>
                <div class="p1">
                    <p id="59">以鼻尖点为中心, 计算任意点 (<i>x</i>, <i>y</i>, <i>z</i>) 与鼻尖点 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 的测地线距离<i>d</i>, 若<i>d</i>≤100 mm, 则保留该点到人脸区域;若<i>d</i>&gt;100 mm, 则丢弃该点, 依次剪切出整个人脸区域。利用测地线距离剪切得到的人脸, 既包括尽可能多的人脸表面信息, 同时又包括较少的背景信息。</p>
                </div>
                <div class="p1">
                    <p id="60">为了对所有人脸数据在相同坐标系下进行比对, 本文借助参考模型 (Reference model) 进行实现。参考模型应具备平均人脸的基本形态<citation id="206" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 本文采用北京工业大学三维人脸数据库BJUT (BeiJing University of Technology) - 3D<citation id="207" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>中已对齐的中性三维人脸数据的平均人脸表示。然后, 将所有注册三维人脸和待测试三维人脸与该参考模型通过最近点迭代 (Iterative Closest Point, ICP) 法<citation id="208" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>进行姿态矫正。</p>
                </div>
                <div class="p1">
                    <p id="61">由于姿态、遮挡、三维扫描仪计算错误等原因, 姿态矫正后的三维人脸可能存在部分数据缺失。本文采用对称填补的方法对缺失人脸数据进行填补, 即假设人脸是对称的, 缺失的部分数据使用相应的对称进行填补。</p>
                </div>
                <div class="p1">
                    <p id="62">最后, 为了确保三维人脸模型与参考模型间具有严密的语义对应关系, 便于后续比对, 本文采用基于ICP的公开代码包——非刚性对齐 (nonrigid registration) 方法<citation id="209" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>将所有三维人脸模型与参考模型进行稠密对齐。此对齐方法只需要初始对齐点 (鼻尖点) , 对人脸模型其他部分区域存在遮挡等鲁棒。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag">2 本文算法</h3>
                <div class="p1">
                    <p id="64">以往基于区域划分的表情鲁棒三维人脸识别算法很难将表情不变区域与表情易变区域准确划分, 主要有两方面原因:首先, 人脸区域的划分通常依赖面部特征点的准确定位, 而三维人脸特征点的定位又是一个尚未完全解决的问题;其次, 对于不同对象三维人脸, 很难严格界定表情不变和表情易变区域。因此, 针对上述分析, 为了解决以往算法对区域划分敏感的问题, 本文根据先验, 提出将人脸区域预划分为多个可重叠的模板区域, 通过预先定义多模板区域的方法, 不但有效缓解了区域难定义以及区域划分不准确的问题 (最后结果由多数投票结果决定, 对少数受表情影响较大区域导致错误投票结果具有一定的鲁棒 (容忍) 性) , 本文提出的多区域模板共同投票机制, 对其他诸如遮挡因素也表现出良好的鲁棒性;然后, 针对每个模板区域, 在人脸的三维结构上直接计算模板区域间的相似度并独立给出匹配结果;最后, 综合多个区域匹配结果, 采用多数投票的方式确定最终的匹配结果。本文所提出的基于语义对齐的多区域融合表情鲁棒三维人脸识别算法总的算法流程如图2所示。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 所提算法流程" src="Detail/GetImg?filename=images/JSJY201906023_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 所提算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Flow chart of proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="66" name="66">2.1 <b>多区域模板设计</b></h4>
                <div class="p1">
                    <p id="67">不同于以往方法根据面部特征点将三维人脸划分为多个表情不变和表情易变区域<citation id="210" type="reference"><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 本文提出基于语义对齐的多区域人脸划分方法。如前文预处理部分所述, 所有注册和待识别三维人脸模型都与参考模型进行了稠密对齐, 即对齐之后的三维人脸拥有相同的点数、相同的拓扑结构, 并且各点之间存在语义上的一一对应关系。</p>
                </div>
                <div class="p1">
                    <p id="68">受表情、遮挡等因素的影响, 即使经过语义对齐的三维人脸模型, 也无法避免由于局部形变导致的同一对象 (类内) 的相似度差异大于不同对象 (类间) 间的相似度的问题。为了减小局部区域形变严重进而影响整体区域相似度计算的问题, 以往算法大多将人脸划分为互不重叠的多个局部区域。考虑一般局部区域的区分度也小, 即使融合多个局部区域对整张人脸识别能力依然有限, 因此本文提出基于易受表情影响区域特性, 将人脸区域划分为多个不含表情影响的模板区域再分别进行匹配, 即基于多模板区域的投票策略。依据易受表情影响区域设计的多表情影响区域去除的模板, 既有效避免了以往依赖特征点的区域划分问题, 同时也得到了多个相对可靠的区域分类器。本文在参考模型上采用的三维模板区域投影如图3 所示, 共计24个模板, 白色代表模板包含数据, 黑色代表模板不包含数据, 其中模版 (1) 为全脸模版。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 所提的模板区域示意图" src="Detail/GetImg?filename=images/JSJY201906023_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 所提的模板区域示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Schematic diagram of proposed template regions</p>

                </div>
                <div class="p1">
                    <p id="70">人脸主要包括眼睛、额头、鼻子、嘴巴、脸颊等区域, 不同区域受表情影响程度不同, 如通常认为额头、鼻子受表情影响较小, 但额头易受帽子、头发等遮挡的影响;眼睛区域易受表情或眼镜遮挡的影响;嘴巴和脸颊受表情影响最大。但是, 考虑不同对象受表情影响区域不同, 不同表情影响人脸区域亦不同, 因此, 本文提出了基于局部区域的不同区域模板划分方法。模板设计思想为:将人脸按照易受表情影响区域划分为多个不同的模板区域, 对于某一对象的某种表情, 显然, 受表情影响小的同一对象区域之间具有较大的相似度, 而部分受表情影响较大的区域则倾向具有较小的相似度;最终的投票结果由多数相似度较大区域投票得到最终识别结果, 即受表情影响较小区域决定, 因此, 该多区域模板融合方法不但对表情遮挡有一定的鲁棒性, 同时对区域划分具有很强的容忍性。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">2.2 <b>区域相似度分类</b></h4>
                <div class="p1">
                    <p id="72">区域相似度就是将待测试三维人脸与注册库中三维人脸之间进行相似度比较, 相似度值最大的最相似。本文共使用24个区域模板, 针对每个模板区域内的三维人脸信息, 都独立进行相似度计算。为了保证算法整体的运行速度以及避免损失三维人脸结构信息, 本文定义人脸区域语义对应坐标点的欧氏距离平方和作为两人脸区域的相似度值, 即:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msqrt><mrow><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>z</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中:<i>p</i> (<i>x</i><sub><i>j</i></sub>, <i>y</i><sub><i>j</i></sub>, <i>z</i><sub><i>j</i></sub>) 为待测试人脸区域中某点;<i>g</i> (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>, <i>z</i><sub><i>i</i></sub>) 为注册库中人脸区域中其语义对应点。相似度值越大, 表示两区域越相似。当相似度值大于一定阈值时, 即判定为同一人脸。</p>
                </div>
                <div class="p1">
                    <p id="75">假设所有测试样本都必将属于注册库中某一样本的闭集人脸数据库。作为人脸识别性能常用指标之一, 本文统计当FAR (False Acceptance Rate) 为定值, 每个区域的真实样本通过率TAR (Truth Acceptance Rate) 来确定每个区域的相似度阈值 (见实验3.2节部分) , 其中FAR=0.1%即为允许千分之一误识率的条件下。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">2.3 <b>多模板区域分类融合</b></h4>
                <div class="p1">
                    <p id="77">关于多分类器融合的方法有很多, 如分数级融合、决策级融合等。本文选用后者, 并按照多数投票机制对多模板分类器投票结果进行融合。主要基于以下两方面考虑:首先, 根据人脸特性将人脸划分为不同的区域, 每个区域之间是相互独立的, 因此, 分类结果也应该相互独立;其次, 当人脸受表情、遮挡等因素影响比较严重时, 受影响严重的这些区域必然具有较小的相似度, 而受影响较小的人脸区域仍然可以得到较高的相似度, 每个区域分别单独投票的好处是少数受影响区域的投票结果并不影响其他不受影响的区域获得准确的分类。</p>
                </div>
                <div class="p1">
                    <p id="78">设区域相似度用<i>S</i><sub><i>i</i></sub>表示, 其对应相似度阈值用<i>T</i><sub><i>i</i></sub>表示, 则每个区域的投票结果表示为:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">然后, 所有模板区域投票数总和与一个总体阈值 (0≤<i>T</i><sub><i>v</i></sub>≤24) 进行比较, 当投票总数大于阈值时, 即认为匹配成功;否则, 匹配失败。计算式表示为:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mi>Ν</mi><mo>&lt;</mo><mi>Τ</mi><msub><mrow></mrow><mi>v</mi></msub></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Ν</mi><mo>≥</mo><mi>Τ</mi><msub><mrow></mrow><mi>v</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">综上, 本文提出表情鲁棒三维人脸识别算法, 基本步骤为:</p>
                </div>
                <div class="p1">
                    <p id="83">1) 确定三维人脸数据库的注册人脸和测试人脸数据集, 其中注册人脸数据集包含每人1个中性表情三维人脸数据。</p>
                </div>
                <div class="p1">
                    <p id="84">2) 对所有注册人脸和测试人脸数据集进行预处理, 并执行稠密对齐。</p>
                </div>
                <div class="p1">
                    <p id="85">3) 计算测试人脸与注册人脸多区域模板的相似度及投票结果。</p>
                </div>
                <div class="p1">
                    <p id="86">4) 对多区域模板投票进行多数投票融合。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="88" name="88">3.1 <b>数据库及实验设置</b></h4>
                <div class="p1">
                    <p id="89">为了测试所提出算法的有效性, 分别在FRGC (the Face Recognition Grand Challenge) v2.0和Bosphorus两个三维人脸数据库上对算法进行评估。</p>
                </div>
                <div class="p1">
                    <p id="90">FRGC v2.0三维人脸数据库<citation id="211" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>:包含不同表情 (六种表情变化) 、姿态、年龄共466人的4 007个三维人脸模型。</p>
                </div>
                <div class="p1">
                    <p id="91">Bosphorus数据库<citation id="212" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>:含有姿态、表情、遮挡变化的105人, 共4 666个三维人脸模型。每人包括13种不同姿态、除中性表情以外的6种不同表情以及4种不同程度的遮挡。</p>
                </div>
                <div class="p1">
                    <p id="92">实验中所有用到的三维人脸模型首先按照第1章介绍的预处理过程进行鼻尖点检测、切割人脸区域、姿态矫正、数据填补以及稠密对齐。</p>
                </div>
                <div class="p1">
                    <p id="93">为了便于与其他方法进行比较, 本文的评价指标选用rank- 1识别率, 即在识别测试过程中, 第一次命中 (最相似人脸即为正确人脸) 正确人脸的概率之和。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">3.2 <b>阈值确定</b></h4>
                <div class="p1">
                    <p id="95">衡量人脸识别算法性能常用的指标是EER (Equal Error Rate) , 即当FAR与FRR (False Rejection Rate) 相等时的取值。EER值越小, 表明识别算法性能越好、越稳定。本文共有<i>T</i><sub><i>i</i></sub> (<i>i</i>=1, 2, … , 24) 和<i>T</i><sub><i>v</i></sub>共25个阈值需要确定。</p>
                </div>
                <div class="p1">
                    <p id="96">以FRGC v2.0数据库为例, 图4 (a) 和 (b) 分别给出了测试集在不同模板区域达到的EER, 以及EER最小时所对应阈值<i>T</i><sub><i>i</i></sub>。EER常用于衡量一个算法的稳定性情况, EER越小则算法稳定性越好。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 固定FAR下各模板区域识别性能和对应阈值" src="Detail/GetImg?filename=images/JSJY201906023_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 固定FAR下各模板区域识别性能和对应阈值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Performance and corresponding thresholds for each templete region with fixed FAR</p>

                </div>
                <div class="p1">
                    <p id="98">从图4 (a) 不难看出, 模板6性能最差 (对应最大的EER值) , 模板18性能最好 (对应最小EER值) 。这是由于:模板6包括了人脸的嘴巴和脸颊区域, 而嘴巴和脸颊是受表情影响最大区域;而模板18则包含人脸的额头和鼻子区域, 这部分是受表情影响较小区域。分析其他区域也不难发现, 一般模板区域较小, 达到的EER值也较小, 如区域13、14、22、23、24, 即是受表情变化较小的鼻子区域, 这也是本文预定义有重叠多区域模板的合理之处;而包含脸颊或嘴巴区域的, 一般达到的EER都相对较大, 如区域6、8、21等。</p>
                </div>
                <div class="p1">
                    <p id="99">图5给出了当<i>T</i><sub><i>v</i></sub>取模板2的阈值即<i>T</i><sub><i>v</i></sub>=4时, 多区域投票融合算法的FAR与FRR相等, 即性能最稳定, 表明投票数至少大于等于4票时, 可认为识别成功。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 多区域融合性能" src="Detail/GetImg?filename=images/JSJY201906023_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 多区域融合性能  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Performance of multi-region fusion</p>

                </div>
                <h4 class="anchor-tag" id="101" name="101">3.3 FRGC v2.0<b>数据库实验结果</b></h4>
                <div class="p1">
                    <p id="102">注册集包含466人的第一个中性表情三维人脸数据, 其余3 541 (包括1 984个中性表情, 1 557个非中性表情) 个人脸数据组成该实验的测试集。</p>
                </div>
                <div class="p1">
                    <p id="103">为了便于与当前最新的基于区域类方法如EI3D (Expression-Invariant 3D) <citation id="213" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、Spherical<citation id="214" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、A-SRC (Adaptive Sparse Representation-based Classifier) <citation id="215" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 以及基于同等形变类方法如3DWW (3D Weighted Walkthroughs) <citation id="216" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Curvature-based <citation id="217" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等方法进行比较, 本文仅计算本文算法的rank- 1识别率, 即在识别测试过程中, 第一次命中 (最相似人脸即为正确人脸) 正确人脸的概率之和。</p>
                </div>
                <div class="p1">
                    <p id="104">图6给出了本文算法在FRGC v2.0上的CMC (Cumulative Match Characteristic) 曲线, 可以看出, 该算法达到了98.69%的rank- 1识别率。表1给出了不同算法分别在FRGC v2.0数据库中含具有表情变化的三维人脸识别库上分别达到的rank- 1识别率。</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906023_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 所提算法在FRGC v2.0数据库上的rank识别率" src="Detail/GetImg?filename=images/JSJY201906023_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 所提算法在FRGC v2.0数据库上的rank识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906023_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Recognition rate of rank of proposed algorithm on FRGC v2.0 database</p>

                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表</b>1 FRGC v2.0<b>数据库上不同算法的</b>rank- 1<b>识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Recognition rate of rank- 1 of different algorithms on FRGC v2.0 database </p>
                    <p class="img_note">%</p>
                    <table id="106" border="1"><tr><td>算法</td><td>rank- 1<br />识别率</td><td></td><td>算法</td><td>rank- 1<br />识别率</td><td></td><td>算法</td><td>rank- 1<br />识别率</td></tr><tr><td>本文算法</td><td>98.69</td><td></td><td>Curvature-based<sup>[10]</sup></td><td>97.51</td><td></td><td>EI3D<sup> [12]</sup></td><td>97.18</td></tr><tr><td><br />3DWW<sup>[6]</sup></td><td>91.40</td><td></td><td>A-SRC<sup>[20]</sup></td><td>98.48</td><td></td><td>Spherical<sup> [13]</sup></td><td>97.90</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="107">由表1不难看出, 同等条件下, 不管是相较于基于同等形变的方法3DWW<citation id="218" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Curvature-based<citation id="219" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 还是基于不重叠多区域方法EI3D<citation id="220" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、 Spherical<citation id="221" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、A-SRC<citation id="222" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 本文算法都取得了最高的人脸识别率。原因是:基于同等形变方法将人脸表情的变化通过等距变化来刻画, 对于非刚性区域, 显然表情引起的三维形变不是等距的, 因此, 很难得到满意的效果;相较其他基于区域的方法, 本文算法不依赖特征点定位进行区域分割, 同时, 本文采用多数投票机制对区域划分体现了较强的容忍度和鲁棒性。</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108">3.4 Bosphorus<b>数据库上实验结果</b></h4>
                <div class="p1">
                    <p id="109">为了更进一步验证本文算法对遮挡因素的有效性, 本文还选择在包含遮挡变化的Bosphorus三维人脸数据库上进行验证。注册集包含105人的一个中性表情三维人脸数据, 其余每人4个含有遮挡 (分别为手、头发和眼镜遮挡) 的三维人脸数据组成该实验的测试集。</p>
                </div>
                <div class="p1">
                    <p id="110">对于三维人脸模型存在遮挡的问题, 通常的处理是首先检测出人脸遮挡区域, 然后再利用其他先验模型重建出遮挡区域人脸。如文献<citation id="223" type="reference">[<a class="sup">23</a>]</citation>算法, 首先将三维人脸转换为二维深度图, 在深度图上通过检测最亮的点及阈值范围内的连通区域法检测遮挡区域, 然后对遮挡区域使用主成分分析 (Principal Component Analysis, PCA) 对遮挡区域进行重建。而文献<citation id="224" type="reference">[<a class="sup">24</a>]</citation>算法, 则将遮挡人脸与平均人脸对齐, 对齐后的人脸区域如果大于某以固定阈值就被认为是遮挡区域并丢弃, 然后采用切线PCA以及Gaussion模型相结合对遮挡区域进行重建。这两个对比方法在检测遮挡人脸区域时, 都需要确定阈值, 阈值的大小直接影响检测遮挡区域的多少, 而且, 固定的阈值也很难适应实际应用种的各种遮挡情况, 缺乏灵活性。本文提出的算法不需要检测遮挡区域, 而是通过预定于多模板区域共同投票, 最后选择多区域数投票统计法决定最终的识别结果。类似于表情情况, 不难发现:模板中受遮挡影响严重的区域必然具有较小的相似度, 而受遮挡影响较小的区域则具有较高的相似度, 多数投票机制使得受遮挡影响较小区域更有发言权, 从而提出的算法对遮挡也表现出一定的鲁棒性。</p>
                </div>
                <div class="p1">
                    <p id="111">表2给出了本文算法法及对比算法<citation id="226" type="reference"><link href="191" rel="bibliography" /><link href="193" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>在Bosphorus数据库存在遮挡情况下达到的rank- 1识别率。由表2可以看出, 本文算法取得了84.36%的rank- 1识别率, 比现有较好的文献<citation id="225" type="reference">[<a class="sup">24</a>]</citation>算法提高了5.73个百分点。表2结果表明, 本文算对遮挡因素也具有很强的鲁棒性, 而且本文算法不需要对遮挡区域检测和重建, 具有良好的灵活性。</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表</b>2 Bosphorus<b>数据库上不同算法的</b>rank- 1<b>识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Recognition rate of rank- 1 of different algorithms on Bosphorus database </p>
                    <p class="img_note">%</p>
                    <table id="112" border="1"><tr><td>算法</td><td>rank- 1<br />识别率</td><td></td><td>算法</td><td>rank- 1<br />识别率</td><td></td><td>算法</td><td>rank- 1<br />识别率</td></tr><tr><td><br />本文算法</td><td>84.36</td><td></td><td>文献[23]算法</td><td>66.66</td><td></td><td>文献[24]算法</td><td>78.63</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="113" name="113" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="114">针对表情对三维人脸模型的影响而导致人脸识别算法性能下降的问题, 本文提出了基于语义对齐的多区域融合的表情鲁棒三维人脸识别算法。该算法借助一个参考模型实现所有三维人脸模型的预处理及模型之间的语义对齐;然后, 依据表情对人脸影响, 设计多个独立的有重叠的人脸区域, 在每个模板区域内分别计算区域相似度并投票;最后, 采用多数投票法决定最终的识别结果。在FRGC v2.0和Bosphorus两个三维人脸数据库上的实验结果表明, 本文算法不但对表情变化鲁棒, 对遮挡也有很好的鲁棒性。我们的下一步工作将研究设计更加有效的区域模板, 并在更多、更复杂三维人脸数据库上进行验证。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="147">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF200807002&amp;v=MDU3NzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjNLTHo3QmFMRzRIdG5NcUk5Rlo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>王跃明, 潘纲, 吴朝晖.三维人脸识别研究综述[J].计算机辅助设计与图形学学报, 2008, 20 (7) :819-829. (WANG Y M, PANG, WU Z H.A survey of 3D face recognition[J].Journal of Computer Aided design&amp;Computer Graphics, 2008, 20 (7) :819-829.) 
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Expression-invariant non-rigid 3D face recognition:a robust approach to expression-aware morphing">

                                <b>[2]</b>Al-OSAIMI F, BENNAMOUN M, MIAN A.Expression-invariant non-rigid 3D face recognition:a robust approach to expression-aware morphing[C]//Proceedings of the 4th International Symposium on3D Data Processing, Visualization, and Transmission.Piscataway, NJ:IEEE, 2008:19-26.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Expressioncompensated 3D face recognition with geodesically aligned bilinear models">

                                <b>[3]</b>MPIPERIS I, MALASSIOTIS S, STRINTZIS M G.Expression-compensated 3D face recognition with geodesically aligned bilinear models[C]//Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Efficient 3D Face Recognition Algorithm">

                                <b>[4]</b>KAUSHIK V D, BUDHWAR A, DUBEY A, et al.An efficient 3Dface recognition algorithm[C]//NTMS 2009:Proceedings of the3rd International Conference on New Technologies, Mobility and Security.Piscataway, NJ:IEEE, 2009:259-263.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Expression-Invariant Representations of Faces">

                                <b>[5]</b>BRONSTEIN A M, BRONSTEIN M M, KIMMEL R.Expressioninvariant representations of faces[J].IEEE Transactions on Image Processing, 2007, 16 (1) :188-197.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Three Dimensional Face RecognitionUsing Iso-Geodesic and Iso-Depth Curves">

                                <b>[6]</b>JAHANBIN S, CHOI H, LIU Y, et al.Three dimensional face recognition using iso-geodesic and iso-depth curves[C]//BTAS2008:Proceedings of the 2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D Face Recognition Using Isogeodesic Stripes">

                                <b>[7]</b>BERRETTI S, DEL BIMBO A, PALA P.3D face recognition using isogeodesic stripes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (12) :2162-2177.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pose and expression-invariant 3D face recognition using elastic radial curves">

                                <b>[8]</b>DRIRA H, BEN AMOR B, DAOUDI M, et al.Pose and expression-invariant 3d face recognition using elastic radial curves[C]//Proceedings of the 2010 British Machine Vision Conference.Durham, UK:BMVA Press, 2010:1-11.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A set of selected SIFT features for3D facial expression recognition">

                                <b>[9]</b>BERRETTI S, del BIMBO A, PALA P, et al.A set of selected SIFT features for 3D facial expression recognition[C]//ICPR2010:Proceedings of the 2010 20th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2010:4125-4128.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regional registration for expression resistant 3-D face recognition">

                                <b>[10]</b>ALYUZ N, GOKBERK B, AKARUN L.Regional registration for expression resistant 3-D face recognition[J].IEEE Transactions on Information Forensics and Security, 2010, 5 (3) :425-440.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600448665&amp;v=MjMxMTMxb2RhQkE9TmlmT2ZiSzhIdERNcVk5RllPOEhDbm84b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>SMEETS D, KEUSTERMANS J, VANDERMEULEN D, et al.mesh SIFT:Local surface features for 3D face recognition under expression variations and partial data[J].Computer Vision and Image Understanding, 2013, 117 (2) :158-169.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBA275E200C4C1FD7CB21FB846113E383&amp;v=MDE2NzJaSmdMZjMxUHV4RmdtRDE4UGczcXFCUTBlTEhoUnJLY0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3eTJ3cW89TmlmT2ZjSEpITmJKMm8xRg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>GUO Y L, LEI Y J, LIU L, et al.EI3D:Expression-invariant 3Dface recognition based on feature and shape matching[J].Pattern Recognition Letters, 2016, 83 (Part 3) :403-412.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nasal patches and curves for expression-robust 3Dface recognition">

                                <b>[13]</b>EMAMBAKHSH M, EVANS A.Nasal patches and curves for expression-robust 3D face recognition[J].IEEE transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (5) :995-1007.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple Nose Region Matching for 3D Face Recognition under Varying Facial Expression">

                                <b>[14]</b>CHANG K I, BOWYER K W, FLYNN P J.Multiple nose region matching for 3D face recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHDCF3B9F64473AC0E149B44BF9CC9E066B&amp;v=MDExNjFyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3kyd3FvPU5pZkRhc0RPSGFQRjJZbEJZT3dNZlE4NXVoY1g0MDE1VEEyVXBXRkdjTWVVUTd6dENPTnZGU2lXVw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>SANG G L, LI J, ZHAO Q J.Pose-invariant face recognition via RGB-D images[J].Computational Intelligence and Neuroscience, 2016 (3) :1-9.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nose Tip Detection on a Three-Dimensional Face Range Image Invariant to Head Pose">

                                <b>[16]</b>CHEW W J, SENG K P, ANG L M.Nose tip detection on a three-dimensional face range image invariant to head pose[C]//Proceedings of the 2009 International Multi Conference of Engineers and Computer Scientists.Hong Kong:International Association of Engineers, 2009:858-862.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fixed FAR vote fusion of regional facial classifiers">

                                <b>[17]</b>SPREEUWERS L J, VELDHUIS R N J, SULTANALI S, et al.Fixed FAR vote fusion of regional facial classifiers[C]//BIOSIG2014:Proceedings of the 2014 International Conference of the BI-Ometrics Special Interest Group.Piscataway, NJ:IEEE, 2014:187-194.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200906020&amp;v=MDE5MTN5L2hXcjNLTHl2U2RMRzRIdGpNcVk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>尹宝才, 孙艳丰, 王成章, 等.BJUT-3D三维人脸数据库及其处理技术[J].计算机研究与发展, 2009, 46 (6) :1009-1018. (YIN B C, SUN Y F, WANG C Z, et al.BJUT-3D large scale3D face database and information processing[J].Journal of Computer Research and Development, 2009, 46 (6) :1009-1018.) 
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimal Step Nonrigid ICP Algorithms for Surface Registration">

                                <b>[19]</b>AMBERG B, ROMDHANI S, VETTER T.Optimal step nonrigid ICP algorithms for surface registration[C]//CVPR 2007:Proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1-8.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D face recognition in the presence of expression:a guidance-based constraint deformation approach">

                                <b>[20]</b>WANG Y M, PAN G, WU Z H.3D face recognition in the presence of expression:a guidance-based constraint deformation approach[C]//CVPR 2007:Proceedings of the 2007 Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2007:1180-1187.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bosphorus database for3D face analysis">

                                <b>[21]</b>SAVRAN A, ALYUZ N, DIBEKLIOGLU H, et al.Bosphorus database for 3D face analysis[C]//Proceedings of the 2008 European Workshop on Biometrics and Identity Management, LNCS5372.Berlin:Springer, 2008:47-56.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6A425D751D6FDC505959BC5CF2D001FB&amp;v=MTQ0MDVTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzd5Mndxbz1OajdCYXJYSkd0UEoyNGhBWlo4SmVnaEt5aFlXNHpwME9nem4zMlEzRGJLVVJNenRDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>DENG X, DA F P, SHAO H J.Adaptive feature selection based on reconstruction residual and accurately located landmarks for expression-robust 3D face recognition[J].Signal, Image and Video Processing, 2017, 11 (7) :1305-1312.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust 3Dface recognition in presence of pose and partial occlusions or missing parts">

                                <b>[23]</b>BAGCHI P, BHATTACHARJEE D, NASIPURI M.Robust 3Dface recognition in presence of pose and partial occlusions or missing parts[J].International Journal in Foundations of Computer Science&amp;Technology, 2014, 4 (4) :21-35.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJMS&amp;filename=SJMSFA8BE2896B68CEF35DB3135C068C32B8&amp;v=MTAxNzNTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzd5Mndxbz1OaWZHZmNYSkZxTzVyWWRNWXBrSkJBOU11UlVXbmsxK1NYem4zeEl6Y2NHWFI4aVhDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>GANGULY S, BHATTACHARJEE D, NASIPURI M.Depth based occlusion detection and localization from 3D face image[J].International Journal of Image, Graphics&amp;Signal Processing, 2015, 7 (5) :20-31.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906023" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906023&amp;v=MTkwNzFzRnkvaFdyM0tMejdCZDdHNEg5ak1xWTlIWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
