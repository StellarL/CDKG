<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136674714377500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906012%26RESULT%3d1%26SIGN%3dyEeaHAjY2Ef7wtmN8sywVppKOIg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906012&amp;v=MTg3MDNVUjdxZlp1WnNGeS9oVmJ2UEx6N0JkN0c0SDlqTXFZOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="1 极限学习机与去噪自编码器 ">1 极限学习机与去噪自编码器</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="1.1 &lt;b&gt;极限学习机&lt;/b&gt;">1.1 <b>极限学习机</b></a></li>
                                                <li><a href="#72" data-title="1.2 &lt;b&gt;去噪自编码器&lt;/b&gt;">1.2 <b>去噪自编码器</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="2 基于去噪自编码器的极限学习机 ">2 基于去噪自编码器的极限学习机</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="3 实验结果及分析 ">3 实验结果及分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#104" data-title="3.1 &lt;b&gt;实验环境&lt;/b&gt;">3.1 <b>实验环境</b></a></li>
                                                <li><a href="#106" data-title="3.2 &lt;b&gt;实验数据&lt;/b&gt;">3.2 <b>实验数据</b></a></li>
                                                <li><a href="#109" data-title="3.3 &lt;b&gt;结果分析&lt;/b&gt;">3.3 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="图1 ELM网络结构">图1 ELM网络结构</a></li>
                                                <li><a href="#74" data-title="图2 &lt;i&gt;DAE&lt;/i&gt;网络结构">图2 <i>DAE</i>网络结构</a></li>
                                                <li><a href="#77" data-title="图3 退化过程">图3 退化过程</a></li>
                                                <li><a href="#95" data-title="图4 DAE-ELM网络结构">图4 DAE-ELM网络结构</a></li>
                                                <li><a href="#96" data-title="图5 DAE-ELM系统图">图5 DAE-ELM系统图</a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验数据集&lt;/b&gt;"><b>表</b>1 <b>实验数据集</b></a></li>
                                                <li><a href="#120" data-title="图6 &lt;i&gt;ELM&lt;/i&gt;隐含层节点数对分类错误率的影响">图6 <i>ELM</i>隐含层节点数对分类错误率的影响</a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;i&gt;DAE&lt;/i&gt;-&lt;i&gt;ELM&lt;/i&gt;&lt;b&gt;的参数设定&lt;/b&gt;"><b>表</b>2 <i>DAE</i>-<i>ELM</i><b>的参数设定</b></a></li>
                                                <li><a href="#122" data-title="图7 DAE-ELM隐含层节点数对分类错误率的影响">图7 DAE-ELM隐含层节点数对分类错误率的影响</a></li>
                                                <li><a href="#125" data-title="图8 不同算法分类错误率变化趋势">图8 不同算法分类错误率变化趋势</a></li>
                                                <li><a href="#130" data-title="图9 不同&lt;i&gt;v&lt;/i&gt;下退化后的样本">图9 不同<i>v</i>下退化后的样本</a></li>
                                                <li><a href="#131" data-title="图10 不同&lt;i&gt;v&lt;/i&gt;下的输入权值">图10 不同<i>v</i>下的输入权值</a></li>
                                                <li><a href="#134" data-title="图11 退化率对DAE-ELM性能的影响">图11 退化率对DAE-ELM性能的影响</a></li>
                                                <li><a href="#141" data-title="表3 不同算法分类错误率对比  ">表3 不同算法分类错误率对比  </a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="173">


                                    <a id="bibliography_1" title="HUANG G B, ZHU Q Y, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1/2/3) :489-501." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913101&amp;v=MDg5NDZkR2VycVFUTW53WmVadEZpbmxVcjNJSjFvU2JoVT1OaWZPZmJLN0h0RE5xbzlFYmVvTURYdzRvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        HUANG G B, ZHU Q Y, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1/2/3) :489-501.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_2" title="HUANG G B, CHEN L, SIEW C K.Universal approximation using incremental constructive feedforward networks with random hidden nodes[J].IEEE Transactions on Neural Networks, 2006, 17 (4) :879-892." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Universal approximation using incremental constructive feedforward networks with random hidden nodes">
                                        <b>[2]</b>
                                        HUANG G B, CHEN L, SIEW C K.Universal approximation using incremental constructive feedforward networks with random hidden nodes[J].IEEE Transactions on Neural Networks, 2006, 17 (4) :879-892.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_3" title="HUANG G B, ZHOU H M, DING X J, et al.Extreme learning machine for regression and multiclass classification[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 2012, 42 (2) :513-529." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extreme Learning Machine for Regression and Multiclass Classification">
                                        <b>[3]</b>
                                        HUANG G B, ZHOU H M, DING X J, et al.Extreme learning machine for regression and multiclass classification[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 2012, 42 (2) :513-529.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_4" title="ZONG W W, HUANG G B, CHEN Y Q.Weighted extreme learning machine for imbalance learning[J].Neurocomputing, 2013, 101:229-242." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369807&amp;v=MzEyNTJlcnFRVE1ud1plWnRGaW5sVXIzSUoxb1NiaFU9TmlmT2ZiSzhIdERNcVk5RlorMEdCSHcrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        ZONG W W, HUANG G B, CHEN Y Q.Weighted extreme learning machine for imbalance learning[J].Neurocomputing, 2013, 101:229-242.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_5" title="LIANG N Y, HUANG G B, SARATCHANDRAN P, et al.A fast and accurate online sequential learning algorithm for feedforward networks[J].IEEE Transactions on Neural Networks, 2006, 17 (6) :1411-1423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Fast and Accurate Online Sequential Learning Algorithm for Feedforward Networks">
                                        <b>[5]</b>
                                        LIANG N Y, HUANG G B, SARATCHANDRAN P, et al.A fast and accurate online sequential learning algorithm for feedforward networks[J].IEEE Transactions on Neural Networks, 2006, 17 (6) :1411-1423.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_6" title="LAN Y, HU Z J, SOH Y C, et al.An extreme learning machine approach for speaker recognition[J].Neural Computing and Applications, 2013, 22 (3/4) :417-425." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409074776&amp;v=MTQyMDVsb1ROajdCYXJLN0h0WE1wbzlDWU93SUNoTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3ak1K&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        LAN Y, HU Z J, SOH Y C, et al.An extreme learning machine approach for speaker recognition[J].Neural Computing and Applications, 2013, 22 (3/4) :417-425.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_7" title="王光华, 李素梅, 朱丹, 等.极端学习机在立体图像质量客观评价中的应用[J].光电子&#183;激光, 2014, 25 (9) :1837-1842. (WANG G H, LI S M, ZHU D, et al.Application of extreme learning machine in objective stereoscopic image quality assessment[J].Journal of Optoelectronics&#183;Laser, 2014, 25 (9) :1837-1842.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201409032&amp;v=MDkwMjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oVmJ2UElpblJaTEc0SDlYTXBvOUdab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        王光华, 李素梅, 朱丹, 等.极端学习机在立体图像质量客观评价中的应用[J].光电子&#183;激光, 2014, 25 (9) :1837-1842. (WANG G H, LI S M, ZHU D, et al.Application of extreme learning machine in objective stereoscopic image quality assessment[J].Journal of Optoelectronics&#183;Laser, 2014, 25 (9) :1837-1842.) 
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_8" title="XU Y, DAI Y Y, DONG Z Y, et al.Extreme learning machinebased predictor for real-time frequency stability assessment of electric power systems[J].Neural Computing and Applications, 2013, 22 (3/4) :501-508." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409074761&amp;v=MjgzMzB2bktyaWZaZVp2RnlublU3ak1KbG9UTmo3QmFySzdIdFhNcG85Q1lPd0pEUk04enhVU21EZDlTSDduM3hFOWZi&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        XU Y, DAI Y Y, DONG Z Y, et al.Extreme learning machinebased predictor for real-time frequency stability assessment of electric power systems[J].Neural Computing and Applications, 2013, 22 (3/4) :501-508.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_9" title="HORATA P, CHIEWCHANWATTANA S, SUNAT K.Robust extreme learning machine[J].Neurocomputing, 2013, 102:31-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369828&amp;v=MTIzNTZaZVp0RmlubFVyM0lKMW9TYmhVPU5pZk9mYks4SHRETXFZOUZaKzBHQkg0eG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        HORATA P, CHIEWCHANWATTANA S, SUNAT K.Robust extreme learning machine[J].Neurocomputing, 2013, 102:31-44.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_10" title="RONG H J, ONG Y S, TAN A H, et al.A fast pruned-extreme learning machine for classification problem[J].Neurocomputing, 2008, 72 (1/2/3) :359-366." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501912392&amp;v=MjA1MTZaZVp0RmlubFVyM0lKMW9TYmhVPU5pZk9mYks3SHRETnFvOUViZW9ORDNVN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        RONG H J, ONG Y S, TAN A H, et al.A fast pruned-extreme learning machine for classification problem[J].Neurocomputing, 2008, 72 (1/2/3) :359-366.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_11" title="CHARAMA L L, ZHOU H, HUANG G B.Representational learning with ELMs for big data[J].IEEE Intelligent Systems, 2013, 28 (6) :31-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Representational learning with ELMs for big data">
                                        <b>[11]</b>
                                        CHARAMA L L, ZHOU H, HUANG G B.Representational learning with ELMs for big data[J].IEEE Intelligent Systems, 2013, 28 (6) :31-34.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_12" title="TANG J X, DENG C W, HUANG G B.Extreme learning machine for multilayer perceptron[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (4) :809-821" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extreme Learning Machine for Multilayer Perceptron">
                                        <b>[12]</b>
                                        TANG J X, DENG C W, HUANG G B.Extreme learning machine for multilayer perceptron[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (4) :809-821
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_13" title="ZHU W T, MIAO J, QING L Y, et al.Hierarchical extreme learning machine for unsupervised representation learning[C]//Proceedings of the 2015 International Joint Conference on Neural Networks.Piscataway, NJ:IEEE, 2015:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical extreme learning machine for unsupervised representation learning">
                                        <b>[13]</b>
                                        ZHU W T, MIAO J, QING L Y, et al.Hierarchical extreme learning machine for unsupervised representation learning[C]//Proceedings of the 2015 International Joint Conference on Neural Networks.Piscataway, NJ:IEEE, 2015:1-8.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_14" title="YANG Y M, WU Q M J.Multilayer extreme learning machine with subnetwork nodes for representation learning[J].IEEETransactions on Cybernetics, 2016, 46 (11) :2570-2583." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multilayer extreme learning machine with subnetwork nodes for representation learning">
                                        <b>[14]</b>
                                        YANG Y M, WU Q M J.Multilayer extreme learning machine with subnetwork nodes for representation learning[J].IEEETransactions on Cybernetics, 2016, 46 (11) :2570-2583.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_15" title="VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C]//ICML 2008:Proceedings of the 25th International Conference on Machine Learning.New York:ACM, 2008:1096-1103." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">
                                        <b>[15]</b>
                                        VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C]//ICML 2008:Proceedings of the 25th International Conference on Machine Learning.New York:ACM, 2008:1096-1103.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_16" title="HUANG G, HUANG G B, SONG S J, et al.Trends in extreme learning machines:a review[J].Neural Networks, 2015, 61:32-48." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0091E92409773BFF5DBE972B8B716F6&amp;v=MDQ1ODg1dHBodzd5NXhLOD1OaWZPZmNhNEh0ak4yb1pIWU9zR0MzczZ2V0JsNzBzUFBYYmxybUE5QzdXVlE4eVpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        HUANG G, HUANG G B, SONG S J, et al.Trends in extreme learning machines:a review[J].Neural Networks, 2015, 61:32-48.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_17" title="郭旭东, 李小敏, 敬如雪, 等.基于改进的稀疏去噪自编码器的入侵检测[J].计算机应用, 2019, 39 (3) :769-773. (GUO XD, LI X M, JING R X, et al.Intrusion detection based on improved sparse denoising autoencoder[J].Journal of Computer Applications, 2019, 39 (3) :769-773.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903025&amp;v=MTQ4NTdCdEdGckNVUjdxZlp1WnNGeS9oVmJ2UEx6N0JkN0c0SDlqTXJJOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        郭旭东, 李小敏, 敬如雪, 等.基于改进的稀疏去噪自编码器的入侵检测[J].计算机应用, 2019, 39 (3) :769-773. (GUO XD, LI X M, JING R X, et al.Intrusion detection based on improved sparse denoising autoencoder[J].Journal of Computer Applications, 2019, 39 (3) :769-773.) 
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                    LECUN Y, BOTTOU L, BENGIO Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.</a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_19" title="XIAO H, RASUL K, VOLLGRAF R.Fashion-MNIST:a novel image dataset for benchmarking machine learning algorithms[EB/OL].[2018-09-15].https://arxiv.org/pdf/1708.07747.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fashion-MNIST:a novel image dataset for benchmarking machine learning algorithms">
                                        <b>[19]</b>
                                        XIAO H, RASUL K, VOLLGRAF R.Fashion-MNIST:a novel image dataset for benchmarking machine learning algorithms[EB/OL].[2018-09-15].https://arxiv.org/pdf/1708.07747.pdf.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_20" title="ERHAN D.Rectangles Data[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Rectangles Data." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rectangles Data">
                                        <b>[20]</b>
                                        ERHAN D.Rectangles Data[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Rectangles Data.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_21" title="ERHAN D.Recognition of convex sets[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Convex Non Convex." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recognition of convex sets">
                                        <b>[21]</b>
                                        ERHAN D.Recognition of convex sets[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Convex Non Convex.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_22" title="肖冬, 王继春, 潘孝礼, 等.基于改进PCA-ELM方法的穿孔机导盘转速测量[J].控制理论与应用, 2010, 27 (1) :19-24. (XIAO D, WANG J C, PAN X L, et al.Modeling and control of guide-disk speed of rotary piercer[J].Control Theory&amp;amp;Applications, 2017, 27 (1) :19-24.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZLY201001005&amp;v=MTc0NzQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hWYnZQTGpmSGQ3RzRIOUhNcm8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        肖冬, 王继春, 潘孝礼, 等.基于改进PCA-ELM方法的穿孔机导盘转速测量[J].控制理论与应用, 2010, 27 (1) :19-24. (XIAO D, WANG J C, PAN X L, et al.Modeling and control of guide-disk speed of rotary piercer[J].Control Theory&amp;amp;Applications, 2017, 27 (1) :19-24.) 
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_23" title="马萌萌.基于深度学习的极限学习机算法研究[D].青岛:中国海洋大学, 2015:28-30. (MA M M.Research on Extreme learning machine algorithm based on deep learning[D].Qingdao:Ocean University of China, 2015:28-30.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015715563.nh&amp;v=MzIwMjl1WnNGeS9oVmJ2UFZGMjZHN1M1RzlUS3JKRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        马萌萌.基于深度学习的极限学习机算法研究[D].青岛:中国海洋大学, 2015:28-30. (MA M M.Research on Extreme learning machine algorithm based on deep learning[D].Qingdao:Ocean University of China, 2015:28-30.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-09 13:44</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1619-1625 DOI:10.11772/j.issn.1001-9081.2018112246            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于去噪自编码器的极限学习机</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A5%E6%9D%B0&amp;code=41987895&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">来杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%99%93%E4%B8%B9&amp;code=20635728&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王晓丹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%9D%BF&amp;code=20108907&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李睿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%8C%AF%E5%86%B2&amp;code=32098878&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵振冲</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A9%BA%E5%86%9B%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E9%98%B2%E7%A9%BA%E5%8F%8D%E5%AF%BC%E5%AD%A6%E9%99%A2&amp;code=0274788&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空军工程大学防空反导学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对极限学习机算法 (ELM) 参数随机赋值降低算法鲁棒性及性能受噪声影响显著的问题, 将去噪自编码器 (DAE) 与ELM算法相结合, 提出了基于去噪自编码器的极限学习机算法 (DAE-ELM) 。首先, 通过去噪自编码器产生ELM的输入数据、输入权值与隐含层参数;然后, 以ELM求得隐含层输出权值, 完成对分类器的训练。该算法一方面继承了DAE的优点, 自动提取的特征更具代表性与鲁棒性, 对于噪声有较强的抑制作用;另一方面克服了ELM参数赋值的随机性, 增强了算法鲁棒性。实验结果表明, 在不含噪声影响下DAE-ELM相较于ELM、PCA-ELM、SAA-2算法, 其分类错误率在MNIST数据集中至少下降了5.6%, 在Fashion MNIST数据集中至少下降了3.0%, 在Rectangles数据集中至少下降了2.0%, 在Convex数据集中至少下降了12.7%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9E%81%E9%99%90%E5%AD%A6%E4%B9%A0%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">极限学习机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E5%99%AA%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去噪自编码器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征降维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%B2%81%E6%A3%92%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁棒性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    来杰 (1994—) , 男, 四川简阳人, 硕士研究生, 主要研究方向:机器学习、智能信息处理;;
                                </span>
                                <span>
                                    *王晓丹 (1966—) , 女, 陕西汉中人, 教授, 博士, 主要研究方向:机器学习、智能信息处理;afeu_wxd@ 163. com;
                                </span>
                                <span>
                                    李睿 (1992—) , 男, 山西岢岚人, 博士研究生, 主要研究方向:机器学习、智能信息处理;;
                                </span>
                                <span>
                                    赵振冲 (1990—) , 男, 河南周口人, 博士研究生, 主要研究方向:机器学习、智能信息处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61876189, 61806219);</span>
                    </p>
            </div>
                    <h1><b>Denoising autoencoder based extreme learning machine</b></h1>
                    <h2>
                    <span>LAI Jie</span>
                    <span>WANG Xiaodan</span>
                    <span>LI Rui</span>
                    <span>ZHAO Zhenchong</span>
            </h2>
                    <h2>
                    <span>College of Air and Missile Defense, Air Force Engineering University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to solve the problem that parameter random assignment reduces the robustness of the algorithm and the performance is significantly affected by noise of Extreme Learning Machine (ELM) , combining Denoising AutoEncoder (DAE) with ELM algorithm, a DAE based ELM (DAE-ELM) algorithm was proposed. Firstly, a denoising autoencoder was used to generate the input data, input weight and hidden layer parameters of ELM. Then, the hidden layer output was obtained through ELM to complete the training of classifier. On the one hand, the advantages of DAE were inherited by the algorithm, which means the features extracted automatically were more representative and robust and were impervious to noise. On the other hand, the randomness of parameter assignment of ELM was overcome and the robustness of the algorithm was improved. The experimental results show that, compared to ELM, Principal Component Analysis ELM (PCA-ELM) , SAA-2, the classification error rate of DAE-ELM at least decreases 5.6% on MNIST, 3.0% on Fashion MINIST, 2.0% on Rectangles and 12.7% on Convex.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Extreme%20Learning%20Machine%20(ELM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Extreme Learning Machine (ELM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20leaning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep leaning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Denoising%20AutoEncoder%20(DAE)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Denoising AutoEncoder (DAE) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=robustness&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">robustness;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LAI Jie, born in 1994, M. S. candidate. His research interests include machine learning, intelligent information processing. ;
                                </span>
                                <span>
                                    WANG Xiaodan, born in 1966, Ph. D. , professor. Her research interests include machine learning, intelligent information processing. ;
                                </span>
                                <span>
                                    LI Rui, born in 1992, Ph. D. candidate. His research interests include machine learning, intelligent information processing. ;
                                </span>
                                <span>
                                    ZHAO Zhenchong, born in 1990, Ph. D. candidate. His research interests include machine learning, intelligent information processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61876189, 61806219);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="50">作为单隐含层前馈神经网络 (Single Hidden Layer Feedforward Neural Network, SLFN) 的最新研究成果, 极限学习机 (Extreme Learning Machine, ELM) <citation id="219" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>自被提出以来, 凭借泛化性能优、训练时间短等特点, 引起了研究者们的密切关注。同一般SLFN方法相比较, ELM的隐含层参数均为随机产生, 无需进行反复的迭代, 而且其输出权值为求解最小二次方程所得的全局最优解, 避免了陷入局部最优解的困境。Huang等<citation id="220" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>证明了ELM的一致逼近性和ELM可直接应用于回归与多分类问题<citation id="221" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。同时, 为处理非平衡数据的学习问题, Zong等<citation id="222" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>通过引入类别权值, 提出了加权极限学习机 (Weighted ELM, W-ELM) 。Liang等<citation id="223" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出的在线贯序极限学习机 (Online Sequential ELM, OS-ELM) , 延伸ELM至在线学习问题, 拓宽了其实际应用领域。目前, ELM在语音识别<citation id="224" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、图像评价<citation id="225" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、电力系统<citation id="226" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等部分模式识别应用领域已得到初步应用。</p>
                </div>
                <div class="p1">
                    <p id="51">但是当参数完全随机选择时, 为保证ELM的分类性能需要大量的隐含层节点<citation id="227" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。对此, 学者们提出可以利用构造或剪枝的方式对隐含层节点进行参数优化, 以提高ELM整体性能<citation id="230" type="reference"><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。Horata等<citation id="228" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>通过将满足最小LOO (Leave-One-Out) 误差准则的节点加入隐含层, 实现对隐含层的参数优化, 提出了增长型鲁棒极限学习机 (Robust Incremental ELM, RI-ELM) 。Rong等<citation id="229" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出的快速剪枝极限学习机 (Pruned ELM, P-ELM) , 利用统计学原理, 裁剪对分类性能影响较小的隐含层节点, 以实现算法优化。但在实际应用中, 此类方法对识别正确率的提升有限, 这是因为基于构造或剪枝的优化方法其基本思想仍局限于传统ELM框架。当数据维数大或存在噪声干扰时, 采用单一隐含层进行特征映射的方式并不适用于处理所有样本。所以, 如何提升ELM算法对高维含噪声样本的识别性能是当前亟待解决的重点问题。</p>
                </div>
                <div class="p1">
                    <p id="52">近年来, 深度学习在高维数据特征提取方面的突出表现, 使得许多的学者尝试将ELM与深度学习结合起来, 以提升ELM算法性能。Chamara等<citation id="231" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>将极限学习机与自编码器 (AutoEncoder, AE) 结合起来, 提出的极限学习机自编码器 (ELM-AutoEncoder, ELM-AE) 拥有良好的特征表达能力。基于ELM-AE, Tang等<citation id="232" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了分层极限学习机 (Hierarchical ELM, H-ELM) 算法, 以逐层编码实现特征的高阶表示, 相较于其他多层感知器, 其训练更快速、准确率更高。同时, 其他的深度极限学习机算法<citation id="233" type="reference"><link href="197" rel="bibliography" /><link href="199" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>也为提高ELM处理高维数据的能力做出了贡献。</p>
                </div>
                <div class="p1">
                    <p id="53">去噪自编码器 (Denoising AutoEncoder, DAE) <citation id="234" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>较其他自编码器, 提取的抽象特征更具代表性与鲁棒性, 拥有较强的抗噪能力。受深度极限学习机算法启发, 本文将DAE与ELM相结合, 提出基于去噪自编码器的极限学习机 (DAE based ELM, DAE-ELM) 算法, 用堆叠DAE先产生ELM的输入数据, 然后产生输入层权值及隐含层参数, 克服了传统ELM参数赋值的随机性, 增强了其鲁棒性及抗噪能力。实验结果表明, 对于典型高维数据集, 无论是否存在噪声影响, DAE-ELM比传统ELM算法和AE算法的分类性能有明显的提升。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">1 极限学习机与去噪自编码器</h3>
                <h4 class="anchor-tag" id="55" name="55">1.1 <b>极限学习机</b></h4>
                <div class="p1">
                    <p id="56">ELM是以SLFN为基础而提出的一种高效的机器学习方法, 同时考虑了分类正确率以及网络拓扑结构之间的平衡。假设ELM输入层节点数为<i>n</i>, 隐含层节点数为<i>l</i>, 输出层节点数为<i>m</i>。其网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 ELM网络结构" src="Detail/GetImg?filename=images/JSJY201906012_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 ELM网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Network structure of ELM</p>

                </div>
                <div class="p1">
                    <p id="58">对于给定的<i>N</i>个任意不同样本 (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>t</i></b><sub><i>i</i></sub>) , 其中<b><i>x</i></b><sub><i>i</i></sub>= (<i>x</i><sub><i>i</i>1</sub>, <i>x</i><sub><i>i</i>2</sub>, …, <i>x</i><sub><i>in</i></sub>) ∈<b>R</b><sup><i>n</i></sup>, <b><i>t</i></b><sub><i>i</i></sub>= (<i>t</i><sub><i>i</i>1</sub>, <i>t</i><sub><i>i</i>2</sub>, …, <i>t</i><sub><i>im</i></sub>) ∈<b>R</b><sup><i>m</i></sup>, 则ELM的输出为:</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mi mathvariant="bold-italic">β</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>; <i>j</i>=1, 2, …, <i>N</i>      (1) </p>
                </div>
                <div class="p1">
                    <p id="61">其中:<b><i>w</i></b><sub><i>i</i></sub>= (<i>w</i><sub><i>i</i>1</sub>, <i>w</i><sub><i>i</i>2</sub>, …, <i>w</i><sub><i>in</i></sub>) <sup>T</sup>为隐含层节点<i>i</i>与输入层节点的权值向量;<i>β</i><sub><i>i</i></sub>= (<i>β</i><sub><i>i</i>1</sub>, <i>β</i><sub><i>i</i>2</sub>, …, <i>β</i><sub><i>im</i></sub>) <sup>T</sup>为隐含层节点<i>i</i>与输出层节点之间的权值向量;<b><i>b</i></b><sub><i>i</i></sub>为隐含层节点<i>i</i>的偏置;<i>g</i> (·) 为隐含层节点的激活函数。由于ELM具有一致逼近性, 则系统的矩阵表达式为:</p>
                </div>
                <div class="p1">
                    <p id="62"><b><i>H</i></b><i>β</i>=<b><i>T</i></b>      (2) </p>
                </div>
                <div class="p1">
                    <p id="63">其中:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Η</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">) </mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msub><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>l</mi></mrow></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">β</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">β</mi><msubsup><mrow></mrow><mn>1</mn><mtext>Τ</mtext></msubsup></mtd><mtd><mi mathvariant="bold-italic">β</mi><msubsup><mrow></mrow><mn>2</mn><mtext>Τ</mtext></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">β</mi><msubsup><mrow></mrow><mi>l</mi><mtext>Τ</mtext></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mo>×</mo><mi>m</mi></mrow><mtext>Τ</mtext></msubsup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Τ</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mn>1</mn><mtext>Τ</mtext></msubsup></mtd><mtd><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mn>2</mn><mtext>Τ</mtext></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mi>Ν</mi><mtext>Τ</mtext></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msubsup><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>m</mi></mrow><mtext>Τ</mtext></msubsup></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">训练ELM就是得到该系统的最小二乘解<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">β</mi><mo>^</mo></mover></math></mathml>, 即:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Η</mi><mover accent="true"><mi mathvariant="bold-italic">β</mi><mo>^</mo></mover><mo>-</mo><mi mathvariant="bold-italic">Τ</mi><mo stretchy="false">∥</mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">β</mi></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Η</mi><mi mathvariant="bold-italic">β</mi><mo>-</mo><mi mathvariant="bold-italic">Τ</mi><mo stretchy="false">∥</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中:<b><i>H</i></b>为隐含层的输出矩阵;<b><i>T</i></b>为样本的期望输出。在不考虑正则化时, 其计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">β</mi><mo>^</mo></mover><mo>=</mo><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mi>ɫ</mi></msup><mi mathvariant="bold-italic">Τ</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">其中:<b><i>H</i></b><sup>ɫ</sup>为<b><i>H</i></b>的Moore-Penrose广义逆, 常采用正交法计算。当<b><i>H</i></b><b><i>H</i></b><sup>T</sup>非奇异时, <b><i>H</i></b><sup>ɫ</sup>= (<b><i>H</i></b><sup>T</sup><b><i>H</i></b>) <sup>-1</sup><b><i>H</i></b><sup>T</sup>;当<b><i>H</i></b><sup>T</sup><b><i>H</i></b>非奇异时, <b><i>H</i></b><sup>ɫ</sup>=<b><i>H</i></b><sup>T</sup> (<b><i>H</i></b><sup>T</sup><b><i>H</i></b>) <sup>-1</sup>。</p>
                </div>
                <div class="p1">
                    <p id="71">与传统分类器相比, ELM在确保良好识别准确率的基础上, 极大地减少了训练时间;但是其输入权值与隐含层参数赋值的随机性降低了算法鲁棒性, 且当样本存在噪声时, ELM算法性能将明显下降<citation id="235" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。本文将去噪自编码器与ELM结合, 其目的就是克服ELM的这些缺陷, 以提高ELM性能。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">1.2 <b>去噪自编码器</b></h4>
                <div class="p1">
                    <p id="73"><i>DAE</i>是对自编码器的改进, 其最大特点是在进行特征提取之前, 加入了对原始样本数据的退化过程<citation id="236" type="reference"><link href="205" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 其结构如图2所示。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 DAE网络结构" src="Detail/GetImg?filename=images/JSJY201906012_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 <i>DAE</i>网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Network structure of DAE</i></p>

                </div>
                <div class="p1">
                    <p id="75">在<i>DAE</i>中, 退化过程是指对于每一个样本, 按照一定比例将其属性值置为0或其他值, 这个比例被称作退化率。退化过程如图3所示 (对于灰度图像, 置0意味着置黑) 。</p>
                </div>
                <div class="p1">
                    <p id="76"><i>DAE</i>加入退化过程的自然原理是人眼在看物体时, 如果物体某一小部分被遮住了, 人依然能将其识别出来<citation id="237" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。该现象说明人所带有的“生物”自编码器所提取的特征更具有代表性与鲁棒性, 对于输入的含有一定噪声的样本数据, 它经过编码、解码后仍能得到纯净无噪的样本。这要求自编码器不仅有编码功能, 还要有去噪作用。然而, 即使数据中含有的噪声, <i>AE</i>却只能重构含有噪声的输入数据。所以, 对原始样本进行适当的退化处理, 再让自编码器重构原始样本, 如此提取的特征更本质、更抗干扰<citation id="238" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 退化过程" src="Detail/GetImg?filename=images/JSJY201906012_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 退化过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Degenerative process</i></p>

                </div>
                <div class="p1">
                    <p id="78"><i>DAE</i>的学习过程包括退化、编码和解码三个阶段。首先, 对输入数据按比例随机置0进行退化, 得到退化数据。然后, 对退化数据完成编码得到编码层。最后, 解码编码层, 得到输入数据的重构, 通过调整各层参数使重构误差函数达到最小值, 以获得输入特征的最优抽象表示。</p>
                </div>
                <div class="p1">
                    <p id="79">假设给定输入特征向量<b><i>x</i></b>∈<b>R</b><sup><i>n</i>×<i>l</i></sup>, 去噪自编码器首先按照一定比例<i>v</i>对输入样本随机置0, 得到退化输入特征向量<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˜</mo></mover></math></mathml>。然后通过线性映射和非线性激活函数完成对退化数据的编码:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">h</mi><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˜</mo></mover><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">其中:<b><i>W</i></b>∈<b>R</b><sup><i>n</i>×<i>d</i></sup>是编码层<b><i>h</i></b>与输入层<b><i>x</i></b>之间的权值矩阵;<i>n</i>为编码层的特征数;<b><i>b</i></b><sub>1</sub>∈<b>R</b><sup><i>n</i></sup>为编码层节点偏置;<i>g</i> (·) 为节点激活函数, 如sigmoid函数。</p>
                </div>
                <div class="p1">
                    <p id="83">最后, 解码器完成对编码特征的解码, 得到输入数据的重构<b><i>z</i></b>。当给定编码<b><i>h</i></b>时, <b><i>z</i></b>也可以看作对<b><i>x</i></b>的预测, 与<b><i>x</i></b>的维度相同。解码过程与编码过程类似:</p>
                </div>
                <div class="p1">
                    <p id="84"><b><i>z</i></b>=<i>g</i> (<b><i>W</i></b><sup>T</sup><b><i>h</i></b>+<b><i>b</i></b><sub>2</sub>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="85">其中<b><i>b</i></b><sub>2</sub>∈<b>R</b><sup><i>d</i></sup>为解码层偏置。<b><i>z</i></b>与<b><i>x</i></b>的重构误差函数为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>, </mo><mi mathvariant="bold-italic">Ζ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">其中:<b><i>X</i></b>、<b><i>Z</i></b>分别为训练数据与重构数据。去噪自编码器利用误差的反向传播算法以调整网络参数, 通过迭代使重构误差函数达到最小值, 以学习样本数据中的关键抽象特征。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">2 基于去噪自编码器的极限学习机</h3>
                <div class="p1">
                    <p id="89"><i>ELM</i>性能受样本数据维数、噪声影响大, 且其鲁棒性因参数随机赋值而降低。而<i>DAE</i>所提取的特征更本质、噪声敏感性更低, 所以结合<i>DAE</i>与<i>ELM</i>, 由<i>DAE</i>获得<i>ELM</i>的输入样本、输入权值与隐含层参数, 一方面可以提高分类器处理高维含噪声数据的能力, 另外一方面可以提高分类器的鲁棒性。</p>
                </div>
                <div class="p1">
                    <p id="90"><i>DAE</i>-<i>ELM</i>的网络结构及如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="91"><i>DAE</i>-<i>ELM</i>的学习过程如下:</p>
                </div>
                <div class="p1">
                    <p id="92">1) 训练第一去噪自编码器网络, 提取出原始输入数据的去噪抽象特征, 以作为<i>ELM</i>的输入数据。该网络结构如图4中<i>DAE</i>1所示, 根据1.2节中所述, 令<i>DAE</i>的输出数据与输入数据相同, 通过反向传播算法进行训练。当重构误差函数最小时, 得到最优网络参数:输入层权值<b><i>w</i></b><sub>1</sub>, 隐含层偏置<b><i>b</i></b><sub>1</sub>及隐含层输出<b><i>h</i></b><sub>1</sub>。<b><i>h</i></b><sub>1</sub>为输入特征的高级抽象表示, 这些抽象特征剔除了输入数据中的冗余信息, 而且过滤了其中部分噪声, 且当输入数据维度较高时, 可以起到降低数据维度的作用。将<b><i>h</i></b><sub>1</sub>作为ELM的输入数据, 有利于提升ELM性能。</p>
                </div>
                <div class="p1">
                    <p id="93">2) 训练第二去噪自编码器网络, 生成ELM输入权值和隐含层参数。该网络结构如图4中的DAE2所示, 与第一去噪自编码器训练相似, 只是将DAE的输出数据与输入数据均置为第一去噪自编码器的隐含层输出<b><i>h</i></b><sub>1</sub>。训练完毕后, 得到第二去噪自编码器的最优网络参数:输入层权值<b><i>w</i></b><sub>2</sub>, 隐含层偏置<b><i>b</i></b><sub>2</sub>及隐含层输出<b><i>h</i></b><sub>2</sub>。将其作为ELM的网络参数, 可以避免输入层权值与隐含层参数随机赋值所造成的性能和鲁棒性下降问题。</p>
                </div>
                <div class="p1">
                    <p id="94">3) 训练ELM作为整个网络的辨别模型。ELM结构如图5中的ELM模块所示, 其输入数据为第一去噪自编码器的隐含层输出矩阵<b><i>h</i></b><sub>1</sub>, 即原始输入数据的去噪抽象特征表示, 其输入层权值与隐含层输出为第二去噪自编码器的输入层权值<b><i>w</i></b><sub>2</sub>与隐含层输出<b><i>h</i></b><sub>2</sub>, 然后根据1.1节中所述理论训练ELM, 即求解ELM隐含层输出权值<i>β</i>, 从而完成整个网络的训练。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 DAE-ELM网络结构" src="Detail/GetImg?filename=images/JSJY201906012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 DAE-ELM网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Network structure of DAE-ELM</p>

                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 DAE-ELM系统图" src="Detail/GetImg?filename=images/JSJY201906012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 DAE-ELM系统图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 System diagram of DAE-ELM</p>

                </div>
                <div class="p1">
                    <p id="97">综上, 基于去噪自编码器的极限学习机训练算法如下。</p>
                </div>
                <div class="p1">
                    <p id="98">输入 经过预处理的训练数据<b><i>x</i></b>与类别标签<b><i>t</i></b>;</p>
                </div>
                <div class="p1">
                    <p id="99">输出 网络最优参数值<b><i>w</i></b><sub>1</sub>, <b><i>b</i></b><sub>1</sub>, <b><i>h</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, <b><i>b</i></b><sub>2</sub>, <b><i>h</i></b><sub>2</sub>, <i>β</i>。</p>
                </div>
                <div class="p1">
                    <p id="100">步骤1 输入数据<b><i>x</i></b>, 利用反向传播算法训练第一去噪自编码器, 得到网络输入层权值<b><i>w</i></b><sub>1</sub>, 第一隐含层偏置<b><i>b</i></b><sub>1</sub>及输出<b><i>h</i></b><sub>1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="101">步骤2 将第一隐含层输出<b><i>h</i></b><sub>1</sub>作为输入数据, 训练第二去噪自编码器, 得到网络第一隐含层输出权值<b><i>w</i></b><sub>2</sub>, 第二隐含层偏置<b><i>b</i></b><sub>2</sub>及输出<b><i>h</i></b><sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="102">步骤3 将<b><i>h</i></b><sub>1</sub>作为ELM的输入数据, <b><i>w</i></b><sub>2</sub>作为输入权值, <b><i>h</i></b><sub>2</sub>作为隐含层输出, 求解ELM隐含层输出权值<i>β</i>, 即网络第二隐含层输出权值<i>β</i>。 <i>β</i>的计算公式为:当<b><i>h</i></b><sub>2</sub><b><i>h</i></b><sup>T</sup><sub>2</sub>非奇异时, <i>β</i>= (<b><i>h</i></b><sup>T</sup><sub>2</sub><b><i>h</i></b><sub>2</sub>) <sup>-1</sup><b><i>h</i></b><sup>T</sup><sub>2</sub><b><i>t</i></b>;当<b><i>h</i></b><sup>T</sup><sub>2</sub><b><i>h</i></b><sub>2</sub>非奇异时, <i>β</i>=<b><i>h</i></b><sup>T</sup><sub>2</sub> (<b><i>h</i></b><sup>T</sup><sub>2</sub><b><i>h</i></b><sub>2</sub>) <sup>-1</sup><b><i>t</i></b>。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">3 实验结果及分析</h3>
                <h4 class="anchor-tag" id="104" name="104">3.1 <b>实验环境</b></h4>
                <div class="p1">
                    <p id="105">实验平台为<i>Intel i</i>7-7700<i>K</i> 4.2 <i>GHz</i>, 16 <i>GB</i>内存和1 <i>TB</i>硬盘的<i>PC</i>, 实验在<i>Windows</i> 7系统上用<i>Matlab</i> 2017 (<i>b</i>) 实现。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">3.2 <b>实验数据</b></h4>
                <div class="p1">
                    <p id="107"><i>DAE</i>-<i>ELM</i>算法旨在提升<i>ELM</i>在高维含声噪数据下的泛化性能, 在本文中采用<i>MNIST</i><citation id="239" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、<i>Fashion MNIST</i><citation id="240" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、<i>Rectangles</i><citation id="241" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>和<i>Convex</i><citation id="242" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>等数据集作为实验数据, 并分别加入10%高斯白噪声与10%椒盐噪声到各数据集生成含噪声的新数据集, 其详细信息如表1所示。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表</b>1 <b>实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Datasets used in experiments</i></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td>名称</td><td>分类描述</td><td>输入</td><td>种类数</td><td>训练集样本数</td><td>测试集样本数</td></tr><tr><td><i>MNIST</i></td><td>区分0到9之间的手写数字</td><td>维数:28×28, 输入值∈ (0, 1) </td><td>10</td><td>60 000</td><td>10 000</td></tr><tr><td><br /><i>Fashion MNIST</i></td><td>区分衣、裤等不同类型商品</td><td>维数:28×28, 输入值∈ (0, 1) </td><td>10</td><td>60 000</td><td>10 000</td></tr><tr><td><br /><i>Rectangles</i></td><td>区分图像中白色区域是高的长方形还是宽的长方形</td><td>维数:28×28, 输入值∈ (0, 1) </td><td>2</td><td>1 200</td><td>50 000</td></tr><tr><td><br /><i>Convex</i></td><td>区分图像中白色区域是凸的还是非凸的</td><td>维数:28×28, 输入值∈ (0, 1) </td><td>2</td><td>8 000</td><td>50 000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">3.3 <b>结果分析</b></h4>
                <div class="p1">
                    <p id="110">为测试所提出模型的性能, 设计了以下实验 (需要强调的是, 本文中所有实验结果皆为重复实验10次后的均值) 。</p>
                </div>
                <div class="p1">
                    <p id="111">实验1 网络结构确定以及与其他<i>ELM</i>算法在无噪声<i>MNIST</i>数据集下的性能对比分析。</p>
                </div>
                <div class="p1">
                    <p id="112">实验2 退化率对模型性能的影响分析。</p>
                </div>
                <div class="p1">
                    <p id="113">实验3 与其他算法在有噪声和无噪声环境下的性能对比分析。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114">3.3.1 网络结构确定与性能对比分析</h4>
                <div class="p1">
                    <p id="115">对于神经网络结构, 即隐含层层数、节点数的确定在目前为止暂无明确的理论指导, 学者们普遍采用试错法, 按照一定准则改变网络结构进行重复实验, 然后采用性能最优的网络结构。因为本文需进行性能对比实验, 隐层节点数目的不同将对模型性能对比的客观性产生影响, 所以各模型网络隐层节点数应尽可能相同。</p>
                </div>
                <div class="p1">
                    <p id="116">因为<i>DAE</i>-<i>ELM</i>含有两层隐含层, 难以同时确实两层节点数, 又因为第二隐含层实为<i>ELM</i>的隐含层, 所以本文首先根据原始<i>ELM</i>算法隐含层节点个数对分类性能的影响以确定<i>DAE</i>-<i>ELM</i>第二隐含层节点数, 然后再根据<i>DAE</i>-<i>ELM</i>第一隐含层节点数对分类性能的影响情况, 确定其节点数。最后在进行对比实验时, 观察隐含层节点数对各模型分类性能的影响, 以判别各模型性能。</p>
                </div>
                <div class="p1">
                    <p id="117">首先, 使用<i>MNIST</i>数据集中的训练样本训练<i>ELM</i>模型, 并使用测试集进行测试, 观察分类性能随隐含层节点数的变化趋势, 其中节点个数取值范围为{100, 200, …, 2 000}。性能趋势图如图6所示。</p>
                </div>
                <div class="p1">
                    <p id="118">根据图6不难发现, 随着隐含层节点数的增加, <i>ELM</i>的训练与测试分类错误率都在逐步下降, 且下降趋势逐渐放缓, 符合<i>ELM</i>的一致逼近性。但是在保证一定分类正确率的前提下, 理应考虑网络的紧凑性, 减少时间与空间复杂度。在图6中, 当节点数等于1 500时, 分类错误率较低, 网络较紧凑, 而且错误率下降趋势已较为缓慢, 所以假定隐含层节点数为1 500, 即<i>DAE</i>-<i>ELM</i>第二隐含层节点数为1 500。</p>
                </div>
                <div class="p1">
                    <p id="119">假定<i>DAE</i>-<i>ELM</i>第二隐含层节点个数为1 500后, 根据重复实验的方法确定其第一隐含层节点个数。<i>DAE</i>-<i>ELM</i>的基本参数设定如表2所示, 分类性能随第一隐含层节点数变化情况如图7所示。</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 ELM隐含层节点数对分类错误率的影响" src="Detail/GetImg?filename=images/JSJY201906012_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 <i>ELM</i>隐含层节点数对分类错误率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Influence of number of ELM hidden nodes on</i><i>classification error rate</i></p>

                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表</b>2 <i>DAE</i>-<i>ELM</i><b>的参数设定</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Parameter setting of DAE</i>-<i>ELM</i></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />参数变量</td><td>取值</td></tr><tr><td><br />学习速率</td><td>0.5</td></tr><tr><td><br />训练集特征提取次数<i>epoch</i></td><td>5</td></tr><tr><td><br />激活函数</td><td>sigmoid</td></tr><tr><td><br />退化率<i>v</i></td><td>0.1</td></tr><tr><td><br />隐含层节点数<i>HUssage</i></td><td>{50, 100, …, 500}</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 DAE-ELM隐含层节点数对分类错误率的影响" src="Detail/GetImg?filename=images/JSJY201906012_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 DAE-ELM隐含层节点数对分类错误率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Influence of number of DAE-ELM hidden nodes on classification error rate</p>

                </div>
                <div class="p1">
                    <p id="123">由图7可以发现, 随着第一隐含层节点数的递增, DAE-ELM的分类错误率先上升后下降, 而后再上升。这表明当第二隐含层节点数固定, 而第一隐含层节点数逐步增加时, DAE-ELM分类性能的变化并不是一个单调的过程, 存在一个或多个最优节点数, 使得DAE-ELM分类错误率最低, 如图7中隐含层节点数为200时。</p>
                </div>
                <div class="p1">
                    <p id="124">当固定DAE-ELM的第一隐含层节点数为200后, 进行DAE-ELM与ELM、K-ELM (Kernel ELM) <citation id="243" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、PCA-ELM (Principal Component Analysis ELM) <citation id="244" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>算法的性能对比分析, 观察各算法性能随隐含层节点数增加的变化情况。其中各算法参数设定为:K-ELM中<i>KernelParam</i>=0.1, PCA-ELM取前200维, 其累计贡献率为96.89%, DAE-AE参数不变。不同算法的分类性能如图8所示。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法分类错误率变化趋势" src="Detail/GetImg?filename=images/JSJY201906012_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同算法分类错误率变化趋势  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Trend of classification error rate of different algorithms</p>

                </div>
                <div class="p1">
                    <p id="126">观察图8可以发现, DAE-ELM算法性能在数据集未添加噪声的情况下, 性能优于其他ELM算法, 尤其在隐含层节点数低于1 500时, 性能优势明显。DAE-ELM分类错误率的降低主要有以下三点原因:1) 与其他ELM相比, DAE-ELM由DAE生成ELM的输入权值与隐含层参数, 避免了算法随机赋值的偶然性, 提高了算法的鲁棒性, 且比K-ELM采用核函数方法优化隐含层输出的方法更优;2) 与ELM, K-ELM相比, DAE-ELM中DAE起到了特征降维的作用, 有利于剔除数据中的冗余信息, 将其作为输入数据, 有利于提高ELM性能;3) 与PCA-ELM相比, DAE的特征降维并不是将部分特征删除, 而是发掘特征间的关联信息, 将其抽象为更高级的特征, 这些高级抽象特征更能体现事物的本质, 有利于降低分类错误率。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">3.3.2 退化率影响实验</h4>
                <div class="p1">
                    <p id="128">退化率是<i>DAE</i>中的重要参数, 它直接关系到编码器所提取的高级抽象特征, 进而影响算法性能。在本次实验中, 将着重分析不同退化率对输入样本、特征提取、分类性能的影响。</p>
                </div>
                <div class="p1">
                    <p id="129">实验数据为未加噪声<i>MNIST</i>数据, <i>DAE</i>-<i>ELM</i>网络结构为784- 200- 1 500- 10, 退化率<i>v</i>={0, 0.1, 0.4}, 其余参数与3.3.1节实验相同 (当<i>v</i>=0时, DAE-ELM算法即为AE-ELM<citation id="245" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>算法) 。当<i>v</i>取不同值, 输入样本、输入权值如图9～10所示。</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同v下退化后的样本" src="Detail/GetImg?filename=images/JSJY201906012_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同<i>v</i>下退化后的样本  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Samples degenerated with different <i>v</i></p>

                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同v下的输入权值" src="Detail/GetImg?filename=images/JSJY201906012_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 不同<i>v</i>下的输入权值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Input weights with different <i>v</i></p>

                </div>
                <div class="p1">
                    <p id="132">由图9可以看出, 随着退化率<i>v</i>的增加, 经退化后的样本所加入的噪声越多, 样本失真越严重。但从图10可以发现, 当<i>v</i>=0.1时, 输入权值较未经过退化情况下的更清晰分明, 这是因为经过退化后, 为使得重构误差函数达到最小值, DAE必须尽可能地发掘更本质、鲁棒的高级抽象特征, 促进其对重构数据的作用, 进而降低次要特征的影响。发掘更加本质、鲁棒的高级抽象特征对模型性能有促进作用。当<i>v</i>=0.4时, 过高的退化率导致样本失真严重, 输入权值更加模糊, 使得提取的特征不能很好地识别不同类别样本的差异, 这对模型是不利的。所以, 将模型退化率控制在合理范围内, 这对DAE-ELM模型具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="133">为进一步确定合理的退化率范围, 接下来测试当其余参数不变, <i>v</i>={0, 0.05, 0.1, …, 0.5}范围内对MNIST数据集的分类性能, 其测试结果如图11所示。</p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906012_134.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 退化率对DAE-ELM性能的影响" src="Detail/GetImg?filename=images/JSJY201906012_134.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 退化率对DAE-ELM性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906012_134.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Influence of degenerative rate on performance of DAE-ELM</p>

                </div>
                <div class="p1">
                    <p id="135">从图11可以发现, 当<i>v</i>≤0.25时, DAE-ELM分类错误率处于一个震荡过程, 且<i>v</i>=0.1时, 训练与测试分类错误率均达到最低值;当<i>v</i>&gt;0.25时, 错误率明显上升。由此可见, 针对MNIST数据集, DAE-ELM中<i>v</i>的合理范围为[0, 0.25], 最佳取值为0.1。模型性能变化大致分为三个阶段:1) 当<i>v</i>&lt;0.1时, 分类错误率先上升后下降, 这是因为提取高级抽象特征对于模型性能的促进作用与退化过程相比是滞后的, 当<i>v</i>较低时, 高级特征的促进作用弱于退化过程的抑制作用, 随着<i>v</i>的增加, 促进作用增加并强于抑制作用, 模型性能逐渐提高, 直到<i>v</i>取到最优值, 模型性能达到最佳。2) 当0.1≤<i>v</i>≤0.25时, 高级抽象特征的促进作用与退化过程的抑制作用不相上下, 模型性能无明显变化。3) 当<i>v</i>&gt;0.25时, 模型性能大幅度下降, 这是因为退化过程造成失真严重, 以至于提取的特征并不能很好表示原始样本, 从而影响模型性能。所以, 对样本数据进行合理范围内的退化有助于提升模型性能。</p>
                </div>
                <h4 class="anchor-tag" id="136" name="136">3.3.3 多算法性能对比分析</h4>
                <div class="p1">
                    <p id="137">为验证<i>DAE</i>-<i>ELM</i>的综合性能, 在本节实验中, 将采用对上述4个数据集及其分别添加10%高斯白噪声与10%椒盐噪声后的8个数据集, 共12个数据集进行<i>DAE</i>-<i>ELM</i>与其他算法的性能比较。其中<i>ELM</i>、<i>PCA</i>-<i>ELM</i>、<i>SAA</i>-2<citation id="246" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、<i>DAE</i>-<i>ELM</i>网络结构分别为:784- 1 500- <i>X</i>, 784- 1 500- <i>X</i>, 784- 200- 200- <i>X</i> (为重复实验后性能最佳的结构) , 784- 200- 1 500- <i>X</i>, 其中<i>X</i>为类别数。各算法其余参数与实验1中相同 (<i>SAA</i>-2参数与<i>DAE</i>-<i>ELM</i>相同) 。各算法分类错误率如表3所示。</p>
                </div>
                <div class="p1">
                    <p id="138">由表3可以发现, 当隐含层节点数较少时, 绝大多数数据集下<i>DAE</i>-<i>ELM</i>的分类错误率皆低于其余算法, 且加入噪声对<i>DAE</i>-<i>ELM</i>性能的影响也较弱。在不含噪声影响下, <i>DAE</i>-<i>ELM</i>相较于<i>ELM</i>、<i>PCA</i>-<i>ELM</i>、<i>SAA</i>-2算法, 其分类错误率在<i>MNIST</i>数据集中至少下降了5.6%, 在<i>Fashion MNIST</i>数据集中至少下降了3.0%, 在<i>Rectangles</i>数据集中至少下降了2.0%, 在<i>Convex</i>数据集中至少下降了12.7%。</p>
                </div>
                <div class="p1">
                    <p id="139">性能分析如下:1) <i>DAE</i>-<i>ELM</i>性能优于<i>ELM</i>、<i>PCA</i>-<i>ELM</i>, 是因为<i>DAE</i>-<i>ELM</i>避免了隐含层随机赋值, 且其提取特征并不是舍弃部分特征, 而是将其融合为更能体现数据本质、更具鲁棒性的高级抽象低维特征。2) <i>DAE</i>-<i>ELM</i>性能优于<i>SAA</i>-2, 一方面是因为<i>ELM</i>具有一致逼近性, 随着隐含层节点数的增加, 能逼近任意函数;另一方面是因为<i>DAE</i>在<i>AE</i>中加入的退化过程使得提取的高级抽象特征更具代表性和鲁棒性。3) 但在个别含噪声数据中, <i>PCA</i>-<i>ELM</i>性能优于<i>DAE</i>-<i>ELM</i>, 其原因可能是因为<i>PCA</i>在去掉部分维度时, 将包含其中的噪声一并去除, 大幅度减少了噪声对<i>PCA</i>-<i>ELM</i>性能的影响。</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit">表3 不同算法分类错误率对比   <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">表3 Classification error rate comparison of different algorithms </p>
                    <p class="img_note">%</p>
                    <table id="141" border="1"><tr><td colspan="2"><br />数据集</td><td><i>ELM</i></td><td><i>PCA</i>-<i>ELM</i></td><td><i>SAA</i>-2</td><td><i>DAE</i>-<i>ELM</i></td></tr><tr><td rowspan="3"><i>MNIST</i></td><td>未添加噪声</td><td> 5.40</td><td> 6.05</td><td> 5.35</td><td> 5.05</td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td></tr><tr><td><br />10%高斯白噪声</td><td>6.10</td><td>6.17</td><td>6.50</td><td>5.41</td></tr><tr><td><br />10%椒盐噪声</td><td>11.49</td><td>8.51</td><td>8.81</td><td>9.52</td></tr><tr><td rowspan="3"><i>Fashion</i><br /><i>MNIST</i></td><td>未添加噪声</td><td>14.18</td><td>14.12</td><td>14.91</td><td>13.70</td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td></tr><tr><td><br />10%高斯白噪声</td><td>15.94</td><td>15.40</td><td>15.66</td><td>14.95</td></tr><tr><td><br />10%椒盐噪声</td><td>19.42</td><td>17.32</td><td>18.31</td><td>18.11</td></tr><tr><td rowspan="3"><i>Rectangles</i></td><td>未添加噪声</td><td>30.98</td><td>29.44</td><td>30.43</td><td>28.85</td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td></tr><tr><td><br />10%高斯白噪声</td><td>32.39</td><td>29.23</td><td>31.74</td><td>30.12</td></tr><tr><td><br />10%椒盐噪声</td><td>43.21</td><td>36.26</td><td>36.67</td><td>34.23</td></tr><tr><td rowspan="3"><i>Convex</i></td><td>未添加噪声</td><td>34.73</td><td>38.33</td><td>35.20</td><td>30.32</td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td><td rowspan="3"></td></tr><tr><td><br />10%高斯白噪声</td><td>36.07</td><td>39.02</td><td>39.59</td><td>34.00</td></tr><tr><td><br />10%椒盐噪声</td><td>42.72</td><td>42.63</td><td>42.10</td><td>35.58</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="142">综上, 无论是否存在一定噪声干扰, <i>DAE</i>-<i>ELM</i>对输入数据进行退化, 然后提取更加本质、鲁棒性更好的高级抽象低维特征用于识别, 并将优化后的网络参数赋予<i>ELM</i>隐含层, 避免随机赋值偶然性的机制是可行的、合理的。</p>
                </div>
                <h3 id="143" name="143" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="144">针对<i>ELM</i>隐含层参数随机赋值降低算法鲁棒性以及传统<i>ELM</i>处理高维含噪数据性能欠佳的问题, 本文提出了基于去噪自编码器的极限学习机 (<i>DAE</i>-<i>ELM</i>) 算法。首先通过堆叠的<i>DAE</i>分别产生<i>ELM</i>输入数据、隐含层参数, 然后通过<i>ELM</i>算法求解隐含层输出权值, 完成对网络的训练。实验结果表明, 不管高维数据是否含有一定噪声, <i>DAE</i>-<i>ELM</i>算法相较传统<i>ELM</i>算法与自编码器算法, 其分类错误率得到了较大的下降, 同时提供了拓宽<i>ELM</i>与深度学习算法结合的思路。但<i>DAE</i>-<i>ELM</i>为保持良好的泛化能力, 仍然需要一定量的隐含层节点数作为支撑, 这需要今后进一步的研究加以改善。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="173">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913101&amp;v=MjgyNjd3WmVadEZpbmxVcjNJSjFvU2JoVT1OaWZPZmJLN0h0RE5xbzlFYmVvTURYdzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>HUANG G B, ZHU Q Y, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1/2/3) :489-501.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Universal approximation using incremental constructive feedforward networks with random hidden nodes">

                                <b>[2]</b>HUANG G B, CHEN L, SIEW C K.Universal approximation using incremental constructive feedforward networks with random hidden nodes[J].IEEE Transactions on Neural Networks, 2006, 17 (4) :879-892.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extreme Learning Machine for Regression and Multiclass Classification">

                                <b>[3]</b>HUANG G B, ZHOU H M, DING X J, et al.Extreme learning machine for regression and multiclass classification[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 2012, 42 (2) :513-529.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369807&amp;v=MDgwODRKMW9TYmhVPU5pZk9mYks4SHRETXFZOUZaKzBHQkh3K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>ZONG W W, HUANG G B, CHEN Y Q.Weighted extreme learning machine for imbalance learning[J].Neurocomputing, 2013, 101:229-242.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Fast and Accurate Online Sequential Learning Algorithm for Feedforward Networks">

                                <b>[5]</b>LIANG N Y, HUANG G B, SARATCHANDRAN P, et al.A fast and accurate online sequential learning algorithm for feedforward networks[J].IEEE Transactions on Neural Networks, 2006, 17 (6) :1411-1423.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409074776&amp;v=MTMwMDJYTXBvOUNZT3dJQ2hNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5uVTdqTUpsb1ROajdCYXJLN0h0&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>LAN Y, HU Z J, SOH Y C, et al.An extreme learning machine approach for speaker recognition[J].Neural Computing and Applications, 2013, 22 (3/4) :417-425.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201409032&amp;v=MDkwMjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hWYnZQSWluUlpMRzRIOVhNcG85R1pvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>王光华, 李素梅, 朱丹, 等.极端学习机在立体图像质量客观评价中的应用[J].光电子·激光, 2014, 25 (9) :1837-1842. (WANG G H, LI S M, ZHU D, et al.Application of extreme learning machine in objective stereoscopic image quality assessment[J].Journal of Optoelectronics·Laser, 2014, 25 (9) :1837-1842.) 
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409074761&amp;v=MTQ1ODBGeW5uVTdqTUpsb1ROajdCYXJLN0h0WE1wbzlDWU93SkRSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>XU Y, DAI Y Y, DONG Z Y, et al.Extreme learning machinebased predictor for real-time frequency stability assessment of electric power systems[J].Neural Computing and Applications, 2013, 22 (3/4) :501-508.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369828&amp;v=MjEwNDYvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxb1NiaFU9TmlmT2ZiSzhIdERNcVk5RlorMEdCSDR4b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>HORATA P, CHIEWCHANWATTANA S, SUNAT K.Robust extreme learning machine[J].Neurocomputing, 2013, 102:31-44.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501912392&amp;v=MDIxNjBGaW5sVXIzSUoxb1NiaFU9TmlmT2ZiSzdIdEROcW85RWJlb05EM1U3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>RONG H J, ONG Y S, TAN A H, et al.A fast pruned-extreme learning machine for classification problem[J].Neurocomputing, 2008, 72 (1/2/3) :359-366.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Representational learning with ELMs for big data">

                                <b>[11]</b>CHARAMA L L, ZHOU H, HUANG G B.Representational learning with ELMs for big data[J].IEEE Intelligent Systems, 2013, 28 (6) :31-34.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extreme Learning Machine for Multilayer Perceptron">

                                <b>[12]</b>TANG J X, DENG C W, HUANG G B.Extreme learning machine for multilayer perceptron[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (4) :809-821
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical extreme learning machine for unsupervised representation learning">

                                <b>[13]</b>ZHU W T, MIAO J, QING L Y, et al.Hierarchical extreme learning machine for unsupervised representation learning[C]//Proceedings of the 2015 International Joint Conference on Neural Networks.Piscataway, NJ:IEEE, 2015:1-8.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multilayer extreme learning machine with subnetwork nodes for representation learning">

                                <b>[14]</b>YANG Y M, WU Q M J.Multilayer extreme learning machine with subnetwork nodes for representation learning[J].IEEETransactions on Cybernetics, 2016, 46 (11) :2570-2583.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">

                                <b>[15]</b>VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C]//ICML 2008:Proceedings of the 25th International Conference on Machine Learning.New York:ACM, 2008:1096-1103.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0091E92409773BFF5DBE972B8B716F6&amp;v=Mjc4ODZqTjJvWkhZT3NHQzNzNnZXQmw3MHNQUFhibHJtQTlDN1dWUTh5WkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3eTV4Szg9TmlmT2ZjYTRIdA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>HUANG G, HUANG G B, SONG S J, et al.Trends in extreme learning machines:a review[J].Neural Networks, 2015, 61:32-48.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903025&amp;v=MTY5OTQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hWYnZQTHo3QmQ3RzRIOWpNckk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>郭旭东, 李小敏, 敬如雪, 等.基于改进的稀疏去噪自编码器的入侵检测[J].计算机应用, 2019, 39 (3) :769-773. (GUO XD, LI X M, JING R X, et al.Intrusion detection based on improved sparse denoising autoencoder[J].Journal of Computer Applications, 2019, 39 (3) :769-773.) 
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                LECUN Y, BOTTOU L, BENGIO Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fashion-MNIST:a novel image dataset for benchmarking machine learning algorithms">

                                <b>[19]</b>XIAO H, RASUL K, VOLLGRAF R.Fashion-MNIST:a novel image dataset for benchmarking machine learning algorithms[EB/OL].[2018-09-15].https://arxiv.org/pdf/1708.07747.pdf.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rectangles Data">

                                <b>[20]</b>ERHAN D.Rectangles Data[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Rectangles Data.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recognition of convex sets">

                                <b>[21]</b>ERHAN D.Recognition of convex sets[DB/OL].[2018-09-15].http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/Convex Non Convex.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZLY201001005&amp;v=MTIyNzA1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFZidlBMamZIZDdHNEg5SE1ybzlGWVlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>肖冬, 王继春, 潘孝礼, 等.基于改进PCA-ELM方法的穿孔机导盘转速测量[J].控制理论与应用, 2010, 27 (1) :19-24. (XIAO D, WANG J C, PAN X L, et al.Modeling and control of guide-disk speed of rotary piercer[J].Control Theory&amp;Applications, 2017, 27 (1) :19-24.) 
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015715563.nh&amp;v=MzExMTE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oVmJ2UFZGMjZHN1M1RzlUS3JKRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>马萌萌.基于深度学习的极限学习机算法研究[D].青岛:中国海洋大学, 2015:28-30. (MA M M.Research on Extreme learning machine algorithm based on deep learning[D].Qingdao:Ocean University of China, 2015:28-30.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906012" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906012&amp;v=MTg3MDNVUjdxZlp1WnNGeS9oVmJ2UEx6N0JkN0c0SDlqTXFZOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
