<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136482736377500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909050%26RESULT%3d1%26SIGN%3deLtxaLgT3Gwdh4g3TYfO6HPTtjE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909050&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909050&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909050&amp;v=MDE1NjU3RzRIOWpNcG85QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WYnJBTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 研究现状 ">1 研究现状</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 算法分析 ">2 算法分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="2.1 &lt;b&gt;传统的&lt;/b&gt;&lt;i&gt;K&lt;/i&gt;NN&lt;b&gt;算法&lt;/b&gt;">2.1 <b>传统的</b><i>K</i>NN<b>算法</b></a></li>
                                                <li><a href="#50" data-title="2.2 &lt;b&gt;本文采用的改进&lt;/b&gt;&lt;i&gt;K&lt;/i&gt;NN&lt;b&gt;算法&lt;/b&gt;">2.2 <b>本文采用的改进</b><i>K</i>NN<b>算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="3 实验分析 ">3 实验分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="3.1 &lt;b&gt;实验数据处理&lt;/b&gt;">3.1 <b>实验数据处理</b></a></li>
                                                <li><a href="#85" data-title="3.2 &lt;b&gt;实验流程&lt;/b&gt;">3.2 <b>实验流程</b></a></li>
                                                <li><a href="#87" data-title="3.3 &lt;b&gt;实验结果&lt;/b&gt;">3.3 <b>实验结果</b></a></li>
                                                <li><a href="#97" data-title="3.4 &lt;b&gt;整体实验结论分析&lt;/b&gt;">3.4 <b>整体实验结论分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="图1 当样本空间加入新样本时的计算">图1 当样本空间加入新样本时的计算</a></li>
                                                <li><a href="#64" data-title="图2 在改进的&lt;i&gt;K&lt;/i&gt;NN算法样本空间加入新样本 (当新样本点特征很明显时)">图2 在改进的<i>K</i>NN算法样本空间加入新样本 (当新样本点特征很明显时)</a></li>
                                                <li><a href="#65" data-title="图3 在改进的&lt;i&gt;K&lt;/i&gt;NN算法样本空间加入新样本时 (当新样本点特征不明显时)">图3 在改进的<i>K</i>NN算法样本空间加入新样本时 (当新样本点特征不明显时)</a></li>
                                                <li><a href="#67" data-title="图4 改进&lt;i&gt;K&lt;/i&gt;NN可能得到的划分结果">图4 改进<i>K</i>NN可能得到的划分结果</a></li>
                                                <li><a href="#69" data-title="图5 改进的&lt;i&gt;K&lt;/i&gt;NN算法划分结果再进行处理 (可疑点暂不划分分组)">图5 改进的<i>K</i>NN算法划分结果再进行处理 (可疑点暂不划分分组)</a></li>
                                                <li><a href="#70" data-title="图6 改进的&lt;i&gt;K&lt;/i&gt;NN算法划分结果再进行处理 (将相似的可疑点划分为新分组)">图6 改进的<i>K</i>NN算法划分结果再进行处理 (将相似的可疑点划分为新分组)</a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;未对数据进行预处理的结果&lt;/b&gt;"><b>表</b>1 <b>未对数据进行预处理的结果</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;对数据预处理标准化成正态分布的结果&lt;/b&gt;"><b>表</b>2 <b>对数据预处理标准化成正态分布的结果</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;对数据预处理归一化到&lt;/b&gt;[0,1]&lt;b&gt;的结果&lt;/b&gt;"><b>表</b>3 <b>对数据预处理归一化到</b>[0,1]<b>的结果</b></a></li>
                                                <li><a href="#99" data-title="图7 不同算法实验结果比较">图7 不同算法实验结果比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="113">


                                    <a id="bibliography_1" title=" GUO J Y,WANG X,LI Y.kNN based on probability density for fault detection in multimodal processes [J].Journal of Chemometrics,2018,32(7):e3021." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD2E60660BA1D73E8A5B3613CCB3E81BF8&amp;v=MTM3NTM4eVhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4THE1eGFBPU5pZmNhckhOR05IS3FZODNGZXA3QzM5TXgyY1dtRHg3U1h5UjMyQTJETHFWTg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         GUO J Y,WANG X,LI Y.kNN based on probability density for fault detection in multimodal processes [J].Journal of Chemometrics,2018,32(7):e3021.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_2" title=" FEKI-SAHNOUN W,NJAH H,HAMZA A,et al.Using general linear model,Bayesian networks and Naive Bayes classifier for prediction of Karenia selliformis occurrences and blooms [J].Ecological Informatics,2018,43:12-23." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA0FC0FF4D4919A96F5868345CED90480&amp;v=MTQ1ODRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4THE1eGFBPU5pZk9mY0s0YUtMTTJmbEJFTzhHRFhWSXhoQmw3emQ3UUh6bXFXRkFEYnVVUWJLZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         FEKI-SAHNOUN W,NJAH H,HAMZA A,et al.Using general linear model,Bayesian networks and Naive Bayes classifier for prediction of Karenia selliformis occurrences and blooms [J].Ecological Informatics,2018,43:12-23.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_3" title=" SAINI I,SINGH D,KHOSLA A.QRS detection using K-Nearest Neighbor algorithm (KNN) and evaluation on standard ECG databases [J].Journal of Advanced Research,2013,4(4):331-344." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080100003394&amp;v=MjIwMDVycVFUTW53WmVadEZpbmxVcjNJSUZ3U2J4bz1OaWZPZmJLN0h0bk1ybzlGWk9zTUQzVTlvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         SAINI I,SINGH D,KHOSLA A.QRS detection using K-Nearest Neighbor algorithm (KNN) and evaluation on standard ECG databases [J].Journal of Advanced Research,2013,4(4):331-344.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_4" title=" 职为梅,张婷,范明.基于影响函数的k-近邻分类[J].电子与信息学报,2015,37(7):1626-1632.(ZHI W M,ZHANG T,FAN M.k-nearest neighbor classification based on influence function [J].Journal of Electronics and Information Technology,2015,37(7):1626-1632.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201507017&amp;v=MTMzMTVuVmJyQUlUZlNkckc0SDlUTXFJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         职为梅,张婷,范明.基于影响函数的k-近邻分类[J].电子与信息学报,2015,37(7):1626-1632.(ZHI W M,ZHANG T,FAN M.k-nearest neighbor classification based on influence function [J].Journal of Electronics and Information Technology,2015,37(7):1626-1632.)
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_5" title=" 宓文斌.数据挖掘在银行信贷业务中的应用[D].上海:上海交通大学,2012.(MI W B.Application of data mining in the bank credit [D].Shanghai:Shanghai Jiao Tong University,2012.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013003981.nh&amp;v=MTYxODJDVVI3cWZadVpzRnlqblZickFWRjI2SGJPNEhkakVycEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         宓文斌.数据挖掘在银行信贷业务中的应用[D].上海:上海交通大学,2012.(MI W B.Application of data mining in the bank credit [D].Shanghai:Shanghai Jiao Tong University,2012.)
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_6" title=" JIANG L,CAI Z,WANG D,et al.Survey of improving k-nearest-neighbor for classification [C]// Proceedings of the 4th International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway,NJ:IEEE,2007:679-683." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Survey of Improving K-Nearest-Neighbor for Classification">
                                        <b>[6]</b>
                                         JIANG L,CAI Z,WANG D,et al.Survey of improving k-nearest-neighbor for classification [C]// Proceedings of the 4th International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway,NJ:IEEE,2007:679-683.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_7" title=" 肖辉辉,段艳明.基于属性值相关距离的KNN算法的改进研究[J].计算机科学,2013,40(S2):157-159.(XIAO H H,DUAN Y M.Improved the KNN algorithm based on related to the distance of attribute value [J].Computer Science,2013,40(S2):157-159.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2013S2040&amp;v=MDgyNDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WYnJBTHo3QmI3RzRIOUt2clk5QlpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         肖辉辉,段艳明.基于属性值相关距离的KNN算法的改进研究[J].计算机科学,2013,40(S2):157-159.(XIAO H H,DUAN Y M.Improved the KNN algorithm based on related to the distance of attribute value [J].Computer Science,2013,40(S2):157-159.)
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_8" title=" 周治平,苗敏敏.改进的马氏距离动态时间规整手势认证方法[J].计算机应用,2015,35(5):1467-1470.(ZHOU Z P,MIAO M M.Dynamic time warping gesture authentication algorithm based on improved Mahalanobis distance[J].Journal of Computer Applications,2015,35(5):1467-1470.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201505055&amp;v=MjM4OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZickFMejdCZDdHNEg5VE1xbzlBWVk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         周治平,苗敏敏.改进的马氏距离动态时间规整手势认证方法[J].计算机应用,2015,35(5):1467-1470.(ZHOU Z P,MIAO M M.Dynamic time warping gesture authentication algorithm based on improved Mahalanobis distance[J].Journal of Computer Applications,2015,35(5):1467-1470.)
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_9" title=" de MAESSCHALCK R,JOUAN-RIMBAUD D,MASSART D L.The Mahalanobis distance [J].Chemometrics and Intelligent Laboratory Systems,2000,50(1):1-18." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300186274&amp;v=MDM1MDdHZXJxUVRNbndaZVp0RmlubFVyM0lJRndTYnhvPU5pZk9mYks3SHRET3JJOUZaZU1KRG5zOW9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         de MAESSCHALCK R,JOUAN-RIMBAUD D,MASSART D L.The Mahalanobis distance [J].Chemometrics and Intelligent Laboratory Systems,2000,50(1):1-18.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_10" title=" TAHERI S,MAMMADOV M.Learning the naive Bayes classifier with optimization models [J].International Journal of Applied Mathematics and Computer Science,2013,23(4):787-795." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJDG&amp;filename=SJDG14011300000032&amp;v=Mjc4NTVRVE1ud1plWnRGaW5sVXIzSUlGd1NieG89TmlmUGFiSzhIdEROckk5RlpPc1BESDg3b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         TAHERI S,MAMMADOV M.Learning the naive Bayes classifier with optimization models [J].International Journal of Applied Mathematics and Computer Science,2013,23(4):787-795.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_11" title=" BIAU G,CADRE B,ROUVI&#200;RE L.Accelerated gradient boosting [J].Machine Learning,2019,108(6):971-992." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accelerated gradient boosting">
                                        <b>[11]</b>
                                         BIAU G,CADRE B,ROUVI&#200;RE L.Accelerated gradient boosting [J].Machine Learning,2019,108(6):971-992.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_12" title=" 杨朔,陈丽芳,石瑀,等.基于深度生成式对抗网络的蓝藻语义分割[J].计算机应用,2018,38(6):1554-1561.(YANG S,CHEN L F,SHI Y,et al.Semantic segmentation of blue-green algae based on deep generative adversarial net [J].Journal of Computer Applications,2018,38(6):1554-1561.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806006&amp;v=MTg2MTNZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVmJyQUx6N0JkN0c0SDluTXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         杨朔,陈丽芳,石瑀,等.基于深度生成式对抗网络的蓝藻语义分割[J].计算机应用,2018,38(6):1554-1561.(YANG S,CHEN L F,SHI Y,et al.Semantic segmentation of blue-green algae based on deep generative adversarial net [J].Journal of Computer Applications,2018,38(6):1554-1561.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-06-18 09:23</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2784-2788 DOI:10.11772/j.issn.1001-9081.2019030571            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于值差度量和聚类优化的<i>K</i>最近邻算法在银行客户行为预测中的应用</b></span>
                                            <span class="sign">已勘误版</span>
                </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%8D%9A&amp;code=09123158&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%99%93&amp;code=10206139&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张晓</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A2%9C%E9%9D%96%E8%89%BA&amp;code=41608596&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜靖艺</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%8F%AF%E5%A8%81&amp;code=42779663&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李可威</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%81%92&amp;code=09104757&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李恒</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%87%8C%E7%8E%89%E9%BE%99&amp;code=42779664&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">凌玉龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%8B%87&amp;code=00015965&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张勇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0085569&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B7%A5%E4%BF%A1%E9%83%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B8%8E%E7%AE%A1%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">工信部大数据存储与管理重点实验室(西北工业大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E7%AE%A1%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学管理学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为提升贷款金融客户行为预测的准确性,针对传统的<i>K</i>-最近邻(<i>K</i>NN)算法在数据分析中处理非数值因素的不完备问题,提出了一种采用值差度量(VDM)距离的对聚类结果迭代优化的改进<i>K</i>NN算法。首先对收集到的数据信息进行基于VDM距离的<i>K</i>NN算法的聚类,再对聚类结果进行迭代分析,最后通过联合训练提高了预测精度。基于葡萄牙零售银行2008—2013年收集的客户数据比较可知,改进的<i>K</i>NN算法与传统的<i>K</i>NN算法、基于属性值相关距离的<i>K</i>NN改进(FCD-<i>K</i>NN)算法、高斯贝叶斯算法、Gradient Boosting等现有算法相比具有更好的性能和稳定性,在银行数据预测客户行为中具有很大的应用价值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E-%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>-最近邻算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%80%BC%E5%B7%AE%E5%BC%82%E5%BA%A6%E9%87%8F%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">值差异度量距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%91%E8%9E%8D%E5%8D%B1%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金融危机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A1%8C%E4%B8%BA%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">行为预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据挖掘;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *李博(1994—),男,甘肃陇西人,硕士研究生,CCF会员,主要研究方向:云存储、数据挖掘;电子邮箱2640992944@qq.com;
                                </span>
                                <span>
                                    张晓(1978—),男,河南新乡人,副教授,博士,CCF会员,主要研究方向:存储系统;;
                                </span>
                                <span>
                                    颜靖艺(1993—),女(回族),广西桂林人,硕士,主要研究方向:技术创新管理;;
                                </span>
                                <span>
                                    李可威(1993—),男,湖北云梦人,硕士研究生,主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    李恒(1993—),男,河南周口人,硕士研究生,主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    凌玉龙(1995—),男,安徽宿州人,硕士研究生,主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    张勇(1995—),男,安徽六安人,硕士研究生,主要研究方向:数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目(2018YFB1003403, 2018YFB1004401);</span>
                    </p>
            </div>
                    <h1><b>Application of <i>K</i>NN algorithm based on value difference metric and clustering optimization in bank customer behavior prediction</b></h1>
                    <h2>
                    <span>LI Bo</span>
                    <span>ZHANG Xiao</span>
                    <span>YAN Jingyi</span>
                    <span>LI Kewei</span>
                    <span>LI Heng</span>
                    <span>LING Yulong</span>
                    <span>ZHANG Yong</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, Northwestern Polytechnical University</span>
                    <span>Ministry of Communications Key Laboratory of Big Data Storage and Management (Northwestern Polytechnical University)</span>
                    <span>School of Management, Northwestern Polytechnical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the accuracy of loan financial customer behavior prediction, aiming at the incomplete problem of dealing with non-numerical factors in data analysis of traditional <i>K</i>-Nearest Neighbors(<i>K</i>NN) algorithm, an improved <i>K</i>NN algorithm based on Value Difference Metric(VDM) distance and iterative optimization of clustering results was proposed. Firstly the collected data were clustered by <i>K</i>NN algorithm based on VDM distance, then the clustering results were analyzed iteratively, finally the prediction accuracy was improved through joint training. Based on the customer data collected by Portuguese retail banks from 2008 to 2013, it can be seen that compared with traditional <i>K</i>NN algorithm, FCD-<i>K</i>NN(Feature Correlation Difference <i>K</i>NN) algorithm, Gauss Naive Bayes algorithm, Gradient Boosting algorithm, the improved <i>K</i>NN algorithm has better performance and stability, and has great application value in the customer behavior prediction from bank data.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E-Nearest%20Neighbors(%3Ci%3EK%3C%2Fi%3ENN)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>-Nearest Neighbors(<i>K</i>NN) algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Value%20Difference%20Metric(VDM)%20distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Value Difference Metric(VDM) distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=financial%20crisis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">financial crisis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=behavior%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">behavior prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data mining;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Bo, born in 1994, M. S. candidate. His research interests include cloud storage, data mining. ;
                                </span>
                                <span>
                                    ZHANG Xiao, born in 1978, Ph. D. , associate professor. His research interests include storage system. ;
                                </span>
                                <span>
                                    YAN Jingyi, born in 1993, M. S. Her research interests include technology innovation management. ;
                                </span>
                                <span>
                                    LI Kewei, born in 1993, M. S. candidate. His research interests include data mining. ;
                                </span>
                                <span>
                                    LI Heng, born in 1993, M. S. candidate. His research interests include data mining. ;
                                </span>
                                <span>
                                    LING Yulong, born in 1995, M. S. candidate. His research interests include data mining. ;
                                </span>
                                <span>
                                    ZHANG Yong, born in 1995, M. S. candidate. His research interests include data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-08</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Key Research and Development Program of China(2018YFB1003403, 2018YFB1004401);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">在贷款金融领域,银行机构营销需要对用户进行分析和分类,以降低营销成本。基于某目标人群,从海量的其他人群中找出和目标人群相似的人群,以拓展目标人群规模。在现实生活中,通过海量数据集,并对数据划分标签,然后对用户行为进行分析和分类,再进行相应的营销手段,可以降低成本,并取得较好的效果<citation id="137" type="reference"><link href="113" rel="bibliography" /><link href="115" rel="bibliography" /><link href="117" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。当前的一些研究指出,银行信息的数据挖掘不应该仅仅局限于会计数据,还需要考虑一些社会因素。</p>
                </div>
                <div class="p1">
                    <p id="41">基于数据挖掘和用户行为预测的目的,本文采用数据挖掘方法对葡萄牙银行业金融机构直接营销活动(电话)相关数据进行分析,通过电话营销和电话销售预测银行长期存款的可能性。该数据集由葡萄牙零售银行于2008—2013年收集,受到当时金融危机的影响,分类的目的是预测客户是否会订购定期存款。对于该数据集来说,主要的困难在于其特征的选择,数据集中存在无用的或有噪声的特征,这些特征可能会降低预测结果。基于这个目的,本文采用了一种改进的<i>K</i>-最近邻(<i>K</i>-Nearest Neighbors, <i>K</i>NN)算法。<i>K</i>NN算法能够更好地分析相似客户的行为,更好地对客户进行分类。传统的<i>K</i>NN算法存在一定的局限性。本文对距离计算和聚类分析方法进行了改进,实验结果表明,改进的<i>K</i>NN算法在银行数据挖掘中具有良好的预测效果。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 研究现状</h3>
                <div class="p1">
                    <p id="43">数据挖掘是指通过数据过滤,从大量现有数据中搜索有趣的、有价值的数据点或数据模块的数据处理技术。数据挖掘在商业金融领域有着广泛的应用,根据商业分析的既定目标,可以通过企业内部的财务数据系统进行数据分析,以获得所需的业务运营和市场发展规律,并可以通过成熟的数据挖掘模型和其他分析工具进行支持,形成了商业化的数据挖掘与分析系统。</p>
                </div>
                <div class="p1">
                    <p id="44">2008—2013年,葡萄牙零售银行业受到金融危机的影响,因此银行需要分析数据挖掘,分析客户是否可以继续存款。根据社会心理学研究,当人们处于压力状态下时,往往有更多的本能表现,数据分析的准确性也会相应提高<citation id="138" type="reference"><link href="119" rel="bibliography" /><link href="121" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。在金融危机期间,人们对金融投资都会持谨慎态度。另一方面,葡萄牙零售银行业有着成熟的数据仓库,对银行客户的个人数据、账户信息、交易历史、业务服务历史、财务管理数据、个人财务风险评估等进行了数据仓储,可以对每个银行客户进行多维度的财务分析。</p>
                </div>
                <div class="p1">
                    <p id="45">目前,对银行客户信息挖掘的研究较多,对银行客户信息挖掘的研究需求巨大。一些研究发现:配给大量信息的信贷员并没有比配给少量信息的信贷员预测更准确,现有会计信息可能过量。因此当前的研究应该更多考虑考虑非数值指标,如:职业、学历等。基于属性值相关距离的<i>K</i>NN(Feature Correlation Difference-<i>K</i>NN, FCD-<i>K</i>NN)改进算法对非数值的因素进行了考虑:比较样本间的距离为属性值的相关距离,从而度量样本间的相似度<citation id="139" type="reference"><link href="123" rel="bibliography" /><link href="125" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。<i>K</i>NN算法是一种非常常见的算法,简单易用,易懂,精度高,理论成熟;但也存在许多问题,为此人们提出了许多改进的<i>K</i>近邻算法。为了解决银行分类问题,本文采用了一种改进的<i>K</i>NN算法:用更适合银行情况的搜索距离函数代替标准欧几里得距离,用更精确的概率估计方法代替简单的投票机制。实验表明,本文提出的改进的<i>K</i>NN算法精度得到了很大的提高,是一种有效的算法,具有很好的推广前景。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 算法分析</h3>
                <h4 class="anchor-tag" id="47" name="47">2.1 <b>传统的</b><i>K</i>NN<b>算法</b></h4>
                <div class="p1">
                    <p id="48"><i>K</i>-最近邻(<i>K</i>NN)分类算法在模式识别领域得到了广泛的应用。<i>K</i>NN算法基于类比学习,所有训练基元都存储在<i>N</i>维模式空间中。如果特征空间中<i>k</i>个最相似的样本中的大多数属于某个类别,那么这些样本就属于这个类别。<i>K</i>NN算法不仅可以用于分类,还可以用于回归分析。通过寻找样本的<i>K</i>最近邻点,并将这些相邻点的属性平均值赋给样本,可以得到样本的预测值。例如,在图1中,当一个新的样本值添加到向量空间中时,在样本值附近对其进行分析并进行分类。传统的<i>K</i>NN算法得到了广泛的应用,但鉴于银行系统的特殊性,本文对距离选择和判别法进行了改进,使分析预测更加准确,与传统的<i>K</i>NN算法相比,其预测精度有了显著的提高。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 当样本空间加入新样本时的计算" src="Detail/GetImg?filename=images/JSJY201909050_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 当样本空间加入新样本时的计算  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Calculation of sample space when new samples are added</p>

                </div>
                <h4 class="anchor-tag" id="50" name="50">2.2 <b>本文采用的改进</b><i>K</i>NN<b>算法</b></h4>
                <div class="p1">
                    <p id="51">针对银行的特殊情况,本文采用了一种改进的<i>K</i>NN算法。改进措施包括:用更适合银行业情况的搜索距离函数代替标准欧几里得距离,用更精确的概率估计方法代替简单的投票机制。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">1)采用VDM距离修正。</h4>
                <div class="p1">
                    <p id="53">距离计算是数据挖掘聚类的关键步骤。距离计算是计算采样点与采样点之间的距离,并根据计算结果判断采样点之间的关系。传统的<i>K</i>NN算法使用欧几里得距离公式计算距离,例如:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mo>=</mo><msqrt><mrow><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中<i>ρ</i>为点(<i>x</i><sub>1</sub>,<i>x</i><sub>2</sub>)与点(<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>)之间的欧氏距离。</p>
                </div>
                <div class="p1">
                    <p id="56">欧氏距离通常被用来本表示样本的有序属性,在本数据集中只有“年龄”符合这一条件。其他的条件如:婚姻状况、工作类型等这样的无序属性,更适合采用值差度量(Value Difference Metric, VDM)距离。VDM距离是指: 令<i>M</i><sub><i>u</i>,<i>a</i></sub>表示在属性<i>u</i>上取值为<i>a</i>的样本数,<i>M</i><sub><i>u</i>,<i>a</i>,<i>i</i></sub>表示在第<i>i</i>个样本簇中在属性<i>u</i>上取值为<i>a</i>的样本数,则属性<i>u</i>上两个离散值<i>a</i>与<i>b</i>之间的VDM距离为:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mi>D</mi><mi>Μ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>a</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>a</mi></mrow></msub></mrow></mfrac><mo>-</mo><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>b</mi></mrow></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mi>p</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">将欧氏距离和VDM结合可处理混合属性。为不失一般性,令有序属性排列在无序属性之前,可得:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>k</mi><mi>o</mi><mi>w</mi><mi>D</mi><mi>Μ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></munderover><mo stretchy="false">|</mo></mstyle><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>u</mi></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>u</mi></mrow></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mi>p</mi></msup><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>c</mi></msub><mo>+</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>V</mi></mstyle><mi>D</mi><mi>Μ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>x</mi><mrow><mi>j</mi><mi>u</mi></mrow><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">因为是在二维分析,可以<i>p</i>=2。无序属性就是通过计算样本簇中在属性<i>u</i>上样本点的多少来得到该样本簇在该属性上的“距离”。通过修正数据采集的距离,可以使得数据挖掘分析预测结果更为精确。</p>
                </div>
                <div class="p1">
                    <p id="61">本文也探讨了马氏距离(Mahalanobis distance)在该问题下的应用,马氏距离是对有序的、数值型的属性,考虑其内在的关联性,从而计算得出结果<citation id="140" type="reference"><link href="127" rel="bibliography" /><link href="129" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。但是本文所提到的数据也有很多无序的属性,使用马氏距离处理会较为复杂,故未采用该处理方法。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">2)对数据处理修正。</h4>
                <div class="p1">
                    <p id="63">传统的<i>K</i>NN方法对新增加的样本点进行分类,使其具有更高的相似性。本文同时设置了各采样点的属性,并设置了划分区域的阈值(比如:70%)。如果超出此阈值,本算法将把采样点添加到一个没有争议的区域。如果点与每个区域之间的距离不明显,本算法将该点标记为疑问点,在初步聚类结束后再考虑它。如图2所示,如果点<i>X</i><sub><i>a</i></sub>与区域1(<i>ω</i><sub>1</sub>)和区域2(<i>ω</i><sub>2</sub>)之间的距离显著不同,则将点<i>X</i><sub><i>a</i></sub>划分为区域1。然而,在图3中,例如,点<i>X</i><sub><i>b</i></sub>与区域1和区域2之间的距离没有显著差异。因此,点<i>X</i><sub><i>b</i></sub>暂时被标记为疑问点。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 在改进的KNN算法样本空间加入新样本 (当新样本点特征很明显时)" src="Detail/GetImg?filename=images/JSJY201909050_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 在改进的<i>K</i>NN算法样本空间加入新样本 (当新样本点特征很明显时)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 New sample points added in the sample space of the improved <i>K</i>NN algorithm (when the characteristics of new sample points are obvious)</p>

                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 在改进的KNN算法样本空间加入新样本时 (当新样本点特征不明显时)" src="Detail/GetImg?filename=images/JSJY201909050_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 在改进的<i>K</i>NN算法样本空间加入新样本时 (当新样本点特征不明显时)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 New sample points added in the sample space of the improved <i>K</i>NN algorithm (when the characteristics of new sample points are not obvious)</p>

                </div>
                <div class="p1">
                    <p id="66">根据这种方法,最终会发现两种类型的点:区域中心的无争议点和区域边缘的争议点,如图4所示。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 改进KNN可能得到的划分结果" src="Detail/GetImg?filename=images/JSJY201909050_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 改进<i>K</i>NN可能得到的划分结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Possible classification results of improved <i>K</i>NN</p>

                </div>
                <div class="p1">
                    <p id="68">在图4中的情况,需要额外增加判断过程,整体划分,保留整个区域的最小离群值。甚至对于离群值边缘太多,本算法可以将其划分为新的区域或合并原始区域,即对分类结果又进行了一次处理。而对于图5,如果区域外的点内部之间存在更多的相关性,即这一群争议点彼此之间更为相似,如果用距离作标准,即这一群争议点内部彼此之间的距离明显小于它们与现有簇之间的距离(根据本文设置的阈值判断)。首先可以通过在这些争议点中随机找到一个点,计算该点与其他争议点之间的距离。如果发现其内部距离更小,则可以形成一个新的分类;甚至于其内部可能还会进一步的分裂,也可以进一步的处理。在图5,中间的三个点彼此之间的距离更为接近(超过本文设置的阈值),可以直接增加新的分类,结果如图6所示,这样就有了更合理的集群。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 改进的KNN算法划分结果再进行处理 (可疑点暂不划分分组)" src="Detail/GetImg?filename=images/JSJY201909050_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 改进的<i>K</i>NN算法划分结果再进行处理 (可疑点暂不划分分组)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Process the results of improved <i>K</i>NN algorithm (separate treatment of suspicious points)</p>

                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 改进的KNN算法划分结果再进行处理 (将相似的可疑点划分为新分组)" src="Detail/GetImg?filename=images/JSJY201909050_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 改进的<i>K</i>NN算法划分结果再进行处理 (将相似的可疑点划分为新分组)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Process the results of improved <i>K</i>NN algorithm (divide similar suspicious points into new groups)</p>

                </div>
                <h3 id="71" name="71" class="anchor-tag">3 实验分析</h3>
                <div class="p1">
                    <p id="72">为了验证改进的<i>K</i>-最近邻算法在银行数据挖掘中的有效性,本文进行了实验分析。选用的数据样本是葡萄牙零售银行在2008—2013年期间收集的数据样本,将数据分为测试集和验证集。数据预处理会有三种情况,分别为:未对原始数据作处理,将原始数据整合为符合正态分布,将原始数据整合到归一化分布。同时为了比较算法的有效性,将传统的<i>K</i>NN算法、FCD-<i>K</i>NN算法,高斯贝叶斯(Gaussian Naive Bayes)算法、Gradient Boosting 4种方法作为对照组实验<citation id="141" type="reference"><link href="131" rel="bibliography" /><link href="133" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>。因此共进行了15组实验,然后对实验结果进行分析。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">3.1 <b>实验数据处理</b></h4>
                <div class="p1">
                    <p id="74">为了更为全面地分析数据,本文采用了3种数据预处理的方法,这三种方法各有利弊。本文会通过这5种算法的具体表现,验证其稳定性和有效性。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75">3.1.1 未对原始数据作处理(只对数据标签数字化)</h4>
                <div class="p1">
                    <p id="76">在这种情况下,只对数据进行了预处理,分析数据本来之间的关系。具体步骤是:将原始数据的标签进行数字化,具体是按序1,2,3的进行转化,“no”是1,“yes”是2,null是3。不进行其他转换,然后进行实验分析。这种情况下,保持了数据的基本特性,但数据中的奇异点可能会对实验精度有较大影响,从而降低一些依赖数值关系算法的精度,如:<i>K</i>-最近邻算法。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77">3.1.2 将数据标准化成符合正态分布</h4>
                <div class="p1">
                    <p id="78">大部分的数据分析都希望原始数据是满足正态分布的定距变量,这样数据分析更为精确,也会降低数据分析的复杂度。数据标准化调整是非常有用的。许多机器学习算法在具有不同范围特征的数据中呈现不同的学习效果。例如,Gaussian Naive Bayes在没有标准化调整过的数据中表现很差,因为可能一个变量的范围是0～10 000,而另一个变量的范围是0～1。因此,对数据预处理符合正态分布,是一种有效的分析手段。将数据处理为符合正态分布的公式为:</p>
                </div>
                <div class="p1">
                    <p id="79"><i>z</i>=(<i>x</i>-<i>μ</i>)/<i>σ</i>      (4)</p>
                </div>
                <div class="p1">
                    <p id="80">其中: <i>μ</i>、<i>σ</i>分别为原始数据集的均值和方法。该种归一化方式要求原始数据的分布近似为高斯分布,否则归一化的效果会变得很糟糕。本文首先对原始数据进行了分析,发现其大致符合高斯分布,符合将数据正态分布化的先决条件。通过这种方式,可以使数据规范化,同时使数据分析更为简单。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">3.1.3 将数据进行归一化到[0,1]</h4>
                <div class="p1">
                    <p id="82">对原始数据进行标签数字化后,再对数据进行线性函数归一化。利用线性函数将原始数据线性化的方法转换到[0,1]的范围,归一化公式如下:</p>
                </div>
                <div class="p1">
                    <p id="83"><i>X</i><sub>norm</sub>=(<i>X</i>-<i>X</i><sub>min</sub>)/(<i>X</i><sub>max</sub>-<i>X</i><sub>min</sub>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="84">该方法实现对原始数据的等比例缩放,其中<i>X</i><sub>norm</sub>为归一化后的数据,<i>X</i>为原始数据,<i>X</i><sub>max</sub>、<i>X</i><sub>min</sub>分别为原始数据集的最大值和最小值。通过这种方法可以避免奇异点对数据分析造成的影响,但是会对数据的完整性和对比度造成影响。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">3.2 <b>实验流程</b></h4>
                <div class="p1">
                    <p id="86">本文使用Eclipse3+Python3+pydev的开发环境,也可以使用Java开发环境(JDK1.8以上),进行仿真模拟实验。一共做12组实验,随机选取样本集的70%为训练集,30%为测试集,先对处理后训练数据进行训练,然后再在测试集上进行训练,最后根据预测的精度来验证实验。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">3.3 <b>实验结果</b></h4>
                <h4 class="anchor-tag" id="88" name="88">1)未对数据进行预处理的精度情况。</h4>
                <div class="p1">
                    <p id="89">当未对数据进行预处理时(仅对标签进行数字化),Gaussian Naive Bayes和Gradient Boosting算法表现的并不是特别理想,相比之下3种<i>K</i>NN算法的准确性更好,FCD-<i>K</i>NN算法作为一种较新颖的算法在这种情况下表现略优于于本文提出的改进<i>K</i>NN算法。未对数据进行预处理时,实验结果如表1所示。</p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"><b>表</b>1 <b>未对数据进行预处理的结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Results of no pre-processed data</p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td><br />选用方法</td><td>精度</td></tr><tr><td><br />Improved <i>K</i>NN</td><td>0.949 613 252 437 653 3</td></tr><tr><td><br />Traditional <i>K</i>NN</td><td>0.930 808 448 652 585 6</td></tr><tr><td><br />FCD-<i>K</i>NN</td><td>0.961 258 147 309 458 0</td></tr><tr><td><br />Gaussian Naive Bayes</td><td>0.846 807 477 543 092 9</td></tr><tr><td><br />Gradient Boosting</td><td>0.912 600 145 666 423 9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2)对数据预处理标准化成正态分布的精度情况。</h4>
                <div class="p1">
                    <p id="92">根据<i>K</i>NN算法的特性,<i>K</i>NN算法一般会很好地处理奇异点(比如:不归类),而本文改进的<i>K</i>NN算法会尽可能得将数据进行合理的分类;相比于FCD-<i>K</i>NN算法,对数据分类进行了进一步的处理,从而在银行数据分析预测中有更好的表现。对数据预处理标准化成正态分布时,实验结果如表2所示。</p>
                </div>
                <div class="area_img" id="93">
                    <p class="img_tit"><b>表</b>2 <b>对数据预处理标准化成正态分布的结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Results of data standardized into normal distribution</p>
                    <p class="img_note"></p>
                    <table id="93" border="1"><tr><td><br />选用方法</td><td>精度</td></tr><tr><td><br />Improved <i>K</i>NN</td><td>0.945 567 434 278 632 0</td></tr><tr><td><br />Traditional <i>K</i>NN</td><td>0.932 993 445 010 925 0</td></tr><tr><td><br />FCD-<i>K</i>NN</td><td>0.940 950 556 877 904 0</td></tr><tr><td><br />Gaussian Naive Bayes</td><td>0.848 992 473 901 432 4</td></tr><tr><td><br />Gradient Boosting</td><td>0.924 496 236 950 716 1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">3)对数据预处理归一化到[0,1]的精度情况。</h4>
                <div class="p1">
                    <p id="95">相比于对数据进行正态化分布预处理的情形,对数据进行归一化处理得到的结果很相似。归一化后加快了梯度下降求最优解的速度。同时,如果一个特征值域范围非常大,那么距离计算就主要取决于这个特征,从而与实际情况相悖(比如这时实际情况是值域范围小的特征更重要)。这种方法非常适用于采用距离判断的<i>K</i>-最近邻算法 ,通过这种方法,虽然此时5种预测算法的精度都有所下降,但是3种<i>K</i>NN算法还是明显优于其他2种算法,同时改进的<i>K</i>NN算法略优于其他两种的<i>K</i>NN算法。对数据预处理归一化到[0,1]时,实验结果如表3所示。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表</b>3 <b>对数据预处理归一化到</b>[0,1]<b>的结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Results of data normalized to [0,1]</p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td><br />选用方法</td><td>精度</td></tr><tr><td><br />Improved <i>K</i>NN</td><td>0.946 080 055 467 216 3</td></tr><tr><td><br />Traditional <i>K</i>NN</td><td>0.919 397 912 114 590 9</td></tr><tr><td><br />FCD-<i>K</i>NN</td><td>0.941 346 587 430 683 0</td></tr><tr><td><br />Gaussian Naive Bayes</td><td>0.836 125 273 124 544 8</td></tr><tr><td><br />Gradient Boosting</td><td>0.910 172 371 934 935 6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">3.4 <b>整体实验结论分析</b></h4>
                <div class="p1">
                    <p id="98">在整体结果中,本文提出的改进的<i>K</i>NN方法和FCD-<i>K</i>NN算法表现更好,说明本文提出的改进的<i>K</i>NN算法有一定的研究价值。分析原因,银行用户数据集不适合进行标准化,其噪声可以通过SVM的RBF核函数的处理,RBF将数据集映射到高维上进行分类,从而有效减少了噪声的影响,在低维上进行计算。进一步的展望是先进行聚类算法,假设噪声都是一些离群点,将识别出来的很小的集合划为噪声,从而将噪声识别出来并剔除,进一步提高精度。改进的<i>K</i>NN方法采用了VDM距离法,而样本集中很多无法数字化比较的标签(如婚姻状态、工作状态等)很难作为数字因素考虑。FCD-<i>K</i>NN算法也是对非数值的指标进行了考虑,但是本文提出的改进的<i>K</i>NN算法在数据分类过程中有更多的考虑,对实验结果产生了一些有利的结果。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909050_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法实验结果比较" src="Detail/GetImg?filename=images/JSJY201909050_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法实验结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909050_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison of experimental results by different algorithms</p>

                </div>
                <div class="p1">
                    <p id="100">而Naive Bayes方法相比于其他方法精度较低,原因可能是:1)朴素贝叶斯方法需要先知道先验分布和数据来决定后验的概率从而决定分类,所以分类决策存在一定的错误率;2) 理论上,朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但实际上,因为朴素贝叶斯模型假设属性之间相互独立,这个假设在实际应用中往往是不成立的,在属性个数比较多或者属性之间相关性较大时,分类效果不好。</p>
                </div>
                <div class="p1">
                    <p id="101">分析原因,可能是数据集中样本的属性之间有联系,分析银行客户资料,“工作类型”“教育”“住房”“贷款”等属性之间都可能会有联系,所以这也是Naive Bayes方法精度比其他三种方法更低的原因。</p>
                </div>
                <div class="p1">
                    <p id="102">3种<i>K</i>NN方法在三组实验中均有优秀的实验结果,精度均在0.92左右或以上,预测精度都非常稳定。整体实验结果为:在不同预处理方式的之间,不标准化(仅对标签数字化)&gt;对数据预处理正态分布化&gt;对数据预处理线性函数归一化。因为在本次数据集,标签并没有太多的数值关系,因此使用欧氏距离传统的<i>K</i>NN方法精度会下降,而采用VDM距离的改进的<i>K</i>NN方法和FCD-<i>K</i>NN方法均有突出的表现。而综合三种情况分析,本文提出的改进的<i>K</i>NN方法无疑是在银行数据挖掘分析预测中表现作为优秀和稳定的算法,其对于距离计算和聚类方式的改变,非常适用于银行情况,因此具有很大的潜力。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="104">在大数据的背景下,对数据进行充分分析,可以减少实际工作中的成本。在金融行业对客户的分析预测显得尤为重要,数据分析聚类,可以给客户提供相应的个性化服务。本文所提出的改进的<i>K</i>-最近邻算法,对传统的<i>K</i>-最近邻算法进行距离计算和聚类方式的改变,通过实验分析与数据验证,以2008—2013葡萄牙银行数据作为样本集和测试集,对该算法进行验证,取得了非常理想的计算结果。与目前主流的其他算法相比,具有更好的稳定性和精确性,该算法在金融数据分析方面有良好的效果,有乐观的应用前景。</p>
                </div>
                <div class="p1">
                    <p id="105">本文未来还会做以下工作:</p>
                </div>
                <div class="p1">
                    <p id="106">1)本文研究的是处于金融危机下的人群,从社会学角度,这一时期的人群处于敏感时期,理财行为更为谨慎,因此要考虑本文研究的价值。</p>
                </div>
                <div class="p1">
                    <p id="107">2)对数据的预处理是通常的数据挖掘中采用的手段,本文所提到数据预处理手段都较为简单,本文会未来尝试更多的预处理手段,使预测度更为精确。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="113">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD2E60660BA1D73E8A5B3613CCB3E81BF8&amp;v=MTEzMjhxWTgzRmVwN0MzOU14MmNXbUR4N1NYeVIzMkEyRExxVk44eVhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4THE1eGFBPU5pZmNhckhOR05ISw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> GUO J Y,WANG X,LI Y.kNN based on probability density for fault detection in multimodal processes [J].Journal of Chemometrics,2018,32(7):e3021.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA0FC0FF4D4919A96F5868345CED90480&amp;v=MTMwODNHRFhWSXhoQmw3emQ3UUh6bXFXRkFEYnVVUWJLZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMcTV4YUE9TmlmT2ZjSzRhS0xNMmZsQkVPOA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> FEKI-SAHNOUN W,NJAH H,HAMZA A,et al.Using general linear model,Bayesian networks and Naive Bayes classifier for prediction of Karenia selliformis occurrences and blooms [J].Ecological Informatics,2018,43:12-23.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080100003394&amp;v=MDExNTlPZmJLN0h0bk1ybzlGWk9zTUQzVTlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRndTYnhvPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> SAINI I,SINGH D,KHOSLA A.QRS detection using K-Nearest Neighbor algorithm (KNN) and evaluation on standard ECG databases [J].Journal of Advanced Research,2013,4(4):331-344.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201507017&amp;v=MTIwMjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWpuVmJyQUlUZlNkckc0SDlUTXFJOUVZNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 职为梅,张婷,范明.基于影响函数的k-近邻分类[J].电子与信息学报,2015,37(7):1626-1632.(ZHI W M,ZHANG T,FAN M.k-nearest neighbor classification based on influence function [J].Journal of Electronics and Information Technology,2015,37(7):1626-1632.)
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013003981.nh&amp;v=MDg1NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqblZickFWRjI2SGJPNEhkakVycEViUElRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 宓文斌.数据挖掘在银行信贷业务中的应用[D].上海:上海交通大学,2012.(MI W B.Application of data mining in the bank credit [D].Shanghai:Shanghai Jiao Tong University,2012.)
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Survey of Improving K-Nearest-Neighbor for Classification">

                                <b>[6]</b> JIANG L,CAI Z,WANG D,et al.Survey of improving k-nearest-neighbor for classification [C]// Proceedings of the 4th International Conference on Fuzzy Systems and Knowledge Discovery.Piscataway,NJ:IEEE,2007:679-683.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2013S2040&amp;v=MTkyNDNVUjdxZlp1WnNGeWpuVmJyQUx6N0JiN0c0SDlLdnJZOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 肖辉辉,段艳明.基于属性值相关距离的KNN算法的改进研究[J].计算机科学,2013,40(S2):157-159.(XIAO H H,DUAN Y M.Improved the KNN algorithm based on related to the distance of attribute value [J].Computer Science,2013,40(S2):157-159.)
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201505055&amp;v=MDIxNDRSN3FmWnVac0Z5am5WYnJBTHo3QmQ3RzRIOVRNcW85QVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 周治平,苗敏敏.改进的马氏距离动态时间规整手势认证方法[J].计算机应用,2015,35(5):1467-1470.(ZHOU Z P,MIAO M M.Dynamic time warping gesture authentication algorithm based on improved Mahalanobis distance[J].Journal of Computer Applications,2015,35(5):1467-1470.)
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300186274&amp;v=MTAzOTFsVXIzSUlGd1NieG89TmlmT2ZiSzdIdERPckk5RlplTUpEbnM5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> de MAESSCHALCK R,JOUAN-RIMBAUD D,MASSART D L.The Mahalanobis distance [J].Chemometrics and Intelligent Laboratory Systems,2000,50(1):1-18.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJDG&amp;filename=SJDG14011300000032&amp;v=MjY5NzZaZVp0RmlubFVyM0lJRndTYnhvPU5pZlBhYks4SHRETnJJOUZaT3NQREg4N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> TAHERI S,MAMMADOV M.Learning the naive Bayes classifier with optimization models [J].International Journal of Applied Mathematics and Computer Science,2013,23(4):787-795.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accelerated gradient boosting">

                                <b>[11]</b> BIAU G,CADRE B,ROUVIÈRE L.Accelerated gradient boosting [J].Machine Learning,2019,108(6):971-992.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806006&amp;v=MDIwMjNVUjdxZlp1WnNGeWpuVmJyQUx6N0JkN0c0SDluTXFZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 杨朔,陈丽芳,石瑀,等.基于深度生成式对抗网络的蓝藻语义分割[J].计算机应用,2018,38(6):1554-1561.(YANG S,CHEN L F,SHI Y,et al.Semantic segmentation of blue-green algae based on deep generative adversarial net [J].Journal of Computer Applications,2018,38(6):1554-1561.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909050" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909050&amp;v=MDE1NjU3RzRIOWpNcG85QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am5WYnJBTHo3QmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
