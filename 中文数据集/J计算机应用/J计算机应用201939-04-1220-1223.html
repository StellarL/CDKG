<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779719033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904046%26RESULT%3d1%26SIGN%3diLzTJgPQK5O5zCWtmZAvPNzNKGQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904046&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904046&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904046&amp;v=MTI4ODZxZlp1WnNGeURoVUxyT0x6N0JkN0c0SDlqTXE0OUJZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#32" data-title="1 仿人机器人的运动学建模 ">1 仿人机器人的运动学建模</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="1.1 NAO&lt;b&gt;仿人机器人建模&lt;/b&gt;">1.1 NAO<b>仿人机器人建模</b></a></li>
                                                <li><a href="#39" data-title="1.2 &lt;b&gt;正向运动学计算&lt;/b&gt;">1.2 <b>正向运动学计算</b></a></li>
                                                <li><a href="#46" data-title="1.3 &lt;b&gt;逆向运动学计算&lt;/b&gt;">1.3 <b>逆向运动学计算</b></a></li>
                                                <li><a href="#48" data-title="1.4 &lt;b&gt;刚体坐标转换&lt;/b&gt;">1.4 <b>刚体坐标转换</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="2 仿人机器人能力图 ">2 仿人机器人能力图</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="2.1 &lt;b&gt;能力图运动学表示&lt;/b&gt;">2.1 <b>能力图运动学表示</b></a></li>
                                                <li><a href="#69" data-title="2.2 &lt;b&gt;能力图&lt;/b&gt;Octomap&lt;b&gt;表示&lt;/b&gt;">2.2 <b>能力图</b>Octomap<b>表示</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#100" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#111" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="图1 仿人机器人的建模">图1 仿人机器人的建模</a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;表&lt;/b&gt;1 NAO&lt;b&gt;机器人关节电机采样空间&lt;/b&gt;"><b>表</b>1 NAO<b>机器人关节电机采样空间</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;表&lt;/b&gt;2 NAO&lt;b&gt;机器人连杆长度&lt;/b&gt;"><b>表</b>2 NAO<b>机器人连杆长度</b></a></li>
                                                <li><a href="#68" data-title="图2 仿人机器人NAO左手工作空间的三维点云表示">图2 仿人机器人NAO左手工作空间的三维点云表示</a></li>
                                                <li><a href="#74" data-title="图3 存储空闲和占用单元的八叉树示例">图3 存储空闲和占用单元的八叉树示例</a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;空间点在&lt;/b&gt;Octomap&lt;b&gt;中每个层次的状态示例&lt;/b&gt;"><b>表</b>3 <b>空间点在</b>Octomap<b>中每个层次的状态示例</b></a></li>
                                                <li><a href="#93" data-title="图4 节点构建示意图">图4 节点构建示意图</a></li>
                                                <li><a href="#104" data-title="图5 仿人机器人位置模拟">图5 仿人机器人位置模拟</a></li>
                                                <li><a href="#106" data-title="图6 能力图Octomap表示">图6 能力图Octomap表示</a></li>
                                                <li><a href="#108" data-title="图7 优化前后节点数量对比">图7 优化前后节点数量对比</a></li>
                                                <li><a href="#110" data-title="图8 三维场景模拟">图8 三维场景模拟</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="131">


                                    <a id="bibliography_1" title=" KHOSHELHAM K. Accuracy analysis of Kinect depth data[EB/OL].[2018-05-10]. https://people. eng. unimelb. edu. au/kkhoshelham/research_files/kinectaccuracy/isprsarchives-XXXVIII-5-W12-133-2011. pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accuracy analysis of Kinect depth data">
                                        <b>[1]</b>
                                         KHOSHELHAM K. Accuracy analysis of Kinect depth data[EB/OL].[2018-05-10]. https://people. eng. unimelb. edu. au/kkhoshelham/research_files/kinectaccuracy/isprsarchives-XXXVIII-5-W12-133-2011. pdf.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_2" title=" TAN M, WANG S. Research progress on robotics[J]. Acta Automatica Sinica, 2013, 39 (7) :963-972." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201307003&amp;v=MTQ1Njl1WnNGeURoVUxyT0tDTGZZYkc0SDlMTXFJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         TAN M, WANG S. Research progress on robotics[J]. Acta Automatica Sinica, 2013, 39 (7) :963-972.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_3" title="梶田秀司.仿人机器人[M].北京:清华大学出版社, 2007:44-50. (SHUUJI K. Humanoid Robots[M]. Beijing:Tsinghua University Press, 2007:44-50.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302144533001&amp;v=MTI2NDFIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3Zk1JMXNTWEZxekdiQzRITkRJcTRwR1orc1BEUk04enhVU21EZDlT&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        梶田秀司.仿人机器人[M].北京:清华大学出版社, 2007:44-50. (SHUUJI K. Humanoid Robots[M]. Beijing:Tsinghua University Press, 2007:44-50.) 
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_4" title=" KOFINAS N, ORFANOUDAKIS E, LAGOUDAKIS M G. Complete analytical forward and inverse kinematics for the NAO humanoid robot[J]. Journal of Intelligent&amp;amp;Robotic Systems, 2015, 77 (2) :251-264." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15011600014340&amp;v=MDY3NDJETnFZOUZaT29MRDNnNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGb1hieFE9Tmo3QmFySzlIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         KOFINAS N, ORFANOUDAKIS E, LAGOUDAKIS M G. Complete analytical forward and inverse kinematics for the NAO humanoid robot[J]. Journal of Intelligent&amp;amp;Robotic Systems, 2015, 77 (2) :251-264.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_5" title=" ZACHARIAS F, BORST C, HIRZINGER G. Capturing robot workspace structure:representing robot capabilities[C]//Proceedings of the 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2007:3229-3236." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Capturing robot workspace structure:representing robot capabilities">
                                        <b>[5]</b>
                                         ZACHARIAS F, BORST C, HIRZINGER G. Capturing robot workspace structure:representing robot capabilities[C]//Proceedings of the 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2007:3229-3236.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_6" title=" MELLMANN H, COTUGNO G. Dynamic Motion Control:Adaptive Bimanual Grasping for a Humanoid Robot[M]. Amsterdam:IOS Press, 2011:89-101." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SIJD&amp;filename=SIJD00000035843&amp;v=MTcyOTVBYk84TVkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlybFc3dkxKVmc9TmlUQmFyTzRIdEhNcjR4&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         MELLMANN H, COTUGNO G. Dynamic Motion Control:Adaptive Bimanual Grasping for a Humanoid Robot[M]. Amsterdam:IOS Press, 2011:89-101.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_7" title=" BURGET F, BENNEWITZ M. Stance selection for humanoid grasping tasks by inverse reachability maps[C]//Proceedings of the 2015IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2015:5669-5674." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stance selection for humanoid grasping tasks by inverse reachability maps">
                                        <b>[7]</b>
                                         BURGET F, BENNEWITZ M. Stance selection for humanoid grasping tasks by inverse reachability maps[C]//Proceedings of the 2015IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2015:5669-5674.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_8" title="温淑慧, 王同辉, 薛红香, 等. NAO机器人的手臂建模及模糊控制算法研究[J].控制工程, 2018, 25 (4) :559-564. (WEN S H, WANG T H, XUE H X, et al. Study of arm dynamics modeling and fuzzy control of humanoid robots[J]. Control Engineering of China, 2018, 25 (4) :559-564.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=JZDF201804004&amp;v=MTg5NTJGeURoVUxyT0x6ZlBhTEc0SDluTXE0OUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        温淑慧, 王同辉, 薛红香, 等. NAO机器人的手臂建模及模糊控制算法研究[J].控制工程, 2018, 25 (4) :559-564. (WEN S H, WANG T H, XUE H X, et al. Study of arm dynamics modeling and fuzzy control of humanoid robots[J]. Control Engineering of China, 2018, 25 (4) :559-564.) 
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_9" title=" SAKAGAMI Y, WATANABE R, AOYAMA C, et al. The intelligent ASIMO:system overview and integration[C]//Proceedings of the 2002 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2002:2478-2483." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The intelligent ASIMO:System overview and integration">
                                        <b>[9]</b>
                                         SAKAGAMI Y, WATANABE R, AOYAMA C, et al. The intelligent ASIMO:system overview and integration[C]//Proceedings of the 2002 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2002:2478-2483.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_10" title=" MELLMANN H, SCHEUNEMANN M, STADIE O. Adaptive grasping for a small humanoid robot utilizing force and electric current sensors[EB/OL].[2018-05-10]. https://www2. informatik.hu-berlin. de/~mellmann/content/publications/data/CSP-Mellma nn Scheunemann EtA l-13. pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive grasping for a small humanoid robot utilizing force and electric current sensors">
                                        <b>[10]</b>
                                         MELLMANN H, SCHEUNEMANN M, STADIE O. Adaptive grasping for a small humanoid robot utilizing force and electric current sensors[EB/OL].[2018-05-10]. https://www2. informatik.hu-berlin. de/~mellmann/content/publications/data/CSP-Mellma nn Scheunemann EtA l-13. pdf.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_11" title=" HORNUNG A, WURM K M, BENNEWITZ M, et al. OctoM ap:an efficient probabilistic 3D mapping framework based on octrees[J]. Autonomous Robots, 2013, 34 (3) :189-206." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130523405830&amp;v=MjU4MjJkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3Zk1JMXNTTmo3QmFySzdIdFRPckl0RlllTU1EQk04enhVU21E&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         HORNUNG A, WURM K M, BENNEWITZ M, et al. OctoM ap:an efficient probabilistic 3D mapping framework based on octrees[J]. Autonomous Robots, 2013, 34 (3) :189-206.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_12" title=" LEIDNER D, DIETRICH A, SCHMIDT F, et al. Object-centered hybrid reasoning for whole-body mobile manipulation[C]//Proceedings of the 2014 IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2014:1828-1835." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object-centered hybrid reasoning for whole-body mobile manipulation">
                                        <b>[12]</b>
                                         LEIDNER D, DIETRICH A, SCHMIDT F, et al. Object-centered hybrid reasoning for whole-body mobile manipulation[C]//Proceedings of the 2014 IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2014:1828-1835.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_13" title="王秋玥, 方明, 张海涛.基于多空间混合约束的NAO机器人抓取轨迹规划[J].长春理工大学学报 (自然科学版) , 2014, 37 (6) :107-110. (WANG Q Y, FANG M, ZHANG H T. Grasp track planning with the NAO robot under mixed constraints of multispace[J]. Journal of Changchun University of Science and Technology (Natural Science Edition) , 2014, 37 (6) :107-110.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJM201406027&amp;v=MTExNTBac0Z5RGhVTHJPSmlyQlk3RzRIOVhNcVk5SFk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        王秋玥, 方明, 张海涛.基于多空间混合约束的NAO机器人抓取轨迹规划[J].长春理工大学学报 (自然科学版) , 2014, 37 (6) :107-110. (WANG Q Y, FANG M, ZHANG H T. Grasp track planning with the NAO robot under mixed constraints of multispace[J]. Journal of Changchun University of Science and Technology (Natural Science Edition) , 2014, 37 (6) :107-110.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-19 11:01</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1220-1223 DOI:10.11772/j.issn.1001-9081.2018091935            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于Octomap的仿人机器人局部环境与能力图模型算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%98%93%E5%BA%B7&amp;code=21130313&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">易康</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E7%8E%89%E5%A9%B7&amp;code=40882851&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵玉婷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BD%90%E6%96%B0%E7%A4%BE&amp;code=39024968&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">齐新社</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E9%80%9A%E4%BF%A1%E5%AD%A6%E9%99%A2%E8%AF%95%E9%AA%8C%E8%AE%AD%E7%BB%83%E5%9F%BA%E5%9C%B0&amp;code=0269230&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国防科技大学信息通信学院试验训练基地</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于3D点云数据的机器人三维空间能力图模型算法存在体素网格搜索计算量大的问题, 由于OcTree在三维空间细分时的层次化优势, 提出一种基于Octomap的局部环境与能力图模型算法。首先, 根据NAO机器人的关节组成、正向运动学、逆向运动学和刚体坐标变换, 对NAO仿人机器人构建全身二叉树状运动学模型;其次在此基础上使用前向运动学在笛卡儿空间计算离散的三维可达点云, 并将其作为机器人终端效应器的基础工作空间;然后重点描述将点云空间表示转化为Octomap空间节点表示的方法, 尤其是空间节点的概率更新方法;最后提出根据节点几何关系进行空间节点更新顺序选择的优化方法, 从而高效地实现了仿人机器人能力图的空间优化表示。实验结果表明, 相对于之前的原始Octomap更新方法, 优化后的算法能降低近30%空间节点数, 提高计算效率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BB%BF%E4%BA%BA%E6%9C%BA%E5%99%A8%E4%BA%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">仿人机器人;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E5%AD%A6%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动学模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Octomap&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Octomap;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8A%93%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">抓取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E5%8A%9B%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能力图;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *易康 (1981—) , 男, 湖南隆回人, 讲师, 硕士, 主要研究方向:深度学习;电子邮箱penfangs@163.com;
                                </span>
                                <span>
                                    赵玉婷 (1984—) , 女, 山西昔阳人, 副教授, 硕士, 主要研究方向:机器学习;;
                                </span>
                                <span>
                                    齐新社 (1973—) , 男, 陕西扶风人, 副教授, 硕士, 主要研究方向:数学建模、数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61702390);</span>
                    </p>
            </div>
                    <h1><b>Humanoid robot local environment and capability map model based on Octomap</b></h1>
                    <h2>
                    <span>YI Kang</span>
                    <span>ZHAO Yuting</span>
                    <span>QI Xinshe</span>
            </h2>
                    <h2>
                    <span>The Experimental and Training Base of College of Information and Communication, National University of Defense Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The 3 D capability map model of humanoid robot based on 3 D point cloud data has the disadvantage of large voxel mesh searching computation. Considering the hierarchical advantage of OcTree in 3 D space subdivision, a local environment and capability map model based on Octomap was proposed. Firstly, a binary-tree-like kinematics model of NAO humanoid robot was constructed according to the joint composition, forward kinematics, inverse kinematics and rigid body coordinate transformation of NAO robot. Secondly, the forward kinematics was used to calculate the 3 D discrete reachable point clouds in Cartesian space, which were used as the basic workspace of the robot terminal effector. Thirdly, the methods of transforming the point cloud space representation into Octomap space node representation, especially the probability updating method of space node, were described emphatically. Finally, an optimization method of space node updating order selection was proposed according to the geometric relationship of nodes. With this optimization method, the space optimization representation of the humanoid robot's capability map was realized efficiently. Experimental results show that compared with the original Octomap updating method, the proposed algorithm can reduce the number of space nodes by nearly 30% and improve the computional efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=humanoid%20robot&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">humanoid robot;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=kinematics%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">kinematics model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Octomap&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Octomap;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=grasp&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">grasp;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=capability%20map&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">capability map;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YI Kang, born in 1981, M. S. , lecturer. His research interests include deep learning.;
                                </span>
                                <span>
                                    ZHAO Yuting, born in 1984, M. S. , associate professor. Her research interests include machine learning.;
                                </span>
                                <span>
                                    QI Xinshe, born in 1973, M. S. , associate professor. His research interests include mathematical modeling, data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-18</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61702390);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="30">机器人作为一种最典型的应用范围广、技术附加值高的数字控制装备, 在现代先进生产制造业中发挥越来越重要的作用。除工业机器人外, 仿人机器人是模仿人的形态和行为而设计制造的机器人, 一般由模仿人头部、四肢和躯干的机器人连杆和大量的传感器组成。搬运工业机器人大都是通过示教或预编程对其进行操作的, 机器人只是完成点到点的动作, 不能适应真实的复杂场景中对于物体感知识别定位和进行人机交互。如今人们对机器人技术提出了更高的要求, 希望机器人具有更高的智能和更强的环境适应能力。标定的彩色和深度图像<citation id="157" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是机器人感知环境的重要信息来源, 抓取是机器人最基本的功能也是最重要的功能之一<citation id="158" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 结合视觉信息对仿人机器人的抓取控制反馈, 是仿人机器人具备更加智能化的感知能力的前提, 也是如今研究的重点。</p>
                </div>
                <div class="p1">
                    <p id="31">要构建仿人机器人局部环境与能力图, 需要对机器人进行运动学建模, 在这方面国内外有大量的文献支撑。针对NAO的运动学建模在文献<citation id="159" type="reference">[<a class="sup">3</a>]</citation>中有详细描述, Kofinas等<citation id="160" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>将NAO机器人分解成五个独立的部分, 得出了NAO机器人完整的正逆运动学的解析解。文献<citation id="161" type="reference">[<a class="sup">5</a>]</citation>最早提出了机器人能力图的表示方法和构建方法, 文献<citation id="162" type="reference">[<a class="sup">6</a>]</citation>则进一步提出了NAO机器人的能力图构建和表示方法。本文在此基础上提出了一种基于Octomap的机器人局部环境与能力图模型算法, 并提出根据节点几何关系进行空间节点更新顺序选择的优化方法。</p>
                </div>
                <h3 id="32" name="32" class="anchor-tag">1 仿人机器人的运动学建模</h3>
                <h4 class="anchor-tag" id="33" name="33">1.1 NAO<b>仿人机器人建模</b></h4>
                <div class="p1">
                    <p id="34">机器人的运动学主要研究机器人连杆或终端效应器相对于某个特定参考坐标系的运动几何学关系, 为控制机器人运动提供手段和方法。本节分别介绍对仿人机器人NAO的运动学抽象与建模和正逆问题<citation id="163" type="reference"><link href="135" rel="bibliography" /><link href="143" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">7</a>]</sup></citation>求解。</p>
                </div>
                <div class="p1">
                    <p id="35">本文系统使用的是日本软银公司的NAO仿人机器人平台。NAO机器人有25个自由度, 下半身包括腿和骨盆共有11个自由度, 上半身的脑袋、手臂和躯干共14个自由度。每个手臂在肩膀上有2个自由度, 肘部有2个自由度, 手腕1个自由度, 还有1个自由度用来控制手的操作<citation id="164" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="36">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 仿人机器人的建模" src="Detail/GetImg?filename=images/JSJY201904046_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 仿人机器人的建模  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Modeling of humanoid robot</p>

                </div>
                <div class="p1">
                    <p id="37">对机器人的连杆和关节角进行分离, 每个连杆都有两个分支, 以二叉树的形式表示连杆之间的关系:左子树表示“子”连杆;右子树表示“兄弟”连杆, 如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="38">为了从二叉树结构的连杆关系中获取相邻连杆的关系, 从树根开始记为1, 依次给每个连杆一个编号, 这样对于机器人的任意连杆都可以以二叉树遍历的方式进行访问。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">1.2 <b>正向运动学计算</b></h4>
                <div class="p1">
                    <p id="40">正向运动学 (Forward Kinematics, FK) 通过计算连杆关节角配置解决终端效应器的六自由度 (6 Degree of Freedom, 6DoF) 位姿问题。根据机器人链式法则, 计算得到目标连杆的位置与姿态矩阵<citation id="165" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="41"><b><i>p</i></b><sub><i>j</i></sub>= <b><i>p</i></b><sub><i>i</i></sub>+<b><i>R</i></b><sub><i>i</i></sub>·<b><i>b</i></b><sub><i>j</i></sub>      (1) </p>
                </div>
                <div class="p1">
                    <p id="42" class="code-formula">
                        <mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi>e</mi><msup><mrow></mrow><mrow><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>⋅</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="43">其中: <b><i>p</i></b><sub><i>i</i></sub>为连杆的平移变换;<b><i>R</i></b><sub><i>i</i></sub>为连杆的旋转变换;<b><i>b</i></b><sub><i>j</i></sub>是相对母连杆的相对位置;<b><i>a</i></b><sub><i>j</i></sub>表示相对母连杆的关节轴矢量;<i>q</i><sub><i>j</i></sub>是关节角。<mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msup><mrow></mrow><mrow><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>⋅</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow></math></mathml>是著名的Rodrigues公式:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msup><mrow></mrow><mrow><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>⋅</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msup><mo>=</mo><mi mathvariant="bold-italic">E</mi><mo>+</mo><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>^</mo></mover><mo>⋅</mo><mrow><mi>sin</mi></mrow><mspace width="0.25em" /><mi>θ</mi><mo>+</mo><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>^</mo></mover><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mrow><mi>cos</mi></mrow><mspace width="0.25em" /><mi>θ</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="46" name="46">1.3 <b>逆向运动学计算</b></h4>
                <div class="p1">
                    <p id="47">在机器人技术中, 逆向运动学 (Inverse Kinematics, IK) <citation id="166" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>利用运动学方程来确定为机器人末端执行器提供期望位置的关节参数, 将机器人的运动规划转化为关节运动向量从而指导与关节级联的电机的运动。本文采用的是通过迭代求解正运动学问题而得到最优近似解的算法<citation id="167" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 其核心思想就是对正运动学方程进行建模, 在一定的误差范围内停止迭代计算。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48">1.4 <b>刚体坐标转换</b></h4>
                <div class="p1">
                    <p id="49">一个物体在空间的表示可以这样实现<citation id="168" type="reference"><link href="135" rel="bibliography" /><link href="147" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">9</a>]</sup></citation>:通过在它上面固连的一个局部坐标系, 由于坐标系一直固连在该物体上, 因此只要这个坐标系在空间表示出来, 它相对于机器人坐标系的变换矩阵求出来, 那么这个物体相对于固定坐标系的位姿也就已知了。</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mtext>R</mtext><mtext>o</mtext><mtext>b</mtext><mtext>o</mtext><mtext>t</mtext></mrow></msup><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext><mtext>e</mtext><mtext>c</mtext><mtext>t</mtext></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><msup><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msup><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext><mtext>e</mtext><mtext>c</mtext><mtext>t</mtext></mrow></msub></mtd><mtd><msup><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msup><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext><mtext>e</mtext><mtext>c</mtext><mtext>t</mtext></mrow></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ο</mi></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>⋅</mo><msup><mrow></mrow><mrow><mtext>R</mtext><mtext>o</mtext><mtext>b</mtext><mtext>o</mtext><mtext>t</mtext></mrow></msup><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">其中:<sup>Robot</sup><b><i>T</i></b><sub>local</sub>表示从物体局部坐标系到机器人坐标系的齐次坐标变换, 根据固定在NAO机器人头上立体传感器位置所确定。在本文中, NAO机器人使用左手坐标系, 而立体传感器使用右手坐标系, 从右手坐标系转到左手坐标系需要调整轴的顺序, 因此在齐次变换之前对三轴进行变换, [<i>x</i>, <i>y</i>, <i>z</i>]=[<i>x</i>, <i>z</i>, <i>y</i>], 之后计算相机到头的平移量得到<sup>Robot</sup><b><i>T</i></b><sub>local</sub>齐次变换矩阵:</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mtext>R</mtext><mtext>o</mtext><mtext>b</mtext><mtext>o</mtext><mtext>t</mtext></mrow></msup><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">E</mi></mtd><mtd><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>, </mo><mn>0</mn><mo>.</mo><mn>1</mn><mn>2</mn><mn>6</mn><mtext> </mtext><mn>5</mn><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ο</mi></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="53" name="53" class="anchor-tag">2 仿人机器人能力图</h3>
                <div class="p1">
                    <p id="54">机器人的工作空间是机器人使用末端效应器影响环境的一部分, 因此, 仿人机器人<i>NAO</i>的工作空间是它的手、脚或头能够到达环境的一部分。机器人的这些部分位于各自的运动连杆的末端, 是机器人与周围世界互动的主要方式。众所周知, 每个终端效应器能够工作的工作空间非常重要, 因为它保证机器人得以继续完成之后的任务。仿人机器人试图抓取能力空间以外的物体, 将导致电机发热, 甚至失衡等严重后果。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">2.1 <b>能力图运动学表示</b></h4>
                <div class="p1">
                    <p id="56">当确定机器人能力内的工作空间时, 不仅仅是确定空间中三维点的坐标, 应该还包括点上对应的旋转位姿, 这样可以称作机器人终端效应器的灵巧空间, 本节将集中在机器人手操作的能力图<citation id="169" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>中, 并通过机器人运动学的方式求解, 这对于成功完成抓取任务是非常重要的。</p>
                </div>
                <div class="p1">
                    <p id="57">为机器人的运动链构建可达图, 需要从关节电机空间进行采样。通过计算每个样本的正向运动学, 可以确定末端执行器的空间工作空间, 算法如下。</p>
                </div>
                <div class="p1">
                    <p id="58">1) 初始化机器人连杆位姿及关节向量。</p>
                </div>
                <div class="p1">
                    <p id="59">2) 在关节电机向量样本空间进行采样:<b><i>Vq</i></b><sub>lsp</sub>、<b><i>Vq</i></b><sub>lsr</sub>、<b><i>Vq</i></b><sub>ley</sub>和<b><i>Vq</i></b><sub>ler</sub>。</p>
                </div>
                <div class="p1">
                    <p id="60">3) 对所有采样样本进行笛卡儿积遍历:<b><i>Vq</i></b>=<b><i>Vq</i></b><sub>lsp</sub>·<b><i>Vq</i></b><sub>lsr</sub>·<b><i>Vq</i></b><sub>ley</sub>·<b><i>Vq</i></b><sub>ler</sub></p>
                </div>
                <div class="p1">
                    <p id="62">4) 对样本空间的所有采样计算正向运动学得到终端效应器位姿:<b><i>C</i></b><sub><i>S</i></sub>= (<b><i>p</i></b>, <b><i>R</i></b>) =<i>FK</i> (<b><i>Vq</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="64">这种基于运动学的方法需要知道机器人的前臂和上臂的恒定长度。对于仿人机器人NAO来说, 通过肩关节和肘关节角运动范围和连杆长度确定工作空间。如表1和表2所示, 这里以机器人左臂为例。</p>
                </div>
                <div class="area_img" id="65">
                    <p class="img_tit"><b>表</b>1 NAO<b>机器人关节电机采样空间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Sampling space of NAO robot joint motor</p>
                    <p class="img_note"></p>
                    <table id="65" border="1"><tr><td><br />关节名称</td><td>采样范围/rad</td><td>说明</td></tr><tr><td><br />LShoulderPicth</td><td>-2.085 7～2.085 7</td><td>左肩关节绕<i>Y</i>轴旋转范围</td></tr><tr><td><br />LShoulderRoll</td><td>-0.314 2～1.326 5</td><td>左肩关节绕<i>Z</i>轴旋转范围</td></tr><tr><td><br />LElbowYaw</td><td>-2.085 7～2.085 7</td><td>左肘关节绕<i>X</i>轴旋转范围</td></tr><tr><td><br />LElbowRoll</td><td>-1.544 6～-0.034 9</td><td>左肘关节绕<i>Z</i>轴旋转范围</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="66">
                    <p class="img_tit"><b>表</b>2 NAO<b>机器人连杆长度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Length of NAO robot connecting rod</p>
                    <p class="img_note"></p>
                    <table id="66" border="1"><tr><td><br />连杆名称</td><td>长度/mm</td><td>连杆名称</td><td>长度/mm</td></tr><tr><td><br />上臂长度</td><td>105.00</td><td>肩关节偏移量</td><td>98.00</td></tr><tr><td><br />下臂长度</td><td>55.95</td><td>肘关节偏移量</td><td>15.00</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="67">图2表明, 机械手的工作空间是一个近似球形的形状, 集中在机器人的肩部<citation id="170" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。形状向仿人机器人的背面变形, 后面的某些点是不可到达的, 为了绘图的目的, 旋转的结果就是丢弃这部分, 只表征了空间的三维点。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 仿人机器人NAO左手工作空间的三维点云表示" src="Detail/GetImg?filename=images/JSJY201904046_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 仿人机器人NAO左手工作空间的三维点云表示  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 3D point cloud representation of humanoid robot NAO left hand workspace</p>

                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2 <b>能力图</b>Octomap<b>表示</b></h4>
                <h4 class="anchor-tag" id="70" name="70">2.2.1 <i>Octomap</i>表示的必要性</h4>
                <div class="p1">
                    <p id="71">从上文可知, 给定目标物体的6<i>DoF</i>位姿<sup>Robot</sup><b><i>F</i></b><sub>object</sub>, 根据上述算法得到离散空间点的计算取决于采样精度。判断目标物体是否在工作空间之内, 将遭受暴力搜索带来的时间效率上的延迟, 并且, 在基于采样空间是仿人机器人实际的灵巧空间的子集的前提下:<b><i>C</i></b><sub><i>S</i></sub>⊂<b><i>C</i></b><sub><b><i>R</i></b></sub>, 推导出:∃<b><i>p</i></b>∈<b><i>C</i></b><sub><b><i>R</i></b></sub>, <b><i>p</i></b>∉<b><i>C</i></b><sub><i>S</i></sub>, 因此, 为了降低维度和进行高效地体素网格搜索, 更新空间表示的数据结构是必不可少的<citation id="171" type="reference"><link href="141" rel="bibliography" /><link href="149" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">10</a>]</sup></citation>。本节试图通过Octomap这种新的表示方法来构建能力图和局部环境, 并提出通过空节点优化提升构建效率的方法。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">2.2.2 使用Octomap对三维空间建模</h4>
                <div class="p1">
                    <p id="73">基于<i>OcTree</i>的三维空间地图<i>Octomap</i>可完成三维空间地图构建<citation id="172" type="reference"><link href="151" rel="bibliography" /><link href="153" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。<i>Octomap</i>是一个开放源码且抽象封装的<i>C</i>++库。它基于伯克利软件发行版 (<i>Berkeley Software Distribution</i>, <i>BSD</i>) 协议许可证, 并在<i>GitHub</i>上发布, 体现了完整的开放源码理念和思想, 为智能移动机器人三维空间地图的研究创造了新起点。<i>OcTree</i>是一种用于三维空间细分的层次化数据结构, 八叉树中的每个节点表示包含在立方体的空间, 通常称为体素。这些体素通常递归地被八分割直到达到<i>Octomap</i>的最小分辨率, 图3展示八分割的原理。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 存储空闲和占用单元的八叉树示例" src="Detail/GetImg?filename=images/JSJY201904046_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 存储空闲和占用单元的八叉树示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Octree example of free and occupied storing unit</i></p>

                </div>
                <div class="p1">
                    <p id="75">最小体素大小决定了八叉树的分辨率。在<i>Octomap</i>的实现中, 八叉树的层次最大到16层以表征足够大的真实空间, 其中三轴的尺度由式 (6) 表示:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mi>l</mi><mi>e</mi><mi>v</mi><mi>e</mi><mi>l</mi></mrow></msup></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>Y</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mi>l</mi><mi>e</mi><mi>v</mi><mi>e</mi><mi>l</mi></mrow></msup></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>Ζ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mi>l</mi><mi>e</mi><mi>v</mi><mi>e</mi><mi>l</mi></mrow></msup></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中:<i>level</i>表示八叉树的层数。为了替换空间坐标中的负数, 坐标原点位置如式 (7) 所示。</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo></mrow><mn>2</mn></mfrac><mo>, </mo><mfrac><mrow><mo stretchy="false">|</mo><mi>Y</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo></mrow><mn>2</mn></mfrac><mo>, </mo><mfrac><mrow><mo stretchy="false">|</mo><mi>Ζ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">|</mo></mrow><mn>2</mn></mfrac><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">举个例子, 当树的分辨率为0.01, 最大层次到16层的情况下, 坐标原点表示如式 (8) ～ (9) 所示:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>1</mn><mn>5</mn></mrow></msup><mo>=</mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>7</mn><mn>6</mn><mn>8</mn></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>1</mn><mn>5</mn></mrow></msup><mo>=</mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>7</mn><mn>6</mn><mn>8</mn></mtd></mtr><mtr><mtd><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>1</mn><mn>5</mn></mrow></msup><mo>=</mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>7</mn><mn>6</mn><mn>8</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ο</mi><mo>=</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mspace width="0.25em" /><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">假设空间中存在点<b><i>p</i></b>= (1, -1, 1) 在Octomap中的表示如式 (10) 所示:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi mathvariant="bold-italic">p</mi><mo>′</mo></msup><mo>=</mo><mi mathvariant="bold-italic">Ο</mi><mo>+</mo><mfrac><mi mathvariant="bold-italic">p</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></mfrac><mo>=</mo><mo stretchy="false"> (</mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>8</mn><mn>6</mn><mn>8</mn><mo>, </mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>6</mn><mn>6</mn><mn>8</mn><mo>, </mo><mn>3</mn><mn>2</mn><mtext> </mtext><mn>8</mn><mn>6</mn><mn>8</mn><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">将向量中的值转化成二进制的表示形式, 根据三轴每个层次的二进制值组合, 可以得到空间点在Octomap中每个层次的状态, 如表3所示。</p>
                </div>
                <div class="p1">
                    <p id="84">从上到下、从左往右, 得到向量<b><i>V</i></b>=<citation id="173" type="reference">[<a class="sup">2</a>,<a class="sup">5</a>,<a class="sup">7</a>]</citation>表示空间点<b><i>p</i></b>= (1, -1, 1) 在Octomap中每一层节点的序号。</p>
                </div>
                <div class="p1">
                    <p id="85">在实时局部环境中, 往往会受到噪点和移动物体的影响, 在更新Octomap节点时候, 使用概率的方式表征某个节点占有、未知、空的三个状态。叶子节点<i>n</i>在传感器测量时间范围<i>z</i><sub>1:<i>t</i></sub>被占有的概率<i>P</i> (<i>n</i>|<i>z</i><sub>1:<i>t</i></sub>) 可表示根据式 (11) 确定:</p>
                </div>
                <div class="area_img" id="130">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201904046_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="88">通过对式子log-odds变换, 将概率空间解变换到实数空间得到:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>α</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mfrac><mi>Ρ</mi><mrow><mn>1</mn><mo>-</mo><mi>Ρ</mi></mrow></mfrac><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mi>α</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi>α</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>:</mo><mi mathvariant="bold-italic">Τ</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mn>1</mn><mo>:</mo><mi mathvariant="bold-italic">Τ</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Τ</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">因此, 对空间点状态的概率问题在最大值和最小值限定的前提下转化成了实数空间的加和问题。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表</b>3 <b>空间点在</b>Octomap<b>中每个层次的状态示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Status samples of space points in each level of Octomap</p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td>层次</td><td><i>x</i></td><td><i>y</i></td><td><i>z</i></td><td>层次</td><td><i>x</i></td><td><i>y</i></td><td><i>z</i></td></tr><tr><td><br />15</td><td>1</td><td>0</td><td>1</td><td>7</td><td>0</td><td>1</td><td>0</td></tr><tr><td><br />14</td><td>0</td><td>1</td><td>0</td><td>6</td><td>1</td><td>0</td><td>1</td></tr><tr><td><br />13</td><td>0</td><td>1</td><td>0</td><td>5</td><td>1</td><td>0</td><td>1</td></tr><tr><td><br />12</td><td>0</td><td>1</td><td>0</td><td>4</td><td>0</td><td>1</td><td>0</td></tr><tr><td><br />11</td><td>0</td><td>1</td><td>0</td><td>3</td><td>0</td><td>1</td><td>0</td></tr><tr><td><br />10</td><td>0</td><td>1</td><td>0</td><td>2</td><td>1</td><td>1</td><td>1</td></tr><tr><td><br />9</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td><br />8</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:<i>x</i>=32 868, <i>y</i>=32 668, <i>z</i>=32 868。</p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">2.2.3 空节点优化</h4>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 节点构建示意图" src="Detail/GetImg?filename=images/JSJY201904046_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 节点构建示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>Schematic diagram of</i><i>node construction</i></p>

                </div>
                <div class="p1">
                    <p id="94">构建和更新Octomap的过程中, 需要当完成节点<b><i>V</i></b><sub>1</sub>构建之后, 在以某一轴为基准的前提下需要确认在另外两轴构建节点的优先级, 如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="95">假设三个节点分别表示为<b><i>V</i></b><sub>1</sub>= (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) , <b><i>V</i></b><sub>2</sub>= (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>+1) , <b><i>V</i></b><sub>3</sub>= (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>+1, <i>z</i><sub>0</sub>+1) , 且节点的分辨率为<b><i>R</i></b>, 在沿着虚线构建的过程中, 规定它的起点和终点分别是<b><i>s</i></b>= (<i>x</i><sub>s</sub>, <i>y</i><sub>s</sub>, <i>z</i><sub>s</sub>) 和<b><i>e</i></b>= (<i>x</i><sub>e</sub>, <i>y</i><sub>e</sub>, <i>z</i><sub>e</sub>) , 得到三轴的偏移量分别是:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mtext>Δ</mtext><mi>x</mi><mo>=</mo><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mtext>e</mtext></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mtext>Δ</mtext><mi>y</mi><mo>=</mo><mo stretchy="false">|</mo><mi>y</mi><msub><mrow></mrow><mtext>e</mtext></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mtext>Δ</mtext><mi>z</mi><mo>=</mo><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mtext>e</mtext></msub><mo>-</mo><mi>z</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">|</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">要确定优先构建的节点, 需要确定<b><i>p</i></b><sub>1</sub>的值, 根据几何关系可以得到:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mn>3</mn></msub><mtext>Δ</mtext><mi>x</mi><mo>×</mo><mtext>Δ</mtext><mi>z</mi><mo>-</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mn>2</mn></msub><mtext>Δ</mtext><mi>x</mi><mo>×</mo><mtext>Δ</mtext><mi>y</mi></mrow><mrow><mtext>Δ</mtext><mi>x</mi><mo>×</mo><mtext>Δ</mtext><mi>z</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">当<b><i>p</i></b><sub>1</sub>&gt;0优先构建<b><i>V</i></b><sub>2</sub>, 反之优先构建<b><i>V</i></b><sub>3</sub>。</p>
                </div>
                <h3 id="100" name="100" class="anchor-tag">3 实验与结果分析</h3>
                <div class="p1">
                    <p id="101">为验证本文提出的空间建模方法, 实验中参考利用<i>NAO</i>机器人仿真平台进行其自身能力图的仿真测试, 同时动态更新地图中采用<i>Kinect</i><b><i>V</i></b><sub>1</sub>传感器作为视觉输入, 进行环境数据采集, Kinect <b><i>V</i></b><sub>1</sub>可以同时获取环境的色彩数据和深度数据, 并形成点云数据作为动态环境地图的数据输入。</p>
                </div>
                <div class="p1">
                    <p id="102">动态更新的三维地图和静态构建的能力图为仿人机器人在未知环境中提供了重要信息, 如图5所示的例子中, 仿人机器人需要至少移动<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Τ</mi><mo>=</mo><mi mathvariant="bold-italic">b</mi><mo>-</mo><mo stretchy="false">|</mo><mi>r</mi><mo stretchy="false">|</mo><mfrac><mi mathvariant="bold-italic">b</mi><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>抓取到目标物体。在不考虑旋转的前提下, 能力图对最小移动距离进行了限定。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 仿人机器人位置模拟" src="Detail/GetImg?filename=images/JSJY201904046_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 仿人机器人位置模拟  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Position simulation of humanoid robot</p>

                </div>
                <div class="p1">
                    <p id="105">本文使用0.01的分辨率在可达离散空间的基础上构建了静态能力图, 如图6所示。注意, 本文为了展示效果忽略了旋转。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 能力图Octomap表示" src="Detail/GetImg?filename=images/JSJY201904046_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 能力图Octomap表示  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Octomap representation of capability map</p>

                </div>
                <div class="p1">
                    <p id="107">通过上文提到空节点优化, 在更新节点时, 能够大量减少空节点数目从而提升效率、降低冗余率, 如图7所示, 图中浅色点为空间中的空节点, 深色点为可达到的最远节点。从图7中可以明显看出, 图 (b) 中空节点的数量明显低于图 (a) 。统计结果表示优化后的Octomap相对于优化之前, 空间节点节省近30%。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 优化前后节点数量对比" src="Detail/GetImg?filename=images/JSJY201904046_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 优化前后节点数量对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison of number of nodes before and after optimization</p>

                </div>
                <div class="p1">
                    <p id="109">动态更新的三维地图考虑到机器人非质点的自碰撞, 向外膨胀了0.06 m, 构建如图8所示。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904046_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 三维场景模拟" src="Detail/GetImg?filename=images/JSJY201904046_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 三维场景模拟  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904046_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 3D scene simulation</p>

                </div>
                <h3 id="111" name="111" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="112">仿人机器人在空间中抓取目标物体是一项复杂的工程, 在整个过程中, 获取自身终端效应器能力图以及局部环境的信息, 是完成抓取操作的前提之一。本文以仿人机器人<i>NAO</i>作为平台, 对链式的连杆和关节进行抽象建模, 并以此为基础构建了基于运动学的离散能力空间, 随后使用<i>Octomap</i>作为数据结构, 提出一种基于<i>Octomap</i>的局部环境与能力图模型算法, 在此基础上提出了根据节点几何关系进行空间节点更新顺序选择的优化方法, 降低了空节点的数量, 从而提升了构建效率。但是, 实现仿人机器人的抓取, 还需要视觉、导航等多个模块的协同。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="131">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accuracy analysis of Kinect depth data">

                                <b>[1]</b> KHOSHELHAM K. Accuracy analysis of Kinect depth data[EB/OL].[2018-05-10]. https://people. eng. unimelb. edu. au/kkhoshelham/research_files/kinectaccuracy/isprsarchives-XXXVIII-5-W12-133-2011. pdf.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201307003&amp;v=Mjc2NzVGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVMck9LQ0xmWWJHNEg5TE1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> TAN M, WANG S. Research progress on robotics[J]. Acta Automatica Sinica, 2013, 39 (7) :963-972.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302144533001&amp;v=MDc2ODlORElxNHBHWitzUERSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlublU3Zk1JMXNTWEZxekdiQzRI&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>梶田秀司.仿人机器人[M].北京:清华大学出版社, 2007:44-50. (SHUUJI K. Humanoid Robots[M]. Beijing:Tsinghua University Press, 2007:44-50.) 
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15011600014340&amp;v=MjI4MjZud1plWnRGaW5sVXIzSUtGb1hieFE9Tmo3QmFySzlIdEROcVk5RlpPb0xEM2c1b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> KOFINAS N, ORFANOUDAKIS E, LAGOUDAKIS M G. Complete analytical forward and inverse kinematics for the NAO humanoid robot[J]. Journal of Intelligent&amp;Robotic Systems, 2015, 77 (2) :251-264.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Capturing robot workspace structure:representing robot capabilities">

                                <b>[5]</b> ZACHARIAS F, BORST C, HIRZINGER G. Capturing robot workspace structure:representing robot capabilities[C]//Proceedings of the 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2007:3229-3236.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SIJD&amp;filename=SIJD00000035843&amp;v=MjkxNzZXN3ZMSlZnPU5pVEJhck80SHRITXI0eEFiTzhNWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXJs&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> MELLMANN H, COTUGNO G. Dynamic Motion Control:Adaptive Bimanual Grasping for a Humanoid Robot[M]. Amsterdam:IOS Press, 2011:89-101.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stance selection for humanoid grasping tasks by inverse reachability maps">

                                <b>[7]</b> BURGET F, BENNEWITZ M. Stance selection for humanoid grasping tasks by inverse reachability maps[C]//Proceedings of the 2015IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2015:5669-5674.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=JZDF201804004&amp;v=MjEwMzZxQnRHRnJDVVI3cWZadVpzRnlEaFVMck9MemZQYUxHNEg5bk1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>温淑慧, 王同辉, 薛红香, 等. NAO机器人的手臂建模及模糊控制算法研究[J].控制工程, 2018, 25 (4) :559-564. (WEN S H, WANG T H, XUE H X, et al. Study of arm dynamics modeling and fuzzy control of humanoid robots[J]. Control Engineering of China, 2018, 25 (4) :559-564.) 
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The intelligent ASIMO:System overview and integration">

                                <b>[9]</b> SAKAGAMI Y, WATANABE R, AOYAMA C, et al. The intelligent ASIMO:system overview and integration[C]//Proceedings of the 2002 IEEE/RSJ International Conference on Intelligent Robots and Systems. Piscataway, NJ:IEEE, 2002:2478-2483.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive grasping for a small humanoid robot utilizing force and electric current sensors">

                                <b>[10]</b> MELLMANN H, SCHEUNEMANN M, STADIE O. Adaptive grasping for a small humanoid robot utilizing force and electric current sensors[EB/OL].[2018-05-10]. https://www2. informatik.hu-berlin. de/~mellmann/content/publications/data/CSP-Mellma nn Scheunemann EtA l-13. pdf.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130523405830&amp;v=MjIwNTIzeEU5ZmJ2bktyaWZaZVp2RnlublU3Zk1JMXNTTmo3QmFySzdIdFRPckl0RlllTU1EQk04enhVU21EZDlTSDdu&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> HORNUNG A, WURM K M, BENNEWITZ M, et al. OctoM ap:an efficient probabilistic 3D mapping framework based on octrees[J]. Autonomous Robots, 2013, 34 (3) :189-206.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object-centered hybrid reasoning for whole-body mobile manipulation">

                                <b>[12]</b> LEIDNER D, DIETRICH A, SCHMIDT F, et al. Object-centered hybrid reasoning for whole-body mobile manipulation[C]//Proceedings of the 2014 IEEE International Conference on Robotics and Automation. Piscataway, NJ:IEEE, 2014:1828-1835.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJM201406027&amp;v=MTIwNzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVMck9KaXJCWTdHNEg5WE1xWTlIWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>王秋玥, 方明, 张海涛.基于多空间混合约束的NAO机器人抓取轨迹规划[J].长春理工大学学报 (自然科学版) , 2014, 37 (6) :107-110. (WANG Q Y, FANG M, ZHANG H T. Grasp track planning with the NAO robot under mixed constraints of multispace[J]. Journal of Changchun University of Science and Technology (Natural Science Edition) , 2014, 37 (6) :107-110.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904046" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904046&amp;v=MTI4ODZxZlp1WnNGeURoVUxyT0x6N0JkN0c0SDlqTXE0OUJZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
