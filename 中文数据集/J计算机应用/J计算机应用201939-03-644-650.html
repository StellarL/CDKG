<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991530260000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903006%26RESULT%3d1%26SIGN%3dlCPPavJXjPmfOSpfBFFWFKK0zeI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903006&amp;v=MjA1ODc0SDlqTXJJOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzcvS0x6N0JkN0c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="1.1 &lt;b&gt;主动学习算法概述&lt;/b&gt;">1.1 <b>主动学习算法概述</b></a></li>
                                                <li><a href="#44" data-title="1.2 &lt;b&gt;卷积神经网络文本分类&lt;/b&gt;">1.2 <b>卷积神经网络文本分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="2 CNN分类模型改进算法 ">2 CNN分类模型改进算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="2.1 &lt;b&gt;主动学习算法的改进&lt;/b&gt;">2.1 <b>主动学习算法的改进</b></a></li>
                                                <li><a href="#142" data-title="2.2 SVD-CNN&lt;b&gt;模型&lt;/b&gt;">2.2 SVD-CNN<b>模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="3 弹幕分类解决方案的构建 ">3 弹幕分类解决方案的构建</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#169" data-title="3.1 &lt;b&gt;弹幕分类模型优化算法&lt;/b&gt;">3.1 <b>弹幕分类模型优化算法</b></a></li>
                                                <li><a href="#195" data-title="3.2 &lt;b&gt;模型描述&lt;/b&gt;">3.2 <b>模型描述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#205" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#206" data-title="4.1 &lt;b&gt;实验数据与参数设置&lt;/b&gt;">4.1 <b>实验数据与参数设置</b></a></li>
                                                <li><a href="#212" data-title="4.2 &lt;b&gt;算法性能验证&lt;/b&gt;">4.2 <b>算法性能验证</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#230" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="图1 CNN模型结构">图1 CNN模型结构</a></li>
                                                <li><a href="#155" data-title="图2 SVD-CNN模型">图2 SVD-CNN模型</a></li>
                                                <li><a href="#197" data-title="图3 SVD-CNN算法解决方案">图3 SVD-CNN算法解决方案</a></li>
                                                <li><a href="#209" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验使用的数据集&lt;/b&gt;"><b>表</b>1 <b>实验使用的数据集</b></a></li>
                                                <li><a href="#211" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;模型参数设置&lt;/b&gt;"><b>表</b>2 <b>模型参数设置</b></a></li>
                                                <li><a href="#215" data-title="图4 不同模型精度下各个算法采样次数对比">图4 不同模型精度下各个算法采样次数对比</a></li>
                                                <li><a href="#219" data-title="图5 不同数据集下各个分类模型的分类性能">图5 不同数据集下各个分类模型的分类性能</a></li>
                                                <li><a href="#223" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同句向量维度下模型分类正确率对比&lt;/b&gt;"><b>表</b>3 <b>不同句向量维度下模型分类正确率对比</b></a></li>
                                                <li><a href="#228" data-title="图6 迭代次数对模型训练稳定性的影响">图6 迭代次数对模型训练稳定性的影响</a></li>
                                                <li><a href="#229" data-title="图7 不同训练时间下模型分类正确率对比">图7 不同训练时间下模型分类正确率对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="249">


                                    <a id="bibliography_1" title="谭侃, 高旻, 李文涛, 等.基于双层采样主动学习的社交网络虚假用户检测方法[J].自动化学报, 2017, 43 (3) :448-461. (TANK, GAO M, LI W T, et al.Two-layer sampling active learning algorithm for social spammer detection[J].Acta Automatica Sinica, 2017, 43 (3) :448-461.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703012&amp;v=MTM1Njc0SDliTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzcvS0tDTGZZYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        谭侃, 高旻, 李文涛, 等.基于双层采样主动学习的社交网络虚假用户检测方法[J].自动化学报, 2017, 43 (3) :448-461. (TANK, GAO M, LI W T, et al.Two-layer sampling active learning algorithm for social spammer detection[J].Acta Automatica Sinica, 2017, 43 (3) :448-461.) 
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_2" title="徐海龙, 别晓峰, 冯卉, 等.一种基于QBC的SVM主动学习算法[J].系统工程与电子技术, 2015, 37 (12) :2865-2871. (XU H L, BIE X F, FENG H, et al.Active learning algorithm for SVM based on QBC[J].Systems Engineering and Electronics, 2015, 37 (12) :2865-2871.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYD201512032&amp;v=MDc5NjdmWnVacEZpRGxXNy9LUFRuU2FyRzRIOVROclk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        徐海龙, 别晓峰, 冯卉, 等.一种基于QBC的SVM主动学习算法[J].系统工程与电子技术, 2015, 37 (12) :2865-2871. (XU H L, BIE X F, FENG H, et al.Active learning algorithm for SVM based on QBC[J].Systems Engineering and Electronics, 2015, 37 (12) :2865-2871.) 
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_3" title="姚拓中, 安鹏, 宋加涛.基于历史分类加权和分级竞争采样的多视角主动学习[J].电子学报, 2017, 45 (1) :46-53. (YAO T Z, AN P, SONG J T.Multi-view active learning based on weighted hypothesis boosting and hierarchical competition sampling[J].Atca Electronica Sinica, 2017, 45 (1) :46-53.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201701007&amp;v=MzE3NzA1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tJVGZUZTdHNEg5Yk1ybzlGWTRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        姚拓中, 安鹏, 宋加涛.基于历史分类加权和分级竞争采样的多视角主动学习[J].电子学报, 2017, 45 (1) :46-53. (YAO T Z, AN P, SONG J T.Multi-view active learning based on weighted hypothesis boosting and hierarchical competition sampling[J].Atca Electronica Sinica, 2017, 45 (1) :46-53.) 
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_4" title="LI M, WANG R, TANG K.Combining semi-supervised and active learning for hyperspectral image classification[C]//Proceedings of the 2013 IEEE Symposium on Computational Intelligence and Data Mining.Piscataway, NJ:IEEE, 2013:89-94." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining Semi-Supervised and Active Learning for Hyperspectral Image Classification">
                                        <b>[4]</b>
                                        LI M, WANG R, TANG K.Combining semi-supervised and active learning for hyperspectral image classification[C]//Proceedings of the 2013 IEEE Symposium on Computational Intelligence and Data Mining.Piscataway, NJ:IEEE, 2013:89-94.
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_5" title="WAN L, TANG K, LI M, et al.Collaborative active and semisupervised learning for hyperspectral remote sensing image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2384-2396." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative active and semisupervised learning for hyperspectral remote sensing image classification">
                                        <b>[5]</b>
                                        WAN L, TANG K, LI M, et al.Collaborative active and semisupervised learning for hyperspectral remote sensing image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2384-2396.
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_6" title="WANG Z, DU B, ZHANG L, et al.A novel semisupervised activelearning algorithm for hyperspectral image classification[J].IEEETransactions on Geoscience and Remote Sensing, 2017, 55 (6) :3071-3083." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel semisupervised active-learning algorithm for hyperspectral image classification">
                                        <b>[6]</b>
                                        WANG Z, DU B, ZHANG L, et al.A novel semisupervised activelearning algorithm for hyperspectral image classification[J].IEEETransactions on Geoscience and Remote Sensing, 2017, 55 (6) :3071-3083.
                                    </a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_7" title="SAMIAPPAN S, MOORHEAD R J.Semi-supervised co-training and active learning framework for hyperspectral image classification[C]//Proceedings of the 2015 IEEE International Geoscience and Remote Sensing Symposium.Piscataway, NJ:IEEE, 2015:401-404." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-supervised co-training and active learning framework for hyperspectral image classification">
                                        <b>[7]</b>
                                        SAMIAPPAN S, MOORHEAD R J.Semi-supervised co-training and active learning framework for hyperspectral image classification[C]//Proceedings of the 2015 IEEE International Geoscience and Remote Sensing Symposium.Piscataway, NJ:IEEE, 2015:401-404.
                                    </a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_8" title="魏超, 罗森林, 张竞, 等.自编码网络短文本流形表示方法[J].浙江大学学报 (工学版) , 2015, 49 (8) :1591-1599. (WEI C, LUO SL, ZHANG J, et al.Short text manifold representation based on autoencoder network[J].Journal of Zhejiang University (Engineering Science) , 2015, 49 (8) :1591-1599.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201508027&amp;v=MTA4MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LUHluUmJiRzRIOVRNcDQ5SFk0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        魏超, 罗森林, 张竞, 等.自编码网络短文本流形表示方法[J].浙江大学学报 (工学版) , 2015, 49 (8) :1591-1599. (WEI C, LUO SL, ZHANG J, et al.Short text manifold representation based on autoencoder network[J].Journal of Zhejiang University (Engineering Science) , 2015, 49 (8) :1591-1599.) 
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_9" title="谢金宝, 侯永进, 康守强, 等.基于语义理解注意力神经网络的多元特征融合中文文本分类[J].电子与信息学报, 2018, 40 (5) :1258-1265. (XIE J B, HOU Y J, KANG S Q, et al.Multi-feature fusion based on semantic understanding attention neural network for Chinese text categorization[J].Journal of Electronics and Information Technology, 2018, 40 (5) :1258-1265.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201805034&amp;v=MTkxNzJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LSVRmU2RyRzRIOW5NcW85R1lJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        谢金宝, 侯永进, 康守强, 等.基于语义理解注意力神经网络的多元特征融合中文文本分类[J].电子与信息学报, 2018, 40 (5) :1258-1265. (XIE J B, HOU Y J, KANG S Q, et al.Multi-feature fusion based on semantic understanding attention neural network for Chinese text categorization[J].Journal of Electronics and Information Technology, 2018, 40 (5) :1258-1265.) 
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_10" title="孙松涛, 何炎祥.基于CNN特征空间的微博多标签情感分类[J].四川大学学报 (工程科学版) , 2017, 49 (3) :162-169. (SUNS T, HE Y X.Multi-label emotion classification for microblog based on CNN feature space[J].Journal of Sichuan University (Engineering Science Edition) , 2017, 49 (3) :162-169.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201703021&amp;v=MTQ0MzA1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tOaTdIWnJHNEg5Yk1ySTlIWllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        孙松涛, 何炎祥.基于CNN特征空间的微博多标签情感分类[J].四川大学学报 (工程科学版) , 2017, 49 (3) :162-169. (SUNS T, HE Y X.Multi-label emotion classification for microblog based on CNN feature space[J].Journal of Sichuan University (Engineering Science Edition) , 2017, 49 (3) :162-169.) 
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_11" title="KALCHBRENNER N, GREFENSTETTE E, BLUNSOM P.A convolutional neural network for modelling sentences[EB/OL].[2018-07-11].https://arxiv.org/pdf/1404.2188v1.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network for modelling sentences">
                                        <b>[11]</b>
                                        KALCHBRENNER N, GREFENSTETTE E, BLUNSOM P.A convolutional neural network for modelling sentences[EB/OL].[2018-07-11].https://arxiv.org/pdf/1404.2188v1.pdf.
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_12" title="KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-11].https://arxiv.org/pdf/1408.5882.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[12]</b>
                                        KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-11].https://arxiv.org/pdf/1408.5882.pdf.
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_13" title="郑啸, 王义真, 袁志祥, 等.基于卷积记忆神经网络的微博短文本情感分析[J].电子测量与仪器学报, 2018 (3) :195-200. (ZHENG X, WANG Y Z, YUAN Z X, et al.Sentiment analysis of micro-blog short text based on convolutional memory neural network[J].Journal of Electronic Meatruement and Instrumentation, 2018 (3) :195-200.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201803028&amp;v=MjA0MzJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LSVRmQ2Q3RzRIOW5Nckk5SGJJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        郑啸, 王义真, 袁志祥, 等.基于卷积记忆神经网络的微博短文本情感分析[J].电子测量与仪器学报, 2018 (3) :195-200. (ZHENG X, WANG Y Z, YUAN Z X, et al.Sentiment analysis of micro-blog short text based on convolutional memory neural network[J].Journal of Electronic Meatruement and Instrumentation, 2018 (3) :195-200.) 
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_14" title="HSU S T, MOON C, JONES P, et al.A hybrid CNN-RNN alignment model for phrase-aware sentence classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Vancouver:[s.n.], 2017, 2:433-449." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hybrid CNN-RNN alignment model for phrase-aware sentence classification">
                                        <b>[14]</b>
                                        HSU S T, MOON C, JONES P, et al.A hybrid CNN-RNN alignment model for phrase-aware sentence classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Vancouver:[s.n.], 2017, 2:433-449.
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_15" title="YIN W, SCHUTZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[EB/OL].[2018-07-11].https://arxiv.org/pdf/1512.05193.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ABCNN:attention-based convolutional neural network for modeling sentence pairs">
                                        <b>[15]</b>
                                        YIN W, SCHUTZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[EB/OL].[2018-07-11].https://arxiv.org/pdf/1512.05193.pdf.
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_16" title="陈荣, 曹永锋, 孙洪.基于主动学习和半监督学习的多类图像分类[J].自动化学报, 2011, 37 (8) :954-962. (CHEN R, CAO YF, SUN H.Multi-class image classification with active learning and semi-supervised learning[J].Acta Automatica Sinica, 2011, 37 (8) :954-962.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201108008&amp;v=MTYzOTVGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tLQ0xmWWJHNEg5RE1wNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        陈荣, 曹永锋, 孙洪.基于主动学习和半监督学习的多类图像分类[J].自动化学报, 2011, 37 (8) :954-962. (CHEN R, CAO YF, SUN H.Multi-class image classification with active learning and semi-supervised learning[J].Acta Automatica Sinica, 2011, 37 (8) :954-962.) 
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_17" title="陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957. (CHEN K, LIANG B, KE W D, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805006&amp;v=MDIzMjhadVpwRmlEbFc3L0tMeXZTZExHNEg5bk1xbzlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957. (CHEN K, LIANG B, KE W D, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-27 16:47</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),644-650 DOI:10.11772/j.issn.1001-9081.2018081757            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合改进主动学习的SVD-CNN弹幕文本分类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B1%E5%AE%81%E4%BD%B3&amp;code=24498470&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邱宁佳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%9B%E7%90%B3&amp;code=40611039&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">丛琳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%80%9D%E4%B8%9E&amp;code=40611038&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周思丞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E9%B9%8F&amp;code=06466219&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%B2%A9%E8%8A%B3&amp;code=14583001&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李岩芳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%98%A5%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0103753&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长春理工大学计算机科学技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决传统卷积神经网络 (CNN) 模型使用池化层进行文本特征降维会损失较多文本语义信息的问题, 提出一种基于奇异值分解 (SVD) 算法的卷积神经网络模型 (SVD-CNN) 。首先, 采用改进的基于密度中心点采样的主动学习算法 (DBC-AL) 选择对分类模型贡献率较高的样本进行标注, 以低标注代价获得高质量模型训练集;然后, 结合SVD算法建立SVD-CNN弹幕文本分类模型, 使用奇异值分解的方法代替传统CNN模型池化层进行特征提取和降维, 并在此基础上完成弹幕文本分类任务;最后, 使用改进的梯度下降算法 (PSGD) 对模型参数进行优化。为了验证改进算法的有效性, 使用多种弹幕数据样本集, 对提出的模型与常用的文本分类模型进行对比实验。实验结果表明, 改进的算法能够更好地保留文本语义特征, 保证训练过程的稳定性并提高了模型的收敛速度, 在不同的弹幕文本上较传统算法具有更好的分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">奇异值分解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">主动学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梯度下降;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *邱宁佳 (1984—) , 男, 河南南阳人, 讲师, 博士, CCF会员, 主要研究方向:数据挖掘、算法分析;电子邮箱760560291@qq.com;
                                </span>
                                <span>
                                    丛琳 (1992—) , 女, 吉林吉林人, 硕士研究生, 主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    周思丞 (1994—) , 男, 吉林长春人, 硕士研究生, 主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    王鹏 (1973—) , 男, 内蒙古包头人, 教授, 博士, CCF会员, 主要研究方向:数据挖掘;;
                                </span>
                                <span>
                                    李岩芳 (1965—) , 女, 吉林长春人, 教授, 博士, 主要研究方向:数据库与数据挖掘、软件工程、信息系统。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>吉林省重大科技招标项目 (20170203004GX);</span>
                                <span>吉林省省级产业创新专项 (2017C051);</span>
                    </p>
            </div>
                    <h1><b>SVD-CNN barrage text classification algorithm combined with improved active learning</b></h1>
                    <h2>
                    <span>QIU Ningjia</span>
                    <span>CONG Lin</span>
                    <span>ZHOU Sicheng</span>
                    <span>WANG Peng</span>
                    <span>LI Yanfang</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Changchun University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>For the loss of much semantic information in dimension reduction of text features when using pooling layer of the traditional Convolutional Network (CNN) model, a Convolutional Neural Network model based on Singular Value Decomposition algorithm (SVD-CNN) was proposed. Firstly, an improved Active Learning algorithm based on Density Center point sampling (DC-AL) was used to tag samples contributing a lot to the classification model, obtaining a high-quality model training set at a low tagging cost. Secondly, an SVD-CNN barrage text classification model was established by combining SVD algorithm, and SVD was used to replace the traditional CNN model pooling layer for feature extraction and dimension reduction, then the barrage text classification task was completed on these bases. Finally, the model parameters were optimized by using Partial Sampling Gradient Descent algorithm (PSGD) . In order to verify the effectiveness of the improved algorithm, multiple barrage data sample sets were used in the comparison experiments between the proposed model and the common text classification model. The experimental results show that the improved algorithm can better preserve semantic features of the text, ensure the stability of training process and improve the convergence speed of the model. In summary, the proposed algorithm has better classification performance than traditional algorithms on multiple barrage texts.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Nerual%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Nerual Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Singular%20Value%20Decompostion%20(SVD)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Singular Value Decompostion (SVD) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Active%20Learning%20(AL)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Active Learning (AL) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=gradient%20descent&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">gradient descent;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    QIU Ningjia, born in 1984, Ph. D. , lecturer. His research interests include data mining, analysis of algorithms.;
                                </span>
                                <span>
                                    CONG Lin, born in 1992, M. S. candidate. Her research interests include data mining.;
                                </span>
                                <span>
                                    ZHOU Sicheng, born in 1994, M. S. candidate. His research interests include data mining.;
                                </span>
                                <span>
                                    WANG Peng, born in 1973, Ph. D. , professor. His research interests include data mining.;
                                </span>
                                <span>
                                    LI Yanfang, born in 1965, Ph. D. , professor. Her research interests include database and data mining, software engineering and information system.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-23</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Major Science and Technology Bidding Project of Jilin Province (20170203004GX);</span>
                                <span>the Provincial Industrial Innovation Project of Jilin Province (2017C051);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="38">国内外研究者使用有监督的深度学习神经网络进行文本分类, 这种监督型检测方法需要大量已标记数据, 人工标注大量数据耗时耗力, 因而难以实施。针对已有方法存在的问题, 谭侃等<citation id="283" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出一种基于双层采样主动学习方法, 用样本不确定性、代表性和多样性来评估未标记样本的价值, 使用排序和聚类相结合的双层采样算法对未标记的样本进行筛选, 使用少量有标签样本达到与有监督学习接近的检测效果。徐海龙等<citation id="284" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出一种基于 委员会投票选择算法 (Query By Committee, QBC) 的支持向量机 (Support Vector Machine, SVM) 主动学习算法, 将改进的QBC与加权SVM有机结合并应用于SVM训练学习中, 有效地减少了样本分布不均衡对主动学习性能的影响。姚拓中等<citation id="285" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将Boosting思想应用到多视角主动学习框架中, 通过将历史上各次查询得到的分类假设进行加权式投票来实现每次查询后分类假设的强化, 相比于传统单视角主动学习算法能够更快地完成收敛并达到较高的场景分类准确性。Li等<citation id="286" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了结合半监督的主动学习方法, 将主动学习过程产生的价值样本用来加速分类器的训练, 和伪标签一起辅助分类器进行高效的分类。Wan等<citation id="287" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了基于主动学习的伪标签校验框架, 极大地提高了半监督学习中伪标签的置信度。Wang等<citation id="288" type="reference"><link href="259" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了主动学习与聚类相结合的伪标签校验的方法, 进一步提高了伪标签的置信度。Samiappan等<citation id="289" type="reference"><link href="261" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了Co-Training与主动学习算法进行组合的半监督算法, 缓解了Self-Training中容易产生的数据倾斜问题而导致的分类器持续恶化的情况。上述主动学习采样方法普遍面临以下问题:1) 基于概率型的采样算法不适用句子型文本。2) 只考虑分类结果最明确的样本, 这种样本对当前分类器影响较小, 并不能提高模型的泛化能力。本文提出基于密度中心点采样的主动学习算法, 根据样本间的可连接性不断扩展聚类簇, 选择每个类别中与密度中心相似度最高与最低的样本进行标注, 实现采样的多样性, 从而适用于大规模未标注句子级弹幕样本, 使用极少量的标签样本训练初始分类器, 迭代选择信息量最大的未标记弹幕样本加入训练集, 以此提高分类器的分类性能, 完成弹幕文本分类任务。</p>
                </div>
                <div class="p1">
                    <p id="39">随着深度学习的发展, 越来越多的深度学习模型被应用于短文本分类任务中, 魏超等<citation id="290" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出基于自编码网络的短文本流形表示方法实现文本特征的非线性降维, 可以更好地以非稀疏形式更准确地描述短文本特征信息, 提高分类效率。谢金宝等<citation id="291" type="reference"><link href="265" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出一种基于语义理解的多元特征融合中文文本分类模型, 通过嵌入层的各个通路提取不同层次的文本特征, 比神经网络模型 (Conveolutional Neural Network, CNN) 与长短期记忆网络模型 (Long Short-Term Memory, LSTM) 的文本分类精度提升了8%。孙松涛等<citation id="292" type="reference"><link href="267" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用CNN模型将句子中的词向量合成为句子向量, 并作为特征训练多标签分类器完成分类任务, 取得了较好的分类效果。Kalchbrenner等<citation id="293" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出DCNN模型, 在不依赖句法解析树的条件下, 利用动态k-max pooling提取全局特征, 取得了良好的分类效果。Kim<citation id="294" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>采用多通道卷积神经网络模型进行有监督学习, 将词矢量作为输入特征, 可以在不同大小的窗口内进行语义合成操作, 完成文本分类任务。郑啸等<citation id="295" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>结合CNN和LSTM模型的特点, 提出了卷积记忆神经网络模型 (Convolutional Memory Neural Network, CMNN) , 相比传统方法, 该模型避免了具体任务的特征工程设计。Hsu等<citation id="296" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>将CNN与循环神经网络 (Recurrent Neural Network, RNN) 有机结合, 从语义层面对sentense进行分类, 取得良好的分类效果。Yin等<citation id="297" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出一种基于注意力机制的卷积神经网络, 并将该网络用在句子对建模任务中, 证明了注意力机制和CNN结合的有效性。上述方法使用传统CNN模型对文本进行特征提取和分类, 但池化操作在进行特征提取和降维时会损失较多的文本语义信息, 从而导致分类精度下降。本文使用奇异值分解算法代替池化层的特征提取与降维工作, 将奇异值较高的特征作为主要特征来代替原有目标矩阵的表达, 更好地保存句子原有的语义结构, 提升分类模型的精度。</p>
                </div>
                <h3 id="40" name="40" class="anchor-tag">1 相关研究</h3>
                <h4 class="anchor-tag" id="41" name="41">1.1 <b>主动学习算法概述</b></h4>
                <div class="p1">
                    <p id="42">主动学习算法是为了解决现实中标签数据不足、标注数据耗时耗力的问题而提出的。该算法能够从未标记样例中挑选部分价值量高的样例, 标注后补充到已标记样例集中来提高分类器和精度, 降低领域专家的工作量。如何高效地选出具有高分类贡献度的未标记样本进行标注并补充到已有训练集中, 逐步提高分类器精度与鲁棒性是主动学习亟待解决的问题。</p>
                </div>
                <div class="p1">
                    <p id="43">主动学习根据选择未标记样本方式的不同, 可以分为成员查询综合主动学习、基于流的主动学习和基于池的主动学习。其中, 基于委员会的主动学习是当前应用最广泛的采样策略。根据选择未标记样例的标准不同, 基于池的采样策略又可分为:不确定性的采样策略、基于版本空间缩减的采样策略、基于模型改变期望的采样策略以及基于误差缩减的采样策略。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">1.2 <b>卷积神经网络文本分类</b></h4>
                <div class="p1">
                    <p id="45">近年来, CNN模型在文本分类任务上取得了很好的实用效果。CNN模型首先根据输入文本和词向量构建输入矩阵, 然后通过卷积和池化操作, 筛选和组合词的分布式信息。其模型结构如图1所示, 在这样一个网络中, 输入层表示的是由每个词的分布式向量组成的句子矩阵;卷积层使用若干个卷积核对于局部的词向量矩阵进行卷积运算;池化层使用最大池化策略把卷积的结果转换为一组特征向量;基于前两层运算得到的特征向量, 使用Softmax函数进行分类。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CNN模型结构" src="Detail/GetImg?filename=images/JSJY201903006_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 CNN模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 CNN model structure</p>

                </div>
                <h3 id="47" name="47" class="anchor-tag">2 CNN分类模型改进算法</h3>
                <h4 class="anchor-tag" id="48" name="48">2.1 <b>主动学习算法的改进</b></h4>
                <div class="p1">
                    <p id="49">大多数传统的主动学习算法使用基于概率的启发式方法, 这种方法建立在样例的后验概率分布基础之上, 用信息熵较大的样本训练分类模型。这种基于概率的信息熵计算方法并不适用于句子级弹幕文本, 所以本文在原有主动学习算法的思想基础上, 提出一种基于密度中心点的主动学习采样算法, 通过比对句向量间相似度与设定最小密度阈值对样本进行划分, 根据阈值的约束条件来选择价值高的样本标注, 增强了样本选择算法的鲁棒性。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">2.1.1 基于相似度的密度聚类算法</h4>
                <div class="p1">
                    <p id="51">传统的密度聚类算法是基于样本间距离的考察, 本文针对句向量的空间分布提出向量间的相似度阈值来刻画样本类型的贴近程度, 设计基于相似度的密度聚类算法, 设置相似度与最小密度阈值, 聚类核心步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="52">1) 首先利用分词工具进行弹幕句子样本分词, 将句子以词为单位形成一个词向量序列, 如式 (1) 所示:</p>
                </div>
                <div class="p1">
                    <p id="53"><b><i>x</i></b><sub>1:<i>n</i></sub>=[<b><i>x</i></b><sub>1</sub>, <b><i>x</i></b><sub>2</sub>, …, <b><i>x</i></b><sub><i>n</i></sub>]      (1) </p>
                </div>
                <div class="p1">
                    <p id="54">然后使用Word2vec模型将每一个词映射为一个多维的连续值词向量序列, 最后利用LSTM算法, 将词向量序列结合文本语序信息生成语义向量, 公式表达如下:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>C</mi></msub><mo>⋅</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>×</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>×</mo><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⋅</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">其中, <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover></math></mathml><sub><i>t</i></sub>表示前一时刻的cell状态, <b><i>C</i></b><sub><i>t</i></sub>表示当前时刻cell状态, <i>f</i><sub><i>t</i></sub>表示遗忘门限, <i>i</i><sub><i>t</i></sub>表示输入门限, <i>o</i><sub><i>t</i></sub>表示输出门限, <b><i>g</i></b><sub><i>t</i></sub>表示当前单元的输出, tanh表示激活函数。</p>
                </div>
                <div class="p1">
                    <p id="58">2) 设置样本相似度阈值<i>γ</i>与最小密度样本数<i>MinPts</i>, 如式 (5) 、 (6) 所示:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>×</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>×</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac><mo>≥</mo><mi>γ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>Ν</mi><msub><mrow></mrow><mo>∈</mo></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>≥</mo><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>Ρ</mi><mi>t</mi><mi>s</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中, <b><i>g</i></b><sub><i>j</i></sub>为核心密度点, <i>N</i><sub>∈</sub> (<b><i>g</i></b><sub><i>j</i></sub>) 表示以<b><i>g</i></b><sub><i>j</i></sub>为中心点的邻域。</p>
                </div>
                <div class="p1">
                    <p id="61">3) 从步骤1) 中筛选出符合步骤2) 中条件的点, 加入到核心对象集合<i>Ω</i>中, 如式 (7) 所示:</p>
                </div>
                <div class="p1">
                    <p id="62"><i>Ω</i>=<i>Ω</i>∪{<b><i>g</i></b><sub><i>j</i></sub>}      (7) </p>
                </div>
                <div class="p1">
                    <p id="63">4) 在核心对象集合中随机选取一个点<i>α</i>, 找出由它密度可达的所有样本, 生成第一个聚类簇<i>B</i><sub>1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="64">5) 将<i>B</i><sub>1</sub>中包含的核心对象从<i>Ω</i>中去除, 再从更新后的<i>Ω</i>中随机选取一个核心对象, 作为种子来生成下一个聚类簇, 反复迭代上述步骤, 直至<i>Ω</i>为空。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65">2.1.2 主动学习采样策略</h4>
                <div class="p1">
                    <p id="66">普通的主动学习采样策略, 存在采样单一、采样偏置的问题。结合样本在特征空间中的分布结构, 本文提出一种带约束条件的主动学习采样策略对未标记样本进行筛选, 以聚类簇为单位, 计算聚类中心点与其他样本间的相似度, 其中相似度最高与最低的样本最能代表整个聚类簇的分布状态, 依据上述方法可以在样本的信息性和预测标号的准确性两者之间获得较好的平衡, 选出最有价值的弹幕样本给专家标注。核心步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="67">1) 计算属于同一个密度中心点<b><i>g</i></b><sub><i>j</i></sub>阈值范围内的所有样本<b><i>g</i></b><sub><i>i</i></sub>到密度中心的相似度<i>SimG</i>, 如式 (8) 所示:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mi>G</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mfrac><mrow><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo>×</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><msqrt><mrow><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>×</mo><msqrt><mrow><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">其中, <b><i>g</i></b><sub><i>i</i></sub>为中心点<b><i>g</i></b><sub><i>j</i></sub>阈值范围内的所有样本。</p>
                </div>
                <div class="p1">
                    <p id="70">2) 选择相似度最高与最低的两个样本:<i>MaxSim</i>、<i>MinSim</i>, 如式 (9) 、 (10) 所示:</p>
                </div>
                <div class="p1">
                    <p id="71"><i>MaxSim</i>=arg max (<i>SimG</i>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="72"><i>MinSim</i>=arg min (<i>SimG</i>)      (10) </p>
                </div>
                <div class="p1">
                    <p id="73">3) 将<i>MaxMin</i>、<i>MinSim</i>进行人工标注, 加入到训练样本集<i>S</i>中。</p>
                </div>
                <div class="p1">
                    <p id="74">结合上述两个算法将基于密度中心点采样的主动学习算法 (Density-Based Clustering of Active Learning, DBC-AL) 归纳如下:</p>
                </div>
                <div class="p1">
                    <p id="75">算法1 DBC-AL算法。</p>
                </div>
                <div class="p1">
                    <p id="76">输入:样本集<i>D</i>={<b><i>g</i></b><sub>1</sub>, <b><i>g</i></b><sub>2</sub>, …, <b><i>g</i></b><sub><i>m</i></sub>}, 邻域参数 (<i>ε</i>, <i>MinPts</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="77">输出:待标注样本<i>MaxSim</i>、<i>MinSim</i>。</p>
                </div>
                <div class="area_img" id="300">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903006_30000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="142" name="142">2.2 SVD-CNN<b>模型</b></h4>
                <div class="p1">
                    <p id="143">在自然语言领域, 传统的CNN使用池化层对文本进行采样降维工作, 该操作只是简单地从前一维FeatureMap中提取了最大值, 并不关心特征的分布状态, 从而导致特征的位置信息丢失, 文本语义发生变化的问题。本文使用奇异值分解算法 (Singular Value Decomposition, SVD) 代替池化层的特征提取工作, 根据奇异值的大小选取矩阵的主要特征。奇异值往往对应着矩阵中隐含的重要信息, 每个目标矩阵都可以表示为一系列秩为1的特征矩阵之和, 而奇异值则表征了这些特征矩阵对于目标矩阵的权重, 因此奇异值较高的特征能够作为主要特征来代替原有目标矩阵的表达。如式 (11) 所示:</p>
                </div>
                <div class="p1">
                    <p id="144"><b><i>A</i></b>=<b><i>U</i></b><sub>1</sub><i>δ</i><sub>1</sub><b><i>V</i></b><sub>1</sub><sup>T</sup>+<b><i>U</i></b><sub>2</sub><i>δ</i><sub>2</sub><b><i>V</i></b><sub>2</sub><sup>T</sup>+…+<b><i>U</i></b><sub><i>n</i></sub><i>δ</i><sub><i>n</i></sub><b><i>V</i></b><sub><i>n</i></sub><sup>T</sup>      (11) </p>
                </div>
                <div class="p1">
                    <p id="145">其中:<b><i>A</i></b>为目标矩阵, <b><i>U</i></b><sub><i>n</i></sub>为左奇异值矩阵, <i>δ</i><sub><i>n</i></sub>为特征矩阵, <b><i>V</i></b><sub><i>n</i></sub><sup>T</sup>为右奇异值矩阵。</p>
                </div>
                <div class="p1">
                    <p id="146">本文在传统CNN分类模型基础上设计了基于奇异值分解算法的卷积神经网络模型 (Convolutional Neural Network based on Singular Value Decomposition, SVD-CNN) , 利用SVD算法良好的数值稳定性和几何不变性完成对矩阵的主要特征提取和降维, 较好地保留文本语义信息的完整性, 整个模型体系如图2所示。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147">1) 输入层。</h4>
                <div class="p1">
                    <p id="148">模型的输入为一个<i>n</i>×<i>m</i>的句子矩阵, 矩阵的每一行代表句子中每个词对应的向量, 行数<i>n</i>代表句子的词数, 列数<i>m</i>为向量的维数。</p>
                </div>
                <h4 class="anchor-tag" id="149" name="149">2) 卷积层。</h4>
                <div class="p1">
                    <p id="150">采用列数与行数相同的卷积矩阵窗口<b><i>h</i></b>∈<i>R</i><sup><i>n</i>×<i>m</i></sup>, 为了获取不同类别的语义特征, 采用多个不同尺寸 (<b><i>h</i></b>) 的卷积窗口与原矩阵进行卷积运算, 得到卷积语义特征<b><i>F</i></b><sub><i>i</i></sub>, 如式 (12) 所示:</p>
                </div>
                <div class="p1">
                    <p id="151"><b><i>F</i></b><sub><i>i</i></sub>=<i>relu</i> (<b><i>W</i></b>·<b><i>x</i></b><sub><i>i</i>:<i>i</i>+<i>h</i>-1</sub>+<b><i>b</i></b>)      (12) </p>
                </div>
                <h4 class="anchor-tag" id="152" name="152">3) 奇异值分解层。</h4>
                <div class="p1">
                    <p id="153">对特征矩阵<b><i>F</i></b><sub><i>i</i></sub>进行奇异值分解运算, 降维后的特征矩阵记为<b><i>A</i></b>, 如式 (13) 所示:</p>
                </div>
                <div class="p1">
                    <p id="154" class="code-formula">
                        <mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><mo>=</mo><mi>f</mi><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">w</mi></mstyle><msub><mrow></mrow><mi>a</mi></msub><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub><mfrac><mrow><mi mathvariant="bold-italic">δ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">δ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow></mfrac><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>a</mi></msub></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SVD-CNN模型" src="Detail/GetImg?filename=images/JSJY201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SVD-CNN模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 SVD-CNN model</p>

                </div>
                <div class="p1">
                    <p id="156">为了使各个特征处于同一数量级, 在奇异值分解后, 对各个特征进行归一化处理, <i>δ</i><sub><i>i</i></sub>/‖<i>δ</i><sub><i>i</i></sub>‖代表第<i>i</i>个特征的归一化奇异值, <b><i>w</i></b><sub><i>a</i></sub>表示权重矩阵, 其中<b><i>U</i></b><sub><i>i</i></sub><b><i>V</i></b><sub><i>i</i></sub><sup>T</sup>表示文本的第<i>i</i>个特征向量, <b><i>b</i></b><sub><i>a</i></sub>表示偏置项。选择奇异值较大的特征向量组成原矩阵的主要特征向量, 完成降维和特征提取工作, 降维后的维数<i>k</i>可以通过设置阈值<i>t</i>来界定, 如式 (14) 所示:</p>
                </div>
                <div class="p1">
                    <p id="157" class="code-formula">
                        <mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">δ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">δ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mi>t</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="158">根据阈值选择前<b><i>k</i></b>个奇异值与其对应的标准正交基, 构建原矩阵<b><i>A</i></b>的<i>k</i>秩近似矩阵<b><i>A</i></b><sub><i>k</i></sub>如式 (15) 所示:</p>
                </div>
                <div class="p1">
                    <p id="159" class="code-formula">
                        <mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">U</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">δ</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="160">其中:<b><i>U</i></b><sub><i>i</i></sub>为左奇异矩阵, <i>δ</i><sub><i>i</i></sub>为奇异值矩阵, <b><i>V</i></b><sub><i>i</i></sub><sup>T</sup>为右奇异矩阵。</p>
                </div>
                <h4 class="anchor-tag" id="161" name="161">4) 输出层。</h4>
                <div class="p1">
                    <p id="162">将得到的多个<b><i>A</i></b><sub><i>k</i></sub>矩阵融合, 记为<b><i>S</i></b>, 如式 (16) 所示:</p>
                </div>
                <div class="p1">
                    <p id="163"><b><i>S</i></b>={<b><i>A</i></b><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>, <b><i>A</i></b><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup></mrow></math></mathml>, …, <b><i>A</i></b><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>λ</mi><mi>k</mi></msubsup></mrow></math></mathml>}      (16) </p>
                </div>
                <div class="p1">
                    <p id="167">其中, <i>λ</i>为语义特征<b><i>F</i></b><sub><i>i</i></sub>的个数, 使用Softmax函数对<b><i>S</i></b>进行分类, 最终输出弹幕样本在不同类别上的分布概率。</p>
                </div>
                <h3 id="168" name="168" class="anchor-tag">3 弹幕分类解决方案的构建</h3>
                <h4 class="anchor-tag" id="169" name="169">3.1 <b>弹幕分类模型优化算法</b></h4>
                <div class="p1">
                    <p id="170">考虑到深度学习模型是较复杂的非线性结构, 在这种非凸问题上往往很难直接求解, 所以本文采用梯度下降算法对模型参数进行优化以得到全局最优解。</p>
                </div>
                <div class="p1">
                    <p id="171">兼顾随机梯度下降算法 (Stochastic Gradient Descent, SGD) 的随机性, 本文设计一种通过选取数据相关性较高的样本来形成批量数据训练集的梯度下降算法 (Partial Sampling Gradient Descent, PSGD) , 该算法在保证训练过程稳定性的同时, 提高模型的学习速度, 使模型更快速地收敛, 参数更新公式如式 (17) 所示:</p>
                </div>
                <div class="p1">
                    <p id="172"><i>θ</i>←<i>θ</i>-<i>ε</i>ᐁ<sub><i>θ</i></sub><i>J</i> (<i>θ</i>)      (17) </p>
                </div>
                <div class="p1">
                    <p id="173">其中:<i>θ</i>为优化参数, <i>ε</i>为学习率, ᐁ<sub><i>θ</i></sub><i>J</i> (<i>θ</i>) 为参数梯度。</p>
                </div>
                <div class="p1">
                    <p id="174">考虑到随机选取训练样本的不确定性可能会导致目标函数值出现震荡的现象, 本文从模型正确预测出的数据集中随机抽取10%样本, 结合所有错误预测的样本, 形成新的训练集来训练模型, 具体算法描述如下:</p>
                </div>
                <div class="p1">
                    <p id="175">算法2 PSGD梯度下降算法。</p>
                </div>
                <div class="p1">
                    <p id="176">输入:全样本训练集<i>U</i>, 误差函数<i>loss</i>和迭代终止阈值<i>p</i>, 学习率<i>ε</i>, 初始参数<i>θ</i>;</p>
                </div>
                <div class="p1">
                    <p id="177">输出:更新后的参数<i>θ</i>。</p>
                </div>
                <div class="area_img" id="301">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903006_30100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="195" name="195">3.2 <b>模型描述</b></h4>
                <div class="p1">
                    <p id="196">本文使用改进的主动学习采样策略, 从未标注弹幕样本集中根据算法1设定的规则挑选少量弹幕样本, 交由人工标注, 使用标注好的弹幕样本训练SVD-CNN分类模型, 为了能够较好保存句子的语义信息, 模型使用SVD算法代替池化层来完成特征提取与特征降维, 将得到的主要特征进行信息融合, 并输入到Softmax函数中完成分类任务。整体结构如图3所示。</p>
                </div>
                <div class="area_img" id="197">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_197.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SVD-CNN算法解决方案" src="Detail/GetImg?filename=images/JSJY201903006_197.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SVD-CNN算法解决方案  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_197.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 SVD-CNN model solution</p>

                </div>
                <div class="p1">
                    <p id="198">在数据预处理阶段, 首先对弹幕样本进行数据清洗, 然后利用分词工具与Word2vec模型将每一个词映射为一个多维的连续值词向量序列, 最后利用LSTM模型将词向量序列结合文本语序信息生成语义向量。</p>
                </div>
                <div class="p1">
                    <p id="199">使用算法1中的方法, 将句向量样本根据相似度阈值和最小密度样本数进行聚类, 对每个密度中心点相似度临界值进行采样, 得到最能代表每个聚类簇的整体样本分布状态, 将样本交由专家标注, 以此提高训练样本集的代表性和广泛性。</p>
                </div>
                <div class="p1">
                    <p id="200">为了获取不同的语义特征, 采用不同尺寸的卷积窗口与原矩阵进行卷积运算, 得到卷积语义特征<b><i>F</i></b><sub><i>i</i></sub>, 对特征矩阵<b><i>F</i></b><sub><i>i</i></sub>进行奇异值分解运算, 根据设定的阈值选择前<i>k</i>个奇异值与其对应的标准正交基, 构建原矩阵<b><i>A</i></b>的<i>k</i>秩近似矩阵, 将多个<b><i>A</i></b><sub><i>k</i></sub>矩阵的融合<i>S</i>, 通过Softmax函数计算得到样本属于各个类的概率分布, 如式 (17) 所示:</p>
                </div>
                <div class="p1">
                    <p id="201"><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><mo>=</mo><mi>i</mi><mo stretchy="false">|</mo><mi>Q</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>Q</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>j</mi></msub><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>Q</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>; <i>i</i>=1, 2, …, <i>d</i>      (18) </p>
                </div>
                <div class="p1">
                    <p id="203">其中:<i>Q</i>为一条弹幕样本, <i>θ</i><sub><i>i</i></sub><sup>T</sup>表示<i>S</i>中第<i>i</i>个特征的权重矩阵, <i>p</i> (<i>y</i>=<i>i</i>|<i>Q</i>) 表示每个样本属于类别<i>i</i>的概率, <i>d</i>为弹幕类别数。为了更好地训练模型, 本文采用<i>loss</i>函数来衡量文本类别的真实概率分布<i>P</i><sub><i>j</i></sub>和预测的概率分布<i>η</i><sub><i>j</i></sub>之间的差距, 如式 (18) 所示:</p>
                </div>
                <div class="p1">
                    <p id="204" class="code-formula">
                        <mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Q</mi><mo>∈</mo><mi>R</mi></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mi>Ρ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>j</mi></msub><mspace width="0.25em" /><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mi>η</mi><msub><mrow></mrow><mi>j</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="205" name="205" class="anchor-tag">4 实验与结果分析</h3>
                <h4 class="anchor-tag" id="206" name="206">4.1 <b>实验数据与参数设置</b></h4>
                <div class="p1">
                    <p id="207">本文针对三个方面对改进算法的有效性进行验证。第一, 通过模型不同的分类准确率, 对比传统采样算法和DBC-AL算法的模型迭代次数, 验证后者具有更高的效率;第二, 使用本文提出的SVD-CNN模型对弹幕文本分类, 同时考虑词向量维度和数据集泛化能力来验证其分类性能;第三, 使用改进后的梯度下降算法对模型进行优化, 通过收敛速度和模型训练速度来验证优化算法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="208">本文通过爬虫技术在不同视频网站分别爬取弹幕文本, 根据视频类别形成不同的数据集进行对照实验, 对本文提出的算法进行性能评估。详细的实验数据统计如表1所示。</p>
                </div>
                <div class="area_img" id="209">
                    <p class="img_tit"><b>表</b>1 <b>实验使用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Experimental data sets</p>
                    <p class="img_note"></p>
                    <table id="209" border="1"><tr><td><br />数据集</td><td>积极倾向样本数</td><td>消极倾向样本数</td></tr><tr><td><br />Bilibili弹幕训练集</td><td>1 138</td><td>1 362</td></tr><tr><td><br />Bilibili弹幕测试集</td><td>1 226</td><td>1 274</td></tr><tr><td><br />爱奇艺弹幕训练集</td><td>1 098</td><td>1 402</td></tr><tr><td><br />爱奇艺弹幕测试集</td><td>1 336</td><td>1 164</td></tr><tr><td><br />优酷视频弹幕测试集</td><td>1 256</td><td>1 101</td></tr><tr><td><br />优酷视频弹幕测试集</td><td>1 339</td><td>1 206</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="210">本文在实验中选择不同尺寸的卷积核对输入的句子矩阵进行卷积操作, 结合设定的阈值选取特征, 使用奇异值分解算法完成矩阵的特征降维和特征提取, 具体参数设置如表2所示。</p>
                </div>
                <div class="area_img" id="211">
                    <p class="img_tit"><b>表</b>2 <b>模型参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Model parameter settings</p>
                    <p class="img_note"></p>
                    <table id="211" border="1"><tr><td>参数</td><td>参数描述</td><td>值</td><td></td><td>参数</td><td>参数描述</td><td>值</td></tr><tr><td><i>h</i></td><td>窗口大小</td><td>3, 4, 5</td><td></td><td><i>ε</i></td><td>学习率</td><td>10<sup>-3</sup></td></tr><tr><td><br /><i>F</i></td><td>特征图数</td><td>32</td><td></td><td><i>k</i></td><td>奇异值特征选取阈值</td><td>80%</td></tr><tr><td><br /><i>P</i></td><td>Dropout大小</td><td>0.5</td><td></td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="212" name="212">4.2 <b>算法性能验证</b></h4>
                <div class="p1">
                    <p id="213">实验1 主动学习采样算法性能验证。</p>
                </div>
                <div class="p1">
                    <p id="214">通过算法1中的方法对表1中的弹幕样本进行采样, 为了验证该算法对短文本语句向量在减少人工标注上所起到的作用, 比较在模型达到同一分类准确率时, 不同采样算法所需的迭代次数。实验选择QBC算法、随机采样算法、基于最优标号和次优标号的 (Best vs Second-Best, BvSB) <citation id="298" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>算法作为对照算法, 使用CNN分类模型, 实验结果如图4所示。</p>
                </div>
                <div class="area_img" id="215">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同模型精度下各个算法采样次数对比" src="Detail/GetImg?filename=images/JSJY201903006_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同模型精度下各个算法采样次数对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison of sampling times of algorithms under different model accuracy</p>

                </div>
                <div class="p1">
                    <p id="216">从图4可以看出, 在分类器识别精度为60%时, 模型的分类正确率较低, 除随机采样算法外, 其余3种分类算法使用采样所需的迭代次数没有明显差距。随着分类精度从70%逐渐提升到90%时, 随机采样和信息熵采样算法所需迭代次数有着明显的升高, 而DBC-AL算法和BvSB算法相对较为稳定。由于BvSB算法只考虑样本分类可能性最大的类别, 因此相对前两种算法来说采样次数较少, 但该算法忽略其他对样本的分类结果影响较小的类别, 导致该算法采集的样本所含的信息量较少, 相对于本文提出的DBC-AL算法需要更多的迭代次数, 这说明了随着模型精度的提高, 前三种传统的采样算法收集到的样本信息对于模型收敛提供的帮助越来越少, 而DBC-AL算法根据样本间的相似度进行聚类, 对每个聚类簇采集到对分类模型来说最有价值的样本, 从而体现了DBC-AL算法在句向量中采样的优越性。</p>
                </div>
                <div class="p1">
                    <p id="217">实验2 模型分类性能对比。</p>
                </div>
                <div class="p1">
                    <p id="218">本文采用SVM算法、传统CNN模型、不加池化层的CNN模型、多通道卷积神经网络 (Multi-Channel Convolution Neural Network, MCCNN) 模型<citation id="299" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和本文提出的SVD-CNN模型进行分类正确率对比实验以验证SVD-CNN模型的有效性。考虑到不同数据集可能引起分类模型精度变化的问题, 使用表1中3个数据集分别进行模型分类性能对比实验, 实验结果如图5所示。</p>
                </div>
                <div class="area_img" id="219">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同数据集下各个分类模型的分类性能" src="Detail/GetImg?filename=images/JSJY201903006_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同数据集下各个分类模型的分类性能  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Classification performance of each classification model under different datasets</p>

                </div>
                <div class="p1">
                    <p id="220">从图5可以看出, SVM模型最高取得了78.9%的分类正确率, 说明SVM模型在多分类问题上精度较低。CNN的分类正确率受数据集影响波动较大, 在BiliBili弹幕数据集上的分类精度降低到76.6%, 相比不加池化层的CNN模型分类正确率略有下降, 这说明传统CNN模型的池化层并不能对自然语言的文本特征进行有效提取。由于MCCNN模型采用多通道的特征提取方式, 将不同的特征信息结合形成不同的通道作为卷积神经网络的输入, 使得模型的分类效果优于前两种模型, 最高分类精度达到了87.6%, 而本文提出的SVD-CNN模型相比前三个数据集上取得了最好的弹幕分类效果, 其中在爱奇艺弹幕数据集上的分类精度最高达到了89.2%, 相对于传统使用池化层的CNN模型和MCCNN模型, 分别提高了7.3%和1.6%, 说明本文提出的对文本语义矩阵使用奇异值分解算法进行降维和特征提取的方法, 更好地保留了文本语义特征, 进而提高了模型分类精度, 充分验证了SVD-CNN模型在处理文本语义分类上对特征信息选择的有效性。</p>
                </div>
                <div class="p1">
                    <p id="221">实验3 句向量维度实验。</p>
                </div>
                <div class="p1">
                    <p id="222">考虑到句向量维度会影响文本语义信息的表征, 从而影响最终的分类结果, 本文利用CNN模型、MCCNN模型和SVD-CNN模型在BiliBili弹幕数据集上使用不同维度的句向量进行对比实验, 分析句向量维度对分类结果的影响, 实验结果如表3所示。</p>
                </div>
                <div class="area_img" id="223">
                    <p class="img_tit"><b>表</b>3 <b>不同句向量维度下模型分类正确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Model classification accuracy comparison under different sentence vector dimensions</p>
                    <p class="img_note"></p>
                    <table id="223" border="1"><tr><td><br />词向量维度</td><td>CNN</td><td>MCCNN</td><td>SVD-CNN</td></tr><tr><td><br />10</td><td>0.803</td><td>0.854</td><td>0.852</td></tr><tr><td><br />50</td><td>0.836</td><td>0.876</td><td>0.892</td></tr><tr><td><br />100</td><td>0.831</td><td>0.870</td><td>0.883</td></tr><tr><td><br />150</td><td>0.825</td><td>0.871</td><td>0.890</td></tr><tr><td><br />200</td><td>0.828</td><td>0.865</td><td>0.886</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="224">从表3中可以看出, 当句向量的维度增加到50, 三种模型的分类精度都有着不同程度的提高, 这说明随着句向量维度的增加, 文本语义的特征表达能力在逐渐提高。当维度继续增加时, 语句特征分布会变得更为稀疏, CNN模型与MCCNN模型使用池化层会忽略较多的文本语义特征, 致使分类效果降低。本文使用SVD算法代替池化层进行特征提取, 在语句特征分布较为稀疏的情况下仍然可以保留较多的文本语义特征, 当词向量维度增加到180以上时, 模型的分类精度仍处于平稳状态, 充分验证了SVD-CNN在弹幕文本语义特征提取上的高效性。</p>
                </div>
                <div class="p1">
                    <p id="225">实验4 弹幕分类模型优化算法。</p>
                </div>
                <div class="p1">
                    <p id="226">为了验证本文PSGD算法的训练稳定性与训练速度, 选择批量梯度下降算法 (Batch Gradient Descent, BGD) , SGD算法, 小批量梯度下降算法 (Mini-Batch Gradient Descent, MBGD) 和本文提出的PSGD算法设计两组对照实验来检验算法性能, 使用表1中BiliBili弹幕数据集共10 000条, 设置迭代阈值为2 500次, 设计实验对比模型训练时误差变化率, 验证PSGD算法的稳定性, 如图6所示;设计实验对比模型分类精度随时间的变化率, 验证PSGD算法具有较低的时间复杂度, 如图7所示。</p>
                </div>
                <div class="p1">
                    <p id="227">由实验结果可以看出, 随着迭代次数的增加, 使用BGD算法进行优化的模型误差逐渐减小, 训练过程比较平稳, 模型分类精度较高, 但由于该算法采用全样本训练的方式, 导致模型训练时间长, 模型训练速度慢;SGD算法每次随机选取样本进行训练, 训练时间较短, 但相对于BGD算法存在的噪声较多, 导致每次迭代并没有向着整体最优化方向进行, 因此SGD的训练过程稳定性较差, 模型易陷入局部最优点, 致使分类精度降低;MBGD算法每次迭代使用部分样本更新模型参数, 相对于SGD算法训练过程比较稳定, 训练时间较短, 模型分类精度介于BGD算法与SGD算法之间;由于本文提出的PSGD算法将模型分类错误的样本引入到训练集中, 相对于MBGD算法的随机性训练集包含更多的信息, 所以可以使模型训练时间更短, 训练过程更稳定, 模型分类精度更高, 从而验证了PSGD算法的有效性。</p>
                </div>
                <div class="area_img" id="228">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 迭代次数对模型训练稳定性的影响" src="Detail/GetImg?filename=images/JSJY201903006_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 迭代次数对模型训练稳定性的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Effect of iterations on model training stability</p>

                </div>
                <div class="area_img" id="229">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903006_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同训练时间下模型分类正确率对比" src="Detail/GetImg?filename=images/JSJY201903006_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同训练时间下模型分类正确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903006_229.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Model classification accuracy comparison under different training time</p>

                </div>
                <h3 id="230" name="230" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="231">本文提出一种基于密度中心点采样的主动学习算法, 利用样本间的相似度将样本进行聚类, 并在每一个聚类簇中, 按照设定的规则选择最具有价值的样本进行人工标注, 减少人工标注的工作量;提出SVD-CNN模型, 使用SVD算法代替传统CNN模型的池化层, 更好地保留了文本语义特征, 从而提高模型的分类精度;使用改进的PSGD算法选取信息量较大的训练样本对模型进行优化, 在保证训练过程稳定性的同时提高了模型的训练速度。通过对比不同主动学习采样算法性能实验表明, DBC-AL算法比传统的主动学习采样算法采集到的样本信息量更高, 对模型的分类贡献更多;对比多种数据集和不同句向量维度下分类模型的分类精度可以看出, SVD-CNN模型能够提取到更多的文本语义特征, 具有较高的分类准确率;对比不同模型优化算法的训练误差与训练时间, PSGD算法具有良好的稳定性, 模型收敛速度更快, 总体训练效果优于其他算法。在主动学习采样的规则条件中, 采样的阈值是通过经验选取, 可能并不是最优的, 如何根据数据集及当前分类模型来对该阈值进行自适应的调整是下一步工作中需要考虑的重要问题。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="249">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703012&amp;v=MjY3MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tLQ0xmWWJHNEg5Yk1ySTlFWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>谭侃, 高旻, 李文涛, 等.基于双层采样主动学习的社交网络虚假用户检测方法[J].自动化学报, 2017, 43 (3) :448-461. (TANK, GAO M, LI W T, et al.Two-layer sampling active learning algorithm for social spammer detection[J].Acta Automatica Sinica, 2017, 43 (3) :448-461.) 
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYD201512032&amp;v=MTc0MTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LUFRuU2FyRzRIOVROclk5R1o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>徐海龙, 别晓峰, 冯卉, 等.一种基于QBC的SVM主动学习算法[J].系统工程与电子技术, 2015, 37 (12) :2865-2871. (XU H L, BIE X F, FENG H, et al.Active learning algorithm for SVM based on QBC[J].Systems Engineering and Electronics, 2015, 37 (12) :2865-2871.) 
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201701007&amp;v=MDI0NjhIOWJNcm85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LSVRmVGU3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>姚拓中, 安鹏, 宋加涛.基于历史分类加权和分级竞争采样的多视角主动学习[J].电子学报, 2017, 45 (1) :46-53. (YAO T Z, AN P, SONG J T.Multi-view active learning based on weighted hypothesis boosting and hierarchical competition sampling[J].Atca Electronica Sinica, 2017, 45 (1) :46-53.) 
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining Semi-Supervised and Active Learning for Hyperspectral Image Classification">

                                <b>[4]</b>LI M, WANG R, TANG K.Combining semi-supervised and active learning for hyperspectral image classification[C]//Proceedings of the 2013 IEEE Symposium on Computational Intelligence and Data Mining.Piscataway, NJ:IEEE, 2013:89-94.
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative active and semisupervised learning for hyperspectral remote sensing image classification">

                                <b>[5]</b>WAN L, TANG K, LI M, et al.Collaborative active and semisupervised learning for hyperspectral remote sensing image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2384-2396.
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel semisupervised active-learning algorithm for hyperspectral image classification">

                                <b>[6]</b>WANG Z, DU B, ZHANG L, et al.A novel semisupervised activelearning algorithm for hyperspectral image classification[J].IEEETransactions on Geoscience and Remote Sensing, 2017, 55 (6) :3071-3083.
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-supervised co-training and active learning framework for hyperspectral image classification">

                                <b>[7]</b>SAMIAPPAN S, MOORHEAD R J.Semi-supervised co-training and active learning framework for hyperspectral image classification[C]//Proceedings of the 2015 IEEE International Geoscience and Remote Sensing Symposium.Piscataway, NJ:IEEE, 2015:401-404.
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201508027&amp;v=MDgxMjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tQeW5SYmJHNEg5VE1wNDlIWTRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>魏超, 罗森林, 张竞, 等.自编码网络短文本流形表示方法[J].浙江大学学报 (工学版) , 2015, 49 (8) :1591-1599. (WEI C, LUO SL, ZHANG J, et al.Short text manifold representation based on autoencoder network[J].Journal of Zhejiang University (Engineering Science) , 2015, 49 (8) :1591-1599.) 
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201805034&amp;v=MDU5NzlHRnJDVVI3cWZadVpwRmlEbFc3L0tJVGZTZHJHNEg5bk1xbzlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>谢金宝, 侯永进, 康守强, 等.基于语义理解注意力神经网络的多元特征融合中文文本分类[J].电子与信息学报, 2018, 40 (5) :1258-1265. (XIE J B, HOU Y J, KANG S Q, et al.Multi-feature fusion based on semantic understanding attention neural network for Chinese text categorization[J].Journal of Electronics and Information Technology, 2018, 40 (5) :1258-1265.) 
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201703021&amp;v=MzAzODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNy9LTmk3SFpyRzRIOWJNckk5SFpZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>孙松涛, 何炎祥.基于CNN特征空间的微博多标签情感分类[J].四川大学学报 (工程科学版) , 2017, 49 (3) :162-169. (SUNS T, HE Y X.Multi-label emotion classification for microblog based on CNN feature space[J].Journal of Sichuan University (Engineering Science Edition) , 2017, 49 (3) :162-169.) 
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network for modelling sentences">

                                <b>[11]</b>KALCHBRENNER N, GREFENSTETTE E, BLUNSOM P.A convolutional neural network for modelling sentences[EB/OL].[2018-07-11].https://arxiv.org/pdf/1404.2188v1.pdf.
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[12]</b>KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-11].https://arxiv.org/pdf/1408.5882.pdf.
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201803028&amp;v=MjcyMjdmWnVacEZpRGxXNy9LSVRmQ2Q3RzRIOW5Nckk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>郑啸, 王义真, 袁志祥, 等.基于卷积记忆神经网络的微博短文本情感分析[J].电子测量与仪器学报, 2018 (3) :195-200. (ZHENG X, WANG Y Z, YUAN Z X, et al.Sentiment analysis of micro-blog short text based on convolutional memory neural network[J].Journal of Electronic Meatruement and Instrumentation, 2018 (3) :195-200.) 
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hybrid CNN-RNN alignment model for phrase-aware sentence classification">

                                <b>[14]</b>HSU S T, MOON C, JONES P, et al.A hybrid CNN-RNN alignment model for phrase-aware sentence classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Vancouver:[s.n.], 2017, 2:433-449.
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ABCNN:attention-based convolutional neural network for modeling sentence pairs">

                                <b>[15]</b>YIN W, SCHUTZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[EB/OL].[2018-07-11].https://arxiv.org/pdf/1512.05193.pdf.
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201108008&amp;v=MjgxMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3L0tLQ0xmWWJHNEg5RE1wNDlGYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>陈荣, 曹永锋, 孙洪.基于主动学习和半监督学习的多类图像分类[J].自动化学报, 2011, 37 (8) :954-962. (CHEN R, CAO YF, SUN H.Multi-class image classification with active learning and semi-supervised learning[J].Acta Automatica Sinica, 2011, 37 (8) :954-962.) 
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805006&amp;v=MTk5NzNpRGxXNy9LTHl2U2RMRzRIOW5NcW85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957. (CHEN K, LIANG B, KE W D, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903006" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903006&amp;v=MjA1ODc0SDlqTXJJOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzcvS0x6N0JkN0c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
