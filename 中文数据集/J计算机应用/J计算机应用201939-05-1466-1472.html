<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136766218252500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201905039%26RESULT%3d1%26SIGN%3dOs%252bdiJaImLvGuD2VKReqyIVptU8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201905039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905039&amp;v=MTAxODhadVpzRnlEblVyL09MejdCZDdHNEg5ak1xbzlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="1 本文算法">1 本文算法</a></li>
                                                <li><a href="#66" data-title="2 鱼类图像的特征提取和匹配">2 鱼类图像的特征提取和匹配</a></li>
                                                <li><a href="#126" data-title="3 实验结果与分析">3 实验结果与分析</a></li>
                                                <li><a href="#143" data-title="4 结语">4 结语</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="图1 鱼类图像检索算法流程">图1 鱼类图像检索算法流程</a></li>
                                                <li><a href="#58" data-title="图2 不同类型的空间金字塔模型">图2 不同类型的空间金字塔模型</a></li>
                                                <li><a href="#61" data-title="图3 不同类型的空间金字塔分块模型">图3 不同类型的空间金字塔分块模型</a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;三种算法在&lt;/b&gt;QUT_fish_data&lt;b&gt;数据集上的性能对比&lt;/b&gt;"><b>表</b>1 <b>三种算法在</b>QUT_fish_data<b>数据集上的性能对比</b></a></li>
                                                <li><a href="#138" data-title="图4 3种算法在QUT_fish_data数据集的P-R曲线对比">图4 3种算法在QUT_fish_data数据集的P-R曲线对比</a></li>
                                                <li><a href="#140" data-title="图5 3种算法在DLOU_fish_data数据集的P-R曲线对比">图5 3种算法在DLOU_fish_data数据集的P-R曲线对比</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;三种算法在&lt;/b&gt;DLOU_fish_data&lt;b&gt;数据集上的性能对比&lt;/b&gt;"><b>表</b>2 <b>三种算法在</b>DLOU_fish_data<b>数据集上的性能对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="165">


                                    <a id="bibliography_1" title=" BOSCH A, ZISSERMAN A, MUNOZ X.Scene classification using a hybrid generative/discriminative approach[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 30 (4) :712-727." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scene classification using a hybrid generative/discriminative approach">
                                        <b>[1]</b>
                                         BOSCH A, ZISSERMAN A, MUNOZ X.Scene classification using a hybrid generative/discriminative approach[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 30 (4) :712-727.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_2" title=" LIAO K, LIU G, HUI Y.An improvement to the SIFT descriptor for image representation and matching[J].Pattern Recognition Letters, 2013, 34 (11) :1211-1220." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080100119424&amp;v=MDAyNzZmYks3SHRuTXJvOUZaZW9HQ0g0OW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGd1ZhaFE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         LIAO K, LIU G, HUI Y.An improvement to the SIFT descriptor for image representation and matching[J].Pattern Recognition Letters, 2013, 34 (11) :1211-1220.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_3" title=" CHUANG M C, HWANG J N, KUO F F, et al.Recognizing live fish species by hierarchical partial classification based on the exponential benefit[C]// Proceedings of the 2014 IEEE International Conference on Image Processing.Piscataway, NJ:IEEE, 2014:5232-5236." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recognizing live fish species by hierarchical partial classification based on the exponential benefit">
                                        <b>[3]</b>
                                         CHUANG M C, HWANG J N, KUO F F, et al.Recognizing live fish species by hierarchical partial classification based on the exponential benefit[C]// Proceedings of the 2014 IEEE International Conference on Image Processing.Piscataway, NJ:IEEE, 2014:5232-5236.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_4" title=" 黄仁, 胡敏.综合颜色空间特征和纹理特征的图像检索[J].计算机科学, 2014, 41 (s1) :118-121. (HUANG R, HU M.Content-based image retrieval using color position and texture fused features[J].Computer Science, 2014, 41 (s1) :118-121.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2014S1026&amp;v=MDc5NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RG5Vci9PTHo3QmI3RzRIOVd2cm85SFlvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         黄仁, 胡敏.综合颜色空间特征和纹理特征的图像检索[J].计算机科学, 2014, 41 (s1) :118-121. (HUANG R, HU M.Content-based image retrieval using color position and texture fused features[J].Computer Science, 2014, 41 (s1) :118-121.) 
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_5" title=" 胡二雷, 冯瑞.基于深度学习的图像检索系统[J].计算机系统应用, 2017, 26 (3) :8-19. (HU E L, FENG R.Image retrieval system based on deep learning[J].Computer Systems &amp;amp; Applications, 2017, 26 (3) :8-19.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201703002&amp;v=MzI2MzlPUFRuU2Q3RzRIOWJNckk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RG5Vci8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         胡二雷, 冯瑞.基于深度学习的图像检索系统[J].计算机系统应用, 2017, 26 (3) :8-19. (HU E L, FENG R.Image retrieval system based on deep learning[J].Computer Systems &amp;amp; Applications, 2017, 26 (3) :8-19.) 
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_6" title=" GUO T, MOUSAVI H S, MONGA V.Deep learning based image super-resolution with coupled backpropagation[C]// Proceedings of the 2016 IEEE Global Conference on Signal and Information Processing.Piscataway, NJ:IEEE, 2017:237-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning based image super-resolution with coupled backpropagation">
                                        <b>[6]</b>
                                         GUO T, MOUSAVI H S, MONGA V.Deep learning based image super-resolution with coupled backpropagation[C]// Proceedings of the 2016 IEEE Global Conference on Signal and Information Processing.Piscataway, NJ:IEEE, 2017:237-241.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_7" title=" 张美玲, 吴俊峰, 于红, 等.一种基于HSVG-SURF特征的鱼类图像检索算法[J].小型微型计算机系统, 2018, 39 (9) :2085-2089. (ZHANG M L, WU J F, YU H, et al.Fish image retrieval algorithm based on HSVG four channel SURF feature[J].Journal of Chinese Computer Systems, 2018, 39 (9) :2085-2089.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201809037&amp;v=MTg0NTA1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09QVFhjZHJHNEg5bk1wbzlHWTRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         张美玲, 吴俊峰, 于红, 等.一种基于HSVG-SURF特征的鱼类图像检索算法[J].小型微型计算机系统, 2018, 39 (9) :2085-2089. (ZHANG M L, WU J F, YU H, et al.Fish image retrieval algorithm based on HSVG four channel SURF feature[J].Journal of Chinese Computer Systems, 2018, 39 (9) :2085-2089.) 
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_8" title=" ZHANG M L, WU J F, Y H, et al.A novel fish image retrieval method based on saliency spatial pyramid[C]// Proceedings of the 2017 14th International Symposium on Pervasive Systems, Algorithms and Networks &amp;amp; 2017 International Conference on Frontier of Computer Science and Technology &amp;amp; 2017 3rd International Symposium of Creative Computing.Washington, DC:IEEE Computer Society, 2017:312-317." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel fish image retrieval method based on saliency spatial pyramid">
                                        <b>[8]</b>
                                         ZHANG M L, WU J F, Y H, et al.A novel fish image retrieval method based on saliency spatial pyramid[C]// Proceedings of the 2017 14th International Symposium on Pervasive Systems, Algorithms and Networks &amp;amp; 2017 International Conference on Frontier of Computer Science and Technology &amp;amp; 2017 3rd International Symposium of Creative Computing.Washington, DC:IEEE Computer Society, 2017:312-317.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_9" title=" 程少光, 何毕, 布树辉, 等.基于超像素空间金字塔模型的场景识别研究[J].计算机工程与应用, 2014, 50 (7) :139-143. (CHENG S G, HE B, BU S H, et al.Sence recognition research based on SSPM[J].Computer Engineering and Applications, 2014, 50 (7) :139-143.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201407030&amp;v=MDk2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RG5Vci9PTHo3TWFiRzRIOVhNcUk5R1pJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         程少光, 何毕, 布树辉, 等.基于超像素空间金字塔模型的场景识别研究[J].计算机工程与应用, 2014, 50 (7) :139-143. (CHENG S G, HE B, BU S H, et al.Sence recognition research based on SSPM[J].Computer Engineering and Applications, 2014, 50 (7) :139-143.) 
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_10" title=" 高常鑫, 桑农.整合局部特征和滤波器特征的空间金字塔匹配模型[J].电子学报, 2011, 39 (9) :2034-2038. (GAO C X, SANG N.Unifying local features and filterbank features in the spatial pyramid matching model[J].Acta Electronica Sinica, 2011, 39 (9) :2034-2038.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201109014&amp;v=MTgzNjZHNEg5RE1wbzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09JVGZUZTc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         高常鑫, 桑农.整合局部特征和滤波器特征的空间金字塔匹配模型[J].电子学报, 2011, 39 (9) :2034-2038. (GAO C X, SANG N.Unifying local features and filterbank features in the spatial pyramid matching model[J].Acta Electronica Sinica, 2011, 39 (9) :2034-2038.) 
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_11" title=" YANG J, YU K, GONG Y, et al.Linear spatial pyramid matching using sparse coding for image classification[C]// Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2009:1794-1801." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Theory of incomplete models of dynamic structures">
                                        <b>[11]</b>
                                         YANG J, YU K, GONG Y, et al.Linear spatial pyramid matching using sparse coding for image classification[C]// Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2009:1794-1801.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_12" title=" 陈鑫元, 李筠, 杨海马, 等.自适应阈值图像二值化及形态学处理的FPGA实现[J].电子测量技术, 2016, 39 (7) :67-71. (CHEN X Y, LI Y, YANG H M, et al.Adaptive threshold binarization and morphological image processing based on FPGA[J].Electronic Measurement Technology, 2016, 39 (7) :67-71.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201607014&amp;v=MjA0MzMzenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09JVGZJWXJHNEg5Zk1xSTlFWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         陈鑫元, 李筠, 杨海马, 等.自适应阈值图像二值化及形态学处理的FPGA实现[J].电子测量技术, 2016, 39 (7) :67-71. (CHEN X Y, LI Y, YANG H M, et al.Adaptive threshold binarization and morphological image processing based on FPGA[J].Electronic Measurement Technology, 2016, 39 (7) :67-71.) 
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_13" title=" WU L S, CHEN J X, WEI L I.Niblack-based binaryzation algorithm for palm vein image[J].Communications Technology, 2010, 43 (1) :112-114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXJS201001041&amp;v=MjA0NjRmYkc0SDlITXJvOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURuVXIvT01UWEI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         WU L S, CHEN J X, WEI L I.Niblack-based binaryzation algorithm for palm vein image[J].Communications Technology, 2010, 43 (1) :112-114.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_14" title=" BAY H, TUYTELAARS T, GOOL L V.SURF:Speeded Up Robust Features[C]// Proceedings of the 9th European Conference on Computer Vision.Berlin:Springer, 2006:404-417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Surf Speeded up robust features">
                                        <b>[14]</b>
                                         BAY H, TUYTELAARS T, GOOL L V.SURF:Speeded Up Robust Features[C]// Proceedings of the 9th European Conference on Computer Vision.Berlin:Springer, 2006:404-417.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_15" title=" PYATYKH S, HESSER J, ZHENG L.Image noise level estimation by principal component analysis[J].IEEE Transactions on Image Processing, 2013, 22 (2) :687-699." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Noise Level Estimation by Principal Component Analysis">
                                        <b>[15]</b>
                                         PYATYKH S, HESSER J, ZHENG L.Image noise level estimation by principal component analysis[J].IEEE Transactions on Image Processing, 2013, 22 (2) :687-699.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_16" title=" SALIMI-KHORSHIDI G, SMITH S M, KELTNER J R, et al.Meta-analysis of neuroimaging data:a comparison of image-based and coordinate-based pooling of studies[J].Neuroimage, 2009, 45 (3) :10-23." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501202379&amp;v=MDY4NDVNbndaZVp0RmlubFVyM0lLRndWYWhRPU5pZk9mYks3SHRETnFvOUVadXNORDNzd29CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         SALIMI-KHORSHIDI G, SMITH S M, KELTNER J R, et al.Meta-analysis of neuroimaging data:a comparison of image-based and coordinate-based pooling of studies[J].Neuroimage, 2009, 45 (3) :10-23.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_17" title=" MURTHY A V, KARAM L J.A MATLAB-based framework for image and video quality evaluation[C]// Proceedings of the 2010 2nd International Workshop on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2010:242-247." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A MATLAB-based framework for image and video quality evaluation">
                                        <b>[17]</b>
                                         MURTHY A V, KARAM L J.A MATLAB-based framework for image and video quality evaluation[C]// Proceedings of the 2010 2nd International Workshop on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2010:242-247.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_18" title=" SINGHA M, HEMACHANDRAN K.Content based image retrieval using color and texture[J].Signal &amp;amp; Image Processing, 2012, 3 (1) :271-273." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Content based image retrieval using color and texture">
                                        <b>[18]</b>
                                         SINGHA M, HEMACHANDRAN K.Content based image retrieval using color and texture[J].Signal &amp;amp; Image Processing, 2012, 3 (1) :271-273.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-19 16:43</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(05),1466-1472 DOI:10.11772/j.issn.1001-9081.2018112522            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于颜色四通道及空间金字塔的鱼类图像检索</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%BE%8E%E7%8E%B2&amp;code=35172738&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张美玲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E4%BF%8A%E5%B3%B0&amp;code=27874681&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴俊峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E7%BA%A2&amp;code=27275969&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B4%94%E6%A6%9B&amp;code=39021727&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">崔榛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%A3%E5%A9%89%E5%A9%B7&amp;code=39021726&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">董婉婷</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E6%B5%B7%E6%B4%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1694046&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连海洋大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E7%9C%81%E6%99%AE%E5%8F%8A%E5%9E%8B%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0147648&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东省普及型高性能计算机重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0246359&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">天津大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着计算机视觉技术在海洋水产领域中的应用不断加深, 鱼类图像检索在渔业资源调查、鱼类行为学分析等方面发挥了巨大的作用。通过研究发现, 鱼类图像的背景信息会对鱼类图像检索造成极大干扰, 而且鱼类图像中颜色、纹理、形状等特征由于空间位置信息的缺乏而使检索的准确率不高。为解决以上问题, 提出了一种新的基于颜色四通道及空间金字塔的鱼类图像检索算法。首先, 提取视觉显著性图将鱼类图像的前景和背景分开, 从而减少图像背景对检索的干扰;其次, 为了使图像特征包含一定的空间位置信息, 利用空间金字塔的理论对图像进行分割, 在此基础上, 将图像转为HSVG四通道图并提取SURF特征;;最后, 得到检索结果。为验证所提算法的有效性, 在QUT<sub>f</sub>ish<sub>d</sub>ata数据集和DLOU<sub>f</sub>ish<sub>d</sub>ata数据集上对算法的查全率、查准率与经典的HSVG算法和显著性分块算法进行对比:在两个数据集上查准率分别比传统的HSVG算法最多分别提高12%和5%, 查全率最多分别提高7%和22%;比传统的显著性分块算法查准率最多分别提高15%和5%, 查全率最多分别提高36%和22%;从而证明所提算法是有效的, 能有效提升鱼类图像的检索效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%B1%BC%E7%B1%BB%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鱼类图像检索;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%9C%E8%89%B2%E9%80%9A%E9%81%93&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜色通道;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA%E9%97%B4%E9%87%91%E5%AD%97%E5%A1%94&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空间金字塔;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张美玲 (1992—) , 女, 山西吕梁人, 硕士研究生, 主要研究方向:计算机视觉、模式识别;;
                                </span>
                                <span>
                                    吴俊峰 (1983—) , 男, 辽宁大连人, 讲师, 博士, CCF会员, 主要研究方向:智能信息处理、计算机视觉;;
                                </span>
                                <span>
                                    *于红 (1968—) , 女, 辽宁大连人, 教授, 博士, CCF会员, 主要研究方向:智能信息处理、大数据;电子邮箱yuhong@dlou.edu.cn;
                                </span>
                                <span>
                                    崔榛 (1995—) , 女, 辽宁丹东人, 硕士研究生, 主要研究方向:计算机视觉、模式识别;;
                                </span>
                                <span>
                                    董婉婷 (1995—) , 女, 辽宁鞍山人, 硕士研究生, 主要研究方向:模式识别、大数据。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61701070, 61802046);</span>
                                <span>辽宁省自然科学基金资助项目 (20170520327);</span>
                                <span>辽宁省高等学校海洋产业技术研究院项目 (2018-CY-34);</span>
                                <span>广东省普及型高性能计算机重点实验室开放基金资助项目 (SZU-GDPHPCL201805);</span>
                                <span>大连市科技计划项目 (2015A11GX022);</span>
                    </p>
            </div>
                    <h1><b>Fish image retrieval algorithm based on color four channels and spatial pyramid</b></h1>
                    <h2>
                    <span>ZHANG Meiling</span>
                    <span>WU Junfeng</span>
                    <span>YU Hong</span>
                    <span>CUI Zhen</span>
                    <span>DONG Wanting</span>
            </h2>
                    <h2>
                    <span>College of Information Engineering, Dalian Ocean University</span>
                    <span>Guangdong Province Key Laboratory of Popular High Performance Computers</span>
                    <span>School of Computer Science and Technology, Tianjin University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the development of the application of computer vision in the field of marine fisheries, fish image retrieval has played a huge role in fishery resource survey and fish behavior analysis. It is found that the background information of fish images can greatly interfere with fish image retrieval, and the fish image retrieval results only using color, texture, shape and other characteristics of fish images are not accurate due to the lack of spatial position information. To solve the above problems, a novel fish image retrieval algorithm based on HSVG (Hue, Saturation, Value, Gray) four-channel and spatial pyramid was proposed. Firstly, a visual saliency map was extracted to separate the foreground and the background, thereby reducing the interference of the image background on the retrieval. Then, in order to contain certain spatial position information, the fish image was converted into an HSVG four-channel map, and on this basis, the theory of spatial pyramid was used to segment the image and extract the SURF (Speed Up Robust Feature) . Finally, the search results were obtained. In order to verify the effectiveness of the proposed algorithm, the recall and precision of the algorithm were compared with classic HSVG algorithm and saliency block algorithm on QUT<sub>f</sub>ish<sub>d</sub>ata dataset and DLOU<sub>f</sub>ish<sub>d</sub>ata dataset. Compared with traditional HSVG algorithm, the precision on two datasets is increased at most by 12% and 5%, and the recall is increased at most by 7% and 22%, respectively. Compared with saliency block algorithm, the precision on two datasets is increased at most by 15% and 5%, and the recall is increased at most by 36% and 22%, respectively. So, the proposed algorithm is effective and can improve the retrieval results significantly.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fish%20image%20retrieval&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fish image retrieval;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20channel&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color channel;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial%20pyramid&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial pyramid;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Meiling, born in 1992, M. S. candidate. Her research interests include computer vision, pattern recognition. ;
                                </span>
                                <span>
                                    WU Junfeng, born in 1983, Ph. D. , lecturer. His research interests include intelligent information processing, computer vision. ;
                                </span>
                                <span>
                                    YU Hong, born in 1968, Ph. D. , professor. Her research interests include intelligent information processing, big data. ;
                                </span>
                                <span>
                                    CUI Zhen, born in 1995, M. S. candidate. Her research interests include computer vision, pattern recognition. ;
                                </span>
                                <span>
                                    DONG Wanting, born in 1995, M. S. candidate. Her research interests include pattern recognition, big data.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-04</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61701070, 61802046);</span>
                                <span>the Natural Science Foundation of Liaoning Province (20170520327);</span>
                                <span>the Project for Institute of Marine Industry Technology of Universities in Liaoning Province (2018-CY-34);</span>
                                <span>the Open fund of Guangdong Province Key Laboratory of Popular High Performance Computers (SZU-GDPHPCL201805);</span>
                                <span>the Technology Program of Dalian (2015A11GX022);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">鱼类图像检索技术为鱼类知识科普、鱼类资源调查及种群分析、鱼病诊断等提供了新思路和新方法, 具有重要的研究意义。鱼类图像有前景背景复杂难以区分而且难以识别等问题, 同时鱼类图像具有丰富的颜色、纹理、形状、位置等特征, 这些特征可以为鱼类图像检索提供有价值的信息。因此, 鱼类图像检索既要考虑有效利用颜色、纹理、形状、位置等特征又要考虑避免背景对检索效果产生过大的影响。</p>
                </div>
                <div class="p1">
                    <p id="41">为解决这个难题, 许多专家学者对此进行深入的研究。Bosch等<citation id="201" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出一种基于HSV (Hue, Saturation, Value) 三通道的尺度不变特性变换 (Scale-Invariant Feature Transform, SIFT) 特征提取算法, 该算法对图像中的像素对应的三个通道都提取SIFT特征并组成128×3的特征描述子 (标准的SIFT特征为128维特征向量) , 然后利用提取到的SIFT特征<citation id="202" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>实现对不同场景图像的分类, 但SIFT算法本身的计算复杂度较高, 其特征提取的计算成本很大, 同时可能会在SIFT描述子中混入不必要的噪声。Chuang等<citation id="203" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出SHPC (Systematic Hierarchical Partial Classification) 算法以实现对鱼类的识别, 通过一种逐层带偏袒策略的分类实现对不同种类鱼在空间位置中的识别, 虽然实现了空间位置的识别但是效率和精度上有一定的局限性, 对自然场景中的鱼种不能很好地识别其空间位置。黄仁等<citation id="204" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的基于颜色空间特征的图像检索能够很好地解决这一问题, 该算法采用HSV颜色模型, 在HSV空间中采用非等间隔量化的方式对图像中的像素逐个量化, 计算并归一化图像的颜色直方图和每类颜色的中心位置从而得到图像的颜色空间特征。但是该算法是在传统的颜色直方图的基础上加入相应的空间位置信息, 可以避免不同图像具有相同的颜色直方图的情况, 该方法是针对全局特征进行检索的, 其检索精度不理想。胡二雷等<citation id="205" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一种基于深度学习的图像检索系统, 该算法采用Alexnet神经网络, 前5个卷积层提取的是图像的低级可视化特征, 后3层提取的是图像的高级特征。其检索库为20万张图片, 检索出来前10张的平均相似度在80%以上, 精度不够高, 而且需要的训练时间较长。</p>
                </div>
                <div class="p1">
                    <p id="42">经过进一步研究发现, 采用鱼类图像的其中一种特征进行匹配识别往往不够全面<citation id="206" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 因而要综合考虑鱼类图像的各种特征, 采用多特征合并的方式进行鱼类图像的检索来提高检索效果<citation id="207" type="reference"><link href="177" rel="bibliography" /><link href="179" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。传统的多特征鱼类图像检索采用多特征向量合并方式将颜色特征和纹理特征合并后进行鱼类图像检索, 这种多特征合并方式对表达多种特征的能力较弱, 合并后的多特征向量无法有效地将鱼类的颜色特征和纹理特征进行融合, 从而影响鱼类图像检索算法的性能。其次目前的图像检索算法大多只能对背景简单的图像进行检索, 对自然场景下的图像检索还没有较多的研究, 针对鱼类图像以及自然场景下的鱼类图像检索则相对更少, 局限于单一场景, 很难将鱼类图像检索技术应用到真实的自然场景即海洋渔业领域中, 其检索的结果误差较大。</p>
                </div>
                <div class="p1">
                    <p id="43">基于以上分析, 本文提出一种基于HSVG (Hue, Saturation, Value, Gray) 四通道及空间金字塔的鱼类图像显著区域检索算法以提高鱼类图像检索的准确性和鲁棒性。首先, 根据鱼类图像的特点提取鱼类图像的视觉显著性图, 并根据显著性图自适应的将鱼类图像的前景和背景有效地分开, 从而避免图像背景对检索的干扰; 然后, 根据空间金字塔的理论对图像进行分块, 在此基础上, 将图像转为HSVG四通道图和SURF (Speed Up Robust Feature) 的提取; 最后, 进行最终的匹配并得到检索结果。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">1 本文算法</h4>
                <h4 class="anchor-tag" id="45" name="45">1.1 <b>本文算法框架</b></h4>
                <div class="p1">
                    <p id="46">针对自然场景下的鱼类图像检索问题, 本文提出基于HSVG四通道及空间金字塔的鱼类图像检索算法, 通过并行提取四通道下鱼头、鱼身和鱼尾的SURF鱼类特征使得所提特征能够融合颜色与纹理两种不同类型的特征, 提高不同鱼类之间的区分度。然后对提取到的SURF特征进行特征匹配, 最后对SURF特征匹配结果进行综合加权后求得最终特征的相似度, 根据相似度结果进行排序得出检索结果。该算法的具体步骤如图1所示。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905039_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 鱼类图像检索算法流程" src="Detail/GetImg?filename=images/JSJY201905039_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 鱼类图像检索算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905039_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of fish image retrieval algorithm</p>

                </div>
                <h4 class="anchor-tag" id="48" name="48">1.2 <b>图像的预处理</b></h4>
                <div class="p1">
                    <p id="49">在进行图像检索过程中, 首先需要进行实验数据的收集及整理, 由于收集图像的工具和渠道不同可能导致收集到的图像差异很大, 因此需要对图像进行预处理。图像预处理的目的是最大限度地简化数据并且统一数据格式。预处理过程一般有归一化、去噪、显著性提取以及图像增强等。</p>
                </div>
                <div class="p1">
                    <p id="50">本文所使用的数据来源由三部分组成:实际拍摄、互联网下载及由澳大利亚昆士兰大学提供。由于不同渠道得到的数据其大小不尽相同, 这对于特征的提取匹配会有很大的影响。为方便后续工作, 将所有的数据归一化到相同的分辨率大小。此外, 收集到的鱼类图像中有可能有单通道图像, 即灰度图, 此时需要将这些图像去除掉, 以避免影响后续的实验。同时由于图像的不同获取方式, 使得图像中可能夹杂不同种类的噪声, 比如高斯噪声、椒盐噪声、均匀噪声等, 本文主要针对椒盐噪声和高斯噪声进行了处理, 针对椒盐噪声和高斯噪声, 采取了中值滤波的方法进行处理。此外, 鱼类图像的背景信息会对鱼类图像检索会产生极大的干扰, 许多非鱼类的特征信息被统计到鱼类特征中, 由此会影响最终的检索效果。为了解决这个问题, 比较理想的方法就是将图像中的鱼类与其背景分离开来。由此提出使用视觉显著性图来解决这个问题。图像的显著性区域是最能引起人类视觉注意力的区域, 因此显著性区域在绝大多数情况下为图像中的前景区域, 或者说是图像中的感兴趣区, 也是图像检索的目标区域。而非显著性区域一般情况下为背景, 也是在特征匹配过程中需要去除的区域。一般情况下, 鱼类图像本身前后背景颜色差异大, 轮廓和纹理比较清晰, 由此利用鱼类图像中的颜色差异性和模式差异性来提取图像的显著性图<citation id="208" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="51"><i>S</i> (<i>p</i><sub><i>x</i></sub>) =<i>P</i> (<i>p</i><sub><i>x</i></sub>) ·<i>C</i> (<i>p</i><sub><i>x</i></sub>) ·<i>G</i> (<i>p</i><sub><i>x</i></sub>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="52">其中:<i>p</i><sub><i>x</i></sub>是图像块, <i>S</i> (<i>p</i><sub><i>x</i></sub>) 是图像块的显著性值, <i>P</i> (<i>p</i><sub><i>x</i></sub>) 是图像块的模式差异性, <i>C</i> (<i>p</i><sub><i>x</i></sub>) 是图像块的颜色差异性, <i>G</i> (<i>p</i><sub><i>x</i></sub>) 是高斯权重公式。根据鱼类图像场景的均匀分布, 但又存在一定波动性的特性, 给出了判断鱼类目标或背景信息的阈值计算方法, 如式 (2) 所示:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>m</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>S</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msub><mrow><mo stretchy="false">) </mo><mo>/</mo></mrow><mi>n</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">其中<i>S</i>为<i>m</i>*<i>n</i>大小的显著图。利用式 (2) 所计算得到的阈值, 将显著图二值化后对二值图像进行面积滤波从而避免图像背景中的非鱼类显著性区域对前景造成的干扰。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">1.3 <b>空间位置特征</b></h4>
                <div class="p1">
                    <p id="56">一般情况下, 按指定块数或指定长宽比对图像进行分块, 分块是基于空间金字塔匹配原理进行的。空间金字塔通常是指将图像经过下采样处理后得到不同分辨率的图像组合, 空间金字塔模型 (Spatial Pyramid Model, SPM) <citation id="209" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>是一种利用空间金字塔进行图像匹配、识别、分类的算法<citation id="210" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="57">空间金字塔分块是在不同分辨率的小块上统计图像特征点分布, 从而获取图像的空间信息。金字塔多分辨率生成较快, 且占用存储空间少。由于鱼类图像检索中鱼类目标基本位于图像的中央主体部分, 因而采用空间金字塔模型将鱼类图像分为4块、6块、8块及10块进行实验 (如图2) , 通过大量的实验发现将鱼类图像分为3块所得到的结果更为高效并且实验结果较好。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905039_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同类型的空间金字塔模型" src="Detail/GetImg?filename=images/JSJY201905039_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同类型的空间金字塔模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905039_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Different types of spatial pyramid model</p>

                </div>
                <div class="p1">
                    <p id="59">现阶段实验所用的鱼类图库较为规范, 鱼类图像中的鱼头鱼身和鱼尾的方向一致, 因此按等分的方式将鱼分为3块已经初步符合其生理特性, 如果进一步细分会增加其匹配的复杂度, 同时因为分块区域太多容易使得鱼类图像碎片化, 降低其生理特征的完整度。因此本文采用均匀分块的方式将鱼类图像分为鱼头、鱼身、鱼尾三部分<citation id="211" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>进行。</p>
                </div>
                <div class="p1">
                    <p id="60">用空间金字塔方法表示图像是对传统方法的改进。传统方法提取图像特征时, 首先提取每张检索图像的特征描述子和图库中所有图像的特征描述子, 之后将检索图的特征和图库中的所有特征进行匹配, 这样会丢失图像的空间分布信息即位置信息, 会出现鱼头的特征点与鱼尾的特征点进行匹配的情况, 明显会有很多错误的匹配, 不能够对图像进行精确的识别匹配, 因而在此基础上提出空间金字塔方法, 它是在不同分辨率上进行图像的特征分布统计, 从而获得图像的空间信息, 即将图像划分为精细的网格序列, 从每个网格中导出特征并组合成为一个很大的特征向量。本文基于空间金字塔的精确匹配, 提出将图像分块处理, 在对鱼类图像进行预处理等一系列操作后, 将图像分割成大小相等的矩形区域进行特征提取, 这样能够提高鱼类图像的识别率。如图3是将鱼类原图和显著性二值图<citation id="212" type="reference"><link href="187" rel="bibliography" /><link href="189" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>进行分块的示意图。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905039_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同类型的空间金字塔分块模型" src="Detail/GetImg?filename=images/JSJY201905039_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同类型的空间金字塔分块模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905039_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Different types of spatial pyramid blocking model</p>

                </div>
                <h4 class="anchor-tag" id="62" name="62">1.4 HSVG<b>四通道颜色特征</b></h4>
                <div class="p1">
                    <p id="63">鱼类图像本身包含着丰富的颜色信息, 这些颜色往往在色调、纯度和饱和度上各有差异, 鱼类图像的花纹在单一的H、S或V通道中更为明显, 这种颜色通道能够从三个方面来描述颜色的特性, 在对颜色表述上能够相互补充, 更有效地提取出鱼类图像所蕴藏在颜色差异中的结构信息, 进而在一定程度上反映颜色信息; 同时图像中除了具有丰富的颜色信息之外, 还会因为光照的影响在鱼类表面产生强弱程度不等的反射或产生明暗相间的花纹和轮廓, 因此在HSV三通道外引入灰度图作为第四通道提取SURF特征。本文综合考虑色差和光照这两种因素的影响, 提出基于HSV颜色模型和灰度Gray的四通道模型即HSVG四通道的颜色空间模型。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">1.5 <b>纹理特征</b></h4>
                <div class="p1">
                    <p id="65">SURF是图像检索中基于内容 (Content-Based Image Retrieval, CBIR) 的一种图像特征提取方法<citation id="213" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 常用的CBIR特征有颜色、纹理等, 相较于这些特征, SURF能够更加细致地表示图像的局部信息。在鱼类图像检索中, 鱼的局部差异往往比较明显而全局差异不是特别大, 此外由于拍摄角度等问题, 图像中的鱼类即使是同一条鱼, 它的整体形态也会发生变化, 在这种情况下全局特征的不变性会较差。相比之下, SURF属于局部特征因而能够更好地反映出图像中的局部差异, 并且具有更强的特征不变性, 因此该算法使用SURF特征能够更好地对鱼类图像进行检索。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">2 鱼类图像的特征提取和匹配</h4>
                <h4 class="anchor-tag" id="67" name="67">2.1 <b>特征提取</b></h4>
                <div class="p1">
                    <p id="68">为提高利用SURF特征提取和匹配的准确度, 采用预处理技术得到鱼类图像显著图来提取SURF特征, 这些特征集中于鱼类的关键区域。相对于直接从原始图像中提取的SURF特征, 利用显著图提取到的SURF特征更加稀疏而精确, 同时能够从鱼类图像中获取更为丰富的有效信息。在此基础上, 将鱼类图像利用空间金字塔技术分为鱼头、鱼身、鱼尾三部分, 然后分别提取每一部分的HSVG四个通道下的SURF特征, 进而分别得到鱼头、鱼身、鱼尾三个部分的HSVG四个颜色通道的不同的SURF特征, 使得所提特征包含位置信息, 避免在特征描述子中混入不必要的噪声信息<citation id="214" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 能更好地表现鱼类的形态和局部特征;同时分四个通道提取的特征包含鱼类图像由色差和光照影响的轮廓特征和纹理特征, 从而进一步提高不同种类鱼之间的区分度。这种方式能够通过通道互补使得图像具有更完整的表述能力, 这为精确检索提供有效的帮助。在此基础上采用多核CPU并行处理的方式对四通道下鱼头、鱼身和鱼尾的SURF特征进行计算, 从而降低检索的时间消耗。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2 <b>特征匹配</b></h4>
                <div class="p1">
                    <p id="70">图像特征匹配是指将图像特征进行相似度计算对图像的相似程度作出评价。特征匹配是图像检索模型的一个重要的环节, 在提取出图像的特定特征之后进行相似度的匹配。图像相似度匹配方法有很多种, 不同的匹配方法会影响检索图与图库图像之间的相似度, 即图像特征点之间匹配的相似程度。</p>
                </div>
                <div class="p1">
                    <p id="71">多通道下的图像检索能够带来比单通道检索更为丰富的特征, 但是多通道的SURF特征会面临多种特征匹配方式的选择问题, 不同特征匹配方式会影响提取到的特征向量的保存方式, 同时其特征利用效率以及匹配精度都有差异。经过归纳整理, 发现多通道下的SURF特征匹配方法主要分为两类, 一类匹配方法为将不同通道中的SURF特征进行加权后变为列向量然后进行特征匹配, 另外一类为将特征按通道分别进行特征匹配, 然后将匹配后的特征得分进行加权得到最终匹配得分。第一类特征匹配方式能够降低特征本身的复杂度从而加快特征匹配的过程, 特征匹配的效率较高。第二类特征匹配方式能够更为有效地利用多通道SURF互补性, 因而从检索精度上分析, 该方法的匹配结果精度要高于第一类特征匹配方法。但是该方法的特征匹配效率要低于第一类特征匹配方法。本文综合考虑图像检索的精度和效率问题, 对不同的特征提取和特征匹配的耗时进行研究分析后发现, 在鱼类图像检索的整个过程中, 耗时主要集中在图像的特征提取环节, 相比较之下图像的特征匹配的总体耗时比重不大, 鱼类图像检索的整体效率依然可以保持基本不变。此外由于是采用独立匹配的方式, 可以对各部分进行并行处理, 从而保证算法的时间复杂度不变, 因此本文选取第二类图像特征匹配方式对从多通道中提取的鱼类图像SURF特征进行特征的提取和匹配。</p>
                </div>
                <div class="p1">
                    <p id="72">常用的图像特征匹配方式有距离度量和相关系数度量两类度量方式, 其中距离度量方式能够体现特征向量之间的数值差异, 相关系数度量方式能够体现出特征向量之间相关关系密切程度<citation id="215" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。在HSVG四通道及空间金字塔下的SURF特征具有一定的差异性和互补性, 其特征差异往往不体现在特征的数值差异上而是主要体现在特征向量的相位差异上。所以, 采用相关系数的度量方式更加符合HSVG四通道和空间金字塔下SURF特征的特征匹配特性。本文首先将提取到的鱼类图像特征向量进行归一化处理, 经过归一化的特征向量之间其差异性相对被压缩, 因此采用相关系数度量方式对其进行相关系数的计算。</p>
                </div>
                <div class="p1">
                    <p id="73">本文首先提取四通道下每个通道中的鱼头、鱼身、鱼尾三个部分的SURF特征, 按照特征所属通道的不同空间位置单独保存。在特征匹配过程中, 为了能够继续保持各个颜色通道和各个空间位置的特征独立性, 本课题组只针对检索图和图库图像的相同通道下的相同空间位置的SURF特征进行特征匹配。其匹配公式如下:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>Η</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>Η</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>Η</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>Η</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>Η</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>Η</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>S</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>S</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>V</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>V</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>V</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>V</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>V</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>V</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>V</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>V</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>V</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>G</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>G</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>G</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>G</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>=</mo><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>G</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi>F</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>G</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">其中:corr为图像特征相关系数的计算公式, 本文采用皮尔逊相关系数作为四通道鱼类SURF特征的特征计算方法。式 (3) 计算HSVG四通道每个通道下检索图和图库图像的鱼头、鱼身和鱼尾的SURF特征的相关系数, 在此基础上计算HSVG四通道下相同位置的SURF特征的相似度匹配得分<i>S</i><sub>1</sub>, 如式 (4) :</p>
                </div>
                <div class="p1">
                    <p id="76"><i>S</i><sub>1</sub>=<i>w</i><sub><i>H</i><sub>1</sub></sub>·<i>S</i><sub><i>H</i><sub>1</sub></sub>+<i>w</i><sub><i>S</i><sub>1</sub></sub>·<i>S</i><sub><i>S</i><sub>1</sub></sub>+<i>w</i><sub><i>V</i><sub>1</sub></sub>·<i>S</i><sub><i>V</i><sub>1</sub></sub>+<i>w</i><sub><i>G</i><sub>1</sub></sub>·<i>S</i><sub><i>G</i><sub>1</sub></sub>      (4) </p>
                </div>
                <div class="p1">
                    <p id="77">其中参数<i>w</i><sub><i>H</i><sub>1</sub></sub>、<i>w</i><sub><i>S</i><sub>1</sub></sub>、<i>w</i><sub><i>V</i><sub>1</sub></sub>、<i>w</i><sub><i>G</i><sub>1</sub></sub>为鱼类图像检索图和图库图像对应通道提取到鱼头的SURF特征其相似度得分权重。本课题组是基于HSVG四通道及空间金字塔的鱼类图像SURF特征提取匹配检索过程, 其通过四通道提取的SURF特征相互之间的互补性的重要程度相当, 因而本课题组采用的四通道的权重相等, 此外为了防止四通道相似度叠加后的值过大, 因而<i>w</i><sub><i>H</i><sub>1</sub></sub>=<i>w</i><sub><i>S</i><sub>1</sub></sub>=<i>w</i><sub><i>V</i><sub>1</sub></sub>=<i>w</i><sub><i>G</i><sub>1</sub></sub>=1/4。</p>
                </div>
                <div class="p1">
                    <p id="78">四通道下的SURF特征向量首先按通道独立匹配, 然后将四通道匹配得分加权计算综合得分, 采用这种方法所得到的相似度值, 其特征匹配过程更加全面, 特征匹配效果相较于仅从灰度图中提取SURF特征并匹配的效果要更加精确。</p>
                </div>
                <div class="p1">
                    <p id="79">类似的, 得到鱼身、鱼尾的SURF特征的相似度得分, 最终得到检索图和图库中每条鱼的相似度得分, 如式 (5) 所示:</p>
                </div>
                <div class="p1">
                    <p id="80"><i>S</i>=<i>W</i><sub>1</sub>·<i>S</i><sub>1</sub>+<i>W</i><sub>2</sub>·<i>S</i><sub>2</sub>+<i>W</i><sub>3</sub>·<i>S</i><sub>3</sub>      (5) </p>
                </div>
                <div class="p1">
                    <p id="81">其中:<i>S</i><sub>1</sub>、<i>S</i><sub>2</sub>、 <i>S</i><sub>3</sub>为鱼头、鱼身和鱼尾的相似度得分, 加权求和后得到这幅检索图同图库中的其中一幅鱼类图像的匹配相关度。同样的, 通过空间金字塔提取的SURF特征之间的位置细腻的重要程度相当, 因而本课题组采用的鱼头、鱼身和鱼尾的权重相等, 同样地为了防止三部分相似度叠加后的得到的相似度值过大, 因而其权重<i>w</i><sub>1</sub>=<i>w</i><sub>2</sub>=<i>w</i><sub>3</sub>=1/3。经过实验验证四通道采用相同的权重同时鱼头鱼身鱼尾采用相同的权重进行特征的匹配其准确率较高, 因此本文采用相同权重进行相似度的叠加。</p>
                </div>
                <div class="p1">
                    <p id="82">将特征匹配加权得分进行排序, 得到鱼类图像检索结果, 如式 (6) :</p>
                </div>
                <div class="p1">
                    <p id="83"><i>R</i>=sort (<i>R</i>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="84">其中:<i>R</i>=[<i>r</i><sub>1</sub>, <i>r</i><sub>2</sub>, …, <i>r</i><sub><i>i</i></sub>, …, <i>r</i><sub><i>n</i></sub>], <i>n</i>∈ (1, 2, …, <i>n</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="85">下面给出特征匹配的基本步骤:</p>
                </div>
                <div class="p1">
                    <p id="86">步骤1 提取鱼类检索图和图库图像的HSVG每个通道下鱼头、鱼身、鱼尾三个部分的SURF特征点<i>F</i><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>q</mi><mi>i</mi></msubsup></mrow></math></mathml>、<i>F</i><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>d</mi><mi>i</mi></msubsup></mrow></math></mathml>, 其中<i>F</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>q</mi><mi>i</mi></msubsup></mrow></math></mathml>表示检索图特征点, <i>F</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>d</mi><mi>i</mi></msubsup></mrow></math></mathml>表示图库图像特征点。</p>
                </div>
                <div class="p1">
                    <p id="91">步骤2 对鱼类图像的SURF特征点进行点匹配, 得到单通道下检索图的每个部分每个SURF特征点与单幅图库图像中所有SURF特征点之间的最大相关度系数作为该通道该部分鱼类检索图SURF特征点与图库图像特征点之间的最高匹配度。</p>
                </div>
                <div class="p1">
                    <p id="92">步骤3 将得到的该幅鱼类检索图HSVG四个通道下鱼头、鱼身、鱼尾部分的SURF特征点与单幅图库图像的SURF特征点的最高匹配度进行排序, 把排名前三的匹配度进行加权求和, 作为该幅检索图该通道下该部分的相似度得分。</p>
                </div>
                <div class="p1">
                    <p id="93">步骤4 按上述步骤计算后, 对检索图和图库图像分别按HSVG四通道下鱼头、鱼身、鱼尾三部分对应进行特征匹配。</p>
                </div>
                <div class="p1">
                    <p id="94">步骤5 将得到的检索图和图库图像鱼头、鱼身和鱼尾中某一部分在四通道下的相关系数进行加权计算, 得到这幅鱼类检索图与图库中所有图像该部分的相似度得分。同理计算, 得到鱼类图像检索图与图库每幅图像之间鱼头、鱼身和鱼尾三部分之间的相似度得分。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">2.3 <b>鱼类图像检索算法</b></h4>
                <div class="p1">
                    <p id="96">首先, 采用HSVG四通道颜色模型和空间金字塔按鱼头、鱼身、鱼尾进行分块;然后, 分别进行特征提取和匹配;最后, 加权求得特征相似度。这样既避免因外界因素光照影响和鱼类图像本身的色差产生的影响, 同时也符合鱼类的生理特性, 进而能够有效地提高检索结果的准确度。该算法的伪代码如下:</p>
                </div>
                <div class="p1">
                    <p id="97">算法 Fish-Image-Retrieval。</p>
                </div>
                <div class="area_img" id="220">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201905039_22000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="126" name="126">3 实验结果与分析</h4>
                <div class="p1">
                    <p id="127">本文在Windows7系统下使用Matlab2012b<citation id="216" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>进行图像检索仿真实验。实验环境的硬件配置为:Intell Xeon CPU E5-250 v2 2.60 GHz 32核处理器, 32 GB内存。</p>
                </div>
                <div class="p1">
                    <p id="128">本文采用的数据集为澳大利亚昆士兰大学提供的QUT_fish_data鱼类图像数据集, 该图像库包含4 405张海洋鱼类静态图像, 每张图像标有对应的种类标签。该图像库是目前已知的最大规模鱼类图像数据标定集。在此数据集上可以客观有效地评价图像检索算法的鲁棒性和准确率。此外本文还采用大连海洋大学图像组采集的鱼类场景图像数据集DLOU_fish_data, 该图像库包含200张鱼类图像数据, 每类鱼类图像包含不同的鱼类图像场景, 采用此图像库能够在一定程度上评价鱼类图像检索算法对复杂场景下的鱼类图像的检索能力。</p>
                </div>
                <div class="p1">
                    <p id="129">评价方法 本文采用准确率和召回率对所提算法的有效性进行评价<citation id="217" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。其中准确率反映的是图像检索的精度, 召回率是图像检索算法对同类信息检索查找全面程度的评价指标。此外, 综合考虑检索算法的查准和查全能力, 采用准确率-召回率 (Precision-Recall, P-R) 曲线评价图像检索算法:</p>
                </div>
                <div class="p1">
                    <p id="130" class="code-formula">
                        <mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132">其中:<i>TP</i> (True Positive) 是检索到的图像中包含有与检索图像相似的同类图的数量, <i>FP</i> (False Positive) 为检索到的图像中非同类图像的数量, <i>FN</i> (False Negative) 是图库中全部同类图中未检索到的同类图数量。</p>
                </div>
                <div class="p1">
                    <p id="133">为了验证本文所提的基于HSVG四通道及空间金字塔的鱼类图像检索算法的有效性和鲁棒性, 采用基于HSVG四通道的鱼类图像检索算法 (以下简称HSVG算法) <citation id="218" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和基于显著性及空间金字塔的鱼类图像检索算法 (以下简称显著性分块算法) <citation id="219" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>作基准, 在QUT_fish_data数据集和DLOU_fish_data数据集上进行仿真实验, 并采用P-R曲线对图像检索算法性能进行评价。</p>
                </div>
                <div class="p1">
                    <p id="134">由于以上两种鱼类图像检索对比算法都有一定的局限性, 不能很好地将其应用到自然场景中, 因此提出基于HSVG四通道及空间金字塔的鱼类图像检索算法。该算法将HSVG算法和显著性分块算法结合起来, 既采用基于HSVG四通道鱼类图像检索算法中颜色特征和纹理特征的差异性和互补性;同时采用基于显著性及空间金字塔的鱼类图像检索算法中的显著性提取和空间金字塔技术, 避免背景区域误检到的噪声导致的特征被误提取, 采用空间金字塔技术将空间位置信息融入到提取的特征中, 避免特征的误匹配。</p>
                </div>
                <div class="p1">
                    <p id="135">为了验证该算法的有效性, 首先在QUT_fish_data数据集上进行测试, 测试集同样为数据集中100次随机挑选的200幅不同种类的鱼类图像进行100次实验, 检索结果如表1所示。</p>
                </div>
                <div class="area_img" id="136">
                    <p class="img_tit"><b>表</b>1 <b>三种算法在</b>QUT_fish_data<b>数据集上的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Performance comparison of three methods on QUT_fish_data</p>
                    <p class="img_note"></p>
                    <table id="136" border="1"><tr><td rowspan="2">检索数</td><td colspan="2"><br />HSVG</td><td rowspan="2"></td><td colspan="2"><br />显著性分块</td><td rowspan="2"></td><td colspan="2"><br />本文算法</td></tr><tr><td><br />查准率</td><td>查全率</td><td><br />查准率</td><td>查全率</td><td><br />查准率</td><td>查全率</td></tr><tr><td>5</td><td>0.95</td><td>0.35</td><td></td><td>0.92</td><td>0.25</td><td></td><td>0.98</td><td>0.40</td></tr><tr><td><br />10</td><td>0.82</td><td>0.52</td><td></td><td>0.75</td><td>0.30</td><td></td><td>0.90</td><td>0.51</td></tr><tr><td><br />15</td><td>0.76</td><td>0.60</td><td></td><td>0.65</td><td>0.32</td><td></td><td>0.87</td><td>0.62</td></tr><tr><td><br />20</td><td>0.72</td><td>0.62</td><td></td><td>0.70</td><td>0.35</td><td></td><td>0.83</td><td>0.65</td></tr><tr><td><br />25</td><td>0.67</td><td>0.67</td><td></td><td>0.64</td><td>0.38</td><td></td><td>0.79</td><td>0.74</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="137">从表1以及图4可以看出, 基于本文算法在QUT_fish_data 数据集上查准率和查全率高于HSVG算法和显著性分块算法。但是该算法与基于HSVG四通道的鱼类图像检索算法差异不大, 经过分析发现通过这两种算法提取到的特征点相似度较高, 究其原因主要在于QUT_fish_data数据集中鱼类种类繁多, 但其前后背景差异不大, 因而通过显著性预处理得到前景鱼类中提取得到的特征与不采用显著性预处理提取到的特征差异不大, 但是该算法中采用空间金字塔模型, 使得提取到的特征中包含空间位置信息, 在一定程度上提高检索精度。由图4中P-R曲线可以进一步验证本文算法在较大规模鱼类图像数据集上具有较强的鲁棒性以及较高的准确度, 进而可以在一定程度上通过实验证明该算法理论在鱼类图像检索问题上具有一定的正确性和可靠性。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905039_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3种算法在QUT_fish_data数据集的P-R曲线对比" src="Detail/GetImg?filename=images/JSJY201905039_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 3种算法在QUT_fish_data数据集的P-R曲线对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905039_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 P-R curves comparison of three algorithms on QUT_fish_data dataset</p>

                </div>
                <div class="p1">
                    <p id="139">同时, 本文在DLOU_fish_data数据集上进行扩充实验, 从实验结果表2来看, 在小数据集上, 本文算法检索效果比较明显, 查全率随着检索数量的增加而显著增加。其原因在于, DLOU_fish_data数据集中的鱼类图像处于自然场景中, 背景比较复杂, 对特征提取的干扰较为严重;而本文算法采用显著性提取技术, 能很好地将鱼类图像的前后背景区分开来, 有效地避免背景对前景的干扰, 使得提取到的特征更加准确。通过图5中的P-R曲线可以看出本文检索算法在DLOU_fish_data上的总体性能要好于对比算法, 这证明本文算法对于复杂场景的鱼类图像检索具有一定的鲁棒性和准确度。</p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201905039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种算法在DLOU_fish_data数据集的P-R曲线对比" src="Detail/GetImg?filename=images/JSJY201905039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 3种算法在DLOU_fish_data数据集的P-R曲线对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201905039_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 P-R curves comparison of three algorithms on DLOU_fish_data</p>

                </div>
                <div class="p1">
                    <p id="141">通过以上两组实验可以看出, 由于这两种数据集中同类图的数量较少, 因此其准确率随着检索数量的增加而显著降低, 但是其召回率显著增高。因此本文所提出的基于HSVG四通道及空间金字塔的鱼类图像检索算法在较大规模图像集中具有较强鲁棒性和准确率, 并且对复杂的自然场景图像具有一定的适应能力, 通过以上实验可以基本证明本文所提理论的客观有效性。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表</b>2 <b>三种算法在</b>DLOU_fish_data<b>数据集上的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Performance comparison of three methods on DLOU_fish_data</p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td rowspan="2">检索数</td><td colspan="2"><br />HSVG</td><td rowspan="2"></td><td colspan="2"><br />显著性分块</td><td rowspan="2"></td><td colspan="2"><br />本文算法</td></tr><tr><td><br />查准率</td><td>查全率</td><td><br />查准率</td><td>查全率</td><td><br />查准率</td><td>查全率</td></tr><tr><td>5</td><td>0.13</td><td>0.40</td><td></td><td>0.17</td><td>0.40</td><td></td><td>0.22</td><td>0.62</td></tr><tr><td><br />10</td><td>0.09</td><td>0.50</td><td></td><td>0.12</td><td>0.55</td><td></td><td>0.15</td><td>0.68</td></tr><tr><td><br />15</td><td>0.08</td><td>0.61</td><td></td><td>0.10</td><td>0.61</td><td></td><td>0.11</td><td>0.70</td></tr><tr><td><br />20</td><td>0.08</td><td>0.65</td><td></td><td>0.09</td><td>0.70</td><td></td><td>0.08</td><td>0.72</td></tr><tr><td><br />25</td><td>0.07</td><td>0.75</td><td></td><td>0.08</td><td>0.70</td><td></td><td>0.09</td><td>0.82</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="143" name="143">4 结语</h4>
                <div class="p1">
                    <p id="144">本文提出基于HSVG四通道及空间金字塔的鱼类图像检索算法。该算法先利用图像显著性提取算法去除背景对鱼的干扰;再利用空间金字塔模型将鱼类图像分为鱼头、鱼身、鱼尾三部分;然后对鱼类图像按HSVG四个通道分别提取SURF特征, 使得提取到的特征融合形状特征、空间位置特征、颜色特征和纹理特征, 利用所提取到的SURF特征按通道进行匹配求取检索图与图库图像之间的相关度;最后经过加权求得图像之间的相似度, 按相似度由高到低顺序输出检索结果, 提高检索准确度, 增强检索算法的鲁棒性。为验证所提算法的有效性, 在QUT_fish_data数据集和DLOU_fish_data数据集上对算法的查全率、查准率与一些经典的鱼类图像检索算法进行了对比, 在两个数据集上查准率分别比传统的HSVG算法最多分别提高12%和5%, 查全率最多分别提高7%和22%, 从而证明本文算法是有效的, 可有效提升鱼类图像的检索效果。</p>
                </div>
                <div class="p1">
                    <p id="145">随着深度学习的火热发展, 未来的工作应逐步扩充数据集, 设计网络结构来提取到更为有效的鱼类图像特征, 以增强鱼类图像检索效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="165">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scene classification using a hybrid generative/discriminative approach">

                                <b>[1]</b> BOSCH A, ZISSERMAN A, MUNOZ X.Scene classification using a hybrid generative/discriminative approach[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 30 (4) :712-727.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080100119424&amp;v=MjM2MjVUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJS0Z3VmFoUT1OaWZPZmJLN0h0bk1ybzlGWmVvR0NINDlvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> LIAO K, LIU G, HUI Y.An improvement to the SIFT descriptor for image representation and matching[J].Pattern Recognition Letters, 2013, 34 (11) :1211-1220.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recognizing live fish species by hierarchical partial classification based on the exponential benefit">

                                <b>[3]</b> CHUANG M C, HWANG J N, KUO F F, et al.Recognizing live fish species by hierarchical partial classification based on the exponential benefit[C]// Proceedings of the 2014 IEEE International Conference on Image Processing.Piscataway, NJ:IEEE, 2014:5232-5236.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2014S1026&amp;v=MjY0OTZxQnRHRnJDVVI3cWZadVpzRnlEblVyL09MejdCYjdHNEg5V3ZybzlIWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 黄仁, 胡敏.综合颜色空间特征和纹理特征的图像检索[J].计算机科学, 2014, 41 (s1) :118-121. (HUANG R, HU M.Content-based image retrieval using color position and texture fused features[J].Computer Science, 2014, 41 (s1) :118-121.) 
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201703002&amp;v=MzAwMDk5Yk1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09QVG5TZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 胡二雷, 冯瑞.基于深度学习的图像检索系统[J].计算机系统应用, 2017, 26 (3) :8-19. (HU E L, FENG R.Image retrieval system based on deep learning[J].Computer Systems &amp; Applications, 2017, 26 (3) :8-19.) 
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning based image super-resolution with coupled backpropagation">

                                <b>[6]</b> GUO T, MOUSAVI H S, MONGA V.Deep learning based image super-resolution with coupled backpropagation[C]// Proceedings of the 2016 IEEE Global Conference on Signal and Information Processing.Piscataway, NJ:IEEE, 2017:237-241.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201809037&amp;v=MDg0ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09QVFhjZHJHNEg5bk1wbzlHWTRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 张美玲, 吴俊峰, 于红, 等.一种基于HSVG-SURF特征的鱼类图像检索算法[J].小型微型计算机系统, 2018, 39 (9) :2085-2089. (ZHANG M L, WU J F, YU H, et al.Fish image retrieval algorithm based on HSVG four channel SURF feature[J].Journal of Chinese Computer Systems, 2018, 39 (9) :2085-2089.) 
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel fish image retrieval method based on saliency spatial pyramid">

                                <b>[8]</b> ZHANG M L, WU J F, Y H, et al.A novel fish image retrieval method based on saliency spatial pyramid[C]// Proceedings of the 2017 14th International Symposium on Pervasive Systems, Algorithms and Networks &amp; 2017 International Conference on Frontier of Computer Science and Technology &amp; 2017 3rd International Symposium of Creative Computing.Washington, DC:IEEE Computer Society, 2017:312-317.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201407030&amp;v=MTM0NzMzenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09MejdNYWJHNEg5WE1xSTlHWklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 程少光, 何毕, 布树辉, 等.基于超像素空间金字塔模型的场景识别研究[J].计算机工程与应用, 2014, 50 (7) :139-143. (CHENG S G, HE B, BU S H, et al.Sence recognition research based on SSPM[J].Computer Engineering and Applications, 2014, 50 (7) :139-143.) 
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201109014&amp;v=MTI1ODZxZlp1WnNGeURuVXIvT0lUZlRlN0c0SDlETXBvOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 高常鑫, 桑农.整合局部特征和滤波器特征的空间金字塔匹配模型[J].电子学报, 2011, 39 (9) :2034-2038. (GAO C X, SANG N.Unifying local features and filterbank features in the spatial pyramid matching model[J].Acta Electronica Sinica, 2011, 39 (9) :2034-2038.) 
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Theory of incomplete models of dynamic structures">

                                <b>[11]</b> YANG J, YU K, GONG Y, et al.Linear spatial pyramid matching using sparse coding for image classification[C]// Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2009:1794-1801.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201607014&amp;v=MjQ2NzVFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEblVyL09JVGZJWXJHNEg5Zk1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 陈鑫元, 李筠, 杨海马, 等.自适应阈值图像二值化及形态学处理的FPGA实现[J].电子测量技术, 2016, 39 (7) :67-71. (CHEN X Y, LI Y, YANG H M, et al.Adaptive threshold binarization and morphological image processing based on FPGA[J].Electronic Measurement Technology, 2016, 39 (7) :67-71.) 
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXJS201001041&amp;v=MTgwMzE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURuVXIvT01UWEJmYkc0SDlITXJvOUJaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> WU L S, CHEN J X, WEI L I.Niblack-based binaryzation algorithm for palm vein image[J].Communications Technology, 2010, 43 (1) :112-114.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Surf Speeded up robust features">

                                <b>[14]</b> BAY H, TUYTELAARS T, GOOL L V.SURF:Speeded Up Robust Features[C]// Proceedings of the 9th European Conference on Computer Vision.Berlin:Springer, 2006:404-417.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Noise Level Estimation by Principal Component Analysis">

                                <b>[15]</b> PYATYKH S, HESSER J, ZHENG L.Image noise level estimation by principal component analysis[J].IEEE Transactions on Image Processing, 2013, 22 (2) :687-699.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501202379&amp;v=MjExMzgzSUtGd1ZhaFE9TmlmT2ZiSzdIdEROcW85RVp1c05EM3N3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> SALIMI-KHORSHIDI G, SMITH S M, KELTNER J R, et al.Meta-analysis of neuroimaging data:a comparison of image-based and coordinate-based pooling of studies[J].Neuroimage, 2009, 45 (3) :10-23.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A MATLAB-based framework for image and video quality evaluation">

                                <b>[17]</b> MURTHY A V, KARAM L J.A MATLAB-based framework for image and video quality evaluation[C]// Proceedings of the 2010 2nd International Workshop on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2010:242-247.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Content based image retrieval using color and texture">

                                <b>[18]</b> SINGHA M, HEMACHANDRAN K.Content based image retrieval using color and texture[J].Signal &amp; Image Processing, 2012, 3 (1) :271-273.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201905039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201905039&amp;v=MTAxODhadVpzRnlEblVyL09MejdCZDdHNEg5ak1xbzlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
