<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779379190000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904034%26RESULT%3d1%26SIGN%3dTQvh%252bMxFMIPFL8fqjWyC7IFfq5E%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904034&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904034&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904034&amp;v=MTQ4NjdmWnVac0Z5RGhVTC9LTHo3QmQ3RzRIOWpNcTQ5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#29" data-title="1 相关滤波跟踪算法 ">1 相关滤波跟踪算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#31" data-title="1.1 &lt;b&gt;岭回归模型建立&lt;/b&gt;">1.1 <b>岭回归模型建立</b></a></li>
                                                <li><a href="#44" data-title="1.2 &lt;b&gt;快速检测运算&lt;/b&gt;">1.2 <b>快速检测运算</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="2 快速尺度自适应目标跟踪算法 ">2 快速尺度自适应目标跟踪算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="2.1 &lt;b&gt;全局特征图&lt;/b&gt;">2.1 <b>全局特征图</b></a></li>
                                                <li><a href="#54" data-title="2.2 &lt;b&gt;快速自适应尺度&lt;/b&gt;">2.2 <b>快速自适应尺度</b></a></li>
                                                <li><a href="#68" data-title="2.3 &lt;b&gt;自适应更新策略&lt;/b&gt;">2.3 <b>自适应更新策略</b></a></li>
                                                <li><a href="#78" data-title="2.4 &lt;b&gt;算法流程&lt;/b&gt;">2.4 <b>算法流程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#89" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="3.1 &lt;b&gt;实验参数与评价标准&lt;/b&gt;">3.1 <b>实验参数与评价标准</b></a></li>
                                                <li><a href="#93" data-title="3.2 &lt;b&gt;实验结果分析&lt;/b&gt;">3.2 <b>实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="图1 特征融合流程">图1 特征融合流程</a></li>
                                                <li><a href="#63" data-title="图2 尺度分离选择窗口">图2 尺度分离选择窗口</a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;分离窗口分离规则&lt;/b&gt;"><b>表</b>1 <b>分离窗口分离规则</b></a></li>
                                                <li><a href="#88" data-title="图3 本文算法流程">图3 本文算法流程</a></li>
                                                <li><a href="#96" data-title="图4 精度和成功率曲线">图4 精度和成功率曲线</a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;i&gt;FSACF&lt;/i&gt;&lt;b&gt;和&lt;/b&gt;&lt;i&gt;SACF&lt;/i&gt;&lt;b&gt;的&lt;/b&gt;&lt;i&gt;FPS&lt;/i&gt;&lt;b&gt;对比&lt;/b&gt;&lt;i&gt;frame&lt;/i&gt;/&lt;i&gt;s&lt;/i&gt;"><b>表</b>2 <i>FSACF</i><b>和</b><i>SACF</i><b>的</b><i>FPS</i><b>对比</b><i>frame</i>/<i>s</i></a></li>
                                                <li><a href="#100" data-title="图5 不同&lt;i&gt;μ&lt;/i&gt;取值的成功率曲线">图5 不同<i>μ</i>取值的成功率曲线</a></li>
                                                <li><a href="#102" data-title="图6 不同算法的跟踪结果对比">图6 不同算法的跟踪结果对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="117">


                                    <a id="bibliography_1" title=" ZHENG Y, LI S E, WANG J, et al. Stability and scalability of homogeneous vehicular platoon:study on the influence of information flow topologies[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 17 (1) :14-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stability and Scalability of Homogeneous Vehicular Platoon:Study on the Influence of Information Flow Topologies">
                                        <b>[1]</b>
                                         ZHENG Y, LI S E, WANG J, et al. Stability and scalability of homogeneous vehicular platoon:study on the influence of information flow topologies[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 17 (1) :14-26.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_2" title="勾承甫, 陈斌, 赵雪专, 等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用, 2017, 36 (9) :2566-2569. (GOU C F, CHEN B, ZHAO X Z, et al. Object tracking algorithm based on random sampling consensus estimation[J]. Journal of Computer Applications, 2017, 36 (9) :2566-2569.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201609040&amp;v=MDQ0NjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVML0tMejdCZDdHNEg5Zk1wbzlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        勾承甫, 陈斌, 赵雪专, 等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用, 2017, 36 (9) :2566-2569. (GOU C F, CHEN B, ZHAO X Z, et al. Object tracking algorithm based on random sampling consensus estimation[J]. Journal of Computer Applications, 2017, 36 (9) :2566-2569.) 
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_3" title=" BOLME D S, BEVERIDGE J R, DRAPER B A, et al. Visual object tracking using adaptive correlation filters[C]//CVPR 2010:Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2010:2544-2550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">
                                        <b>[3]</b>
                                         BOLME D S, BEVERIDGE J R, DRAPER B A, et al. Visual object tracking using adaptive correlation filters[C]//CVPR 2010:Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2010:2544-2550.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_4" title=" HENRIQUES J F, RUI C, MARTINS P, et al. Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 12th European Conference on Computer Vision, LNCS 7575. Berlin:Springer, 2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">
                                        <b>[4]</b>
                                         HENRIQUES J F, RUI C, MARTINS P, et al. Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 12th European Conference on Computer Vision, LNCS 7575. Berlin:Springer, 2012:702-715.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     HENRIQUES J F, CASEIRO R, MARTINS P, et al. High-speed tracking with kernelized correlation filters[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.</a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_6" title=" LI Y, ZHU J. A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision, LNCS 8926. Berlin:Springer, 2014:254-265." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">
                                        <b>[6]</b>
                                         LI Y, ZHU J. A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision, LNCS 8926. Berlin:Springer, 2014:254-265.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     KALAL Z, MATAS J. Tracking learning detection[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (7) :1409-1422.</a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_8" title=" FELZENSZWALB P, GIRSHICK R, MCALLESTER D, et al. Object detection with discriminatively trained part-based models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) :1627-1645." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Detection with Discriminatively Trained Part-Based Models">
                                        <b>[8]</b>
                                         FELZENSZWALB P, GIRSHICK R, MCALLESTER D, et al. Object detection with discriminatively trained part-based models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) :1627-1645.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_9" title=" DANELLJAN M, KHAN F S, FELSBERG M, et al. Adaptive color attributes for real-time visual tracking[C]//CVPR 2014:Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2014:1090-1097." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Color Attributes for Real-Time Visual Tracking">
                                        <b>[9]</b>
                                         DANELLJAN M, KHAN F S, FELSBERG M, et al. Adaptive color attributes for real-time visual tracking[C]//CVPR 2014:Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2014:1090-1097.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     WUY, LIM J, YANG M H. Object tracking benchmark[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.</a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_11" title=" HARE S, GOLODETZ S, SAFFARI A. Struck:structured output tracking with kernels[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (10) :2096-2109." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Struck:Structured output tracking with kernels">
                                        <b>[11]</b>
                                         HARE S, GOLODETZ S, SAFFARI A. Struck:structured output tracking with kernels[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (10) :2096-2109.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-17 16:47</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1145-1149 DOI:10.11772/j.issn.1001-9081.2018081821            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>分离窗口快速尺度自适应目标跟踪算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E6%98%A5%E5%BE%B7&amp;code=10625479&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨春德</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E4%BA%AC&amp;code=26337650&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘京</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%9E%BF%E4%B8%AD&amp;code=10878789&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">瞿中</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0174747&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆邮电大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对核相关滤波器 (KCF) 跟踪算法在面对尺度变化时产生的目标漂移问题, 提出一种分离窗口快速尺度自适应目标跟踪算法——FSACF。首先, 通过直接对原始帧图像进行特征提取得到基于显著性颜色特征的全局梯度组合特征图, 以减小后续的尺度计算对性能的影响;其次, 对全局特征图采用分离窗口法, 自适应地选取尺度大小并计算对应的最大响应值;最后, 采用定义的置信度函数自适应地更新迭代模板函数, 提高模型的鲁棒性。通过带有不同干扰属性的视频集上进行实验, 发现FSACF算法与KCF算法相比, 在精度上提升7.4个百分点, 成功率提高12.8个百分点;与未采用全局特征和分离窗口的算法对比, 处理速度上提升1.5倍。实验结果表明, FSACF算法在尺度变化发生时能有效避免目标漂移的产生, 同时具有一定的效率, 并在精度与成功率上均优于对比算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%B8%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">核相关滤波器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%BA%E5%BA%A6%E8%87%AA%E9%80%82%E5%BA%94&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尺度自适应;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">全局特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BD%AE%E4%BF%A1%E5%BA%A6%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">置信度函数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨春德 (1964—) , 男, 重庆人, 教授, 硕士, 主要研究方向:数字图像处理、信息与计算理论;;
                                </span>
                                <span>
                                    *刘京 (1991—) , 男, 湖北黄石人, 硕士研究生, 主要研究方向:数字图像处理;电子邮箱jfliu1027@163.com;
                                </span>
                                <span>
                                    瞿中 (1972—) , 男, 重庆人, 教授, 博士, CCF会员, 主要研究方向:数字图像处理、普适计算、物联网。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>重庆市科委基础科学与前沿技术研究重点项目 (cstc2015jcyjBX0090);</span>
                    </p>
            </div>
                    <h1><b>Fast scale adaptive object tracking algorithm with separating window</b></h1>
                    <h2>
                    <span>YANG Chunde</span>
                    <span>LIU Jing</span>
                    <span>QU Zhong</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Chongqing University of Posts and Telecommunications</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to solve the problem of object drift caused by Kernelized Correlation Filter (KCF) tracking algorithm when scale changes, a Fast Scale Adaptive tracking of Correlation Filter (FSACF) was proposed. Firstly, a global gradient combination feature map based on salient color features was obtained by directly extracting features for the original frame image, reducing the effect of subsequent scale calculation on the performance. Secondly, the method of separating window was performed on the global feature map, adaptively selecting the scale and calculating the corresponding maximum response value. Finally, a defined confidence function was used to adaptively update the iterative template function, improving robustness of the model. Experimental result on video sets with different interference attributes show that compared with KCF algorithm, the accuracy of the FSACF algorithm by was improved 7.4 percentage points, and the success rate was increased by 12.8 percentage points; compared with the algorithm without global feature and separating window, the Frames Per Second was improved by 1.5 times. The experimental results show that the FSACF algorithm avoids the object drift when facing scale change with certain efficiency, and is superior to the comparison algorithms in accuracy and success rate.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kernelized%20Correlation%20Filter%20(KCF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kernelized Correlation Filter (KCF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=scale%20adaptive&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">scale adaptive;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=global%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">global feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=confidence%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">confidence function;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YANG Chunde, born in 1964, M. S. , professor. His research interests include digital image processing, information and calculation theory.;
                                </span>
                                <span>
                                    LIU Jing, born in 1991, M. S. candidate. His research interests include digital image processing.;
                                </span>
                                <span>
                                    QU Zhong, born in 1972, Ph. D. , professor. His research interests include digital image processing, pervasive computing, Internet of things.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-04</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Key Program for Basic Science and Frontier Technology Research of Chongqing Science and Technology Committee (cstc2015jcyjB X0090);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="26">目标跟踪是计算机视觉中最基本的问题之一, 在视频监控<citation id="139" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、行为分析等方面有着广泛的应用。尽管目标跟踪已经取得了较大的进展, 但仍受众多因素的影响, 如尺度变化、遮挡<citation id="140" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>等, 所以目标跟踪仍是一个具有挑战性的课题。</p>
                </div>
                <div class="p1">
                    <p id="27">Bolme等<citation id="141" type="reference"><link href="121" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出的最小平方误差输出和 (Minimum Output Sum of Squared Error, MOSSE) 算法, 将相关滤波引入跟踪领域, 使跟踪速度得到提高。而后Henriques等<citation id="142" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>基于MOSSE的框架加入密集采样的思想提出核循环结构跟踪 (Circulant Structure with Kernel, CSK) 算法, 利用循环矩阵的性质加速了求解过程。随后, Henriques等<citation id="143" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>又对CSK算法加入多通道特征的方法并推导出非线性解, 提出非线性核相关滤波器 (Kernelized Correlation Filter, KCF) 使多特征融合成为可能。Li等<citation id="144" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>针对KCF算法无法处理尺度变化的问题, 提出尺度与位移同时计算最优的多特征尺度自适应 (Scale Adaptive Multiple Feature, SAMF) 跟踪算法, 解决由于尺度变化而导致的目标信息丢失问题, 但无法满足实时性需求, 且在面对遮挡时易产生模型污染。Kalal等<citation id="145" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出学习检测跟踪 (Tracking-Learning-Detection, TLD) 算法, 将跟踪和检测相结合, 引入在线学习机制, 鲁棒性强, 具有很强的学习恢复能力, 但在面对光照变化等因素影响时易产生目标漂移, 并且效率不高。</p>
                </div>
                <div class="p1">
                    <p id="28">本文针对KCF算法在尺度变化时易产生漂移的问题, 提出一种分离窗口尺度自适应跟踪算法——FSACF (Fast Scale Adaptive tracking of Correlation Filter) 。首先对每帧原始图像进行全局特征提取, 基于显著性颜色特征和灰度特征提取对应的梯度特征;然后采用提出的尺度自适应算法在全局特征图上进行计算, 以分离窗口的方式选择合适的尺度进行响应值计算并得到模板函数;最后修改了更新策略, 提出一组置信度函数的定义, 采用置信度函数对模板函数学习率进行自适应的调整更新, 使得模型更加稳定。</p>
                </div>
                <h3 id="29" name="29" class="anchor-tag">1 相关滤波跟踪算法</h3>
                <div class="p1">
                    <p id="30">相关滤波器跟踪算法的主要框架包括:首先滤波器采用岭回归模型对第一帧选定的目标进行训练;然后将模型与下一帧的图像进行快速检测, 通过相关运算得到响应矩阵来确定当前帧图像中目标的中心位置;最后以新的位置信息对图像的目标重采样进行模型更新迭代, 重复以上过程实现跟踪。</p>
                </div>
                <h4 class="anchor-tag" id="31" name="31">1.1 <b>岭回归模型建立</b></h4>
                <div class="p1">
                    <p id="32">假定训练集的图像样本表示为<b><i>z</i></b> (<i>m</i><sub><i>i</i></sub>, <i>n</i><sub><i>i</i></sub>) , 则训练的目标就是找到一个函数<i>f</i> (<b><i>z</i></b>) =<b><i>p</i></b><sup>T</sup><b><i>z</i></b>, 使得误差函数<mathml id="33"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">p</mi></munder><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">) </mo><mo>-</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mrow><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>最小。其中:<b><i>Y</i></b>为回归目标;<i>λ</i>为正则化参数, 防止过拟合。</p>
                </div>
                <div class="p1">
                    <p id="34">为了让检测器有更好的表现, Henriques等<citation id="146" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>利用循环矩阵的性质, 将得到的一组封闭解形式<b><i>p</i></b>= (<b><i>X</i></b><sup>T</sup><b><i>X</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>X</i></b><sup>T</sup><b><i>y</i></b> 转换为<mathml id="35"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Ρ</mi><mo>¯</mo></mover><mo>=</mo><mfrac><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover></mrow><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mo>*</mo></msup><mo>+</mo><mi>λ</mi></mrow></mfrac></mrow></math></mathml>, 其中<mathml id="36"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover></math></mathml>表示<b><i>x</i></b>的傅里叶变化, ⊙表示元素相乘, 分号代表对应元素相除。而在非线性的一般情况下引入核函数, 可以将目标函数表示为:</p>
                </div>
                <div class="p1">
                    <p id="37" class="code-formula">
                        <mathml id="37"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">α</mi></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mi mathvariant="bold-italic">κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="38">其中:<i>α</i>是对偶空间中的参数, <i>κ</i> (<b><i>z</i></b>, <b><i>x</i></b><sub><i>i</i></sub>) 表示核函数。这样就将矩阵的乘法运算转换到在希尔伯特空间的点乘运算。</p>
                </div>
                <div class="p1">
                    <p id="39">对于岭回归解的核化形式<i>α</i>= (<b><i>K</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>y</i></b>, 进行傅里叶变化可以有如式 (2) 解的形式:</p>
                </div>
                <div class="p1">
                    <p id="40" class="code-formula">
                        <mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">α</mi><mo>¯</mo></mover><mo>=</mo><mfrac><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">x</mi></mrow></msup><mo>+</mo><mi>λ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="41">其中:<mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover></math></mathml><sup><b><i>zx</i></b></sup>表示在傅里叶域中<b><i>z</i></b>自身的核相关性, <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover></math></mathml>是标准正太分布的傅里叶变换。这样对<b><i>p</i></b>的求解就转变到对偶空间中对<i>α</i>的求解。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">1.2 <b>快速检测运算</b></h4>
                <div class="p1">
                    <p id="45">循环矩阵的性质同样被用到了检测过程中。对下一帧历史位置提取的图像块<b><i>z</i></b>进行循环采样, 可以由式 (3) 得到频域中的响应函数:</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>F</mi><mo>¯</mo></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">x</mi></mrow></msup><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">α</mi><mo>¯</mo></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47">得到响应值矩阵后进行傅里叶逆变换即可得到时域中响应值矩阵, 其最大值的位置就是对应目标的中心位置。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">2 快速尺度自适应目标跟踪算法</h3>
                <div class="p1">
                    <p id="49">在目标确定后, 本文算法 (<i>FSACF</i>) 对目标原始图提取显著颜色梯度全局特征图, 以避免多次重复提取特征, 并提出一种特征组合方式;然后在全局特征图上采用分离窗口快速尺度估计算法得到响应矩阵, 进一步加速尺度信息确定的计算;最后针对响应矩阵的数值进行分析, 并代入到提出的置信度函数中, 实现对模板函数自适应更新。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">2.1 <b>全局特征图</b></h4>
                <div class="p1">
                    <p id="51">在相关方法中, 傅里叶变换的计算次数与特征维数呈线性关系, 为提高计算的速度, 本文提出在原始图的基础上只进行一次特征提取得到全局特征图, 避免多次提取的重复操作。适当的特征组合也可以显著地提高检测性能, 而梯度和颜色特征的联合已被证实有着很强的互补性, 但如何进行合适的组合仍是一个有待解决的问题。</p>
                </div>
                <div class="p1">
                    <p id="52">常规的方向梯度直方图 (<i>Histogram of Oriented Gradients</i>, <i>HOG</i>) 特征<citation id="147" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和颜色名称 (<i>Color Name</i>, <i>CN</i>) 特征<citation id="148" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>的融合是直接相连的, 而在不同的颜色空间中, 目标的梯度特征是不同的, 因此从每个颜色空间中提取梯度特征是一种更好的策略。为了平衡性能, 本文提出一种基于显著性颜色特征提取梯度特征的方法, 其过程如下:首先将<i>RGB</i>图像转换为11维颜色空间, 接着对其降维, 提取显著性颜色特征图;然后在显著性颜色特征图的每一个通道和灰度特征图上提取<i>HOG</i>特征;最后将得到的梯度特征降维, 连接成一个共54通道的三维矩阵为全局特征图, 如图1所示, 后续尺度估计算法直接在全局特征图上提取对应的目标进行计算。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 特征融合流程" src="Detail/GetImg?filename=images/JSJY201904034_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 特征融合流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Flow chart of feature fusion</i></p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">2.2 <b>快速自适应尺度</b></h4>
                <div class="p1">
                    <p id="55">假定初始尺度模板大小为<i>s</i><sub><i>H</i></sub>= (<i>s</i><sub><b><i>x</i></b></sub>, <i>s</i><sub><b><i>y</i></b></sub>) , 定义一个尺度池<i>S</i>={<i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>, …, <i>h</i><sub><i>mid</i></sub>, …, <i>h</i><sub><i>t</i></sub>}, 其中<i>t</i>为尺度规模, 中间值<i>h</i><sub><i>mid</i></sub>=1。对当前帧的全局特征图采样后得到以{<i>h</i><sub><i>i</i></sub><i>s</i><sub><i>H</i></sub>|<i>h</i><sub><i>i</i></sub>∈<i>S</i>}为大小的<i>t</i>个不同尺度的候选目标样本, 采用分离窗口法选定其中<i>m</i>个, 采用双线性插值缩放至<i>s</i><sub><i>H</i></sub>的大小, 再输入检测器<i>f</i> (<b><i>z</i></b>) 进行响应值计算, 其计算公式如式 (4) 所示:</p>
                </div>
                <div class="p1">
                    <p id="56">arg max <i>F</i><sup>-1</sup><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>F</mi><mo>¯</mo></mover></math></mathml> (<b><i>z</i></b><sup><i>m</i></sup>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="58">其中:<b><i>z</i></b><sup><i>m</i></sup>是选定的<i>m</i>个尺度得到的矩阵, <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>F</mi><mo>¯</mo></mover></math></mathml> (<b><i>z</i></b>) 为式 (3) 得到的值。</p>
                </div>
                <div class="p1">
                    <p id="60">由于视频序列的尺度变化具有连续性, 因此本文提出分离窗口选择法, 对尺度池进行合理性选择计算。尺度池规模为<i>t</i>, 窗口为<i>W</i>={<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>mid</i></sub>, …, <i>w</i><sub><i>m</i></sub>} (<i>m</i>&lt;<i>t</i>) , 其中 <i>w</i><sub><i>mid</i></sub>为中间值且默认初始化<i>w</i><sub><i>mid</i></sub>指向<i>h</i><sub><i>mid</i></sub>的位置, 前后同比例间隔, 以<i>w</i><sub><i>mid</i></sub>为间隔将窗口上下分离为三个部分:缩小、保持、放大。如图2所示:图2 (a) 为初始化状态, 图2 (b) ～ (d) 为后续视频序列根据分离规则分离后得到的对应窗口位置, 其中黑点处为当前最大响应值的位置。当图2 (a) 中最大响应处于上半部分时, 图2 (b) 中<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub>窗口上移;当图2 (b) 中最大响应处于上半部分时, 图2 (c) 中<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub>窗口上移;当图2 (c) 中最大响应处于下半部分时, 图2 (d) 中<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub>窗口重新初始化, <i>w</i><sub><i>mid</i>-1</sub>～<i>w</i><sub><i>m</i></sub>窗口下移。</p>
                </div>
                <div class="p1">
                    <p id="61">分离规则如表1所示。表1中:<i>cur</i>表示当前帧最大响应所在的窗口位置;move-1和move+1分别表示对应窗口上移/下移一个单位;stay表示维持当前位置;initialise表示重新初始化到原始位置。</p>
                </div>
                <div class="p1">
                    <p id="62">采用分离窗口法可以根据上一帧得到的尺度信息, 快速寻找到最适合下一帧目标特征图<b><i>feature</i>_<i>map</i></b>的最可能的<i>m</i>个尺度信息。如图2 (b) 所示, 当上一帧<i>cur</i>指向<i>h</i><sub><i>mid</i>-1</sub>时, 下一帧继续缩小或保持的概率更大, 所以缩小窗口上移偏向选择缩放比例更小的尺度;而由实验分析可得, 视频中尺度是渐变的, 若此时放大部分的上一尺度不是保持部分则将放大部分初始化至原始位置, 保证目标的下一帧目标若为放大时有更适合的尺度与之匹配。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 尺度分离选择窗口" src="Detail/GetImg?filename=images/JSJY201904034_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 尺度分离选择窗口  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Selection window of scale separation</p>

                </div>
                <div class="area_img" id="64">
                    <p class="img_tit"><b>表</b>1 <b>分离窗口分离规则</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Separation rule of separating window</p>
                    <p class="img_note"></p>
                    <table id="64" border="1"><tr><td><br />条件</td><td>规则</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub><br />&amp; <i>w</i><sub><i>mid</i>+1</sub>=<i>w</i><sub><i>mid</i></sub>+1</td><td><i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub> move-1<br />如图2 (b) ～ (c) 状态所示</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub><br />&amp; <i>w</i><sub><i>mid</i>-1</sub>=<i>w</i><sub><i>mid</i></sub>-1</td><td><i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub> move+1</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub><br />&amp; <i>w</i><sub><i>mid</i>+1</sub>≠<i>w</i><sub><i>mid</i></sub>+1</td><td><i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub> move-1 <br /><i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub> initialise</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub><br />&amp; <i>w</i><sub><i>mid</i>-1</sub>≠<i>w</i><sub><i>mid</i></sub>-1</td><td><i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub> move+1 <br /><i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub> initialise<br />如图2 (d) 状态所示</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub><br />&amp; <i>w</i><sub>1</sub>=<i>h</i><sub>1</sub></td><td><i>w</i><sub>1</sub>～<i>w</i><sub><i>mid</i>-1</sub> stay</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub><br />&amp; <i>w</i><sub><i>m</i></sub>=<i>h</i><sub><i>t</i></sub></td><td><i>w</i><sub><i>mid</i>+1</sub>～<i>w</i><sub><i>m</i></sub> stay</td></tr><tr><td><br /><i>cur</i>∈<i>w</i><sub><i>mid</i></sub></td><td><i>w</i><sub>1</sub>～<i>w</i><sub><i>m</i></sub> initialise<br />如图2 (a) 状态所示</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="65">按对应的尺度<i>h</i><sub><i>i</i></sub><i>s</i><sub><i>H</i></sub>为大小在<b><i>feature</i>_<i>map</i></b>上截取对应尺度特征图, 将得到包含不同比例的正负样本信息的特征图, 采用双线性插值法还原到初始尺度, 然后将其映射到核空间, 代入到式 (5) , 则可以得到目标第<i>t</i>与<i>t</i>-1帧对应的高斯核函数;代入到式 (3) , 则可得到最大响应值, 即可确认位置信息和尺度信息。</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">κ</mi><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup></mrow></msup><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mo>-</mo><mspace width="0.25em" /><mfrac><mn>1</mn><mrow><mi>δ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">∥</mo><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mn>2</mn><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mspace width="0.25em" /></mstyle><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>^</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo>⊙</mo><msup><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>^</mo></mover><mo>′</mo></msup><msubsup><mrow></mrow><mi>m</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中:<b><i>F</i></b><sup>-1</sup>表示傅里叶逆变换;<b><i>x</i></b>和<b><i>x</i></b>′分别表示当前帧的特征和历史所有帧的特征。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">2.3 <b>自适应更新策略</b></h4>
                <div class="p1">
                    <p id="69">由于视频序列的连续性, 帧间的目标信息重复性大, 大多数跟踪算法采用的是持续地对模板函数式 (2) 进行恒定更新迭代, 导致跟踪过程中不可避免的存在模型污染、目标漂移等问题。</p>
                </div>
                <div class="p1">
                    <p id="70">经研究发现持续地对模板函数进行更新, 在遮挡等情况发生的情况下, 不适合的更新容易导致模型污染。针对这个问题, 本文提出了一个置信度函数<i>Φ</i> (·) , 如式 (6) 所示:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><mspace width="0.25em" /><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>α</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><msup><mrow></mrow><mn>3</mn></msup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>α</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>≤</mo><mi>μ</mi></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>μ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>4</mn></mrow></msup><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>α</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mspace width="0.25em" /><mo>&gt;</mo><mspace width="0.25em" /><mi>μ</mi></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">其中:<i>α</i><sub>max</sub>是式 (2) 求得的所有尺度信息的响应最大值; <i>μ</i>是用来控制自适应更新学习率的门限。</p>
                </div>
                <div class="p1">
                    <p id="73">若发生遮挡, 为避免采集到过多的错误信息污染模型, 自适应地调整学习率。当响应值小于门限<i>μ</i>时, 采用<i>α</i><sub>max</sub><sup>3</sup>函数降低学习率, 降低错误采样对模型造成的影响;当响应值大于门限<i>μ</i>时, 采用 (<i>α</i><sub>max</sub>-<i>μ</i>) <sup>1/4</sup>函数, 适当地提高更新学习率, 维护模型的稳定性。</p>
                </div>
                <div class="p1">
                    <p id="74">设∂<sub>new</sub>和∂<sub>pre</sub>分别表示当前帧和前一帧的模板信息, <i>ξ</i>表示模板函数的学习率, <b><i>x</i></b><sub>new</sub>和<b><i>x</i></b><sub>pre</sub>分别表示当前帧和前一帧的目标信息, <i>η</i>表示目标特征的学习率, <i>h</i><sub><i>c</i></sub>表示当前帧的尺度信息。根据提出的置信度函数对模板更新函数进行改进, 可以得到学习率自适应更新函数如式 (7) 所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo>∂</mo><mo>=</mo><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo stretchy="false">) </mo><mi>ξ</mi><mo>∂</mo><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo stretchy="false">) </mo><mi>ξ</mi><mo stretchy="false">) </mo><mo>∂</mo><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msub></mtd></mtr><mtr><mtd><mo>∂</mo><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mfrac><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">x</mi></mrow></msup><mo>+</mo><mi>λ</mi></mrow></mfrac><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup><mo>=</mo><mi>η</mi><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msub></mtd></mtr><mtr><mtd><mi>s</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>=</mo><mi>h</mi><msub><mrow></mrow><mi>c</mi></msub><mi>s</mi><msub><mrow></mrow><mi>Η</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">对<b><i>x</i></b>′目标信息保持持续更新的策略。对于模板函数∂加入自适应学习率, 即控制模板函数在可能发生模型污染的情况下, 对模板函数以自适应学习率进行选择性更新, 避免模型污染。对于尺度模板<i>s</i><sub><i>H</i></sub>逐帧进行更新, 以<i>t</i>-1帧时的尺度信息作为第<i>t</i>帧的尺度模板。</p>
                </div>
                <div class="p1">
                    <p id="77">由于∂<sub>pre</sub>为前一帧的模板信息, 所以更新策略从第二帧开始计算。式 (7) 中第一个公式中的∂<sub>new</sub>和∂<sub>pre</sub>为输入。可将其变形为 (∂-∂<sub>pre</sub>) =<i>Φ</i> (<i>α</i><sub>new</sub>) <i>ξ</i> (∂<sub>new</sub>-∂<sub>pre</sub>) 的形式, 因为学习率<i>ξ</i>是一个很小的值 (实验所得) , 而<i>Φ</i> (<i>α</i><sub>max</sub>) 中自变量响应值的取值范围在 (0, 1) , 所以<i>Φ</i> (<i>α</i><sub>max</sub>) 的取值范围在 (0, 1) 。又因为视频帧的连续性, 目标两帧之间的差异很小, 可得∂≈∂<sub>first</sub>, 即∂的取值将收敛于第一帧的模板信息∂<sub>first</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.4 <b>算法流程</b></h4>
                <div class="p1">
                    <p id="79">FSACF算法的具体流程为:首先输入第<i>t</i>-1帧的目标中心位置和目标尺度信息, 训练检测器, 根据第<i>t</i>-1帧中的目标中心位置, 提取当前第<i>t</i>帧的全局特征图;然后在全局特征图上执行快速自适应尺度估计算法进行尺度选择, 将选中的尺度池<i>S</i>中对应的尺度在特征图中提取出目标, 代入到响应值函数进行计算;最后在得到的<i>m</i>组响应矩阵中取最大值进行对比, 找到全局最大值的位置, 即可确定第<i>t</i>帧的目标中心位置和尺度信息, 信息确认后执行自适应更新策略对模板函数和目标信息进行更新。本文算法流程如图3所示。</p>
                </div>
                <div class="p1">
                    <p id="80">具体算法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="81">输入 第<i>t</i>-1帧目标中心位置和目标尺度信息。</p>
                </div>
                <div class="p1">
                    <p id="82">输出 第<i>t</i>帧目标的目标中心位置和目标尺度信息。</p>
                </div>
                <div class="p1">
                    <p id="83">步骤1 提取第<i>t</i>帧的基于显著性颜色特征的梯度特征得到全局特征图。</p>
                </div>
                <div class="p1">
                    <p id="84">步骤2 采用分离窗口确定的尺度信息和第<i>t</i>-1帧的中心位置信息, 对全局特征图使用式 (5) 进行目标特征图提取, 并通过核函数式 (6) 进行融合得到样本<b><i>k</i></b><sup><b><i>xx</i></b>′</sup>。</p>
                </div>
                <div class="p1">
                    <p id="85">步骤3 将<b><i>k</i></b><sup><b><i>xx</i></b>′</sup>依次与模板函数<i>α</i>进行相关运算式 (3) 得到对应响应图, 选择拥有最大响应值的响应图, 即可确认第<i>t</i>帧中目标的中心位置与目标尺度信息。</p>
                </div>
                <div class="p1">
                    <p id="86">步骤4 对第<i>t</i>帧中的更新模板系数∂、基样本<b><i>x</i></b>和尺度模板<i>s</i><sub><i>H</i></sub>采用式 (7) 进行更新。</p>
                </div>
                <div class="p1">
                    <p id="87">重复迭代以上步骤, 以实现跟踪。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文算法流程" src="Detail/GetImg?filename=images/JSJY201904034_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Flow chart of the proposed algorithm</p>

                </div>
                <h3 id="89" name="89" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="90" name="90">3.1 <b>实验参数与评价标准</b></h4>
                <div class="p1">
                    <p id="91">实验平台为<i>Windows</i> 10操作系统, 处理器<i>Core i</i>5-6200<i>U</i>, 8 <i>GB</i>内存, 运行平台为<i>Matlab</i>。实验测试视频数据为<i>OTB</i>-50<citation id="149" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 选取其中40组视频, 涉及到灰度图像和彩色图像, 同时包含尺度变化、遮挡等11个属性, 每个视频序列包含多个属性。为方便与<i>KCF</i>算法进行对比, 实验中参数与<i>KCF</i>算法保持一致。本文为保证精度窗口规模<i>m</i>=5;尺度池<i>S</i>规模<i>t</i>=9, 间隔为0.015;学习率<i>ξ</i>=0.01;超参数门限<i>μ</i>=0.25为实验经验值。选取了CSK、SAMF等5种算法和本文算法的结果进行定性定量的分析。</p>
                </div>
                <div class="p1">
                    <p id="92">所有的实验均采用四个评价指标:1) 精度曲线。精度曲线表示某一距离阈值的正确跟踪帧的百分比, 如果预测的目标中心在距离标准值的一定阈值内, 则被认为正确跟踪, 较高的低阈值精度表示跟踪器更精确, 在此选择的阈值为20个像素。2) 平均中心位置误差 (Centre Location Error, CLE) 。中心位置误差是跟踪算法计算的位置中心与数据集的标准值之间的差异, 误差越小效果越优。3) 成功率曲线。成功率是以目标边界框的重叠率<i>O</i>=|<i>B</i><sub>t</sub>∩<i>B</i><sub>g</sub>|/|<i>B</i><sub>t</sub>∪<i>B</i><sub>g</sub>|进行计算的, 其中∩和∪分别表示两个区域的交集和并集, |·|指的是区域内的像素点个数, <i>B</i><sub>t</sub>为跟踪的边界框, <i>B</i><sub>g</sub>是标准边界框。重叠率越高越准确, 这里选择重叠率的阈值为0.5。4) 每秒处理的帧数 (Frames Per Second, FPS) 。FPS的数值越大说明处理速度越快。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">3.2 <b>实验结果分析</b></h4>
                <div class="p1">
                    <p id="94">为了评估本文提出的<i>FSACF</i>算法的有效性, 选取<i>OTB</i>视频集中40组视频, 平均所有属性下的跟踪结果, 绘制出精度曲线和成功率曲线如图4所示, 对比算法包括<i>SAMF</i>、<i>KCF</i>、<i>TLD</i>、核结构化输出跟踪算法<i>Struck</i> (<i>structured output tracking with kernels</i>) <citation id="150" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和<i>CSK</i>算法。</p>
                </div>
                <div class="p1">
                    <p id="95">从图4可看出:本文提出的跟踪器在20个像素的位置误差上精度为82.7%, 在50%的重叠率上的成功率表现为76.2%, 在精确性和鲁棒性方面都有很好的应用前景。本文<i>FSACF</i>算法与<i>SAMF</i>算法相比, 在精度上高出1.4个百分点, 成功率高出3.9个百分点;与<i>KCF</i>算法相比, 在精度上提高7.4个百分点, 成功率提高12.8个百分点;与<i>Struck</i>算法相比, 在精度上高出12.4个百分点, 成功率高出18个百分点, 在精度与成功率上均优于其他对比算法。由此可以看出, 显著性颜色梯度特征能在一定程度上抑制背景的干扰, 经改进后算法对目标信息的捕捉能力有一定提升。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 精度和成功率曲线" src="Detail/GetImg?filename=images/JSJY201904034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 精度和成功率曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>Accuracy curve and success rate curves</i></p>

                </div>
                <div class="p1">
                    <p id="97">为了验证本文提出的基于显著性颜色特征的全局梯度特征法和分离窗口法对尺度计算效率的提升, 将<i>FSACF</i>算法与尺度自适应跟踪 (<i>Scale Adaptive Correlation Filter</i>, <i>SACF</i>) 算法即无分离窗口和全局特征法的<i>FSACF</i>算法进行比较。本文提出的<i>FSACF</i>算法在处理速度方面如表2所示 (这里只选择了部分的视频序列进行列举) , 平均比<i>SACF</i>算法提升1.5倍。</p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表</b>2 <i>FSACF</i><b>和</b><i>SACF</i><b>的</b><i>FPS</i><b>对比</b><i>frame</i>/<i>s</i> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>FPS comparison between FSACF and NFSACF</i><i>frame</i>/<i>s</i></p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td>视频</td><td><i>FSACF</i></td><td><i>SACF</i></td><td>视频</td><td><i>FSACF</i></td><td><i>SACF</i></td></tr><tr><td><br /><i>Scale</i></td><td><b>81.78</b></td><td>36.87</td><td>Couple</td><td><b>67.23</b></td><td>17.21</td></tr><tr><td><br />Cat4</td><td><b>26.49</b></td><td>14.04</td><td>Football</td><td><b>78.13</b></td><td>18.03</td></tr><tr><td><br />David</td><td><b>31.31</b></td><td>14.34</td><td>Jumping</td><td><b>108.51</b></td><td>47.57</td></tr><tr><td><br />Fleet</td><td><b>50.23</b></td><td>23.15</td><td>Football</td><td><b>71.13</b></td><td>28.23</td></tr><tr><td><br />Free</td><td><b>181.32</b></td><td>86.13</td><td>Faceocc</td><td><b>24.23</b></td><td>13.86</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:加粗值表示最优结果。</p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="99">对超参数<i>μ</i>进行对比分析实验如图5所示, 其中<i>μ</i>分别取值0～0.7 (以0.05为间隔) 。以不同<i>μ</i>值依次对FSACF算法进行测试, 得到的精度取平均值, 可以从实验结果中看出在<i>μ</i>=0.25时可以得到最高成功率。当给置信度函数选取适当的<i>μ</i>值, 模型在一定程度上可以避免异常值对模型造成的污染, 从而缓解因遮挡等因素而引起的目标漂移问题。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同μ取值的成功率曲线" src="Detail/GetImg?filename=images/JSJY201904034_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同<i>μ</i>取值的成功率曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Success rate curve with different <i>μ</i> values</p>

                </div>
                <div class="p1">
                    <p id="101">选取多组视频序列进行定性分析, 各算法的跟踪结果如图6所示。实验结果显示, 现有的一些跟踪算法仅能在自然场景中小部分干扰因素下正常跟踪, 当有光照、尺度等因素影响时效果反差大, 易产生目标漂移等问题。而FSACF算法采用颜色梯度特征能很好地克服光照变化的影响, 同时采用了分离窗口法有效地克服了尺度变化对跟踪造成的影响。当尺度发生较大变化时FSACF算法在三组视频中均能准确地框定出目标, 其他算法则易产生不同程度的目标漂移。所以FSACF算法具有良好的鲁棒性, 特别是在尺度变化方面表现优异。</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904034_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法的跟踪结果对比" src="Detail/GetImg?filename=images/JSJY201904034_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法的跟踪结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904034_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Tracking results comparison of different algorithms</p>

                </div>
                <h3 id="103" name="103" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="104">针对KCF算法在跟踪过程中面对尺度变化和遮挡发生时易产生目标漂移和模型污染的问题, 对其进行改进, 提出FSACF算法。本文利用颜色空间和梯度特征的互补性, 提出的全局组合特征和分离窗口法, 不但能处理尺度的问题, 同时保证了实时性的需求。并验证了置信度函数可以在一定程度上提高模型更新策略的鲁棒性, 避免模型污染。但综合所有干扰因素的情况, 整体跟踪精度与成功率没有大幅度的提升。在接下来的工作中, 如何在保证效率的同时对精度与成功率进行进一步的提升是下一步的研究重点。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="117">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stability and Scalability of Homogeneous Vehicular Platoon:Study on the Influence of Information Flow Topologies">

                                <b>[1]</b> ZHENG Y, LI S E, WANG J, et al. Stability and scalability of homogeneous vehicular platoon:study on the influence of information flow topologies[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 17 (1) :14-26.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201609040&amp;v=MjgwNDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVUwvS0x6N0JkN0c0SDlmTXBvOUJaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>勾承甫, 陈斌, 赵雪专, 等.基于随机一致性采样估计的目标跟踪算法[J].计算机应用, 2017, 36 (9) :2566-2569. (GOU C F, CHEN B, ZHAO X Z, et al. Object tracking algorithm based on random sampling consensus estimation[J]. Journal of Computer Applications, 2017, 36 (9) :2566-2569.) 
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">

                                <b>[3]</b> BOLME D S, BEVERIDGE J R, DRAPER B A, et al. Visual object tracking using adaptive correlation filters[C]//CVPR 2010:Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2010:2544-2550.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">

                                <b>[4]</b> HENRIQUES J F, RUI C, MARTINS P, et al. Exploiting the circulant structure of tracking-by-detection with kernels[C]//ECCV2012:Proceedings of the 12th European Conference on Computer Vision, LNCS 7575. Berlin:Springer, 2012:702-715.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 HENRIQUES J F, CASEIRO R, MARTINS P, et al. High-speed tracking with kernelized correlation filters[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">

                                <b>[6]</b> LI Y, ZHU J. A scale adaptive kernel correlation filter tracker with feature integration[C]//ECCV 2014:Proceedings of the 2014 European Conference on Computer Vision, LNCS 8926. Berlin:Springer, 2014:254-265.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 KALAL Z, MATAS J. Tracking learning detection[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (7) :1409-1422.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Detection with Discriminatively Trained Part-Based Models">

                                <b>[8]</b> FELZENSZWALB P, GIRSHICK R, MCALLESTER D, et al. Object detection with discriminatively trained part-based models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) :1627-1645.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Color Attributes for Real-Time Visual Tracking">

                                <b>[9]</b> DANELLJAN M, KHAN F S, FELSBERG M, et al. Adaptive color attributes for real-time visual tracking[C]//CVPR 2014:Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC:IEEE Computer Society, 2014:1090-1097.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 WUY, LIM J, YANG M H. Object tracking benchmark[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Struck:Structured output tracking with kernels">

                                <b>[11]</b> HARE S, GOLODETZ S, SAFFARI A. Struck:structured output tracking with kernels[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (10) :2096-2109.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904034" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904034&amp;v=MTQ4NjdmWnVac0Z5RGhVTC9LTHo3QmQ3RzRIOWpNcTQ5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
