<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637139023727916250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903043%26RESULT%3d1%26SIGN%3dafFveukA9siSRxjDsrYkyuecnmQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903043&amp;v=MzE4MDZHNEg5ak1ySTlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkxMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 相关理论 ">1 相关理论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="1.1 &lt;b&gt;基于&lt;/b&gt;K-means&lt;b&gt;的局部相关系数方法&lt;/b&gt;">1.1 <b>基于</b>K-means<b>的局部相关系数方法</b></a></li>
                                                <li><a href="#53" data-title="1.2 One-class SVM&lt;b&gt;异常检测算法&lt;/b&gt;">1.2 One-class SVM<b>异常检测算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#65" data-title="2 异常值检测与噪声图像分割方法 ">2 异常值检测与噪声图像分割方法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#112" data-title="3.1 &lt;b&gt;合成图像&lt;/b&gt;">3.1 <b>合成图像</b></a></li>
                                                <li><a href="#123" data-title="3.2 &lt;b&gt;自然图像&lt;/b&gt;">3.2 <b>自然图像</b></a></li>
                                                <li><a href="#134" data-title="3.3 &lt;b&gt;混合噪声图像&lt;/b&gt;">3.3 <b>混合噪声图像</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#142" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="图1 三维线性分类超平面示意图">图1 三维线性分类超平面示意图</a></li>
                                                <li><a href="#70" data-title="图2 LCK模型对噪声像素点降权示意图">图2 LCK模型对噪声像素点降权示意图</a></li>
                                                <li><a href="#71" data-title="图3 LSV模型对噪声像素点降权示意图">图3 LSV模型对噪声像素点降权示意图</a></li>
                                                <li><a href="#73" data-title="图4 均值滤波和本文方法对噪声图像的滤波结果">图4 均值滤波和本文方法对噪声图像的滤波结果</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;计算&lt;/b&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-&lt;i&gt;score&lt;/i&gt;&lt;b&gt;所需的参数&lt;/b&gt;"><b>表</b>1 <b>计算</b><i>F</i><sub>1</sub>-<i>score</i><b>所需的参数</b></a></li>
                                                <li><a href="#118" data-title="图5 高斯噪声环境下人工图像的分割结果对比">图5 高斯噪声环境下人工图像的分割结果对比</a></li>
                                                <li><a href="#122" data-title="图6 各模型对高斯合成图像分割的&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-&lt;i&gt;score&lt;/i&gt;分值图">图6 各模型对高斯合成图像分割的<i>F</i><sub>1</sub>-<i>score</i>分值图</a></li>
                                                <li><a href="#126" data-title="图7 高斯噪声环境下自然图像的分割结果对比">图7 高斯噪声环境下自然图像的分割结果对比</a></li>
                                                <li><a href="#127" data-title="图8 各模型对高斯自然图像&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-&lt;i&gt;score&lt;/i&gt;分值图">图8 各模型对高斯自然图像<i>F</i><sub>1</sub>-<i>score</i>分值图</a></li>
                                                <li><a href="#131" data-title="图9 椒盐噪声环境下自然图像的分割结果对比">图9 椒盐噪声环境下自然图像的分割结果对比</a></li>
                                                <li><a href="#132" data-title="图10 各椒盐噪声强度下各模型&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-&lt;i&gt;score&lt;/i&gt;分值图">图10 各椒盐噪声强度下各模型<i>F</i><sub>1</sub>-<i>score</i>分值图</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同模型收敛耗时&lt;/b&gt;"><b>表</b>2 <b>不同模型收敛耗时</b></a></li>
                                                <li><a href="#139" data-title="图11 混合噪声环境下自然图像的分割结果对比">图11 混合噪声环境下自然图像的分割结果对比</a></li>
                                                <li><a href="#141" data-title="图12 混合噪声环境下自然图像的量化分值对比">图12 混合噪声环境下自然图像的量化分值对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="163">


                                    <a id="bibliography_1" title="KASS M, WITKIN A, TERZOPOULOS D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830144&amp;v=MTI3Njc5U1hxUnJ4b3hjTUg3UjdxZForWnVGaS9sVXIvTEpGdz1OajdCYXJPNEh0SE9wNHhGWmU4TFkzazV6QmRoNGo5&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        KASS M, WITKIN A, TERZOPOULOS D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_2" title="CHAN T F, VESE L A.Active contour without edges[J].IEEETransactions on Image Processing, 2001, 10 (2) :266-277." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Active contour without edges">
                                        <b>[2]</b>
                                        CHAN T F, VESE L A.Active contour without edges[J].IEEETransactions on Image Processing, 2001, 10 (2) :266-277.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_3" title="LI C, KAO C-Y, GORE J C, et al.Implicit active contours driven by local binary fitting energy[C]//CVPR 2007:Proceedings of the2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2007:1-7" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Implicit Active Contours Driven by Local Binary Fitting Energy">
                                        <b>[3]</b>
                                        LI C, KAO C-Y, GORE J C, et al.Implicit active contours driven by local binary fitting energy[C]//CVPR 2007:Proceedings of the2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2007:1-7
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_4" title="ZHANG K, SONG H, ZHANG L.Active contours driven by local image fitting energy[J].Pattern Recognition, 2010, 43 (4) :1199-1206." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738565&amp;v=MTkzMjkrZ0hDWG84b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpJSVY0WGJoQT1OaWZPZmJLN0h0RE5xWTlGWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        ZHANG K, SONG H, ZHANG L.Active contours driven by local image fitting energy[J].Pattern Recognition, 2010, 43 (4) :1199-1206.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_5" title="WANG L, PAN C.Robust level set image segmentation via a local correntropy-based K-means clustering[J].Pattern Recognition, 2014, 47 (5) :1917-1925." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600107321&amp;v=MjUwMjFoQT1OaWZPZmJLOEh0RE1xWTlGWmVzSUQzNDRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyaklJVjRYYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        WANG L, PAN C.Robust level set image segmentation via a local correntropy-based K-means clustering[J].Pattern Recognition, 2014, 47 (5) :1917-1925.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_6" title="JIANG X-L, WANG Q, HE B, et al.Robust level set image segmentation algorithm using local correntropy-based fuzzy c-means clustering with spatial constraints[J].Neurocomputing, 2016, 207 (C) :22-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Robust level set image segmentation algorithm using local correntropy-based fuzzy cmeans clustering with spatial constraints.&amp;quot;">
                                        <b>[6]</b>
                                        JIANG X-L, WANG Q, HE B, et al.Robust level set image segmentation algorithm using local correntropy-based fuzzy c-means clustering with spatial constraints[J].Neurocomputing, 2016, 207 (C) :22-35.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_7" title="LI C, XU C, GUI C, et al.Level set evolution without re-initialization:a new variational formulation[C]//CVPR&#39;05:Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2005:430-436." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Level set evolution without re-initialization: A new variational formulation">
                                        <b>[7]</b>
                                        LI C, XU C, GUI C, et al.Level set evolution without re-initialization:a new variational formulation[C]//CVPR&#39;05:Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2005:430-436.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_8" title="赵怡, 邓红霞, 张玲, 等.基于最大类间方差的权重自适应活动轮廓模型[J].计算机工程与设计, 2018, 39 (2) :486-491. (ZHAOY, DENG H X, ZHANG L, et al.Weight-self adjustment active contour model based on method of maximum classes square error[J].Computer Engineering and Design, 2018, 39 (2) :486-491.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201802034&amp;v=MzIxNDdmWnVacEZ5bmxVTHZLTmlmWVpMRzRIOW5Nclk5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        赵怡, 邓红霞, 张玲, 等.基于最大类间方差的权重自适应活动轮廓模型[J].计算机工程与设计, 2018, 39 (2) :486-491. (ZHAOY, DENG H X, ZHANG L, et al.Weight-self adjustment active contour model based on method of maximum classes square error[J].Computer Engineering and Design, 2018, 39 (2) :486-491.) 
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_9" title="李钢, 李海芳, 尚方信, 等.基于梯度信息的自适应邻域噪声图像分割模型[J].计算机工程, 2018, 44 (5) :227-233. (LI G, LI HF, SHANG F X, et al.Noise image segmentation model with adaptive neighborhood based on gradient information[J].Computer Engineering, 2018, 44 (5) :227-233.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201805038&amp;v=MTM5ODBMejdCYmJHNEg5bk1xbzlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdks=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        李钢, 李海芳, 尚方信, 等.基于梯度信息的自适应邻域噪声图像分割模型[J].计算机工程, 2018, 44 (5) :227-233. (LI G, LI HF, SHANG F X, et al.Noise image segmentation model with adaptive neighborhood based on gradient information[J].Computer Engineering, 2018, 44 (5) :227-233.) 
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_10" title="SCHLKOPF B, PLATT J C, SHAWE-TAYLOR J, et al.Estimating the support of a high-dimensional distribution[J].Neural Computation, 2001, 13 (7) :1443-1471." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011964&amp;v=MTE2MDBlcnFRVE1ud1plWnRGaW5sVXJqSUlWNFhiaEE9TmlmSlpiSzlIdGpNcW85RlpPb09CWG85b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        SCHLKOPF B, PLATT J C, SHAWE-TAYLOR J, et al.Estimating the support of a high-dimensional distribution[J].Neural Computation, 2001, 13 (7) :1443-1471.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_11" title="李昊奇, 应娜, 郭春生, 等.基于深度信念网络和线性单分类SVM的高维异常检测[J].电信科学, 2018, 34 (1) :34-42. (LIH Q, YING N, GUO C S, et al.High-dimensional outlier detection based on deep belief network and linear one-class SVM[J].Telecommunications Science, 2018, 34 (1) :34-42.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX201801005&amp;v=MTk4MzJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5bmxVTHZLSVRYQWRyRzRIOW5Ncm85RllZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        李昊奇, 应娜, 郭春生, 等.基于深度信念网络和线性单分类SVM的高维异常检测[J].电信科学, 2018, 34 (1) :34-42. (LIH Q, YING N, GUO C S, et al.High-dimensional outlier detection based on deep belief network and linear one-class SVM[J].Telecommunications Science, 2018, 34 (1) :34-42.) 
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_12" title="杨成佳.图像去噪及其效果评估若干问题研究[D].长春:吉林大学, 2016:4-5. (YANG C J.Research on image denoising and its effect evaluation[D].Changchun:Jilin University, 2016:4-5.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017015903.nh&amp;v=MjUzODBWRjI2R2JPNUc5ak1ySkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdks=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        杨成佳.图像去噪及其效果评估若干问题研究[D].长春:吉林大学, 2016:4-5. (YANG C J.Research on image denoising and its effect evaluation[D].Changchun:Jilin University, 2016:4-5.) 
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_13" title="Le CUN Y, BOTTOU L, BENGIO Y, et al.MNIST[DB/OL]. (2012-01-01) [2018-08-27].http://yann.lecun.com/exdb/mnist/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MNIST">
                                        <b>[13]</b>
                                        Le CUN Y, BOTTOU L, BENGIO Y, et al.MNIST[DB/OL]. (2012-01-01) [2018-08-27].http://yann.lecun.com/exdb/mnist/.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_14" title="BORENSTEIN E.Weizmann horse database[DB/OL]. (2005-01-19) [2018-08-27].http://www.msri.org/m/people/members/eranb/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weizmann Horse Database">
                                        <b>[14]</b>
                                        BORENSTEIN E.Weizmann horse database[DB/OL]. (2005-01-19) [2018-08-27].http://www.msri.org/m/people/members/eranb/.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-10-17 15:36</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),874-881 DOI:10.11772/j.issn.1001-9081.2018071494            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于One-class SVM的噪声图像分割方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%9A%E6%96%B9%E4%BF%A1&amp;code=38120458&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尚方信</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%B5%A9&amp;code=08870075&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭浩</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%92%A2&amp;code=17451251&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李钢</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%8E%B2&amp;code=08868749&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张玲</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学信息与计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决现有无监督图像分割模型对强噪声环境鲁棒性差、无法适应复杂混合噪声的问题, 提出了一种基于One-class SVM方法的改进后的噪声鲁棒图像分割模型。首先, 基于One-class SVM构建一种数据离群程度检测机制;然后, 将离群程度值引入能量泛函, 令分割模型可以在多种噪声强度下获得较为准确的图像信息, 同时避免现有方法在强噪声环境下, 降权机制失效的问题;最后, 通过最小化能量函数, 驱动分割轮廓向目标边缘演化。在噪声图像分割实验中, 当选取不同类型和强度的噪声时, 该模型均能得到较为理想的分割结果。在F<sub>1</sub>-score评估标准下, 该模型比基于局部相关熵的<i>K</i>-means (LCK) 模型高0.2～0.3, 在强噪声环境下具有更高的稳定性, 且在分割收敛时间上仅略大于LCK模型0.1 s左右。实验结果表明, 所提模型在未显著增加分割耗时的前提下, 对于概率、极值及混合噪声均有着更强的鲁棒性, 并且可以分割带有噪声的自然图像。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%99%AA%E5%A3%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像噪声;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%95%E7%B1%BB%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单类支持向量机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A6%BB%E7%BE%A4%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">离群检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E9%A1%B9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量项;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    尚方信 (1994—) , 男, 山西太原人, 硕士研究生, 主要研究方向:图像处理;;
                                </span>
                                <span>
                                    *郭浩 (1981—) , 男, 山西太原人, 副教授, 博士, CCF会员, 主要研究方向:视觉信息处理、人工智能、脑信息学;电子邮箱feiyu_guo@sina.com;
                                </span>
                                <span>
                                    李钢 (1980—) , 男, 内蒙古临河人, 讲师, 博士, CCF会员, 主要研究方向:视觉信息处理;;
                                </span>
                                <span>
                                    张玲 (1985—) , 女, 山西孝义人, 讲师, 博士, 主要研究方向:图像处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61472270);</span>
                    </p>
            </div>
                    <h1><b>Novel image segmentation method with noise based on One-class SVM</b></h1>
                    <h2>
                    <span>SHANG Fangxin</span>
                    <span>GUO Hao</span>
                    <span>LI Gang</span>
                    <span>ZHANG Ling</span>
            </h2>
                    <h2>
                    <span>College of Information and Computer, Taiyuan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To deal with poor robustness in strong noise environment, weak adaptability to complex mixed noise that appear in the existing unsupervised image segmentation models, an improved noise-robust image segmentation model based on One-class SVM (Support Vector Machine) method was proposed. Firstly, a data outlier detection mechanism was constructed based on One-class SVM. Secondly, an outlier degree was introduced into the energy function, so that more accurate image information could be obtained by the proposed model under multiple noise intensities and the failure of weight-descend mechanism in strong noise environment was avoided. Finally, the segmentation contour was driven to the target edge by minimizing the energy function. In noise image segmentation experiments, the proposed model could obtain ideal segmentation results with different types and intensities of noise. Under F<sub>1</sub>-score metric, the proposed model is 0.2 to 0.3 higher than LCK (Local Correntropy-based <i>K</i>-means) model, and has better stability in strong noise environments. The segmentation convergence time of the proposed model is only slightly longer than that of LCK model by about 0.1 s. Experimental results show that the proposed model is more robust to probabilistic, extreme values and mixed noise without significantly increase of segmentation time, and can segment natural images with noise.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20noise&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image noise;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=One-class%20Support-Vector-Machine%20(SVM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">One-class Support-Vector-Machine (SVM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=outlier%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">outlier detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=energy%20term&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">energy term;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SHANG Fangxin, born in 1994, M. S. candidate. His research interests include image processing.;
                                </span>
                                <span>
                                    GUO Hao, born in 1981, Ph. D. , associate professor. His research interests include visual information processing, artificial intelligence, brain informatics.;
                                </span>
                                <span>
                                    LI Gang, born in 1980 Ph. D. , lecturer. His research interests include visual information processing.;
                                </span>
                                <span>
                                    ZHANG Ling, born in 1985, Ph. D. , lecturer. Her research interests include image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-20</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61472270);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="33">作为计算机视觉技术的基础, 图像分割一直以来就是图像处理研究领域中的重点和难点。其主要目标是根据图像像素值或其他统计指标构建图像特征, 将图像划分为若干个互不重叠的子区域, 每一子区域内部具有相同或相似的图像特征。近年来, 结合多种统计方法的分割模型<citation id="191" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 在解决各种类型的图像分割问题中得到了较为广泛且成功的应用, 但应用于模糊图像、噪声图像和目标边界不平滑的自然图像的分割问题时, 仍存在诸多问题。</p>
                </div>
                <div class="p1">
                    <p id="34">C-V (Chan-Vese) 模型<citation id="192" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>开创了依据图像区域特征完成分割的先河, 它使用分片常数函数对分割轮廓线两侧的图像区域进行拟合, 在像素值与所属区域均值差异最小时, 达到稳定状态。C-V模型对边界较不清晰的目标分割性能良好, 但无法分割非同质不均匀图像。针对C-V模型的不足, 局部二值拟合 (Local Binary Fitting, LBF) <citation id="193" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>和局部图像拟合 (Local Image Fitting, LIF) <citation id="194" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>为代表的局部区域型模型利用局部窗的思想, 以每一个像素点为中心, 将图像划分为多个有重叠的局部区域。上述局部模型可较准确地分割不均匀图像, 但由于其仅考虑了图像局部信息, 能量函数在迭代过程中容易陷入局部极小值, 同时对初始位置的敏感性也较强。</p>
                </div>
                <div class="p1">
                    <p id="35">研究人员在LBF、LIF的基础上提出了许多改进方法, Wang等<citation id="195" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出LCK (Local Correntropy-based K-means) 方法, 假设异常数据与局部均值具有显著差异, 对以椒盐噪声为代表的极值噪声具有较好的分辨能力, 但不能准确分辨没有显著极值的概率噪声 (如高斯噪声) 。Jiang等<citation id="196" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>于2016年提出的模糊C聚类 (Fuzzy C-Means, FCM) 方法认为在分割过程中, 像素点对每一个子区域均应具有从属概率, 最终选择从属概率最大的区域作为分割结果。该方法可较准确地分割椒盐噪声图像, 但像素点从属区域的结果被概率化, 该模型在高斯噪声图像、或弱边界图像的边界处易受到异常信息的干扰, 无法准确估计图像灰度依赖的概率分布而造成混淆, 最终导致分割失败。Li等<citation id="197" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>于2016年提出的RLSF模型 (Region-based model via Local Similarity Factor) 考虑了图像局部像素的相对位置与空间信息 (像素点间的欧氏距离) , 结合较小的自适应迭代步长, 可实现对弱椒盐噪声图像的有效分割, 但在强噪声环境或概率噪声环境下, 均表现不佳。2018年赵怡等<citation id="198" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>认为进行图像分割时, 不仅要考虑每一子区域内部图像特征的相似性, 还需最大化不同区域之间图像特征的差异性, 并引入图像熵分别度量每一区域内部的均匀程度。2018年李钢等<citation id="199" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在目标边界灰度变化相对显著的区域使用可变形邻域去除弱相关图像信息, 结合LCK降权方法提升模型在弱边界模糊图像和噪声图像的性能。该方法的可变形邻域为模型提供了更多的灵活性, 但仍属于作者赋予的先验信息。模型不具有机器学习能力, 未能充分适应复杂的图像数据, 在轮廓复杂的噪声自然图像和混合噪声图像上表现仍有提升空间。上述改进使得该模型对于非均匀和弱边界图像的分割问题具有良好的适应能力, 但在椒盐噪声环境下, 噪声颗粒原本就与其所属区域的图像特征差异较大, 容易导致分割失败。</p>
                </div>
                <div class="p1">
                    <p id="36">上述模型分别对特定类别的图像具有良好的分割效果, 但大多未考虑噪声图像或仅考虑使模型适应弱噪声环境, 且适应的噪声类别各有不同。因而这些模型在噪声强度较高或噪声分布复杂时, 会出现过分割或分割失败的现象。针对这些问题, 本文基于单类支持向量机 (One-class Support Vector Machine, One-class SVM) 方法提出一种更加合理的像素点赋权方案, 在考虑图像局部信息的基础上, 在图像全局范围内利用所有的局部均值构造一个离群程度检测机制。实验表明, 本文模型对不同强度和多种类别的图像噪声有着良好的适应能力, 并且可以在噪声环境下处理背景较为复杂的自然图像。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag">1 相关理论</h3>
                <h4 class="anchor-tag" id="38" name="38">1.1 <b>基于</b>K-means<b>的局部相关系数方法</b></h4>
                <div class="p1">
                    <p id="39">2013年, Wang等<citation id="200" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种名为LCK (Local Correntropy-based <i>K</i>-means) 的噪声鲁棒模型。其核心思想是根据<i>K</i>-means无监督聚类方法构建一种介于0～1的相关性系数, 衡量邻域内像素点与邻域中心在像素空间中的相似程度。某一像素点处的相关性系数越接近0, 该像素点与邻域内图像内容的相关性越低, 被噪声污染的可能性越大。</p>
                </div>
                <div class="p1">
                    <p id="40">椒盐噪声是产生自图像传输过程中的极值点状噪声, 噪声颗粒与其邻域灰度均值的差异较大。在LCK模型中, 该类噪声颗粒被分配较小的相关性系数, 对模型能量函数的计算影响较小。因此LCK对椒盐噪声具有较强的鲁棒性, 模型能量函数如式 (1) 所示:</p>
                </div>
                <div class="p1">
                    <p id="41"><i>E</i><sub>LCK</sub>=<i>E</i><mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>C</mtext><mtext>Κ</mtext></mrow></msubsup></mrow></math></mathml>+<i>κ</i>·<i>P</i> (<i>φ</i>) +<i>ν</i>·<i>L</i> (<i>φ</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="43">其中:<i>P</i> (<i>φ</i>) 是惩罚项, 作用是在迭代过程中保持水平集函数为符号距离函数<citation id="201" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 即函数梯度值的绝对值处为1, 省去重新初始化的计算步骤;<i>L</i> (<i>φ</i>) 是分割轮廓线长度约束项, 在曲线长度为0时取到最小值, 对分割轮廓线起到类似气球弹力的约束作用, 确保分割曲线在拟合图像内容的过程中保持平滑。形式如式 (2) 、 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></mrow></mstyle><mo>⋅</mo><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mo>∇</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>δ</mi></mrow></mstyle><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mrow><mo>|</mo><mrow><mo>∇</mo><mi>φ</mi></mrow><mo>|</mo></mrow><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45"><i>E</i><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>C</mtext><mtext>Κ</mtext></mrow></msubsup></mrow></math></mathml>是LCK模型的图像拟合项, 使用<i>I</i>代表像素灰度值, <i>μ</i><sub>1</sub>、 <i>μ</i><sub>2</sub>代表图像域内以各点为中心的、分割轮廓线两侧的邻域灰度均值, 形式如下:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>C</mtext><mtext>Κ</mtext></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><mrow><mo>∬</mo><mrow><mtable><mtr><mtd><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow></mstyle><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo></mtd></mtr><mtr><mtd><mi>Η</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><mtext>d</mtext><mi>x</mi><mo>+</mo><mstyle displaystyle="true"><mrow><mo>∬</mo><mrow><mtable><mtr><mtd><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow></mstyle><mo>⋅</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>g</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mspace width="0.25em" /><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>Κ</mi></mrow></mstyle><msub><mrow></mrow><mi>σ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mspace width="0.25em" /><mtext>d</mtext><mi>y</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>Κ</mi></mrow></mstyle><msub><mrow></mrow><mi>σ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>⋅</mo><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mspace width="0.25em" /><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>Κ</mi></mrow></mstyle><msub><mrow></mrow><mi>σ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>⋅</mo><mi>c</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi></mrow></msub><mspace width="0.25em" /><mtext>d</mtext><mi>y</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48"><i>c</i><sub><i>x</i>, <i>y</i></sub>为图像域内<i>x</i>, <i>y</i>两点之间的相关性系数, 计算方式如下:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>c</i><sub><i>x</i>, <i>y</i></sub>=<i>H</i><sub><i>ε</i></sub> (<i>φ</i>) ·<i>g</i> (‖<i>I</i> (<i>y</i>) -<i>μ</i><sub>1</sub> (<i>x</i>) ‖<sub>2</sub>) + (1-<i>H</i><sub><i>ε</i></sub> (<i>φ</i>) ) ·</p>
                </div>
                <div class="p1">
                    <p id="50"><i>g</i> (‖<i>I</i> (<i>y</i>) -<i>μ</i><sub>2</sub> (<i>x</i>) ‖<sub>2</sub>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="51"><i>g</i> (<i>x</i>) =exp (-<i>x</i><sup>2</sup>/2<i>σ</i><sup>2</sup>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="52">该方法通过计算图像中各像素点的灰度值与其邻域灰度的相关性, 减少了水平集函数迭代过程中噪声点对分割结果的影响, 但该模型在图像包含较多噪声时, 可能会对过多的像素点降权, 抛弃过多图像内容, 以至出现分割失败的情况。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53">1.2 One-class SVM<b>异常检测算法</b></h4>
                <div class="p1">
                    <p id="54">支持向量机方法在线性不可分数据的二分类及多分类问题上得到了成功且广泛的应用。Schölkopf等<citation id="202" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将支持向量机推广至单分类问题, 提出了单类支持向量机 (One-class SVM) 方法以后, 研究人员提出了诸多改进, 使其在异常检测问题上得到广泛应用<citation id="203" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>本质上, One-class SVM是一种无监督分类方法。设定义在<i>n</i>维数据空间上的非线性映射核函数<i>K</i>, 单类样本集{<b><i>x</i></b><sub><i>i</i></sub>, <i>i</i>=1, 2, …, <i>M</i>}, <b><i>x</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>n</i></sup>, One-class SVM方法通过核函数<i>K</i>将数据映射至更高维的空间中, 使原本线性不可分的数据线性可分;在数据点间寻找一个最大间隔分类超平面。该超平面可用<i>n</i>维向量<b><i>W</i></b>=[<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>n</i></sub>]和常量<i>b</i>描述, One-class SVM的分类机制为:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo>+</mo><mn>1</mn><mo>, </mo><mtext> </mtext><mi mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">x</mi><mo>+</mo><mi>b</mi><mo>&gt;</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">x</mi><mo>+</mo><mi>b</mi><mo>&lt;</mo><mo>-</mo><mn>1</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">图1是数据空间维度<i>n</i>=3时的分类机制示意图, 展示了超平面在映射空间中对数据的分类机制。</p>
                </div>
                <div class="p1">
                    <p id="57">One-class SVM有两种实现方式, 即构造与数据分离的超平面和构造包裹数据的超球体。可以证明, 在映射核函数<i>K</i>是高斯核函数时, 两种方法等价。无论哪一种实现方式, 都以现有样本作为正样本构造数据域描述, 并将异常值标记为负样本。为使决策分类超平面在描述数据特征的同时尽可能地远离负样本, 需要求解下式的受限优化问题:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>w</mi><mo>, </mo><mi>b</mi><mo>, </mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mfrac><mn>1</mn><mrow><mi>ν</mi><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>ξ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>ρ</mi></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><mo>⋅</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>≥</mo><mi>ρ</mi><mo>-</mo><mi>ξ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mtext> </mtext><mi>ξ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo>, </mo><mtext> </mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中:<i>N</i>为样本数量;<b><i>x</i></b><sub><i>i</i></sub>代表数据点; <i>ρ</i>为常数, 代表分类超平面的截距;<i>ξ</i><sub><i>i</i></sub>为松弛变量, 用于在一定范围内忽略分类误差, 降低分类超平面对异常数据的敏感性;<i>ν</i>∈ (0, 1]是模型超参数, 与正样本侧的训练数据量成反比, 它反映了分类平面最大化正样本一侧的训练数据数量和最小化到每一训练样本间距离的折中, 即尽可能多且紧密地将训练数据包含在分类超球内部。对于有条件限制的参数优化问题, 构造形式如式的拉格朗日函数求解:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><mo>, </mo><mspace width="0.25em" /><mi>ρ</mi><mo>, </mo><mi>ξ</mi><mo>, </mo><mi>α</mi><mo>, </mo><mi>γ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mfrac><mn>1</mn><mrow><mi>ν</mi><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>ξ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>ρ</mi><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><mo>⋅</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>-</mo><mi>ρ</mi><mo>+</mo><mi>ξ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi>γ</mi><msub><mrow></mrow><mi>i</mi></msub><mi>ξ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">其中<i>a</i>和<i>γ</i>为拉格朗日因子。求解式 (11) 可得到One-class SVM的决策函数, 形式如下:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>=</mo><mtext>s</mtext><mtext>i</mtext><mtext>g</mtext><mtext>n</mtext><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>ρ</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>ρ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>a</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">One-class SVM作为一种异常值检测算法, 通过拟合数据得到最大化边界的分类超平面, 兼顾了对正常数据的泛化能力和对异常数据检测的敏感性。但该模型仅能完成“正常/异常”数据的二分检测, 无法判定数据离群程度。若直接将该方法应用于图像分割, 模型将只能“接受”或“抛弃”图像像素点, 而无法获取中间状态, 这对具有复杂目标的自然图像分割是极为不利的。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 三维线性分类超平面示意图" src="Detail/GetImg?filename=images/JSJY201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 三维线性分类超平面示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Schematic diagram of three-dimensional linear classification hyperplane</p>

                </div>
                <h3 id="65" name="65" class="anchor-tag">2 异常值检测与噪声图像分割方法</h3>
                <div class="p1">
                    <p id="66">基于噪声颗粒降权的噪声图像分割模型利用图像统计特征衡量区域与特定点的相似关系, 与区域特征差距较大的像素点被判定为噪声点, 可根据差异值平滑地对噪声点进行降权, 降低图像噪声对分割过程的干扰。此类噪声鲁棒方法处理弱椒盐噪声效果显著, 但噪声点判定方法在高斯噪声和强椒盐噪声环境下容易失效, 影响分割结果, 出现分割失败的情况。</p>
                </div>
                <div class="p1">
                    <p id="67">如图2所示, 取一边长为3、包含9个像素点的正方形邻域。图中分块颜色代表该处的像素值, 数字代表LCK模型在该像素点处的权值。该区域正常像素信息为浅色, 在图2 (a) 所示的弱噪声环境中, 仅有少量像素点被胡椒颗粒污染, 变为深色, 此时LCK模型为该异常点赋予了一个较低的权值, 因此该异常点对能量函数的计算和分割迭代影响较小;而在图2 (b) 所示的强噪声环境下, 多个像素点被噪声污染, 此时噪声点被降权, 但原本正常的浅色像素也被赋予了较低的权值, 此加权灰度均值的计算相当于仅依赖少数像素颗粒, 从而使加权的邻域均值失去了对邻域信息的代表性, 而只包含了其中某一个像素点的信息。这显然是不合理的。</p>
                </div>
                <div class="p1">
                    <p id="68">研究<citation id="204" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>表明, 常见图像噪声可分为概率噪声和极值脉冲噪声。其中, 以高斯噪声、伽马噪声为代表的随机噪声均服从某种具有均值和方差的概率分布;以椒盐噪声为代表的极值脉冲噪声具有较稳定的均值。</p>
                </div>
                <div class="p1">
                    <p id="69">针对图像噪声的上述类型和特性, 本文将基于支持向量方法构建一种噪声鲁棒的局部型图像分割模型LSV (Localized Support Vector) 。在如图3 (a) 所示的弱噪声环境下, 邻域内仅有少量像素点被噪声污染, 且噪声点处像素值离群程度较大, 距离包裹大部分数据的SVM分类超球面较远。此时噪声点将被赋予较小的权重以避免其对能量泛函的干扰。如图3 (b) 所示的强噪声环境下, 虽然多个噪声点被污染, 邻域内像素方差较大, 但SVM仍致力于通过核函数将数据点映射至高维空间中分类超球体内侧, 即对多个噪声点赋予接近的权重, 使邻域均值的计算方式趋近于算术平均数。LSV模型对噪声点的降权机制如图3所示。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 LCK模型对噪声像素点降权示意图" src="Detail/GetImg?filename=images/JSJY201903043_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 LCK模型对噪声像素点降权示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Schematic diagram of reducing weights of noise pixels in LCK model</p>

                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LSV模型对噪声像素点降权示意图" src="Detail/GetImg?filename=images/JSJY201903043_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 LSV模型对噪声像素点降权示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Schematic diagram of reducing weights of noise pixels in LSV model</p>

                </div>
                <div class="p1">
                    <p id="72">以图4所示的多幅弱边界人工合成图像为例, 在叠加方差0.3的高斯噪声的强噪声环境下, 基于算术平均数的全局均值滤波可有效去除图像噪声, 并保留部分图像内容;在弱噪声环境下, 图像被叠加方差0.05的高斯噪声。显然, 在噪声强度较弱时, 均值滤波会损失过多的图像信息, 可能导致分割模型无法捕捉到足够的图像信息而造成过分割或误分割, 是一种相对低效的预处理方式。而对于给定的图像, 本文方法中离群程度的检测机制可在图像的每一个局部区域对每一个像素点计算出一个合理的权值, 使用这种权值作为滤波算子对噪声图像进行滤波, 其结果也一并展示在图4中。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 均值滤波和本文方法对噪声图像的滤波结果" src="Detail/GetImg?filename=images/JSJY201903043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 均值滤波和本文方法对噪声图像的滤波结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Filtering results of noise image by mean filtering and the proposed method</p>

                </div>
                <div class="p1">
                    <p id="74">可以发现基于本文方法的滤波结果清晰程度要优于均值滤波的结果。这是由于图像噪声服从某概率分布或具有较稳定的均值, 被噪声污染的像素点仍然可能保留着部分图像信息, 强噪声场景下在整个图像上使用接近算术平均数的计算方式是合理的, 但弱噪声环境下仍应对噪声点进行有效的降权, 均值滤波算子在弱噪声环境下仍会对所有像素点进行无差别的平均运算。</p>
                </div>
                <div class="p1">
                    <p id="75">设One-class SVM方法的分类超平面为超空间中的<i>xy</i>零平面, 数据点经高斯核函数映射后位于平面两侧。考虑人工构建的特征空间中一点<i>p</i>, 到超平面距离为<i>z</i>, 有如下关系:</p>
                </div>
                <div class="p1">
                    <p id="76"><i>z</i>=<i>f</i> (<b><i>p</i></b>) ·<i>K</i> (<b><i>W</i></b><b><i>p</i></b>+<i>b</i>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="77">其中:二值函数<i>f</i> (<i>x</i>) 形式如式 (12) 所示, <i>K</i>为高斯核函数。使用数据点到超平面的距离作为数据离群程度度量, 构造数据合理值<i>S</i> (<b><i>p</i></b>) 使得数据被判定为异常时, 距离决策超平面越远, <i>S</i> (<b><i>p</i></b>) 值越小。形式如下:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>/</mo><mi>z</mi><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mn>1</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">模型能量函数构造如下:</p>
                </div>
                <div class="p1">
                    <p id="80"><i>E</i><sub>LSV</sub> (<i>φ</i>, <i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>) =<i>E</i><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>S</mtext><mtext>V</mtext></mrow></msubsup></mrow></math></mathml>+<i>μP</i> (<i>φ</i>) +<i>νL</i> (<i>φ</i>)      (16) </p>
                </div>
                <div class="p1">
                    <p id="82">其中<i>φ</i>为水平集函数, 取函数的零水平集{<i>φ</i> (<i>x</i>) =0|<i>x</i>∈<i>Ω</i>}作为分割轮廓线, 函数值在分割轮廓两侧的符号相反。惩罚项<i>P</i> (<i>φ</i>) 在迭代过程中限制水平集函数, 使其保持为符号距离函数而无需重新初始化。长度约束项<i>L</i> (<i>φ</i>) 在迭代过程中起着类似气球弹力的作用, 消除分割轮廓线上不必要的凸起, 保持曲线平滑。</p>
                </div>
                <div class="p1">
                    <p id="83"><i>E</i><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>S</mtext><mtext>V</mtext></mrow></msubsup></mrow></math></mathml>为本文模型的图像拟合项, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><msubsup><mrow></mrow><mi>Ι</mi><mrow><mtext>L</mtext><mtext>S</mtext><mtext>V</mtext></mrow></msubsup><mo>=</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>x</mi><mo>∈</mo><mi>Ω</mi></mrow></msub><mspace width="0.25em" /></mrow></mstyle><mo stretchy="false">[</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mi>x</mi></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo></mtd></mtr><mtr><mtd><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>⋅</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>x</mi><mo>∈</mo><mi>Ω</mi></mrow></msub><mspace width="0.25em" /></mrow></mstyle><mo stretchy="false">[</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mi>x</mi></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中两项分别是邻域在分割轮廓线内外两侧的图像拟合项, <i>λ</i><sub>1</sub>, <i>λ</i><sub>2</sub>是相应的权重系数, <i>H</i> (<i>φ</i>) 为Heaviside阶跃函数, 形式如式:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Η</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>[</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mn>2</mn><mtext>π</mtext></mfrac><mi>arctan</mi><mo stretchy="false"> (</mo><mfrac><mi>x</mi><mi>ε</mi></mfrac><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mi>δ</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mtext>d</mtext><mi>Η</mi></mrow><mrow><mtext>d</mtext><mi>x</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mtext>π</mtext></mfrac><mo>⋅</mo><mfrac><mi>ε</mi><mrow><mi>ε</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88"><i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) 分别代表以点<i>x</i>为中心、邻域内轮廓线两侧的像素灰度均值。<i>S</i><sub><i>x</i></sub>为点<i>x</i>处的数据合理程度。为简化计算量和模型复杂度, 本文使用像素灰度值<i>I</i> (<i>x</i>) 和邻域灰度均值<i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) 构建三维数据<b><i>p</i></b>=[<i>I</i> (<i>x</i>) , <i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) ], 由One-class SVM模型进行异常检测。即<i>S</i><sub><i>x</i></sub>=<i>S</i> (<i>I</i> (<i>x</i>) , <i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) ) 。</p>
                </div>
                <div class="p1">
                    <p id="89">值得注意的是, 本文方法中, One-class SVM在整个图像域上进行异常值判断, 并将计算得到的离群程度应用于能量函数。而LBF的局部均值方法仅考虑每一个特定邻域内的图像数据, 考虑的样本数量较少, 因而无法去除噪声数据的影响。</p>
                </div>
                <div class="p1">
                    <p id="90">根据变分法和Euler-Lagrange方程, 设本文模型的水平集演化方程如下:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>φ</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup><mo>-</mo><mtext>Δ</mtext><mi>t</mi><mo>⋅</mo><mfrac><mrow><mo>∂</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mi>δ</mi><mo stretchy="false"> (</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">) </mo><mo>⋅</mo><mspace width="0.25em" /><mo stretchy="false">[</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mi>x</mi></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext>d</mtext><mi>y</mi><mo>-</mo></mtd></mtr><mtr><mtd><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mi>x</mi></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext>d</mtext><mi>y</mi><mo stretchy="false">]</mo><mo>+</mo><mi>μ</mi><mo>⋅</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92"> (div (<i>φ</i><sup><i>i</i></sup>) -div<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mfrac><mrow><mo>∇</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo>⋅</mo><mi>δ</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false">) </mo><mo>⋅</mo><mtext>d</mtext><mtext>i</mtext><mtext>v</mtext><mo stretchy="false"> (</mo><mfrac><mrow><mo>∇</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><mi>φ</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="94">其中:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>⋅</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>⋅</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mi>S</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo>⋅</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">本文算法主要步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="97">1) 初始化水平集函数<i>φ</i><sup>0</sup>。</p>
                </div>
                <div class="p1">
                    <p id="98">2) 初始化相关性系数<i>S</i><sup>0</sup>, 为一个与图像尺寸相同的二维零矩阵。</p>
                </div>
                <div class="p1">
                    <p id="99">3) 根据式计算<i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="100">4) 根据式演化水平集函数, 得到<i>φ</i><sup><i>i</i>+1</sup>。</p>
                </div>
                <div class="p1">
                    <p id="101">5) 构建数据<b><i>p</i></b>=[<i>I</i> (<i>x</i>) , <i>c</i><sub>1</sub> (<i>x</i>) , <i>c</i><sub>2</sub> (<i>x</i>) ], 根据式计算<i>S</i><sup><i>i</i>+1</sup>。</p>
                </div>
                <div class="p1">
                    <p id="102">6) 判断当前迭代状态是否满足停止条件, 如满足, 停止曲线演化;否则重复步骤3) 至5) 。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="104">为验证本文模型在强噪声环境下, 对内容较为复杂的自然图像及弱边界图像的处理能力, 本章将本文模型、LBF模型、LCK模型、FCM模型应用于解决上述类型的图像分割问题中, 并对分割结果进行直观展示和量化对比。实验表明本文模型在叠加多种噪声的弱边界图像、光照和灰度不均匀图像、复杂自然图像等多类型目标上均可以呈现出较为理想的分割结果。特别是在强噪声环境中其他对比模型均出现不同程度误分割时, 本文模型能保持较好的有效性、分割精度和初始轮廓位置鲁棒性, 基于局部支持向量的噪声数据检测方法对噪声数据的检测和抑制作用得到充分展示。实验在Lenovo台式机上使用Matlab R2018a完成。如无特别说明, 本文实验参数设置为:<i>μ</i>=0.003×255×255, <i>λ</i><sub>1</sub>=1, <i>λ</i><sub>2</sub>=1, <i>ν</i>=1, Δ<i>t</i>=0.1, <i>ε</i>=1, <i>σ</i>=1。</p>
                </div>
                <div class="p1">
                    <p id="105">为便于定量分析本文模型与其他对比模型的分割精度, 作为分割结果的水平集函数需要被二值化, 即:</p>
                </div>
                <div class="area_img" id="161">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903043_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="108">本段实验应用F1-score作为分割精度的评估标准, 其计算方式为:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mn>2</mn><mo>⋅</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">对于定义在图像域<i>Ω</i>上的每一个像素点<i>x</i>, 均有模型预测分割结果<i>r</i> (<i>x</i>) 与参考分割结果<i>g</i> (<i>x</i>) 。真阳类 (True Positive, TP) 代表模型预测为前景, 且参考分割结果也为前景的像素点个数;假阳类 (False Positive, FP) 代表模型预测为前景, 但参考分割结果为背景区域的像素点个数;假阴类 (False Negative, FN) 代表模型预测为背景, 但参考分割结果为前景区域的像素点个数。模型的分割结果与参考分割结果重合程度越高, 得到的<i>F</i><sub>1</sub>-<i>score</i>越高。上述内容的直观表达如表1所示。</p>
                </div>
                <div class="area_img" id="111">
                                            <p class="img_tit">
                                                <b>表</b>1 <b>计算</b><i>F</i><sub>1</sub>-<i>score</i><b>所需的参数</b>
                                                    <br />
                                                Tab. 1 Meaning of parameters in <i>F</i><sub>1</sub>-<i>score</i> format
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201903043_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 计算F1-score所需的参数" src="Detail/GetImg?filename=images/JSJY201903043_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">注:<image id="162" type="formula" href="images/JSJY201903043_16200.jpg" display="inline" placement="inline"><alt></alt></image>x∈Ω。</p>

                </div>
                <h4 class="anchor-tag" id="112" name="112">3.1 <b>合成图像</b></h4>
                <div class="p1">
                    <p id="113">Mnist数据集<citation id="205" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>是一个知名的手写字符图像数据集, 包含大量手写数字图像, 尺寸均为28 px (pixel) ×28 px, 其图像内容具有较强的空间复杂性。本段实验从Mnist数据集中随机选取50幅手写字符图片, 进行如下预处理步骤:</p>
                </div>
                <div class="p1">
                    <p id="114">1) 使用双线性插值方法将待分割图像处理至128 px×128 px, 增加像素总数以便准确评估图像噪声对分割结果的干扰;</p>
                </div>
                <div class="p1">
                    <p id="115">2) 进行散焦处理, 弱化目标区域边界;</p>
                </div>
                <div class="p1">
                    <p id="116">3) 依据实验需要叠加图像噪声。</p>
                </div>
                <div class="p1">
                    <p id="117">图5展示了从Mnist数据集中随机抽取的5幅经预处理的图像, 及对比模型在这些图像上的分割结果。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 高斯噪声环境下人工图像的分割结果对比" src="Detail/GetImg?filename=images/JSJY201903043_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 高斯噪声环境下人工图像的分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Segmentation result comparison of artificial images in Gaussian noise environment</p>

                </div>
                <div class="p1">
                    <p id="119">为确保对比实验的有效性和公平性, 本段实验的初始轮廓均位于图像中心, 半径为8 px, 且设定了相同的分割参数。可以发现, 随着高斯噪声强度增加, 图像内容被污染程度同步增加。在方差为0.01的高斯噪声环境下, 图像基本没有被噪声污染, 且模糊的目标边缘并未影响大多数模型的分割。RLSF模型由于迭代步长较小, 易被噪声点干扰, 且邻域不服从高斯分布, 分割结果较不理想。LBF、LCK、FCM和RLSF模型均在强度为0.05以上的高斯噪声环境下, 出现了不同程度的误分割。由于高斯噪声服从高斯概率分布, 每个噪声点与正常像素点的灰度差异不明显, 其局部均值却与无噪声图像的局部均值差异较大, LCK模型相关性系数方法易被干扰, 导致降权机制失效;FCM模型对高斯噪声的适应能力优于前述模型, 但模糊聚类的特性使得图像噪声密度较大时像素点被正确分类的概率不显著, 进而出现误分割现象。本文模型中使用局部均值和图像灰度值作为像素点的特征向量, 且高斯噪声服从的概率分布参数为均值和方差。One-class SVM具有的偏置项使得离群程度判断机制不受概率噪声的均值影响。方差 (噪声强度) 较小时, 图像各像素点与无噪声图像相差不大, 模型可完成准确分割;方差 (噪声强度) 较大时, 大多数噪声点与无噪声图像差异依然较小, 但少量噪声点的偏差值较大。拟合的SVM超球面将尽可能地紧密包裹大多数像素点, 而将少量差异较大的像素点判定为异常, 确保离群程度检测机制的正常, 使模型在强噪声环境下依然可以有效抽取出较为明显的目标边界, 完成准确分割。</p>
                </div>
                <div class="p1">
                    <p id="120">按照上述预处理步骤, 本段实验从Mnist数据集中随机抽取500幅图像, 利用未散焦且未叠加噪声的原始图像, 经二值化处理后作为参考分割结果。上述数据被分为5组, 并分别叠加方差为0.01、0.05、0.1、0.2、0.3的高斯噪声。使用LBF、LCK、FCM、RLSF和本文方法分别进行分割, 记录分割结果并按照<i>F</i><sub>1</sub>-<i>score</i>的计算方式二值化, 所得分值误差棒图如图6所示。其中折线中心点处代表对应噪声强度下该模型所得分数的均值, 上下两侧横线代表该场景下分值的最大值和最小值。</p>
                </div>
                <div class="p1">
                    <p id="121">与图5所示的分割结果相比, 在更广泛的数据上进行的实验进一步证明, 与其他对比模型相比, 本文模型可在弱边界图像、高斯噪声图像上实现准确且稳定的分割。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 各模型对高斯合成图像分割的F1-score分值图" src="Detail/GetImg?filename=images/JSJY201903043_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 各模型对高斯合成图像分割的<i>F</i><sub>1</sub>-<i>score</i>分值图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 <i>F</i><sub>1</sub>-<i>score</i> of segmentation results of Gaussian artificial image by different models</p>

                </div>
                <h4 class="anchor-tag" id="123" name="123">3.2 <b>自然图像</b></h4>
                <div class="p1">
                    <p id="124">在弱边界噪声合成图像上进行的对比实验, 证明了本文模型可以准确分割该类型图像。为了证明本文模型对被分割图像具有广泛的适应性, 本节实验引入Weizmann Horse Database自然图像数据集<citation id="206" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。该数据集包含上百幅以马为主体的图像, 图像背景覆盖多种自然环境。本节实验从该数据集中随机抽取30幅图像, 对每幅图片都进行散焦模糊并分别叠加椒盐噪声和高斯噪声。由于自然图像中灰度、纹理等局部信息较丰富, 本段实验将图像尺寸调整至256 px×256 px, 以保留大部分图像信息, 并使用与上节实验相同的量化方法评估各个模型的分割性能。以下选取了部分具有代表性的图像展示实验结果。</p>
                </div>
                <div class="p1">
                    <p id="125">图7展示了LBF模型、LCK模型、FCM模型和RLSF模型和本文模型在部分高斯噪声图像上的分割结果对比, 图8展示的是全部分割结果的<i>F</i><sub>1</sub>-<i>score</i>量化分值对比情况。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 高斯噪声环境下自然图像的分割结果对比" src="Detail/GetImg?filename=images/JSJY201903043_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 高斯噪声环境下自然图像的分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Segmentation results comparison of natural images in Gaussian noise environment</p>

                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 各模型对高斯自然图像F1-score分值图" src="Detail/GetImg?filename=images/JSJY201903043_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 各模型对高斯自然图像<i>F</i><sub>1</sub>-<i>score</i>分值图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 <i>F</i><sub>1</sub>-<i>score</i> of segmentation results of Gaussian natural image by different models</p>

                </div>
                <div class="p1">
                    <p id="128">与目标较简单的人工合成图像相比, 自然图像具有更丰富的背景内容和图像细节, 容易造成分割模型的误分割和过分割。即使在方差为0.01的弱高斯噪声环境下, LBF、LCK、FCM和RLSF模型在图像全局范围内均出现了不同程度的误分割。这是由于高斯概率噪声在局部范围内造成了与原始图像不同的灰度差异, 且这种差异在局部无法被LBF的均值计算方式消除;同时概率噪声的特性使得大多数差异值位于概率分布的均值附近, 未能触发有效的降权或模糊聚类机制, 导致LCK和FCM模型的分割失败。RLSF模型试图使用较小的迭代步长获得水平集函数的稳定迭代, 但概率噪声的特性使水平集函数极易被局部的不均匀性质干扰, 造成局部的误分割。但由于噪声分布的方差处于相对较低的水平, 各模型在对噪声点的误分割以外, 仍旧识别了期望的目标轮廓, 即水平集函数在噪声点处的取值在±0附近波动, 而期望的目标轮廓两侧函数值则具有较大的差异, 体现为误分割结果与目标轮廓间的空白。在中等强度的高斯噪声环境下 (噪声强度0.1) , 由于噪声分布的方差变大, 使得噪声图像与原始图像的差异值相对增加, LCK模型和FCM模型基于聚类和相关性系数的降权机制生效, 减小了局部误分割的概率, 体现为全局范围内误分割结果的降低。但随着噪声强度进一步升高, 传统的噪声鲁棒方法对邻域内多个像素点进行降权, 损失了较多的图像信息, 最终导致模型在全局范围内出现较为严重的误分割。本文模型基于像素值、分割轮廓两侧的邻域灰度均值等图像特征构建的One-class SVM离群程度检测方法, 将上述图像特征数据映射至高维空间中, 并构建一个尽可能紧密包裹数据的超球面, 而异常数据位于超球面以外, 受高斯噪声污染越严重的像素点, 与局部其他像素点的差异越大, 与超球面的距离越远。因此在弱噪声环境下, 本文模型对异常值的灵敏检测, 有效降低了异常点对能量泛函的干扰, 确保分割迭代的正常运行。强噪声环境下, One-class SVM方法中包含的偏置项使降权机制可有效适应局部噪声均值非0的情况, 并且为邻域内大多数像素点赋予较高的权重, 即倾向使用大范围内的平均灰度数据引导目标轮廓的分割。上述机制使得本文模型对高斯噪声和自然图像背景或目标区域内的干扰信息不敏感, 可获得理想且稳定的分割结果。</p>
                </div>
                <div class="p1">
                    <p id="129">原始图像像素值位于[<i>p</i><sub>min</sub>, <i>p</i><sub>max</sub>]范围内, <i>p</i><sub>min</sub>≥0, <i>p</i><sub>max</sub>≤255。以椒盐噪声为代表的极值脉冲噪声实质上是从图像域内所有像素点中, 随机选取一部分像素点, 其值被替换为<i>p</i><sub>min</sub>或<i>p</i><sub>max</sub>。与服从概率分布、随机修改图像域内每一个像素点的高斯噪声相比, 被椒盐噪声污染的图像只丢失了一部分图像信息。但椒盐噪声点与局部灰度均值的差异较大, 极易干扰能量泛函的最小化过程。这一特性导致局部模型倾向将噪声点识别为与邻域大多数像素点不同的类别, 体现为误分割或过分割。与LBF模型相比, LCK和FCM模型的降权机制对椒盐噪声具有一定适应能力, 在弱噪声环境下降低了噪声点对分割过程的干扰;但随着噪声强度增加, 邻域内正常像素点的数量减少, 上述模型的降权机制使得模型中邻域均值的计算依赖于极少数像素点, 因而出现误分割的结果。RLSF模型较小的迭代步长使模型对弱边界和非均值图像具有较好的适应能力的同时, 也使模型容易被噪声干扰, 陷入局部极小值而无法脱离, 最终在全图像域上出现误分割。本文方法基于SVM构建的离群程度检测机制, 在弱噪声环境下对异常值进行更为强烈的降权。在强噪声环境下, 虽然噪声点的密度较高, 但邻域内像素的平均值依然保留着部分图像信息。本文模型尽可能全面地利用图像信息, 得到更为合理的邻域均值, 并引导分割轮廓向期望的目标运动, 最终在噪声环境下得到了较为理想的分割结果。相关量化对比分值, 如图10所示。</p>
                </div>
                <div class="p1">
                    <p id="130">本段实验对各模型运算耗时进行了统计, 即从运算代码初始化完成, 迭代函数开始第一次迭代时起开始计时, 至分割轮廓不再显著变化, 两次迭代状态之间差异小于阈值时停止计时。各对比模型运算用时如表2所示, 本节涉及实验均在Lenovo台式机 (i3-4170 CPU, 4G RAM) 上使用Matlab R2018a完成。可以发现, 图像噪声对于各模型收敛速度影响相对不显著, 无论能否准确分割目标, 各模型均能在一定时间后收敛。其中, 仅计算邻域均值的LBF模型用时最短, 采用较小迭代步长的RLSF模型达到稳定收敛状态所需的时间远大于其他模型, 本文方法与LCK模型、FCM模型用时接近。这是由于LCK模型和FCM模型是在LBF模型的基础上, 对邻域内像素点进行加权, 单次迭代中因计算邻域权值导致的额外运算量与计算邻域均值的运算量接近。而本文方法虽然引入了运算更为复杂的One-class SVM异常值检测机制, 但该检测机制对数据的鲁棒性允许降权机制与分割模型的迭代计算异步进行, 即经过分割轮廓变化相对较小的若干次迭代后, 重新在整个图像范围内进行一次异常值检测机制的运算, 而无需在每次迭代中针对每一个像素点所属的所有邻域计算权值。此外, 在基于One-class SVM的降权机制指引下, 本文模型达到稳定收敛所需的迭代步数也少于对比模型。因此, 与LCK和FCM等基于降权思想的噪声鲁棒模型相比, 本文模型综合耗时并未显著增加。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 椒盐噪声环境下自然图像的分割结果对比" src="Detail/GetImg?filename=images/JSJY201903043_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 椒盐噪声环境下自然图像的分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Segmentation result comparison of natural images in salt-and-pepper noise environment</p>

                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 各椒盐噪声强度下各模型F1-score分值图" src="Detail/GetImg?filename=images/JSJY201903043_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 各椒盐噪声强度下各模型<i>F</i><sub>1</sub>-<i>score</i>分值图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 <i>F</i><sub>1</sub>-<i>score</i> of segmentation results of salt-and-pepper noisy image by different models</p>

                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表</b>2 <b>不同模型收敛耗时</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Convergence time of different models </p>
                    <p class="img_note"> s</p>
                    <table id="133" border="1"><tr><td rowspan="2"><br />噪声<br />强度</td><td colspan="5"><br />模型名称</td></tr><tr><td><br />LBF</td><td>LCK</td><td>FCM</td><td>RLSF</td><td>本文方法</td></tr><tr><td><br />0.1</td><td>2.394</td><td>4.342</td><td>4.367</td><td>8.367</td><td>4.468</td></tr><tr><td><br />0.2</td><td>2.717</td><td>4.309</td><td>4.281</td><td>8.280</td><td>4.420</td></tr><tr><td><br />0.3</td><td>2.866</td><td>4.623</td><td>4.284</td><td>8.284</td><td>4.514</td></tr><tr><td><br />0.4</td><td>2.862</td><td>4.847</td><td>4.776</td><td>8.076</td><td>4.486</td></tr><tr><td><br />0.5</td><td>2.878</td><td>4.839</td><td>4.960</td><td>8.160</td><td>4.495</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">3.3 <b>混合噪声图像</b></h4>
                <div class="p1">
                    <p id="135">在叠加高斯噪声的人工合成图像与叠加椒盐噪声的自然图像上分别进行的分割实验, 证实本文方法与传统噪声鲁棒分割模型相比, 具有更强的噪声适应能力与分割稳定性。为更好地展现本文模型对图像噪声的鲁棒性, 本节实验从Weizmann Horse Database自然图像数据集<citation id="207" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>中随机选取25幅自然图像, 统一将图像尺寸调整至256 px×256 px, 叠加多种强度的混合噪声, 并使用骰子相似系数法 (Dice Similarity Coefficient, DSC) 和分割错误比 (Ratio of Segmentation Error, RSE) 与参考分割结果进行定量比较。DSC与RSE定义如式:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mi>S</mi><mi>C</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><mo>∩</mo><mi>S</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mrow><mrow><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>+</mo><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mrow><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mo>!</mo><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>S</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>+</mo><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><mo>∩</mo><mo stretchy="false"> (</mo></mstyle><mo>!</mo><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>A</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false"> (</mo><mi>Ω</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">其中:<i>Area</i> (<i>S</i>) 表示<i>S</i>区域包含的像素个数, 即<i>S</i>区域的面积, <i>S</i><sub>1</sub>, <i>S</i><sub>2</sub>分别表示模型分割结果与基准分割结果中的前景目标区域。实验结果中, 模型分割结果越接近基准分割结果, 则<i>DSC</i>值越接近1, <i>RSE</i>值越接近0, 代表模型分割精度越高。</p>
                </div>
                <div class="p1">
                    <p id="138">图11展示了本文模型在不同强度组合的概率极值混合噪声环境下, 对自然图像的分割结果。可以发现, 在弱混合噪声环境下, 本文模型的表现出色, 对噪声具有较强的鲁棒性;在强椒盐噪声与弱高斯噪声的环境下, 仍可以实现较为理想的分割结果, 这是由于本文模型基于One-class SVM的异常值检测机制仍然可以有效判别被椒盐噪声污染的极值点, 而分割模型的邻域均值计算机制基于高斯核函数, 结合异常值检测的权值, 可以在一定强度范围内适应高斯噪声并平滑椒盐噪声, 保留了大部分图像信息为分割提供了依据;在弱椒盐噪声与强高斯噪声环境下, 极值噪声对异常值检测机制造成影响, 同时高斯噪声强度超出了高斯核函数的适应能力, 因此分割结果中出现了少量误分割区域, 但未严重影响主要目标的分割精度;在实际应用中出现概率较低、人眼也很难判别目标区域的强混合噪声环境下, 噪声严重干扰了图像信息, 本文模型的分割轮廓形态受到较为严重的影响, 出现过分割与误分割的现象, 但仍能识别大部分边缘形状平滑的目标区域。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 混合噪声环境下自然图像的分割结果对比" src="Detail/GetImg?filename=images/JSJY201903043_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 混合噪声环境下自然图像的分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Segmentation result comparison of natural images in mixed noise environment</p>

                </div>
                <div class="p1">
                    <p id="140">图12展示了上述分割结果的量化分值, 即DSC与RSE。其中每一条折线包含25个数据点, 分别对应25个噪声强度组合下的分割分值。其中, 数据点按横轴方向排列, 并以纵轴方向代表该噪声强度下的分割精度。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903043_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 混合噪声环境下自然图像的量化分值对比" src="Detail/GetImg?filename=images/JSJY201903043_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 混合噪声环境下自然图像的量化分值对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903043_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 Quantitative score comparison of natural images in mixed noise environment</p>

                </div>
                <h3 id="142" name="142" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="143">本文提出一种新的噪声图像分割模型, 根据基于One-class SVM离群程度检测机制的图像噪声检测方法, 在强噪声环境下对图像噪声实现更为合理的降权, 增强了分割模型对噪声的鲁棒性。One-class SVM具有将数据映射到高维空间的能力, 并总是试图寻找一个紧密包裹数据的超球面。本文方法将位于球面内的数据视作正常数据, 反之则为异常, 与球面距离越远的数据点, 其离群程度越高, 得到的权值也越小。此外, One-class SVM方法属于机器学习方法, 相比于传统的相关性降权方法, 其适应性和灵活性更强。与传统噪声鲁棒模型相比, 本文模型的降权机制在强噪声环境下更加合理, 同时在弱噪声环境下加强了对异常点的惩罚。最后, 本文通过多组实验定量分析验证了本文模型相对于其他模型在处理噪声图像时的优越性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="163">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830144&amp;v=MzA0MzhveGNNSDdSN3FkWitadUZpL2xVci9MSkZ3PU5qN0Jhck80SHRIT3A0eEZaZThMWTNrNXpCZGg0ajk5U1hxUnJ4&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>KASS M, WITKIN A, TERZOPOULOS D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Active contour without edges">

                                <b>[2]</b>CHAN T F, VESE L A.Active contour without edges[J].IEEETransactions on Image Processing, 2001, 10 (2) :266-277.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Implicit Active Contours Driven by Local Binary Fitting Energy">

                                <b>[3]</b>LI C, KAO C-Y, GORE J C, et al.Implicit active contours driven by local binary fitting energy[C]//CVPR 2007:Proceedings of the2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2007:1-7
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738565&amp;v=MjI0Njg2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSUlWNFhiaEE9TmlmT2ZiSzdIdEROcVk5RlkrZ0hDWG84b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>ZHANG K, SONG H, ZHANG L.Active contours driven by local image fitting energy[J].Pattern Recognition, 2010, 43 (4) :1199-1206.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600107321&amp;v=MjA4NDRyUmRHZXJxUVRNbndaZVp0RmlubFVyaklJVjRYYmhBPU5pZk9mYks4SHRETXFZOUZaZXNJRDM0NG9CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>WANG L, PAN C.Robust level set image segmentation via a local correntropy-based K-means clustering[J].Pattern Recognition, 2014, 47 (5) :1917-1925.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Robust level set image segmentation algorithm using local correntropy-based fuzzy cmeans clustering with spatial constraints.&amp;quot;">

                                <b>[6]</b>JIANG X-L, WANG Q, HE B, et al.Robust level set image segmentation algorithm using local correntropy-based fuzzy c-means clustering with spatial constraints[J].Neurocomputing, 2016, 207 (C) :22-35.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Level set evolution without re-initialization: A new variational formulation">

                                <b>[7]</b>LI C, XU C, GUI C, et al.Level set evolution without re-initialization:a new variational formulation[C]//CVPR'05:Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2005:430-436.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201802034&amp;v=MzIxNTZVTHZLTmlmWVpMRzRIOW5Nclk5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5bmw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>赵怡, 邓红霞, 张玲, 等.基于最大类间方差的权重自适应活动轮廓模型[J].计算机工程与设计, 2018, 39 (2) :486-491. (ZHAOY, DENG H X, ZHANG L, et al.Weight-self adjustment active contour model based on method of maximum classes square error[J].Computer Engineering and Design, 2018, 39 (2) :486-491.) 
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201805038&amp;v=MDkxNTVxcUJ0R0ZyQ1VSN3FmWnVacEZ5bmxVTHZLTHo3QmJiRzRIOW5NcW85R2JJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>李钢, 李海芳, 尚方信, 等.基于梯度信息的自适应邻域噪声图像分割模型[J].计算机工程, 2018, 44 (5) :227-233. (LI G, LI HF, SHANG F X, et al.Noise image segmentation model with adaptive neighborhood based on gradient information[J].Computer Engineering, 2018, 44 (5) :227-233.) 
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011964&amp;v=MDM3MzQ0WGJoQT1OaWZKWmJLOUh0ak1xbzlGWk9vT0JYbzlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyaklJVg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>SCHLKOPF B, PLATT J C, SHAWE-TAYLOR J, et al.Estimating the support of a high-dimensional distribution[J].Neural Computation, 2001, 13 (7) :1443-1471.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX201801005&amp;v=MjQwNTh2S0lUWEFkckc0SDluTXJvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>李昊奇, 应娜, 郭春生, 等.基于深度信念网络和线性单分类SVM的高维异常检测[J].电信科学, 2018, 34 (1) :34-42. (LIH Q, YING N, GUO C S, et al.High-dimensional outlier detection based on deep belief network and linear one-class SVM[J].Telecommunications Science, 2018, 34 (1) :34-42.) 
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017015903.nh&amp;v=MDIzNDBWRjI2R2JPNUc5ak1ySkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdks=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>杨成佳.图像去噪及其效果评估若干问题研究[D].长春:吉林大学, 2016:4-5. (YANG C J.Research on image denoising and its effect evaluation[D].Changchun:Jilin University, 2016:4-5.) 
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MNIST">

                                <b>[13]</b>Le CUN Y, BOTTOU L, BENGIO Y, et al.MNIST[DB/OL]. (2012-01-01) [2018-08-27].http://yann.lecun.com/exdb/mnist/.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weizmann Horse Database">

                                <b>[14]</b>BORENSTEIN E.Weizmann horse database[DB/OL]. (2005-01-19) [2018-08-27].http://www.msri.org/m/people/members/eranb/.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903043" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903043&amp;v=MzE4MDZHNEg5ak1ySTlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkxMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3Y1hydlZKcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
