<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136661677033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907004%26RESULT%3d1%26SIGN%3drL8X0a1sdLIsnfMChLU0xxGDvTM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907004&amp;v=MTM2OTNJOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwvTEx6N0JkN0c0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 脑电波信号测量和预处理 ">1 脑电波信号测量和预处理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="2 本研究提出的预测系统 ">2 本研究提出的预测系统</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="2.1 &lt;b&gt;脑电地形图视频&lt;/b&gt;">2.1 <b>脑电地形图视频</b></a></li>
                                                <li><a href="#63" data-title="2.2 &lt;b&gt;卷积神经网络模型&lt;/b&gt;">2.2 <b>卷积神经网络模型</b></a></li>
                                                <li><a href="#73" data-title="2.3 &lt;b&gt;长短期记忆神经网络模型&lt;/b&gt;">2.3 <b>长短期记忆神经网络模型</b></a></li>
                                                <li><a href="#84" data-title="2.4 &lt;b&gt;结合卷积神经网络与长短期记忆神经网络的预测模型&lt;/b&gt;">2.4 <b>结合卷积神经网络与长短期记忆神经网络的预测模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="3 实验结果和分析 ">3 实验结果和分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#96" data-title="3.1 &lt;b&gt;预测模型的结构和参数确定以及对比模型&lt;/b&gt;">3.1 <b>预测模型的结构和参数确定以及对比模型</b></a></li>
                                                <li><a href="#102" data-title="3.2 &lt;b&gt;消费者依赖模型的性能对比&lt;/b&gt;">3.2 <b>消费者依赖模型的性能对比</b></a></li>
                                                <li><a href="#109" data-title="3.3 &lt;b&gt;消费者独立模型性能对比&lt;/b&gt;">3.3 <b>消费者独立模型性能对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="图1 基于国际10- 20电极排列系统的脑电信号测量位置">图1 基于国际10- 20电极排列系统的脑电信号测量位置</a></li>
                                                <li><a href="#49" data-title="图2 实验中使用的具有不同外观和颜色的产品图片">图2 实验中使用的具有不同外观和颜色的产品图片</a></li>
                                                <li><a href="#61" data-title="图3 特定时间点的脑电地形图">图3 特定时间点的脑电地形图</a></li>
                                                <li><a href="#67" data-title="图4 3D CNN结构">图4 3D CNN结构</a></li>
                                                <li><a href="#83" data-title="图5 LSTM神经网络的结构">图5 LSTM神经网络的结构</a></li>
                                                <li><a href="#87" data-title="图6 本文结合3&lt;i&gt;D CNN&lt;/i&gt;与&lt;i&gt;LSTM&lt;/i&gt;神经网络的预测模型">图6 本文结合3<i>D CNN</i>与<i>LSTM</i>神经网络的预测模型</a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;候选模型的结构和参数&lt;/b&gt;"><b>表</b>1 <b>候选模型的结构和参数</b></a></li>
                                                <li><a href="#100" data-title="图7 四种候选模型的性能比较">图7 四种候选模型的性能比较</a></li>
                                                <li><a href="#106" data-title="图8 3&lt;i&gt;D CNN&lt;/i&gt;-&lt;i&gt;LSTM&lt;/i&gt;消费者依赖模型的准确度">图8 3<i>D CNN</i>-<i>LSTM</i>消费者依赖模型的准确度</a></li>
                                                <li><a href="#107" data-title="图9 消费者依赖模型的性能对比">图9 消费者依赖模型的性能对比</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;消费者独立模型的产品类型准确度对比&lt;/b&gt;"><b>表</b>2 <b>消费者独立模型的产品类型准确度对比</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;消费者独立模型的消费者人数准确度对比&lt;/b&gt;"><b>表</b>3 <b>消费者独立模型的消费者人数准确度对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="129">


                                    <a id="bibliography_1" title=" SOLEYMANI M, CHANEL G, KIERKELS J J, et al.Affective ranking of movie scenes using physiological signals and content analysis[C]// Proceedings of the 2nd ACM Workshop on Multimedia Semantics.New York:ACM, 2008:32-39." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Affective ranking of movie scenes using physiological signals and content analysis">
                                        <b>[1]</b>
                                         SOLEYMANI M, CHANEL G, KIERKELS J J, et al.Affective ranking of movie scenes using physiological signals and content analysis[C]// Proceedings of the 2nd ACM Workshop on Multimedia Semantics.New York:ACM, 2008:32-39.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_2" title=" TELPAZ A, WEBB R, LEVY D J.Using EEG to predict consumers&#39; future choices[J].Journal of Marketing Research, 2015, 52 (4) :511-529." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST4297CDF90B7D0B0E273643FA7B31C246&amp;v=MjczNDNJZUh4THoyTVI3VHg3VEh5VTNSVkhlclBuUjc2WkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3cTR3S289TmlmWWVyZTZGOWEvMi9sTVpKaw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         TELPAZ A, WEBB R, LEVY D J.Using EEG to predict consumers&#39; future choices[J].Journal of Marketing Research, 2015, 52 (4) :511-529.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_3" title=" AMBLER T, BRAEUTIGAM S, STINS J, et al.Salience and choice:neural correlates of shopping decisions[J].Psychology and Marketing, 2004, 21 (4) :247-261." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Salience and choice:neural correlates of shopping decisions">
                                        <b>[3]</b>
                                         AMBLER T, BRAEUTIGAM S, STINS J, et al.Salience and choice:neural correlates of shopping decisions[J].Psychology and Marketing, 2004, 21 (4) :247-261.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_4" title=" BALDO D, PARIKH H, PIU Y, et al.Brain waves predict success of new fashion products:a practical application for the footwear retailing industry[J].Journal of Creating Value, 2015, 1 (1) :61-71." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX40C9B7E24ED7EBF8E65DA752492339B0&amp;v=Mjk2MTI1dHBodzdxNHdLbz1OaWZDZHJlNGJkaStxUHBIWUo1N0N3bEx1UjVtN0RvSk9Yam5yaFk4ZTdHWFRNaWZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         BALDO D, PARIKH H, PIU Y, et al.Brain waves predict success of new fashion products:a practical application for the footwear retailing industry[J].Journal of Creating Value, 2015, 1 (1) :61-71.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_5" title=" KHUSHABA R N, GREENACRE L, KODAGODA S, et al.Choice modeling and the brain:a study on the electroencephalogram (EEG) of preferences[J].Expert Systems with Applications, 2012, 39 (16) :12378-12388." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501637339&amp;v=Mjc5Nzg0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMXdUYWhBPU5pZk9mYks3SHRETnFvOUVZdWdJRDM4d29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         KHUSHABA R N, GREENACRE L, KODAGODA S, et al.Choice modeling and the brain:a study on the electroencephalogram (EEG) of preferences[J].Expert Systems with Applications, 2012, 39 (16) :12378-12388.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_6" title=" MURUGAPPAN M.Wireless EEG signals based neuromarketing system using fast Fourier transform (FFT) [C]// CSPA 2014:Proceedings of the 10th International Colloquium on Signal Processing and Its Applications.Piscataway, NJ:IEEE, 2014:25-30." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wireless EEG signals based neuromarketing system using fast Fourier transform (FFT)">
                                        <b>[6]</b>
                                         MURUGAPPAN M.Wireless EEG signals based neuromarketing system using fast Fourier transform (FFT) [C]// CSPA 2014:Proceedings of the 10th International Colloquium on Signal Processing and Its Applications.Piscataway, NJ:IEEE, 2014:25-30.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_7" title=" BOKSEM M A, SMIDTS A.Brain responses to movie trailers predict individual preferences for movies and their population-wide commercial success[J].Journal of Marketing Research, 2015, 52 (4) :482-492." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST7FF87716A9C21FEDB1622E11D0620D72&amp;v=MjI0NjZKOERuMVB1bUpoNnpsL1NncmpyV1kxZjdDVU1iMmRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3E0d0tvPU5pZlllclRPYU5uTHFJNURGZQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         BOKSEM M A, SMIDTS A.Brain responses to movie trailers predict individual preferences for movies and their population-wide commercial success[J].Journal of Marketing Research, 2015, 52 (4) :482-492.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_8" title=" KAWASAKI M, YAMAGUCHI Y.Effects of subjective preference of colors on attention-related occipital theta oscillations[J].Neuroimage, 2012, 59 (1) :808-814." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501197426&amp;v=MDU3NzVUYWhBPU5pZk9mYks3SHRETnFvOUVaZUlJQ0g0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxdw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         KAWASAKI M, YAMAGUCHI Y.Effects of subjective preference of colors on attention-related occipital theta oscillations[J].Neuroimage, 2012, 59 (1) :808-814.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_9" title=" FAUST O, HAGIWARA Y, HONG T J, et al.Deep learning for healthcare applications based on physiological signals:A review[J].Computer Methods and Programs in Biomedicine, 2018, 161:1-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES769E0760D5156E7C626E3E6F8FE26EF4&amp;v=MDQ4NTVHUWxmQnJMVTA1dHBodzdxNHdLbz1OaWZPZmJTK0Y2VE1xSWxGRU80T0NYcE15R1VWNkRrSVN3cmsyaHBERExDU01NeWJDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         FAUST O, HAGIWARA Y, HONG T J, et al.Deep learning for healthcare applications based on physiological signals:A review[J].Computer Methods and Programs in Biomedicine, 2018, 161:1-13.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_10" title=" SHU L, XIE J Y, YANG M Y, et al.A review of emotion recognition using physiological signals[J].Sensors, 2018, 18 (7) :2074." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A review of emotion recognition using physiological signals">
                                        <b>[10]</b>
                                         SHU L, XIE J Y, YANG M Y, et al.A review of emotion recognition using physiological signals[J].Sensors, 2018, 18 (7) :2074.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_11" title=" LIANG J W, CHAUDHURI S R, SHINOZUKA M.Simulation of nonstationary stochastic processes by spectral representation[J].Journal of Engineering Mechanics, 2007, 133 (6) :616-627." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCE&amp;filename=SJCE322459B9C864FF7F99EE988ABF6DA0BB&amp;v=MDY0MDY3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3cTR3S289TmlmSWE3QzZITlhKcHYxTUYrTUpDQXBQeUdBYTQwb0lRWGZxM1dCRGY4YmxSY2p0Q09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         LIANG J W, CHAUDHURI S R, SHINOZUKA M.Simulation of nonstationary stochastic processes by spectral representation[J].Journal of Engineering Mechanics, 2007, 133 (6) :616-627.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_12" title=" HUANG G Q, SU Y W, KAREEM A, et al.Time-frequency analysis of nonstationary process based on multivariate empirical mode decomposition[J].Journal of Engineering Mechanics, 2016, 142 (1) :04015065." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCE&amp;filename=SJCE15062400000026&amp;v=MjU1ODdQREg0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxd1RhaEE9TmlmSWE3SzlIdGZPcTQ5RlpPcw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         HUANG G Q, SU Y W, KAREEM A, et al.Time-frequency analysis of nonstationary process based on multivariate empirical mode decomposition[J].Journal of Engineering Mechanics, 2016, 142 (1) :04015065.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_13" title=" Mathworks Inc.Griddata function description[EB/OL].[2018- 11- 20].https://ww2.mathworks.cn/help/matlab/ref/griddata.html." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Griddata function description">
                                        <b>[13]</b>
                                         Mathworks Inc.Griddata function description[EB/OL].[2018- 11- 20].https://ww2.mathworks.cn/help/matlab/ref/griddata.html.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_14" title=" TRAN D, BOURDEV L, FERGUS R, et al.Learning spatiotemporal features with 3D convolutional networks[C]// ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4489-4497." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning spatiotemporal features with 3dconvolutional networks">
                                        <b>[14]</b>
                                         TRAN D, BOURDEV L, FERGUS R, et al.Learning spatiotemporal features with 3D convolutional networks[C]// ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4489-4497.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_15" title=" 孔祥浩, 马琳, 李海峰, 等.CNN与CSP相结合的脑电特征提取与识别方法研究[J].信号处理, 2018, 34 (2) :164-173. (KONG X H, MA L, LI H F, et al.Research on EEG feature extraction and recognition method based on CNN and CSP[J].Journal of Signal Processing, 2018, 34 (2) :164-173.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201802006&amp;v=MTYxNDFUWElZTEc0SDluTXJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwvS1A=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         孔祥浩, 马琳, 李海峰, 等.CNN与CSP相结合的脑电特征提取与识别方法研究[J].信号处理, 2018, 34 (2) :164-173. (KONG X H, MA L, LI H F, et al.Research on EEG feature extraction and recognition method based on CNN and CSP[J].Journal of Signal Processing, 2018, 34 (2) :164-173.) 
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_16" title=" 谢逸, 饶文碧, 段鹏飞, 等.基于CNN和LSTM混合模型的中文词性标注[J].武汉大学学报 (理学版) , 2017, 63 (3) :246-250. (XIE Y, RAO W B, DUAN P F, et al.A Chinese POS tagging approach using CNN and LSTM-based hybrid model[J].Wuhan University Journal of Natural Sciences, 2017, 63 (3) :246-250.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHDY201703009&amp;v=MTY1MzA1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZML0tNaVhQZDdHNEg5Yk1ySTlGYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         谢逸, 饶文碧, 段鹏飞, 等.基于CNN和LSTM混合模型的中文词性标注[J].武汉大学学报 (理学版) , 2017, 63 (3) :246-250. (XIE Y, RAO W B, DUAN P F, et al.A Chinese POS tagging approach using CNN and LSTM-based hybrid model[J].Wuhan University Journal of Natural Sciences, 2017, 63 (3) :246-250.) 
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_17" title=" GREFF K, SRIVASTAVA R K, KOUTN&#237;K J, et al.LSTM:a search space odyssey[J].IEEE Transactions on Neural Networks and Learning Systems, 2015, 28 (10) :2222-2232." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LSTM:A Search Space Odyssey">
                                        <b>[17]</b>
                                         GREFF K, SRIVASTAVA R K, KOUTN&#237;K J, et al.LSTM:a search space odyssey[J].IEEE Transactions on Neural Networks and Learning Systems, 2015, 28 (10) :2222-2232.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_18" title=" GERS F A, ECK D, SCHMIDHUBER J.Applying LSTM to time series predictable through time-window approaches[C]// ICANN 2001:Proceedings of the 10th International Conference on Artificial Neural Networks.Berlin:Springer, 2001:21-25." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Applying LSTM to time series predictable through time-window approaches">
                                        <b>[18]</b>
                                         GERS F A, ECK D, SCHMIDHUBER J.Applying LSTM to time series predictable through time-window approaches[C]// ICANN 2001:Proceedings of the 10th International Conference on Artificial Neural Networks.Berlin:Springer, 2001:21-25.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-19 15:16</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),1888-1893 DOI:10.11772/j.issn.1001-9081.2019010061            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>消费者偏好预测的深度学习神经网络模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%87%91%E5%BF%A0%E6%98%9F&amp;code=42202178&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金忠星</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%B8%9C&amp;code=06988254&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李东</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%93%88%E5%B0%94%E6%BB%A8%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E7%BB%8F%E6%B5%8E%E4%B8%8E%E7%AE%A1%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=0149444&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">哈尔滨工业大学经济与管理学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%91%E7%AD%96%E5%B7%A5%E4%B8%9A%E7%BB%BC%E5%90%88%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0005843&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金策工业综合大学自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>通过对于人类大脑活动的研究来分析消费者对广告和产品的反应的神经营销正在受到新的关注。针对基于脑电波 (EEG) 的神经营销, 提出了一种基于深度学习神经网络的消费者对产品的偏好预测方法。首先, 为了提取消费者EEG的特征, 采用短时傅里叶变换 (STFT) 与双调和样条插值, 从多通道脑电信号中得到了5个不同频带的EEG形图视频;然后, 提出了一种结合5个三维卷积神经网络 (3D CNN) 与多层长短期记忆 (LSTM) 神经网络的预测模型, 用于从脑电地形图视频预测到消费者的偏好。与卷积神经网络 (CNN) 模型和LSTM神经网络模型相比, 消费者依赖模型的平均准确度分别提高了15.05个百分点和19.44个百分点, 消费者独立模型的平均准确度分别提高了16.34个百分点和17.88个百分点。理论分析与实验结果表明, 所提出的消费者偏好预测系统可以以低成本提供有效的营销策略开发和营销管理。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E8%90%A5%E9%94%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经营销;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%84%91%E7%94%B5%E5%9C%B0%E5%BD%A2%E5%9B%BE%E8%A7%86%E9%A2%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">脑电地形图视频;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    金忠星 (1984—) , 男, 朝鲜平壤人, 博士研究生, 主要研究方向:深度学习、脑机接口;;
                                </span>
                                <span>
                                    *李东 (1958—) , 男, 黑龙江哈尔滨人, 教授, 博士, 主要研究方向:企业经济学、人力资源管理、市场营销。电子邮箱sxlidong@yahoo.com.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61301012, 61401117, 61471140);</span>
                    </p>
            </div>
                    <h1><b>Deep learning neural network model for consumer preference prediction</b></h1>
                    <h2>
                    <span>KIM Chungsong</span>
                    <span>LI Dong</span>
            </h2>
                    <h2>
                    <span>School of Management, Harbin Institute of Technology</span>
                    <span>School of Automation, Kimchaek University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Neuromarketing, by which consumer responses to advertisements and products are analyzed through research on human brain activity, is receiving new attention. Aiming at neuromarketing based on ElectroEncephaloGraphy (EEG) , a method of consumer preference prediction based on deep learning neural network was proposed. Firstly, in order to extract features of consumer's EEG, five different frequency bands of EEG topographic videos were obtained from multi-channel EEG signals by using Short Time Fourier Transform (STFT) and biharmonic spline interpolation. Then, a prediction model combining five three-Dimensional Convolutional Neural Networks (3 D CNNs) and multi-layer Long Short-Term Memory (LSTM) neural networks was proposed for predicting consumer preference from EEG topographic videos. Compared with the Convolutional Neural Network (CNN) model and LSTM neural network model, the average accuracy of consumer-dependence model was increased by 15.05 percentage points and 19.44 percentage points respectively, and the average accuracy of consumer-independence model was increased by 16.34 percentage points and 17.88 percentage points respectively. Theoretical analysis and experimental results show that the proposed consumer preference prediction system can provide effective marketing strategy development and marketing management at low cost.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20Convolutional%20Neural%20Network%20(3D%20CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D Convolutional Neural Network (3D CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20Short-Term%20Memory%20(LSTM)%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long Short-Term Memory (LSTM) neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neuromarketing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neuromarketing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ElectroEncephaloGraphy%20(EEG)%20topographic%20video&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ElectroEncephaloGraphy (EEG) topographic video;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    KIM Chungsong, born in 1984, Ph. D. candidate. His research interests include deep learning, brain-computer interface. ;
                                </span>
                                <span>
                                    LI Dong, born in 1958, Ph. D. , professor. His research interests include business economics, human resource management, marketing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-10</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61301012, 61401117, 61471140);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">准确了解消费者想要什么以及消费者愿意做什么, 对每家公司来说既是渴望又是挑战, 因此, 许多公司在消费者研究方面投入了大量资金, 以提前掌握消费者对产品或广告的反应。然而, 与由于各种原因 (包括消费者和社会关系的主观感受) 导致的公司所花费的成本和时间相比, 传统的研究技术 (例如焦点小组访谈和调查) 往往未能提供令人满意的结果。</p>
                </div>
                <div class="p1">
                    <p id="41">最近, “神经营销”作为克服传统消费者研究局限的更科学的研究技术而备受关注。神经营销, 是人类大脑生物学研究中的神经和商业营销的结合名词。它通过测量消费者的大脑活动, 分析大脑活动信息 (如无意识反应等) , 进而了解消费者的心理和行为, 并将其应用于营销。在21世纪, 先进的高级工程技术应用于脑生理学领域, 这使人们能够通过开发安全的大脑活动测量装置来测量大脑活动信息, 创造了一种研究消费者意识的新分析方法。通过这种方法, 公司在投入大量营销成本之前, 能够定量地测量产品或广告对消费者潜意识的影响。</p>
                </div>
                <div class="p1">
                    <p id="42">近年来, 如功能磁共振成像 (functional Magnetic Resonance Imaging, fMRI) 、脑磁图 (MagnetoEncephaloGraphy, MEG) 和脑电波 (ElectroEncephaloGraph, EEG) 的测量装置已经频繁用于神经营销。一项研究利用fMRI数据分析了27名青少年的大脑活动, 并预测了音乐的受欢迎度, 该研究结果显示参与者的大脑反应与三年后的销售量成正比。然而, 这些实验的成本是巨大的, 并且由于诸如保险、维护和可移植性问题之类的额外成本, 在神经营销中使用fMRI是有限的。MEG用于捕获由神经元活动引起的大脑活动。这种神经元活动产生的磁场由MEG通过时空信息放大和映射。然而, 由于成本较高、技术复杂并且皮层下区域的成像访问受限, 因此不优选作为开发神经营销系统的装置。与fMRI和MEG相比, 脑电波测量装置便宜, 不限制电极的数量, 易于操作, 易于携带, 维护成本低得多, 同时提供高时间分辨率, 因此, 本研究专注于使用脑电信号来分析大脑活动信息, 并对消费者产品偏好进行分类和预测<citation id="165" type="reference"><link href="129" rel="bibliography" /><link href="131" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">目前, 使用脑电波信号的神经营销研究已取得一定成果。有一些研究者发现消费者对产品的脑电波与消费者购买决策之间存在相关关系, 因此得到采用脑电波方法的利润增长率几乎是问卷调查方法三倍的研究结论<citation id="166" type="reference"><link href="133" rel="bibliography" /><link href="135" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。在研究中, 有学者提出了通过使用主成分分析或带通滤波器进行预处理并进行傅里叶变换来定量计算消费者偏好和脑电波频带之间的相关性的方法<citation id="167" type="reference"><link href="137" rel="bibliography" /><link href="139" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。此外, 一些学者还提出了消费者偏好预测框架来预测消费者对颜色和视频的情绪状态<citation id="168" type="reference"><link href="141" rel="bibliography" /><link href="143" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">根据以往的研究结果, 本研究开发了一种基于深度学习神经网络从消费者脑电信号功率谱密度预测产品偏好的新方法。近来, 作为人工智能的机器学习领域的深度学习已经成功地应用于各种领域, 例如计算机视觉、图像和视频分类、预测、语音识别、自然语言处理、网络搜索和自主导航。当然, 在脑电图研究领域也有许多研究使用深度学习<citation id="169" type="reference"><link href="145" rel="bibliography" /><link href="147" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。本研究的目的是提出一种神经营销框架, 通过分析脑电波信号来预测消费者对电子商务产品的偏好。该研究首先使用短时傅里叶变换 (Short Time Fourier Transform, STFT) 来计算多通道脑电波信号的功率谱密度, 并且用双调和样条插值 (Biharmonic spline interpolation) 从多通道脑电波信号功率谱密度来作出脑电地形图。由于脑电地形图是圆形的, 因此没有数值的非数区域存在脑电地形图矩阵的四个角中。这些脑电地形图随时间排列的话, 它变成与视频类似的三维格式, 称为脑电地形图视频。从5个频带中得到的5个脑电地形图视频分别输入到5个三维卷积神经网络 (3D Convolutional Neural Network, 3D CNN) 。为了处理脑电地形图的非数区域, 定义面膜层并将其插入到卷积层与池化层之间。将5个卷积神经网络 (Convolutional Neural Network, CNN) 的结果连接成一个矩阵, 接着将其输入到长短期记忆 (Long Short-Term Memory, LSTM) 神经网络。在这里, 卷积神经网络用作特征学习端, 用于从5个频带的消费者功率谱密度脑电地形图视频中提取特征, 并且长短期记忆神经网络作用于得到的特征预测消费者的产品偏好的分类端。通过实验过程和结果, 确定了结合三维卷积神经网络和长短期记忆神经网络的预测模型的结构参数, 并与其他预测方法进行了准确度对比。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 脑电波信号测量和预处理</h3>
                <div class="p1">
                    <p id="46">如图1所示, 根据国际10- 20电极放置方案, 在32个电极位置上测量脑电波信号。32个电极的位置如下:FP1、FP2、AF3、AF4、Fz、F3、F4、F7、F8、FC1、FC2、FC5、FC6、Cz、C3、C4、T7、T8、CP1、CP2、CP5、CP6、Pz、P3、P4、P7、P8、PO3、PO4、Oz、O1、O2。测量的脑电波信号以1 024 Hz采样并发送到电脑。在电脑中, 脑电波信号再次被下采样到128 Hz并通过50 Hz巴特沃斯 (Butterworth) 低通滤波器。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于国际10- 20电极排列系统的脑电信号测量位置" src="Detail/GetImg?filename=images/JSJY201907004_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于国际10- 20电极排列系统的脑电信号测量位置  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_047.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 EEG signal detection positions based on international 10- 20 electrode array system</p>

                </div>
                <div class="p1">
                    <p id="48">在该实验中, 20名年龄在18至40岁之间的男女消费者 (13名男性和7名女性) 自愿参加。产品图片在电脑屏幕上显示4秒钟, 消费者就所显示的产品选择“喜欢”或“不喜欢”。电脑屏幕上显示的产品如图2所示。如图中所示, 6种类型的产品选择了3种不同颜色和不同形式的样本。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_049.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 实验中使用的具有不同外观和颜色的产品图片" src="Detail/GetImg?filename=images/JSJY201907004_049.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 实验中使用的具有不同外观和颜色的产品图片  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_049.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Images of products with different appearances and colors used in experiment</p>

                </div>
                <h3 id="50" name="50" class="anchor-tag">2 本研究提出的预测系统</h3>
                <div class="p1">
                    <p id="51">在本章中, 本文叙述了使用短时傅里叶变换和双调和样条插值<citation id="170" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 作出5个频带功率谱密度脑电地形图视频的预处理过程, 然后提出了构建预测模型的过程。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">2.1 <b>脑电地形图视频</b></h4>
                <div class="p1">
                    <p id="53">正如在引言中已经提到的, 许多研究人员已经研究并建议消费者对产品的偏好可以引起脑电波信号频带的变化, 因此, 本研究感兴趣的是脑电波信号的功率谱密度作为研究中预测模型的输入数据。功率谱密度可以通过短时傅里叶变换获得。短时傅里叶变换是用于利用窗函数表示非平稳信号的时频分布的时频分析方法。短时间傅里叶变换的计算方法是将长时间信号分成相同长度的窗段, 然后分别在每个窗段上计算傅里叶变换<citation id="171" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。信号<i>s</i> (<i>t</i>) 的短时间傅里叶变换<i>F</i> (<i>τ</i>, <i>ω</i>) 定义为;</p>
                </div>
                <div class="p1">
                    <p id="54"><i>F</i> (<i>τ</i>, <i>ω</i>) =∫<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo>-</mo><mi>∞</mi></mrow><mrow><mo>+</mo><mi>∞</mi></mrow></msubsup></mrow></math></mathml><i>s</i> (<i>t</i>) <i>h</i> (<i>t</i>-<i>τ</i>) e<sup>-j<i>ωt</i></sup> d<i>t</i>      (1) </p>
                </div>
                <div class="p1">
                    <p id="56">其中, <i>h</i> (<i>t</i>) 是窗函数, 通常使用哈明 (Hamming) 窗函数或汉宁 (Hanning) 窗函数。短时间傅里叶变换<i>F</i> (<i>τ</i>, <i>ω</i>) 的功率谱密度<i>P</i> (<i>τ</i>, <i>ω</i>) 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>ω</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>ω</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">从上面的公式中可以看出, 通过沿着输入信号时间轴移动窗来计算每个窗段的傅里叶变换。在短时间傅里叶变换的功率谱密度中, 更宽的窗函数导致更好的频率分辨率, 并且更窄的窗函数导致更好的时间分辨率<citation id="172" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。该研究中, 窗的长度和相邻窗之间的交叠长度分别设置为128和120, 并且使用哈明窗函数。</p>
                </div>
                <div class="p1">
                    <p id="59">脑电波信号具有时间、频率和空间特征, 空间特征反映了头皮上的电极位置。通用脑电波信号分类预测方法从多通道脑电波信号中提取特征并应用分类预测算法。该研究试图基于电极的位置制作脑电地形图。当脑电地形图随着时间排列时, 最终获得脑电地形图视频。脑电地形图视频可以显示头皮上脑电波信号的功率谱密度如何随时间变化。为了作出脑电地形图, 将Cz电极位置设定为极坐标系的中心点, 并将剩余的31个电极位置相对排列。</p>
                </div>
                <div class="p1">
                    <p id="60">然后, 这32个电极的位置矢量被转换成正交坐标系的位置矢量。将双调和样条插值<citation id="173" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>应用于32个正交坐标系上的坐标点处的脑电信号功率谱密度, 并在41×41网格上绘制脑电地形图。通过在每个时间点重复该过程来获取脑电地形图视频。通常, 根据频带将脑电波信号分为δ波 (0～4 Hz) 、θ波 (4～8 Hz) 、α波 (8～13 Hz) 、β波 (13～30 Hz) 和λ波 (30～50 Hz) , 因此, 计算每个频带中的功率谱密度的总和来获得5个频带的脑电地形图视频。当从4 s的脑电波信号生成脑电地形图视频时, 该脑电地形图视频由41×41×49矩阵数据表示。其中49是时间点数。该脑电地形图视频在[-1, +1]区间缩放并输入到神经网络输入层。图3显示0.5、1.5、2.5和3.5 s时间点的脑电地形图。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 特定时间点的脑电地形图" src="Detail/GetImg?filename=images/JSJY201907004_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 特定时间点的脑电地形图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 EEG topography at specific points in time</p>

                </div>
                <div class="p1">
                    <p id="62">如图3所示, 在41×41网络上绘制的脑电地形图具有圆形形状, 四个角上的空白区域是没有数值的区域。将此区域定义为非数区域。该研究中, 为了便于在神经网络中进行计算, 非数区域用0填充。当输入数据通过神经网络的每个层时, 在非数区域中可以生成非零值, 并且这些非数区域的非零值可以影响后层的计算, 因此, 每当在非数区域中生成非零值时, 就必须将其除去。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">2.2 <b>卷积神经网络模型</b></h4>
                <div class="p1">
                    <p id="64">卷积神经网络 (CNN) 是在人类神经系统中提出的非常有用的神经网络, 并且在各种应用中表现出优异的性能。卷积神经网络是一种分层结构, 在卷积层和池化层交错时提取入口数据的特征。</p>
                </div>
                <div class="p1">
                    <p id="65">卷积层通过滑动窗口方式从输入数据中提取特征, 该方式实现表示数据特征的特征映射。执行特征映射的卷积内核的权重在卷积层中共享, 并且本地链接到输入数据。池化层通过卷积层中的特征映射的平均池化或最大池化来减小输出维度的大小, 因此, 可以忽略诸如输入数据中的精细移位或失真的变化。在卷积神经网络的最终结构中, 神经网络完全连接并输出到一维向量。卷积神经网络包括一维、二维和三维的卷积神经网络, 通常, 一维应用于序列数据, 二维应用于图像数据, 三维应用于视频数据。</p>
                </div>
                <div class="p1">
                    <p id="66">人脑活动产生的脑电信号不仅随着时间和频率而变化, 而且随着通道而变化。这些三维数据不仅应考虑空间 (通道和频率) 特征, 还应考虑时间特征。二维卷积神经网络已经在许多图像识别应用中得到了广泛的研究, 并且已经显示出良好的结果, 但仅限于处理单帧输入。三维卷积神经网络 (3D CNN) 可以同时提取空间和时间的特征, 超过了视频分析中二维卷积神经网络的性能<citation id="174" type="reference"><link href="155" rel="bibliography" /><link href="157" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。在这研究中, 三维卷积神经网络用于三维脑电地形图视频的特征学习。图4显示了三维卷积神经网络的结构。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3D CNN结构" src="Detail/GetImg?filename=images/JSJY201907004_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 3D CNN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_067.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 3D CNN structure</p>

                </div>
                <div class="p1">
                    <p id="68">三维卷积神经网络通过以三维体积格式输入数据来一起学习空间特征和时间特征。这种时空特征学习是通过三维卷积和三维池化操作实现的。使用ReLU (Rectified Linear Unit) 作为激活函数的属于第<i>i</i>层的第<i>j</i>个特征映射中的 (<i>x</i>, <i>y</i>, <i>z</i>) 位置的值通过式 (3) 计算:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>x</mi><mi>y</mi><mi>z</mi></mrow></msubsup><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false"> (</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>q</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Q</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>r</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><mi>W</mi></mstyle></mrow></mstyle></mrow></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>m</mi></mrow><mrow><mi>p</mi><mi>q</mi><mi>r</mi></mrow></msubsup><mi>V</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>m</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mi>p</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>y</mi><mo>+</mo><mi>q</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>z</mi><mo>+</mo><mi>r</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mn>0</mn><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">其中:<i>b</i><sub><i>ij</i></sub>是偏压, <i>P</i><sub><i>i</i></sub>和<i>Q</i><sub><i>i</i></sub>分别是三维内核的高度和宽度, <i>R</i><sub><i>i</i></sub>是三维内核的深度, <i>W</i><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>m</mi></mrow><mrow><mi>p</mi><mi>q</mi><mi>r</mi></mrow></msubsup></mrow></math></mathml>是与前一层的第<i>m</i>个特征映射连接的 (<i>p</i>, <i>q</i>, <i>r</i>) 位置的权重值, <i>V</i><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>m</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mi>p</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>y</mi><mo>+</mo><mi>q</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>z</mi><mo>+</mo><mi>r</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示前一层第<i>m</i>个特征中偏离 (<i>x</i>, <i>y</i>, <i>z</i>) 位置 (<i>p</i>, <i>q</i>, <i>r</i>) 的位置值。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.3 <b>长短期记忆神经网络模型</b></h4>
                <div class="p1">
                    <p id="74">长短期记忆 (LSTM) 神经网络是一种能够学习长期依赖性的特殊类型的循环神经网络, 旨在通过短期记忆解决长期依赖性问题。长短期记忆神经网络能够处理甚至最长的序列数据而不会消失梯度, 现在, 它被广泛用于解决序列数据问题, 例如语音识别、自然语言处理和图像的自动注释。</p>
                </div>
                <div class="p1">
                    <p id="75">如图5所示, 长短期记忆神经网络在单个单元中具有复杂的循环结构, 其在时间上按时间顺序连接。长短期记忆神经网络具有两个属性值:一个是随时间变化的单元的隐藏状态<i>H</i> (<i>t</i>) 值, 另一个是使得可以长期维持存储器的单元状态<i>C</i> (<i>t</i>) 。在图5中, 在框图中沿着长短期记忆神经网络单元的顶行水平改变单元状态。长短期记忆神经网络可以在单元状态中添加或删除信息。遗忘门<i>F</i> (<i>t</i>) 调整输入<i>X</i> (<i>t</i>) 和先前隐藏状态<i>H</i> (<i>t</i>-1) 与单元状态<i>C</i> (<i>t</i>) 的连接, 允许单元记住或忘记<i>X</i> (<i>t</i>) 和<i>H</i> (<i>t</i>-1) , 并且输入门<i>I</i> (<i>t</i>) 和<i>I</i>′ (<i>t</i>) 确定是否将输入值送到单元状态<i>C</i> (<i>t</i>) 。输出门<i>O</i> (<i>t</i>) 还基于单元状态<i>C</i> (<i>t</i>) 确定单元的输出<citation id="175" type="reference"><link href="159" rel="bibliography" /><link href="161" rel="bibliography" /><link href="163" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>。该过程如式 (4) ～ (9) 所示:</p>
                </div>
                <div class="p1">
                    <p id="76"><i>F</i> (<i>t</i>) =<i>σ</i> (<b><i>W</i></b><sub><i>f</i></sub>[<i>H</i> (<i>t</i>-1) , <i>X</i> (<i>t</i>) ]+<b><i>B</i></b><sub><i>f</i></sub>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="77"><i>I</i> (<i>t</i>) =<i>σ</i> (<b><i>W</i></b><sub><i>i</i></sub>[<i>H</i> (<i>t</i>-1) , <i>X</i> (<i>t</i>) ]+<b><i>B</i></b><sub><i>i</i></sub>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="78"><i>O</i> (<i>t</i>) =<i>σ</i> (<b><i>W</i></b><sub><i>o</i></sub>[<i>H</i> (<i>t</i>-1) , <i>X</i> (<i>t</i>) ]+<b><i>B</i></b><sub><i>o</i></sub>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="79"><i>I</i>′ (<i>t</i>) =tanh (<b><i>W</i></b><sub><i>i</i>′</sub>[<i>H</i> (<i>t</i>-1) , <i>X</i> (<i>t</i>) ]+<b><i>B</i></b><sub><i>i</i>′</sub>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="80"><i>C</i> (<i>t</i>) =<i>F</i> (<i>t</i>) ·<i>C</i> (<i>t</i>-1) +<i>I</i> (<i>t</i>) ·<i>I</i>′ (<i>t</i>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="81"><i>H</i> (<i>t</i>) =<i>O</i> (<i>t</i>) ·tanh (<i>C</i> (<i>t</i>) )      (9) </p>
                </div>
                <div class="p1">
                    <p id="82">其中:<b><i>W</i></b>和<b><i>B</i></b>分别表示权重矩阵和偏差矢量, <i>σ</i> (·) 表示sigmoid函数, tanh (·) 表示双曲正切函数。从长短期记忆神经网络的特性可以看出, 可以通过反映单元的状态和内部状态来精确地控制输入数据。此外, 固定长度和可变长度数据都可以在长短期记忆神经网络入口和出口处理。当将长短期记忆神经网络与其他类型的深度学习神经网络一起结合使用时, 这种优势比单独使用长短期记忆神经网络更明显。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 LSTM神经网络的结构" src="Detail/GetImg?filename=images/JSJY201907004_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 LSTM神经网络的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_083.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Structure of LSTM neural network</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84">2.4 <b>结合卷积神经网络与长短期记忆神经网络的预测模型</b></h4>
                <div class="p1">
                    <p id="85">三维卷积神经网络可以提取许多有用的特征, 以确保从输入数据成功预测, 具体取决于三维内核的大小。这样提取的特征也以三维矩阵表示。也就是说, 它是一种时空特征。然而, 像典型的卷积神经网络一样, 当通过在最后全连接层将三维特征矩阵制作成单个矢量来进行分类时, 可能时空特征丢失它们自己的信息。另一方面, 如上所述, 长短期记忆神经网络具有非常适合于时间序列数据的结构, 因此, 可以从其固有特性在记忆输入数据的长时间历史并同时输出结果。如果建立将三维卷积神经网络作为特征学习端与将长短期记忆神经网络作为分类/预测端的结合模型, 该模型可以获得非常好的结果, 所以, 本研究提出了一种新的消费者偏好预测模型, 通过长短期记忆层而不是全连接层, 以便在保持从三维卷积神经网络特征学习获得的时空特征信息同时执行预测。</p>
                </div>
                <div class="p1">
                    <p id="86">图6显示所提出的结合三维卷积神经网络与长短期记忆神经网络的预测模型。如图6所示, 由于脑电地形图是圆形, 因此在输入到卷积神经网络的脑电地形图视频中存在未定义数值的非数区域 (参见图3) 。为了便于在卷积神经网络中进行计算, 非数区域填充了零。然而, 由于卷积神经网络的特性, 在通过卷积层之后在非数区域中产生一些非零数值。这是不必要的结果, 会对后层产生不利影响, 因此, 在通过卷积层之后, 应该去除在非数区域中产生的非零数。在该研究中, 定义一个面膜层来去除非零值并将其插入到在卷积层和池化层之间。面膜层预定义0和1元素组成的面膜矩阵, 并进行面膜矩阵与卷积层结果的对应元素乘法, 以去除在非数区域中的非零值。非数区域在通过卷积层和池化层的过程中逐渐变小并消失, 因此必须应用面膜层, 直到非数区域消失。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 本文结合3D CNN与LSTM神经网络的预测模型" src="Detail/GetImg?filename=images/JSJY201907004_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 本文结合3<i>D CNN</i>与<i>LSTM</i>神经网络的预测模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>The proposed prediction model combining</i> 3<i>D CNN and</i><i>LSTM neural network</i></p>

                </div>
                <div class="p1">
                    <p id="88">如图6所示, 在5个频带中得到的脑电地形图视频数据分别输入到5个三维卷积神经网络。每个三维卷积神经网络由几个卷积层、面膜层和池化层组成。各个三维卷积神经网络的结果保留时间顺序来组成一个矩阵, 并输入到长短期记忆神经网络层。预测结果通过几个长短期记忆神经网络层输出。</p>
                </div>
                <div class="p1">
                    <p id="89">本文提出的这种预测模型可以应用于脑电信号的分类和预测, 同时它可以提供良好的结果。首先, 与一种基于特定公式或算法从时间-频率-通道格式的大规模脑电波数据中提取特征的方法不同, 本文提出的方法具有能够从三维卷积神经网络的学习过程中学习特征以产生理想的最终结果的优点。简而言之, 可以通过三维卷积神经网络特征学习来学习适合于从脑电波数据传递到结果的特征。另外, 由于长短期记忆神经网络被用作分类/预测端, 因此其优点在于它可以充分反映根据时间的脑电波信号的变化特性。</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag">3 实验结果和分析</h3>
                <div class="p1">
                    <p id="91">如第2章已经提到的, 在电脑上以128 <i>Hz</i>下采样的脑电波数据由32个通道中的512个样本值组成。通过短时间傅里叶变换将该脑电波数据转换成在32个通道、49个时间样本和50个频带样本中以三维形式表示的功率谱密度。该功率谱密度是预测模型的输入数据。总脑电波数据中的80%用于学习数据, 20%用于检查数据。</p>
                </div>
                <div class="p1">
                    <p id="92">为了评估所提出的预测模型的性能, 本研究比较了所提出的预测模型与三维卷积神经网络预测模型和长短期记忆神经网络预测模型。针对两种情况进行了性能评估:消费者依赖预测模型和消费者独立预测模型。</p>
                </div>
                <div class="p1">
                    <p id="93">本研究在<i>Intel</i> 2.5 <i>GHz Core i</i>7处理器和内存8 <i>GHz</i>计算机上使用深度学习专用包<i>tensorflow</i>开发了一个<i>Python</i>程序。性能评估的准确度 (<i>Accuracy</i>, <i>Acc</i>) 计算如下:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">当消费者对产品的偏好表示为“喜欢”和“不喜欢”时, <i>TP</i> (True Positive) 、<i>FP</i> (False Positive) 、<i>TN</i> (True Negative) 、<i>FN</i> (False Negative) 分别表示将“喜欢”样本预测为“喜欢”样本的次数, 将“不喜欢”样本预测为“喜欢”样本的次数、将“喜欢”样本预测为“不喜欢”样本的次数、将“不喜欢”样本预测为“不喜欢”样本的次数。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96">3.1 <b>预测模型的结构和参数确定以及对比模型</b></h4>
                <div class="p1">
                    <p id="97">进行实验以确定图6所示预测模型的结构和参数, 为此提出了4种候选模型, 4种候选模型的结构和参数如表1所示。其中特征学习端 (第二列) 的参数说明为:卷积层 (高度×宽度×深度-输出数量) ;面膜层 (高度×宽度) ) ; (池化层 (高度×宽度×深度) ;<i>LSTM</i>层 (长短期记忆单元数量) 。</p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表</b>1 <b>候选模型的结构和参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Structure and parameters of candidate models</i></p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td><br />模型</td><td>特征学习端</td><td>分类预测端</td></tr><tr><td><br />模型Ⅰ</td><td>卷积层 (8×8×8- 5) <br />面膜层 (34×34) <br />池化层 (2×2×2) </td><td><i>LSTM</i>层 (100) </td></tr><tr><td><br />模型Ⅱ</td><td>卷积层 (8×8×8- 5) <br />面膜层 (34×34) <br />池化层 (2×2×2) </td><td><i>LSTM</i>层 (100) <br /><i>Dropout</i>=0.6<br /><i>LSTM</i>层 (20) </td></tr><tr><td><br />模型Ⅲ</td><td>卷积层 (8×8×8- 5) <br />面膜层 (34×34) <br />池化层 (2×2×2) <br />卷积层 (4×4×4- 10) <br />池化层 (2×2×2) </td><td><i>LSTM</i>层 (100) </td></tr><tr><td><br />模型Ⅳ</td><td>卷积层 (8×8×8- 5) <br />面膜层 (34×34) <br />池化层 (2×2×2) <br />卷积层 (4×4×4- 10) <br />池化层 (2×2×2) </td><td><i>LSTM</i>层 (100) <br /><i>Dropout</i>=0.6<br /><i>LSTM</i>层 (20) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="99">4种候选模型的性能结果如图7所示。从图7可以看出, 模型Ⅳ的性能优于其他模型, 因此选择了模型Ⅳ。所提出的预测模型简单地表示为3<i>D CNN</i>-<i>LSTM</i>。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 四种候选模型的性能比较" src="Detail/GetImg?filename=images/JSJY201907004_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 四种候选模型的性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 7 <i>Performance comparison of four candidate models</i></p>

                </div>
                <div class="p1">
                    <p id="101">为了评估3<i>D CNN</i>-<i>LSTM</i>预测模型的有效性, 本研究将其与3<i>D CNN</i>和<i>LSTM</i>的单独预测模型进行了比较。3<i>D CNN</i>预测模型如3<i>D CNN</i>-<i>LSTM</i>, 由两个卷积层、一个面膜层和两个池化层和全连接输出层组成。对于<i>LSTM</i>预测模型, 输入数据随着时间轴被转换为二维格式, 并且两个<i>LSTM</i>层的单元数分别被设置为100、20, 并且层之间的压差系数被设置为0.6。</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102">3.2 <b>消费者依赖模型的性能对比</b></h4>
                <div class="p1">
                    <p id="103">该实验通过训练和测试每个消费者的预测模型来进行, 因此, 所学习的预测模型就是消费者依赖预测模型。首先, 当产品类型设置为1、3、5和6时, 为每个消费者训练和测试本文提出的3<i>D CNN</i>-<i>LSTM</i>模型。这些结果如图8所示。从图8中可见, 消费者在实验中的偏好预测结果通常显示出超过80%的准确度。尤其是第3、第4和第17消费者的平均预测准确度超过85%;而第5、第14和第15消费者的平均预测准确度在75%至80%。由于消费者们对产品的情绪状态互相不同, 所以消费者们的大脑激活状态也互相不同, 因此存在消费者们之间的准确度差异。</p>
                </div>
                <div class="p1">
                    <p id="104">除了第15和第17消费者以外, 每个消费者对产品类型数量的预测准确度没有显示出很明显的差异。由此可以看出, 预测消费者产品偏好的准确度不会受到产品类型数量的影响。</p>
                </div>
                <div class="p1">
                    <p id="105">接下来, 使用3个预测模型来训练每个消费者对于所有产品类型的预测模型并测试。该实验的结果如图9所示。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 3D CNN-LSTM消费者依赖模型的准确度" src="Detail/GetImg?filename=images/JSJY201907004_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 3<i>D CNN</i>-<i>LSTM</i>消费者依赖模型的准确度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 8 <i>Accuracy of</i> 3<i>D CNN</i>-<i>LSTM consumer</i>-<i>dependence model</i></p>

                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907004_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 消费者依赖模型的性能对比" src="Detail/GetImg?filename=images/JSJY201907004_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 消费者依赖模型的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907004_107.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 9 <i>Performance comparison of consumer</i>-<i>dependence models</i></p>

                </div>
                <div class="p1">
                    <p id="108">3<i>D CNN</i>-<i>LSTM</i>模型、3<i>D CNN</i>模型和<i>LSTM</i>神经网络模型的平均预测准确度分别为82.36%, 67.31%和62.92%。本文所提出的3<i>D CNN</i>-<i>LSTM</i>模型的平均预测准确度分别比3<i>D CNN</i>模型和<i>LSTM</i>神经网络模型提高15.05个百分点和19.44个百分点。3<i>D CNN</i>模型的预测准确度比<i>LSTM</i>神经网络模型提高4.39个百分点。3<i>D CNN</i>预测模型通过特征学习充分反映了时空特征, 但准确度较低的原因是在全连接层中没有考虑特征矩阵的时间顺序。在<i>LSTM</i>神经网络预测模型的情况下, 由于仅将连接矩阵连接到输入层和输出层而不能通过时空特征来进行模型学习, 因此, 尽管反映了输入数据的整体时间特性, 但未反映空间特性。这就是<i>LSTM</i>预测模型的性能较低的原因。然而, 3<i>D CNN</i>-<i>LSTM</i>预测模型获得了良好的结果是因为特征矩阵是通过<i>CNN</i>特征提取阶段中的时空特征学习来计算的, 并且预测结果是在反映特征矩阵的时间顺序的<i>LSTM</i>分类阶段中进行的。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">3.3 <b>消费者独立模型性能对比</b></h4>
                <div class="p1">
                    <p id="110">在之前的实验中, 进行消费者依赖预测模型的性能评估。在该实验中, 重点在于构建可应用于所有消费者的预测模型, 而不考虑每个消费者的特性。表2显示了消费者独立预测模型的产品类型性能对比。</p>
                </div>
                <div class="area_img" id="111">
                    <p class="img_tit"><b>表</b>2 <b>消费者独立模型的产品类型准确度对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Accuracy comparison of different product types of</i><i>consumer</i>-<i>independence models</i></p>
                    <p class="img_note">%</p>
                    <table id="111" border="1"><tr><td><br />产品名</td><td>3<i>D CNN</i></td><td><i>LSTM</i></td><td>3<i>D CNN</i>-<i>LSTM</i></td></tr><tr><td><br />鞋子</td><td>56.32</td><td>54.65</td><td>73.24</td></tr><tr><td><br />帽子</td><td>54.31</td><td>52.35</td><td>71.54</td></tr><tr><td><br />围巾</td><td>52.85</td><td>51.93</td><td>70.62</td></tr><tr><td><br />手表</td><td>59.15</td><td>57.46</td><td>72.98</td></tr><tr><td><br />毛衣</td><td>55.34</td><td>52.68</td><td>70.24</td></tr><tr><td><br />箱包</td><td>51.97</td><td>51.63</td><td>69.36</td></tr><tr><td><br />平均值</td><td>54.99</td><td>53.45</td><td>71.33</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="112">因为消费者的大脑活动进展不同, 消费者独立模型的预测结果比消费者依赖模型大约低10个百分点。每种产品准确度的差异与消费者对产品的不同响应状态有关。与之前的实验结果相似, 使用3<i>D CNN</i>和<i>LSTM</i>的预测模型分别与3<i>D CNN</i>-<i>LSTM</i>预测模型的准确度大约低16.34个百分点和17.88个百分点。3<i>D CNN</i>-<i>LSTM</i>的消费者独立预测模型平均准确度为71.33%, 其中最高73.24%是鞋子产品的, 最低69.36%是箱包产品的。</p>
                </div>
                <div class="p1">
                    <p id="113">为了测试所提出模型的可扩展性, 本研究分析了消费者人数对预测模型的预测准确性的影响, 为此, 通过将消费者人数改变为5、10、15和20来评估预测模型的预测准确度。这些结果显示在表3中, 可见所提出的模型仍然优于3<i>D CNN</i>和<i>LSTM</i>神经网络模型;而且, 随着消费者人数的增加, 所提出模型的预测准确度几乎保持稳定。</p>
                </div>
                <div class="area_img" id="114">
                    <p class="img_tit"><b>表</b>3 <b>消费者独立模型的消费者人数准确度对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 3 <i>Accuracy comparison of different number of consumers of</i><i>consumer</i>-<i>independence models</i></p>
                    <p class="img_note">%</p>
                    <table id="114" border="1"><tr><td><br />消费者人数</td><td>3<i>D CNN</i>-<i>LSTM</i></td><td>3<i>D CNN</i></td><td><i>LSTM</i></td></tr><tr><td><br />5</td><td>78.10</td><td>63.24</td><td>60.33</td></tr><tr><td><br />10</td><td>77.49</td><td>57.55</td><td>56.22</td></tr><tr><td><br />15</td><td>75.25</td><td>55.80</td><td>54.54</td></tr><tr><td><br />20</td><td>71.33</td><td>54.20</td><td>52.64</td></tr><tr><td><br />平均值</td><td>75.54</td><td>57.69</td><td>55.93</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="115" name="115" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="116">本文提出了一种利用深度学习神经网络预测模型从消费者脑电波信号预测消费者产品偏好的新方法, 并对该方法进行了评估实验。</p>
                </div>
                <div class="p1">
                    <p id="117">首先, 本研究使用短时间傅里叶变换和双调和样条插值从多通道脑电波信号得到五个频带功率谱密度的脑电地形图视频;其次, 本研究提出结合特征学习端和分类预测端的消费者偏好预测模型, 该模型中, 特征学习端由5个三维卷积神经网络的并联连接组成, 而且分类预测段由2个长短期记忆神经网络的串联连接组成;最后, 在选取20名消费者 (13名男性和7名女性) 参与实验并对预测模型进行性能评估模型的训练和测试后, 结果显示, 与卷积神经网络模型和长短期记忆神经网络模型相比, 消费者依赖模型的平均准确度分别提高了15.05个百分点和19.44个百分点, 消费者独立模型的平均准确度分别提高了16.34个百分点和17.88个百分点。综上, 本文提出的预测模型的理论特性与实验结果, 为消费者偏好预测系统低成本且高效服务于企业营销策略研发与营销管理提供了参考。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="129">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Affective ranking of movie scenes using physiological signals and content analysis">

                                <b>[1]</b> SOLEYMANI M, CHANEL G, KIERKELS J J, et al.Affective ranking of movie scenes using physiological signals and content analysis[C]// Proceedings of the 2nd ACM Workshop on Multimedia Semantics.New York:ACM, 2008:32-39.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST4297CDF90B7D0B0E273643FA7B31C246&amp;v=Mjg3MjdMejJNUjdUeDdUSHlVM1JWSGVyUG5SNzZaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzdxNHdLbz1OaWZZZXJlNkY5YS8yL2xNWkprSWVIeA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> TELPAZ A, WEBB R, LEVY D J.Using EEG to predict consumers' future choices[J].Journal of Marketing Research, 2015, 52 (4) :511-529.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Salience and choice:neural correlates of shopping decisions">

                                <b>[3]</b> AMBLER T, BRAEUTIGAM S, STINS J, et al.Salience and choice:neural correlates of shopping decisions[J].Psychology and Marketing, 2004, 21 (4) :247-261.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX40C9B7E24ED7EBF8E65DA752492339B0&amp;v=MTYwMjRZSjU3Q3dsTHVSNW03RG9KT1hqbnJoWThlN0dYVE1pZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3cTR3S289TmlmQ2RyZTRiZGkrcVBwSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> BALDO D, PARIKH H, PIU Y, et al.Brain waves predict success of new fashion products:a practical application for the footwear retailing industry[J].Journal of Creating Value, 2015, 1 (1) :61-71.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501637339&amp;v=MDM1MTJUTW53WmVadEZpbmxVcjNJSjF3VGFoQT1OaWZPZmJLN0h0RE5xbzlFWXVnSUQzOHdvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> KHUSHABA R N, GREENACRE L, KODAGODA S, et al.Choice modeling and the brain:a study on the electroencephalogram (EEG) of preferences[J].Expert Systems with Applications, 2012, 39 (16) :12378-12388.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wireless EEG signals based neuromarketing system using fast Fourier transform (FFT)">

                                <b>[6]</b> MURUGAPPAN M.Wireless EEG signals based neuromarketing system using fast Fourier transform (FFT) [C]// CSPA 2014:Proceedings of the 10th International Colloquium on Signal Processing and Its Applications.Piscataway, NJ:IEEE, 2014:25-30.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST7FF87716A9C21FEDB1622E11D0620D72&amp;v=MTUxMDFJNURGZUo4RG4xUHVtSmg2emwvU2dyanJXWTFmN0NVTWIyZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3cTR3S289TmlmWWVyVE9hTm5McQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> BOKSEM M A, SMIDTS A.Brain responses to movie trailers predict individual preferences for movies and their population-wide commercial success[J].Journal of Marketing Research, 2015, 52 (4) :482-492.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501197426&amp;v=MTgxNjBmYks3SHRETnFvOUVaZUlJQ0g0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxd1RhaEE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> KAWASAKI M, YAMAGUCHI Y.Effects of subjective preference of colors on attention-related occipital theta oscillations[J].Neuroimage, 2012, 59 (1) :808-814.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES769E0760D5156E7C626E3E6F8FE26EF4&amp;v=MzE5NDI0T0NYcE15R1VWNkRrSVN3cmsyaHBERExDU01NeWJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3E0d0tvPU5pZk9mYlMrRjZUTXFJbEZFTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> FAUST O, HAGIWARA Y, HONG T J, et al.Deep learning for healthcare applications based on physiological signals:A review[J].Computer Methods and Programs in Biomedicine, 2018, 161:1-13.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A review of emotion recognition using physiological signals">

                                <b>[10]</b> SHU L, XIE J Y, YANG M Y, et al.A review of emotion recognition using physiological signals[J].Sensors, 2018, 18 (7) :2074.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCE&amp;filename=SJCE322459B9C864FF7F99EE988ABF6DA0BB&amp;v=MjAzMjc0d0tvPU5pZklhN0M2SE5YSnB2MU1GK01KQ0FwUHlHQWE0MG9JUVhmcTNXQkRmOGJsUmNqdENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHc3cQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> LIANG J W, CHAUDHURI S R, SHINOZUKA M.Simulation of nonstationary stochastic processes by spectral representation[J].Journal of Engineering Mechanics, 2007, 133 (6) :616-627.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCE&amp;filename=SJCE15062400000026&amp;v=MTQyMTZhN0s5SHRmT3E0OUZaT3NQREg0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxd1RhaEE9TmlmSQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> HUANG G Q, SU Y W, KAREEM A, et al.Time-frequency analysis of nonstationary process based on multivariate empirical mode decomposition[J].Journal of Engineering Mechanics, 2016, 142 (1) :04015065.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Griddata function description">

                                <b>[13]</b> Mathworks Inc.Griddata function description[EB/OL].[2018- 11- 20].https://ww2.mathworks.cn/help/matlab/ref/griddata.html.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning spatiotemporal features with 3dconvolutional networks">

                                <b>[14]</b> TRAN D, BOURDEV L, FERGUS R, et al.Learning spatiotemporal features with 3D convolutional networks[C]// ICCV 2015:Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 2015:4489-4497.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201802006&amp;v=MjcwODM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTC9LUFRYSVlMRzRIOW5Nclk5RllvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 孔祥浩, 马琳, 李海峰, 等.CNN与CSP相结合的脑电特征提取与识别方法研究[J].信号处理, 2018, 34 (2) :164-173. (KONG X H, MA L, LI H F, et al.Research on EEG feature extraction and recognition method based on CNN and CSP[J].Journal of Signal Processing, 2018, 34 (2) :164-173.) 
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHDY201703009&amp;v=MTMwNTR6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwvS01pWFBkN0c0SDliTXJJOUZiWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 谢逸, 饶文碧, 段鹏飞, 等.基于CNN和LSTM混合模型的中文词性标注[J].武汉大学学报 (理学版) , 2017, 63 (3) :246-250. (XIE Y, RAO W B, DUAN P F, et al.A Chinese POS tagging approach using CNN and LSTM-based hybrid model[J].Wuhan University Journal of Natural Sciences, 2017, 63 (3) :246-250.) 
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LSTM:A Search Space Odyssey">

                                <b>[17]</b> GREFF K, SRIVASTAVA R K, KOUTNíK J, et al.LSTM:a search space odyssey[J].IEEE Transactions on Neural Networks and Learning Systems, 2015, 28 (10) :2222-2232.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Applying LSTM to time series predictable through time-window approaches">

                                <b>[18]</b> GERS F A, ECK D, SCHMIDHUBER J.Applying LSTM to time series predictable through time-window approaches[C]// ICANN 2001:Proceedings of the 10th International Conference on Artificial Neural Networks.Berlin:Springer, 2001:21-25.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907004&amp;v=MTM2OTNJOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwvTEx6N0JkN0c0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
