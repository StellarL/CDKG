<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136675105783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906024%26RESULT%3d1%26SIGN%3dWXk%252bdPyzOJVO5TtfK5sJIF0IMlw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906024&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906024&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906024&amp;v=MTQzNDNCZDdHNEg5ak1xWTlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01Mejc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 3D掌纹纹理特征提取 ">1 3D掌纹纹理特征提取</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="1.1 3D&lt;b&gt;掌纹的形状指数表示&lt;/b&gt;">1.1 3D<b>掌纹的形状指数表示</b></a></li>
                                                <li><a href="#61" data-title="1.2 &lt;b&gt;局部三值模式&lt;/b&gt;">1.2 <b>局部三值模式</b></a></li>
                                                <li><a href="#66" data-title="1.3 &lt;b&gt;近邻三值模式&lt;/b&gt;">1.3 <b>近邻三值模式</b></a></li>
                                                <li><a href="#81" data-title="1.4 &lt;b&gt;纹理特征提取&lt;/b&gt;">1.4 <b>纹理特征提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="2 基于NTP和协作表示的掌纹识别算 ">2 基于NTP和协作表示的掌纹识别算</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="2.1 SRC&lt;b&gt;算法&lt;/b&gt;">2.1 SRC<b>算法</b></a></li>
                                                <li><a href="#110" data-title="2.2 CRC_RLS&lt;b&gt;算法&lt;/b&gt;">2.2 CRC_RLS<b>算法</b></a></li>
                                                <li><a href="#118" data-title="2.3 &lt;b&gt;本文算法&lt;/b&gt;NTP_CRC">2.3 <b>本文算法</b>NTP_CRC</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#133" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#134" data-title="3.1 &lt;b&gt;实验环境与评价指标&lt;/b&gt;">3.1 <b>实验环境与评价指标</b></a></li>
                                                <li><a href="#139" data-title="3.2 &lt;b&gt;实验图库&lt;/b&gt;">3.2 <b>实验图库</b></a></li>
                                                <li><a href="#141" data-title="3.3 &lt;b&gt;结果分析&lt;/b&gt;">3.3 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#156" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="图1 形状指数图">图1 形状指数图</a></li>
                                                <li><a href="#70" data-title="图2 3&#215;3像素矩阵">图2 3×3像素矩阵</a></li>
                                                <li><a href="#80" data-title="图3 NTP编码过程">图3 NTP编码过程</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同分块情况下识别率&lt;/b&gt;"><b>表</b>1 <b>不同分块情况下识别率</b></a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同特征提取方法的识别效果&lt;/b&gt;"><b>表</b>2 <b>不同特征提取方法的识别效果</b></a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同分类方法的识别效果和分类时间&lt;/b&gt;"><b>表</b>3 <b>不同分类方法的识别效果和分类时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="178">


                                    <a id="bibliography_1" title="AGGITHAYA V K, ZHANG D, LUO N.A multimodal biometric authentication system based on 2D and 3D palmprint features[C]//Proceedings of the SPIE 6944-the International Society for Optical Engineering, Biometric Technology for Human Identification V.Bellingham:SPIE, 2008:69440C." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A multimodal biometricauthentication system based on 2D and 3D palmprint features">
                                        <b>[1]</b>
                                        AGGITHAYA V K, ZHANG D, LUO N.A multimodal biometric authentication system based on 2D and 3D palmprint features[C]//Proceedings of the SPIE 6944-the International Society for Optical Engineering, Biometric Technology for Human Identification V.Bellingham:SPIE, 2008:69440C.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_2" title="ZHANG D, LU G M, LI W, et al.Three dimensional palmprint recognition using structured light imaging[C]//Proceedings of the2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Three Dimensional Palmprint Recognition using Structured Light Imaging">
                                        <b>[2]</b>
                                        ZHANG D, LU G M, LI W, et al.Three dimensional palmprint recognition using structured light imaging[C]//Proceedings of the2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_3" title="BAI X, HUANG S, GAO N, et al.Person identification by using3D palmprint data[C]//Proceedings of the SPIE 10025, Advanced Sensor Systems and Applications VII.Bellingham:SPIE, 2016:100250Q." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Person identification by using3D palmprint data">
                                        <b>[3]</b>
                                        BAI X, HUANG S, GAO N, et al.Person identification by using3D palmprint data[C]//Proceedings of the SPIE 10025, Advanced Sensor Systems and Applications VII.Bellingham:SPIE, 2016:100250Q.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_4" title="BAI X, GAO N, ZHANG Z, et al.3D palmprint identification combining blocked ST and PCA[J].Pattern Recognition Letters, 2017, 100:89-95." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF7BD2028DE7F7C32396CD8900EDECB27&amp;v=MjY2Njg1dHBodzd5Mndxdz1OaWZPZmNXL2JLWE9yNDFORUo0SWVudEt6QlFRNHprT1BIZnJyQkpBRGNmbk43aVlDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        BAI X, GAO N, ZHANG Z, et al.3D palmprint identification combining blocked ST and PCA[J].Pattern Recognition Letters, 2017, 100:89-95.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_5" title="林国军, 解梅.一种鲁棒协作表示的人脸识别算法[J].计算机应用研究, 2014, 31 (8) :2520-2522, 2531. (LIN G J, XIE M.Face recognition algorithm of robust collaborative representation[J].Application Research of Computers, 2014, 31 (8) :2520-2522, 2531.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201408070&amp;v=MDk3MDU3cWZadVpzRnkvaFdyM01MejdTWkxHNEg5WE1wNDlDWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        林国军, 解梅.一种鲁棒协作表示的人脸识别算法[J].计算机应用研究, 2014, 31 (8) :2520-2522, 2531. (LIN G J, XIE M.Face recognition algorithm of robust collaborative representation[J].Application Research of Computers, 2014, 31 (8) :2520-2522, 2531.) 
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_6" title="GUO X M, ZHOU W D, ZHANG Y L.Collaborative representation with HM-LBP features for palmprint recognition[J].Machine Vision and Applications, 2017, 28 (3/4) :283-291." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD717390E51AA4568FE45A40A9D3FEAFA1&amp;v=Mjc1NTJNOHVlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzd5Mndxdz1OajdCYXJTNUdkTEZyL3BBWlpwK0NIay94MkJtN2pvTVRIK1RwV1kyRDhmbA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        GUO X M, ZHOU W D, ZHANG Y L.Collaborative representation with HM-LBP features for palmprint recognition[J].Machine Vision and Applications, 2017, 28 (3/4) :283-291.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_7" title="ZHANG D, LU G M, LI W, et al.Palmprint recognition using 3-Dinformation[J].IEEE Transactions on Systems, Man and Cybernetics, Part C:Applications and Reviews, 2009, 39 (5) :505-519." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Palmprint Recognition Using 3-D Information">
                                        <b>[7]</b>
                                        ZHANG D, LU G M, LI W, et al.Palmprint recognition using 3-Dinformation[J].IEEE Transactions on Systems, Man and Cybernetics, Part C:Applications and Reviews, 2009, 39 (5) :505-519.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_8" title="杨冰, 王小华, 杨鑫.基于局部纹理特征的三维掌纹识别研究[J].光电工程, 2014, 41 (12) :53-59. (YANG B, WANG X H, YANG X.3D Palmprint recognition based on local texture feature sets[J].Opto-Electronic Engineering, 2014, 41 (12) :53-59.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201412011&amp;v=MDg1NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01JaW5NYmJHNEg5WE5yWTlFWllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        杨冰, 王小华, 杨鑫.基于局部纹理特征的三维掌纹识别研究[J].光电工程, 2014, 41 (12) :53-59. (YANG B, WANG X H, YANG X.3D Palmprint recognition based on local texture feature sets[J].Opto-Electronic Engineering, 2014, 41 (12) :53-59.) 
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_9" title="姚骋天, 夏哲雷.一种改进的局部三值模式的人脸识别方法[J].中国计量学院学报, 2016, 27 (1) :68-72. (YAO C T, XIAZ L.Face recognition based on improved local ternary patterns[J].Journal of China University of Metrology, 2016, 27 (1) :68-72.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGJL201601013&amp;v=MDgyNzQvaFdyM01QeXJCWXJHNEg5Zk1ybzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        姚骋天, 夏哲雷.一种改进的局部三值模式的人脸识别方法[J].中国计量学院学报, 2016, 27 (1) :68-72. (YAO C T, XIAZ L.Face recognition based on improved local ternary patterns[J].Journal of China University of Metrology, 2016, 27 (1) :68-72.) 
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_10" title="刘海军.局部方向三值模式纹理描述子[J].计算机工程与设计, 2015, 36 (5) :1260-1264, 1303. (LIU H J.Texture descriptor of local directional ternary patterns[J].Computer Engineering and Design, 2015, 36 (5) :1260-1264, 1303.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201505028&amp;v=MjU2MTgzTU5pZllaTEc0SDlUTXFvOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        刘海军.局部方向三值模式纹理描述子[J].计算机工程与设计, 2015, 36 (5) :1260-1264, 1303. (LIU H J.Texture descriptor of local directional ternary patterns[J].Computer Engineering and Design, 2015, 36 (5) :1260-1264, 1303.) 
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_11" title="林森, 苑玮琦, 吴微, 等.基于离散余弦变换和主线分块能量的模糊掌纹识别[J].光电子&#183;激光, 2012, 23 (11) :2200-2206. (LIN S, YUAN W Q, WU W, et al.Blurred palmprint recognition based on DCT and block enrgy of principal lines[J].Journal of Optoelectronics&#183;Laser, 2012, 23 (11) :2200-2206.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201211030&amp;v=MTMyMTJybzlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01JaW5SWkxHNEg5UE4=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        林森, 苑玮琦, 吴微, 等.基于离散余弦变换和主线分块能量的模糊掌纹识别[J].光电子&#183;激光, 2012, 23 (11) :2200-2206. (LIN S, YUAN W Q, WU W, et al.Blurred palmprint recognition based on DCT and block enrgy of principal lines[J].Journal of Optoelectronics&#183;Laser, 2012, 23 (11) :2200-2206.) 
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_12" title="李善广.基于分块的掌纹识别算法研究[D].哈尔滨:哈尔滨工业大学, 2013:18-23. (LI S G.Research on modular palmprint recognition algorithms[D].Harbin:Harbin Institute of Technology, 2013:18-23.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014081208.nh&amp;v=MDgwMTR6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3IzTVZGMjZHck93SDlQTXA1RWJQSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        李善广.基于分块的掌纹识别算法研究[D].哈尔滨:哈尔滨工业大学, 2013:18-23. (LI S G.Research on modular palmprint recognition algorithms[D].Harbin:Harbin Institute of Technology, 2013:18-23.) 
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_13" title="芦鑫.基于稀疏表示的遮挡人脸识别算法的研究与实现[D].北京:华北电力大学, 2016:7-16. (LU X.Research and implementation of occluded face recognition based on sparse representation[D].Beijing:North China Electric Power University, 2016:7-16.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016276661.nh&amp;v=MDMzODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01WRjI2R0xHL0dOZktycEViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        芦鑫.基于稀疏表示的遮挡人脸识别算法的研究与实现[D].北京:华北电力大学, 2016:7-16. (LU X.Research and implementation of occluded face recognition based on sparse representation[D].Beijing:North China Electric Power University, 2016:7-16.) 
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_14" title="ZHANG L, YANG M, FENG X C.Sparse representation or collaborative representation:which helps face recognition?[C]//Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:471-478." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse representation or collaborative representation:Which helps face recognition?">
                                        <b>[14]</b>
                                        ZHANG L, YANG M, FENG X C.Sparse representation or collaborative representation:which helps face recognition?[C]//Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:471-478.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_15" title="王文龙, 金炜, 谢芸, 等.采用均匀局部二元模式及稀疏表示的掌纹识别[J].光电工程, 2014, 41 (12) :60-65. (WANG W L, JIN W, XIE Y, et al.Palmprint recognition using uniform local binary patterns and sparse representation[J].Opto-Electronic Engineering, 2014, 41 (12) :60-65.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201412012&amp;v=MTI0NTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjNNSWluTWJiRzRIOVhOclk5RVpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        王文龙, 金炜, 谢芸, 等.采用均匀局部二元模式及稀疏表示的掌纹识别[J].光电工程, 2014, 41 (12) :60-65. (WANG W L, JIN W, XIE Y, et al.Palmprint recognition using uniform local binary patterns and sparse representation[J].Opto-Electronic Engineering, 2014, 41 (12) :60-65.) 
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_16" title="张宏星, 邹刚, 赵键, 等.基于Gabor特征与协同表示的人脸识别算法[J].计算机工程与设计, 2014, 35 (2) :666-670, 676. (ZHANG H X, ZOU G, ZHAO J, et al.Face recognition algorithm based on Gabor feature and collaborative representation[J].Computer Engineering and Design, 2014, 35 (2) :666-670, 676.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201402059&amp;v=MTU5NTZXcjNNTmlmWVpMRzRIOVhNclk5QWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2g=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        张宏星, 邹刚, 赵键, 等.基于Gabor特征与协同表示的人脸识别算法[J].计算机工程与设计, 2014, 35 (2) :666-670, 676. (ZHANG H X, ZOU G, ZHAO J, et al.Face recognition algorithm based on Gabor feature and collaborative representation[J].Computer Engineering and Design, 2014, 35 (2) :666-670, 676.) 
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_17" title="ZHANG L, LI L D, YANG A Q, et al.Towards contactless palmprint recognition:a novel device, a new benchmark, and a collaborative representation based identification approach[J].Pattern Recognition, 2017, 69:199-212." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1CC3D2C4D96804348D2A8074DCF26426&amp;v=MTIwNTRmT2ZiTExiZEs0cmZ4QkVPSUpCSHc5ekJJYm5qME1RSC9scUdaR0Q3Q1NRYmlaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBodzd5Mndxdz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        ZHANG L, LI L D, YANG A Q, et al.Towards contactless palmprint recognition:a novel device, a new benchmark, and a collaborative representation based identification approach[J].Pattern Recognition, 2017, 69:199-212.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_18" title="曹忠赞.基于2D和3D掌纹图像方向特征融合的掌纹识别研究[D].秦皇岛:燕山大学, 2013:13-17. (CAO Z Z.Study on palmprint recognition based on 2D and 3D palmprint image orientation features fusion[D].Qinhuangdao:Yashan University, 2013:13-17.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013028666.nh&amp;v=MTkwMTgzTVZGMjZIYk82RnRmS3FaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        曹忠赞.基于2D和3D掌纹图像方向特征融合的掌纹识别研究[D].秦皇岛:燕山大学, 2013:13-17. (CAO Z Z.Study on palmprint recognition based on 2D and 3D palmprint image orientation features fusion[D].Qinhuangdao:Yashan University, 2013:13-17.) 
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_19" title="李春燕, 卢光明, 黎伟.基于曲面曲率和RLDA 3D掌纹识别方法[J].中国图象图形学报, 2011, 16 (5) :807-812. (LI C Y, LU G M, LI W.3D palmprint recognition based on surface curvature and RLDA[J].Journal of Image and Graphics, 2011, 16 (5) :807-812.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201105015&amp;v=MTYyNDFyQ1VSN3FmWnVac0Z5L2hXcjNNUHlyZmJMRzRIOURNcW85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        李春燕, 卢光明, 黎伟.基于曲面曲率和RLDA 3D掌纹识别方法[J].中国图象图形学报, 2011, 16 (5) :807-812. (LI C Y, LU G M, LI W.3D palmprint recognition based on surface curvature and RLDA[J].Journal of Image and Graphics, 2011, 16 (5) :807-812.) 
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_20" title="ZHANG L, SHEN Y, LI H Y, et al.3D palmprint identification using block-wise features and collaborative representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (8) :1730-1736." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D palmprint identification using block-wise features and collaborative representation">
                                        <b>[20]</b>
                                        ZHANG L, SHEN Y, LI H Y, et al.3D palmprint identification using block-wise features and collaborative representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (8) :1730-1736.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-29 10:10</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1690-1695 DOI:10.11772/j.issn.1001-9081.2018102124            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于近邻三值模式和协作表示的三维掌纹识别</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E7%8E%89%E7%8F%8D&amp;code=07934526&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘玉珍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E6%94%BF%E6%9D%83&amp;code=41987901&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋政权</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E5%A8%9C&amp;code=41987902&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵娜</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0034851&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁工程技术大学电子与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%94%9F%E9%99%A2&amp;code=0034851&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁工程技术大学研究生院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E7%BD%91%E9%9E%8D%E5%B1%B1%E4%BE%9B%E7%94%B5%E5%85%AC%E5%8F%B8&amp;code=0021910&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国网鞍山供电公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对二维掌纹图像存在易伪造、抗噪能力差的问题, 提出一种基于近邻三值模式 (NTP) 和协作表示的三维掌纹识别方法。首先, 利用形状指数把三维掌纹的表面几何信息映射成二维数据, 以弥补常用均值或高斯曲率映射无法精确描述三维掌纹特征的缺陷;其次, 对形状指数图作分块处理, 利用近邻三值模式提取分块形状指数图的纹理特征;最后, 利用协作表示的方法进行特征分类。在三维掌纹库上和经典算法进行的对比实验中, 该方法的识别率为99.52%, 识别时长为0.673 8 s, 优于其他算法;在识别率方面, 与经典的局部二值模式 (LBP) 、局部三值模式 (LLTP) 、CompCode、均值曲率图 (MCI) 法相比分别提高了7.77%、6.02%、5.12%和3.97%;在识别时间方面, 与Homotopy、对偶增广拉格朗日法 (DALM) 、SpaRSA方法相比分别降低了6.7 s、15.9 s和61 s。实验结果表明, 所提算法具有良好的特征提取和分类能力, 能够有效地提高识别精度并减少识别时间。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E6%8E%8C%E7%BA%B9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维掌纹;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A2%E7%8A%B6%E6%8C%87%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">形状指数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E4%B8%89%E5%80%BC%E6%A8%A1%E5%BC%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部三值模式;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">纹理特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8F%E4%BD%9C%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">协作表示;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘玉珍 (1964—) , 女, 吉林德惠人, 教授, 硕士, 主要研究方向:信号检测;;
                                </span>
                                <span>
                                    蒋政权 (1995—) , 男, 辽宁大连人, 硕士, 主要研究方向:遥感图像处理;;
                                </span>
                                <span>
                                    *赵娜 (1994—) , 女, 辽宁朝阳人, 硕士研究生, 主要研究方向:图像处理、模式识别。2391274376@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>辽宁省教育厅高等学校基本科研项目 (LJ2017QL014);</span>
                    </p>
            </div>
                    <h1><b>Three dimensional palmprint recognition based on neighbor ternary pattern and collaborative representation</b></h1>
                    <h2>
                    <span>LIU Yuzhen</span>
                    <span>JIANG Zhengquan</span>
                    <span>ZHAO Na</span>
            </h2>
                    <h2>
                    <span>School of Electronics and Information Engineering, Liaoning Technical University</span>
                    <span>Graduate School, Liaoning Technical University</span>
                    <span>State Grid Anshan Electric Power Supply Company</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Concerning the problem that two Dimensional (2 D) palmprint images are eaasily to be forged and affected by noise, a three Dimensional (3 D) palmprint recognition method based on Neighbor Ternary Pattern (NTP) and collaborative representation was proposed. Firstly, a shape index was used to map the surface geometric information of 3 D palmprint into 2 D data, avoiding the inaccurate description of 3 D palmprint features by common mean value or Gaussian curvature mapping. Secondly, the shape index image was divided into several blocks, and NTP algorithm was used to extract texture features of divided shape index images. Finally, collaborative representation was used to classify the features. Experiments on 3 D palmprint base show that compared with the classical algorithms, the proposed method has the best recognition effect with recognition rate of 99.52% and recognition time of 0.673 8 s. The proposed method improves the recognition rate by 7.77%, 6.02%, 5.12% and 3.97% respectively compared to Local Binary Pattern (LBP) , Local Ternary Pattern (LTP) , CompCode and Mean Curvature Image (MCI) method; the proposed method reduces the recognition time by 6.7 s, 15.9 s and 61 s compared to Homotopy, Dual Augmented Lagrangian Algorithm (DALM) and SpaRSA method. The experimental results show that the proposed algorithm has good feature extraction and classification ability, which can effectively improve the recognition accuracy and reduce the recognition time.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three%20dimensional%20palmprint&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three dimensional palmprint;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=shape%20index&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">shape index;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=local%20ternary%20pattern&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">local ternary pattern;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=texture%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">texture feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=collaborative%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">collaborative representation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LIU Yuzhen, born in 1964, M. S. , professor. Her research interests include signal detection. ;
                                </span>
                                <span>
                                    JIANG Zhengquan, born in 1995, M. S. His research interests include remote sensing image processing. ;
                                </span>
                                <span>
                                    ZHAO Na, born in 1994, M. S. candidate. Her research interests include image processing, pattern recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-22</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Basic Research Project of Liaoning Provincial Department of Education (LJ2017QL014);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="44">目前, 传统掌纹识别大多基于二维 (two Dimensional, 2D) 掌纹图像进行识别研究。在研究过程中, 2D掌纹的不足之处也渐渐突显出来, 如:手掌不是纯平面, 不能捕捉手掌的深度信息, 系统的光照变化会影响2D掌纹的图像质量, 2D掌纹图像获取较为容易, 易被窃取和复制。3D掌纹作为相比2D掌纹特征更为准确、有效、稳定的生物特征, 进入人们的视线。</p>
                </div>
                <div class="p1">
                    <p id="45">2008, 文献<citation id="218" type="reference">[<a class="sup">1</a>]</citation>中首次提出了三维掌纹识别。同年, 文献<citation id="219" type="reference">[<a class="sup">2</a>]</citation>中详细介绍了3D掌纹识别系统, 文中提取手掌表面的高斯曲率、均值曲率和表面信息作为特征, 采用特征匹配分数级融合的算法进行识别, 有效提高了识别精度。文献<citation id="220" type="reference">[<a class="sup">3</a>]</citation>中通过提取掌纹的均值曲率、Gabor特征进行匹配识别, 实验表明该方法具有精度高、识别率低、存储空间小等优点。文献<citation id="221" type="reference">[<a class="sup">4</a>]</citation>中为了克服样本量小和一对多识别速度低的局限性, 采用表面形状直方图作为有效的掌纹特征, 利用主成分分析 (Principal Component Analysis, PCA) 法进一步压缩了三维信息, 减少了数据维数, 实现了准确、高效的识别。</p>
                </div>
                <div class="p1">
                    <p id="46">掌纹识别系统中关键的问题是如何提取特征向量, 为了更完整地描述掌纹特征, 采用近邻三值模式方法提取掌纹的纹理特征。文献<citation id="222" type="reference">[<a class="sup">5</a>,<a class="sup">6</a>]</citation>表明基于协作表示的分类方法在模式识别领域取得了良好的效果, 本文采用基于协作表示的分类方法。所以, 本文提出基于近邻三值模式与协作表示的三维掌纹识别方法, 利用形状指数将3D掌纹映射成二维数据, 并将形状指数图像均匀分块, 提取分块形状指数图像的近邻三值模式纹理特征, 最后通过协作表示方法分类, 达到掌纹识别的目的。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 3D掌纹纹理特征提取</h3>
                <h4 class="anchor-tag" id="48" name="48">1.1 3D<b>掌纹的形状指数表示</b></h4>
                <div class="p1">
                    <p id="49">3D掌纹数据存储的是掌纹每一点到参考平面的深度信息。文献<citation id="223" type="reference">[<a class="sup">7</a>]</citation>中表明曲率能够很好地描述3D掌纹的特征, 曲率特征能够克服手掌的旋转、平移带来的不利影响, 是一种比较稳定的特征。曲率特征分为高斯曲率和均值曲率, 但是单用一种特征描述掌纹信息存在一定的局限性, 导致识别结果不够准确。本文将高斯曲率特征和均值曲率特征相结合共同表示掌纹特征, 利用形状指数 (Shape Index, SI) 特征来更加完整地表示3D掌纹的几何细节信息。</p>
                </div>
                <div class="p1">
                    <p id="50">假设<i>F</i> (<i>x</i>, <i>y</i>, <i>f</i> (<i>x</i>, <i>y</i>) ) 为3D掌纹曲面<i>S</i>上一点, 其中:<i>x</i>, <i>y</i>是该点在图像中的位置坐标, <i>x</i>是横坐标, <i>y</i>是纵坐标, <i>f</i> (<i>x</i>, <i>y</i>) 是该点相对于参考平面的距离。由式 (1) 、 (2) 分别得到高斯曲率<i>K</i>、均值曲率<i>H</i>:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Κ</mi><mo>=</mo><mfrac><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mspace width="0.25em" /><mi>f</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo>-</mo><mi>f</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>x</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>y</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Η</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>x</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo stretchy="false">) </mo><mi>f</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>y</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo stretchy="false">) </mo><mi>f</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mo>-</mo><mn>2</mn><mi>f</mi><msub><mrow></mrow><mi>x</mi></msub><mspace width="0.25em" /><mi>f</mi><msub><mrow></mrow><mi>y</mi></msub><mspace width="0.25em" /><mi>f</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>x</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo>+</mo><mi>f</mi><msubsup><mrow></mrow><mi>y</mi><mrow><mspace width="0.25em" /><mn>2</mn></mrow></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>3</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中, <i>f</i><sub><i>x</i></sub>, <i>f</i><sub><i>y</i></sub>, <i>f</i><sub><i>xx</i></sub>, <i>f</i><sub><i>yy</i></sub>以及<i>f</i><sub><i>xy</i></sub>分别是<i>f</i> (<i>x</i>, <i>y</i>) 的一阶、二阶和混合偏导。</p>
                </div>
                <div class="p1">
                    <p id="53">形状指数是由曲线曲率的最大值和最小值决定的, 令<i>l</i><sub><i>φ</i></sub>表示3D掌纹曲面<i>S</i>上经过点<i>F</i>的所有曲线, 任意曲线<i>l</i><sub><i>φ</i></sub>在该点的曲率值记为<i>k</i><sub><i>φ</i></sub>。若曲率最大值为<i>k</i><sub>max</sub>, 最小值为<i>k</i><sub>min</sub>, 两者的值可以通过式 (3) 、 (4) 计算:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>k</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>=</mo><mi>Η</mi><mo>+</mo><msqrt><mrow><mi>Η</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mi>Κ</mi></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>k</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo>=</mo><mi>Η</mi><mo>-</mo><msqrt><mrow><mi>Η</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mi>Κ</mi></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">通过计算<i>k</i><sub>max</sub>和<i>k</i><sub>min</sub>, 形状指数可定义为:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>S</mi><mi>Ι</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>-</mo><mfrac><mn>1</mn><mtext>π</mtext></mfrac><mrow><mi>arctan</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mi>k</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>+</mo><mi>k</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow><mrow><mi>k</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>k</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow></mfrac><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">形状指数除了具有高斯、均值曲率的尺度、旋转不变性特点外, 还能将掌纹表面细微的变化体现出来<citation id="224" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。根据式 (5) 中可以确定, 形状指数<i>S</i><sub><i>SI</i></sub>取值区间为[0, 1], 通过式 (6) 转化为灰度图像, 即为形状指数图。</p>
                </div>
                <div class="p1">
                    <p id="58"><i>SI</i>=round (255×<i>S</i><sub><i>SI</i></sub> (<i>x</i>, <i>y</i>) )      (6) </p>
                </div>
                <div class="p1">
                    <p id="59">其中:图像的灰度值均为整数;<i>round</i>代表四舍五入运算;<i>SI</i>就是形状指数图。图1为3D掌纹图像的形状指数图, 图中能够看出3D掌纹清晰分明的线条特征, 在保留主纹理的同时, 也体现了更丰富的细节形状信息。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906024_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 形状指数图" src="Detail/GetImg?filename=images/JSJY201906024_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 形状指数图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906024_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Shape index map</p>

                </div>
                <h4 class="anchor-tag" id="61" name="61">1.2 <b>局部三值模式</b></h4>
                <div class="p1">
                    <p id="62">局部三值模式 (Local Ternary Pattern, LTP) 算法是传统局部二值模式 (Local Binary Pattern, LBP) 算法的改进形式, 也是一种应用在数字图像领域中的纹理分析算子<citation id="225" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。与LBP算法相比, LTP算法中定义了一个阈值, 由此增加了算法的抗噪性。LTP算法采用三值编码的模式, 在原来LBP算法中“0”码和“1”码的基础上增加了“-1”码, 并且自定义一个阈值<i>t</i>。其中心思想是在像素矩阵中, 将邻域像素<i>g</i><sub><i>i</i></sub>与中心像素<i>g</i><sub><i>k</i></sub>作比较, 差值大于等于<i>t</i>, 则标记为1;差值小于-<i>t</i>, 则标记为-1;差值在[-<i>t</i>, <i>t</i>]内, 则标记为0。式 (7) 为LTP的编码方式。</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>Τ</mi><mi>Ρ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>α</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></munderover><mn>3</mn></mstyle><msup><mrow></mrow><mi>i</mi></msup><mi>S</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>α</mi></msub><mo>, </mo><mi>g</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>α</mi></msub><mo>, </mo><mi>g</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mi>α</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>k</mi></msub><mo>≥</mo><mi>t</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">|</mo><mi>g</mi><msub><mrow></mrow><mi>α</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mo>&lt;</mo><mi>t</mi></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>g</mi><msub><mrow></mrow><mi>α</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>k</mi></msub><mo>&lt;</mo><mo>-</mo><mi>t</mi></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>α</i>表示第<i>α</i>个像素, <i>g</i><sub><i>α</i></sub>为其像素灰度值;<i>k</i>表示中心像素, <i>g</i><sub><i>k</i></sub>为其像素灰度值;<i>t</i>为设定的阈值, 由于算法定义了阈值<i>t</i>, 增强了局部纹理特征的分类能力, 提高了鉴别能力和抗噪性。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">1.3 <b>近邻三值模式</b></h4>
                <div class="p1">
                    <p id="67">LTP算法是利用中心像素点与周围相邻像素点间的差异, 通过对比邻域像素与中心像素灰度值的方式确定数量关系<citation id="226" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。该算法忽略了相邻的像素点之间的关系, 没有考虑到相邻像素的对比度信息, 最终得到的特征会丢失局部的差异信息。为了改善这种情况, 对LTP算法作出改进, 提出一种基于相邻像素间差异性的纹理描述方法, 称为近邻三值模式 (Neighbor Ternary Pattern, NTP) , NTP针对的是相邻像素灰度值的差别信息。</p>
                </div>
                <div class="p1">
                    <p id="68">NTP算法既有LTP算法对光照不敏感、抗噪能力较强的优点, 又增加了相邻像素间的对比度。NTP的编码思想是将相邻两个像素的差值与阈值<i>t</i>作对比, 差值在 (-<i>t</i>, <i>t</i>) 范围内标记为0, 差值大于等于<i>t</i>标记为1, 差值小于-<i>t</i>标记为-1。将二进制编码中除1以外的值标记为0后得到的编码, 定义为上模式。将原编码除-1以外的值标记为0后, 用1代替原来的-1, 此编码定义为下模式。上模式和下模式作为两个独立的局部二值模式, 分别获得上、下模式的直方图统计, 最后将图像的上、下模式直方图向量串联起来作为特征用于分类识别。</p>
                </div>
                <div class="p1">
                    <p id="69">图2为3×3窗口大小的NTP像素矩阵。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906024_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 3&#215;3像素矩阵" src="Detail/GetImg?filename=images/JSJY201906024_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 3×3像素矩阵  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906024_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 3×3 pixel matrix</p>

                </div>
                <div class="p1">
                    <p id="71">NTP的计算如式 (8) :</p>
                </div>
                <div class="area_img" id="72">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201906024_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="74">特别定义:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mn>7</mn></msub><mo>≥</mo><mi>t</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">|</mo><mi>g</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false">|</mo><mo>&lt;</mo><mi>t</mi></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>g</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mn>7</mn></msub><mo>&lt;</mo><mo>-</mo><mi>t</mi></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">则该邻域的NTP值为:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>Τ</mi><mi>Ρ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>7</mn></munderover><mi>s</mi></mstyle><msub><mrow></mrow><mi>α</mi></msub><mo>×</mo><mn>3</mn><msup><mrow></mrow><mi>α</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">其中:<i>α</i> (<i>α</i>=0, 1, …, 7) 表示第<i>α</i>个像素点, <i>g</i><sub><i>α</i></sub>为其像素灰度值;<i>t</i>为阈值。<i>t</i>为自定义阈值, 固定的阈值无法适用于所有样本, 因此本文中选择相邻像素差值绝对值的平均值作为阈值, 避免了固定阈值对不同样本的影响。</p>
                </div>
                <div class="p1">
                    <p id="79">NTP的编码过程如图3所示。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906024_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 NTP编码过程" src="Detail/GetImg?filename=images/JSJY201906024_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 NTP编码过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906024_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 NTP encoding process</p>

                </div>
                <h4 class="anchor-tag" id="81" name="81">1.4 <b>纹理特征提取</b></h4>
                <div class="p1">
                    <p id="82">在对二维掌纹图像的处理过程中, 文献<citation id="227" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>]</citation>通过实验证明基于分块统计的特征提取是一种有效的方案。当分块区域大小与图像的纹理特征相互匹配时, 将会得到较好的识别效果, 能够提高系统的识别精度, 因此, 将分块思想应用到三维掌纹的特征提取中来。首先将三维掌纹映射成形状指数图像, 然后把形状指数图像均匀地分割成若干块, 把新分割的区域看作独立的样本。分块以后, 提取的是以每一小块为单位的局部特征, 而不是整个图像的全局特征, 这样能够有效地改善基于全局特征的提取方法对局部变化的敏感程度。</p>
                </div>
                <div class="p1">
                    <p id="83">三维掌纹纹理特征提取的具体过程可描述为如下几个步骤:</p>
                </div>
                <div class="p1">
                    <p id="84">1) 首先将三维掌纹映射成二维形状指数图。</p>
                </div>
                <div class="p1">
                    <p id="85">2) 将形状指数图像对应的<i>M</i>维矩阵<b><i>G</i></b>作分块处理, 将矩阵均分为大小相等的若干个矩阵。</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">G</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>n</mi></mrow></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>n</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mi>n</mi><mn>1</mn></mrow></msub></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mi>n</mi><mn>2</mn></mrow></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>n</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">式中, <b><i>G</i></b><sub><i>ij</i></sub>为<i>m</i>×<i>m</i>大小的方阵, <i>M</i>=<i>n</i>×<i>m</i>。</p>
                </div>
                <div class="p1">
                    <p id="88">3) 提取每块图像矩阵的NTP直方图, 将各个直方图矩阵<b><i>G</i></b>′<sub><i>ij</i></sub>串联起来, 迭加形成一个NTP直方图矩阵<b><i>G</i></b>′, 作为三维掌纹的特征。</p>
                </div>
                <div class="p1">
                    <p id="89"><b><i>G</i></b>′=[<b><i>G</i></b>′<sub>11</sub>, <b><i>G</i></b>′<sub>12</sub>, …, <b><i>G</i></b>′<sub><i>n</i>1</sub>, …, <b><i>G</i></b>′<sub><i>nn</i>-1</sub>, <b><i>G</i></b>′<sub><i>nn</i></sub>]      (12) </p>
                </div>
                <div class="p1">
                    <p id="90">4) 将提取的直方图特征, 用于匹配识别。</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">2 基于NTP和协作表示的掌纹识别算</h3>
                <div class="p1">
                    <p id="92">“协作表示”是在稀疏表示 (<i>Sparse Representation for Classification</i>, <i>SRC</i>) 的基础上发展而来的<citation id="228" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 文献<citation id="229" type="reference">[<a class="sup">14</a>]</citation>中对<i>SRC</i>分类方法的基本原理作了详细的分析, 指出在<i>SRC</i>分类方法中, 样本类别之间的协作表示特性比<i>l</i><sub>1</sub>范数的稀疏特性更加重要。文中提出了用<i>l</i><sub>2</sub>范数来替代SRC算法中的<i>l</i><sub>1</sub>范数, 这种分类方法叫作基于协作表示和规则最小二乘法的分类识别 (Collaborative Representation Classification with Regularized Least Square, CRC_RLS) 方法。通过实验表明, CRC_RLS不仅具有良好的分类效果, 而且识别速度快于SRC, 因此本文采用CRC_RLS的分类方法。</p>
                </div>
                <div class="p1">
                    <p id="93">在本章中, 首先对模式识别领域中的经典分类方法SRC算法原理作了具体的分析, 分析该算法的优缺点, 并进一步提出了基于NTP特征与协作表示的三维掌纹识别, 即NTP_CRC (NTP with Collaborative Representation Classification) 。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">2.1 SRC<b>算法</b></h4>
                <div class="p1">
                    <p id="95"><i>SRC</i>的主要思想是通过训练样本字典中原子的线性组合来表示测试样本的特征。对于每个类别, 字典用于原始图像的重建, 并将具有最小残差的类别判定为测试图像类别。在训练样本库足够大的情况下, 将与测试样本属于同一类别的系数看作非零, 与测试样本类别不同的系数看作零, 称这种表示为稀疏表示<citation id="230" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="96">对于<i>K</i>类掌纹的训练样本集<b><i>A</i></b>记作<b><i>A</i></b>=[<b><i>A</i></b><sub>1</sub>, <b><i>A</i></b><sub>2</sub>, …, <b><i>A</i></b><sub><i>K</i></sub>], 第<i>i</i>类训练样本用<b><i>A</i></b><sub><i>i</i></sub>=[<b><i>v</i></b><sub><i>i</i>, 1</sub>, <b><i>v</i></b><sub><i>i</i>, 2</sub>, …, <b><i>v</i></b><sub><i>i</i>, <i>n</i><sub><i>i</i></sub></sub>]∈<b>R</b><sup><i>m</i>×<i>n</i><sub><i>i</i></sub></sup>表示, <b><i>v</i></b><sub><i>i</i>, <i>j</i></sub> (<i>j</i>=1, 2, …, <i>n</i><sub><i>i</i></sub>) 为第<i>i</i>类掌纹的第<i>j</i>个样本的特征向量, 特征向量维度为<i>n</i>。假设一个测试样本的特征向量为<b><i>y</i></b>, 则<b><i>y</i></b>可以用训练样本集的特征线性表示出来, 即<b><i>y</i></b>≈<b><i>A</i></b><i>γ</i>, <i>γ</i>=[<i>γ</i><sub>1</sub>;<i>γ</i><sub>2</sub>;…;<i>γ</i><sub><i>K</i></sub>], 其中<i>γ</i><sub><i>i</i></sub>为第<i>i</i>类的编码系数矢量, 表示为<i>γ</i><sub><i>i</i></sub>=[<i>γ</i><sub><i>i</i>, 1</sub>, <i>γ</i><sub><i>i</i>, 2</sub>, …, <i>γ</i><sub><i>i</i>, <i>n</i><sub><i>i</i></sub></sub>]<sup>T</sup>。若测试样本的特征向量<b><i>y</i></b>属于第<i>i</i>类掌纹, 则<b><i>y</i></b>≈<b><i>A</i></b><sub><i>i</i></sub><i>γ</i><sub><i>i</i></sub>成立。因此, 可以通过系数矢量<i>γ</i>和训练样本集<b><i>A</i></b>来完成样本重构过程, 通过计算重构后的残差来确定各类样本的最终类别信息。</p>
                </div>
                <div class="p1">
                    <p id="97">SRC算法的具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="98">1) 对所有训练及测试样本特征向量作归一化处理, 使得每个元素的<i>l</i><sub>2</sub>范数为1, 计算训练字典<i>K</i>和测试样本特征向量<b><i>y</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="99">2) 解式 (13) 中最小<i>l</i><sub>1</sub>范数问题。</p>
                </div>
                <div class="p1">
                    <p id="100"><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi>γ</mi></munder><mo stretchy="false">∥</mo><mi>γ</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>; ‖<b><i>y</i></b>-<b><i>A</i></b><i>γ</i>‖<sub>2</sub>&lt;<i>ε</i>      (13) </p>
                </div>
                <div class="p1">
                    <p id="102">其中, <i>ε</i>表示<b><i>y</i></b>与<i>γ</i>之间的编码误差。</p>
                </div>
                <div class="p1">
                    <p id="103">3) 计算残差。</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>i</mi></msub><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中, <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>为第<i>i</i>类的编码系数矢量。</p>
                </div>
                <div class="p1">
                    <p id="107">4) 计算测试样本的类别。</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi>i</mi></munder><mo stretchy="false">{</mo><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109">将使<i>e</i><sub><i>i</i></sub> (<b><i>y</i></b>) 值最小的<i>i</i>所对应的类别作为测试样本的类别, 用<i>identity</i> (<b><i>y</i></b>) 表示。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110">2.2 CRC_RLS<b>算法</b></h4>
                <div class="p1">
                    <p id="111"><i>SRC</i>在模式识别领域被广泛使用, 在相关工作中体现了该方法的重要性。研究人员在对稀疏表示的研究中对<i>l</i><sub>1</sub>范数所起的作用表现出质疑的态度, 没有相关的经验与理论知识表明<i>l</i><sub>1</sub>范数的稀疏约束条件能够完善识别性能, <i>l</i><sub>1</sub>范数求解过程过于复杂, 使得计算复杂度增加。同时, 从SRC算法的主要流程中可以看到两个重点部分:一是测试样本特征向量<b><i>y</i></b>的编码系数矢量必须呈稀疏分布;二是测试样本特征向量<b><i>y</i></b>的稀疏编码并不是每类训练样本单独作用的结果, 而是所有训练样本协作共同作用的结果。目前很多文献都在强调<i>l</i><sub>1</sub>范数稀疏特性的重要性, 而忽略了协作表示的重要性。协作表示就是使用来自所有类的训练样本来表示测试样本<citation id="231" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。基于协作表示的分类原理与稀疏表示分类算法类似, 都是依据重建残差最小作为分类标准。</p>
                </div>
                <div class="p1">
                    <p id="112">CRC_RLS的基本过程如下:</p>
                </div>
                <div class="p1">
                    <p id="113">对<i>K</i>类掌纹的训练样本集<b><i>A</i></b>记作<b><i>A</i></b>=[<b><i>A</i></b><sub>1</sub>, <b><i>A</i></b><sub>2</sub>, …, <b><i>A</i></b><sub><i>K</i></sub>], 第<i>i</i>类训练样本用<b><i>A</i></b><sub><i>i</i></sub>=[<b><i>v</i></b><sub><i>i</i>, 1</sub>, <b><i>v</i></b><sub><i>i</i>, 2</sub>, …, <b><i>v</i></b><sub><i>i</i>, <i>n</i><sub><i>i</i></sub></sub>]∈<b>R</b><sup><i>m</i>×<i>n</i><sub><i>i</i></sub></sup>表示, <b><i>v</i></b><sub><i>i</i>, <i>j</i></sub> (<i>j</i>=1, 2, …, <i>n</i><sub><i>i</i></sub>) 为第<i>i</i>类掌纹的第<i>j</i>个样本的特征向量, 特征向量维度为<i>n</i>。假设一个测试样本的特征向量为<b><i>y</i></b>∈<b>R</b><sup><i>m</i></sup>, 则<b><i>y</i></b>可以用训练样本集的特征向量线性表示出来, <b><i>y</i></b>≈<b><i>A</i></b><i>χ</i>, <i>χ</i>=[<i>χ</i><sub>1</sub>;<i>χ</i><sub>2</sub>;…;<i>χ</i><sub><i>K</i></sub>], 其中<i>χ</i><sub><i>i</i></sub>为第<i>i</i>类的编码系数矢量, 表示为<i>χ</i><sub><i>i</i></sub>=[<i>χ</i><sub><i>i</i>, 1</sub>, <i>χ</i><sub><i>i</i>, 2</sub>, …, <i>χ</i><sub><i>i</i>, <i>n</i><sub><i>i</i></sub></sub>]<sup>T</sup>。若测试样本的特征向量<b><i>y</i></b>属于第<i>i</i>类掌纹, <b><i>y</i></b>≈<b><i>A</i></b><sub><i>i</i></sub><i>χ</i><sub><i>i</i></sub>成立。用所有训练样本来协同表示测试样本, 为了简化运算, <b><i>y</i></b>可以将SRC算法中的基于<i>l</i><sub>1</sub>范数的约束条件简化为求解规则化最小二乘问题。这实际上解决了以下优化问题:</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">χ</mi><mo>^</mo></mover><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi>χ</mi></munder><mo stretchy="false">{</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><mi mathvariant="bold-italic">χ</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">χ</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">其中<i>λ</i>是规则化参数。与SRC算法相比, 解式 (16) 所示基于规则化最小二乘的问题要比求解基于<i>l</i><sub>1</sub>范数的最优解问题要简单很多, 经计算得:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">χ</mi><mo>^</mo></mover><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">y</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">其中<b><i>I</i></b>∈<b>R</b><sup><i>n</i>×<i>n</i></sup>是单位矩阵, 令<b><i>P</i></b>= (<b><i>A</i></b><sup>T</sup><b><i>A</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>A</i></b><sup>T</sup>, 可以看出, <b><i>P</i></b>独立于<b><i>y</i></b>, 并且可以通过样本集预先计算, <b><i>P</i></b>可作为投影矩阵。在对测试样本<b><i>y</i></b>进行识别过程中, 只需将<b><i>y</i></b>投影到<b><i>P</i></b>上, 直接计算系数向量, 进而得到<b><i>P</i></b><b><i>y</i></b>, 从而降低了计算复杂度, 表明与SRC相比, CRC更具有速度优势。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118">2.3 <b>本文算法</b>NTP_CRC</h4>
                <div class="p1">
                    <p id="119">本文利用1.4节所提出的三维掌纹特征提取方案, 首先提取三维掌纹的形状指数图像, 将形状指数均匀分成若干小块后, 分别提取每块的<i>NTP</i>直方图, 将所有直方图级联起来, 作为最终特征, 最后利用<i>CRC</i>_<i>RLS</i>算法实现掌纹类别的分类, 即基于<i>NTP</i>与协作表示的三维掌纹识别算法<i>NTP</i>_<i>CRC</i>。</p>
                </div>
                <div class="p1">
                    <p id="120">基于<i>NTP</i>特征和协作表示的三维掌纹识别算法的详细步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="121">1) 将训练和测试3<i>D</i>掌纹感兴趣区域 (<i>Region Of Interest</i>, <i>ROI</i>) 映射成形状指数图像。</p>
                </div>
                <div class="p1">
                    <p id="122">2) 将各样本的形状指数图进行均匀分块, 提取各样本的<i>NTP</i>直方图。</p>
                </div>
                <div class="p1">
                    <p id="123">3) 将提取的<i>NTP</i>直方图级联起来, 成为一个特征矩阵。</p>
                </div>
                <div class="p1">
                    <p id="124">4) 将每个样本的<i>NTP</i>特征作归一化处理, 计算得到训练字典<b><i>A</i></b>与<b><i>y</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="125">5) 解决式 (16) 规则化最小二乘问题。</p>
                </div>
                <div class="p1">
                    <p id="126">计算可得<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">χ</mi><mo>^</mo></mover><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">y</mi></mrow></math></mathml>, 投影矩阵<b><i>P</i></b>= (<b><i>A</i></b><sup>T</sup><b><i>A</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>A</i></b><sup>T</sup>。</p>
                </div>
                <div class="p1">
                    <p id="128">6) 计算规则化残差。</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><mo>-</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>i</mi></msub><mover accent="true"><mi mathvariant="bold-italic">χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>/</mo><mo stretchy="false">∥</mo><mover accent="true"><mi mathvariant="bold-italic">χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">其中, <i>χ</i><sub><i>i</i></sub>为第<i>i</i>类的编码系数矢量。</p>
                </div>
                <div class="p1">
                    <p id="131">7) 计算测试样本<i>y</i>的类别。</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi>i</mi></munder><mo stretchy="false">{</mo><mi>ε</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="133" name="133" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="134" name="134">3.1 <b>实验环境与评价指标</b></h4>
                <div class="p1">
                    <p id="135">实验环境为<i>Matlab R</i>2015<i>a</i>、<i>Windows</i> 7系统, 中央处理器为<i>Intel Core i</i>3- 2120, 主频为3.3 <i>GHz</i>, 内存为4 <i>GB</i>。</p>
                </div>
                <div class="p1">
                    <p id="136">本文算法的性能评价指标为正确识别率 (<i>Correct Recognition Rate</i>, <i>CRR</i>) , <i>CRR</i>是系统正确识别出合法者的次数占实验总次数的百分比, 可用式 (20) 表示:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mtext>R</mtext><mtext>R</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>V</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow><mrow><mi>V</mi><msub><mrow></mrow><mi>Μ</mi></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">其中:<i>V</i><sub><i>N</i></sub>表示正确识别次数;<i>V</i><sub><i>M</i></sub>表示实验总次数。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">3.2 <b>实验图库</b></h4>
                <div class="p1">
                    <p id="140">香港理工大学的生物识别研究中心开发了一个实时的3<i>D</i>掌纹采集设备, 通过该设备能够同时采集2<i>D</i>和3<i>D</i>掌纹图像, 构建一个大型的2<i>D</i>和3<i>D</i>掌纹数据库。本文在两个掌纹库进行实验, 库中包含了从200人的左、右手掌采集的8 000个样本。掌纹分两次采集, 平均间隔为30 <i>d</i>。每次采集左、右手掌各10个掌纹。第一次采集的掌纹数据作为训练样本集, 第二次采集的掌纹数据为测试样本。三维掌纹库中的每个样本都包含一个三维感兴趣区域 (<i>ROI</i>) , 每个3<i>D ROI</i>数据存储在二进制文件记录, 该二进制文件包含128×128浮点值, 表示掌纹每一点到参考平面的深度信息。每个2<i>D ROI</i>图像的格式为<i>BMP</i>, 大小为128 <i>pixels</i>×128 <i>pixels</i>, 与3<i>D ROI</i>一一对应。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141">3.3 <b>结果分析</b></h4>
                <h4 class="anchor-tag" id="142" name="142">3.3.1 确定最佳分块方式</h4>
                <div class="p1">
                    <p id="143">本文在进行纹理特征提取时, 将形状指数图作了分块处理。图像分为若干个大小相同的子块, 当子块大小与图像的纹理特征相互匹配时, 将得到较好的识别效果。通过计算不同分块情况下的识别率, 比较识别率大小, 确定最佳的分块方式。</p>
                </div>
                <div class="p1">
                    <p id="144">表1分别给出了不同分块情况下的<i>CRR</i>。从表1中可以看出, 在不作分块处理的情况下, <i>CRR</i>值为89.98%;当采用4×4分块方式时, <i>CRR</i>值最高, 为99.52%;当采用5×5、6×6、7×7分块方式时, <i>CRR</i>值分别为97.35%、95.25%和91.80%;随着块数的增加, <i>CRR</i>值呈现出下降的趋势。经过分析可知, 分块区域过大, 不能精确提取掌纹的局部纹理特征;分块区域过小, 则导致局部的纹理特征被分割, 不能有效地表征掌纹的纹理结构, 得到的纹理特征区分度不大, 从而影响识别精度。因此, 适当的分块方式能够有效地提高系统的识别性能。</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表</b>1 <b>不同分块情况下识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Recognition rate under different division conditions</i></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />分块方式</td><td>识别率/%</td><td></td><td>分块方式</td><td>识别率/%</td></tr><tr><td><br />1×1</td><td>89.98</td><td></td><td>5×5</td><td>97.35</td></tr><tr><td><br />2×2</td><td>93.17</td><td></td><td>6×6</td><td>95.25</td></tr><tr><td><br />3×3</td><td>96.24</td><td></td><td>7×7</td><td>91.80</td></tr><tr><td><br />4×4</td><td>99.52</td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="146" name="146">3.3.2 2<i>D</i>掌纹对比实验</h4>
                <div class="p1">
                    <p id="147">3<i>D</i>掌纹与2<i>D</i>掌纹进行对比实验, 采用基于<i>NTP</i>和协作表示的二维掌纹识别方法。对2<i>D</i>掌纹作分块处理, 提取各块的<i>NTP</i>纹理直方图, 将各块级联的直方图作为特征向量, 最后利用<i>CRC</i>_<i>RLS</i>方法进行类别分类。3<i>D</i>掌纹识别的<i>CRR</i>值为99.52%, 2<i>D</i>掌纹识别的<i>CRR</i>值为98.98%, 表明3<i>D</i>掌纹的特征信息比2<i>D</i>掌纹更为丰富, 因此识别效果较好。</p>
                </div>
                <h4 class="anchor-tag" id="148" name="148">3.3.3 验证本文算法的有效性</h4>
                <div class="p1">
                    <p id="149">在基于<i>NTP</i>特征和协作表示的3<i>D</i>掌纹识别中, 首先将3<i>D</i>掌纹的<i>ROI</i>映射成形状指数图像, 然后将形状指数图均匀分块, 利用<i>NTP</i>提取各块的形状指数直方图特征, 将所有块的直方图连接在一起作为特征向量, 最后利用<i>CRC</i>_<i>RLS</i>方法进行类别分类。在本节中, 为了验证本文所提算法的性能, 与其他几种经典算法进行了比较。本次实验选择较为经典的算法作对比实验, 如<i>LBP</i>法、<i>LTP</i>法、<i>CompCode</i><citation id="232" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、均值曲率图 (<i>Mean Curvature Image</i>, <i>MCI</i>) 法<citation id="233" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>及高斯曲率图 (<i>Gaussian Curvature Image</i>, <i>GCI</i>) 法<citation id="234" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="150">表2为不同方法的识别效果。根据表2中的实验结果能够看出, 利用本文特征提取方法得到的<i>CRR</i>值为99.52%, 与经典<i>LBP</i>、<i>LTP</i>、<i>CompCode</i>、<i>MCI</i>法相比分别提高了7.77、6.02、5.12、3.97个百分点, 表明本文提出的方法具有较强的表征3<i>D</i>掌纹局部纹理特征的能力, 识别效果优于其他方法。</p>
                </div>
                <div class="area_img" id="151">
                    <p class="img_tit"><b>表</b>2 <b>不同特征提取方法的识别效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Recognition effect of different feature extraction methods</i></p>
                    <p class="img_note"></p>
                    <table id="151" border="1"><tr><td><br />特征提取方法</td><td>识别率/%</td><td></td><td>特征提取方法</td><td>识别率/%</td></tr><tr><td><br /><i>LBP</i></td><td>91.75</td><td></td><td><i>MCI</i></td><td>95.55</td></tr><tr><td><br /><i>LTP</i></td><td>93.50</td><td></td><td><i>GCI</i></td><td>67.10</td></tr><tr><td><br /><i>CompCode</i></td><td>94.40</td><td></td><td>本文方法</td><td>99.52</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="152" name="152">3.3.4 验证<i>CRC</i>_<i>RLS</i>分类方法的性能</h4>
                <div class="p1">
                    <p id="153">本文提出利用<i>CRC</i>_<i>RLS</i>方法进行3<i>D</i>掌纹识别, 具有较快的计算速度, 为了更加准确地体现该方法的优越性能, 在本次实验中采用统一的特征提取方法, 即<i>NTP</i>形状指数直方图特征, 然后利用不同的分类方法进行匹配识别。选择目前较为流行的解决基于<i>l</i><sub>1</sub>范数最小化问题的方法, 如Homotopy<citation id="235" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、SpaRSA<citation id="236" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、对偶增广拉格朗日法 (Dual Augmented Lagrangian Algorithm, DALM) <citation id="237" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 分别记作CR_L1_Homotopy、CR_L1_SpaRSA、CR_L1_DALM。实验过程中, 分别记录每种分类方法的CRR及识别时间。</p>
                </div>
                <div class="p1">
                    <p id="154">表3为各分类方法的识别效果和识别时间。根据表3中的数据可知, 本文所利用的CRC_RLS方法的识别时间为0.673 8 s, 与Homotopy、DALM、SpaRSA方法相比分别降低了6.7 s、15.9 s、61 s, 表明求解基于规则化最小二乘的问题比求解基于<i>l</i><sub>1</sub>范数的最优解问题要简单很多, CRC_RLS方法具有较快的计算速度。</p>
                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表</b>3 <b>不同分类方法的识别效果和分类时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Recognition effect and recognition time of different methods</p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />分类方法</td><td>识别率/%</td><td>识别时间/s</td></tr><tr><td><br />CR_L1_Homotopy</td><td>96.94</td><td>7.384 5</td></tr><tr><td><br />CR_L1_DALM</td><td>99.35</td><td>16.564 5</td></tr><tr><td><br />CR_L1_SpaRSA</td><td>98.89</td><td>62.044 3</td></tr><tr><td><br />本文算法</td><td>99.52</td><td>0.673 8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="156" name="156" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="157">基于二维掌纹图像具有获取容易、易被仿冒, 并且手掌不是纯表面、不能体现手掌的深度信息等缺点。本文以三维掌纹为研究对象, 提出基于近邻三值模式与协作表示的三维掌纹识别方法。该方法首先采用形状指数来描述三维掌纹的表面几何信息, 并对形状指数图作分块处理, 然后利用<i>NTP</i>算法提取形状指数图像的纹理特征, 最后利用协作表示的方法进行特征分类。在香港理工大学<i>PolyU</i> 3<i>D</i>掌纹库上进行实验, 实验结果表明本文方法正确识别率为99.52%, 识别时间为0.673 8 <i>s</i>, 具有一定的应用前景。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="178">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A multimodal biometricauthentication system based on 2D and 3D palmprint features">

                                <b>[1]</b>AGGITHAYA V K, ZHANG D, LUO N.A multimodal biometric authentication system based on 2D and 3D palmprint features[C]//Proceedings of the SPIE 6944-the International Society for Optical Engineering, Biometric Technology for Human Identification V.Bellingham:SPIE, 2008:69440C.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Three Dimensional Palmprint Recognition using Structured Light Imaging">

                                <b>[2]</b>ZHANG D, LU G M, LI W, et al.Three dimensional palmprint recognition using structured light imaging[C]//Proceedings of the2008 IEEE Second International Conference on Biometrics:Theory, Applications and Systems.Piscataway, NJ:IEEE, 2008:1-6.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Person identification by using3D palmprint data">

                                <b>[3]</b>BAI X, HUANG S, GAO N, et al.Person identification by using3D palmprint data[C]//Proceedings of the SPIE 10025, Advanced Sensor Systems and Applications VII.Bellingham:SPIE, 2016:100250Q.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF7BD2028DE7F7C32396CD8900EDECB27&amp;v=MDc3MTlodzd5Mndxdz1OaWZPZmNXL2JLWE9yNDFORUo0SWVudEt6QlFRNHprT1BIZnJyQkpBRGNmbk43aVlDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>BAI X, GAO N, ZHANG Z, et al.3D palmprint identification combining blocked ST and PCA[J].Pattern Recognition Letters, 2017, 100:89-95.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201408070&amp;v=MjA1MzQ5Q1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjNNTHo3U1pMRzRIOVhNcDQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>林国军, 解梅.一种鲁棒协作表示的人脸识别算法[J].计算机应用研究, 2014, 31 (8) :2520-2522, 2531. (LIN G J, XIE M.Face recognition algorithm of robust collaborative representation[J].Application Research of Computers, 2014, 31 (8) :2520-2522, 2531.) 
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD717390E51AA4568FE45A40A9D3FEAFA1&amp;v=MzAwNTVtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3kyd3F3PU5qN0JhclM1R2RMRnIvcEFaWnArQ0hrL3gyQm03am9NVEgrVHBXWTJEOGZsTTh1ZUNPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>GUO X M, ZHOU W D, ZHANG Y L.Collaborative representation with HM-LBP features for palmprint recognition[J].Machine Vision and Applications, 2017, 28 (3/4) :283-291.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Palmprint Recognition Using 3-D Information">

                                <b>[7]</b>ZHANG D, LU G M, LI W, et al.Palmprint recognition using 3-Dinformation[J].IEEE Transactions on Systems, Man and Cybernetics, Part C:Applications and Reviews, 2009, 39 (5) :505-519.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201412011&amp;v=MDg2ODFyQ1VSN3FmWnVac0Z5L2hXcjNNSWluTWJiRzRIOVhOclk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>杨冰, 王小华, 杨鑫.基于局部纹理特征的三维掌纹识别研究[J].光电工程, 2014, 41 (12) :53-59. (YANG B, WANG X H, YANG X.3D Palmprint recognition based on local texture feature sets[J].Opto-Electronic Engineering, 2014, 41 (12) :53-59.) 
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGJL201601013&amp;v=MDc1Njc0SDlmTXJvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3IzTVB5ckJZckc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>姚骋天, 夏哲雷.一种改进的局部三值模式的人脸识别方法[J].中国计量学院学报, 2016, 27 (1) :68-72. (YAO C T, XIAZ L.Face recognition based on improved local ternary patterns[J].Journal of China University of Metrology, 2016, 27 (1) :68-72.) 
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201505028&amp;v=MjYzMTMzenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01OaWZZWkxHNEg5VE1xbzlIYklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>刘海军.局部方向三值模式纹理描述子[J].计算机工程与设计, 2015, 36 (5) :1260-1264, 1303. (LIU H J.Texture descriptor of local directional ternary patterns[J].Computer Engineering and Design, 2015, 36 (5) :1260-1264, 1303.) 
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201211030&amp;v=MjI0MDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3IzTUlpblJaTEc0SDlQTnJvOUdaSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>林森, 苑玮琦, 吴微, 等.基于离散余弦变换和主线分块能量的模糊掌纹识别[J].光电子·激光, 2012, 23 (11) :2200-2206. (LIN S, YUAN W Q, WU W, et al.Blurred palmprint recognition based on DCT and block enrgy of principal lines[J].Journal of Optoelectronics·Laser, 2012, 23 (11) :2200-2206.) 
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014081208.nh&amp;v=MjM4NTlHRnJDVVI3cWZadVpzRnkvaFdyM01WRjI2R3JPd0g5UE1wNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>李善广.基于分块的掌纹识别算法研究[D].哈尔滨:哈尔滨工业大学, 2013:18-23. (LI S G.Research on modular palmprint recognition algorithms[D].Harbin:Harbin Institute of Technology, 2013:18-23.) 
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016276661.nh&amp;v=MTk2OTJycEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01WRjI2R0xHL0dOZks=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>芦鑫.基于稀疏表示的遮挡人脸识别算法的研究与实现[D].北京:华北电力大学, 2016:7-16. (LU X.Research and implementation of occluded face recognition based on sparse representation[D].Beijing:North China Electric Power University, 2016:7-16.) 
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse representation or collaborative representation:Which helps face recognition?">

                                <b>[14]</b>ZHANG L, YANG M, FENG X C.Sparse representation or collaborative representation:which helps face recognition?[C]//Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:471-478.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201412012&amp;v=MDg3NzNZOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9oV3IzTUlpbk1iYkc0SDlYTnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>王文龙, 金炜, 谢芸, 等.采用均匀局部二元模式及稀疏表示的掌纹识别[J].光电工程, 2014, 41 (12) :60-65. (WANG W L, JIN W, XIE Y, et al.Palmprint recognition using uniform local binary patterns and sparse representation[J].Opto-Electronic Engineering, 2014, 41 (12) :60-65.) 
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201402059&amp;v=MDAxNjNVUjdxZlp1WnNGeS9oV3IzTU5pZllaTEc0SDlYTXJZOUFiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>张宏星, 邹刚, 赵键, 等.基于Gabor特征与协同表示的人脸识别算法[J].计算机工程与设计, 2014, 35 (2) :666-670, 676. (ZHANG H X, ZOU G, ZHAO J, et al.Face recognition algorithm based on Gabor feature and collaborative representation[J].Computer Engineering and Design, 2014, 35 (2) :666-670, 676.) 
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1CC3D2C4D96804348D2A8074DCF26426&amp;v=MDk4NTNkSzRyZnhCRU9JSkJIdzl6QklibmowTVFIL2xxR1pHRDdDU1FiaVpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh3N3kyd3F3PU5pZk9mYkxMYg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>ZHANG L, LI L D, YANG A Q, et al.Towards contactless palmprint recognition:a novel device, a new benchmark, and a collaborative representation based identification approach[J].Pattern Recognition, 2017, 69:199-212.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013028666.nh&amp;v=MDc1NTVoV3IzTVZGMjZIYk82RnRmS3FaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>曹忠赞.基于2D和3D掌纹图像方向特征融合的掌纹识别研究[D].秦皇岛:燕山大学, 2013:13-17. (CAO Z Z.Study on palmprint recognition based on 2D and 3D palmprint image orientation features fusion[D].Qinhuangdao:Yashan University, 2013:13-17.) 
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201105015&amp;v=MTU0NjFyQ1VSN3FmWnVac0Z5L2hXcjNNUHlyZmJMRzRIOURNcW85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>李春燕, 卢光明, 黎伟.基于曲面曲率和RLDA 3D掌纹识别方法[J].中国图象图形学报, 2011, 16 (5) :807-812. (LI C Y, LU G M, LI W.3D palmprint recognition based on surface curvature and RLDA[J].Journal of Image and Graphics, 2011, 16 (5) :807-812.) 
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D palmprint identification using block-wise features and collaborative representation">

                                <b>[20]</b>ZHANG L, SHEN Y, LI H Y, et al.3D palmprint identification using block-wise features and collaborative representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (8) :1730-1736.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906024" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906024&amp;v=MTQzNDNCZDdHNEg5ak1xWTlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyM01Mejc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
