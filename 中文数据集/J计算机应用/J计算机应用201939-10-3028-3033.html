<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136463438877500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910039%26RESULT%3d1%26SIGN%3dcHTfFe0isTerM229yVqA1QOt2oc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910039&amp;v=MjkxMTVHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqa1Y3M0FMejdCZDdHNEg5ak5yNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 一致性点漂移算法 ">1 一致性点漂移算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="2 全局和局部混合距离 ">2 全局和局部混合距离</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="2.1 &lt;b&gt;全局距离&lt;/b&gt;">2.1 <b>全局距离</b></a></li>
                                                <li><a href="#56" data-title="2.2 &lt;b&gt;局部距离&lt;/b&gt;">2.2 <b>局部距离</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="3 本文算法 ">3 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="3.1 &lt;b&gt;局部相似性的改进&lt;/b&gt;">3.1 <b>局部相似性的改进</b></a></li>
                                                <li><a href="#68" data-title="3.2 &lt;b&gt;全局局部相似性测度&lt;/b&gt;">3.2 <b>全局局部相似性测度</b></a></li>
                                                <li><a href="#75" data-title="3.3 &lt;b&gt;全局与局部测度引导的配准过程&lt;/b&gt;">3.3 <b>全局与局部测度引导的配准过程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="4 实验与分析 ">4 实验与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#103" data-title="4.1 &lt;b&gt;合成点集配准实验&lt;/b&gt;">4.1 <b>合成点集配准实验</b></a></li>
                                                <li><a href="#117" data-title="4.2 &lt;b&gt;真实图像配准实验&lt;/b&gt;">4.2 <b>真实图像配准实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="图1 邻域之间的局部距离">图1 邻域之间的局部距离</a></li>
                                                <li><a href="#78" data-title="图2 本文算法流程">图2 本文算法流程</a></li>
                                                <li><a href="#99" data-title="图3 二维点集配准结果">图3 二维点集配准结果</a></li>
                                                <li><a href="#100" data-title="图4 二维点集配准算法性能比较">图4 二维点集配准算法性能比较</a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;二维点集配准误差&lt;/b&gt; 单位:像素"><b>表</b>1 <b>二维点集配准误差</b> 单位:像素</a></li>
                                                <li><a href="#113" data-title="图5 本文算法针对三维点集配准结果">图5 本文算法针对三维点集配准结果</a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;三维点集配准误差&lt;/b&gt;"><b>表</b>2 <b>三维点集配准误差</b></a></li>
                                                <li><a href="#121" data-title="图6 &lt;i&gt;MRI&lt;/i&gt;图像配准结果">图6 <i>MRI</i>图像配准结果</a></li>
                                                <li><a href="#122" data-title="图7 &lt;i&gt;MRI&lt;/i&gt;图像配准召回率曲线">图7 <i>MRI</i>图像配准召回率曲线</a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表&lt;/b&gt;3 MRI&lt;b&gt;图像配准误差&lt;/b&gt;"><b>表</b>3 MRI<b>图像配准误差</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="163">


                                    <a id="bibliography_1" title="MA J,ZHAO J,JIANG J,et al.Locality preserving matching[J].International Journal of Computer Vision,2019,127(5):512-531." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locality preserving matching">
                                        <b>[1]</b>
                                        MA J,ZHAO J,JIANG J,et al.Locality preserving matching[J].International Journal of Computer Vision,2019,127(5):512-531.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_2" title="FERRANTE E,PARAGIOS N.Slice-to-volume medical image registration:a survey[J].Medical Image Analysis,2017,39:101-123." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9B4EFF9872AE477D3D38B99F24808461&amp;v=MzAzMDVoQXhjYktjUWJ5ZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTd3cUE9TmlmT2ZicktHcVM2MllaTlkrbCtlWGcreUdJUW5qeDFPbmJyMg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        FERRANTE E,PARAGIOS N.Slice-to-volume medical image registration:a survey[J].Medical Image Analysis,2017,39:101-123.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_3" title="GUAN S,WANG T,MENG C,et al.A review of point feature based medical image registration[J].Chinese Journal of Mechanical Engineering,2018,31:No.76." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YJXB201804002&amp;v=MDg0MTJxNDlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqa1Y3M0FQQ2ZUYkxHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        GUAN S,WANG T,MENG C,et al.A review of point feature based medical image registration[J].Chinese Journal of Mechanical Engineering,2018,31:No.76.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_4" title="TANG H,PAN A,YANG Y,et al.Retinal image registration based on robust non-rigid point matching method[J].Journal of Medical Imaging and Health Informatics,2018,8(2):240-249." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH867043E7898C3DA61A2E47220B519321&amp;v=MDA5MThBPU5pZktacnUrR2RISXJQcENiT0lIZjM5TnZoQVNtejBJVEhqZ3JoSkhmTE9kUnJpZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTd3cQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        TANG H,PAN A,YANG Y,et al.Retinal image registration based on robust non-rigid point matching method[J].Journal of Medical Imaging and Health Informatics,2018,8(2):240-249.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_5" title="WU Y,MA W,ZHANG J,et al.Point-matching algorithm based on local neighborhood information for remote sensing image registration[J].Journal of Applied Remote Sensing,2018,12(1):No.016002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG6B7C7EA8B09D7C03EC41FC6B3C63266F&amp;v=MjExNDJmQnJMVTA1dHBoeExtN3dxQT1OaWZPYWJYS0dhTEwydjVORnVzR2VIdEt6eFZtbVR0OFBnemszaEZHZjdHV1E3enBDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        WU Y,MA W,ZHANG J,et al.Point-matching algorithm based on local neighborhood information for remote sensing image registration[J].Journal of Applied Remote Sensing,2018,12(1):No.016002.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_6" title="BELONGIE S,MALIK J,PUZICHA J.Shape matching and object recognition using shape contexts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2002,24(4):509-522." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape matching and object recognition using shape contexts">
                                        <b>[6]</b>
                                        BELONGIE S,MALIK J,PUZICHA J.Shape matching and object recognition using shape contexts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2002,24(4):509-522.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_7" title="BESL P J,Mc KAY N D.Method for registration of 3-D shapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1992,14(2):239-256." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A method for registration of 3-D shapes">
                                        <b>[7]</b>
                                        BESL P J,Mc KAY N D.Method for registration of 3-D shapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1992,14(2):239-256.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_8" title="CHUI H,RANGARAJAN A.A new point matching algorithm for non-rigid registration[J].Computer Vision and Image Understanding,2003,89(2/3):114-141." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501084334&amp;v=MjYzNjZadEZpbmxVcjNJSUY4UWFCbz1OaWZPZmJLN0h0RE5xbzlFWk9NTEQzODlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        CHUI H,RANGARAJAN A.A new point matching algorithm for non-rigid registration[J].Computer Vision and Image Understanding,2003,89(2/3):114-141.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_9" title="MYRONENKO A,SONG X.Point set registration:coherent point drift[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(12):2262-2275." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Point Set Registration: Coherent Point Drift">
                                        <b>[9]</b>
                                        MYRONENKO A,SONG X.Point set registration:coherent point drift[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(12):2262-2275.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_10" title="WANG G,CHEN Y.Fuzzy correspondences guided Gaussian mixture model for point set registration[J].Knowledge-Based Systems,2017,136:200-209." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES5CF3C62F62A7EB65B842621578710EAE&amp;v=MTI0NzVXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTd3cUE9TmlmT2ZiYkxhTksvcVkwell1bCtDd2xMeVJOaDRqdC9UbjNqcVJVOWZyT1VNTXZxQ09OdkZTaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        WANG G,CHEN Y.Fuzzy correspondences guided Gaussian mixture model for point set registration[J].Knowledge-Based Systems,2017,136:200-209.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_11" title="JIAN B,VEMURI B C.Robust point set registration using Gaussian mixture models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(8):1633-1645." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Point Set Registration Using Gaussian Mixture Models">
                                        <b>[11]</b>
                                        JIAN B,VEMURI B C.Robust point set registration using Gaussian mixture models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(8):1633-1645.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_12" title="WANG G,ZHOU Q,CHEN Y.Robust non-rigid point set registration using spatially constrained Gaussian fields[J].IEEETransactions on Image Processing,2017,26(4):1759-1769." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust non-rigid point set registration using spatially constrained Gaussian fields">
                                        <b>[12]</b>
                                        WANG G,ZHOU Q,CHEN Y.Robust non-rigid point set registration using spatially constrained Gaussian fields[J].IEEETransactions on Image Processing,2017,26(4):1759-1769.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_13" title="WANG G,CHEN Y,ZHENG X.Gaussian field consensus:a robust nonparametric matching method for outlier rejection[J].Pattern Recognition,2018,74:305-316." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9BC48A64978A921BDFD4A084C914D2BD&amp;v=MjM4MzFPZmJyS2JkWEUzb2xCYmV3SGZYVTd6bVJubkV0NU9YL3FxR0U4ZUxiZ1I4anJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4TG03d3FBPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        WANG G,CHEN Y,ZHENG X.Gaussian field consensus:a robust nonparametric matching method for outlier rejection[J].Pattern Recognition,2018,74:305-316.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_14" title="MA J,QIU W,ZHAO J,et al.Robust L&lt;sub&gt;2&lt;/sub&gt;E estimation of transformation for non-rigid registration[J].IEEE Transactions on Signal Processing,2015,63(5):1115-1129." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust L2Eestimation of transformation for non-rigid registration">
                                        <b>[14]</b>
                                        MA J,QIU W,ZHAO J,et al.Robust L&lt;sub&gt;2&lt;/sub&gt;E estimation of transformation for non-rigid registration[J].IEEE Transactions on Signal Processing,2015,63(5):1115-1129.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_15" title="MA J,ZHAO J,TIAN J,et al.Robust estimation of nonrigid transformation for point set registration[C]//Proceedings of the IEEE 2013 Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2147-2154." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust estimation of nonrigid transformation for point set registration">
                                        <b>[15]</b>
                                        MA J,ZHAO J,TIAN J,et al.Robust estimation of nonrigid transformation for point set registration[C]//Proceedings of the IEEE 2013 Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2147-2154.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_16" title="YANG Y,ONG S H,FOONG K W C.A robust global and local mixture distance based non-rigid point set registration[J].Pattern Recognition,2015,48(1):156-173." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162318&amp;v=MDgxOTFQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlGOFFhQm89TmlmT2ZiSzlIOVBPckk5RlplME5EMzB4b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        YANG Y,ONG S H,FOONG K W C.A robust global and local mixture distance based non-rigid point set registration[J].Pattern Recognition,2015,48(1):156-173.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_17" title="王丽芳,王雁丽,蔺素珍,等.基于改进的Zernike矩的局部描述符与图割离散优化的非刚性多模态脑部图像配准[J].计算机应用,2019,39(2):582-588.(WANG L F,WANG YL,LIN S Z,et al.Non-rigid multi-modal brain image registration based on improved Zernike moments based local descriptor and graph cuts discrete optimization[J].Journal of Computer Applications,2019,39(2):582-588.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902048&amp;v=MDQ0MjBGckNVUjdxZlp1WnNGeWprVjczQUx6N0JkN0c0SDlqTXJZOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        王丽芳,王雁丽,蔺素珍,等.基于改进的Zernike矩的局部描述符与图割离散优化的非刚性多模态脑部图像配准[J].计算机应用,2019,39(2):582-588.(WANG L F,WANG YL,LIN S Z,et al.Non-rigid multi-modal brain image registration based on improved Zernike moments based local descriptor and graph cuts discrete optimization[J].Journal of Computer Applications,2019,39(2):582-588.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-08-19 09:48</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),3028-3033 DOI:10.11772/j.issn.1001-9081.2019040681            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于全局与局部相似性测度的非刚性点集配准</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BD%AD%E7%A3%8A&amp;code=31317950&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彭磊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E7%A7%80%E4%BA%91&amp;code=42295187&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨秀云</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%A3%95%E9%A3%9E&amp;code=42897044&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张裕飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%85%89%E8%80%80&amp;code=08949925&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李光耀</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0118734&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同济大学电子与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E4%B8%9C%E7%AC%AC%E4%B8%80%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6(%E5%B1%B1%E4%B8%9C%E7%9C%81%E5%8C%BB%E5%AD%A6%E7%A7%91%E5%AD%A6%E9%99%A2)%E5%8C%BB%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1717635&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山东第一医科大学(山东省医学科学院)医学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E4%B8%9C%E7%AC%AC%E4%B8%80%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6(%E5%B1%B1%E4%B8%9C%E7%9C%81%E5%8C%BB%E5%AD%A6%E7%A7%91%E5%AD%A6%E9%99%A2)%E7%8E%B0%E4%BB%A3%E6%95%99%E8%82%B2%E6%8A%80%E6%9C%AF%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山东第一医科大学(山东省医学科学院)现代教育技术中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>非刚性点集配准算法中,能否找到正确的对应关系对配准结果起着至关重要的作用,而通常两个点集中的对应点除了距离比较接近之外还具有相似的邻域结构,因此提出基于全局与局部相似性测度的非刚性点集配准算法。首先,使用一致性点漂移(CPD)算法作为配准框架,采用高斯混合模型对点集进行建模。然后,对全局局部混合距离进行改进,形成全局与局部相似性测度准则。最后,采用期望最大化(EM)算法迭代地求解对应关系和变换公式:在迭代初期局部相似性所占比重较大,从而能够尽快地找到正确的对应关系;随着迭代的进展全局相似性比重逐渐增大,从而确保得到较小的配准误差。实验结果表明,与薄板样条鲁棒点匹配(TPS-RPM)算法、高斯混合模型点集配准(GMMREG)算法、基于L<sub>2</sub>E估计的鲁棒点匹配算法(RPM-L2E)、基于全局局部混合距离与薄板样条的点集配准算法(GLMDTPS)和CPD算法相比,所提算法的均方根误差(RMSE)分别下降了39.93%、42.45%、32.51%、22.36%和11.76%,说明该算法具有较好的配准效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%82%B9%E9%9B%86%E9%85%8D%E5%87%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">点集配准;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像配准;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%88%9A%E6%80%A7%E9%85%8D%E5%87%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非刚性配准;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高斯混合模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%B5%8B%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相似性测度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *彭磊(1977—),男,山东泰安人,副教授,硕士,CCF会员,主要研究方向:医学图像处理、机器学习;电子邮箱pengleisd@163.com;
                                </span>
                                <span>
                                    杨秀云(1982—),女,山东聊城人,助理工程师,硕士,主要研究方向:医学图像处理;;
                                </span>
                                <span>
                                    张裕飞(1965—),男,山东微山人,教授,硕士,主要研究方向:医学信息学;;
                                </span>
                                <span>
                                    李光耀(1965—),男,安徽安庆人,教授,博士,主要研究方向:计算机视觉、图像处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>山东省自然科学基金资助项目(ZR2015FL005);</span>
                                <span>泰安市科技发展计划项目(2017GX0045);</span>
                    </p>
            </div>
                    <h1><b>Non-rigid point set registration based on global and local similarity measurement</b></h1>
                    <h2>
                    <span>PENG Lei</span>
                    <span>YANG Xiuyun</span>
                    <span>ZHANG Yufei</span>
                    <span>LI Guangyao</span>
            </h2>
                    <h2>
                    <span>College of Electronics and Information Engineering, Tongji University</span>
                    <span>College of Medical Information Engineering,Shandong First Medical University &amp; Shandong Academy of Medical Sciences</span>
                    <span>Modern Education Technology Center,Shandong First Medical University &amp; Shandong Academy of Medical Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the non-rigid point set registration algorithm, whether the correct correspondence can be found plays an important role. Generally the corresponding points in two point sets have similar neighborhood structures besides the close distance. Therefore, a non-rigid point set registration algorithm based on global and local similarity measurement was proposed. Firstly, the Coherent Point Drift(CPD) algorithm was used as the registration framework, and the Gaussian mixture model was used to model the point sets. Secondly, the global and local mixture distance was improved to form the global and local similarity measurement criterion. Finally, the correspondence and the transformation formula were solved by the Expectation Maximization(EM) algorithm. In the initial stage of the iteration, the proportion of local similarity was larger so that the correct correspondence was able to be found rapidly; with the progress of the iteration, the proportion of global similarity was increased to ensure the smaller registration error. Experimental results show that compared with the Thin Plate Spline Robust Point Matching(TPS-RPM) algorithm, the Gaussian Mixture Models point set REGistration(GMMREG) algorithm, the Robust Point Matching algorithm based on L<sub>2</sub>E estimation(RPM-L2 E), the Global and Local Mixture Distance and Thin Plate Spline based point set registration algorithm(GLMDTPS) and the CPD algorithm, the proposed algorithm has the Root Mean Squared Error(RMSE) decreased by 39.93%, 42.45%, 32.51%, 22.36% and 11.76% respectively, indicating the proposed algorithm has better registration performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=point%20set%20registration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">point set registration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20registration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image registration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-rigid%20registration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-rigid registration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gaussian%20mixture%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gaussian mixture model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=similarity%20measurement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">similarity measurement;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    PENG Lei,born in 1977,M.S.,associate professor.His research interests include medical image processing,machine learning.;
                                </span>
                                <span>
                                    YANG Xiuyun,born in 1982,M.S.,assistant engineer.Her research interests include medical image processing.;
                                </span>
                                <span>
                                    ZHANG Yufei,born in 1965,M.S.,professor.His research interests include medical informatics.;
                                </span>
                                <span>
                                    LI Guangyao,born in 1965,Ph.D.,professor.His research interests include computer vision and image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-22</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Shandong Provincial Natural Science Foundation(ZR2015FL005);</span>
                                <span>the Tai&#39;an Science and Technology Development Program(2017GX0045);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="38">点集配准是一个基础而关键的问题,广泛应用在计算机视觉<citation id="197" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、医学图像分析<citation id="200" type="reference"><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><link href="169" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、遥感图像处理<citation id="198" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和模式识别<citation id="199" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等领域。其目标是寻找两组给定点集之间的对应关系,通过空间变换将一个点集对齐到另一个点集。根据变换方式的不同可分为刚性配准和非刚性配准。刚性点集配准的变换方式包括放缩、平移、旋转,仅涉及少量的参数。非刚性点集配准的变换方式往往是未知的、复杂的、难以建模的,通常包含较多的变换参数。</p>
                </div>
                <div class="p1">
                    <p id="39">迭代最近点算法<citation id="201" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>是著名的点集配准方法之一,主要用于自由曲线和曲面的配准,它假设两个点集间距离最近的点为对应点,通过迭代地最小化均方距离来达到目标函数的收敛。Chui等<citation id="202" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一个非刚性点匹配的通用框架,使用薄板样条作为空间变换模型,并通过软分配和确定性退火技术联合求解优化问题。一致性点漂移(Coherent Point Drift, CPD)算法<citation id="203" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将配准两个点集考虑为概率密度估计问题,使用运动一致性理论进行约束,通过迭代方法将高斯混合模型(Gaussian Mixture Model, GMM)<citation id="205" type="reference"><link href="179" rel="bibliography" /><link href="181" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>的质心拟合到数据点。Jian等<citation id="204" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>使用两个GMM来表示点集,并通过两个GMM之间的差异最小化来解决点集配准问题。文献<citation id="206" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>采用高斯域的方法实现了异常点移除和点集配准。这些方法主要使用点之间的全局距离来确定对应关系,基本没有考虑点的邻域结构信息。</p>
                </div>
                <div class="p1">
                    <p id="40">Belongie等<citation id="207" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>引入了形状上下文(Shape Context,SC)的概念,用来测量两个形状之间的相似度。Ma等<citation id="209" type="reference"><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>首先使用SC描述符建立粗糙的对应关系,然后用L<sub>2</sub>E估计器来估算变换。Yang等<citation id="208" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>采用鲁棒的全局和局部混合距离(Global and Local Mixture Distance,GLMD)测度准则进行非刚性点集配准。虽然这些算法使用点集的结构信息作为相似性测量,但是它们在查找对应关系和估计变换模型时是分别处理的。</p>
                </div>
                <div class="p1">
                    <p id="41">为了充分利用点之间的距离和点的邻域结构信息,快速找到正确的对应关系,本文以CPD算法<citation id="210" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>为框架,采用GMM表示点集,对GLMD<citation id="211" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>进行改进,并融入到GMM中,形成了全局与局部相似性测度准则。GMM的高斯分量反映了全局相似性测度准则,而每个高斯分量使用不同的比例系数,则反映了点的局部相似性测度准则。通过权重系数调节二者的比重。采用期望最大化(Expectation Maximization, EM)算法迭代地求解对应关系和变换公式。在迭代初期,局部相似性所占比重较大,从而尽快找到正确的对应关系;迭代过程中逐渐提高全局相似性比重,最终得到更小的配准误差。该算法在保证快速找到点的正确对应关系的同时,能够得到较好的配准效果。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 一致性点漂移算法</h3>
                <div class="p1">
                    <p id="43">设<i>D</i>维(通常<i>D</i>=2或3)空间的两个点集<i>X</i>和<i>Y</i>,浮动点集为<i>X</i>={<i>x</i><sub><i>m</i></sub>|<i>m</i>=1,2,…,<i>M</i>},参考点集为<i>Y</i>={<i>y</i><sub><i>n</i></sub>|<i>n</i>=1,2,…,<i>N</i>}。非刚性点集配准算法的目标是根据相似性测度准则找到<i>X</i>和<i>Y</i>之间点的对应关系,并估算一个非刚性变换公式<i>T</i>,使<i>X</i>通过变换后对齐到<i>Y</i>。</p>
                </div>
                <div class="p1">
                    <p id="44">CPD算法将两个点集的配准看成是概率密度估计问题。使用GMM对问题进行建模<citation id="212" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,把<i>X</i>中的点看成GMM的质心,<i>Y</i>中的点看成是由GMM产生的数据点。方法的核心是保持点集的拓扑结构,迫使GMM的质心作为一个整体一致地向参考点集移动。在优化过程中,浮动点集通过变换<i>T</i>与参考点集逐渐对齐,并可以根据后验概率获得点的对应关系。GMM的概率密度函数为:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>ω</mi><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">|</mo><mi>Μ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>ω</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>η</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">|</mo><mi>m</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">各高斯组成部分的表达式为:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">|</mo><mi>m</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">(</mo><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mi>D</mi><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mspace width="0.25em" /><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">式(1)中的均匀分布<i>p</i>(<i>y</i><sub><i>n</i></sub>|<i>M</i>+1)=1/<i>N</i>,用来处理点集中存在的噪声和异常点,所占比重为<i>ω</i>(0≤<i>ω</i>≤1)。其他所有高斯组成部分所占比重为1-<i>ω</i>,其中每个高斯分量使用相同的比例系数<i>η</i><sub><i>mn</i></sub>=1/<i>M</i>。</p>
                </div>
                <div class="p1">
                    <p id="49">为了使变换比较平滑,采用Tikhonov正则化框架<citation id="213" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。定义再生核希尔伯特空间的正则项<i>λφ</i>(<i>T</i>)/2,其中<i>φ</i>(<i>T</i>)为一个平滑函数,<i>λ</i>为正则项的权重系数。使用<i>θ</i>表示参数集合,通过极大似然估计来求得参数。将负对数似然函数作为CPD算法的能量函数,如式(3)所示:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mi>log</mi></mrow></mstyle><mspace width="0.25em" /><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi>φ</mi><mo stretchy="false">(</mo><mi>Τ</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">2 全局和局部混合距离</h3>
                <h4 class="anchor-tag" id="52" name="52">2.1 <b>全局距离</b></h4>
                <div class="p1">
                    <p id="53">浮动点集上一点x<sub>m</sub>与参考点集上一点y<sub>n</sub>之间的全局距离<citation id="214" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>定义为其欧氏距离的平方,如式(4)所示:</p>
                </div>
                <div class="p1">
                    <p id="54">G<sub>mn</sub>=‖y<sub>n</sub>-x<sub>m</sub>‖<sup>2</sup>      (4)</p>
                </div>
                <div class="p1">
                    <p id="55">G<sub>mn</sub>可以描述两个点集之间的全局性结构差异。通常两个点集基本对齐后,距离较近的点很可能就是对应点。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56">2.2 <b>局部距离</b></h4>
                <div class="p1">
                    <p id="57">某个点q的邻域定义为其所在点集中距离q最近的K个点。用φ(q)<sub>k</sub>来表示第k个最近点。局部距离<citation id="215" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>用于度量两个点x<sub>m</sub>与y<sub>n</sub>的邻域结构相似性,定义为:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>ψ</mi><mo stretchy="false">(</mo><mi>φ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><msub><mrow></mrow><mi>k</mi></msub><mo>,</mo><mspace width="0.25em" /><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>φ</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中ψ是位移函数,表示点x<sub>m</sub>及其邻域点整体向点y<sub>n</sub>移动直至x<sub>m</sub>与y<sub>n</sub>点重合,其定义为:</p>
                </div>
                <div class="p1">
                    <p id="60">ψ(φ(x<sub>m</sub>)<sub>k</sub>, y<sub>n</sub>)=φ(x<sub>m</sub>)<sub>k</sub>+(y<sub>n</sub>-x<sub>m</sub>)      (6)</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag">3 本文算法</h3>
                <h4 class="anchor-tag" id="62" name="62">3.1 <b>局部相似性的改进</b></h4>
                <div class="p1">
                    <p id="63"><i>GLMD</i>算法中局部距离是通过计算两个点的邻域中具有相同编号k的点对之间距离的和得到的。本文将式(5)中φ(y<sub>n</sub>)的下标由k改为f(k),即寻找两个邻域中两两点对之间距离之和最小的值作为局部相似性。式(5)改写为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>f</mi></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>ψ</mi><mo stretchy="false">(</mo><mi>φ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><msub><mrow></mrow><mi>k</mi></msub><mo>,</mo><mspace width="0.25em" /><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>φ</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><msub><mrow></mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">f为两个邻域中点的某种一一映射关系,使得两个邻域(分别包含K个点)之间K个点对的距离之和达到最小,即能够使L<sub>mn</sub>得到最小值。相当于二分图的最大匹配问题,可以通过匈牙利算法来求解f。</p>
                </div>
                <div class="p1">
                    <p id="66">如图1所示,两个点p和q,各自的邻域内分别有编号为1、2、3、4的点,虚线表示两个邻域之间点的对应关系。通过计算对应点间距离之和得到局部距离。GLMD按照编号确定对应点,有可能产生错误的结果,从而得到错误的局部距离,如图1(a)所示。本文算法能够找到一个最佳匹配来确定对应点,因此能够求得正确的局部距离,同时所求局部距离也是最小的,如图1(b)所示。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 邻域之间的局部距离" src="Detail/GetImg?filename=images/JSJY201910039_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 邻域之间的局部距离  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Local distance between neighborhoods</p>

                </div>
                <h4 class="anchor-tag" id="68" name="68">3.2 <b>全局局部相似性测度</b></h4>
                <div class="p1">
                    <p id="69">CPD算法利用了点之间的全局距离,即认为全局距离较近的点很可能为对应点。因此,式(2)可以写为:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">|</mo><mi>m</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">(</mo><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mi>D</mi><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mspace width="0.25em" /><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mi>G</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">CPD算法中每个高斯分量使用相同的比例系数<i>η</i><sub><i>mn</i></sub>=1/<i>M</i>,没有考虑点的邻域结构。然而两个点的邻域结构越相似,即局部相似性越高,它们成为对应点的可能性也越大。为了充分利用点的局部相似性,对GMM中的每个高斯分量使用不同的比例系数:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>S</mi></mfrac><mspace width="0.25em" /><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mi>β</mi><mi>L</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中:<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mspace width="0.25em" /></mstyle><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mi>β</mi><mi>L</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo>,</mo><mspace width="0.25em" /><mi>β</mi></mrow></math></mathml>为权重系数。两个点的局部相似性越大时,对应的<i>η</i><sub><i>mn</i></sub>越大,即该高斯分量在GMM中所占的比重越大,其成为对应点的概率就越大。</p>
                </div>
                <div class="p1">
                    <p id="74">式(8)和(9)共同体现了全局与局部相似性结合的测度准则。权重系数<i>β</i>控制全局相似性和局部相似性之间的比例关系。当<i>β</i>非常大时,相当于最小化局部相似性<i>L</i><sub><i>mn</i></sub>;当<i>β</i>很小时,趋向于最小化全局相似性<i>G</i><sub><i>mn</i></sub>。全局与局部相似性测度提供了一种灵活的方式,通过最小化两个点集之间的全局相似性和局部相似性上的差异来估算对应关系。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75">3.3 <b>全局与局部测度引导的配准过程</b></h4>
                <div class="p1">
                    <p id="76">在非刚性点集配准中,能否找到正确的对应关系对配准效果有很大的影响。当两个点集形态近似时,距离较近的点,往往是对应点;而当两个点集形态差别较大时,具有相似邻域结构的点,很有可能是对应点。因此采用全局与局部相似性结合的测度准则引导配准过程。在优化算法迭代的初期局部相似性起较大的作用,从而尽快找到正确的对应关系;在迭代后期,两个点集基本对齐,此时全局相似性测度起的作用变大,从而确保算法收敛到较小的配准误差。</p>
                </div>
                <div class="p1">
                    <p id="77">配准过程首先以浮动点集X和参考点集Y为输入;其次使用<i>GMM</i>进行建模,把X看成<i>GMM</i>的质心,Y看成由GMM产生的数据点;再次构造目标函数并进行参数设置;然后使用EM优化策略对目标函数中的参数进行估计,交替地执行期望步(Expectation step,E-step)和最大化步(Maximization step, M-step)两步,直至算法收敛;最后输出浮动点集的变换公式和两个点集之间的对应关系。本文算法流程如图2所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文算法流程" src="Detail/GetImg?filename=images/JSJY201910039_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="79" name="79">3.3.1 目标函数</h4>
                <div class="p1">
                    <p id="80">对式(3)进行最小化<citation id="216" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,其上限即为算法的目标函数。去除与参数无关的项之后,可以写为:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Q</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi mathvariant="bold-italic">Ρ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>D</mi><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub></mrow><mn>2</mn></mfrac><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mspace width="0.25em" /><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub><mo>-</mo><mi>Ν</mi><mo stretchy="false">)</mo><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mspace width="0.25em" /><mi>ω</mi><mo>-</mo></mtd></mtr><mtr><mtd><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi>φ</mi><mo stretchy="false">(</mo><mi>Τ</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">其中:<i><b>P</b></i><sub><i>mn</i></sub>=<i>p</i>(<i>m</i>|<i>y</i><sub><i>n</i></sub>);<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi mathvariant="bold-italic">Ρ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub></mrow></math></mathml>,未知参数的集合为<i>θ</i>={<i>T</i>,<i>ω</i>,<i>σ</i><sup>2</sup>}。</p>
                </div>
                <div class="p1">
                    <p id="83">假设数据是独立同分布的,则后验概率<i>p</i>(<i>m</i>|<i>y</i><sub><i>n</i></sub>)=<i>η</i><sub><i>mn</i></sub><i>p</i>(<i>y</i><sub><i>n</i></sub>|<i>m</i>)/<i>p</i>(<i>y</i><sub><i>n</i></sub>)决定了两点<i>x</i><sub><i>m</i></sub>和<i>y</i><sub><i>n</i></sub>是否为对应点。由式(8)和(9)可知,其体现了全局与局部相似性测度准则。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">3.3.2 参数设置</h4>
                <div class="p1">
                    <p id="85">优化算法最大迭代次数设为100。邻域中点的个数设为<i>K</i>=4。初始时权重系数<i>β</i>取一个较大的值,一般设<i>β</i>=<i>K</i><sup>2</sup>,每一次迭代均乘以一个系数<i>r</i>=0.95,类似于退火率,即<i>β</i>←<i>rβ</i>。这样能够保证优化迭代的前期局部相似性起主导作用,后期全局相似性起主导作用,从而在尽快找到正确对应关系的同时得到较小的配准误差。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">3.3.3 E-step阶段</h4>
                <div class="p1">
                    <p id="87">在<i>E</i>-<i>step</i>阶段,首先计算<i>Y</i>与<i>T</i>(<i>X</i>)之间的局部相似性,更新每个高斯分量的比例系数<i>η</i><sub><i>mn</i></sub>;然后根据贝叶斯定理,使用当前参数计算后验概率分布<i><b>P</b></i><sub><i>mn</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mfrac><mrow><mi>η</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>η</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>n</mi></mrow></msub><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo><mo>+</mo><mfrac><mrow><mi>ω</mi><mi>S</mi><mo stretchy="false">(</mo><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mi>D</mi><mo>/</mo><mn>2</mn></mrow></msup></mrow><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>ω</mi><mo stretchy="false">)</mo><mi>Ν</mi></mrow></mfrac></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中: <i><b>P</b></i><sub><i>mn</i></sub>为(<i>M</i>+1)×<i>N</i>阶矩阵<i><b>P</b></i>中的元素。当<i>m</i>≤<i>M</i>时,<i><b>P</b></i><sub><i>mn</i></sub>表示在当前变换公式下,点<i>x</i><sub><i>m</i></sub>与<i>y</i><sub><i>n</i></sub>为对应点的概率;当<i>m</i>=<i>M</i>+1时,<i><b>P</b></i><sub><i>mn</i></sub>表示<i>x</i><sub><i>m</i></sub>为噪声或异常点的概率。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">3.3.4 M-step阶段</h4>
                <div class="p1">
                    <p id="91">在<i>M</i>-<i>step</i>阶段,计算并更新参数。对式(10)求导,并使其等于0,可以求得相应参数。</p>
                </div>
                <div class="p1">
                    <p id="92">非刚性变换公式<i>T</i>定义为点的初始位置加上一个位移函数<i>v</i>,即<i>T</i>(<i>X</i>)=<i>X</i>+<i>v</i>(<i>X</i>)<citation id="217" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。使用高斯矩阵核定义再生核希尔伯特空间,可以得到<i>v</i>的函数形式:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi mathvariant="bold-italic">Γ</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>m</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中:<i><b>w</b></i><sub><i>m</i></sub>是系数矩阵<i><b>W</b></i>=<i><b>w</b></i><sub>1</sub><i><b>w</b></i><sub>2</sub> … <i><b>w</b></i><sub><i>M</i></sub><sup>T</sup>中的元素;<i>Γ</i>(<i>x</i>,<i>x</i><sub><i>m</i></sub>)是核矩阵。正则项<i>φ</i>(<i>T</i>)在这里的具体形式为<i><b>WΓW</b></i><sup>T</sup><citation id="218" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。则变换公式可表示为<i>T</i>=<i>X</i>+<i>Γ</i><i><b>W</b></i>。</p>
                </div>
                <div class="p1">
                    <p id="95">同时求得参数<i>ω</i>和<i>σ</i><sup>2</sup>的值。</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ω</mi><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub></mrow><mi>Ν</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Ρ</mi></msub><mi>D</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi mathvariant="bold-italic">Ρ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">3.3.5 算法输出</h4>
                <div class="p1">
                    <p id="98"><i>EM</i>算法交替地执行<i>E</i>-<i>step</i>和<i>M</i>-<i>step</i>,直至最大迭代次数或配准误差小于给定阈值。最终浮动点集的变换公式由<i>T</i>给出,点的对应关系由后验概率矩阵<i><b>P</b></i>给出。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 二维点集配准结果" src="Detail/GetImg?filename=images/JSJY201910039_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 二维点集配准结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Registration results of 2D point sets</p>

                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 二维点集配准算法性能比较" src="Detail/GetImg?filename=images/JSJY201910039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 二维点集配准算法性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Performance comparison of 2D point set registration algorithms</p>

                </div>
                <h3 id="101" name="101" class="anchor-tag">4 实验与分析</h3>
                <div class="p1">
                    <p id="102">为了评估算法的性能,设计了二维与三维合成点集配准实验和真实医学图像配准实验,并对实验结果进行了比较和定量分析。所有实验的软件环境为<i>Matlab R</i>2013<i>a</i>,硬件环境为16 <i>GB</i>内存、<i>i</i>7-4770<i>K Inter</i>处理器的<i>PC</i>。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">4.1 <b>合成点集配准实验</b></h4>
                <div class="p1">
                    <p id="104">采用二维的<i>Chui</i>-<i>Rangarajan</i>合成数据<citation id="219" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和三维的人脸点集<citation id="220" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>数据进行实验。且实验结果与薄板样条鲁棒点匹配(<i>Thin Plate Spline Robust Point Matching</i>, <i>TPS</i>-<i>RPM</i>)算法<citation id="221" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、高斯混合模型点集配准(<i>Gaussian Mixture Models point set REGistration</i>, <i>GMMREG</i>)算法<citation id="222" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、基于<i>L</i><sub>2</sub><i>E</i>估计的鲁棒点匹配算法(<i>Robust Point Matching algorithm based on L</i><sub>2</sub><i>E estimation</i>, <i>RPM</i>-<i>L</i>2<i>E</i>)<citation id="225" type="reference"><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>、基于全局局部混合距离与薄板样条的点集配准算法(<i>Global and Local Mixture Distance and Thin Plate Spline based point set registration algorithm</i>, <i>GLMDTPS</i>)<citation id="223" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>和<i>CPD</i>算法<citation id="224" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>进行比较。性能评价采用与文献<citation id="226" type="reference">[<a class="sup">8</a>,<a class="sup">10</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</citation>相同的方法。由于合成数据中每组测试样例的真正对应点已经预先标识出,即真正的对应关系是已知的,因此使用配准后两个点集的真正对应点之间的平均欧氏距离,即均方根误差(<i>Root Mean Squared Error</i>, <i>RMSE</i>)进行定量分析。误差计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>J</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中: <i>y</i><sub><i>j</i></sub>与<i>x</i><sub><i>j</i></sub>是真正的对应点;<i>J</i>是真正对应点对的总数。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107">4.1.1 二维点集配准实验</h4>
                <div class="p1">
                    <p id="108">选取<i>Chui</i>-<i>Rangarajan</i>合成数据小鱼形状的变形、遮挡、异常点3组数据进行实验。每组包括由低到高5种不同的退化等级,每一等级包含100个测试样例。图3为6种算法的配准结果展示。</p>
                </div>
                <div class="p1">
                    <p id="109">图4是配准性能的定量分析与比较,用误差棒表示每种退化等级样例的平均误差和标准差。图4中横坐标表示5种不同的退化等级。每种算法所对应的误差棒的中心表示平均误差,误差棒的长度表示标准差。从图4可以看出,当变形、遮挡、异常点等退化程度较小时,各种算法均有不错的性能,但随着退化程度的增大,本文算法的优势越来越明显。表1为6种算法3组实验的平均误差统计,可看出本文算法在各种情况下都有一定的优势。</p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit"><b>表</b>1 <b>二维点集配准误差</b> 单位:像素 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Registration error of</i> 2<i>D point sets</i><i>unit</i>: <i>pixel</i></p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td><br />算法</td><td>变形</td><td>遮挡</td><td>异常点</td></tr><tr><td><br /><i>TPS</i>-<i>RPM</i></td><td>0.018 4</td><td>0.061 2</td><td>0.106 8</td></tr><tr><td><br /><i>GMMREG</i></td><td>0.021 4</td><td>0.080 2</td><td>0.129 5</td></tr><tr><td><br /><i>RPM</i>-<i>L</i>2<i>E</i></td><td>0.014 8</td><td>0.075 3</td><td>0.085 1</td></tr><tr><td><br /><i>GLMDTPS</i></td><td>0.005 0</td><td>0.064 6</td><td>0.057 6</td></tr><tr><td><br /><i>CPD</i></td><td>0.009 2</td><td>0.029 9</td><td>0.055 1</td></tr><tr><td><br /> 本文算法</td><td>0.003 9</td><td>0.021 4</td><td>0.049 2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="111" name="111">4.1.2 三维点集配准实验</h4>
                <div class="p1">
                    <p id="112">三维点集配准实验选取文献<citation id="227" type="reference">[<a class="sup">9</a>]</citation>中的人脸点集。变形、遮挡和异常点3组数据,每组选取50个测试样例。本文算法的配准效果如图5所示。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文算法针对三维点集配准结果" src="Detail/GetImg?filename=images/JSJY201910039_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文算法针对三维点集配准结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.5 <i>Registration results of the proposed algorithm for</i> 3<i>D point sets</i></p>

                </div>
                <div class="p1">
                    <p id="114">表2为6种算法的配准误差统计。在变形和异常点情况下本文算法明显优于其他算法;在遮挡情况下,6种算法差别不大,本文算法略优。</p>
                </div>
                <div class="area_img" id="115">
                    <p class="img_tit"><b>表</b>2 <b>三维点集配准误差</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.2 <i>Registration error of</i> 3<i>D point sets</i></p>
                    <p class="img_note">单位:像素</p>
                    <table id="115" border="1"><tr><td><br />算法</td><td>变形</td><td>遮挡</td><td>异常点</td></tr><tr><td><br /><i>TPS</i>-<i>RPM</i></td><td>0.053 2</td><td>0.990 2</td><td>0.167 9</td></tr><tr><td><br /><i>GMMREG</i></td><td>0.032 0</td><td>0.979 5</td><td>0.160 6</td></tr><tr><td><br /><i>RPM</i>-<i>L</i>2<i>E</i></td><td>0.018 8</td><td>0.945 5</td><td>0.085 9</td></tr><tr><td><br /><i>GLMDTPS</i></td><td>0.015 0</td><td>0.923 8</td><td>0.065 1</td></tr><tr><td><br /><i>CPD</i></td><td>0.005 7</td><td>0.934 6</td><td>0.056 4</td></tr><tr><td><br />本文算法</td><td>0.004 1</td><td>0.919 2</td><td>0.048 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="116">在二维和三维点集上的实验结果表明,本文算法与<i>TPS</i>-<i>RPM</i>、<i>GMMREG</i>、<i>RPM</i>-<i>L</i>2<i>E</i>、<i>GLMDTPS</i>和<i>CPD</i>算法相比,平均<i>RMSE</i>分别下降了39.93%、42.45%、32.51%、22.36%和11.76%。</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117">4.2 <b>真实图像配准实验</b></h4>
                <div class="p1">
                    <p id="118">为了比较在<i>CPD</i>配准框架中引入全局与局部相似性测度前、后的配准效果,选用20组医学<i>MRI</i>图像进行实验。首先提取图像的轮廓,生成点集,对点集进行配准;然后根据变换公式生成配准后的图像。图6为一组人脑<i>MRI</i>图像的测试样例,展示了<i>CPD</i>算法与本文算法的配准结果。图6第一行为初始的浮动图像与参考图像,以及两种算法配准后浮动图像与参考图像的灰度差图像;第二行为对应的点集。</p>
                </div>
                <div class="p1">
                    <p id="119">配准效果的定量分析采用轮廓点集配准误差和图像灰度误差两种方法。</p>
                </div>
                <div class="p1">
                    <p id="120">首先采用类似文献<citation id="228" type="reference">[<a class="sup">17</a>]</citation>人工标注点的方法,在两个轮廓点集上查找具有明显特征的点对,人工标<citation id="229" type="reference">注50</citation>个标准对应点。计算两个轮廓对应标注点之间的<i>RMSE</i>。两种算法的平均误差如表3中人工标注点的平均误差所示。召回率定义为配准后误差小于给定阈值的对应点与全部标注的对应点在数量上的比值。图7展示了20组测试样例在各种阈值下<i>CPD</i>与本文算法召回率的变化曲线。实验结果表明,本文算法优于<i>CPD</i>算法。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 MRI图像配准结果" src="Detail/GetImg?filename=images/JSJY201910039_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 <i>MRI</i>图像配准结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.6 <i>Registration results of MRI images</i></p>

                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910039_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 MRI图像配准召回率曲线" src="Detail/GetImg?filename=images/JSJY201910039_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 <i>MRI</i>图像配准召回率曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910039_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.7 <i>Recall curve of MRI image egistration</i></p>

                </div>
                <div class="p1">
                    <p id="123">由于手工标注对应点的方法具有一定的人为因素,因此进一步采用配准后的图像灰度误差进行定量分析。两幅图像逐像素点灰度值的均方根误差定义为:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>U</mi><mo>×</mo><mi>V</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><mi>U</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mo stretchy="false">(</mo></mstyle></mrow></mstyle><mi>Y</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>-</mo><mi>X</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">其中:<i>Y</i>(<i>u</i>,<i>v</i>)与<i>X</i>(<i>u</i>,<i>v</i>)是两个图像在坐标点(<i>u</i>,<i>v</i>)上的灰度值;<i>U</i>×<i>V</i>是图像的分辨率。表3中像素灰度的均方根误差展示了20组测试样例使用两种算法配准后的图像灰度误差,同样可以看出本文算法优于CPD算法。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表</b>3 MRI<b>图像配准误差</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.3 Registration error of MRI images</p>
                    <p class="img_note">单位:像素</p>
                    <table id="126" border="1"><tr><td><br />误差</td><td>CPD</td><td>本文算法</td></tr><tr><td><br />人工标注点的平均误差</td><td>1.365 5</td><td>0.914 2</td></tr><tr><td><br />像素灰度的均方根误差</td><td>15.122 5</td><td>12.257 6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="127" name="127" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="128">在非刚性点集配准算法中,为了充分利用点的邻域结构信息来查找对应关系,将改进的全局和局部混合距离融入到<i>CPD</i>算法的高斯混合模型配准框架中,提出了基于全局与局部相似性的测度准则。使用权重系数调节全局相似性测度和局部相似性测度二者的比例。采用<i>EM</i>算法迭代地求解对应关系和变换公式,迭代过程中局部相似性所占比重由大变小,全局距离所占比重由小变大,从而在保证快速找到正确对应关系的前提下,提高配准的精确度。通过合成数据与真实数据的实验结果比对和分析,可以看出本文算法具有较好的配准性能。然而将点集邻域结构的计算引入到相似性测度中,加大了算法的计算量、增加了算法的运行时间,可能无法满足实时性要求较高的应用场合。因此未来的工作在进一步研究如何更好地利用点集结构信息的同时,还需要考虑如何提高算法的执行速度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="163">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locality preserving matching">

                                <b>[1]</b>MA J,ZHAO J,JIANG J,et al.Locality preserving matching[J].International Journal of Computer Vision,2019,127(5):512-531.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9B4EFF9872AE477D3D38B99F24808461&amp;v=MDY1NzRLY1FieWVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4TG03d3FBPU5pZk9mYnJLR3FTNjJZWk5ZK2wrZVhnK3lHSVFuangxT25icjJoQXhjYg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>FERRANTE E,PARAGIOS N.Slice-to-volume medical image registration:a survey[J].Medical Image Analysis,2017,39:101-123.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YJXB201804002&amp;v=MDMzNzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWprVjczQVBDZlRiTEc0SDluTXE0OUZab1E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>GUAN S,WANG T,MENG C,et al.A review of point feature based medical image registration[J].Chinese Journal of Mechanical Engineering,2018,31:No.76.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH867043E7898C3DA61A2E47220B519321&amp;v=MjY2MzVlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeExtN3dxQT1OaWZLWnJ1K0dkSElyUHBDYk9JSGYzOU52aEFTbXowSVRIamdyaEpIZkxPZFJyaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>TANG H,PAN A,YANG Y,et al.Retinal image registration based on robust non-rigid point matching method[J].Journal of Medical Imaging and Health Informatics,2018,8(2):240-249.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG6B7C7EA8B09D7C03EC41FC6B3C63266F&amp;v=MjU2NjM3d3FBPU5pZk9hYlhLR2FMTDJ2NU5GdXNHZUh0S3p4Vm1tVHQ4UGd6azNoRkdmN0dXUTd6cENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>WU Y,MA W,ZHANG J,et al.Point-matching algorithm based on local neighborhood information for remote sensing image registration[J].Journal of Applied Remote Sensing,2018,12(1):No.016002.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape matching and object recognition using shape contexts">

                                <b>[6]</b>BELONGIE S,MALIK J,PUZICHA J.Shape matching and object recognition using shape contexts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2002,24(4):509-522.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A method for registration of 3-D shapes">

                                <b>[7]</b>BESL P J,Mc KAY N D.Method for registration of 3-D shapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1992,14(2):239-256.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501084334&amp;v=MDA2NjhVcjNJSUY4UWFCbz1OaWZPZmJLN0h0RE5xbzlFWk9NTEQzODlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>CHUI H,RANGARAJAN A.A new point matching algorithm for non-rigid registration[J].Computer Vision and Image Understanding,2003,89(2/3):114-141.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Point Set Registration: Coherent Point Drift">

                                <b>[9]</b>MYRONENKO A,SONG X.Point set registration:coherent point drift[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(12):2262-2275.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES5CF3C62F62A7EB65B842621578710EAE&amp;v=MDA3NzRVOWZyT1VNTXZxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeExtN3dxQT1OaWZPZmJiTGFOSy9xWTB6WXVsK0N3bEx5Uk5oNGp0L1RuM2pxUg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>WANG G,CHEN Y.Fuzzy correspondences guided Gaussian mixture model for point set registration[J].Knowledge-Based Systems,2017,136:200-209.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Point Set Registration Using Gaussian Mixture Models">

                                <b>[11]</b>JIAN B,VEMURI B C.Robust point set registration using Gaussian mixture models[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(8):1633-1645.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust non-rigid point set registration using spatially constrained Gaussian fields">

                                <b>[12]</b>WANG G,ZHOU Q,CHEN Y.Robust non-rigid point set registration using spatially constrained Gaussian fields[J].IEEETransactions on Image Processing,2017,26(4):1759-1769.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9BC48A64978A921BDFD4A084C914D2BD&amp;v=MjkxNzVFM29sQmJld0hmWFU3em1Sbm5FdDVPWC9xcUdFOGVMYmdSOGpyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeExtN3dxQT1OaWZPZmJyS2JkWA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>WANG G,CHEN Y,ZHENG X.Gaussian field consensus:a robust nonparametric matching method for outlier rejection[J].Pattern Recognition,2018,74:305-316.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust L2Eestimation of transformation for non-rigid registration">

                                <b>[14]</b>MA J,QIU W,ZHAO J,et al.Robust L<sub>2</sub>E estimation of transformation for non-rigid registration[J].IEEE Transactions on Signal Processing,2015,63(5):1115-1129.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust estimation of nonrigid transformation for point set registration">

                                <b>[15]</b>MA J,ZHAO J,TIAN J,et al.Robust estimation of nonrigid transformation for point set registration[C]//Proceedings of the IEEE 2013 Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2147-2154.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162318&amp;v=MDMyMTFGWmUwTkQzMHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRjhRYUJvPU5pZk9mYks5SDlQT3JJOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>YANG Y,ONG S H,FOONG K W C.A robust global and local mixture distance based non-rigid point set registration[J].Pattern Recognition,2015,48(1):156-173.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902048&amp;v=MDc4NzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5amtWNzNBTHo3QmQ3RzRIOWpNclk5QmI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>王丽芳,王雁丽,蔺素珍,等.基于改进的Zernike矩的局部描述符与图割离散优化的非刚性多模态脑部图像配准[J].计算机应用,2019,39(2):582-588.(WANG L F,WANG YL,LIN S Z,et al.Non-rigid multi-modal brain image registration based on improved Zernike moments based local descriptor and graph cuts discrete optimization[J].Journal of Computer Applications,2019,39(2):582-588.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910039&amp;v=MjkxMTVHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlqa1Y3M0FMejdCZDdHNEg5ak5yNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
