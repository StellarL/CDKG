<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136779546690000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904040%26RESULT%3d1%26SIGN%3dTttBfU815EYjS4gFWwOdIjErxOw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904040&amp;v=MTI3NjFyQ1VSN3FmWnVac0Z5RGhVTDNKTHo3QmQ3RzRIOWpNcTQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 国内外研究现状 ">1 国内外研究现状</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 相关知识 ">2 相关知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="2.1 &lt;b&gt;线性整流激活函数&lt;/b&gt;">2.1 <b>线性整流激活函数</b></a></li>
                                                <li><a href="#51" data-title="2.2 &lt;b&gt;批标准化&lt;/b&gt;">2.2 <b>批标准化</b></a></li>
                                                <li><a href="#53" data-title="2.3 &lt;b&gt;端到端模型及跳跃连接&lt;/b&gt;">2.3 <b>端到端模型及跳跃连接</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="3 本文算法 ">3 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="3.1 &lt;b&gt;数据预处理&lt;/b&gt;">3.1 <b>数据预处理</b></a></li>
                                                <li><a href="#60" data-title="3.2 &lt;b&gt;数据扩充&lt;/b&gt;">3.2 <b>数据扩充</b></a></li>
                                                <li><a href="#64" data-title="3.3 &lt;b&gt;本文网络模型&lt;/b&gt;">3.3 <b>本文网络模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="4.1 &lt;b&gt;实验数据和评价指标&lt;/b&gt;">4.1 <b>实验数据和评价指标</b></a></li>
                                                <li><a href="#90" data-title="4.2 &lt;b&gt;分割结果&lt;/b&gt;">4.2 <b>分割结果</b></a></li>
                                                <li><a href="#100" data-title="4.3 &lt;b&gt;与其他算法对比&lt;/b&gt;">4.3 <b>与其他算法对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#104" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 感兴趣区域提取">图1 感兴趣区域提取</a></li>
                                                <li><a href="#63" data-title="图2 数据扩充">图2 数据扩充</a></li>
                                                <li><a href="#66" data-title="图3 本文采用的U-net结构">图3 本文采用的U-net结构</a></li>
                                                <li><a href="#68" data-title="图4 卷积块及反卷积块结构">图4 卷积块及反卷积块结构</a></li>
                                                <li><a href="#92" data-title="图5 分割结果示例">图5 分割结果示例</a></li>
                                                <li><a href="#94" data-title="图6 测试样例上的平均DSC、PM、CR指标">图6 测试样例上的平均DSC、PM、CR指标</a></li>
                                                <li><a href="#95" data-title="图7 测试样例上的平均ASSD指标">图7 测试样例上的平均ASSD指标</a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同训练集下分割结果对比&lt;/b&gt;"><b>表</b>1 <b>不同训练集下分割结果对比</b></a></li>
                                                <li><a href="#98" data-title="图8 四种算法分割结果对应的DSC、PM、CR及ASSD评价指标">图8 四种算法分割结果对应的DSC、PM、CR及ASSD评价指标</a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;本文算法与其他算法的分割结果对比&lt;/b&gt;"><b>表</b>2 <b>本文算法与其他算法的分割结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="120">


                                    <a id="bibliography_1" title="CHANG E T, ADAMI H O.The enigmatic epidemiology of nasopharyngeal carcinoma[J].Cancer Epidemiology and Prevention Biomarkers, 2006, 15 (10) :1765-1777." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The enigmatic epidemiology of nasopharyngeal carcinoma">
                                        <b>[1]</b>
                                        CHANG E T, ADAMI H O.The enigmatic epidemiology of nasopharyngeal carcinoma[J].Cancer Epidemiology and Prevention Biomarkers, 2006, 15 (10) :1765-1777.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_2" title="TORRE L A, BRAY F, SIEGEL R L, et al.Global cancer statistics, 2012[J].CA:A Cancer Journal for Clinicians, 2015, 65 (2) :87-108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Global Cancer Statistics,2012">
                                        <b>[2]</b>
                                        TORRE L A, BRAY F, SIEGEL R L, et al.Global cancer statistics, 2012[J].CA:A Cancer Journal for Clinicians, 2015, 65 (2) :87-108.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_3" title="时永刚, 王东青, 刘志文.字典学习和稀疏表示的海马子区图像分割[J].中国图象图形学报, 2015, 20 (12) :1593-1601. (SHI Y G, WANG D Q, LIU Z W.Segmentation of hippocampal subfields using dictionary learning and sparse representation[J].Journal of Image and Graphics, 2015, 20 (12) :1593-1601.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201512004&amp;v=MjQxNDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVMM0pQeXJmYkxHNEg5VE5yWTlGWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        时永刚, 王东青, 刘志文.字典学习和稀疏表示的海马子区图像分割[J].中国图象图形学报, 2015, 20 (12) :1593-1601. (SHI Y G, WANG D Q, LIU Z W.Segmentation of hippocampal subfields using dictionary learning and sparse representation[J].Journal of Image and Graphics, 2015, 20 (12) :1593-1601.) 
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_4" title="YUSHKEVICH P A, WANG H, PLUTA J, et al.Nearly automatic segmentation of hippocampal subfields in in vivo focal T2-weighted MRI[J].Neuro Image, 2010, 53 (4) :1208-1224." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501198576&amp;v=MTIxOTUvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJS0ZvWGFCTT1OaWZPZmJLN0h0RE5xbzlFWmVJSENYcw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        YUSHKEVICH P A, WANG H, PLUTA J, et al.Nearly automatic segmentation of hippocampal subfields in in vivo focal T2-weighted MRI[J].Neuro Image, 2010, 53 (4) :1208-1224.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_5" title="SHE L, ZHONG H.Fuzzy C-means clustering algorithm combined with Markov random field for brain MR image segmentation[J].Journal of Image&amp;amp;Graphics, 2012, 17 (12) :1554-1560." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201212015&amp;v=MDEzMzJyWTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFVMM0pQeXJmYkxHNEg5UE4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        SHE L, ZHONG H.Fuzzy C-means clustering algorithm combined with Markov random field for brain MR image segmentation[J].Journal of Image&amp;amp;Graphics, 2012, 17 (12) :1554-1560.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_6" title="TATANUN C, RITTHIPRAVAT P, BHONGMAKAPAT T, et al.Automatic segmentation of nasopharyngeal carcinoma from CT images:region growing based technique[C]//Proceedings of the 2nd International Conference on Signal Processing Systems.Piscataway, NJ:IEEE, 2010:18-22." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Segmentation of Nasopharyngeal Carcinoma from CT Images:Region Growing Based Technique">
                                        <b>[6]</b>
                                        TATANUN C, RITTHIPRAVAT P, BHONGMAKAPAT T, et al.Automatic segmentation of nasopharyngeal carcinoma from CT images:region growing based technique[C]//Proceedings of the 2nd International Conference on Signal Processing Systems.Piscataway, NJ:IEEE, 2010:18-22.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_7" title="FITTON I, CORNELISSEN S A P, DUPPEN J C, et al.Semi-automatic delineation using weighted CT-MRI registered images for radiotherapy of nasopharyngeal cancer[J].Medical Physics, 2011, 38 (8) :4662-4666." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-automatic delineation using weighted CT-MRI registered images for radiotherapy of nasopharyngeal cancer">
                                        <b>[7]</b>
                                        FITTON I, CORNELISSEN S A P, DUPPEN J C, et al.Semi-automatic delineation using weighted CT-MRI registered images for radiotherapy of nasopharyngeal cancer[J].Medical Physics, 2011, 38 (8) :4662-4666.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_8" title="HUANG K W, ZHAO Z Y, GONG Q, et al.Nasopharyngeal carcinoma segmentation via HMRF-EM with maximum entropy[C]//Proceedings of the 37th Annual International Conference of the IEEEEngineering in Medicine and Biology Society.Piscataway, NJ:IEEE, 2015:2968-2972." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nasopharyngeal carcinoma segmentation via HMRF-EM with maximum entropy">
                                        <b>[8]</b>
                                        HUANG K W, ZHAO Z Y, GONG Q, et al.Nasopharyngeal carcinoma segmentation via HMRF-EM with maximum entropy[C]//Proceedings of the 37th Annual International Conference of the IEEEEngineering in Medicine and Biology Society.Piscataway, NJ:IEEE, 2015:2968-2972.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_9" title="ZHOU J, CHAN K L, XU P, et al.Nasopharyngeal carcinoma lesion segmentation from MR images by support vector machine[C]//Proceedings of the 3rd IEEE International Symposium on Biomedical Imaging:Nano To Macro.Piscataway, NJ:IEEE, 2006:1364-1367." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nasopharyngeal carcinoma lesion segmentation from MR images by support vector machine">
                                        <b>[9]</b>
                                        ZHOU J, CHAN K L, XU P, et al.Nasopharyngeal carcinoma lesion segmentation from MR images by support vector machine[C]//Proceedings of the 3rd IEEE International Symposium on Biomedical Imaging:Nano To Macro.Piscataway, NJ:IEEE, 2006:1364-1367.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_10" title="HOSSEINI-ASL E, GHAZAL M, MAHMOUD A, et al.Alzheimer&#39;s disease diagnostics by a 3D deeply supervised adaptable convolutional network[J].Frontiers in Bioscience, 2016, 23 (3) :584-596." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Alzheimer&amp;#39;&amp;#39;s disease diagnostics by a 3D deeply supervised adaptable convolutional network">
                                        <b>[10]</b>
                                        HOSSEINI-ASL E, GHAZAL M, MAHMOUD A, et al.Alzheimer&#39;s disease diagnostics by a 3D deeply supervised adaptable convolutional network[J].Frontiers in Bioscience, 2016, 23 (3) :584-596.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_11" title="LI R, ZHANG W, SUK H I, et al.Deep learning based imaging data completion for improved brain disease diagnosis[C]//MICCAI 2014:Proceedings of the 2014 Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer, 2014:305-312." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning based imaging data completion for improved brain disease diagnosis">
                                        <b>[11]</b>
                                        LI R, ZHANG W, SUK H I, et al.Deep learning based imaging data completion for improved brain disease diagnosis[C]//MICCAI 2014:Proceedings of the 2014 Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer, 2014:305-312.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_12" title="FU H, XU Y, WONG D W K, et al.Retinal vessel segmentation via deep learning network and fully-connected conditional random fields[C]//Proceedings of the IEEE 13th International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:698-701." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Retinal vessel segmentation via deep learning network and fully-connected conditional random fields">
                                        <b>[12]</b>
                                        FU H, XU Y, WONG D W K, et al.Retinal vessel segmentation via deep learning network and fully-connected conditional random fields[C]//Proceedings of the IEEE 13th International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:698-701.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_13" title="CIRESAN D, GIUSTI A, GAMBARDELLA L M, et al.Deep neural networks segment neuronal membranes in electron microscopy images[EB/OL].[2018-05-10].http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep neural networks segment neuronal membranes in electron microscopy images">
                                        <b>[13]</b>
                                        CIRESAN D, GIUSTI A, GAMBARDELLA L M, et al.Deep neural networks segment neuronal membranes in electron microscopy images[EB/OL].[2018-05-10].http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_14" title="ZHANG W, LI R, DENG H, et al.Deep convolutional neural networks for multi-modality isointense infant brain image segmentation[J].Neuro Image, 2015, 108:1342-1345." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0E2BC5E46FDD0F06DDB9C77E3246A0D&amp;v=MzI0NjlMeTh3cWs9TmlmT2ZjYTRhOU8rM0lvd1lPMTVlQWc1dVJZVm5rc1BRUXpscTJjMmU3YVNOTHJyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        ZHANG W, LI R, DENG H, et al.Deep convolutional neural networks for multi-modality isointense infant brain image segmentation[J].Neuro Image, 2015, 108:1342-1345.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_15" title="LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:3431-3440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[15]</b>
                                        LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:3431-3440.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_16" title="RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 18th International Conference on Medical Image Computing and Computer Assisted Intervention.Berlin:Springer, 2015:234-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">
                                        <b>[16]</b>
                                        RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 18th International Conference on Medical Image Computing and Computer Assisted Intervention.Berlin:Springer, 2015:234-241.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_17" title="IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//Proceedings of the 32nd International Conference on International Conference on Machine Learning.New York:ACM, 2015:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">
                                        <b>[17]</b>
                                        IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//Proceedings of the 32nd International Conference on International Conference on Machine Learning.New York:ACM, 2015:448-456.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_18" title="SCHAEFER S, MCPHAIL T, WARREN J.Image deformation using moving least squares[J].ACM Transactions on Graphics, 2006, 25 (3) :533-540." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098351&amp;v=MjQxMDFUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJS0ZvWGFCTT1OaWZJWTdLN0h0ak5yNDlGWk9JSEQzazRvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        SCHAEFER S, MCPHAIL T, WARREN J.Image deformation using moving least squares[J].ACM Transactions on Graphics, 2006, 25 (3) :533-540.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-16 10:09</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1183-1188 DOI:10.11772/j.issn.1001-9081.2018091908            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于U-net模型的全自动鼻咽肿瘤MR图像分割</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%BD%98%E6%B2%9B%E5%85%8B&amp;code=37919551&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潘沛克</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%89%B3&amp;code=08734982&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王艳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E5%8B%87&amp;code=22042011&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗勇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%BF%80%E6%B5%81&amp;code=00011651&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周激流</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0054367&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川大学电子信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0128376&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%A4%A7%E5%AD%A6%E5%8D%8E%E8%A5%BF%E5%8C%BB%E9%99%A2%E8%82%BF%E7%98%A4%E7%A7%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川大学华西医院肿瘤科</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>鼻咽肿瘤生长方向不确定, 解剖结构复杂, 当前主要依靠医生手动分割, 该方法耗时久同时严重依赖于医生的经验。针对这一问题, 基于深度学习理论, 提出一种基于U-net模型的全自动鼻咽肿瘤MR图像分割算法, 利用卷积操作替换原始U-net模型中的最大池化操作以减少特征信息的损失。首先, 从所有患者的肿瘤切片中提取大小为128×128的区域作为数据样本;然后, 将患者样本分为训练样本集和测试样本集, 并对训练样本集进行数据扩充;最后, 选择训练样本集中所有数据用于训练网络模型。为了验证所提模型的有效性, 选取测试样本集中患者的所有肿瘤切片进行分割, 最终平均分割精度可达到:DSC (Dice Similarity Coefficient) 为80.05%, PM系数为85.7%, CR系数为71.26%, ASSD (Average Symmetric Surface Distance) 指标为1.156 8。与基于图像块的卷积神经网络 (CNN) 相比, 所提算法DSC, PM (Prevent Match) 、CR (Correspondence Ratio) 系数分别提高了9.86个百分点、19.61个百分点、16.02个百分点, ASSD指标下降了0.436 4;与全卷积神经网络 (FCN) 模型及基于最大池化的U-net网络相比, 所提算法的DSC、CR系数均取得了最优结果, PM系数较两种对比模型中的最大值低2.55个百分点, ASSD指标较两种对比模型中的最小值略高出0.004 6。实验结果表明, 所提算法针对鼻咽肿瘤图像可以实现较好的自动化分割效果以辅助医生进行诊断。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%BC%BB%E5%92%BD%E8%82%BF%E7%98%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鼻咽肿瘤;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">医学图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%AB%AF%E5%88%B0%E7%AB%AF%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">端到端模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=U-net%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">U-net模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    潘沛克 (1995—) , 男, 湖北鄂州人, 硕士研究生, 主要研究方向:深度学习、医学图像处理;;
                                </span>
                                <span>
                                    *王艳 (1986—) , 女, 宁夏平罗人, 讲师, 博士, 主要研究方向:医学图像处理、模式识别;通信作者电子邮箱ywang@scu.edu.cn;
                                </span>
                                <span>
                                    罗勇 (1980—) , 男, 四川成都人, 主治医师, 博士, 主要研究方向:医学影像分析;;
                                </span>
                                <span>
                                    周激流 (1963—) , 男, 四川成都人, 教授, 博士, 主要研究方向:数字图像处理、分数阶微积分、无线传感网络。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61701324);</span>
                    </p>
            </div>
                    <h1><b>Automatic segmentation of nasopharyngeal neoplasm in MR image based on U-net model</b></h1>
                    <h2>
                    <span>PAN Peike</span>
                    <span>WANG Yan</span>
                    <span>LUO Yong</span>
                    <span>ZHOU Jiliu</span>
            </h2>
                    <h2>
                    <span>College of Electronics and Information Engineering, Sichuan University</span>
                    <span>College of Computer Science, Sichuan University</span>
                    <span>Department of Oncology, West China Hospital, Sichuan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Because of the uncertain growth direction and complex anatomical structure for nasopharyngeal tumors, doctors always manually delineate the tumor regions in MR images, which is time-consuming and the delineation result heavily depends on the experience of doctors. In order to solve this problem, based on deep learning algorithm, a U-net based MR image automatic segmentation algorithm of nasopharyngeal tumors was proposed, in which the max-pooling operation in original U-net model was replaced by the convolution operation to keep more feature information. Firstly, the regions of 128×128 were extracted from all slices with tumor regions of the patients as data samples. Secondly, the patient samples were divided into training sample set and testing sample set, and data augmentation was performed on the training samples. Finally, all the training samples were used to train the model. To evaluate the performance of the proposed U-net based model, all slices of patients in testing sample set were selected for segmentation, and the final average results are: Dice Similarity Coefficient (DSC) is 80.05%, Prevent Match (PM) coefficient is 85.7%, Correspondence Ratio (CR) coefficient is 71.26% and Average Symmetric Surface Distance (ASSD) is 1.156 8. Compared with Convolutional Neural Network (CNN) based model, DSC, PM and CR coefficients of the proposed method are increased by 9.86 percentage points, 19.61 percentage points and 16.02 percentage points respectively, and ASSD is decreased by 0.436 4. Compared with Fully Convolutional Network (FCN) model and max-pooling based U-net model, DSC and CR coefficients of the proposed method achieve the best results, while PM coefficient is 2.55 percentage points lower than the maximum value in the two comparison models, and ASSD is slightly higher than the minimum value of the two comparison models by 0.004 6. The experimental results show that the proposed model can achieve good segmentation results of nasopharyngeal neoplasm, which assists doctors in diagnosis.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=nasopharyngeal%20neoplasm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">nasopharyngeal neoplasm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=medical%20image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">medical image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=end-to-end%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">end-to-end model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=U-net%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">U-net model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    PAN Peike, born in 1995, M. S. candidate. His research interests include deep learning, medical image processing.;
                                </span>
                                <span>
                                    WANG Yan, born in 1986, Ph. D. , lecturer. Her research interests include medical image processing, pattern recognition.;
                                </span>
                                <span>
                                    LUO Yong, born in 1980, Ph. D. , attending physician, His research interests include medical image analysis.;
                                </span>
                                <span>
                                    ZHOU Jiliu, born in 1963, Ph. D. , professor. His research interests include digital image processing, fractional calculus, wireless sensor network.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-13</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61701324);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">医学图像在临床诊断中发挥着极其重要的作用。近年来, 随着医学成像技术的进步和图像处理技术的不断发展, 针对医学图像的图像处理技术逐渐发展成为一个重要的研究领域, 其中医学图像分割更是一个具有很高临床应用价值的研究方向。医学图像分割技术的目的是通过设计自动或半自动的分割算法, 将医学图像中医生感兴趣的部分分割出来, 并使分割结果尽可能地接近该区域的原始结构。医学图像分割在临床诊断、病理诊疗方面具有重要意义, 利用分割后的图像测量病灶体积可以辅助医生确定病情以制定治疗计划, 利用肿瘤分割图像可以辅助医生标定放疗靶区。在医学图像分割问题中, 针对肿瘤的图像分割问题是一个难点, 其中针对鼻咽肿瘤的分割尤其困难。</p>
                </div>
                <div class="p1">
                    <p id="41">鼻咽肿瘤是一种常见的恶性头颈部肿瘤, 其生长于鼻咽部位置, 具有较高的致死率。鼻咽肿瘤多发于中国的南部地区、中东地区、东南亚地区以及北非地区<citation id="156" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 根据一份公开的报道<citation id="157" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 2012年在世界范围内有超过8万例的新增鼻咽肿瘤患者被诊断出, 有3万例患者因患鼻咽肿瘤死亡, 在这些患者中, 有大量患者被检出时已是肿瘤晚期, 因而错过了最佳的治疗阶段。当前, 医生对鼻咽肿瘤的诊断大部分基于病人的核磁共振成像 (Magnetic Resonance Imaging, MRI) 图像, 通过医生的手工勾画实现对MRI图像中鼻咽肿瘤区域的提取。手工勾画的方式主要存在两个问题:一是耗时长, 医生需要花费大量的时间为病人勾画肿瘤区域, 效率低下;第二是手工勾画结果严重依赖于医生的经验, 对于同一个病人的MRI图像不同医生可能得到不同的勾画结果。针对传统的由医生手工进行勾画存在的问题, 一些研究人员开始研究自动化或半自动化的鼻咽肿瘤图像分割算法, 通过软件对鼻咽肿瘤区域进行分割, 从而辅助医生进行鼻咽肿瘤的诊断和治疗。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 国内外研究现状</h3>
                <div class="p1">
                    <p id="43">当前, 在医学图像分割领域, 已经有大量应用传统机器学习算法的模型, 这些模型被广泛应用到如脑肿瘤分割、海马体分割等领域<citation id="162" type="reference"><link href="124" rel="bibliography" /><link href="126" rel="bibliography" /><link href="128" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。但对于鼻咽肿瘤分割, 由于鼻咽肿瘤生长区域不确定, 在电子计算机断层扫描 (Computed Tomography, CT) 图像和MRI图像中边界不明显, 同时鼻咽部解剖结构复杂, 包含多种组织, 且鼻咽肿瘤区域常与正常组织发生混叠, 因此针对鼻咽肿瘤的分割十分困难。当前国内外对鼻咽肿瘤自动分割算法的研究较少, 但仍有一些研究学者在该领域作出了卓有成效的工作。如Tatanun等<citation id="158" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种基于区域生长的分割算法, 该算法利用像素点灰度值、非肿瘤区域等先验知识初始化种子点实现对鼻咽肿瘤CT图像的分割;Fitton等<citation id="159" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>采用加权CT及MRI图像进行鼻咽肿瘤分割, 该方法基于一种交互的方式, 以医生初步勾画的肿瘤区域为基准进行优化, 该方法在一定程度上可以提高分割效率, 但无法显著提升肿瘤分割精度;Huang等<citation id="160" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种基于最大熵的隐马尔可夫随机场模型对鼻咽肿瘤MRI图像进行分割;Zhou等<citation id="161" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一种基于支持向量机的模型, 其将T1权重及加权的T1权重MRI图像的特征投影到多维空间, 通过支持向量机对多维空间中的特征进行分类, 从而实现对鼻咽肿瘤图像的分割。</p>
                </div>
                <div class="p1">
                    <p id="44">近些年来, 随着深度学习的发展, 基于深度卷积神经网络及其变种的模型被广泛应用于医学图像处理的各个领域中并取得了相当好的效果<citation id="166" type="reference"><link href="138" rel="bibliography" /><link href="140" rel="bibliography" /><link href="142" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。其中医学图像分割是最为常见的一类研究课题, 而卷积神经网络 (Convolutional Neural Network, CNN) 及其变种是医学图像分割问题中最为常见的算法模型之一。如Ciresan等<citation id="163" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>利用二维卷积神经网络实现了对电子显微镜成像图像的分割;Zhang等<citation id="164" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用深度卷积神经网络实现对多模态脑部图像的分割。虽然这些基于CNN的算法模型在相关问题上已经取得了较好的表现, 但是这些方法都存在着共同的问题, 即:所有网络都是以图像块作为输入, 大量重叠的图像块带来的冗余计算增大了对网络进行测试的时间开销, 同时图像块大小会影响所训练网络的性能。针对这一问题, 有很多研究人员开始采用基于全卷积神经网络的模型来解决图像分割问题, 全卷积神经网络 (Fully Convolutional Network, FCN) <citation id="165" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>是一种端到端模型, 它可以将整张图片作为网络的输入并生成相应整张图片输出, 从而避免了使用图像块带来的问题。</p>
                </div>
                <div class="p1">
                    <p id="45">虽然目前深度学习模型被广泛应用到医学图像分割中, 但针对鼻咽肿瘤的深度学习算法模型还很少, 受此启发, 本文基于深度学习理论, 提出一种基于U-net模型<citation id="167" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的鼻咽肿瘤分割算法, U-net模型作为一种端到端模型, 因其在少量训练数据下仍能获得较好的训练效果因而适用于往往只有少量可用数据的医学图像处理领域。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 相关知识</h3>
                <h4 class="anchor-tag" id="47" name="47">2.1 <b>线性整流激活函数</b></h4>
                <div class="p1">
                    <p id="48">相对于最原始的感知机结构不采用激活函数, 输出始终是输入的线性组合。在当前的神经网络模型中, 往往在卷积层之后引入非线性激活函数, 从而使得神经网络的输出不再是输入的线性组合, 因此相关网络模型理论上可以逼近任意函数, 从而有效地提升了网络模型的表达能力。常用的非线性激活函数主要有:sigmoid函数、tanh函数、线性整流 (Rectified Linear Unit, ReLu) 函数及maxout函数。其中ReLu激活函数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>f</i> (<i>x</i>) =max (<i>x</i>, 0)      (1) </p>
                </div>
                <div class="p1">
                    <p id="50">相对于sigmoid函数和tanh函数由于饱和区域带来的梯度消失的问题, ReLu激活函数采用单侧抑制非饱和计算公式, 能有效解决深层网络的收敛问题并加速收敛过程。同时相对于maxout函数, ReLu函数参数数量较少, 更易于使用。当前ReLu函数被广泛应用于各类网络模型中, 在本文网络结构中同样选择采用ReLu函数作为激活函数。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51">2.2 <b>批标准化</b></h4>
                <div class="p1">
                    <p id="52">随着网络模型深度加深, 网络训练可能越发困难, 其收敛速度可能逐渐变慢。其原因在于神经网络中间层的数据分布随着参数更新或网络加深会发生改变, 且这种差异会随着网络深度增大而增大, 从而造成网络模型必须适应学习新的数据分布, 因此影响网络训练速度。针对这一问题, Ioffe等<citation id="168" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出了批标准化 (Batch Normalization, BN) 方法, 该方法通过对层间数据进行均值和方差的修正保证层间数据分布的稳定, 同时引入两个可学习的参数对数据进行缩放和平移以保证网络的表达能力。通过引入批标准化方法, 可以提高网络收敛速度, 同时可以控制过拟合, 实现少用或不用dropout及正则化操作。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53">2.3 <b>端到端模型及跳跃连接</b></h4>
                <div class="p1">
                    <p id="54">与传统的基于图像块的卷积神经网络模型相比, 端到端模型可使用整张图片作为输入同时生成整张图片作为输出, 对于肿瘤图像分割任务, 端到端模型仅需一次即可获取一个肿瘤切片的完整分割结果, 而基于图像块的模型则需要对切片中的每个像素点单独进行预测, 因此在本文中采用端到端模型可以有效减少进行图像分割的时间开销。常见的端到端模型主要有全卷积神经网络, 它将不同层级的特征图通过求和的方式组合到一起进行利用。区别于FCN模型, U-net模型中采用跳跃连接 (skip connection) 的方式将模型中收缩编码路径的特征信息与扩展路径中反卷积操作获得的特征级联到一起, 从而获得多尺度特征信息以提高网络性能。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">3 本文算法</h3>
                <div class="p1">
                    <p id="56">本文算法的整体流程主要包括三个步骤:预处理、数据扩充 (data augmentation) 和基于U-net网络模型的图像分割。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">3.1 <b>数据预处理</b></h4>
                <div class="p1">
                    <p id="58">对于获取的鼻咽肿瘤MRI图像样本, 需要从中提取感兴趣区域并对其进行预处理以作为训练网络和进行测试时使用的样本。首先考虑到鼻咽肿瘤区域在获取到的原始232×320大小的MRI图像切片中所占比例较小同时鼻咽部解剖位置相对固定, 因此从每个MRI切片中提取一个128×128 的固定大小的区域作为感兴趣区域 (Region Of Interest, ROI) , 该区域足以包含切片上所有可能存在肿瘤的位置。之后对获取到的所有鼻咽肿瘤感兴趣区域图像进行灰度正则化处理, 提取相关样本数据的均值及标准差, 通过减均值除以标准差的方式实现图像的灰度正则化运算。在之后的训练和测试过程中, 以该128×128大小的图片数据作为样本送入到网络模型中去, 提取区域如图1所示。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 感兴趣区域提取" src="Detail/GetImg?filename=images/JSJY201904040_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 感兴趣区域提取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Extraction of region of interest</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60">3.2 <b>数据扩充</b></h4>
                <div class="p1">
                    <p id="61">由于可用的已标注的鼻咽肿瘤图像数据较少, 难以用于训练一个深度神经网络模型, 因此在本文中通过采用一些随机的图像处理方法来对原始数据进行扩充以增加可用的训练样本数量。在本文中共采用了五种数据扩充的方式, 包括:随机角度旋转、随机平移、水平方向翻转、竖直方向翻转, 以及图像变形。其中, 通过随机角度旋转、随机平移、水平方向及竖直方向翻转可以获得简单形变后的图像, 但是这些新的图像相对于原本的图像并没有太大的形状上的差异;而考虑到在真实的鼻咽肿瘤图像中, 个体间肿瘤形状差异较大的问题, 在本文中还引入了由Schaefer等<citation id="169" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出的图像变形 (Image Deformation) 的方法来对图像数据进行扩充, 借助该方法可生成更具形状差异性的图像数据以供网络进行训练。</p>
                </div>
                <div class="p1">
                    <p id="62">在本文中, 首先对所有原始的MRI切片进行两次图像变形, 之后对原始图片及其图像变形后的图片应用旋转、平移等四种数据扩充方法, 从而最终实现对原始MRI图像数据的数据扩充。图2展示了图像扩充的示例。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 数据扩充" src="Detail/GetImg?filename=images/JSJY201904040_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 数据扩充  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Data Augmentation</p>

                </div>
                <h4 class="anchor-tag" id="64" name="64">3.3 <b>本文网络模型</b></h4>
                <div class="p1">
                    <p id="65">图3展现了本文中使用的U-net网络结构。一个U-net网络结构由两个部分构成, 即左边用于处理输入MRI图像的收缩编码器部分及右边用于产生标签输出的解码器部分。其中跳跃连接将编码器部分每个分块的特征与解码器中反卷积操作获得的特征进行级联。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文采用的U-net结构" src="Detail/GetImg?filename=images/JSJY201904040_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文采用的U-net结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Proposed U-net structure</p>

                </div>
                <div class="p1">
                    <p id="67">在本文中, 整个U-net网络包括了28个卷积层, 其中24个卷积层分布在4个卷积块、4个反卷积块中。U-net的收缩编码器部分包含了4个卷积块, 如图4 (a) 所示。每个卷积块包含两个卷积层 (Convolutional layer, Conv) , 每个卷积层采用步长为1的3×3卷积核进行卷积, 同时每个卷积层紧跟一个批规范化 (BN) 层及一个ReLu非线性激活函数层以提高网络性能。在每个卷积块中, 其第一个卷积层会加倍特征图数量, 经过网络的前两个卷积层将特征图数量增大至64, 再经过四个卷积块使得特征图数量从64增加到1 024。在每个卷积块之间, 区别于传统的U-net模型采用最大池化的方式来进行下采样, 在本文中采用步长为2的2×2卷积核进行Down-Conv卷积操作以实现对上一个卷积块的特征图像的下采样操作。通过该卷积操作使特征图大小逐层减半, 从而使得输入图像大小从128×128逐层减小至8×8。而U-net网络模型的扩张解码器部分包含4个反卷积块, 如图4 (b) 所示。反卷积Up-Conv操作采用步长为2的3×3卷积核, 通过反卷积操作使特征图大小增大为原来的两倍从而使特征图在最后一个反卷积块中恢复为输入图像的大小。同时经过每个反卷积操作时减半特征图数量, 并将反卷积获得的特征图与卷积块中对应的特征图级联作为反卷积块的特征输入。在每个反卷积块内部包含两个卷积层, 采用步长为1的3×3卷积核, 其中第一个卷积层会使级联后的特征图数量减半。区别于原始的U-net结构, 本文采用的U-net结构在每个卷积层采用零填充方式进行填充。根据式 (2) 可知利用零填充可保证网络模型的输出大小与输入图片数据大小保持一致。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 卷积块及反卷积块结构" src="Detail/GetImg?filename=images/JSJY201904040_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 卷积块及反卷积块结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Structure of ConvBlock and Up-ConvBlock</p>

                </div>
                <div class="p1">
                    <p id="69"><i>I</i><sub>output</sub>= (<i>I</i><sub>input</sub>-<i>F</i>+2<i>P</i>) /<i>S</i>+1      (2) </p>
                </div>
                <div class="p1">
                    <p id="70">其中:<i>I</i><sub>input</sub> 和<i>I</i><sub>output</sub>分别表示网络模型输入、输出图像的大小;<i>F</i>表示卷积核大小, 在本文中为3×3;<i>P</i>表示填充大小, 在本文中为1×1;<i>S</i>表示步长, 在本文中为1。</p>
                </div>
                <div class="p1">
                    <p id="71">在本文U-net模型的最后采用一个1×1的卷积层将特征图数目缩减为1, 并利用sigmoid函数对最终输出进行处理, 使得最终输出图像中每个像素点值对应位于0～1内。将该图像作为网络的最终输出概率图, 每一个像素点对应值表示该点属于肿瘤的概率。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag">4 实验与结果分析</h3>
                <h4 class="anchor-tag" id="73" name="73">4.1 <b>实验数据和评价指标</b></h4>
                <div class="p1">
                    <p id="74">本文采用Keras框架构建基于U-net的鼻咽肿瘤分割模型。本文实验数据获取自四川大学华西医院肿瘤科, 包含鼻咽肿瘤患者的三维MRI-T1权重图像, 图像大小为232×320×103。为了测试本文算法的分割精度, 将数据集分成训练样本集和测试样本集, 提取相关肿瘤层感兴趣区域构建训练样本对U-net模型进行训练。原始训练样本中共包含556张含肿瘤切片数据, 其中对每张原始图像进行两次图像变形操作后可获得两张变形后图像, 将其与原始图像一并经水平翻转、竖直翻转、平移、旋转操作, 最终可获取8 340张图像数据, 将该组数据作为训练样本集用以训练本文网络模型。同时利用6例测试样本中的肿瘤层构建测试样本对算法分割精度进行测试。</p>
                </div>
                <div class="p1">
                    <p id="75">为了定量的评估算法分割性能, 本文采用了四种评价指标:</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">1) DSC (Dice Similarity Coefficient) 。</h4>
                <div class="p1">
                    <p id="77">该指标可用于度量实际分割结果与理论分割结果的重合度。</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>S</mi><mi>C</mi><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>A</mi><mstyle displaystyle="true"><mo>∩</mo><mi>B</mi></mstyle><mo stretchy="false">) </mo></mrow><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>A</mi><mo stretchy="false">) </mo><mo>+</mo><mi>V</mi><mo stretchy="false"> (</mo><mi>B</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中:<i>V</i> (·) 表示区域大小;<i>A</i>和<i>B</i>分别表示医生标注的实际分割结果及本文算法实际分割结果。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">2) ASSD (Average Symmetric Surface Distance) 。</h4>
                <div class="p1">
                    <p id="81">该指标可用于计算实际分割结果与理论分割结果的差异性, 值越小越好。</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>S</mi><mi>S</mi><mi>D</mi><mo>=</mo><mfrac><mrow><mi>X</mi><mo>+</mo><mi>Y</mi></mrow><mrow><mi>A</mi><mo>+</mo><mi>B</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>其</mtext><mtext>中</mtext><mo>:</mo><mi>X</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><mo stretchy="false">{</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>a</mi><mo>, </mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Y</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mo stretchy="false">{</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>b</mi><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mo stretchy="false">]</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84"><i>dist</i> (<i>a</i>, <i>b</i>) 表示在两个图像中像素点<i>a</i>和<i>b</i>的距离。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">3) PM (Prevent Match) 和CR (Correspondence Ratio) 。</h4>
                <div class="p1">
                    <p id="86">这两个指标在图像分割领域较为常见, 其中:<i>PM</i>指标可以度量肿瘤漏分割的情况, <i>PM</i>指标越高则肿瘤漏分割的情况就越少, 但在极端情况下可能存在大量的误分割情况。而<i>CR</i>指标可度量肿瘤误分割的情况, <i>CR</i>指标越大, 则说明实际分割结果中误分割的情况越少。</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mi>Μ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mi>s</mi></mrow><mrow><mi>G</mi><mi>Τ</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>C</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mi>s</mi><mo>-</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>×</mo><mi>F</mi><mi>Ρ</mi><mi>s</mi></mrow><mrow><mi>G</mi><mi>Τ</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中:<i>TPs</i>表示正确分割的区域;<i>FPs</i>表示误分割区域;<i>GT</i>表示医生手工标注的肿瘤区域。</p>
                </div>
                <div class="p1">
                    <p id="89">上述四个评价指标中, DSC、PM、CR指标越高代表分割结果越好, ASSD指标越低代表分割结果与理论结果越接近。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">4.2 <b>分割结果</b></h4>
                <div class="p1">
                    <p id="91">为了验证本文算法的有效性, 利用6例病人的肿瘤切片层构建测试样本, 测试本文算法在每个病人的所有肿瘤层上的平均分割精度。图5展示了在部分肿瘤层上本文算法的分割结果。从图5可看出, 利用本文算法进行鼻咽肿瘤分割得到的结果与手工标记的结果较为接近。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 分割结果示例" src="Detail/GetImg?filename=images/JSJY201904040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 分割结果示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Some segmentation results</p>

                </div>
                <div class="p1">
                    <p id="93">在图6～7中给出了本文算法在6个测试样例上分割结果的定量评价指标。从图6～7可看出:本文所采用的算法在除样本3、6外的其他样本上DSC均在80%以上, CR系数均在70%以上;除样本3外, 所有样本的PM系数均在80%以上;除样本6以外, 所有样本的ASSD指标均在1.5以下。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 测试样例上的平均DSC、PM、CR指标" src="Detail/GetImg?filename=images/JSJY201904040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 测试样例上的平均DSC、PM、CR指标  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Average DSC, PM and CR coefficients on test samples</p>

                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 测试样例上的平均ASSD指标" src="Detail/GetImg?filename=images/JSJY201904040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 测试样例上的平均ASSD指标  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Average ASSD coefficients on test samples</p>

                </div>
                <div class="p1">
                    <p id="96">同时为验证经由图像变形获取的数据对实验结果的影响, 额外从原始训练样本集中提取两组训练样本对网络模型进行训练以测试最终分割结果。其中一组训练样本集仅包含原始图像数据及其对应扩充后的图像数据;另一组训练样本集则仅包含图像变形后的数据及对应扩充后的数据样本。利用两组训练样本对网络进行训练, 结果如表1所示。</p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表</b>1 <b>不同训练集下分割结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Segmentation result comparison by different training sets</p>
                    <p class="img_note"></p>
                    <table id="97" border="1"><tr><td>训练集</td><td>DSC</td><td>PM</td><td>CR</td><td>ASSD/mm</td></tr><tr><td><br />原始图像</td><td>0.782 5</td><td>0.846 4</td><td>0.682 4</td><td>1.313 0</td></tr><tr><td><br />变形图像</td><td>0.776 9</td><td>0.790 4</td><td>0.665 6</td><td>1.244 9</td></tr><tr><td><br />全部图像</td><td>0.800 5</td><td>0.857 0</td><td>0.712 6</td><td>1.156 8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904040_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 四种算法分割结果对应的DSC、PM、CR及ASSD评价指标" src="Detail/GetImg?filename=images/JSJY201904040_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 四种算法分割结果对应的DSC、PM、CR及ASSD评价指标  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904040_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Segmentation results in terms of DSC, PM, CR and ASSD by four algorithms</p>

                </div>
                <div class="p1">
                    <p id="99">从表1可看出:仅采用变形图像及其扩充数据作为训练样本进行训练, 可以在测试样本集上获得与仅采用原始图像及其扩充数据进行训练时相近的结果, 这一点充分说明了变形后图像数据的合理性。同时观察两组实验结果发现, 单独采用原始图像或单独采用变形图像进行数据扩充以训练网络模型, 均无法达到采用所有数据进行训练时网络模型的分割效果。这充分说明了在原始图像数据样本量较小的情况下, 通过采用包括图像变形在内的数据扩充方式来增大训练样本数量, 可以在一定程度上提升本文网络模型的性能。</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100">4.3 <b>与其他算法对比</b></h4>
                <div class="p1">
                    <p id="101">为验证本文算法在鼻咽肿瘤分割问题上的效果提升, 本文选取三种图像分割算法与本文算法进行对比, 这三种算法分别为:基于图像块的卷积神经网络模型、全卷积神经网络模型及基于最大池化 (maxpooling) 的U-net模型。在6个测试样本上的所有肿瘤层上的平均分割精度如图8所示。从图8可看出本文所采用的基于卷积的U-net模型在样本1、2、4、5中均获得了最高的DSC, 在样本1和5中取得了最高的PM指标, 在样本1、4、5中取得了最高的CR指标, 而在样本2、4、5中均取得了最低的ASSD指标, 同时在其他样本中, 本文算法也大都获得了与其他对比算法相近的结果。在表2中还给出了四种算法在所有测试样例上的所有肿瘤切片上的平均分割结果。</p>
                </div>
                <div class="area_img" id="102">
                    <p class="img_tit"><b>表</b>2 <b>本文算法与其他算法的分割结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Comparison of segmentation results among different algorithms</p>
                    <p class="img_note"></p>
                    <table id="102" border="1"><tr><td><br />算法</td><td>DSC</td><td>PM</td><td>CR</td><td>ASSD/mm</td></tr><tr><td><br />CNN</td><td>0.701 9</td><td>0.660 9</td><td>0.552 4</td><td>1.593 2</td></tr><tr><td><br />FCN</td><td>0.779 1</td><td><b>0.882</b><b>5</b></td><td>0.683 7</td><td>1.268 4</td></tr><tr><td><br />U-net (maxpooling) </td><td>0.790 7</td><td>0.867 9</td><td>0.699 2</td><td><b>1.152</b><b>2</b></td></tr><tr><td><br />U-net (conv) </td><td><b>0.800</b><b>5</b></td><td>0.857 0</td><td><b>0.712</b><b>6</b></td><td>1.156 8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="103">从表2可看出, 采用图像块的卷积神经网络模型在所有测试样例上分割结果最差。相对于CNN模型, 本文所提算法模型的DSC、PM及CR系数分别提高了9.86个百分点、19.61个百分点及16.02个百分点, ASSD指标下降了0.436 4。CNN模型分割结果较差的原因在于卷积神经网络模型的表达能力在很大程度上受到图像块大小的影响, 大的图像块会降低定位精度, 而小的图像块仅包含少量的上下文特征信息。另一方面, 在测试过程中, 采用CNN对一个给定图片进行分割需要对图片中的每个点的标签信息进行预测, 因此时间开销较大, 在本文中采用CNN模型对一张MRI图像进行分割大约需要一到两分钟, 而采用其他的端到端模型时间开销仅在一到两秒钟左右。同时从表2还可看出, 本文模型相对于FCN模型及基于最大值池化的U-net模型, 在DSC和CR指标上都可取得最好的结果, 在PM指标上较FCN模型低2.55个百分点, 在ASSD指标上较两种对比模型中的最优结果略高出0.004 6。</p>
                </div>
                <h3 id="104" name="104" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="105">本文针对鼻咽肿瘤分割问题提出了一种基于U-net网络模型的鼻咽肿瘤MRI图像自动分割算法。实验结果表明, 本文提出的U-net结构模型可以实现较好的实际分割效果。跟传统算法如基于图像块的CNN模型比较, 本文算法可实现较高的分割精度, 同时时间效率大幅提升。另外两组对比实验结果表明本文提出的基于卷积的U-net模型能实现比FCN模型及基于最大池化的U-net模型更好的效果。但在实验过程中也发现, 针对鼻咽肿瘤图像中肿瘤区块较小的切片, 现有算法模型常存在漏分类或误分类的情况, 难以实现精确分割。针对这一问题, 拟在后续采用多模态数据, 融合多模态图像中的相关特征信息以实现更高精度的鼻咽肿瘤自动分割算法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="120">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The enigmatic epidemiology of nasopharyngeal carcinoma">

                                <b>[1]</b>CHANG E T, ADAMI H O.The enigmatic epidemiology of nasopharyngeal carcinoma[J].Cancer Epidemiology and Prevention Biomarkers, 2006, 15 (10) :1765-1777.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Global Cancer Statistics,2012">

                                <b>[2]</b>TORRE L A, BRAY F, SIEGEL R L, et al.Global cancer statistics, 2012[J].CA:A Cancer Journal for Clinicians, 2015, 65 (2) :87-108.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201512004&amp;v=MjcxNTR6cXFCdEdGckNVUjdxZlp1WnNGeURoVUwzSlB5cmZiTEc0SDlUTnJZOUZZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>时永刚, 王东青, 刘志文.字典学习和稀疏表示的海马子区图像分割[J].中国图象图形学报, 2015, 20 (12) :1593-1601. (SHI Y G, WANG D Q, LIU Z W.Segmentation of hippocampal subfields using dictionary learning and sparse representation[J].Journal of Image and Graphics, 2015, 20 (12) :1593-1601.) 
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501198576&amp;v=MjM5MDZkR2VycVFUTW53WmVadEZpbmxVcjNJS0ZvWGFCTT1OaWZPZmJLN0h0RE5xbzlFWmVJSENYcy9vQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>YUSHKEVICH P A, WANG H, PLUTA J, et al.Nearly automatic segmentation of hippocampal subfields in in vivo focal T2-weighted MRI[J].Neuro Image, 2010, 53 (4) :1208-1224.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201212015&amp;v=MTY0MDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhVTDNKUHlyZmJMRzRIOVBOclk5RVlZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>SHE L, ZHONG H.Fuzzy C-means clustering algorithm combined with Markov random field for brain MR image segmentation[J].Journal of Image&amp;Graphics, 2012, 17 (12) :1554-1560.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Segmentation of Nasopharyngeal Carcinoma from CT Images:Region Growing Based Technique">

                                <b>[6]</b>TATANUN C, RITTHIPRAVAT P, BHONGMAKAPAT T, et al.Automatic segmentation of nasopharyngeal carcinoma from CT images:region growing based technique[C]//Proceedings of the 2nd International Conference on Signal Processing Systems.Piscataway, NJ:IEEE, 2010:18-22.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-automatic delineation using weighted CT-MRI registered images for radiotherapy of nasopharyngeal cancer">

                                <b>[7]</b>FITTON I, CORNELISSEN S A P, DUPPEN J C, et al.Semi-automatic delineation using weighted CT-MRI registered images for radiotherapy of nasopharyngeal cancer[J].Medical Physics, 2011, 38 (8) :4662-4666.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nasopharyngeal carcinoma segmentation via HMRF-EM with maximum entropy">

                                <b>[8]</b>HUANG K W, ZHAO Z Y, GONG Q, et al.Nasopharyngeal carcinoma segmentation via HMRF-EM with maximum entropy[C]//Proceedings of the 37th Annual International Conference of the IEEEEngineering in Medicine and Biology Society.Piscataway, NJ:IEEE, 2015:2968-2972.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nasopharyngeal carcinoma lesion segmentation from MR images by support vector machine">

                                <b>[9]</b>ZHOU J, CHAN K L, XU P, et al.Nasopharyngeal carcinoma lesion segmentation from MR images by support vector machine[C]//Proceedings of the 3rd IEEE International Symposium on Biomedical Imaging:Nano To Macro.Piscataway, NJ:IEEE, 2006:1364-1367.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Alzheimer&amp;#39;&amp;#39;s disease diagnostics by a 3D deeply supervised adaptable convolutional network">

                                <b>[10]</b>HOSSEINI-ASL E, GHAZAL M, MAHMOUD A, et al.Alzheimer's disease diagnostics by a 3D deeply supervised adaptable convolutional network[J].Frontiers in Bioscience, 2016, 23 (3) :584-596.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning based imaging data completion for improved brain disease diagnosis">

                                <b>[11]</b>LI R, ZHANG W, SUK H I, et al.Deep learning based imaging data completion for improved brain disease diagnosis[C]//MICCAI 2014:Proceedings of the 2014 Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer, 2014:305-312.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Retinal vessel segmentation via deep learning network and fully-connected conditional random fields">

                                <b>[12]</b>FU H, XU Y, WONG D W K, et al.Retinal vessel segmentation via deep learning network and fully-connected conditional random fields[C]//Proceedings of the IEEE 13th International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:698-701.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep neural networks segment neuronal membranes in electron microscopy images">

                                <b>[13]</b>CIRESAN D, GIUSTI A, GAMBARDELLA L M, et al.Deep neural networks segment neuronal membranes in electron microscopy images[EB/OL].[2018-05-10].http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0E2BC5E46FDD0F06DDB9C77E3246A0D&amp;v=MDcyMTB6bHEyYzJlN2FTTkxyckNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHpMeTh3cWs9TmlmT2ZjYTRhOU8rM0lvd1lPMTVlQWc1dVJZVm5rc1BRUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>ZHANG W, LI R, DENG H, et al.Deep convolutional neural networks for multi-modality isointense infant brain image segmentation[J].Neuro Image, 2015, 108:1342-1345.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[15]</b>LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:3431-3440.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">

                                <b>[16]</b>RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 18th International Conference on Medical Image Computing and Computer Assisted Intervention.Berlin:Springer, 2015:234-241.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">

                                <b>[17]</b>IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//Proceedings of the 32nd International Conference on International Conference on Machine Learning.New York:ACM, 2015:448-456.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098351&amp;v=MDMyNzE3SHRqTnI0OUZaT0lIRDNrNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUtGb1hhQk09TmlmSVk3Sw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>SCHAEFER S, MCPHAIL T, WARREN J.Image deformation using moving least squares[J].ACM Transactions on Graphics, 2006, 25 (3) :533-540.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904040" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904040&amp;v=MTI3NjFyQ1VSN3FmWnVac0Z5RGhVTDNKTHo3QmQ3RzRIOWpNcTQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
