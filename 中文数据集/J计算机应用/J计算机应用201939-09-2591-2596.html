<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136474593721250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201909019%26RESULT%3d1%26SIGN%3dzIJI4KrNkIxvB2h6gzU8hAoXyWg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909019&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201909019&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909019&amp;v=MzEyODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am1Wci9OTHo3QmQ3RzRIOWpNcG85RWJZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#56" data-title="1 预备理论 ">1 预备理论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="1.1 SMOTE&lt;b&gt;算法&lt;/b&gt;">1.1 SMOTE<b>算法</b></a></li>
                                                <li><a href="#61" data-title="1.2 AdaBoost&lt;b&gt;算法&lt;/b&gt;">1.2 AdaBoost<b>算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="2 KSMOTE-AdaBoost算法 ">2 KSMOTE-AdaBoost算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="2.1 &lt;i&gt;K&lt;/i&gt;NN&lt;b&gt;噪声样本滤除算法&lt;/b&gt;">2.1 <i>K</i>NN<b>噪声样本滤除算法</b></a></li>
                                                <li><a href="#118" data-title="2.2 &lt;b&gt;基于&lt;/b&gt;&lt;i&gt;k&lt;/i&gt;-means&lt;b&gt;改进的&lt;/b&gt;SMOTE&lt;b&gt;算法&lt;/b&gt;">2.2 <b>基于</b><i>k</i>-means<b>改进的</b>SMOTE<b>算法</b></a></li>
                                                <li><a href="#162" data-title="2.3 &lt;b&gt;基于改进过采样的集成分类算法&lt;/b&gt;">2.3 <b>基于改进过采样的集成分类算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#199" data-title="3.1 &lt;b&gt;数据集&lt;/b&gt;">3.1 <b>数据集</b></a></li>
                                                <li><a href="#202" data-title="3.2 &lt;b&gt;性能评价指标&lt;/b&gt;">3.2 <b>性能评价指标</b></a></li>
                                                <li><a href="#214" data-title="3.3 &lt;b&gt;参数寻优&lt;/b&gt;">3.3 <b>参数寻优</b></a></li>
                                                <li><a href="#219" data-title="3.4 &lt;b&gt;本文过采样方法与其他过采样方法的比较&lt;/b&gt;">3.4 <b>本文过采样方法与其他过采样方法的比较</b></a></li>
                                                <li><a href="#226" data-title="3.5 &lt;b&gt;本文分类模型与其他算法的比较&lt;/b&gt;">3.5 <b>本文分类模型与其他算法的比较</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#230" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="图1 基于过采样的不平衡数据集成分类模型">图1 基于过采样的不平衡数据集成分类模型</a></li>
                                                <li><a href="#201" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;数据集的基本信息&lt;/b&gt;"><b>表</b>1 <b>数据集的基本信息</b></a></li>
                                                <li><a href="#204" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;混淆矩阵&lt;/b&gt;"><b>表</b>2 <b>混淆矩阵</b></a></li>
                                                <li><a href="#216" data-title="图2 不同&lt;i&gt;K&lt;/i&gt;值下噪声样本所占比例">图2 不同<i>K</i>值下噪声样本所占比例</a></li>
                                                <li><a href="#218" data-title="图3 不同&lt;i&gt;K&lt;/i&gt;值下的评估指标">图3 不同<i>K</i>值下的评估指标</a></li>
                                                <li><a href="#221" data-title="图4 不同采样算法合成样本分布效果">图4 不同采样算法合成样本分布效果</a></li>
                                                <li><a href="#225" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;基于不同过采样算法得到的&lt;/b&gt;&lt;i&gt;G&lt;/i&gt;-mean&lt;b&gt;和&lt;/b&gt;AUC"><b>表</b>3 <b>基于不同过采样算法得到的</b><i>G</i>-mean<b>和</b>AUC</a></li>
                                                <li><a href="#228" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;基于不同算法得到的&lt;/b&gt;&lt;i&gt;G&lt;/i&gt;-mean&lt;b&gt;和&lt;/b&gt;AUC"><b>表</b>4 <b>基于不同算法得到的</b><i>G</i>-mean<b>和</b>AUC</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="252">


                                    <a id="bibliography_1" title=" 莫赞,盖彦蓉,樊冠龙.基于GAN-AdaBoost-DT不平衡分类算法的信用卡欺诈分类[J].计算机应用,2019,39(2):618-622.(MO Z,GAI Y R,FAN G L.Credit card fraud classification based on GAN-AdaBoost-DT imbalanced classification algorithm[J].Journal of Computer Applications,2019,39(2):618-622.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902053&amp;v=MTMwNjRSN3FmWnVac0Z5am1Wci9NTHo3QmQ3RzRIOWpNclk5QVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         莫赞,盖彦蓉,樊冠龙.基于GAN-AdaBoost-DT不平衡分类算法的信用卡欺诈分类[J].计算机应用,2019,39(2):618-622.(MO Z,GAI Y R,FAN G L.Credit card fraud classification based on GAN-AdaBoost-DT imbalanced classification algorithm[J].Journal of Computer Applications,2019,39(2):618-622.)
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_2" title=" MAZUROWSKI M A,HABAS P A,ZURADA J M,et al.Training neural network classifiers for medical decision making:the effects of imbalanced datasets on classification performance [J].Neural Networks,2008,21(2/3):427-436." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300069470&amp;v=MDc5MDBySTlGWk8wR0NIczVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRjBSYWhZPU5pZk9mYks3SHRETw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         MAZUROWSKI M A,HABAS P A,ZURADA J M,et al.Training neural network classifiers for medical decision making:the effects of imbalanced datasets on classification performance [J].Neural Networks,2008,21(2/3):427-436.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_3" title=" YANG Z,TANG W,SHINTEMIROV A,et al.Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2009,39(6):597-610." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers">
                                        <b>[3]</b>
                                         YANG Z,TANG W,SHINTEMIROV A,et al.Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2009,39(6):597-610.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_4" title=" PUN J,LAWRYSHYN Y.Improving credit card fraud detection using a meta-classification strategy [J].International Journal of Computer Applications,2012,56(10):41-46." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving credit card fraud detection using a meta-classification strategy">
                                        <b>[4]</b>
                                         PUN J,LAWRYSHYN Y.Improving credit card fraud detection using a meta-classification strategy [J].International Journal of Computer Applications,2012,56(10):41-46.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_5" title=" 康松林,樊晓平,刘乐,等.ENN-ADASYN-SVM算法检测P2P僵尸网络的研究[J].小型微型计算机系统,2016,37(2):216-220.(KANG S L,FAN X P,LIU L,et al.Research on P2P botnets detection based on the ENN-ADASYN-SVM classification algorithm[J].Journal of Chinese Computer Systems,2016,37(2):216-220.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201602005&amp;v=MTkxODdmWnVac0Z5am1Wci9NUFRYY2RyRzRIOWZNclk5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         康松林,樊晓平,刘乐,等.ENN-ADASYN-SVM算法检测P2P僵尸网络的研究[J].小型微型计算机系统,2016,37(2):216-220.(KANG S L,FAN X P,LIU L,et al.Research on P2P botnets detection based on the ENN-ADASYN-SVM classification algorithm[J].Journal of Chinese Computer Systems,2016,37(2):216-220.)
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_6" title=" BERMEJO P,GAMEZ J A,PUERTA J M.Improving the performance of Naive Bayes multinomial in e-mail foldering by introducing distribution-based balance of datasets [J].Expert Systems with Applications,2011,38(3):2072-2080." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501640150&amp;v=MDgzNjBhaFk9TmlmT2ZiSzdIdEROcW85RVl1OFBEWGs1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSUYwUg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         BERMEJO P,GAMEZ J A,PUERTA J M.Improving the performance of Naive Bayes multinomial in e-mail foldering by introducing distribution-based balance of datasets [J].Expert Systems with Applications,2011,38(3):2072-2080.
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_7" title=" CHAWLA N V,BOWYER K W,HALL L O,et al.SMOTE:synthetic minority over-sampling technique [J].Journal of Artificial Intelligence Research,2002,16(1):321-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">
                                        <b>[7]</b>
                                         CHAWLA N V,BOWYER K W,HALL L O,et al.SMOTE:synthetic minority over-sampling technique [J].Journal of Artificial Intelligence Research,2002,16(1):321-357.
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_8" title=" HE H,BAI Y,GARCIA E A,et al.ADASYN:adaptive synthetic sampling approach for imbalanced learning [C]// Proceedings of the 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence).Piscataway,NJ:IEEE,2008:1322-1328." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ADASYN:adaptive synthetic sampling approach for imbalanced learning">
                                        <b>[8]</b>
                                         HE H,BAI Y,GARCIA E A,et al.ADASYN:adaptive synthetic sampling approach for imbalanced learning [C]// Proceedings of the 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence).Piscataway,NJ:IEEE,2008:1322-1328.
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_9" title=" HAN H,WANG W Y,MAO B H.Borderline-SMOTE:a new over-sampling method in imbalanced data sets learning [C]// Proceedings of the 2005 International Conference on Intelligent Computing,LNCS 3644.Berlin:Springer,2005:878-887." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning">
                                        <b>[9]</b>
                                         HAN H,WANG W Y,MAO B H.Borderline-SMOTE:a new over-sampling method in imbalanced data sets learning [C]// Proceedings of the 2005 International Conference on Intelligent Computing,LNCS 3644.Berlin:Springer,2005:878-887.
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_10" title=" CASTRO C L,BRAGA A P.Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data[J].IEEE Transactions on Neural Networks and Learning Systems,2013,24(6):888-899." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data">
                                        <b>[10]</b>
                                         CASTRO C L,BRAGA A P.Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data[J].IEEE Transactions on Neural Networks and Learning Systems,2013,24(6):888-899.
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_11" title=" 李勇,刘占东,张海军.不平衡数据的集成分类算法综述[J].计算机应用研究,2014,31(5):1287-1291.(LI Y,LIU Z D,ZHANG H J.Review on ensemble algorithms for imbalanced data classification [J].Application Research of Computers,2014,31(5):1287-1291.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201405003&amp;v=MjI0MTMzenFxQnRHRnJDVVI3cWZadVpzRnlqbVZyL01MejdTWkxHNEg5WE1xbzlGWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         李勇,刘占东,张海军.不平衡数据的集成分类算法综述[J].计算机应用研究,2014,31(5):1287-1291.(LI Y,LIU Z D,ZHANG H J.Review on ensemble algorithms for imbalanced data classification [J].Application Research of Computers,2014,31(5):1287-1291.)
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_12" title=" GALAR M,FERNANDEZ A,BARRENECHEA E,et al.A review on ensembles for the class imbalance problem:bagging-,boosting-,and hybrid-based approaches [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2012,42(4):463-484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches">
                                        <b>[12]</b>
                                         GALAR M,FERNANDEZ A,BARRENECHEA E,et al.A review on ensembles for the class imbalance problem:bagging-,boosting-,and hybrid-based approaches [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2012,42(4):463-484.
                                    </a>
                                </li>
                                <li id="276">


                                    <a id="bibliography_13" title=" SEIFFERT C,KHOSHGOFTAAR T M,van HULSE J,et al.RUSBoost:a hybrid approach to alleviating class imbalance [J].IEEE Transactions on Systems,Man,and Cybernetics—Part A:Systems and Humans,2010,40(1):185-197." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RUSBoost: A Hybrid Approach to Alleviating Class Imbalance">
                                        <b>[13]</b>
                                         SEIFFERT C,KHOSHGOFTAAR T M,van HULSE J,et al.RUSBoost:a hybrid approach to alleviating class imbalance [J].IEEE Transactions on Systems,Man,and Cybernetics—Part A:Systems and Humans,2010,40(1):185-197.
                                    </a>
                                </li>
                                <li id="278">


                                    <a id="bibliography_14" title=" CHAWLA N V,LAZAREVIC A,HALL L O,et al.SMOTEBoost:improving prediction of the minority class in boosting [C]// Proceedings of the 2003 European Conference on Principles of Data Mining and Knowledge Discovery,LNCS 2838.Berlin:Springer,2003:107-119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTEBoost: improving prediction of the minority class in boosting">
                                        <b>[14]</b>
                                         CHAWLA N V,LAZAREVIC A,HALL L O,et al.SMOTEBoost:improving prediction of the minority class in boosting [C]// Proceedings of the 2003 European Conference on Principles of Data Mining and Knowledge Discovery,LNCS 2838.Berlin:Springer,2003:107-119.
                                    </a>
                                </li>
                                <li id="280">


                                    <a id="bibliography_15" title=" FREUND Y,SCHAPIRE R E.A decision-theoretic generalization of on-line learning and an application to boosting [J].Journal of Computer and System Sciences,1997,55(1):119-139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601258112&amp;v=MzA5NzQvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlGMFJhaFk9TmlmT2ZiSzdIdEROcVk5RVp1NEhEWDA3b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         FREUND Y,SCHAPIRE R E.A decision-theoretic generalization of on-line learning and an application to boosting [J].Journal of Computer and System Sciences,1997,55(1):119-139.
                                    </a>
                                </li>
                                <li id="282">


                                    <a id="bibliography_16" title=" KANG Q,CHEN X S,LI S S,et al.A noise-filtered under-sampling scheme for imbalanced classification [J].IEEE Transactions on Cybernetics,2017,47(12):4263-4274." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A noise-filtered under-sampling scheme for imbalanced classification">
                                        <b>[16]</b>
                                         KANG Q,CHEN X S,LI S S,et al.A noise-filtered under-sampling scheme for imbalanced classification [J].IEEE Transactions on Cybernetics,2017,47(12):4263-4274.
                                    </a>
                                </li>
                                <li id="284">


                                    <a id="bibliography_17" title=" 周志华.机器学习[M].北京:清华大学出版社,2016:33-35.(ZHOU Z H.Machine Learning[M].Beijing:Tsinghua University Press,2016:33-35.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MTQyNzA0UVhGcXpHYkM0SE5YT3JJMU5ZK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5uVTcvTEpW&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         周志华.机器学习[M].北京:清华大学出版社,2016:33-35.(ZHOU Z H.Machine Learning[M].Beijing:Tsinghua University Press,2016:33-35.)
                                    </a>
                                </li>
                                <li id="286">


                                    <a id="bibliography_18" title=" 王伟,谢耀滨,尹青.针对不平衡数据的决策树改进方法[J].计算机应用,2019,39(3):623-628.(WANG W,XIE Y B,YIN Q.Decision tree improvement method for imbalanced data [J].Journal of Computer Applications,2019,39(3):623-628.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903002&amp;v=MjkxNzBqTXJJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWptVnIvTUx6N0JkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         王伟,谢耀滨,尹青.针对不平衡数据的决策树改进方法[J].计算机应用,2019,39(3):623-628.(WANG W,XIE Y B,YIN Q.Decision tree improvement method for imbalanced data [J].Journal of Computer Applications,2019,39(3):623-628.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-28 11:00</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(09),2591-2596 DOI:10.11772/j.issn.1001-9081.2019030531            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>改进SMOTE的不平衡数据集成分类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%BF%A0%E9%9C%87&amp;code=42438202&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王忠震</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E5%8B%83&amp;code=36577169&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄勃</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%B9%E5%BF%97%E5%86%9B&amp;code=36577168&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">方志军</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E6%B0%B8%E5%BD%AC&amp;code=39161618&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高永彬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%A8%9F&amp;code=25960201&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张娟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0202052&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海工程技术大学电子电气工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B1%9F%E8%A5%BF%E7%9C%81%E7%BB%8F%E6%B5%8E%E7%8A%AF%E7%BD%AA%E4%BE%A6%E6%9F%A5%E4%B8%8E%E9%98%B2%E6%8E%A7%E6%8A%80%E6%9C%AF%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=1693667&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江西省经济犯罪侦查与防控技术协同创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对不平衡数据集的低分类准确性,提出基于改进合成少数类过采样技术(SMOTE)和AdaBoost算法相结合的不平衡数据分类算法(KSMOTE-AdaBoost)。首先,根据<i>K</i>近邻(<i>K</i>NN)的思想,提出噪声样本识别算法,通过样本的<i>K</i>个近邻中所包含的异类样本数目,对样本集中的噪声样本进行精确识别并予以滤除;其次,在过采样过程中基于聚类的思想将样本集划分为不同的子簇,根据子簇的簇心及其所包含的样本数目,在簇内样本与簇心之间进行新样本的合成操作。在样本合成过程中充分考虑类间和类内数据不平衡性,对样本及时修正以保证合成样本质量,平衡样本信息;最后,利用AdaBoost算法的优势,采用决策树作为基分类器,对平衡后的样本集进行训练,迭代多次直到满足终止条件,得到最终分类模型。选择<i>G</i>-mean、AUC作为评价指标,通过在6组KEEL数据集进行对比实验。实验结果表明,所提的过采样算法与经典的过采样算法SMOTE、自适应综合过采样技术(ADASYN)相比,<i>G</i>-means和AUC在4组中有3组最高;所提分类模型与现有的不平衡分类模型SMOTE-Boost,CUS-Boost,RUS-Boost相比,6组数据中:<i>G</i>-means均高于CUS-Boost和RUS-Boost,有3组低于SMOTE-Boost;AUC均高于SMOTE-Boost和RUS-Boost,有1组低于CUS-Boost。验证了所提的KSMOTE-AdaBoost具有更好的分类效果,且模型泛化性能更高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不平衡数据分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%88%E6%88%90%E5%B0%91%E6%95%B0%E7%B1%BB%E8%BF%87%E9%87%87%E6%A0%B7%E6%8A%80%E6%9C%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">合成少数类过采样技术;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E%E8%BF%91%E9%82%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>近邻;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%87%E9%87%87%E6%A0%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">过采样;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AdaBoost%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AdaBoost算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王忠震(1992—),男,江苏徐州人,硕士研究生,主要研究方向:机器学习、数据挖掘;;
                                </span>
                                <span>
                                    *黄勃(1985—),男,湖北武汉人,博士,CCF会员,主要研究方向:人工智能、软件工程、需求工程;电子邮箱huangbosues@sues.edu.cn;
                                </span>
                                <span>
                                    方志军(1971—),男,江西鄱阳人,教授,博士,CCF会员,主要研究方向:模式识别、智能计算、视频分析;;
                                </span>
                                <span>
                                    高永彬(1988—),男,江西南昌人,博士,主要研究方向:人工智能、机器学习、图像处理、模式识别;;
                                </span>
                                <span>
                                    张娟(1975—),女,江西南昌人,副教授,博士,主要研究方向:计算机视觉、人工智能、软件测试。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61603242);</span>
                                <span>江西省经济犯罪侦查与防控技术协同创新中心开放基金资助课题(JXJZXTCX-030);</span>
                    </p>
            </div>
                    <h1><b>Improved SMOTE unbalanced data integration classification algorithm</b></h1>
                    <h2>
                    <span>WANG Zhongzhen</span>
                    <span>HUANG Bo</span>
                    <span>FANG Zhijun</span>
                    <span>GAO Yongbin</span>
                    <span>ZHANG Juan</span>
            </h2>
                    <h2>
                    <span>School of Electric and Electronic Engineering, Shanghai University of Engineering Science</span>
                    <span>Jiangxi Province Economic Crime Investigation and Prevention and Control Technology Collaborative Innovation Center</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the low classification accuracy of unbalanced datasets, an unbalanced data classification algorithm based on improved SMOTE(Synthetic Minority Oversampling TEchnique) and AdaBoost algorithm(KSMOTE-AdaBoost) was proposed. Firstly, a noise sample identification algorithm was proposed according to the idea of <i>K</i>-Nearest Neighbors(<i>K</i>NN). The noise samples in the sample set were accurately identified and filtered out by the number of heterogeneous samples included in the <i>K</i> neighbors of the sample. Secondly, in the process of oversampling, the sample set was divided into different sub-clusters based on the idea of clustering. According to the cluster center of the sub-cluster and the number of samples the sub-cluster contains, the synthesis of new samples was performed between the samples in the cluster and the cluster center. In the process of sample synthesis, the data imbalance between classes as well as in the class was fully considered, and the samples were corrected in time to ensure the quality of the synthesized samples and balance the sample information. Finally, using the advantage of AdaBoost algorithm, the decision tree was used as the base classifier and the balanced sample set was trained and iterated several times until the termination condition was satisfied, and the final classification model was obtained. The comparative experiments were carried out on 6 KEEL datasets with <i>G</i>-mean and AUC selected as evaluation indicators. The experimental results show that compared with the classical oversampling algorithm SMOTE and ADASYN(ADAptive SYNthetic sampling approach), <i>G</i>-means and AUC have the highest of 3 groups in 4 groups. Compared with the existing unbalanced classification models SMOTE-Boost, CUS(Cluster-based Under-Sampling)-Boost and RUS(Random Under-Sampling)-Boost, among the 6 groups of data: the proposed classification model has higher <i>G</i>-means than CUS-Boost and RUS-Boost, and 3 groups are lower than SMOTE-Boost; AUC is higher than SMOTE-Boost and RUS-Boost, and one group is lower than CUS-Boost. It is verified that the proposed KSMOTE-AdaBoost has better classification effect and the model has higher generalization performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unbalanced%20data%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unbalanced data classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Synthetic%20Minority%20Oversampling%20TEchnique(SMOTE)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Synthetic Minority Oversampling TEchnique(SMOTE);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E-Nearest%20Neighbors(%3Ci%3EK%3C%2Fi%3ENN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>-Nearest Neighbors(<i>K</i>NN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=oversampling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">oversampling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AdaBoost%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AdaBoost algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Zhongzhen, born in 1992, M. S. candidate. His research interests include machine learning, data mining. ;
                                </span>
                                <span>
                                    HUANG Bo, born in 1985, Ph. D. His research interests include artificial intelligence, software engineering, requirements engineering. ;
                                </span>
                                <span>
                                    FANG Zhijun, born in 1971, Ph. D. , professor. His research interests include pattern recognition, intelligent computing, video analysis. ;
                                </span>
                                <span>
                                    GAO Yongbin, born in 1988, Ph. D. His research interests include artificial intelligence, machine learning, image processing, pattern recognition. ;
                                </span>
                                <span>
                                    ZHANG Juan, born in 1975, Ph. D. , associate professor. Her research interests include computer vision, artificial intelligence, software testing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-01</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China(61603242);</span>
                                <span>the Open Project of Jiangxi Collaborative Innovation Center of Economic Crime Investigation,Prevention and Control Technology(JXJZXTCX-030);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="53">不平衡数据集是指数据集中某个或某些类样本数量远远高于其他类,反之则样本数量低于其他类,通常把样本数量较多的类称为多数类,样本数量较少的类称为少数类<citation id="288" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在不平衡数据集中,少数类样本所包含的信息有可能更加关键,例如医疗诊断<citation id="289" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>中人类患恶性疾病的事件属于少数类,但是如果将恶性疾病诊断为良性,就会错过最佳的治疗时机,严重影响身体健康。不平衡分类问题是指:由于不平衡数据集本身数据分布的不平衡性,使用传统分类算法的效果较差,模型准确度较低。随着大数据时代的到来,现在这种问题普遍存在于故障检测<citation id="290" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、信用卡欺诈检测<citation id="291" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、网络入侵识别<citation id="292" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>以及电子邮件分类<citation id="293" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等领域,对不平衡数据集进行科学的分类已经成为学术研究的一个热点。</p>
                </div>
                <div class="p1">
                    <p id="54">针对不平衡数据集的分类研究,目前的处理方法主要分为三类:数据层面的方法、算法层面的方法以及数据与算法层面相结合的方法。数据层面的方法,目前方法是使用欠采样和过采样两种方式,即对数据集中多数类样本进行删除或对少数类样本进行增加以达到平衡数据集的目的;代表性的算法有合成少数类过采样技术(Synthetic Minority Oversampling Technique, SMOTE)<citation id="294" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、自适应综合过采样技术(ADAptive SYNthetic sampling approach, ADASYN)<citation id="295" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、Borderliner-SMOTE算法<citation id="296" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。算法层面的方法,现有算法绝大多数是在平衡数据分类算法的基础上,通过引入损失函数或者错误率进行改进;代表性的算法有代价敏感学习<citation id="297" type="reference"><link href="270" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、集成学习<citation id="298" type="reference"><link href="272" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和提升算法<citation id="299" type="reference"><link href="274" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。融合数据采样与分类算法的方法,使其训练得出的分类器具有更强的多元性和鲁棒性:文献<citation id="300" type="reference">[<a class="sup">13</a>]</citation>提出了在自适应增强(Adaptive Boosting, AdaBoost)每次迭代中对多数类样本进行随机欠采样(Random Under-Sampling, RUS)的RUSBoost算法,由于随机采样方法的不确定性,往往一些采样出来的样本不具有代表性,对模型效果的提升不明确;文献<citation id="301" type="reference">[<a class="sup">14</a>]</citation>提出以一种基于SMOTE算法和AdaBoost.M2算法相结合的不平衡数据集分类算法,该算法虽然在一定程度上提高了分类器的召回率和预测的准确度,但并没有考虑到少数类样本中的边缘化问题以及存在噪声样本干扰问题。</p>
                </div>
                <div class="p1">
                    <p id="55">本文提出一种针对不平衡数据二分类问题的KSMOTE-自适应增强(KSMOTE-AdaBoost)算法。首先针对少数类样本中存在的噪声样本干扰问题,引入<i>K</i>-最近邻(<i>K</i>-Nearest Neighbors, <i>K</i>NN)噪声样本滤除算法,对噪声样本进行滤除。其次考虑现有过采样方法的合成样本不具有代表性、忽略同类样本之间的差异性问题,依据机器学习中的聚类思想,对现有的过采样算法进行改进,引入子簇质心、过采样权重等概念,对合成样本进行修正,提高整体合成样本的质量;最后将过采样后的数据集使用以决策树(Decision Tree, DT)作为基分类器的AdaBoost算法进行分类。通过将本文提出采样算法与经典的SMOTE、ADASYN采样算法相对比,本文的分类模型与于聚类的提升欠采样的非平衡数据分类(Cluster-based Under-Sampling with Boosting for imbalanced classification, CUS-Boost)等三种分类模型相对比,实验表明本文采样算法采样后的样本更具有代表性,本文的分类模型具有更好的分类效果,验证了本文方法的有效性与可行性。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">1 预备理论</h3>
                <h4 class="anchor-tag" id="57" name="57">1.1 SMOTE<b>算法</b></h4>
                <div class="p1">
                    <p id="58">Chawla<citation id="302" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在2002年提出了少数类样本合成技术,即SMOTE。该算法的特点是:通过在少数类样本与其<i>K</i>个最近邻样本之间线性内插的方法合成新的样本,其合成公式如下:</p>
                </div>
                <div class="p1">
                    <p id="59"><i>X</i><sub>new</sub>=<i>X</i><sub><i>i</i></sub>+<i>gif</i>*(<i>X</i><sub><i>i</i>, <i>j</i></sub>-<i>X</i><sub><i>i</i></sub>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="60">其中:<i>X</i><sub>new</sub>为新少数类样本,<i>X</i><sub><i>i</i></sub>为第<i>i</i>个少数类样本,<i>X</i><sub><i>i</i>, <i>j</i></sub>为第<i>i</i>个少数类样本的第<i>j</i>个近邻样本;<i>gif</i>∈[0,1]。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">1.2 AdaBoost<b>算法</b></h4>
                <div class="p1">
                    <p id="62">AdaBoost算法是经典的Boosting算法,通过对弱分类器的组合来达到较好的预测效果。基本过程如下所示:首先给每个样本赋予同等的权重,例如有样本<i>m</i>个,每个样本的权重设置为1/<i>m</i>,以此样本分布为基础训练一个弱分类器。根据分类的结果,更新样本权重,对分类错误的样本增加其权重,相反则减少权重。在得到新的样本分布同时得出该弱分类器的权重。根据新的样本分布,进行新一轮的训练,更新样本权重,获得新的弱分类器与其权值,通过<i>T</i>次的迭代循环,将获得<i>T</i>个弱分类器与其权值。最后将<i>T</i>个弱分类器<i>f</i><sub><i>t</i></sub>及其权值进行线性组合,得到最终强分类器。</p>
                </div>
                <div class="p1">
                    <p id="307">算法的训练过程如下:</p>
                </div>
                <div class="area_img" id="308">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201909019_30800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="85" name="85" class="anchor-tag">2 KSMOTE-AdaBoost算法</h3>
                <div class="p1">
                    <p id="86">本文提出的KSMOTE-AdaBoost分类模型分为3个部分:噪声样本滤除阶段、数据平衡阶段和数据训练分类阶段。分类模型如图1所示。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909019_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于过采样的不平衡数据集成分类模型" src="Detail/GetImg?filename=images/JSJY201909019_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于过采样的不平衡数据集成分类模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909019_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Unbalanced data ensemble classification model based on over-sampling</p>

                </div>
                <h4 class="anchor-tag" id="88" name="88">2.1 <i>K</i>NN<b>噪声样本滤除算法</b></h4>
                <div class="p1">
                    <p id="89">在真实数据集中,噪声数据的存在是不可避免的,并且在某种程度上会对分类器性能产生影响。尤其在少数类样本数量相对较少、样本抗干扰能力较弱的情况下,噪声数据对样本分布影响更大。所以本文在对少数类样本采样之前,引入<i>K</i>NN噪声样本滤除算法。该算法基于文献<citation id="303" type="reference">[<a class="sup">16</a>]</citation>中噪声样本识别算法,在类内以及类间样本的分布较为紧密的情况下,难以对噪声样本进行有效的识别与过滤的缺点。本文从提高合成样本质量、提升分类器模型性能出发,对噪声样本的定义如下:若某一少数类样本的<i>K</i>个近邻中超过2/3的样本为多数类样本,则将该样本定义为噪声样本。</p>
                </div>
                <div class="p1">
                    <p id="90"><i>K</i>NN噪声样本滤除算法首先针对输入样本集,进行样本集的类别划分;然后通过<i>K</i>近邻算法获取每个少数类样本的近邻样本集,对各近邻样本集进行分类汇总;最后根据噪声样本判别条件对样本集中的噪声样本识别并滤除,详细的算法步骤如算法1所示。</p>
                </div>
                <div class="area_img" id="309">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201909019_30900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="118" name="118">2.2 <b>基于</b><i>k</i>-means<b>改进的</b>SMOTE<b>算法</b></h4>
                <div class="p1">
                    <p id="119">针对不平衡数据集中样本类别数目的不平衡性,文献<citation id="304" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>]</citation>中提出的过采样算法,在进行样本采样时,更多考虑到样本类别之间的不平衡,即少数类与多数类之间的不平衡,没有充分地考虑同类样本本身分布的不平衡,即类间不平衡,以及合成样本分布“边缘化”问题。所以针对以上的问题,本文提出改进的SMOTE算法。</p>
                </div>
                <div class="p1">
                    <p id="120">在分类任务中,不仅类间样本的不平衡性对模型性能造成影响,类内样本的不平衡性也同样影响。本文针对以上两类不平衡问题,引入子簇的概念。首先采用聚类算法<i>k</i>-均值聚类(<i>k</i>-means clustering, <i>k</i>-means)对样本集进行子簇的划分,根据子簇中样本数目为其分配不同的采样权重记作<i>W</i>(<i>i</i>),则有:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>-</mo><mi>n</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>/</mo><mo stretchy="false">(</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mi>n</mi></mstyle><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">其中:<i>c</i>表示样本集划分的类簇总数,<i>num</i>(<i>i</i>)表示第<i>i</i>个类簇中的样本数量。根据(2)可知,某一类簇中样本数目越多,则<i>W</i>(<i>i</i>)越小,即过采样权重越小,合成样本数目就越小,最终实现同类样本之间的平衡分布。</p>
                </div>
                <div class="p1">
                    <p id="123">在过采样过程中,合成样本的质量越高,则模型的性能就越好;反之若合成样本分布在类别分布的“边缘”,则有可能影响多数类样本的分类精准度,且合成样本不具有代表性。为了防止新样本的“边缘化”,本文引入质心的概念,质心是指少数类划分子簇后每个子簇的簇心<i>C</i><sub><i>i</i>,center</sub>。对SMOTE算法进行改进,原始的方法新样本的合成如(1)所示,改进后的公式如式(3)所示:</p>
                </div>
                <div class="p1">
                    <p id="124"><i>X</i><sub>new</sub>=<i>C</i><sub><i>i</i>,center</sub>+<i>gif</i>*(<i>X</i><sub><i>i</i>, <i>j</i></sub>-<i>C</i><sub><i>i</i>,center</sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="125">其中:<i>C</i><sub><i>i</i>,center</sub>表示第<i>i</i>个子簇的簇心,<i>X</i><sub><i>i</i>, <i>j</i></sub>表示第<i>i</i>个子簇中的第<i>j</i>个样本。整个公式表示为在<i>C</i><sub><i>i</i>,center</sub>与<i>X</i><sub><i>i</i>, <i>j</i></sub>之间进行线性插值得到新的样本<i>X</i><sub>new</sub>。</p>
                </div>
                <div class="p1">
                    <p id="126">改进的SMOTE算法是根据样本集中所包含样本的分布特点,进行新样本的合成,合成过程如下:</p>
                </div>
                <div class="p1">
                    <p id="127">1) 使用聚类算法将样本集划分为特定数目的类簇;</p>
                </div>
                <div class="p1">
                    <p id="128">2) 根据需要合成样本的数目,以及各类簇中所包含样本数量,得出各类簇所占权重以及需要合成的样本数目;</p>
                </div>
                <div class="p1">
                    <p id="129">3) 通过轮盘赌的方式进行样本的选择,在选中样本与所属类簇簇心之间进行线性插值,获得合成样本;</p>
                </div>
                <div class="p1">
                    <p id="130">4) 输出合成样本集。</p>
                </div>
                <div class="p1">
                    <p id="131">详细算法步骤如算法2所示。</p>
                </div>
                <div class="area_img" id="310">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201909019_31000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="162" name="162">2.3 <b>基于改进过采样的集成分类算法</b></h4>
                <div class="p1">
                    <p id="163">数据集经过算法1和算法2处理后,会得到一个相对“干净”且平衡的数据集,最后对处理后的数据集使用AdaBoost算法训练分类模型。三者结合在一起,得出本文提出的KSMOTE-AdaBoost算法。</p>
                </div>
                <div class="p1">
                    <p id="164">KSMOTE-AdaBoost算法训练过程如下:</p>
                </div>
                <div class="p1">
                    <p id="165">1)通过算法1对样本集中噪声样本识别、滤除;</p>
                </div>
                <div class="p1">
                    <p id="166">2)使用算法2对去噪后的样本集进行新样本的合成;</p>
                </div>
                <div class="p1">
                    <p id="167">3)将合成的样本集与去噪后的样本集进行组合,获得平衡样本集;</p>
                </div>
                <div class="p1">
                    <p id="168">4)对平衡样本集,通过AdaBoost算法进行模型训练;</p>
                </div>
                <div class="p1">
                    <p id="169">5)获得KSMOTE-AdaBoost分类模型。</p>
                </div>
                <div class="p1">
                    <p id="170">详细算法步骤如算法3所示。</p>
                </div>
                <div class="area_img" id="311">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201909019_31100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="197" name="197" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="198">为验证本文所提出方法的具有较高的适用性,实验采用6组KEEL数据集,实验数据选择10次十折交叉验证后的平均值,作为对本文分类算法以及对比算法性能的评估标准。实验思路:首先选择类别不平衡数据集,对本文提出改进的过采样算法与以往算法进行比较,对比其实验结果,证明改进的过采样算法的有效性;然后将本文提出的分类模型与其他分类模型进行比较,验证本文的模型在处理不平衡数据上能够有更好的分类效果,更具有优势。</p>
                </div>
                <h4 class="anchor-tag" id="199" name="199">3.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="200">实验采用来自KEEL公开数据库中不同领域的6组数据集。这些数据集被国内大量的研究者引用。实验前要先对数据集进行预处理,同时把含有多类别的数据集划分为二分类别,预处理后的数据集特征如表1。</p>
                </div>
                <div class="area_img" id="201">
                    <p class="img_tit"><b>表</b>1 <b>数据集的基本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Basic information of datasets</p>
                    <p class="img_note"></p>
                    <table id="201" border="1"><tr><td><br />数据集</td><td>样本数</td><td>分布情况</td><td>不平衡率/%</td><td>特征数</td></tr><tr><td>Ecoli2</td><td>336</td><td>284,52</td><td>5.46</td><td>7</td></tr><tr><td><br />Glass1</td><td>214</td><td>138,76</td><td>1.82</td><td>9</td></tr><tr><td><br />Yeast3</td><td>1 484</td><td>1 321,163</td><td>8.10</td><td>8</td></tr><tr><td><br />Pima</td><td>768</td><td>500,268</td><td>1.87</td><td>8</td></tr><tr><td><br />Yeast6</td><td>1 484</td><td>1 449,35</td><td>41.40</td><td>8</td></tr><tr><td><br />Glass6</td><td>214</td><td>185,29</td><td>6.38</td><td>9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="202" name="202">3.2 <b>性能评价指标</b></h4>
                <div class="p1">
                    <p id="203">针对不平衡数据集的特征,不能通过分类准确率的方式来评价一个分类模型的优劣,所以本文采用<i>G</i>-mean和AUC作为分类模型的评估指标(本文中定义少数类为正类,多数类为负类)。利用混淆矩阵表示不平衡数据的分类结果,见表2。</p>
                </div>
                <div class="area_img" id="204">
                    <p class="img_tit"><b>表</b>2 <b>混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Confusion matrix</p>
                    <p class="img_note"></p>
                    <table id="204" border="1"><tr><td><br />分类</td><td>预测正类</td><td>预测负类</td></tr><tr><td><br />实际正类</td><td>TP</td><td>FN</td></tr><tr><td><br />实际负类</td><td>FP</td><td>TN</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="205">根据表2可求出如下评价指标:</p>
                </div>
                <div class="p1">
                    <p id="206">少数类召回率(查全率):</p>
                </div>
                <div class="p1">
                    <p id="207"><i>R</i><sub>P</sub>=<i>TP</i>/(<i>TP</i>+<i>FN</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="208">多数类召回率(查全率):</p>
                </div>
                <div class="p1">
                    <p id="209"><i>R</i><sub>N</sub>=<i>TN</i>/(<i>TN</i>+<i>FP</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="210" class="code-formula">
                        <mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>-</mo><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>n</mtext><mo>=</mo><msqrt><mrow><mi>R</mi><msub><mrow></mrow><mtext>Ρ</mtext></msub><mo>*</mo><mi>R</mi><msub><mrow></mrow><mtext>Ν</mtext></msub></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="211">AUC:在不平衡数据集分类器的评价标准中,“受试者工作特征”(Receiver Operating Characteristic, ROC)曲线是评价学习器泛化性能的有利工具。ROC曲线以<mathml id="212"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>(假阳率)为横轴,以<mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>(真阳率)为纵轴,给出的是当阈值变化时假阳率与真阳率的变化情况,阈值取自分类器的概率输出。最佳的分类器应该尽可能地处于左上角,这就意味着分类器在假阳率很低的同时获得了很高的真阳率。在进行分类器的比较时,若一个分类器的ROC 曲线被另一个分类器的曲线完全“包住”,则可断言后者的性能优于前者;若两个分类器的ROC曲线发生交叉,则难以一般性地断言两者孰优孰劣,所以引入ROC曲线下的面积进行对比,即AUC(Area Under Curve)<citation id="306" type="reference"><link href="284" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="214" name="214">3.3 <b>参数寻优</b></h4>
                <div class="p1">
                    <p id="215">对于噪声处理阶段中<i>K</i>NN算法<i>K</i>的选取在本文中至关重要,因为<i>K</i>值的选取是确定某一样本是否为噪声的关键。若<i>K</i>值较小,则其样本中噪声样本难以过滤,分类器效果得不到提升;选取较大,会造成原有样本中信息数据的丢失,分类模型泛化性较低。对于<i>K</i>值的设定,本文通过将<i>K</i>值限定在3到9之间来进行参数寻优,并从两个方面考虑,一从噪声样本数量,对不用<i>K</i>值下每次过滤的噪声样本数量进行统计,取值为10次十折交叉后的平均值;二从评价指标<i>G</i>-mean值和AUC值,取值为同一<i>K</i>值下不同数据集10次十折交叉后的平均值。从图2与图3中可以看出,当<i>K</i>值取4时,其噪声样本的数量相对较小且平均<i>G</i>-mean、AUC取值最大。</p>
                </div>
                <div class="area_img" id="216">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909019_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同K值下噪声样本所占比例" src="Detail/GetImg?filename=images/JSJY201909019_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同<i>K</i>值下噪声样本所占比例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909019_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Proportion of noise samples at different <i>K</i> values</p>

                </div>
                <div class="p1">
                    <p id="217">对于聚类算法中<i>K</i>值的选取,本文自适应地调整各数据集<i>K</i>的取值,保证数据集聚类效果。方法如下:首先通过计算类中各点与类中心的距离平方和来度量类内的紧密度,再通过计算各类中心点与数据集中心点距离平方和来度量数据集的分离度,求二者比值,比值越大类与类之间越分散,即聚类结果更优。在实验中统一使用C4.5决策树算法作为所有实验的基本分类算法。根据表1中的数据可知,本文所选用数据集的不平衡率是存在差异的,所以其合成新样本的数目因不平衡率而不同。</p>
                </div>
                <div class="area_img" id="218">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909019_218.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同K值下的评估指标" src="Detail/GetImg?filename=images/JSJY201909019_218.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同<i>K</i>值下的评估指标  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909019_218.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Evaluation indicators under different <i>K</i> values</p>

                </div>
                <h4 class="anchor-tag" id="219" name="219">3.4 <b>本文过采样方法与其他过采样方法的比较</b></h4>
                <div class="p1">
                    <p id="220">为验证本文所提出的样本合成算法的优势与降低数据集不平衡率的有效性,首先采用人工数据集进行验证,将本文样本合成方法与SMOTE算法进行对比,比较两者合成样本的分布情况。本文采用Python3.6中的Sklearn包随机生成两组高斯样本,样本数分别为35和50,合成样本数34。图4为不同算法合成样本分布对比效果图,所用数据为同一高斯分布数据集。</p>
                </div>
                <div class="area_img" id="221">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201909019_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同采样算法合成样本分布效果" src="Detail/GetImg?filename=images/JSJY201909019_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同采样算法合成样本分布效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201909019_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Synthetic sample distribution effect diagrams of different sampling algorithms</p>

                </div>
                <div class="p1">
                    <p id="222">图4(a)所示为原始少数类样本集分布情况,从图中可知样本集的分布主要聚集在两个区域,且每个区域中所包含样本数目不等。图4(b)所示为通过SMOTE采样后,所有样本的分布情况。与图4(a)相比,可以看出新合成样本中有较多样本分布在原始样本分布的“边缘”区域,且采样后的样本分布没有改变原样本集中的类内不平衡性。针对图4(b)中所呈现的不足,本文对SMOTE采样算法进行改进。在对样本集进行过采样之前,针对类内样本分布的不平衡性,引入子簇的概念,将样本集划分为不同的子簇,并通过式(2)赋予其不同的采样权重。针对合成样本的“边缘性”问题,引入簇心的概念。将簇心与任一簇内样本进行线性组合,通过式(3)合成新样本,实验效果图如图4(c)所示。</p>
                </div>
                <div class="p1">
                    <p id="223">其次为验证本文所提出的过采样方法的泛化性,使用本文的方法与SMOTE、ADASYN在不同数据集上对<i>G</i>-mean和AUC评价指标进行对比。实验中均采用scikit-learn自带的C4.5作为分类器。实验结果如表3所示(加粗部分为最好实验结果)。</p>
                </div>
                <div class="p1">
                    <p id="224">由表3实验数据可以看出本文提出的过采样算法确实提高了预测效果。在数据集Glass1和Yeast6上<i>G</i>-mean和AUC表现均高于其他方法,<i>G</i>-mean值最高提高了1.03%,AUC值提高了4.6%;对比经典的过采样算法SMOTE,<i>G</i>-mean值平均提高了约0.899%,AUC值平均提高了约4.44%;与ADASYN相比,本文提出过采样算法的评价指标均高于其指标;在Yeast3中本文算法的AUC均高于其他算法,而<i>G</i>-mean值略低的原因为<i>R</i><sub>N</sub>降低程度高于<i>R</i><sub>P</sub>增大程度。在Pima中本文算法的<i>G</i>-mean高于另外两种过采样算法,AUC值相对较低,分析其原因为Pima原始数据集中数据分布比较集中,对噪声样本的划分比较敏感,所以导致AUC的取值略低于其他两种方法。</p>
                </div>
                <div class="area_img" id="225">
                    <p class="img_tit"><b>表</b>3 <b>基于不同过采样算法得到的</b><i>G</i>-mean<b>和</b>AUC <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 <i>G</i>-mean and AUC based on different oversampling algorithms</p>
                    <p class="img_note"></p>
                    <table id="225" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="3"><br /><i>G</i>-mean</td><td rowspan="2"></td><td colspan="3"><br />AUC</td></tr><tr><td><br />SMOTE</td><td>ADASYN</td><td>本文方法</td><td><br />SMOTE</td><td>ADASYN</td><td>本文方法</td></tr><tr><td>Glass1</td><td>0.781</td><td>0.785</td><td>0.787</td><td></td><td>0.782</td><td>0.799</td><td>0.818</td></tr><tr><td><br />Yeast3</td><td>0.948</td><td>0.972</td><td>0.960</td><td></td><td>0.928</td><td>0.933</td><td>0.952</td></tr><tr><td><br />Pima</td><td>0.678</td><td>0.690</td><td>0.698</td><td></td><td>0.683</td><td>0.692</td><td>0.675</td></tr><tr><td><br />Yeast6</td><td>0.971</td><td>0.979</td><td>0.981</td><td></td><td>0.890</td><td>0.912</td><td>0.928</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="226" name="226">3.5 <b>本文分类模型与其他算法的比较</b></h4>
                <div class="p1">
                    <p id="227">3.4节验证了本文采样算法的有效性,现进一步验证本文提出的基于改进的过采样方法与集成学习结合对分类模型的提升。本文算法与SMOTE-Boost、CUS-Boost和RUS-Boost在6个不同数据集上的<i>G</i>-mean、AUC比较结果,如表4所示(加粗部分为最好实验结果)。</p>
                </div>
                <div class="area_img" id="228">
                    <p class="img_tit"><b>表</b>4 <b>基于不同算法得到的</b><i>G</i>-mean<b>和</b>AUC <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 <i>G</i>-mean and AUC of different methods</p>
                    <p class="img_note"></p>
                    <table id="228" border="1"><tr><td rowspan="2"><br />数据<br />集</td><td colspan="5"><br /><i>G</i>-mean</td><td rowspan="2"></td><td colspan="4"><br />AUC</td></tr><tr><td><br />SMOTE-<br />Boost</td><td colspan="2">CUS-<br />Boost</td><td>RUS-<br />Boost</td><td>本文<br />算法</td><td><br />SMOTE-<br />Boost</td><td>CUS-<br />Boost</td><td>RUS-<br />Boost</td><td>本文<br />算法</td></tr><tr><td>Ecoli2</td><td>0.876</td><td>0.880</td><td colspan="2">0.573</td><td>0.882</td><td></td><td>0.931</td><td>0.921</td><td>0.840</td><td>0.941</td></tr><tr><td><br />Glass1</td><td>0.623</td><td>0.778</td><td colspan="2">0.253</td><td>0.790</td><td></td><td>0.779</td><td>0.857</td><td>0.624</td><td>0.889</td></tr><tr><td><br />Yeast3</td><td>0.902</td><td>0.874</td><td colspan="2">0.685</td><td>0.859</td><td></td><td>0.958</td><td>0.963</td><td>0.927</td><td>0.959</td></tr><tr><td><br />Pima</td><td>0.351</td><td>0.611</td><td colspan="2">0.271</td><td>0.707</td><td></td><td>0.655</td><td>0.672</td><td>0.572</td><td>0.759</td></tr><tr><td><br />Yeast6</td><td>0.761</td><td>0.747</td><td colspan="2">0.615</td><td>0.704</td><td></td><td>0.892</td><td>0.848</td><td>0.86</td><td>0.932</td></tr><tr><td><br />Glass6</td><td>0.917</td><td>0.889</td><td colspan="2">0.754</td><td>0.890</td><td></td><td>0.930</td><td>0.895</td><td>0.928</td><td>0.954</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="229">从表4的实验结果可以看出,本文提出的分类模型在所选用的数据集上其<i>G</i>-mean值、AUC值上均得到了提升,在数据集Ecoli2、Glass1以及Pima中,其分类的效果均优于对比模型,<i>G</i>-mean值的最高值达到了88.2%,AUC的最高值达到了94.1%。在数据集Yeast3中本文算法的低于<i>G</i>-mean值、AUC值略低一些,原因为其数据集本身类别数据的分布区域较为重叠,多数类样本集中包含“干扰样本”。在数据集Yeast6中本文算法的<i>G</i>-mean值略低,但其AUC值最高提高了9.9%。对于数据集Glass6即使在<i>G</i>-mean值上低于SMOTE-Boost算法,但其AUC值增加了2.6%。</p>
                </div>
                <h3 id="230" name="230" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="231">针对不平衡数据集分类问题,现有的过采样算法更多地考虑类间数据的不平衡,进而忽略了类内样本的不平衡性,存在样本分布“边缘化”问题,导致合成样本的质量较低,实际情况下对样本的分类准确度较低。针对以上问题,本文在SMOTE算法的基础上进行改进。为了克服SMOTE算法的不足,本文在进行过采样之前,提出噪声样本过滤算法,对少数类样本集先进行噪声样本的滤除,提高合成样本的质量。其次针对合成样本存在的不平衡性问题,引入聚类思想,有效降低了数据集中类内的不平衡性,同时利用滤除噪声样本数、<i>G</i>-mean以及AUC进行模型参数的寻优。最后与AdaBoost算法相结合,在KEEL数据集上与其他方法进行对比,实验表明该分类模型可以明显提高少数类样本的分类准确度,分类性能更优。</p>
                </div>
                <div class="p1">
                    <p id="232">本文将聚类思想引入到不平衡分类问题的过采样算法中,并与集成学习相结合提出一种针对不平衡数据二分类问题的KSMOTE-自适应增强(KSMOTE-AdaBoost)算法,并通过一系列实验验证了KSMOTE-AdaBoost算法训练出的分类器可以有效处理不平衡数据的分类问题。然而在实际应用中所接触的数据大部分是多类别的,未来将研究考虑针对多类的基于过采样的分类算法,提高分类的精度以及减少算法所运行的复杂度。通过,也期望本文所提出的不平衡数据集分类算法可以应用到更多的领域。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="252">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902053&amp;v=MDAyMzVtVnIvTUx6N0JkN0c0SDlqTXJZOUFaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 莫赞,盖彦蓉,樊冠龙.基于GAN-AdaBoost-DT不平衡分类算法的信用卡欺诈分类[J].计算机应用,2019,39(2):618-622.(MO Z,GAI Y R,FAN G L.Credit card fraud classification based on GAN-AdaBoost-DT imbalanced classification algorithm[J].Journal of Computer Applications,2019,39(2):618-622.)
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300069470&amp;v=MzA4MzNUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSUYwUmFoWT1OaWZPZmJLN0h0RE9ySTlGWk8wR0NIczVvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> MAZUROWSKI M A,HABAS P A,ZURADA J M,et al.Training neural network classifiers for medical decision making:the effects of imbalanced datasets on classification performance [J].Neural Networks,2008,21(2/3):427-436.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers">

                                <b>[3]</b> YANG Z,TANG W,SHINTEMIROV A,et al.Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2009,39(6):597-610.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving credit card fraud detection using a meta-classification strategy">

                                <b>[4]</b> PUN J,LAWRYSHYN Y.Improving credit card fraud detection using a meta-classification strategy [J].International Journal of Computer Applications,2012,56(10):41-46.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201602005&amp;v=MTk3MTE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWptVnIvTVBUWGNkckc0SDlmTXJZOUZZWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 康松林,樊晓平,刘乐,等.ENN-ADASYN-SVM算法检测P2P僵尸网络的研究[J].小型微型计算机系统,2016,37(2):216-220.(KANG S L,FAN X P,LIU L,et al.Research on P2P botnets detection based on the ENN-ADASYN-SVM classification algorithm[J].Journal of Chinese Computer Systems,2016,37(2):216-220.)
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501640150&amp;v=MjU3NjBVcjNJSUYwUmFoWT1OaWZPZmJLN0h0RE5xbzlFWXU4UERYazVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> BERMEJO P,GAMEZ J A,PUERTA J M.Improving the performance of Naive Bayes multinomial in e-mail foldering by introducing distribution-based balance of datasets [J].Expert Systems with Applications,2011,38(3):2072-2080.
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">

                                <b>[7]</b> CHAWLA N V,BOWYER K W,HALL L O,et al.SMOTE:synthetic minority over-sampling technique [J].Journal of Artificial Intelligence Research,2002,16(1):321-357.
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ADASYN:adaptive synthetic sampling approach for imbalanced learning">

                                <b>[8]</b> HE H,BAI Y,GARCIA E A,et al.ADASYN:adaptive synthetic sampling approach for imbalanced learning [C]// Proceedings of the 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence).Piscataway,NJ:IEEE,2008:1322-1328.
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning">

                                <b>[9]</b> HAN H,WANG W Y,MAO B H.Borderline-SMOTE:a new over-sampling method in imbalanced data sets learning [C]// Proceedings of the 2005 International Conference on Intelligent Computing,LNCS 3644.Berlin:Springer,2005:878-887.
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data">

                                <b>[10]</b> CASTRO C L,BRAGA A P.Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data[J].IEEE Transactions on Neural Networks and Learning Systems,2013,24(6):888-899.
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201405003&amp;v=MTg4OTZWci9NTHo3U1pMRzRIOVhNcW85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 李勇,刘占东,张海军.不平衡数据的集成分类算法综述[J].计算机应用研究,2014,31(5):1287-1291.(LI Y,LIU Z D,ZHANG H J.Review on ensemble algorithms for imbalanced data classification [J].Application Research of Computers,2014,31(5):1287-1291.)
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches">

                                <b>[12]</b> GALAR M,FERNANDEZ A,BARRENECHEA E,et al.A review on ensembles for the class imbalance problem:bagging-,boosting-,and hybrid-based approaches [J].IEEE Transactions on Systems,Man,and Cybernetics,Part C (Applications and Reviews),2012,42(4):463-484.
                            </a>
                        </p>
                        <p id="276">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RUSBoost: A Hybrid Approach to Alleviating Class Imbalance">

                                <b>[13]</b> SEIFFERT C,KHOSHGOFTAAR T M,van HULSE J,et al.RUSBoost:a hybrid approach to alleviating class imbalance [J].IEEE Transactions on Systems,Man,and Cybernetics—Part A:Systems and Humans,2010,40(1):185-197.
                            </a>
                        </p>
                        <p id="278">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTEBoost: improving prediction of the minority class in boosting">

                                <b>[14]</b> CHAWLA N V,LAZAREVIC A,HALL L O,et al.SMOTEBoost:improving prediction of the minority class in boosting [C]// Proceedings of the 2003 European Conference on Principles of Data Mining and Knowledge Discovery,LNCS 2838.Berlin:Springer,2003:107-119.
                            </a>
                        </p>
                        <p id="280">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601258112&amp;v=MDQ2NjdRVE1ud1plWnRGaW5sVXIzSUlGMFJhaFk9TmlmT2ZiSzdIdEROcVk5RVp1NEhEWDA3b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> FREUND Y,SCHAPIRE R E.A decision-theoretic generalization of on-line learning and an application to boosting [J].Journal of Computer and System Sciences,1997,55(1):119-139.
                            </a>
                        </p>
                        <p id="282">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A noise-filtered under-sampling scheme for imbalanced classification">

                                <b>[16]</b> KANG Q,CHEN X S,LI S S,et al.A noise-filtered under-sampling scheme for imbalanced classification [J].IEEE Transactions on Cybernetics,2017,47(12):4263-4274.
                            </a>
                        </p>
                        <p id="284">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MDcyODV5bm5VNy9MSlY0UVhGcXpHYkM0SE5YT3JJMU5ZK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZG&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 周志华.机器学习[M].北京:清华大学出版社,2016:33-35.(ZHOU Z H.Machine Learning[M].Beijing:Tsinghua University Press,2016:33-35.)
                            </a>
                        </p>
                        <p id="286">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903002&amp;v=MTI1NTBqTXJJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeWptVnIvTUx6N0JkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 王伟,谢耀滨,尹青.针对不平衡数据的决策树改进方法[J].计算机应用,2019,39(3):623-628.(WANG W,XIE Y B,YIN Q.Decision tree improvement method for imbalanced data [J].Journal of Computer Applications,2019,39(3):623-628.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201909019" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201909019&amp;v=MzEyODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5am1Wci9OTHo3QmQ3RzRIOWpNcG85RWJZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
