<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637139023778853750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903045%26RESULT%3d1%26SIGN%3d1nxBU3cQ32jRIw7rK%252fwA4tzzYJM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903045&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903045&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903045&amp;v=Mjk1ODRkN0c0SDlqTXJJOUJZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2Qkx6N0I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#50" data-title="1 sLDA主题模型 ">1 sLDA主题模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="1.1 &lt;b&gt;相关概念&lt;/b&gt;">1.1 <b>相关概念</b></a></li>
                                                <li><a href="#63" data-title="1.2 &lt;b&gt;提取主题分布&lt;/b&gt;">1.2 <b>提取主题分布</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="2 glc-sLDA主题模型 ">2 glc-sLDA主题模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="2.1 &lt;b&gt;全局和局部约束&lt;/b&gt;">2.1 <b>全局和局部约束</b></a></li>
                                                <li><a href="#134" data-title="2.2 &lt;b&gt;主题更新步骤&lt;/b&gt;">2.2 <b>主题更新步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#173" data-title="3 实验设计及结果分析 ">3 实验设计及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#174" data-title="3.1 &lt;b&gt;实验数据及配置&lt;/b&gt;">3.1 <b>实验数据及配置</b></a></li>
                                                <li><a href="#177" data-title="3.2 &lt;b&gt;主题更新权值可视化&lt;/b&gt;">3.2 <b>主题更新权值可视化</b></a></li>
                                                <li><a href="#193" data-title="3.3 &lt;b&gt;本文算法与&lt;/b&gt;sLDA&lt;b&gt;对比&lt;/b&gt;">3.3 <b>本文算法与</b>sLDA<b>对比</b></a></li>
                                                <li><a href="#202" data-title="3.4 &lt;b&gt;扣件图像分类实验&lt;/b&gt;">3.4 <b>扣件图像分类实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#214" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="图1 不同类型的扣件图像">图1 不同类型的扣件图像</a></li>
                                                <li><a href="#49" data-title="图2 本文算法流程">图2 本文算法流程</a></li>
                                                <li><a href="#65" data-title="图3 扣件图像及其标注">图3 扣件图像及其标注</a></li>
                                                <li><a href="#187" data-title="图4 生成的扣件标注图像">图4 生成的扣件标注图像</a></li>
                                                <li><a href="#195" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;本文算法和&lt;/b&gt;sLDA&lt;b&gt;主题分布的类间距离&lt;/b&gt;"><b>表</b>1 <b>本文算法和</b>sLDA<b>主题分布的类间距离</b></a></li>
                                                <li><a href="#196" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;本文算法和&lt;/b&gt;sLDA&lt;b&gt;主题分布的类内散度&lt;/b&gt;"><b>表</b>2 <b>本文算法和</b>sLDA<b>主题分布的类内散度</b></a></li>
                                                <li><a href="#199" data-title="图5 正常和疑似类别图像">图5 正常和疑似类别图像</a></li>
                                                <li><a href="#200" data-title="图6 本文算法和sLDA模型的主题分布">图6 本文算法和sLDA模型的主题分布</a></li>
                                                <li><a href="#208" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;本文算法与其他主题模型的扣件分类结果&lt;/b&gt;"><b>表</b>3 <b>本文算法与其他主题模型的扣件分类结果</b></a></li>
                                                <li><a href="#209" data-title="图7 表3中误检和漏检的扣件">图7 表3中误检和漏检的扣件</a></li>
                                                <li><a href="#212" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;本文算法与其他方法的扣件分类结果&lt;/b&gt;"><b>表</b>4 <b>本文算法与其他方法的扣件分类结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 王凌, 张冰, 陈锡爱.基于计算机视觉的钢轨扣件螺母缺失检测系统[J].计算机工程与设计, 2011, 32 (12) :4147-4150. (WANG L, ZHANG B, CHEN X A. Inspection system for loss of rail fastening nut based on computer vision [J]. Computer Engineering and Design, 2011, 32 (12) : 4147-4150.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201112053&amp;v=MTQwMDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJOaWZZWkxHNEg5RE5yWTlBWjRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王凌, 张冰, 陈锡爱.基于计算机视觉的钢轨扣件螺母缺失检测系统[J].计算机工程与设计, 2011, 32 (12) :4147-4150. (WANG L, ZHANG B, CHEN X A. Inspection system for loss of rail fastening nut based on computer vision [J]. Computer Engineering and Design, 2011, 32 (12) : 4147-4150.) 
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" DOU Y, HUANG Y, LI Q, et al. A fast template matching-based algorithm for railway bolts detection [J]. International Journal of Machine Learning and Cybernetics, 2014, 5 (6) : 835-844." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900015056&amp;v=MjQxMjVpbmxVcmpJSVY0WGJocz1OajdCYXJLOEg5RE5wbzlGWk9vS0RIay9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         DOU Y, HUANG Y, LI Q, et al. A fast template matching-based algorithm for railway bolts detection [J]. International Journal of Machine Learning and Cybernetics, 2014, 5 (6) : 835-844.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" LOWE D G. Distinctive image features from scale-invariant keypoints [J]. International Journal of Computer Vision, 2004, 60 (2) : 91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDg0MzV1RmkvbFVyL0xKRmM9Tmo3QmFyTzRIdEhPcDR4RmJlc09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWita&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         LOWE D G. Distinctive image features from scale-invariant keypoints [J]. International Journal of Computer Vision, 2004, 60 (2) : 91-110.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 刘甲甲, 李柏林, 罗建桥, 等.融合PHOG和MSLBP特征的铁路扣件检测算法[J].西南交通大学学报, 2015, 50 (2) :256-263. (LIU J J, LI B L, LUO J Q, et al. Railway fastener detection algorithm integrating PHOG and MSLBP features [J]. Journal of Southwest Jiaotong University, 2015, 50 (2) : 256-263.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNJT201502008&amp;v=MTg1MTE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2QlBTUEJlckc0SDlUTXJZOUZiSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         刘甲甲, 李柏林, 罗建桥, 等.融合PHOG和MSLBP特征的铁路扣件检测算法[J].西南交通大学学报, 2015, 50 (2) :256-263. (LIU J J, LI B L, LUO J Q, et al. Railway fastener detection algorithm integrating PHOG and MSLBP features [J]. Journal of Southwest Jiaotong University, 2015, 50 (2) : 256-263.) 
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     BLEI D M, NG A Y, JORDAN M I. Latent dirichlet allocation [J]. Journal of Machine Learning Research, 2012, 3: 993-1022.</a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 杨赛, 赵春霞.基于隐含狄利克雷分配模型的图像分类算法[J].计算机工程, 2012, 38 (14) :181-183. (YANG S, ZHAO C X. Image classification algorithm based on latent Dirichlet allocation model [J]. Computer Engineering, 2012, 38 (14) : 181-183.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201214055&amp;v=MjkwMzdMdkJMejdCYmJHNEg5UE5xNDlBWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         杨赛, 赵春霞.基于隐含狄利克雷分配模型的图像分类算法[J].计算机工程, 2012, 38 (14) :181-183. (YANG S, ZHAO C X. Image classification algorithm based on latent Dirichlet allocation model [J]. Computer Engineering, 2012, 38 (14) : 181-183.) 
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 李斌, 程丹, 李星.基于Direct LDA的相关向量机遥感图像分类[J].信息技术, 2017 (4) :17-20. (LI B, CHENG D, LI X. Relevant vector machine classification of hyperspectral image based on direct linear discriminant analysis [J]. Information Technology, 2017 (4) : 17-20.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201704005&amp;v=MDM5NTN5bmxVTHZCTFNuUlpMRzRIOWJNcTQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         李斌, 程丹, 李星.基于Direct LDA的相关向量机遥感图像分类[J].信息技术, 2017 (4) :17-20. (LI B, CHENG D, LI X. Relevant vector machine classification of hyperspectral image based on direct linear discriminant analysis [J]. Information Technology, 2017 (4) : 17-20.) 
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 曾康林, 刘汉文.基于LDA和SVM的图像场景分类[J].中国新通信, 2018, 20 (10) :125-127. (ZENG K L, LIU H W. Image scene classification based on LDA and SVM [J]. China New Telecommunications, 2018, 20 (10) : 125-127.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXWL201810104&amp;v=MTc1MzQ1RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5bmxVTHZCTVRYY1lyRzRIOW5OcjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         曾康林, 刘汉文.基于LDA和SVM的图像场景分类[J].中国新通信, 2018, 20 (10) :125-127. (ZENG K L, LIU H W. Image scene classification based on LDA and SVM [J]. China New Telecommunications, 2018, 20 (10) : 125-127.) 
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" FENG H, JIANG Z, XIE F, et al. Automatic fastener classification and defect detection in vision-based railway inspection systems [J]. IEEE Transactions on Instrumentation and Measurement, 2014, 63 (4) : 877-888." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic fastener classification and defect detection in vision-based railway inspection systems">
                                        <b>[9]</b>
                                         FENG H, JIANG Z, XIE F, et al. Automatic fastener classification and defect detection in vision-based railway inspection systems [J]. IEEE Transactions on Instrumentation and Measurement, 2014, 63 (4) : 877-888.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 罗建桥, 刘甲甲, 李柏林, 等.融合纹理结构的潜在狄利克雷分布铁路扣件检测模型[J].计算机应用, 2016, 36 (2) :574-579. (LUO J Q, LIU J J, LI B L, et al. Latent dirichlet allocation model integrated with texture structure for railway fastener detection [J]. Journal of Computer Applications, 2016, 36 (2) : 574-579.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201602056&amp;v=MDk4NTJyWTlBWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJMejdCZDdHNEg5Zk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         罗建桥, 刘甲甲, 李柏林, 等.融合纹理结构的潜在狄利克雷分布铁路扣件检测模型[J].计算机应用, 2016, 36 (2) :574-579. (LUO J Q, LIU J J, LI B L, et al. Latent dirichlet allocation model integrated with texture structure for railway fastener detection [J]. Journal of Computer Applications, 2016, 36 (2) : 574-579.) 
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 罗建桥, 刘甲甲, 李柏林, 等.基于局部特征和语义信息的扣件图像检测[J].计算机应用研究, 2016, 33 (8) :2514-2518. (LUO J Q, LIU J J, LI B L, et al. Detection for railway fasteners based on local features and semantic information [J]. Application Research of Computers, 2016, 33 (8) : 2514-2518.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201608062&amp;v=MTI3MzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2Qkx6N1NaTEc0SDlmTXA0OURab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         罗建桥, 刘甲甲, 李柏林, 等.基于局部特征和语义信息的扣件图像检测[J].计算机应用研究, 2016, 33 (8) :2514-2518. (LUO J Q, LIU J J, LI B L, et al. Detection for railway fasteners based on local features and semantic information [J]. Application Research of Computers, 2016, 33 (8) : 2514-2518.) 
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 赵理君, 唐娉, 霍连志, 等.图像场景分类中视觉词包模型方法综述[J].中国图象图形学报, 2014, 19 (3) :333-343. (ZHAO L J, TANG P, HUO L Z, et al. Review of the bag-of-visual-words models in image scene classification [J]. Journal of Image and Graphics, 2014, 19 (3) : 333-343.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201403001&amp;v=MDc3MTA1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJQeXJmYkxHNEg5WE1ySTlGWllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         赵理君, 唐娉, 霍连志, 等.图像场景分类中视觉词包模型方法综述[J].中国图象图形学报, 2014, 19 (3) :333-343. (ZHAO L J, TANG P, HUO L Z, et al. Review of the bag-of-visual-words models in image scene classification [J]. Journal of Image and Graphics, 2014, 19 (3) : 333-343.) 
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" GUO Q, LI N, YANG Y, et al. Supervised LDA for image annotation [C]// Proceedings of the 2011 IEEE International Conference on Systems, Man, and Cybernetics. Piscataway, NJ: IEEE, 2011: 471-476." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised LDA for Image Annotation">
                                        <b>[13]</b>
                                         GUO Q, LI N, YANG Y, et al. Supervised LDA for image annotation [C]// Proceedings of the 2011 IEEE International Conference on Systems, Man, and Cybernetics. Piscataway, NJ: IEEE, 2011: 471-476.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" ZHOU H. Markov weight fields for face sketch synthesis [C]// CVPR &#39;12: Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2012: 1091-1097." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Markov Weight Fields for face sketch synthesis">
                                        <b>[14]</b>
                                         ZHOU H. Markov weight fields for face sketch synthesis [C]// CVPR &#39;12: Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2012: 1091-1097.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" PENG C, GAO X, WANG N, et al. Graphical representation for heterogeneous face recognition [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (2) : 301-312." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graphical representation for heterogeneous face recognition">
                                        <b>[15]</b>
                                         PENG C, GAO X, WANG N, et al. Graphical representation for heterogeneous face recognition [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (2) : 301-312.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" WANG N, GAO X, LI J. Random sampling for fast face sketch synthesis [J]. Pattern Recognition, 2018, 76: 215-227." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Random sampling for fast face sketch synthesis">
                                        <b>[16]</b>
                                         WANG N, GAO X, LI J. Random sampling for fast face sketch synthesis [J]. Pattern Recognition, 2018, 76: 215-227.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" ZHANG C, ZHU X, LI L, et al. Joint image representation and classification in random semantic spaces [J]. Neurocomputing, 2015, 156 (C) : 79-85." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES41E29D506977E76730BFE227E90D142D&amp;v=MDIyMTlGMjRwRll1SUlDd2sreVJFUTZrMExQWDNncTJjOGVjYVZRYmpyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDloeGJpOHhLRT1OaWZPZmJlNWE5UA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         ZHANG C, ZHU X, LI L, et al. Joint image representation and classification in random semantic spaces [J]. Neurocomputing, 2015, 156 (C) : 79-85.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" OJALA T, PIETIKAINEN M, MAENPAA T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) : 971-987." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiresolution gray-scale and rotation invariant texture classification with local binary patterns">
                                        <b>[18]</b>
                                         OJALA T, PIETIKAINEN M, MAENPAA T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) : 971-987.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" 李永波, 李柏林, 熊鹰.基于HOG特征的铁路扣件状态检测[J].传感器与微系统, 2013, 32 (10) :110-113. (LI Y B, LI B L, XIONG Y. Railway fastener state detection based on HOG feature [J]. Transducer and Microsystem Technologies, 2013, 32 (10) : 110-113.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201310034&amp;v=Mjc1NDZHNEg5TE5yNDlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJKaXJhWkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         李永波, 李柏林, 熊鹰.基于HOG特征的铁路扣件状态检测[J].传感器与微系统, 2013, 32 (10) :110-113. (LI Y B, LI B L, XIONG Y. Railway fastener state detection based on HOG feature [J]. Transducer and Microsystem Technologies, 2013, 32 (10) : 110-113.) 
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" WANG Y, LIN X, WU L, et al. Effective multi-query expansions: collaborative deep networks based feature learning for robust landmark retrieval [J]. IEEE Transactions on Image Processing, 2017, 26 (3) :1393-1404." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Effective multi-query expansions:collaborative deep networks based feature learning for robust landmark retrieval">
                                        <b>[20]</b>
                                         WANG Y, LIN X, WU L, et al. Effective multi-query expansions: collaborative deep networks based feature learning for robust landmark retrieval [J]. IEEE Transactions on Image Processing, 2017, 26 (3) :1393-1404.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" HUANG C, LUO W, XIE Y. Local-class-shared-topic latent Dirichlet allocation based scene classification [J]. Multimedia Tools and Applications, 2017, 76 (14) : 15661-15679.This work is partially supported by the Science and Technology Support Project of Sichuan Province (2018GZ0361) .YANG Fei, born in 1994, M. S. candidate. His research interests include machine vision, image processing, pattern recognition.LUO Jianqiao, born in 1991, Ph. D. candidate. His research interests include image semantic analysis, machine learning.LI Bailin, born in 1962, Ph. D., professor. His research interests include image processing, machine vision." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local-class-shared-topic latent Dirichlet allocation based scene classification">
                                        <b>[21]</b>
                                         HUANG C, LUO W, XIE Y. Local-class-shared-topic latent Dirichlet allocation based scene classification [J]. Multimedia Tools and Applications, 2017, 76 (14) : 15661-15679.This work is partially supported by the Science and Technology Support Project of Sichuan Province (2018GZ0361) .YANG Fei, born in 1994, M. S. candidate. His research interests include machine vision, image processing, pattern recognition.LUO Jianqiao, born in 1991, Ph. D. candidate. His research interests include image semantic analysis, machine learning.LI Bailin, born in 1962, Ph. D., professor. His research interests include image processing, machine vision.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-10-31 16:02</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),888-893 DOI:10.11772/j.issn.1001-9081.2018081767            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合全局和局部约束的sLDA铁路扣件分类模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E9%A3%9E&amp;code=14177164&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E5%BB%BA%E6%A1%A5&amp;code=32844756&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗建桥</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%9F%8F%E6%9E%97&amp;code=09205914&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李柏林</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E6%9C%BA%E6%A2%B0%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0218487&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南交通大学机械工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对监督潜在狄利克雷分布 (sLDA) 模型中测试图像缺乏标注, 导致测试主题分布忽略目标结构的问题, 提出一种结合全局和局部约束的sLDA (glc-sLDA) 扣件图像分类模型。首先, 人工标注训练图像, 并在sLDA模型中学习得到含有结构信息的训练主题分布;然后, 计算测试主题分布, 将测试图像的类别概率作为全局约束, 将测试图像子块与训练图像子块的主题相似程度作为局部约束;最后, 以全局和局部约束的乘积为更新权值, 对训练主题分布加权求和得到新的测试主题分布, 并在Softmax分类器中得到测试图像的分类结果。实验结果表明, glc-sLDA模型能表达扣件结构信息, 与sLDA相比, 各类别的扣件图像区分性增强, 分类误检率减小了55%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%93%81%E8%B7%AF%E6%89%A3%E4%BB%B6%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">铁路扣件分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%91%E7%9D%A3%E6%BD%9C%E5%9C%A8%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">监督潜在狄利克雷分布;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">主题模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%95%E8%AF%8D%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单词标注;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E7%BB%93%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标结构;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9B%B4%E6%96%B0%E4%B8%BB%E9%A2%98%E5%88%86%E5%B8%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">更新主题分布;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨飞 (1994—) , 男, 重庆垫江人, 硕士研究生, 主要研究方向:机器视觉、图像处理、模式识别;;
                                </span>
                                <span>
                                    罗建桥 (1991—) , 男, 湖南湘潭人, 博士研究生, 主要研究方向:图像语义分析、机器学习;;
                                </span>
                                <span>
                                    *李柏林 (1962—) , 男, 广西桂林人, 教授, 博士生导师, 博士, 主要研究方向:图像处理、机器视觉。电子邮箱blli62@263.net;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>四川省科技支撑计划项目 (2018GZ0361);</span>
                    </p>
            </div>
                    <h1><b>Railway fastener classification model based on sLDA combined with global and local constraints</b></h1>
                    <h2>
                    <span>YANG Fei</span>
                    <span>LUO Jianqiao</span>
                    <span>LI Bailin</span>
            </h2>
                    <h2>
                    <span>School of Mechanical Engineering, Southwest Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the ignorance of target structure in test topic distribution due to the lack of annotation in supervised Latent Dirichlet Allocation (sLDA) model, a sLDA fastener image classification model combined with global and local constraints (glc-LDA) was proposed. Firstly, the training images were manually labeled, and the training topic distribution with structural information was learned in sLDA model. Then, the test topic distribution was calculated to obtain the image category probabilities as global constraints, the topic similarities of training sub-blocks and test sub-blocks as local constraints. Finally, updated test topic distribution was obtained by weighted summation of training topic distribution with the product of global and local constraints as updated weights. The image category labels were obtained in Softmax classifier by the updated topics. The experimental results show that the proposed algorithm can express the structural information of fastener and compared with sLDA model, the distinction of each category of fastener images is enhanced, and the false detection rate is reduced by 55%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=railway%20fastener%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">railway fastener classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=supervised%20Latent%20Dirichlet%20Allocation%20(sLDA)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">supervised Latent Dirichlet Allocation (sLDA) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=topic%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">topic model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=annotation%20of%20word&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">annotation of word;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=target%20structure&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">target structure;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=update%20topic%20distribution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">update topic distribution;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YANG Fei, born in 1994, M. S. candidate. His research interests include machine vision, image processing, pattern recognition.;
                                </span>
                                <span>
                                    LUO Jianqiao, born in 1991, Ph. D. candidate. His research interests include image semantic analysis, machine learning.;
                                </span>
                                <span>
                                    LI Bailin, born in 1962, Ph. D. , professor. His research interests include image processing, machine vision.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-24</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Science and Technology Support Project of Sichuan Province (2018GZ0361);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="45">将铁路钢轨固定在轨枕上的部件称为铁路扣件, 通过机器视觉技术检测扣件状态, 及时发现失效扣件具有十分重要工程价值。扣件检测任务属于图像分类问题, 获取扣件图像后, 根据图像特征将扣件分类为正常类别和失效类别。国内外学者曾研究采用主成分分析 (Principal Component Analysis, PCA) <citation id="217" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、方向场 (Directional Field, DF) <citation id="218" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、尺度不变描述子 (Scale Invariant Feature Transform, SIFT) <citation id="219" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、局部二值模式 (Local Binary Pattern, LBP) <citation id="220" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等底层特征分类扣件图像, 出现了大量分类错误。由于扣件姿态不一、道砟遮挡、光照变化、失效形式多样等因素, 底层特征无法稳定描述图像内容, 导致分类结果和图像真实语义不同。不同类型的扣件图像如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="46">潜在狄利克雷分布 (Latent Dirichlet Allocation, LDA) 主题模型<citation id="221" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>在各种复杂场景图像分类任务中表现出良好性能<citation id="229" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>, 并且能够有效分类扣件图像<citation id="230" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>。LDA主题模型通过对图像底层特征进行统计学习, 增强了图像描述能力。首先, 通过<i>K</i>均值聚类底层特征得到码本;然后, 用词包模型<citation id="222" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将特征编码为视觉单词;最后, 利用多项分布和狄利克雷分布从单词词频中提取主题分布。LDA主题分布不仅维度远小于底层特征, 而且鲁棒性更强<citation id="223" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>;但是, LDA模型忽略了图像的空间结构信息, 无法描述扣件结构变化。单词词频仅统计视觉单词出现的次数, 忽略了单词的空间位置, 所以, LDA主题分布无法体现扣件的结构信息和位置状态<citation id="224" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。扣件失效的宏观表现为结构或位置改变, 扣件的结构信息和位置状态对于最终的扣件分类结果尤其重要。文献<citation id="225" type="reference">[<a class="sup">9</a>]</citation>专门定义了一种结构主题模型 (Structure Topic Model, STM) , STM定义了三个扣件模板, 根据单词在模板中的位置推导主题分布, 能够有效区分各种扣件类别。文献<citation id="226" type="reference">[<a class="sup">10</a>]</citation>利用水平方向纹理特征表达扣件结构, 增强了正常和失效扣件在图像表达上的区别。监督潜在狄利克雷分布 (supervised LDA, sLDA) 模型<citation id="227" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>对训练集图像内容进行了人工标注, 引入了目标结构信息。sLDA联合单词和标注共同训练模型参数, 主题分布通过模型参数间接考虑了图像结构信息。异质人脸图像合成方法<citation id="231" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>中, 训练集由真实人脸图像及其手工素描图像组成的图像对构成, 对于一张原始的人脸图像, 可通过训练集的手工素描图自动生成新图像的素描图像。类似地, sLDA模型的训练集图像的主题分布包含结构信息, 采用sLDA模型的训练集主题分布合成测试图像主题分布, 可以准确表达扣件结构。此外, 随机局部约束 (Random Sampling with Locality Constraint Reconstruction, RSLCR) 方法<citation id="228" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>对图像子块进行局部约束, 根据图像子块坐标, 在训练集中选择相应位置的素描图像子块, 结合图像子块上下文关系, 合成新的素描图像, 快速引入图像的空间结构信息, 在考虑人脸空间结构的同时, 又避免了随机场方法 (Random Field, RF) <citation id="232" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>巨大的计算量。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同类型的扣件图像" src="Detail/GetImg?filename=images/JSJY201903045_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 不同类型的扣件图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Different types of fastener images</p>

                </div>
                <div class="p1">
                    <p id="48">综上所述, 结合sLDA模型和RSLCR方法, 并新增一种全局约束, 提出结合全局和局部约束的sLDA (sLDA wth global and local constraints, glc-sLDA) 扣件图像分类模型。在glc-sLDA模型中, 通过对包含结构信息的训练集子块主题分布加权求和, 更新测试图像子块主题分布, 从而准确表达扣件结构。更新主题分布的权值由全局约束和局部约束两部分构成:全局约束用于描述测试图像的类别, 测试图像属于某一类别的概率越高, 该类训练集图像中的子块权值就越大;局部约束用于描述测试图像子块与训练集子块的主题相似程度, 相似程度越高, 对应子块的权值越大。全局约束和局部约束的乘积作为最终主题更新权值, 子块主题分布的加权和就是测试图像子块的主题分布。更新完测试图像的全体子块后, 获得整幅图像新的主题分布。将更新后的主题分布放入Softmax分类器, 得到测试图像的分类结果。本文算法流程如图2所示。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文算法流程" src="Detail/GetImg?filename=images/JSJY201903045_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Flow chart of the proposed algorithm</p>

                </div>
                <h3 id="50" name="50" class="anchor-tag">1 sLDA主题模型</h3>
                <div class="p1">
                    <p id="51">采用sLDA模型对扣件图像及其标注图像进行建模, 估计模型参数, 推导图像主题分布。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">1.1 <b>相关概念</b></h4>
                <h4 class="anchor-tag" id="53" name="53">1) 单词<b><i>w</i></b>:</h4>
                <div class="p1">
                    <p id="54">一个图像子块<i>b</i><sub><i>n</i></sub>的特征<b><i>f</i></b><sub><i>n</i></sub>对应一个视觉单词<i>w</i><sub><i>n</i></sub>, <i>n</i>=1～<i>V</i>, <i>V</i>是单词容量。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">2) 标注<i>t</i>:</h4>
                <div class="p1">
                    <p id="56">图像子块<i>b</i><sub><i>n</i></sub>的标注<i>t</i><sub><i>n</i></sub>取值为0或1, <i>t</i><sub><i>n</i></sub>=0表示背景, <i>t</i><sub><i>n</i></sub>=1表示扣件。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">3) 主题<b><i>Z</i></b>:</h4>
                <div class="p1">
                    <p id="58"><b><i>Z</i></b>= (<i>z</i><sub>1</sub>, <i>z</i><sub>2</sub>, …, <i>z</i><sub><i>n</i></sub>, …, <i>z</i><sub><i>K</i></sub>) , <i>K</i>是主题容量, 单词<i>w</i><sub><i>n</i></sub>和标注<i>t</i><sub><i>n</i></sub>由主题<i>z</i><sub><i>n</i></sub>产生。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">4) 图像主题分布<i>γ</i>:</h4>
                <div class="p1">
                    <p id="60"><i>γ</i>= (<i>γ</i><sub>1</sub>, <i>γ</i><sub>2</sub>, …, <i>γ</i><sub><i>k</i></sub>, …, <i>γ</i><sub><i>K</i></sub>) <sup>T</sup>, <i>γ</i><sub><i>k</i></sub>是主题<i>k</i>出现的概率, 第<i>m</i>张图像的主题分布记为<i>γ</i><sub><i>m</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">5) 子块主题分布ϕ<sub><i>n</i></sub>:</h4>
                <div class="p1">
                    <p id="62">ϕ<sub><i>n</i></sub>= (ϕ<sub><i>n</i>, 1</sub>, ϕ<sub><i>n</i>, 2</sub>, …ϕ<sub><i>n</i>, <i>k</i></sub>, …, ϕ<sub><i>n</i>, <i>K</i></sub>) <sup>T</sup>, ϕ<sub><i>n</i>, <i>k</i></sub>表示<i>w</i><sub><i>n</i></sub>和<i>t</i><sub><i>n</i></sub>由主题<i>k</i>产生的概率, 第<i>m</i>张图像中第<i>n</i>个子块的主题分布记为ϕ<sub><i>m</i>, <i>n</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">1.2 <b>提取主题分布</b></h4>
                <div class="p1">
                    <p id="64">扣件图像及其标注如图3所示, 将图像均分成<i>N</i>个子块, 编码子块特征得到视觉单词<sup></sup><citation id="233" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。<i>ε</i><sub>0</sub>是标注阈值, 若标注图像子块的白色像素占比大于<i>ε</i><sub>0</sub>时, 标注<i>t</i><sub><i>n</i></sub>=1, 表示扣件;否则标注<i>t</i><sub><i>n</i></sub>=0, 表示背景。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 扣件图像及其标注" src="Detail/GetImg?filename=images/JSJY201903045_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 扣件图像及其标注  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Fastener images and labels</p>

                </div>
                <div class="p1">
                    <p id="66">训练集生成单词<i>w</i><sub><i>n</i></sub>和标注<i>t</i><sub><i>n</i></sub>的具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="67">步骤1 生成视觉词典。聚类所有训练集图像子块特征<b><i>f</i></b>, 将聚类中心作为词典<b><i>L</i></b>, <b><i>L</i></b>={<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>V</i></sub>}。</p>
                </div>
                <div class="p1">
                    <p id="68">步骤2 提取视觉单词。对于子块<i>b</i><sub><i>n</i></sub>, 在词典<b><i>L</i></b>中选择与特征<b><i>f</i></b><sub><i>n</i></sub>欧氏距离最小的单词<i>w</i><sub><i>n</i></sub>作为<i>b</i><sub><i>n</i></sub>的单词编码;</p>
                </div>
                <div class="p1">
                    <p id="69">步骤3 提取结构标注。设定阈值<i>ε</i><sub>0</sub>, 若标注子块<i>b</i><sub><i>n</i></sub>的白色像素占比大于<i>ε</i><sub>0</sub>, 标注<i>t</i><sub><i>n</i></sub>=1;否则标注<i>t</i><sub><i>n</i></sub>=0。</p>
                </div>
                <div class="p1">
                    <p id="70">得到单词<i>w</i><sub><i>n</i></sub>和标注<i>t</i><sub><i>n</i></sub>后, 采用sLDA模型从单词和标注中提取图像主题分布。 <i>β</i><sub><i>K</i>×<i>V</i></sub>是主题生成单词的概率矩阵, 例如: <i>β</i><sub><i>k</i>, <i>v</i></sub>=<i>p</i> (<i>w</i><sub><i>n</i></sub>=<i>v</i>|<i>z</i><sub><i>n</i></sub>=<i>k</i>) , 表示主题<i>k</i>下产生单词<i>v</i>的概率;<i>π</i><sub><i>K</i>×2</sub>是主题生成标注的概率矩阵, 例如:<i>π</i><sub><i>k</i>, 1</sub>=<i>p</i> (<i>t</i><sub><i>n</i></sub>=1|<i>z</i><sub><i>n</i></sub>=<i>k</i>) , 表示主题<i>k</i>下产生图像标注<i>t</i>的概率。ϕ<sub><i>n</i>, <i>k</i></sub>是子块<i>b</i><sub><i>n</i></sub>主题为<i>k</i>的变分后验概率, 设整幅图像中主题取<i>k</i>的变分概率为<i>γ</i><sub><i>k</i></sub>。根据最大期望 (Expectation Maximization, EM) 方法最大化一幅图像的似然概率, 得到迭代公式:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>γ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mtext>ϕ</mtext></mstyle><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>ϕ</mtext><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>=</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mi>π</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mi>ψ</mi><mo stretchy="false"> (</mo><mi>γ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>ψ</mi></mstyle><mo stretchy="false"> (</mo><mi>γ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">式 (1) 中, <i>α</i><sub><i>k</i></sub>为先验常数。迭代收敛后, 获得每个子块<i>b</i><sub><i>n</i></sub>的主题分布ϕ<sub><i>n</i></sub>, 以及整幅图像的主题分布<i>γ</i>。由迭代公式 (1) 、 (2) 获得每张图像的主题分布后, 根据式 (3) 、 (4) 计算sLDA模型参数<i>β</i>、<i>π</i>。</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>β</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>v</mi></mrow></msub><mo>∝</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">{</mo></mstyle></mrow></mstyle><mn>1</mn><mo>, </mo><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi>v</mi><mo stretchy="false">}</mo><mo>×</mo><mtext>ϕ</mtext><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>π</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>y</mi></mrow></msub><mo>∝</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">{</mo></mstyle></mrow></mstyle><mn>1</mn><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi>y</mi><mo stretchy="false">}</mo><mo>×</mo><mtext>ϕ</mtext><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">提取训练集主题分布ϕ、<i>γ</i>, 模型参数<i>β</i>、<i>π</i>的过程称为训练, 训练过程如下:</p>
                </div>
                <div class="p1">
                    <p id="75">步骤1 初始化。随机分配ϕ、<i>γ</i>, <i>β</i>、<i>π</i>的值。</p>
                </div>
                <div class="p1">
                    <p id="76">步骤2 按迭代公式 (1) (2) 计算每张训练图像子块的主题分布ϕ<sub><i>m</i>, <i>n</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="77">步骤3 按迭代公式 (3) (4) 计算模型参数<i>β</i><sub><i>k</i>, <i>v</i></sub>、<i>π</i><sub><i>k</i>, <i>y</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="78">步骤4 判断收敛。若模型参数<i>β</i>、<i>π</i>保持不变, 则结束;否则, 返回步骤2。</p>
                </div>
                <div class="p1">
                    <p id="79">训练集中存在人工标注<i>t</i><sub><i>n</i></sub>, 其主题分布考虑了扣件图像的结构信息。测试图像中没有人工标注, 推导其主题分布时需要忽略标注, 因此修改迭代公式 (2) 为式 (5) :</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>=</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mi>ψ</mi><mo stretchy="false"> (</mo><mi>γ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>ψ</mi></mstyle><mo stretchy="false"> (</mo><mi>γ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">提取一张测试图像主题分布ϕ、<i>γ</i>的过程为测试, 测试过程如下:</p>
                </div>
                <div class="p1">
                    <p id="82">步骤1 初始化。随机分配ϕ、<i>γ</i>的值。</p>
                </div>
                <div class="p1">
                    <p id="83">步骤2 代入模型参数<i>β</i>, 按迭代公式 (1) (5) 计算子块主题分布ϕ<sub><i>n</i></sub>, 以及整幅图像的主题分布<i>γ</i>。</p>
                </div>
                <div class="p1">
                    <p id="84">由此可知, 测试图像的主题分布缺乏结构信息。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag">2 glc-sLDA主题模型</h3>
                <div class="p1">
                    <p id="86">sLDA模型中, 训练过程中包含人工标注, 而测试过程中忽略了扣件结构。因此, 用含结构信息的训练集主题分布更新测试图像的主题分布, 将测试图像子块主题分布ϕ<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>更新为ϕ<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>, 将测试图像主题分布<i>γ</i><sup>test</sup>更新为<i>γ</i><sup>test, new</sup>。在更新过程中, 定义全局约束<i>ω</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup></mrow></math></mathml>和局部约束<i>ω</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>。全局约束<i>ω</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup></mrow></math></mathml>用于描述<i>γ</i><sup>test</sup>的类别状态, 局部约束<i>ω</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>用于描述ϕ<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>和ϕ<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow></msubsup></mrow></math></mathml>的相似程度。将<i>ω</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup></mrow></math></mathml>和<i>ω</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>的乘积作为更新权值<i>ω</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>, 用<i>ω</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>对ϕ<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow></msubsup></mrow></math></mathml>加权求和得到新的ϕ<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">2.1 <b>全局和局部约束</b></h4>
                <div class="p1">
                    <p id="102">文献<citation id="234" type="reference">[<a class="sup">17</a>]</citation>构造的随机语义空间能够充分地描述场景信息。本文参考文献<citation id="235" type="reference">[<a class="sup">17</a>]</citation>的方法, 在训练集中随机选取<i>Ms</i>个图像构造语义空间, 所选取的图像主题分布为{<i>γ</i><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, <i>γ</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, …, <i>γ</i><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, …, <i>γ</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Μ</mi><mi>s</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>}, <i>m</i>∈1～<i>Ms</i>, 图像子块主题分布为{ (ϕ<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>1</mn></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, ϕ<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, …, ϕ<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mi>Ν</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>) , …, (ϕ<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Μ</mi><mi>s</mi><mo>, </mo><mn>1</mn></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, ϕ<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Μ</mi><mi>s</mi><mo>, </mo><mn>2</mn></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, …, ϕ<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Μ</mi><mi>s</mi><mo>, </mo><mi>Ν</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>) }, <i>n</i>∈1～<i>N</i>。采用式 (6) 、式 (7) 更新测试图像的主题分布。</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>ϕ</mtext><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mi>s</mi></mrow></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>m</mi></msub><mtext>ϕ</mtext><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>ω</mi><msub><mrow></mrow><mi>m</mi></msub><mo>=</mo><mi>ω</mi><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup><mo>⋅</mo><mi>ω</mi><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">由式 (6) 可知, 随机选取的<i>Ms</i>个位置<i>n</i>处的训练集子块主题分布ϕ<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, 加权求和得到新的主题分布ϕ<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。由式 (7) 可知, 全局约束权值<i>ω</i><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup></mrow></math></mathml>和局部约束权值<i>ω</i><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>的乘积作为更新权值<i>ω</i><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120">2.1.1 局部约束权值<i>ω</i><sup><i>l</i></sup><sub><i>m</i></sub></h4>
                <div class="p1">
                    <p id="121"><i>ω</i><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>用于度量相同坐标位置<i>n</i>处, 测试图像子块的主题ϕ<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>, 与训练集图像子块的主题ϕ<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>的相似程度。若ϕ<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>与ϕ<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>越相似, 则在更新ϕ<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>时, ϕ<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>所占权重越大。其定义如下:</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ω</mi><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>Ζ</mi></mfrac><mo>⋅</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">{</mo><mo>-</mo><mo stretchy="false">{</mo><mo stretchy="false">∥</mo><mtext>ϕ</mtext><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup><mo>-</mo><mtext>ϕ</mtext><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ζ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mi>s</mi></mrow></munderover><mrow><mi>exp</mi></mrow></mstyle><mo stretchy="false">{</mo><mo>-</mo><mo stretchy="false">{</mo><mo stretchy="false">∥</mo><mtext>ϕ</mtext><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup><mo>-</mo><mtext>ϕ</mtext><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">式 (8) 中, <i>Z</i>为归一化因子。通过局部约束, 在训练集中选择与ϕ<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>相似度高的子块来更新ϕ<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。局部约束仅对图像子块进行描述, 忽略了图像整体的类别状态。</p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">2.1.2 全局约束权值<i>ω</i><sup><i>o</i></sup><sub><i>m</i></sub></h4>
                <div class="p1">
                    <p id="250">ω<sup>o</sup><sub>m</sub>用于度量测试图像所属图像类别的概率。若测试图像和训练集第m张图像类别相同的概率越高, 则ф<sup>train</sup><sub>m</sub><sub>, </sub><sub>n</sub>所占权值越大。例如, 若新图像属于正常的概率较高, 则在更新主题时, 训练集正常图像中的子块所占权值就大。其定义如下:</p>
                </div>
                <div class="area_img" id="251">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903045_25100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="252">其中:γ<sup>test</sup>是测试图像主题分布, 由ф<sup>test</sup><sub>n</sub>学习得到;η是Softmax分类器参数, 由训练集图像主题分布γ<sup>train</sup>及其类别标签学习得到;c<sup>test</sup>是测试图像的类别, c<sup>train</sup><sub>m</sub>是第m张训练图像的类别标签。</p>
                </div>
                <div class="p1">
                    <p id="253">结合主题更新式 (6) 、更新权值表达式 (7) 、局部约束表达式 (8) 、全局约束表达式 (10) 并化简, 得到测试图像子块和测试图像的主题分布更新式 (11) 、 (12) :</p>
                </div>
                <div class="area_img" id="254">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903045_25400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="134" name="134">2.2 <b>主题更新步骤</b></h4>
                <div class="p1">
                    <p id="135">首先, 采用sLDA模型得到训练集图像主题分布<i>γ</i><sup>train</sup>、训练集图像子块主题分布ϕ<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>、测试图像主题分布<i>γ</i><sup>test</sup>、测试图像子块主题分布ϕ<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>。然后, 根据主题分布更新式 (11) , 得到新的图像子块主题分布ϕ<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。在更新ϕ<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>时, 对于每个ϕ<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup></mrow></math></mathml>, 先在训练集中随机选取<i>Ms</i>个ϕ<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>, 并计算更新权值<i>ω</i><sub><i>m</i></sub>, 选择权值最大的<i>Ms</i>′个子块及其权值<i>ω</i>′<sub><i>m</i></sub>合成ϕ<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。最后, 根据图像主题分布更新式 (12) , 由ϕ<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext><mo>, </mo><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>得到新的图像主题分布<i>γ</i><sup>test, new</sup>。重复上述过程<i>T</i>次, 取<i>T</i>次结果的均值作为测试图像最终的主题分布。主题更新过程的伪代码如下所示。</p>
                </div>
                <div class="p1">
                    <p id="144">输入:1) 训练集<i>γ</i><sup>train</sup>, ϕ<sup>train</sup>, <i>η</i>, <i>c</i><sup>train</sup>;</p>
                </div>
                <div class="p1">
                    <p id="145">2) 测试集<i>γ</i><sup>test</sup>, ϕ<sup>test</sup>。</p>
                </div>
                <div class="p1">
                    <p id="146">输出:新的测试图像主题分布<i>γ</i><sup>test, new</sup>。</p>
                </div>
                <div class="area_img" id="255">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903045_25500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="173" name="173" class="anchor-tag">3 实验设计及结果分析</h3>
                <h4 class="anchor-tag" id="174" name="174">3.1 <b>实验数据及配置</b></h4>
                <div class="p1">
                    <p id="175">实验数据来自沪昆线云南至大理路段, 采用定位分割算法<citation id="236" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>得到的扣件图像。图像类别包括扣件正常、扣件丢失、扣件断裂、疑似扣件、铁路道砟、其他类别, 共计6类。疑似扣件类别包括铁路道岔区域的扣件, 定位误差较大的扣件等各种形态各异的图像。对于测试图像, 预测类别若为正常, 则扣件有效;若为丢失、断裂、道砟、其他类别, 则扣件故障;若为疑似类别, 则需要人工复检。正常扣件被预测为失效或疑似类别称为误检, 误检率=误检图像数量/正常扣件总数×100%;扣件故障被预测为有效称为漏检, 漏检率=漏检图像数量/失效扣件总数×100%。</p>
                </div>
                <div class="p1">
                    <p id="176">本文采用1 200张扣件图像作为数据集, 其中正常、丢失、断裂、道砟、其他、疑似六类, 每类200张。另外, 再采用5 000张图像作为扩大的测试集。每张扣件图像分辨率为120×180。计算机处理器为Intel Core i5-6400 CPU @2.70 GHz 2.71 GHz, 内存8.00 GB, 在Matlab 2014a环境下进行实验。</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177">3.2 <b>主题更新权值可视化</b></h4>
                <div class="p1">
                    <p id="178">设计一种可视化实验, 表达主题更新权值<i>ω</i><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>的物理意义。由于测试图像缺乏人工标注, 可根据主题更新权值<i>ω</i><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>, 生成测试图像的标注图像。所生成的标注图像与扣件真实形态的相似程度, 作为<i>ω</i><mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow></mrow></msubsup></mrow></math></mathml>表达扣件结构信息的可视化结果。定义测试图像子块生成的标注图像为:</p>
                </div>
                <div class="p1">
                    <p id="182" class="code-formula">
                        <mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mi>s</mi></mrow></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>m</mi></msub><mo>⋅</mo><mi>l</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="183">其中:<i>l</i><mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msubsup></mrow></math></mathml>是训练集子块的标注图像。另外, 为验证全局约束对图像结构信息的影响, 设置一组仅采用局部约束生成标注图像的对比实验。</p>
                </div>
                <div class="p1">
                    <p id="185">实验过程如下:在1 200张图像数据集中随机选取600张作为训练集, 每类100张;余下600张为测试集, 分别生成测试图像的标注图像。实验参数设置:参考文献<citation id="237" type="reference">[<a class="sup">10</a>]</citation>, 图像子块尺寸20×20, 两个子块之间重叠15个像素, 底层特征采用LBP特征, 邻域半径取2;单词容量<i>V</i>=200, 主题数量<i>K</i>=10, 先验常数<i>α</i><sub><i>k</i></sub>=0.1;子块过大, 会忽略掉图像细节信息;子块过小, 无法体现图像的形状结构。重叠像素过少, 获取的图像信息不完整;重叠像素过多, 则会信息冗余, 计算速度慢。单词容量和主题数量过少则会导致图像的表达不充分, 过多则会导致信息的冗余。因此, 根据已有实验验证, 选取了最佳参数值。标注阈值<i>ε</i><sub>0</sub>=0.2, 扣件弹条在子块中所占最小像素比在0.2左右, 若标注阈值小于0.2则会将背景噪声当作扣件纹理;若标注阈值大于0.2, 则会忽略掉部分扣件纹理。参考文献<citation id="238" type="reference">[<a class="sup">16</a>]</citation>, 经过多次实验优化后, 在训练集中随机选取图像的数量<i>Ms</i>=100, 在100个更新权值中选择5个最大的权值, 即<i>Ms</i>′=5, 以提高实验速度。随机选取的次数<i>T</i>=3。</p>
                </div>
                <div class="p1">
                    <p id="186">可视化实验结果如图4所示。</p>
                </div>
                <div class="area_img" id="187">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_187.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 生成的扣件标注图像" src="Detail/GetImg?filename=images/JSJY201903045_187.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 生成的扣件标注图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_187.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Generated fastener images</p>

                </div>
                <div class="p1">
                    <p id="188">对比分析生成的扣件标注图像, 可得出以下两点结论:1) 单独使用局部约束无法准确描述扣件形态。如图4 (b) 所示, 仅使用局部约束生成的标注图像比较模糊, 且无论原图中扣件是否正常, 生成的标注图像均和正常扣件较为相似, 无法准确描绘扣件的真实形态。这是因为单独采用局部约束时, <i>ω</i><mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>只能度量图像子块之间的相似性, 忽略了整幅图像的类别信息, 生成的标注图像可能由训练集中正常类别的图像子块产生。2) 结合局部约束和全局约束的标注图像与图像内容一致。如图4 (c) 所示, 添加全局约束后, 生成的标注图像基本能描绘扣件的真实形态。这是因为全局约束<i>ω</i><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>o</mi></msubsup></mrow></math></mathml>描述了图像类别状态, 局部约束<i>ω</i><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>保证了子块相似性, 生成的标注图像由和测试图像同类别的训练集图像子块产生, 能反映出扣件的真实形态。</p>
                </div>
                <div class="p1">
                    <p id="192">由实验结果分析可知, 结合全局和局部约束的主题更新权值的方法能够刻画扣件结构, 主题更新权值计算的主题分布考虑了扣件结构信息。</p>
                </div>
                <h4 class="anchor-tag" id="193" name="193">3.3 <b>本文算法与</b>sLDA<b>对比</b></h4>
                <div class="p1">
                    <p id="194">本文算法修改了sLDA模型的测试步骤, 为验证本文方法对测试图像的描述性能, 分别采用本文模型和sLDA模型表达扣件图像, 分析不同类别图像之间的类间距离以及同类别图像的类内散度。类间距离是不同类别间均值的差值, 类间距离越大, 模型对不同类别图像的区分能力越强。类内散度是某类中所有数据与该类别均值求差的平方和, 类内散度越小, 模型描述图像的性能越稳定。实验参数设置与3.2节相同, 实验数据采用1 200张图像的数据集, 其中训练图像600张, 600张测试图像, 每类各100张。类间距离实验结果如表1所示, 类内散度实验结果如表2所示。</p>
                </div>
                <div class="area_img" id="195">
                    <p class="img_tit"><b>表</b>1 <b>本文算法和</b>sLDA<b>主题分布的类间距离</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Distance of topic distribution between the proposed algorithm and the sLDA model</p>
                    <p class="img_note"></p>
                    <table id="195" border="1"><tr><td rowspan="2"><br />类别状态</td><td colspan="2"><br />主题距离</td><td rowspan="2">增长率/%</td></tr><tr><td><br />sLDA</td><td>本文算法</td></tr><tr><td><br />正常-疑似</td><td>0.010</td><td>0.002</td><td>-80.00</td></tr><tr><td><br />正常-丢失</td><td>0.183</td><td>0.241</td><td>31.69</td></tr><tr><td><br />正常-断裂</td><td>0.193</td><td>0.240</td><td>24.35</td></tr><tr><td><br />正常-道砟</td><td>0.160</td><td>0.194</td><td>21.25</td></tr><tr><td><br />正常-其他</td><td>0.210</td><td>0.262</td><td>24.76</td></tr><tr><td><br />疑似-丢失</td><td>0.193</td><td>0.239</td><td>23.83</td></tr><tr><td><br />疑似-断裂</td><td>0.203</td><td>0.238</td><td>17.24</td></tr><tr><td><br />疑似-道砟</td><td>0.170</td><td>0.192</td><td>12.94</td></tr><tr><td><br />疑似-其他</td><td>0.220</td><td>0.259</td><td>17.73</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="196">
                    <p class="img_tit"><b>表</b>2 <b>本文算法和</b>sLDA<b>主题分布的类内散度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 In-class divergence of topic distribution between the proposed algorithm and sLDA model</p>
                    <p class="img_note"></p>
                    <table id="196" border="1"><tr><td rowspan="2"><br />类别状态</td><td colspan="2"><br />主题类内散度</td><td rowspan="2">减少率/%</td></tr><tr><td><br />sLDA</td><td>本文算法</td></tr><tr><td><br />正常</td><td>0.097</td><td>0.033</td><td>65.98</td></tr><tr><td><br />疑似</td><td>0.135</td><td>0.066</td><td>51.11</td></tr><tr><td><br />丢失</td><td>0.063</td><td>0.049</td><td>22.22</td></tr><tr><td><br />断裂</td><td>0.130</td><td>0.042</td><td>67.69</td></tr><tr><td><br />道砟</td><td>0.179</td><td>0.133</td><td>25.70</td></tr><tr><td><br />其他</td><td>0.142</td><td>0.088</td><td>38.03</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="197">分析表1和表2的实验结果, 可得出以下三点结论:1) 本文算法与sLDA相比, 各类的类内散度均减小。其中, 正常、疑似、断裂类别图像减小比例较大, 原因是在这三类的每一类中, 图像内容都比较相似。而对于另外丢失、道砟、其他三类, 每类中图像内容差异较大, 类内故散度减小比例较低。2) 正常类别和丢失、断裂、道砟、其他四个失效类别的类间距离增大。这说明本文算法能够更加明显区分正常和失效扣件图像, 可以降低失效扣件的漏检率。另外, 疑似和失效类别的类间距离增大, 可以降低人工复检比例。3) 正常和疑似类别的类间距离减小。如图5所示, 由于正常和疑似类别中的图像内容具有较高的相似性, 而本文算法和sLDA算法都是无监督方法, 表2中正常和疑似的类间距离大幅降低, 说明本文算法使得这两类的图像表达更加一致, 对图像内容的描述更加真实。</p>
                </div>
                <div class="p1">
                    <p id="198">本文算法和sLDA模型描述600张测试图像的主题分布如图6所示, 图中横坐标为主题值, 图纵坐标为图像编号。编号1～100为其他类别, 101～200为丢失, 201～300为断裂, 301～400为疑似, 401～500为正常, 501～600是道砟。图中每一行表示一张扣件图像的主题分布向量<i>γ</i>, 方格灰度值是<i>γ</i>中一个元素<i>γ</i><sub><i>k</i></sub>的取值, 方格灰度值越大, <i>γ</i><sub><i>k</i></sub>的值也越大。由图6可知, 本文算法与sLDA算法相比, 每个类别内的数据更加稳定、集中, 不同类别之间的区分性更强。</p>
                </div>
                <div class="area_img" id="199">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 正常和疑似类别图像" src="Detail/GetImg?filename=images/JSJY201903045_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 正常和疑似类别图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Normal and suspected fastener images</p>

                </div>
                <div class="area_img" id="200">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 本文算法和sLDA模型的主题分布" src="Detail/GetImg?filename=images/JSJY201903045_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 本文算法和sLDA模型的主题分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Topic distributions of the proposed algorithm and sLDA model</p>

                </div>
                <div class="p1">
                    <p id="201">综上所述, 本文算法通过对sLDA模型的主题分布进行更新, 引入了图像的扣件结构信息, 图像描述的稳定性和区分性增强。</p>
                </div>
                <h4 class="anchor-tag" id="202" name="202">3.4 <b>扣件图像分类实验</b></h4>
                <div class="p1">
                    <p id="203">为评估本文算法的扣件图像分类性能, 设置两组对比实验进行验证。在1 200张数据集中, 每类随机取100张作为训练集, 剩余600张放入测试集, 然后, 再将5 000张数据集放入测试集, 扩大测试图像集至5 600张。分类器采用Softmax, 以后验概率最大的类别作为分类结果, 统计测试图像分类结果的漏检率、误检率、疑似扣件数量。</p>
                </div>
                <h4 class="anchor-tag" id="204" name="204">3.4.1 与其他主题模型对比</h4>
                <div class="p1">
                    <p id="205">将本文算法与sLDA模型、LDA模型对比。LDA是用于描述复杂场景的经典主题模型。sLDA通过训练集标注, 一定程度引入了图像空间结构信息。实验参数设置如下:本文算法和sLDA模型参数配置与3.2节相同, LDA模型参数设置参考文献<citation id="239" type="reference">[<a class="sup">10</a>]</citation>:单词容量<i>V</i>=200, 主题数量<i>K</i>=10, 先验常数<i>α</i><sub><i>k</i></sub>=0.1。底层特征除采用LBP外, 另外采用SIFT特征, 以验证本文算法对不同底层特征的学习能力。SIFT特征子块尺寸为20×20, 两个子块之间重叠15个像素, 统计128维SIFT特征。本文算法与sLDA、LDA的扣件分类结果如表3所示, 其中, 1～3号实验采用LBP特征, 4～6号实验采用SIFT特征。</p>
                </div>
                <div class="p1">
                    <p id="206">对比分析表3的扣件分类结果, 可以得出以下四点结论:1) 本文算法在扣件误检方面优势明显。3、6号实验中的LDA模型误检率最高, 2、5号实验的sLDA模型次之, 1、2号实验的本文算法则大幅降低了误检率。LDA模型忽略了扣件空间结构信息, 模型描述性能不稳定, 当正常扣件的位置、姿态稍微变动时, 就被认为是疑似或失效扣件。LDA模型中误检, 而sLDA和本文方法正确分类的部分图像如图7 (a) 所示。sLDA模型在训练集中标注了扣件结构, 模型稳定性有所提高, 因此降低了正常扣件的误检率。本文方法进一步扩展了sLDA模型, 通过全局和局部约束的方法更新测试图像主题分布, 引入了扣件结构信息, 正常扣件的类内散度减小, 图像描述的稳定性增强, 所以大幅降低了误检率。LDA和sLDA模型中误检, 而本文方法正确分类的部分图像如图7 (b) 所示。2) 本文算法大幅减少了疑似扣件数量。疑似类别中图像内容复杂, LDA模型稳定性较弱, 故实验3、6中LDA模型检出的疑似扣件最多。sLDA一定程度上提高了图像描述性能, 所以实验2、5中sLDA模型检出的疑似数量有所下降。实验1、4中本文方法检出的疑似扣件数量最少, 反映了最佳图像描述性能。3) 本文算法漏检率与sLDA基本相同。本文算法和sLDA正确检出, 而LDA模型漏检的失效扣件全部为断裂扣件。这是因为断裂扣件与正常扣件非常相似, 仅在弹条处存在区别, 若忽略图像结构形状信息, 则无法准确分类断裂扣件。4) 本文算法的时间花费较高。计算每个子块的局部约束权值<i>ω</i><mathml id="207"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>l</mi></msubsup></mrow></math></mathml>时, 需要与大量训练图像子块对比, 导致主题更新需要花费较多的时间。</p>
                </div>
                <div class="area_img" id="208">
                    <p class="img_tit"><b>表</b>3 <b>本文算法与其他主题模型的扣件分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Classification results of the proposed algorithm and other topic models</p>
                    <p class="img_note"></p>
                    <table id="208" border="1"><tr><td>实验<br />序号</td><td>模型</td><td>漏检<br />率/%</td><td>误检<br />率/%</td><td>疑似<br />张数</td><td>时间/<br />ms</td></tr><tr><td>1</td><td>LBP+本文算法</td><td>0.5</td><td>1.2</td><td>95</td><td>1 230</td></tr><tr><td><br />2</td><td>LBP+sLDA</td><td>0.5</td><td>2.7</td><td>149</td><td>892</td></tr><tr><td><br />3</td><td>LBP+LDA</td><td>0.8</td><td>8.6</td><td>261</td><td>422</td></tr><tr><td><br />4</td><td>SIFT+本文算法</td><td>0.4</td><td>1.8</td><td>135</td><td>1 525</td></tr><tr><td><br />5</td><td>SIFT+sLDA</td><td>0.5</td><td>2.9</td><td>171</td><td>1 183</td></tr><tr><td><br />6</td><td>SIFT+LDA</td><td>0.9</td><td>8.7</td><td>286</td><td>720</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="209">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903045_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 表3中误检和漏检的扣件" src="Detail/GetImg?filename=images/JSJY201903045_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 表3中误检和漏检的扣件  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903045_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Error and missing fastener images in Tab. 3</p>

                </div>
                <h4 class="anchor-tag" id="210" name="210">3.4.2 与其他扣件检测方法对比。</h4>
                <div class="p1">
                    <p id="211">将本文算法与其他的扣件检测算法对比, 实验参数设置与原文献一致:文献<citation id="240" type="reference">[<a class="sup">1</a>]</citation>PCA方法, 特征值占比阈值取97%, 特征向量长度为165;文献<citation id="241" type="reference">[<a class="sup">2</a>]</citation>方向场方法, DF特征块尺寸为10×10, 块重叠率50%;文献<citation id="242" type="reference">[<a class="sup">11</a>]</citation>局部特征和语义信息方法, 模型参数与文献相同;文献<citation id="243" type="reference">[<a class="sup">10</a>]</citation>融合文理结构信息的LDA (Texture Structure LDA, TS_LDA) 方法, 采用LBP特征, 其他参数与文献相同;单独采用LBP特征或SIFT特征的方法, 直接将所有子块特征串联作为图像特征。本文算法与其他方法的检测结果如表4所示。</p>
                </div>
                <div class="area_img" id="212">
                    <p class="img_tit"><b>表</b>4 <b>本文算法与其他方法的扣件分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Classification results of the proposed algorithm and other methods</p>
                    <p class="img_note"></p>
                    <table id="212" border="1"><tr><td>实验<br />序号</td><td>方法</td><td>漏检<br />率/%</td><td>误检<br />率/%</td><td>疑似<br />数量</td><td>时间/<br />ms</td></tr><tr><td>1</td><td>LBP+本文算法</td><td>0.50</td><td>1.2</td><td>95</td><td>1 230</td></tr><tr><td><br />2</td><td>文献[11]方法</td><td>0.67</td><td>3.0</td><td>327</td><td>624</td></tr><tr><td><br />3</td><td>文献[10]方法</td><td>1.60</td><td>4.6</td><td>182</td><td>528</td></tr><tr><td><br />4</td><td>文献[1]方法</td><td>24.30</td><td>27.0</td><td>824</td><td>207</td></tr><tr><td><br />5</td><td>文献[2]方法</td><td>0.33</td><td>31.0</td><td>627</td><td>70</td></tr><tr><td><br />6</td><td>文献[4]方法</td><td>4.30</td><td>16.3</td><td>532</td><td>85</td></tr><tr><td><br />7</td><td>文献[3]方法</td><td>3.60</td><td>19.0</td><td>458</td><td>360</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="213">分析表4的扣件分类结果, 可以得出以下两点结论:1) 与其他扣件主题模型相比, 本文分类性能最佳。对比实验1～3, 局部特征方法<citation id="244" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和TS_LDA方法<citation id="245" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>同样存在误检率高、疑似数量大的问题, 本文在降低误检和疑似扣件的同时, 保证了较低的漏检率。2) 与其他直接采用底层特征分类的方法相比, 本文方法具有明显优势。无论是文献<citation id="246" type="reference">[<a class="sup">1</a>]</citation>的PCA特征、文献<citation id="247" type="reference">[<a class="sup">2</a>]</citation>的DF特征, 还是LBP特征<citation id="248" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>或SIFT特征<citation id="249" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 直接采用这些底层特征分类扣件图像都会出现大量分类错误。</p>
                </div>
                <h3 id="214" name="214" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="215">由于测试图像缺乏人工标注, sLDA主题分布不能充分描述扣件图像的结构状态。本文提出一种结合全局和局部约束的主题分布更新方法, 用训练集主题分布合成新测试图像主题分布。采用sLDA模型获得新图像主题分布后, 全局约束整幅图像的类别状态, 局部约束计算测试图像子块与已有训练集子块主题分布的相似程度。将全局和局部约束乘积作为更新权值对训练集子块加权求和, 获得新的主题分布。新的主题分布包含了图像中扣件结构信息, 扣件分类性能提高。具体表现为以下三个方面:1) 用更新权值生成新图像的标注, 标注能够刻画出正常和失效扣件的形态结构;2) 相比sLDA, 在新的主题分布下, 正常和失效类别间区别更加明显, 同一类图像则更加相似;3) 相比其他扣件分类模型, 新模型在减少漏检失效扣件的同时, 大幅降低了正常扣件的误检率。</p>
                </div>
                <div class="p1">
                    <p id="216">本文算法的不足之处是, 更新后的主题分布是训练集子块实例的组合, 这就要求训练集覆盖所有扣件图像类型, 模型泛化能力有待加强。后续可以借鉴可变部件模型 (Deformable Part Model, DPM) 采用混合高斯模型产生扣件模板的方法, 改进局部约束方式。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201112053&amp;v=MDE3MjBGckNVUjdxZlp1WnBGeW5sVUx2Qk5pZllaTEc0SDlETnJZOUFaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王凌, 张冰, 陈锡爱.基于计算机视觉的钢轨扣件螺母缺失检测系统[J].计算机工程与设计, 2011, 32 (12) :4147-4150. (WANG L, ZHANG B, CHEN X A. Inspection system for loss of rail fastening nut based on computer vision [J]. Computer Engineering and Design, 2011, 32 (12) : 4147-4150.) 
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900015056&amp;v=MDk4Njk5RE5wbzlGWk9vS0RIay9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyaklJVjRYYmhzPU5qN0Jhcks4SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> DOU Y, HUANG Y, LI Q, et al. A fast template matching-based algorithm for railway bolts detection [J]. International Journal of Machine Learning and Cybernetics, 2014, 5 (6) : 835-844.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MzE5MTc3cWRaK1p1RmkvbFVyL0xKRmM9Tmo3QmFyTzRIdEhPcDR4RmJlc09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdS&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> LOWE D G. Distinctive image features from scale-invariant keypoints [J]. International Journal of Computer Vision, 2004, 60 (2) : 91-110.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNJT201502008&amp;v=MzIyMjZHNEg5VE1yWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJQU1BCZXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 刘甲甲, 李柏林, 罗建桥, 等.融合PHOG和MSLBP特征的铁路扣件检测算法[J].西南交通大学学报, 2015, 50 (2) :256-263. (LIU J J, LI B L, LUO J Q, et al. Railway fastener detection algorithm integrating PHOG and MSLBP features [J]. Journal of Southwest Jiaotong University, 2015, 50 (2) : 256-263.) 
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 BLEI D M, NG A Y, JORDAN M I. Latent dirichlet allocation [J]. Journal of Machine Learning Research, 2012, 3: 993-1022.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201214055&amp;v=MTY5NTA1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJMejdCYmJHNEg5UE5xNDlBWVlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 杨赛, 赵春霞.基于隐含狄利克雷分配模型的图像分类算法[J].计算机工程, 2012, 38 (14) :181-183. (YANG S, ZHAO C X. Image classification algorithm based on latent Dirichlet allocation model [J]. Computer Engineering, 2012, 38 (14) : 181-183.) 
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201704005&amp;v=MjU5NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2QkxTblJaTEc0SDliTXE0OUZZWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 李斌, 程丹, 李星.基于Direct LDA的相关向量机遥感图像分类[J].信息技术, 2017 (4) :17-20. (LI B, CHENG D, LI X. Relevant vector machine classification of hyperspectral image based on direct linear discriminant analysis [J]. Information Technology, 2017 (4) : 17-20.) 
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXWL201810104&amp;v=MDUwNzE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2Qk1UWGNZckc0SDluTnI0NUZZSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 曾康林, 刘汉文.基于LDA和SVM的图像场景分类[J].中国新通信, 2018, 20 (10) :125-127. (ZENG K L, LIU H W. Image scene classification based on LDA and SVM [J]. China New Telecommunications, 2018, 20 (10) : 125-127.) 
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic fastener classification and defect detection in vision-based railway inspection systems">

                                <b>[9]</b> FENG H, JIANG Z, XIE F, et al. Automatic fastener classification and defect detection in vision-based railway inspection systems [J]. IEEE Transactions on Instrumentation and Measurement, 2014, 63 (4) : 877-888.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201602056&amp;v=MTg0OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2Qkx6N0JkN0c0SDlmTXJZOUFZb1E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 罗建桥, 刘甲甲, 李柏林, 等.融合纹理结构的潜在狄利克雷分布铁路扣件检测模型[J].计算机应用, 2016, 36 (2) :574-579. (LUO J Q, LIU J J, LI B L, et al. Latent dirichlet allocation model integrated with texture structure for railway fastener detection [J]. Journal of Computer Applications, 2016, 36 (2) : 574-579.) 
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201608062&amp;v=MDUzNzMzenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJMejdTWkxHNEg5Zk1wNDlEWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 罗建桥, 刘甲甲, 李柏林, 等.基于局部特征和语义信息的扣件图像检测[J].计算机应用研究, 2016, 33 (8) :2514-2518. (LUO J Q, LIU J J, LI B L, et al. Detection for railway fasteners based on local features and semantic information [J]. Application Research of Computers, 2016, 33 (8) : 2514-2518.) 
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201403001&amp;v=MTMxODU3cWZadVpwRnlubFVMdkJQeXJmYkxHNEg5WE1ySTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 赵理君, 唐娉, 霍连志, 等.图像场景分类中视觉词包模型方法综述[J].中国图象图形学报, 2014, 19 (3) :333-343. (ZHAO L J, TANG P, HUO L Z, et al. Review of the bag-of-visual-words models in image scene classification [J]. Journal of Image and Graphics, 2014, 19 (3) : 333-343.) 
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised LDA for Image Annotation">

                                <b>[13]</b> GUO Q, LI N, YANG Y, et al. Supervised LDA for image annotation [C]// Proceedings of the 2011 IEEE International Conference on Systems, Man, and Cybernetics. Piscataway, NJ: IEEE, 2011: 471-476.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Markov Weight Fields for face sketch synthesis">

                                <b>[14]</b> ZHOU H. Markov weight fields for face sketch synthesis [C]// CVPR '12: Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2012: 1091-1097.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graphical representation for heterogeneous face recognition">

                                <b>[15]</b> PENG C, GAO X, WANG N, et al. Graphical representation for heterogeneous face recognition [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (2) : 301-312.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Random sampling for fast face sketch synthesis">

                                <b>[16]</b> WANG N, GAO X, LI J. Random sampling for fast face sketch synthesis [J]. Pattern Recognition, 2018, 76: 215-227.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES41E29D506977E76730BFE227E90D142D&amp;v=MTY2NDlLRT1OaWZPZmJlNWE5UEYyNHBGWXVJSUN3ayt5UkVRNmswTFBYM2dxMmM4ZWNhVlFianJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0OWh4Ymk4eA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> ZHANG C, ZHU X, LI L, et al. Joint image representation and classification in random semantic spaces [J]. Neurocomputing, 2015, 156 (C) : 79-85.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiresolution gray-scale and rotation invariant texture classification with local binary patterns">

                                <b>[18]</b> OJALA T, PIETIKAINEN M, MAENPAA T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) : 971-987.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201310034&amp;v=MTQyNDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlubFVMdkJKaXJhWkxHNEg5TE5yNDlHWUlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 李永波, 李柏林, 熊鹰.基于HOG特征的铁路扣件状态检测[J].传感器与微系统, 2013, 32 (10) :110-113. (LI Y B, LI B L, XIONG Y. Railway fastener state detection based on HOG feature [J]. Transducer and Microsystem Technologies, 2013, 32 (10) : 110-113.) 
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Effective multi-query expansions:collaborative deep networks based feature learning for robust landmark retrieval">

                                <b>[20]</b> WANG Y, LIN X, WU L, et al. Effective multi-query expansions: collaborative deep networks based feature learning for robust landmark retrieval [J]. IEEE Transactions on Image Processing, 2017, 26 (3) :1393-1404.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local-class-shared-topic latent Dirichlet allocation based scene classification">

                                <b>[21]</b> HUANG C, LUO W, XIE Y. Local-class-shared-topic latent Dirichlet allocation based scene classification [J]. Multimedia Tools and Applications, 2017, 76 (14) : 15661-15679.This work is partially supported by the Science and Technology Support Project of Sichuan Province (2018GZ0361) .YANG Fei, born in 1994, M. S. candidate. His research interests include machine vision, image processing, pattern recognition.LUO Jianqiao, born in 1991, Ph. D. candidate. His research interests include image semantic analysis, machine learning.LI Bailin, born in 1962, Ph. D., professor. His research interests include image processing, machine vision.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903045" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903045&amp;v=Mjk1ODRkN0c0SDlqTXJJOUJZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeW5sVUx2Qkx6N0I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpnREMzODZiNTI3ZE9NNm5wND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
