<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136661937190000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907009%26RESULT%3d1%26SIGN%3dam7T7vTnPJ41KRQUfOw6w8A9nYY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907009&amp;v=MzAzODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTDNBTHo3QmQ3RzRIOWpNcUk5RmJZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="2 方法介绍 ">2 方法介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="2.1 &lt;b&gt;标签模型&lt;/b&gt;">2.1 <b>标签模型</b></a></li>
                                                <li><a href="#80" data-title="2.2 &lt;b&gt;从标签获取结果&lt;/b&gt;">2.2 <b>从标签获取结果</b></a></li>
                                                <li><a href="#83" data-title="2.3 &lt;b&gt;词向量&lt;/b&gt;">2.3 <b>词向量</b></a></li>
                                                <li><a href="#85" data-title="2.4 Bi-LSTM-CRF&lt;b&gt;模型&lt;/b&gt;">2.4 Bi-LSTM-CRF<b>模型</b></a></li>
                                                <li><a href="#111" data-title="2.5 &lt;b&gt;句子选择器&lt;/b&gt;">2.5 <b>句子选择器</b></a></li>
                                                <li><a href="#138" data-title="2.6 &lt;b&gt;句子选择器+序列标注模型&lt;/b&gt;">2.6 <b>句子选择器+序列标注模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="3 实验介绍 ">3 实验介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#142" data-title="3.1 &lt;b&gt;数据集&lt;/b&gt;">3.1 <b>数据集</b></a></li>
                                                <li><a href="#144" data-title="3.2 &lt;b&gt;评估策略&lt;/b&gt;">3.2 <b>评估策略</b></a></li>
                                                <li><a href="#146" data-title="3.3 &lt;b&gt;参数设置&lt;/b&gt;">3.3 <b>参数设置</b></a></li>
                                                <li><a href="#148" data-title="3.4 &lt;b&gt;基准线&lt;/b&gt;">3.4 <b>基准线</b></a></li>
                                                <li><a href="#159" data-title="3.5 &lt;b&gt;实验结果&lt;/b&gt;">3.5 <b>实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#163" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 任务的例句">图1 任务的例句</a></li>
                                                <li><a href="#78" data-title="图2 标签策略">图2 标签策略</a></li>
                                                <li><a href="#97" data-title="图3 LSTM单元内部结构">图3 LSTM单元内部结构</a></li>
                                                <li><a href="#110" data-title="图4 Bi-LSTM-CRF结构">图4 Bi-LSTM-CRF结构</a></li>
                                                <li><a href="#140" data-title="图5 句子选择器+序列标注联合模型">图5 句子选择器+序列标注联合模型</a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;各模型实验结果比较&lt;/b&gt;"><b>表</b>1 <b>各模型实验结果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="207">


                                    <a id="bibliography_1" title=" BANKO M, CAFARELLAM J, SODERLAND S, et al.Open information extraction from the Web[C]// Proceedings of the 20th International Joint Conference on Artificial Intelligence.New York:ACM, 2007:2670-2676." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Open information ex-traction from the web">
                                        <b>[1]</b>
                                         BANKO M, CAFARELLAM J, SODERLAND S, et al.Open information extraction from the Web[C]// Proceedings of the 20th International Joint Conference on Artificial Intelligence.New York:ACM, 2007:2670-2676.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_2" title=" NADEAU D, SEKINE S.A survey of named entity recognition and classification[J].Lingvisticae Investigationes, 2005, 30 (1) :3-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey of named entity recognition and classification">
                                        <b>[2]</b>
                                         NADEAU D, SEKINE S.A survey of named entity recognition and classification[J].Lingvisticae Investigationes, 2005, 30 (1) :3-26.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_3" title=" RINK B, HARABAGIU A.UTD:classifying semantic relations by combining lexical and semantic resources[C]// Proceedings of the 5th International Workshop on Semantic Evaluation.New York:ACM, 2010:256-259." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=UTD:Classifying semantic relations by combining lexical and semantic resources">
                                        <b>[3]</b>
                                         RINK B, HARABAGIU A.UTD:classifying semantic relations by combining lexical and semantic resources[C]// Proceedings of the 5th International Workshop on Semantic Evaluation.New York:ACM, 2010:256-259.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_4" title=" LI Q, JI H.Incremental joint extraction of entity mentions and relations[C]// Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2014:402-412." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incremental joint extraction of entity mentions and relations">
                                        <b>[4]</b>
                                         LI Q, JI H.Incremental joint extraction of entity mentions and relations[C]// Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2014:402-412.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_5" title=" MIWA M, BANSAL M.End-to-end relation extraction using LSTMs on sequences and tree structures[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:1105-1116." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures">
                                        <b>[5]</b>
                                         MIWA M, BANSAL M.End-to-end relation extraction using LSTMs on sequences and tree structures[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:1105-1116.
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_6" title=" ZHENG S C, WANG F.Joint extraction of entities and relations based on a novel tagging scheme[C]// Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2017:1227-1236." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint extraction of entities and relations based on a novel tagging scheme">
                                        <b>[6]</b>
                                         ZHENG S C, WANG F.Joint extraction of entities and relations based on a novel tagging scheme[C]// Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2017:1227-1236.
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_7" title=" MINTZ M, BILLS S, SNOW R, et al.Distant supervision for relation extraction without labeled data[C]// Proceedings of the 2009/47th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2009:1003-1011" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant supervision for relation extraction without labeled data">
                                        <b>[7]</b>
                                         MINTZ M, BILLS S, SNOW R, et al.Distant supervision for relation extraction without labeled data[C]// Proceedings of the 2009/47th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2009:1003-1011
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_8" title=" FENG J, HUANG M, ZHAO L, et al.Reinforcement learning for relation classification from noisy data[C]// Proceedings of the 2018/32nd Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2018:5779-5786" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reinforcement learning for relation classification from noisy data">
                                        <b>[8]</b>
                                         FENG J, HUANG M, ZHAO L, et al.Reinforcement learning for relation classification from noisy data[C]// Proceedings of the 2018/32nd Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2018:5779-5786
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_9" title=" SUTTON R S, BARTO A G.Reinforcement learning:an introduction[J].IEEE Transactions on Neural Networks, 1998, 9 (5) :1054-1054." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reinforcement Learning: An Introduction">
                                        <b>[9]</b>
                                         SUTTON R S, BARTO A G.Reinforcement learning:an introduction[J].IEEE Transactions on Neural Networks, 1998, 9 (5) :1054-1054.
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_10" title=" LUO G, HUANG X J, LIN C Y, et al.Joint entity recognition and disambiguation[C]// Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:879-888." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint entity recognition and disambiguation">
                                        <b>[10]</b>
                                         LUO G, HUANG X J, LIN C Y, et al.Joint entity recognition and disambiguation[C]// Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:879-888.
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_11" title=" 冯元勇, 孙乐, 张大鲲, 等.基于小规模尾字特征的中文命名实体识別研究[J].电子学报, 2008, 36 (9) :1833-1838. (FENG Y Y, SUN L, ZHANG D K, et al.Study on the Chinese named entity recognition using small scale tail hints[J].Acta Electronica Sinaca, 2008, 36 (9) :1833-1838.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200809035&amp;v=Mjc0NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMM0FJVGZUZTdHNEh0bk1wbzlHWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         冯元勇, 孙乐, 张大鲲, 等.基于小规模尾字特征的中文命名实体识別研究[J].电子学报, 2008, 36 (9) :1833-1838. (FENG Y Y, SUN L, ZHANG D K, et al.Study on the Chinese named entity recognition using small scale tail hints[J].Acta Electronica Sinaca, 2008, 36 (9) :1833-1838.) 
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_12" title=" 向晓雯, 史晓东, 曾华琳.一个统计与规则相结合的中文命名实体识别系统[J].计算机应用, 2005, 25 (10) :2404-2406. (XIANG X W, SHI X D, ZENG H L.Chinese named entity recognition system using statistics-based and rules-based method [J].Journal of Computer Applications, 2005, 25 (10) :2404-2406.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY200510064&amp;v=MjUzNzJGeS9uVkwzQUx6N0JkN0c0SHRUTnI0OURZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         向晓雯, 史晓东, 曾华琳.一个统计与规则相结合的中文命名实体识别系统[J].计算机应用, 2005, 25 (10) :2404-2406. (XIANG X W, SHI X D, ZENG H L.Chinese named entity recognition system using statistics-based and rules-based method [J].Journal of Computer Applications, 2005, 25 (10) :2404-2406.) 
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_13" title=" 佘俊, 张学清.音乐命名实体识别方法[J].计算机应用, 2010, 20 (11) :2928-2931. (SHE J, ZHANG X Q.Musical named entity recognition method [J].Journal of Computer Applications, 2010, 30 (11) :2928-2931.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201011022&amp;v=MDU4MjZHNEg5SE5ybzlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMM0FMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         佘俊, 张学清.音乐命名实体识别方法[J].计算机应用, 2010, 20 (11) :2928-2931. (SHE J, ZHANG X Q.Musical named entity recognition method [J].Journal of Computer Applications, 2010, 30 (11) :2928-2931.) 
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_14" title=" 张金龙, 王石, 钱存发.基于CRF和规则的中文医疗机构名称识[J].计算机应用与软件, 2014, 31 (3) :159-162. (ZHANG J L, WANG S, QIAN C F.CRF and rules-based recognition of medical institutions name in Chinese [J].Computer Applications and Software, 2014, 31 (3) :159-162.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201403043&amp;v=MDU4MjF6VFpaTEc0SDlYTXJJOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwzQUw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         张金龙, 王石, 钱存发.基于CRF和规则的中文医疗机构名称识[J].计算机应用与软件, 2014, 31 (3) :159-162. (ZHANG J L, WANG S, QIAN C F.CRF and rules-based recognition of medical institutions name in Chinese [J].Computer Applications and Software, 2014, 31 (3) :159-162.) 
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_15" title=" CHIU J P C, NICHOLS E.Named entity recognition with bidirectional LSTM-CNNs[C]// Proceedings of the 2016 Transactions of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:357-370" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Named Entity Recognition with Bidirectional LSTM-CNNs">
                                        <b>[15]</b>
                                         CHIU J P C, NICHOLS E.Named entity recognition with bidirectional LSTM-CNNs[C]// Proceedings of the 2016 Transactions of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:357-370
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_16" title=" HUANG Z, XU W, YU K.Bidirectional LSTM-CRF models for sequence tagging[EB/OL].[2018- 12- 02].https://arxiv.org/pdf/1508.01991.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]">
                                        <b>[16]</b>
                                         HUANG Z, XU W, YU K.Bidirectional LSTM-CRF models for sequence tagging[EB/OL].[2018- 12- 02].https://arxiv.org/pdf/1508.01991.pdf.
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_17" title=" LAMPLE G, BALLESTEROS M, SUBRAMANIAN S, et al.Neural architectures for named entity recognition[C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:260-270." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural architectures for named entity recognition">
                                        <b>[17]</b>
                                         LAMPLE G, BALLESTEROS M, SUBRAMANIAN S, et al.Neural architectures for named entity recognition[C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:260-270.
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_18" title=" REN X, WU Z, HE W, et al.CoType:joint extraction of typed entities and relations with knowledge bases[C]// Proceedings of the 26th International Conference on World Wide Web.New York:ACM, 2017:1015-1024." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CoType:Joint extraction of typed entities and relations with knowledge bases">
                                        <b>[18]</b>
                                         REN X, WU Z, HE W, et al.CoType:joint extraction of typed entities and relations with knowledge bases[C]// Proceedings of the 26th International Conference on World Wide Web.New York:ACM, 2017:1015-1024.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_19" title=" SINGH S, RIEDEL S, MARTIN B, et al.Joint inference of entities, relations, and coreference[C]// Proceedings of the 2013 Workshop on Automated Knowledge Base Construction.New York:ACM, 2013:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint Inference of Entities,Relations,and Coreference">
                                        <b>[19]</b>
                                         SINGH S, RIEDEL S, MARTIN B, et al.Joint inference of entities, relations, and coreference[C]// Proceedings of the 2013 Workshop on Automated Knowledge Base Construction.New York:ACM, 2013:1-6.
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_20" title=" LIN Y, SHEN S, LIU Z, et al.Neural relation extraction with selective attention over instances[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:2124-2133." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural relation extraction with selective attention over instances">
                                        <b>[20]</b>
                                         LIN Y, SHEN S, LIU Z, et al.Neural relation extraction with selective attention over instances[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:2124-2133.
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_21" title=" JI G, LIU K, HE S, et al.Distant supervision for relation extraction with sentence-level attention and entity descriptions[C]// Proceedings of the Thirty-First Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:3060-3066." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions">
                                        <b>[21]</b>
                                         JI G, LIU K, HE S, et al.Distant supervision for relation extraction with sentence-level attention and entity descriptions[C]// Proceedings of the Thirty-First Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:3060-3066.
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_22" title=" NARASIMHAN K, YALA A, BARZILAY R.Improving information extraction by acquiring external evidence with reinforcement learning[C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:2355-2365." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving information extraction by acquiring external evidence with reinforcement learning">
                                        <b>[22]</b>
                                         NARASIMHAN K, YALA A, BARZILAY R.Improving information extraction by acquiring external evidence with reinforcement learning[C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:2355-2365.
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_23" title=" MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">
                                        <b>[23]</b>
                                         MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119.
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_24" title=" TANG J, QU M, WANG M, et al.LINE:large-scale information network embedding[C]// Proceedings of the 24th International Conference on World Wide Web.New York:ACM, 2015:1067-1077." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Line:Large-scale information network embedding">
                                        <b>[24]</b>
                                         TANG J, QU M, WANG M, et al.LINE:large-scale information network embedding[C]// Proceedings of the 24th International Conference on World Wide Web.New York:ACM, 2015:1067-1077.
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_25" title=" GORMLEY M R, YU M, DREDZE M.Improved relation extraction with feature-rich compositional embedding models[C]// Proceedings of the 2015 Conference on Empirical Method in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:1774-1784." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Relation Extraction with Feature-Rich Compositional Embedding Models">
                                        <b>[25]</b>
                                         GORMLEY M R, YU M, DREDZE M.Improved relation extraction with feature-rich compositional embedding models[C]// Proceedings of the 2015 Conference on Empirical Method in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:1774-1784.
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_26" title=" HOFFMANN R, ZHANG C, LING X, et al.Knowledge-based weak supervision for information extraction of overlapping relations[C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2011:541-550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge-based weak supervision for information extraction of overlapping relations">
                                        <b>[26]</b>
                                         HOFFMANN R, ZHANG C, LING X, et al.Knowledge-based weak supervision for information extraction of overlapping relations[C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2011:541-550.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-08 14:47</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),1918-1924 DOI:10.11772/j.issn.1001-9081.2019010182            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于强化学习的实体关系联合抽取模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">陈佳沣</a>
                                <a href="javascript:;">滕冲</a>
                </h2>
                    <h2>

                    <span>武汉大学国家网络安全学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对现有的基于远程监督的实体和关系抽取方法存在着标签噪声问题, 提出了一种基于强化学习的实体关系联合抽取方法。该模型有两个模块:句子选择器模块和实体关系联合抽取模块。首先, 句子选择器模块选择没有标签噪声的高质量句子, 将所选句子输入到实体关系联合抽取模型;然后, 实体关系联合抽取模块采用序列标注方法对输入的句子进行预测, 并向句子选择器模块提供反馈, 指导句子选择器模块挑选高质量的句子;最后, 句子选择器模块和实体关系联合抽取模块同时训练, 将句子选择与序列标注一起优化。实验结果表明, 该模型在实体关系联合抽取中的F1值为47.3%, 与CoType为代表的联合抽取模型相比, 所提模型的F1值提升了1%;与LINE为代表的串行模型相比, 所提模型的F1值提升了14%。结果表明强化学习结合实体关系联合抽取模型能够有效地提高序列标注模型的F1值, 其中句子选择器能有效地处理数据的噪声。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">强化学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">联合抽取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">序列标注;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">命名实体识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关系分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈佳沣 (1995—) , 男, 湖北武汉人, 硕士研究生, 主要研究方向:数据挖掘、深度学习;;
                                </span>
                                <span>
                                    *滕冲 (1974—) , 女, 湖北武汉人, 副教授, 博士, 主要研究方向:数据挖掘、大数据、深度学习、舆情分析。电子邮箱tengchong@whu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金面上项目 (61772378);</span>
                    </p>
            </div>
                    <h1><b>Joint entity and relation extraction model based on reinforcement learning</b></h1>
                    <h2>
                    <span>CHEN Jiafeng</span>
                    <span>TENG Chong</span>
            </h2>
                    <h2>
                    <span>School of Cyber Science and Engineering, Wuhan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Existing entity and relation extraction methods that rely on distant supervision suffer from noisy labeling problem. A model for joint entity and relation extraction from noisy data based on reinforcement learning was proposed to reduce the impact of noise data. There were two modules in the model: an sentence selector module and a sequence labeling module. Firstly, high-quality sentences without labeling noise were selected by instance selector module and the selected sentences were input into sequence labeling module. Secondly, predictions were made by sequence labeling module and the rewards were provided to sentence selector module to help the module select high-quality sentences. Finally, two modules were trained jointly to optimize instance selection and sequence labeling processes. The experimental results show that the F1 value of the proposed model is 47.3% in the joint entity and relation extraction, which is 1% higher than those of joint extraction models represented by CoType and 14% higher than those of serial models represented by LINE (Large-scale Information Network Embedding) . The results show that the joint entity and relation extraction model in combination with reinforcement learning can effectively improve F1 value of sequential labeling model, in which the sentence selector can effectively deal with the noise of data.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reinforcement%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reinforcement learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=joint%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">joint extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sequence%20tagging&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sequence tagging;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=named%20entity%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">named entity recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=relation%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">relation classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHEN Jiafeng, born in 1995, M. S. candidate. His research interests include data mining, deep learning, ;
                                </span>
                                <span>
                                    TENG Chong, born in 1974, Ph. D. , associate professor. Her research interests include data mining, big data, deep learning, public opinion analysis.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-24</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Surface Program of National Natural Science Foundation of China (61772378);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="55" name="55" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="56">实体和关系的联合抽取是从非结构化文本中同时检测实体引用和识别它们的语义关系, 如图1所示。不同于Banko等<citation id="259" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>从给定句子中抽取关系词的开放信息抽取, 在本任务中, 关系词是从预定义的关系集中抽取的, 该关系集可能不会出现在给定句子中。它是知识抽取和知识库自动构建中的一个重要途径。</p>
                </div>
                <div class="p1">
                    <p id="57">传统方法以串行的方式处理此任务, 即Nadeau等<citation id="260" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>先抽取实体, 然后Rink等<citation id="261" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>识别它们的关系。这个串行的框架使任务易于处理, 并且每个组件可以更灵活;但是它忽略了这两个子任务之间的相关性, 并且每个子任务都是一个独立的模型。Li等<citation id="262" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出实体识别的结果可能会影响关系分类的效果, 并导致错误的传递。</p>
                </div>
                <div class="p1">
                    <p id="58">与传统方法不同, 联合学习框架是使用单个模型将实体识别和关系抽取结合在一起。它能有效地整合实体信息和关系信息, 在这项任务中取得了较好的效果。大多数现有的联合方法是基于特征的结构化系统<citation id="263" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。它们需要复杂的特性工程, 并且严重依赖于其他自然语言处理 (Natural Language Processing, NLP) 工具包, 这也可能导致错误传播。为了减少特征抽取中的手工工作, Miwa等<citation id="264" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种基于神经网络的端到端实体和关系联合抽取方法。虽然联合模型可以在单个模型中让实体识别模块与关系分类模块共享参数, 但它们也是分别抽取实体和关系, 并生成冗余信息。例如, 图1中的句子包含三个实体:“United States”“Trump”和“Apple Inc”, 但只有“United States”和“Trump”才有固定的关系“Country-President”。在这句话中, 实体“Apple Inc”与其他实体没有明显的关系, 因此, 从这句话中抽取的结果是{United States, Country-President, Trump}, 它在这里称为三元组。Zheng等<citation id="265" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一个标签方案, 将联合抽取任务转换为标签问题。通过建立含有关系信息的标签, 使用序列标注模型直接抽取实体及其关系, 而不单独识别实体和关系。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 任务的例句" src="Detail/GetImg?filename=images/JSJY201907009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 任务的例句  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Example sentence of task</p>

                </div>
                <div class="p1">
                    <p id="60">大多数现有的工作都需要高质量的标注数据。为了获得大规模的训练数据, Mintz等<citation id="266" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了远程监督的方法, 假设两个实体在给定的知识库中有关系, 则包含这两个实体的所有句子都会提到这种关系。远程监督虽然能有效地实现数据的自动标注, 但存在着标签噪声的问题。以三元组{Barack Obama, BornIn, United States}为例, 由远程监督标注的数据“Barack Obamba is the 44th president of the United State”就是一个噪声数据, 远程监督认为这个句子中Barack Obama与United States的关系是“BornIn”, 即使这句话根本没有描述“BornIn”关系。</p>
                </div>
                <div class="p1">
                    <p id="61">因此, 以往的基于远程监督的数据集上的实体关系联合抽取的研究存在着标签噪声的问题。噪声语句产生错误的标签, 会对联合抽取模型产生不良影响。Feng等<citation id="267" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种基于噪声数据的句子级关系分类模型, 其模型包括两个模块:句子选择器和关系分类器。句子选择器通过强化学习选择高质量的句子, 将所选句子输入到关系分类器;关系分类器进行句子预测, 并为句子选择器提供反馈。他们的模型能够有效地处理数据的噪声, 在句子层次上获得更好的关系分类效果。</p>
                </div>
                <div class="p1">
                    <p id="62">本文提出了一种由句子选择器和序列标注模型两个模块组成的序列标注模型。通过使用句子选择器, 可以从一个句子包中选择高质量的句子, 然后通过序列标注模型预测句子的标签。目前主要的挑战是当句子选择器不清楚哪些句子的标签错误时, 如何有效地联合训练这两个模块。</p>
                </div>
                <div class="p1">
                    <p id="63">本文将句子选择任务当作强化学习问题来解决<citation id="268" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。直观地说, 虽然模型没有对句子选择器进行显式监督, 但是可以把所选语句作为一个整体进行评估, 因此, 句子选择过程具有以下两个性质:一是试错搜索, 即句子选择器试图从每个实体的句子集合中选择一些句子, 并获得对所选句子质量的反馈;二是只有当句子选择器完成了句子选择过程, 才能获得从序列标注模块的反馈, 这个反馈通常是延迟的。这两个特性让本文使用强化学习技术。</p>
                </div>
                <div class="p1">
                    <p id="64">本文工作中的贡献包括:</p>
                </div>
                <div class="p1">
                    <p id="65">1) 提出了一种新的序列标注模型, 该模型由句子选择器和序列标注模型组成。这个模型能够在相对没有噪声的数据中进行实体和关系的联合抽取。</p>
                </div>
                <div class="p1">
                    <p id="66">2) 将句子选择定义为一个强化学习问题, 使得模型能够在没有明确的句子级标注情况下执行句子选择, 通过序列标注模型较弱的监督信号提供反馈。</p>
                </div>
                <div class="p1">
                    <p id="67">3) 根据实体将数据分成不同的集合, 句子选择器选择实体集合中的高质量句子, 然后所有的集合中选择的数据作为干净的数据训练序列标注模型。</p>
                </div>
                <h3 id="68" name="68" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="69">实体识别和关系分类是构建知识库的重要步骤, 对许多NLP任务都有帮助。两种主要框架被广泛应用于解决实体识别及其关系抽取的问题:一种是流水线方法, 另一种是联合学习方法。</p>
                </div>
                <div class="p1">
                    <p id="70">流水线方法将此任务视为两个独立的任务, 即命名实体识别 (Named Entity Recognition, NER) 和关系分类 (Relation Classification, RC) 。经典的NER模型是线性统计模型, 如隐马尔可夫模型 (Hidden Markov Model, HMM) 和条件随机场 (Conditional Random Field, CRF) <citation id="269" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 其中CRF模型结合了最大熵模型和隐马尔可夫模型的优点<citation id="270" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。向晓雯等<citation id="271" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、佘俊等<citation id="272" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、张金龙等<citation id="273" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>采用规则与统计相结合的方法研究命名实体识别任务, 取得了较好的结果。近几年, Chiu等<citation id="274" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、Huang等<citation id="275" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、Lample等<citation id="276" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>几种神经网络结构已成功应用于NER, 将命名实体识别任务处理成序列标注任务。现有的关系分类方法也可分为手工抽取特征的方法<citation id="277" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>和基于神经网络的方法。</p>
                </div>
                <div class="p1">
                    <p id="71">联合模型使用单个模型抽取实体和关系, 而大多数联合方法是基于特征的结构化系统, 例如Ren等<citation id="278" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、Singh等<citation id="279" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、Miwa等<citation id="280" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、Li等<citation id="281" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的方法。最近, Miwa等<citation id="282" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>使用基于长短期记忆 (Long Short-Term Memory, LSTM) 网络的模型抽取实体和关系, 这可以减少手工工作。Zheng等<citation id="283" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一个标签方案, 可以将联合抽取任务转换为序列标注问题。基于这种标签方案, 研究不同的端到端模型, 可以直接抽取实体及其关系, 而不单独识别实体和关系。本文所提出的方法是基于一种特殊的标签方式, 因此可以很容易地使用端到端模型来抽取结果, 而不需要运用NER和RC分别进行。</p>
                </div>
                <div class="p1">
                    <p id="72">一般来说, 训练神经网络模型需要大量的标签数据, 人工标注数据是非常耗时的。为了解决这个问题, Mintz等<citation id="284" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了远程监督方法, 该方法假设所有关于三元组中的两个实体的句子都描述了三元组中的关系。尽管远程监督取得了成功, 但这种方法存在着标签噪声问题。为了解决这一问题, Lin等<citation id="285" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、Ji等<citation id="286" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出了多个句子级别的注意力机制, 可以降低噪声句子的权重。然而, 这种多句子学习模型并不能直接过滤掉噪声数据的影响。Feng等<citation id="287" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一个基于噪声数据的句子级关系分类模型, 首先在强化学习框架下选择正确的句子<citation id="288" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 然后预测过滤后数据中每个句子的关系。本文提出的方法首先在强化学习的框架下选择正确的句子, 然后从干净的数据中预测每个句子的标签序列。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag">2 方法介绍</h3>
                <div class="p1">
                    <p id="74">本文提出一个句子选择器和序列标注的联合抽取模型, 双向长短期记忆条件随机场 (Bidirectional Long Short-Term Memory Conditional Random Field, Bi-LSTM-CRF) 模型来联合抽取实体及其关系, 句子选择器来选择高质量的句子。在本章中, 首先介绍如何将抽取问题改为标签问题, 然后介绍用于选择高质量句子的强化学习模型。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75">2.1 <b>标签模型</b></h4>
                <div class="p1">
                    <p id="76">图2是对训练集标注的示例。句子中的每个词都被打上一个有助于提取结果的标签。标签“O”表示“其他”标签, 这意味着相应的单词独立于提取的结果。除“O”外, 其他标签还包括三个部分:实体中的单词位置、关系类型和关系角色。本文使用实体开始 (Begin, B) 、实体内部 (Inner, I) 、实体结尾 (End, E) 、单个实体 (Single, S) 等符号来表示实体中单词的位置信息。关系类型信息从一组预定义的关系中获取, 关系角色信息由数字“1”和“2”表示。提取的结果由三元组表示: (Entity1;RelationType;Entity2) 。“1”是指单词属于三元组中的第一个实体, “2”是指关系类型后面的第二个实体, 因此, 标签总数为<i>N</i>=2*4*<i>r</i>+1, 其中<i>r</i>是预定义关系集的大小。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 标签策略" src="Detail/GetImg?filename=images/JSJY201907009_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 标签策略  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Labeling scheme</p>

                </div>
                <div class="p1">
                    <p id="79">输入语句标签以及结果如图2所示。输入语句包含两个三元组:{United States, Country-President, Trump}和{Apple Inc, Company-Founder, Steven Paul Jobs}, 其中“Country-President”和“Company-Founder”是预定义的关系类型。单词“United”“States”“Trump”“Apple”“Inc”“Steven”“Paul”和“Jobs”都与最终提取的结果相关, 因此, 它们是根据本文的特殊标签进行标注的。例如, “United”这个词是实体“United States”的第一个词, 与“Country-President”的关系有关, 所以它的标签是“B-CP- 1”。另一个与“United States”相对应的实体“Trump”被标签为“S-CP- 2”。另外, 其他与最终结果无关的词被标签为“O”。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">2.2 <b>从标签获取结果</b></h4>
                <div class="p1">
                    <p id="81">从图2的标签序列中, 可以知道“Trump”和“United States”共享相同的关系类型“Country-President”;“Apple Inc”和“Steven Paul Jobs”共享相同的关系类型“Company-Founder”。最后将具有相同关系类型的实体组合成一个三元组以得到最终结果, 因此, “Trump”和“United States”可以合并成三元组, 关系类型为“Country-President”。因为“Trump”的关系角色是“2”, “United States”是“1”, 最终结果是{United States, Country-President, Trump}。同样可以得到三元组{Apple Inc, Company-Founder, Steven Paul Jobs}。</p>
                </div>
                <div class="p1">
                    <p id="82">此外, 如果一个句子包含两个或两个以上具有相同关系类型的三元组, 模型会根据就近的原则将每两个实体组合成一个三元组。例如, 如果图2中的关系类型“Country-President”是“Company-Founder”, 那么在给定的句子中会有四个具有相同关系类型的实体。“United States”最接近实体“Trump”, “Apple Inc”最接近“Steven Paul Jobs”, 因此结果将是{United States, Company-Founder, Trump}、{Apple Inc, Company-Founder, Steven Paul Jobs}。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">2.3 <b>词向量</b></h4>
                <div class="p1">
                    <p id="84">词向量是神经网络的输入。对于词嵌入的方法, 本文选择CBOW (Continuous Bag-Of-Words model) 而不是Skip-Gram。本文的选择是基于这样一个考虑:CBOW是根据上下文预测一个词, 或者通过查看上下文最大化目标词的概率进行预测, 而Skip-Gram的输入是当前词的词向量, 而输出是周围词的词向量。也就是说, 通过当前词来预测周围词, 即用于预测上下文。Skip-Gram需要更多的数据来训练, 这样它就可以学会理解很多单词, 甚至是罕见的单词。对于NER任务, 是根据上下文预测词的标签, 而不是预测上下文, 因此, 本文训练CBOW嵌入模型以获得双向长短期记忆 (Bidirectional Long Short-Term Memory, Bi-LSTM) 编码器的输入表示。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2.4 Bi-LSTM-CRF<b>模型</b></h4>
                <h4 class="anchor-tag" id="86" name="86">2.4.1 CRF</h4>
                <div class="p1">
                    <p id="87">条件随机场结合了最大熵模型和隐马尔可夫模型的特点, 是一种无向图模型, 近年来在分词、词性标注和命名实体识别等序列标注任务中取得了很好的效果。条件随机场是一个典型的判别式模型, 其联合概率可以写成若干势函数联乘的形式, 其中最常用的是线性链条件随机场。若让<i>x</i>= (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>) 表示被观察的输入数据序列, <i>y</i>= (<i>y</i><sub>1</sub>, <i>y</i><sub>2</sub>, …, <i>y</i><sub><i>n</i></sub>) 表示一个状态序列, 在给定一个输入序列的情况下, 序列标注通常公式化为:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">|</mo><mi>x</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mspace width="0.25em" /><mi>μ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ζ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mspace width="0.25em" /><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>λ</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><mo>, </mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>μ</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><mo>, </mo><mi>i</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中:<i>t</i><sub><i>j</i></sub> (<i>y</i><sub><i>i</i>-1</sub>, <i>y</i><sub><i>i</i></sub>, <i>x</i>, <i>i</i>) 是一个转移函数, 代表在标注序列中, 第<i>i</i>-1个和第<i>i</i>个的标注与整个观测序列之间的特征关系;<i>s</i><sub><i>k</i></sub> (<i>y</i><sub><i>i</i></sub>, <i>x</i>, <i>i</i>) 是一个状态函数, 代表标注序列中第<i>i</i>个标注与此时相对应的观测序列中的值的特征;<i>λ</i><sub><i>j</i></sub>和<i>μ</i><sub><i>k</i></sub>的值均是从训练数据中进行估计, 较大的负值代表其对应的特征模板可信度低, 而较大的非负值代表其对应的特征事件可信度高, 其中<i>Z</i> (<i>x</i>) 代表归一化因子, 其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ζ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow><mi>exp</mi></mrow></mstyle><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>λ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>μ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">最终的最优化输出序列计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="92"><i>y</i><sup>*</sup>=arg max <i>p</i> (<i>y</i>|<i>x</i>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="93">以往的研究表明, 特征选择在传统的概念抽取中起着重要的作用。NER的性能在很大程度上取决于不同意见的领域知识的构建和研究。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">2.4.2 LSTM与Bi-LSTM</h4>
                <div class="p1">
                    <p id="95">循环神经网络 (Recurrent Neural Network, RNN) 模型是一种在序列标注任务上表现优异的神经网络模型, 因为序列标注任务中, 无论是序列内部还是序列的边界对上下文信息都是敏感的, 而RNN与传统的神经网络相比, 恰好有着时间序列这一特性, 它更能充分地利用前面序列的信息, 因此它更加适用于序列标注的任务。长短期记忆 (LSTM) 网络模型采用LSTM单元来替代原先RNN模型中的隐藏层, 该模型能够有效处理较长距离的依赖关系以及解决梯度消失问题。</p>
                </div>
                <div class="p1">
                    <p id="96">LSTM区别于RNN的地方, 主要就在于它在算法中加入了一个判断信息有用与否的“处理器”, 这个处理器作用的结构被称为细胞 (cell) 。一个cell当中被放置了三扇门, 分别叫作输入门 (<i>i</i>) 、遗忘门 (<i>f</i>) 和输出门 (<i>o</i>) 。一个信息进入LSTM的网络当中, 可以根据规则来判断是否有用。只有符合算法认证的信息才会留下, 不符的信息则通过遗忘门被遗忘。一个细胞的结构如图3所示。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LSTM单元内部结构" src="Detail/GetImg?filename=images/JSJY201907009_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 LSTM单元内部结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_097.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Internal structure of LSTM unit</p>

                </div>
                <div class="p1">
                    <p id="98"><i>i</i>、 <i>f</i>、<i>o</i>分别表示输入门、遗忘门和输出门。<b><i>W</i></b>和<b><i>b</i></b>表示权重矩阵和偏移向量。遗忘门是决定需要从细胞状态中丢弃什么信息, 它会读取<b><i>h</i></b><sub><i>t</i>-1</sub>和<b><i>x</i></b><sub><i>t</i></sub>, 输出一个在0到1之间的数值。1表示“完全保留”, 0表示“完全舍弃”。遗忘门的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="99"><i>f</i>=<i>σ</i> (<b><i>W</i></b><sub><i>f</i></sub>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>f</i></sub>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="100">其中:<b><i>h</i></b><sub><i>t</i>-1</sub>表示的是上一个LSTM单元的输出, <b><i>x</i></b><sub><i>t</i></sub>表示的是当前细胞的输入, <b><i>C</i></b><sub><i>t</i>-1</sub>是前一个单元的记忆, <b><i>h</i></b><sub><i>t</i></sub>是当前网络的输出, <b><i>C</i></b><sub><i>t</i></sub>是当前单元的记忆。Sig表示sigmoid函数, Mul表示向量乘法, Con表示向量加法, tanh为激活函数。</p>
                </div>
                <div class="p1">
                    <p id="101">输入门决定让多少新的信息加入到cell状态中来。实现这个需要包括两个步骤:首先, 一个叫作“输入门”的sigmoid层决定哪些信息需要更新;一个tanh层生成一个向量, 也就是备选的用来更新的内容, <b><i>C</i></b><sub><i>t</i></sub>。在下一步, 把这两部分联合起来, 对cell的状态进行一个更新。</p>
                </div>
                <div class="p1">
                    <p id="102">接下来是更新旧细胞状态, <b><i>C</i></b><sub><i>t</i>-1</sub>更新为<b><i>C</i></b><sub><i>t</i></sub>。需要把旧状态与<b><i>f</i></b><sub><i>t</i></sub>相乘, 丢弃确定需要丢弃的信息。得到新的候选值后, 根据决定更新每个状态的程度进行变化。公式如下:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi mathvariant="bold-italic">C</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi mathvariant="bold-italic">C</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">输出门需要确定输出什么值。这个输出将会基于当前的细胞状态, 也是一个过滤后的版本。首先, 模型运行一个sigmoid层来确定细胞状态的哪个部分将输出;接着, 模型把细胞状态通过tanh进行处理 (得到一个在-1到1之间的值) 并将它和sigmoid层的输出相乘, 最终仅仅会输出确定输出的那部分。公式如下:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">双向长短期记忆 (Bi-LSTM) 网络模型是由前向的LSTM与后向的LSTM结合而成, Bi-LSTM的计算流程与单向长短期记忆网络LSTM模型在本质上是一样的, 也是利用LSTM的公式计算每个LSTM单元的细胞状态与隐藏层输出, 不同的是, Bi-LSTM首先针对逆时序的隐藏层增加了和正时序的隐藏层处理相对应的权重参数矩阵与偏置向量, 正时序和逆时序将通过各自的权重参数矩阵与偏置向量得到隐藏层的输出向量<b><i>h</i></b><sub><i>t</i></sub>, 再对这两个输出向量进行合并操作, 对于不同的应用, 它们的合并方式会略有差异, 本文将采用连接的方式将两个输出向量进行合并。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107">2.4.3 Bi-LSTM-CRF</h4>
                <div class="p1">
                    <p id="108">上面介绍了在序列标注问题上效果比较优异的传统统计模型的代表条件随机场 (<i>CRF</i>) 模型和被广泛应用于序列标注任务中的<i>Bi</i>-<i>LSTM</i>网络模型。其中, <i>CRF</i>模型的优点在于能够通过特征模板去扫描整个输入文本, 从而对整个文本局部特征的线性加权组合有着更多的考量, 最关键的是, 序列标注中的<i>X</i>和<i>Y</i>代表的都是整个输入文本和标注序列, 并非独立的词语或标注, 所以CRF模型优化的目标是出现概率最高的一个序列, 而不是找出序列的每个位置出现最高概率的标注;而它的缺点在于, 首先特征模板的选取需要对训练语料有一定的先验知识, 需要从语料中相关信息的统计数据中分析出对标注有着重要影响的特征, 特征的数量多了会使模型出现过拟合的现象, 特征数量少了则会使模型出现欠拟合的现象, 特征之间如何组合是一项比较困难的工作;其次, 条件随机场模型在训练过程中, 由于受限于特征模板制定的窗口大小, 所以难以考察长远的上下文信息。Bi-LSTM网络模型的优缺点在某种程度上与CRF模型恰恰相反, 它在序列标注任务的表现上异常强大, 可以有效地将长远的上下文信息利用进来, 同时它还具备了神经网络本身的对于非线性数据的拟合能力, Bi-LSTM模型的输出层输出的标注<b><i>y</i></b><sub><i>t</i></sub>由当前时刻的输入文本向量<b><i>x</i></b><sub><i>t</i></sub>和将正时序LSTM单元与逆时序LSTM单元的记忆输出合并而成的隐藏层的输出<b><i>h</i></b><sub><i>t</i></sub>决定, 而与其他时刻<i>k</i>的输出层输出的标注<b><i>y</i></b><sub><i>k</i></sub>没有关系, 因此, Bi-LSTM模型的优化目标是对于每个时刻都寻找到在这个时刻出现概率最大的标注, 再由这些标注构成序列, 这往往会导致模型对标注序列的输出发生不连贯的现象。</p>
                </div>
                <div class="p1">
                    <p id="109">这两种模型的优缺点恰好互补, 于是将两者结合起来的模型Bi-LSTM-CRF出现了, 即在传统的Bi-LSTM模型的隐藏层上在加入一层线性CRF层, 如图4所示。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Bi-LSTM-CRF结构" src="Detail/GetImg?filename=images/JSJY201907009_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Bi-LSTM-CRF结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Structure of Bi-LSTM-CRF</p>

                </div>
                <h4 class="anchor-tag" id="111" name="111">2.5 <b>句子选择器</b></h4>
                <div class="p1">
                    <p id="112">本文将句子选择作为一个强化学习问题来处理。句子选择器称为代理“<i>Agent</i>”, 它与由数据和序列标注模型组成的环境“<i>Environment</i>”进行交互。“<i>Agent</i>”遵循一个策略来决定在每个状态“<i>State</i>” (包括当前句子、所选句子集) 时执行什么操作“<i>Action</i>” (选择当前句子或不选择当前句子) , 然后在作出所有选择时从<i>Bi</i>-<i>LSTM</i>-<i>CRF</i>模型获得反馈“<i>Reward</i>”。</p>
                </div>
                <div class="p1">
                    <p id="113">如前所述, 只有在完成对所有训练语料的选择后, 句子选择器模型才能从序列标注模型中获得延迟反馈, 因此, 对于整个训练数据的每次遍历, 如果只更新一次策略函数, 这显然是低效的。为了获得更多的反馈并提高训练过程的效率, 本文将训练语料<i>X</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}分到<i>N</i>个集合<i>B</i>={<i>B</i><sup>1</sup>, <i>B</i><sup>2</sup>, …, <i>B</i><sup><i>N</i></sup>}中, 并且当完成一个集合的筛选后就计算一次反馈。集合根据实体进行划分, 每个集合对应一个不同的实体, 每个包<b><i>b</i></b><sub><i>k</i></sub>是一个包含同一个实体的句子序列{<i>x</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>, <i>x</i><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup></mrow></math></mathml>, …, <i>x</i><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false">|</mo><mi>B</mi><mi>k</mi><mo stretchy="false">|</mo></mrow><mi>k</mi></msubsup></mrow></math></mathml>}, 但是实体的标签是有噪声的。本文将动作定义为根据策略函数选择句子或不选择句子。一旦在一个包上完成选择, 就会计算反馈。当句子选择器的训练过程完成后, 将每个包中的所有选定语句合并, 得到一个干净的数据集<i>X</i>, 然后, 将干净的数据用于训练序列标注模型。</p>
                </div>
                <div class="p1">
                    <p id="117">本文将介绍句子选择器 (即状态、行动、反馈、优化) 如下。</p>
                </div>
                <div class="p1">
                    <p id="118">1) 状态。</p>
                </div>
                <div class="p1">
                    <p id="119">状态<b><i>s</i></b><sub><i>i</i></sub>表示当前句子和已选定的句子。本文将状态表示为连续实值向量<b><i>F</i></b> (<b><i>s</i></b><sub><i>i</i></sub>) , 它编码以下信息:a) 从序列标注模型中获得的当前句子的向量表示;b) 已选句子集的表示, 它是所有已选句子的向量的平均值。</p>
                </div>
                <div class="p1">
                    <p id="120">2) 动作。</p>
                </div>
                <div class="p1">
                    <p id="121">本文定义了一个动作<b><i>a</i></b><sub><i>i</i></sub>∈{0, 1}来表示句子选择器是否会选择包<i>B</i>的第<i>i</i>个句子, 通过策略函数<i>π</i><sub><i>Θ</i></sub> (<b><i>s</i></b><sub><i>i</i></sub>, <b><i>a</i></b><sub><i>i</i></sub>) 来决定<b><i>a</i></b><sub><i>i</i></sub>的取值, 将一个逻辑函数作为策略函数表示如下:</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>π</mi><msub><mrow></mrow><mi>Θ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mi>Θ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mo>*</mo><mi mathvariant="bold-italic">F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mo>*</mo><mi mathvariant="bold-italic">F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">其中:<b><i>F</i></b> (<b><i>s</i></b><sub><i>i</i></sub>) 表示状态向量, <i>σ</i> (·) 表示sigmoid函数, 参数<i>Θ</i>={<b><i>W</i></b>, <b><i>b</i></b>}。</p>
                </div>
                <div class="p1">
                    <p id="124">3) 反馈。</p>
                </div>
                <div class="p1">
                    <p id="125">反馈函数代表所选句子质量的标志。对于一个集合<i>B</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub>|<i>B</i>|</sub>}, 本文为每个句子选择一个动作, 以确定是否应该选择当前句子。假设模型在完成所有选择后有一个最终反馈, 因此, 句子选择器模型只在最终状态<b><i>S</i></b><sub>|<i>B</i>|+1</sub>收到延迟反馈。其他状态的反馈为零, 因此, 反馈的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo stretchy="false"> (</mo><mi>s</mi><mo stretchy="false">|</mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mspace width="0.25em" /><mi>i</mi><mo>&lt;</mo><mrow><mo>|</mo><mi>B</mi><mo>|</mo></mrow><mo>+</mo><mn>1</mn></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mrow><mi>B</mi><mo>^</mo><mspace width="0.25em" /></mrow><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mrow><mi>B</mi><mo>^</mo><mspace width="0.25em" /></mrow></mrow></munder><mtext>l</mtext></mstyle><mtext>g</mtext><mspace width="0.25em" /><mi>p</mi><mo stretchy="false"> (</mo><mi>r</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>i</mi><mo>=</mo><mrow><mo>|</mo><mi>B</mi><mo>|</mo></mrow><mo>+</mo><mn>1</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">其中:<i>B</i>^ 为选择的句子集合, 是集合<i>B</i>的子集;<i>r</i>是集合代表的实体;<i>p</i> (<i>r</i>|<i>x</i><sub><i>j</i></sub>) 是由序列标注模型计算出来的, 对于特殊情况<image id="300" type="formula" href="images/JSJY201907009_30000.jpg" display="inline" placement="inline"><alt></alt></image>, 将反馈设置为训练集所有句子的平均值, 这样可以过滤掉全是噪声的集合。</p>
                </div>
                <div class="p1">
                    <p id="128">在选择过程中, 不仅最终的行为有助于反馈, 所有先前的行为都有助于反馈, 因此, 这种反馈是延迟的, 并且可以通过强化学习技术很好地处理。</p>
                </div>
                <div class="p1">
                    <p id="129">4) 优化。</p>
                </div>
                <div class="p1">
                    <p id="130">对于一个集合<i>B</i>, 本模型希望得到最大的反馈, 目标函数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>Θ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>V</mi><msub><mrow></mrow><mi>Θ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>|</mo><mi>B</mi></mrow><mo stretchy="false">) </mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>, </mo><mo>⋯</mo></mrow></msub><mo stretchy="false">[</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mrow><mo>|</mo><mrow><mi>B</mi><mo>^</mo><mspace width="0.25em" /></mrow><mo>|</mo></mrow><mo>+</mo><mn>1</mn></mrow></munderover><mi>r</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>|</mo><mi>B</mi></mrow><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132">其中, <b><i>a</i></b><sub><i>i</i></sub>～<i>π</i><sub><i>Θ</i></sub> (<b><i>s</i></b><sub><i>i</i></sub>, <b><i>a</i></b><sub><i>i</i></sub>) , <b><i>s</i></b><sub><i>i</i>+1</sub>～<i>P</i> (<b><i>s</i></b><sub><i>i</i>+1</sub>|<b><i>s</i></b><sub><i>i</i></sub>, <b><i>a</i></b><sub><i>i</i></sub>) , 转移函数<i>P</i> (<b><i>s</i></b><sub><i>i</i>+1</sub>|<b><i>s</i></b><sub><i>i</i></sub>, <b><i>a</i></b><sub><i>i</i></sub>) 等于1, 因为状态<b><i>s</i></b><sub><i>i</i>+1</sub>完全由<b><i>s</i></b><sub><i>i</i></sub>和<b><i>a</i></b><sub><i>i</i></sub>决定, <i>V</i><sub><i>Θ</i></sub>是值函数, <i>V</i><sub><i>Θ</i></sub> (<b><i>s</i></b><sub>1</sub>|<i>B</i>) 表示从开始状态<b><i>S</i></b><sub>1</sub>根据策略函数<i>π</i><sub><i>Θ</i></sub> (<b><i>s</i></b><sub><i>i</i></sub>, <b><i>a</i></b><sub><i>i</i></sub>) 能得到的最大的反馈。</p>
                </div>
                <div class="p1">
                    <p id="133">那么梯度按照如下方式计算。</p>
                </div>
                <div class="p1">
                    <p id="134">1) 对于每组句子, 根据策略函数计算每个句子的状态和动作, 得到{<b><i>s</i></b><sub>1</sub>, <b><i>a</i></b><sub>1</sub>, <b><i>s</i></b><sub>2</sub>, <b><i>a</i></b><sub>2</sub>, …, <b><i>s</i></b><sub>|<i>B</i>|</sub>, <b><i>a</i></b><sub>|<i>B</i>|</sub>, <b><i>s</i></b><sub>|<i>B</i>|+1</sub>}。</p>
                </div>
                <div class="p1">
                    <p id="135">2) 将选出的句子作为序列标注模型的输入, 根据结果得到反馈<i>r</i> (<b><i>s</i></b><sub>|<i>B</i>|+1</sub>|<i>B</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="136">3) 按照如下的规则去更新<i>θ</i>:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mspace width="0.25em" /><mo>←</mo><mspace width="0.25em" /><mi>θ</mi><mo>+</mo><mi>α</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mrow><mi>B</mi><mo>^</mo><mspace width="0.25em" /></mrow><mo>|</mo></mrow></mrow></munderover><mi>v</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>∇</mo><msub><mrow></mrow><mi>θ</mi></msub><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mspace width="0.25em" /><mi>π</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="138" name="138">2.6 <b>句子选择器+序列标注模型</b></h4>
                <div class="p1">
                    <p id="139">如图5所示, 左边为句子选择器, 右边为序列标注模型, 句子选择器由策略函数、反馈函数等组成, 用来在训练集中挑选高质量的句子, 作为序列标注模型的输入, 序列标注模型接收句子选择器的输入, 然后给句子选择器提供反馈, 指导句子选择器选出高质量的句子。</p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 句子选择器+序列标注联合模型" src="Detail/GetImg?filename=images/JSJY201907009_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 句子选择器+序列标注联合模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 5 <i>Joint model of sentence selector and sequence labeling</i></p>

                </div>
                <h3 id="141" name="141" class="anchor-tag">3 实验介绍</h3>
                <h4 class="anchor-tag" id="142" name="142">3.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="143">为了评估本文方法的性能, 本文使用由远程监督方法生成的公共数据集纽约时报 (<i>New York Times</i>, <i>NYT</i>) <citation id="289" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 采用远程监督方式, 无需人工标注, 即可获得大量的训练数据。测试集是人工标注的以确保其质量。总的来说, 训练数据包含353 000个三元组, 测试集包含3 880个三元组。此外, 关系集的大小为24。</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144">3.2 <b>评估策略</b></h4>
                <div class="p1">
                    <p id="145">本文采用准确率 (<i>Precision</i>, <i>P</i>) 、召回率 (<i>Recall</i>, <i>R</i>) 和<i>F</i>1值对结果进行评估。与传统方法不同的是, 本文方法可以在不知道实体类型信息的情况下抽取三元组。换句话说, 本文没有使用实体类型的标签来训练模型, 因此在评估中不需要考虑实体类型。当三元组的关系类型和两个对应实体的位置偏移都正确时, 则认为它是正确的。本文从测试集随机抽取10%的数据来创建验证集, 并根据<i>Ren</i>等<citation id="290" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的建议将剩余数据用作评估。本文将每个实验运行10次, 然后记录平均结果。</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146">3.3 <b>参数设置</b></h4>
                <div class="p1">
                    <p id="147">本文的模型由一个<i>Bi</i>-<i>LSTM</i>-<i>CRF</i>序列标注模型和一个句子选择器模型组成。词向量是通过在<i>NYT</i>训练语料上运行<i>Word</i>2<i>vec</i><citation id="291" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>生成的。词向量的维度为300。本文在嵌入层上使用<i>droupout</i>来防止过拟合, 大小为0.5。<i>LSTM</i>隐藏层维度为300。对于句子选择器的参数, 本文分别在预训练阶段和联合训练阶段将学习率设置为0.02和0.01。延迟系数τ为0.001。</p>
                </div>
                <h4 class="anchor-tag" id="148" name="148">3.4 <b>基准线</b></h4>
                <div class="p1">
                    <p id="149">将本文的方法与几种经典的三元组提取方法进行了比较, 这些方法可分为以下几类:基于本文的标记方案的流水线方法、联合提取方法和<i>Bi</i>-<i>LSTM</i>-<i>CRF</i>方法。</p>
                </div>
                <div class="p1">
                    <p id="150">对于流水线方法, 本文遵循<i>Ren</i>等<citation id="292" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的设置:通过<i>CoType</i>方法获得<i>NER</i>结果, 然后使用几种经典的关系分类方法检测关系。这些方法包括:</p>
                </div>
                <div class="p1">
                    <p id="151">1) 2009年<i>Mintz</i>等<citation id="293" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出的<i>DS</i>-<i>Logistic</i>模型, 这是一种远程监督和基于特征的方法;</p>
                </div>
                <div class="p1">
                    <p id="152">2) 2015年<i>Tang</i>等<citation id="294" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提出的<i>LINE</i> (<i>Large</i>-<i>scale Information Network Embedding</i>) 模型, 这是一种网络嵌入方法, 适用于任意类型的信息网络;</p>
                </div>
                <div class="p1">
                    <p id="153">3) 2015年<i>Gormley</i>等<citation id="295" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出的<i>FCM</i> (<i>Fuzzy C</i>-<i>Mean</i>) 模型, 这是一种复合方法, 将词汇化语言语境和嵌入词结合起来进行关系提取的模式。</p>
                </div>
                <div class="p1">
                    <p id="154">本文采用的联合提取方法如下:</p>
                </div>
                <div class="p1">
                    <p id="155">4) 2014年<i>Li</i>等<citation id="296" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的<i>DS</i>-<i>Joint</i>模型, 这是一种有监督的方法, 它利用人工标注数据集上的结构化感知器联合提取实体和关系;</p>
                </div>
                <div class="p1">
                    <p id="156">5) 2011年<i>Hoffmann</i>等<citation id="297" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>提出的<i>MULTIR</i> (<i>MULTi</i>-<i>Instance learning which handles overlapping Relations</i>) 模型, 这是一种典型的基于多句子学习算法的远程监控方法, 用于对抗噪声训练数据;</p>
                </div>
                <div class="p1">
                    <p id="157">6) 2017年<i>Ren</i>等<citation id="298" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出的<i>CoType</i>模型, 这是一个独立于领域的框架, 将实体信息、关系信息、文本特征和类型标签共同嵌入到有意义的表示中。</p>
                </div>
                <div class="p1">
                    <p id="158">此外, 本文方法还与经典的端到端标注模型进行了比较:2016年<i>Lample</i>等<citation id="299" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出的<i>LSTM</i>-<i>CRF</i>模型, 利用双向<i>LSTM</i>对输入句子进行编码, 利用条件随机场预测实体标签序列, 实现实体识别的<i>LSTM</i>-<i>CRF</i>算法。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159">3.5 <b>实验结果</b></h4>
                <div class="p1">
                    <p id="160">本文的实验分为三个部分进行, 包括序列标注模型的训练、句子选择器模型的训练以及联合训练。其中前面两个模型的训练为预训练, 目的是为了联合模型能够尽快地收敛。本文通过实验得到了不同方法的对比结果, 其中<i>LSTM</i>-<i>CRF</i>模型与<i>RL</i>-<i>LSTM</i>-<i>CRF</i> (<i>Reinforcement Learning for LSTM</i>-<i>CRF</i>) 模型不仅记录下了准确率、召回率、<i>F</i>1值, 还将实验的标准差记录下来, 标准差是将每个模型运行10次的结果, 如表1所示。</p>
                </div>
                <div class="area_img" id="161">
                                            <p class="img_tit">
                                                <b>表</b>1 <b>各模型实验结果比较</b>
                                                    <br />
                                                <i>Tab</i>.1 <i>Experimental result comparison of different models</i>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907009_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201907009_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907009_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 各模型实验结果比较" src="Detail/GetImg?filename=images/JSJY201907009_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="162">可以看出, 本文的方法RL-LSTM-CRF在F1分数上优于所有其他方法, 与联合抽取CoType模型相比本文模型的F1值提升了1%, 与串行抽取LINE模型相比本文模型的F1值提升了14%。实验结果证明了本文方法的有效性。此外, 从表1中还可以看出, 联合提取方法优于流水线方法, 标注方法优于大多数联合提取方法。它还验证了本文的标签方案对于联合提取实体和关系的任务的有效性。与传统方法相比, 端到端模型的精度有了显著提高, 基于神经网络的方法能很好地拟合数据, 因此, 它们可以很好地学习训练集的共同特征。</p>
                </div>
                <h3 id="163" name="163" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="164">本文提出了一个新的模型, 该模型由句子选择器和序列标注模型组成, 通过强化学习框架在噪声数据集中联合抽取实体和关系。句子选择器为序列标注模型选择高质量的数据。Bi-LSTM-CRF模型预测句子级别的序列标签, 并作为弱监督信号向选择器提供反馈, 以监督句子选择过程。大量的实验表明, 本文模型能够过滤掉有噪声的句子, 并比现有的模型更好地执行联合实体和关系提取。</p>
                </div>
                <div class="p1">
                    <p id="165">此外, 本文的解决方案可以推广到使用噪声数据或远程监督的其他任务中, 这将是未来的工作。后期打算用更优的端到端的模型来替换本文现有的序列标注模型, 例如用LSTM解码层替换CRF解码层等。本文只考虑一个实体属于一个三元组的情况, 并将重叠关系的识别留给以后的工作。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="207">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Open information ex-traction from the web">

                                <b>[1]</b> BANKO M, CAFARELLAM J, SODERLAND S, et al.Open information extraction from the Web[C]// Proceedings of the 20th International Joint Conference on Artificial Intelligence.New York:ACM, 2007:2670-2676.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey of named entity recognition and classification">

                                <b>[2]</b> NADEAU D, SEKINE S.A survey of named entity recognition and classification[J].Lingvisticae Investigationes, 2005, 30 (1) :3-26.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=UTD:Classifying semantic relations by combining lexical and semantic resources">

                                <b>[3]</b> RINK B, HARABAGIU A.UTD:classifying semantic relations by combining lexical and semantic resources[C]// Proceedings of the 5th International Workshop on Semantic Evaluation.New York:ACM, 2010:256-259.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incremental joint extraction of entity mentions and relations">

                                <b>[4]</b> LI Q, JI H.Incremental joint extraction of entity mentions and relations[C]// Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2014:402-412.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures">

                                <b>[5]</b> MIWA M, BANSAL M.End-to-end relation extraction using LSTMs on sequences and tree structures[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:1105-1116.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint extraction of entities and relations based on a novel tagging scheme">

                                <b>[6]</b> ZHENG S C, WANG F.Joint extraction of entities and relations based on a novel tagging scheme[C]// Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2017:1227-1236.
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant supervision for relation extraction without labeled data">

                                <b>[7]</b> MINTZ M, BILLS S, SNOW R, et al.Distant supervision for relation extraction without labeled data[C]// Proceedings of the 2009/47th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2009:1003-1011
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reinforcement learning for relation classification from noisy data">

                                <b>[8]</b> FENG J, HUANG M, ZHAO L, et al.Reinforcement learning for relation classification from noisy data[C]// Proceedings of the 2018/32nd Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2018:5779-5786
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reinforcement Learning: An Introduction">

                                <b>[9]</b> SUTTON R S, BARTO A G.Reinforcement learning:an introduction[J].IEEE Transactions on Neural Networks, 1998, 9 (5) :1054-1054.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint entity recognition and disambiguation">

                                <b>[10]</b> LUO G, HUANG X J, LIN C Y, et al.Joint entity recognition and disambiguation[C]// Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:879-888.
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200809035&amp;v=MTYxODJDVVI3cWZadVpzRnkvblZMM0FJVGZUZTdHNEh0bk1wbzlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 冯元勇, 孙乐, 张大鲲, 等.基于小规模尾字特征的中文命名实体识別研究[J].电子学报, 2008, 36 (9) :1833-1838. (FENG Y Y, SUN L, ZHANG D K, et al.Study on the Chinese named entity recognition using small scale tail hints[J].Acta Electronica Sinaca, 2008, 36 (9) :1833-1838.) 
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY200510064&amp;v=MDg0NDNVUjdxZlp1WnNGeS9uVkwzQUx6N0JkN0c0SHRUTnI0OURZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 向晓雯, 史晓东, 曾华琳.一个统计与规则相结合的中文命名实体识别系统[J].计算机应用, 2005, 25 (10) :2404-2406. (XIANG X W, SHI X D, ZENG H L.Chinese named entity recognition system using statistics-based and rules-based method [J].Journal of Computer Applications, 2005, 25 (10) :2404-2406.) 
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201011022&amp;v=MTE0NjZHNEg5SE5ybzlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMM0FMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 佘俊, 张学清.音乐命名实体识别方法[J].计算机应用, 2010, 20 (11) :2928-2931. (SHE J, ZHANG X Q.Musical named entity recognition method [J].Journal of Computer Applications, 2010, 30 (11) :2928-2931.) 
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201403043&amp;v=MjgxNTBYTXJJOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkwzQUx6VFpaTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 张金龙, 王石, 钱存发.基于CRF和规则的中文医疗机构名称识[J].计算机应用与软件, 2014, 31 (3) :159-162. (ZHANG J L, WANG S, QIAN C F.CRF and rules-based recognition of medical institutions name in Chinese [J].Computer Applications and Software, 2014, 31 (3) :159-162.) 
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Named Entity Recognition with Bidirectional LSTM-CNNs">

                                <b>[15]</b> CHIU J P C, NICHOLS E.Named entity recognition with bidirectional LSTM-CNNs[C]// Proceedings of the 2016 Transactions of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:357-370
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]">

                                <b>[16]</b> HUANG Z, XU W, YU K.Bidirectional LSTM-CRF models for sequence tagging[EB/OL].[2018- 12- 02].https://arxiv.org/pdf/1508.01991.pdf.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural architectures for named entity recognition">

                                <b>[17]</b> LAMPLE G, BALLESTEROS M, SUBRAMANIAN S, et al.Neural architectures for named entity recognition[C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:260-270.
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CoType:Joint extraction of typed entities and relations with knowledge bases">

                                <b>[18]</b> REN X, WU Z, HE W, et al.CoType:joint extraction of typed entities and relations with knowledge bases[C]// Proceedings of the 26th International Conference on World Wide Web.New York:ACM, 2017:1015-1024.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint Inference of Entities,Relations,and Coreference">

                                <b>[19]</b> SINGH S, RIEDEL S, MARTIN B, et al.Joint inference of entities, relations, and coreference[C]// Proceedings of the 2013 Workshop on Automated Knowledge Base Construction.New York:ACM, 2013:1-6.
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural relation extraction with selective attention over instances">

                                <b>[20]</b> LIN Y, SHEN S, LIU Z, et al.Neural relation extraction with selective attention over instances[C]// Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:Association for Computational Linguistics, 2016:2124-2133.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions">

                                <b>[21]</b> JI G, LIU K, HE S, et al.Distant supervision for relation extraction with sentence-level attention and entity descriptions[C]// Proceedings of the Thirty-First Association for the Advancement of Artificial Intelligence Conference on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:3060-3066.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving information extraction by acquiring external evidence with reinforcement learning">

                                <b>[22]</b> NARASIMHAN K, YALA A, BARZILAY R.Improving information extraction by acquiring external evidence with reinforcement learning[C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:2355-2365.
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">

                                <b>[23]</b> MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119.
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Line:Large-scale information network embedding">

                                <b>[24]</b> TANG J, QU M, WANG M, et al.LINE:large-scale information network embedding[C]// Proceedings of the 24th International Conference on World Wide Web.New York:ACM, 2015:1067-1077.
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Relation Extraction with Feature-Rich Compositional Embedding Models">

                                <b>[25]</b> GORMLEY M R, YU M, DREDZE M.Improved relation extraction with feature-rich compositional embedding models[C]// Proceedings of the 2015 Conference on Empirical Method in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2015:1774-1784.
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge-based weak supervision for information extraction of overlapping relations">

                                <b>[26]</b> HOFFMANN R, ZHANG C, LING X, et al.Knowledge-based weak supervision for information extraction of overlapping relations[C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2011:541-550.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907009&amp;v=MzAzODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTDNBTHo3QmQ3RzRIOWpNcUk5RmJZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
