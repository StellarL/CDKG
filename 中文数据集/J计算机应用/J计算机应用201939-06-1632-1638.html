<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136674770783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201906014%26RESULT%3d1%26SIGN%3dzYKJxk3fTKnAhdadWxVL3yW%252bD8c%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201906014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906014&amp;v=MTU4OTBac0Z5L2hXcjdLTHo3QmQ3RzRIOWpNcVk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="1.1 node2vec&lt;b&gt;算法&lt;/b&gt;">1.1 node2vec<b>算法</b></a></li>
                                                <li><a href="#55" data-title="1.2 DenseNet&lt;b&gt;模型&lt;/b&gt;">1.2 DenseNet<b>模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="2 基于DenseNet的链路预测方法 ">2 基于DenseNet的链路预测方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="2.1 &lt;b&gt;子图提取算法&lt;/b&gt;">2.1 <b>子图提取算法</b></a></li>
                                                <li><a href="#90" data-title="2.2 &lt;b&gt;节点排序算法&lt;/b&gt;">2.2 <b>节点排序算法</b></a></li>
                                                <li><a href="#107" data-title="2.3 &lt;b&gt;节点对维度转化&lt;/b&gt;">2.3 <b>节点对维度转化</b></a></li>
                                                <li><a href="#124" data-title="2.4 &lt;b&gt;模型预测方法&lt;/b&gt;">2.4 <b>模型预测方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#131" data-title="3.1 &lt;b&gt;实验数据集&lt;/b&gt;">3.1 <b>实验数据集</b></a></li>
                                                <li><a href="#139" data-title="3.2 &lt;b&gt;基准方法&lt;/b&gt;">3.2 <b>基准方法</b></a></li>
                                                <li><a href="#163" data-title="3.3 &lt;b&gt;评估指标&lt;/b&gt;">3.3 <b>评估指标</b></a></li>
                                                <li><a href="#172" data-title="3.4 &lt;b&gt;实验环境和设置&lt;/b&gt;">3.4 <b>实验环境和设置</b></a></li>
                                                <li><a href="#184" data-title="3.5 &lt;b&gt;结果分析&lt;/b&gt;">3.5 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#194" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="图1 密集连接卷积神经网络的网络结构">图1 密集连接卷积神经网络的网络结构</a></li>
                                                <li><a href="#69" data-title="图2 所提方法整体流程">图2 所提方法整体流程</a></li>
                                                <li><a href="#123" data-title="图3 网络子图信息转化整体流程">图3 网络子图信息转化整体流程</a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;网络拓扑结构特征&lt;/b&gt;"><b>表</b>1 <b>网络拓扑结构特征</b></a></li>
                                                <li><a href="#183" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;网络结构参数细节&lt;/b&gt;"><b>表</b>2 <b>网络结构参数细节</b></a></li>
                                                <li><a href="#186" data-title="图4 参数&lt;i&gt;k&lt;/i&gt;对AUC值的影响">图4 参数<i>k</i>对AUC值的影响</a></li>
                                                <li><a href="#192" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同方法的链路预测&lt;/b&gt;AUC&lt;b&gt;值比较&lt;/b&gt;"><b>表</b>3 <b>不同方法的链路预测</b>AUC<b>值比较</b></a></li>
                                                <li><a href="#193" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;不同方法的链路预测&lt;/b&gt;Precision&lt;b&gt;值比较&lt;/b&gt;"><b>表</b>4 <b>不同方法的链路预测</b>Precision<b>值比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="219">


                                    <a id="bibliography_1" title="LYU L Y, ZHOU T.Link prediction in complex networks:a survey[J].Physica A:Statistical Mechanics and its Applications, 2011, 390 (6) :1150-1170." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100530194&amp;v=MDY3Mjl4QT1OaWZPZmJLN0h0RE9ybzlGWWVnUERYVTlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMW9kYQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        LYU L Y, ZHOU T.Link prediction in complex networks:a survey[J].Physica A:Statistical Mechanics and its Applications, 2011, 390 (6) :1150-1170.
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_2" title="AHN M W, JUNG W S.Accuracy test for link prediction in terms of similarity index:the case of WS and BA models[J].Physica A:Statistical Mechanics and its Applications, 2015, 429:177-183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accuracy test for link prediction in terms of similarity index:The case of WS and BA models">
                                        <b>[2]</b>
                                        AHN M W, JUNG W S.Accuracy test for link prediction in terms of similarity index:the case of WS and BA models[J].Physica A:Statistical Mechanics and its Applications, 2015, 429:177-183.
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_3" title="HOFFMAN M, STEINLEY D, BRUSCO M J.A note on using the adjusted rand index for link prediction in networks[J].Social Networks, 2015, 42:72-79." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600722187&amp;v=MjQzNzBNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSjFvZGF4QT1OaWZPZmJLOUg5UE9xWTlGWStrTkRYUStvQg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        HOFFMAN M, STEINLEY D, BRUSCO M J.A note on using the adjusted rand index for link prediction in networks[J].Social Networks, 2015, 42:72-79.
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_4" title="刘思, 刘海, 陈启买, 等.基于网络表示学习与随机游走的链路预测算法[J].计算机应用, 2017, 37 (8) :2234-2239. (LIU S, LIU H, CHEN Q M, et al.Link prediction algorithm based on network representation learning and random walk[J].Journal of Computer Applications, 2017, 37 (8) :2234-2239.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201708020&amp;v=MTUzNTBac0Z5L2hXcjdLTHo3QmQ3RzRIOWJNcDQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        刘思, 刘海, 陈启买, 等.基于网络表示学习与随机游走的链路预测算法[J].计算机应用, 2017, 37 (8) :2234-2239. (LIU S, LIU H, CHEN Q M, et al.Link prediction algorithm based on network representation learning and random walk[J].Journal of Computer Applications, 2017, 37 (8) :2234-2239.) 
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_5" title="NEWMAN M E.Clustering and preferential attachment in growing networks[J].Physical Review E:Statistical, Nonlinear, and Soft Matter Physics, 2001, 64 (2 Pt 2) :025102." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering and preferential attachment in growing networks">
                                        <b>[5]</b>
                                        NEWMAN M E.Clustering and preferential attachment in growing networks[J].Physical Review E:Statistical, Nonlinear, and Soft Matter Physics, 2001, 64 (2 Pt 2) :025102.
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_6" title="JACCARD P.Etude comparative de la distribution florale dans une portion des Alpes et du Jura[J].Bulletin de la Soci&#233;t&#233;Vaudoise des Sciences Naturelles, 1901, 37:547-579." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Etude comparative de la distribution florale dans une portion des Alpes et des Jura">
                                        <b>[6]</b>
                                        JACCARD P.Etude comparative de la distribution florale dans une portion des Alpes et du Jura[J].Bulletin de la Soci&#233;t&#233;Vaudoise des Sciences Naturelles, 1901, 37:547-579.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_7" title="ADAMIC L A, ADAR E.Friends and neighbors on the Web[J].Social Networks, 2003, 25 (3) :211-230." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100484987&amp;v=MTUwMDZud1plWnRGaW5sVXIzSUoxb2RheEE9TmlmT2ZiSzdIdERPcm85RllPTUxCWFErb0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        ADAMIC L A, ADAR E.Friends and neighbors on the Web[J].Social Networks, 2003, 25 (3) :211-230.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_8" title="涂存超, 杨成, 刘知远, 等.网络表示学习综述[J].中国科学:信息科学, 2017, 47 (8) :980-996. (TU C C, YANG C, LIU Z Y, et al.Network representation learning:an overview[J].SCIEN-TIA SINICA Informationis, 2017, 47 (8) :980-996.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201708003&amp;v=MzExMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyN0tOVGZBZHJHNEg5Yk1wNDlGWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        涂存超, 杨成, 刘知远, 等.网络表示学习综述[J].中国科学:信息科学, 2017, 47 (8) :980-996. (TU C C, YANG C, LIU Z Y, et al.Network representation learning:an overview[J].SCIEN-TIA SINICA Informationis, 2017, 47 (8) :980-996.) 
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_9" title="PEROZZI B, AI-RFOU R, SKIENA S.Deep Walk:online learning of social representations[C]//KDD 2014:Proceedings of the2014 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2014:701-710." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deepwalk:Online learning of social representations">
                                        <b>[9]</b>
                                        PEROZZI B, AI-RFOU R, SKIENA S.Deep Walk:online learning of social representations[C]//KDD 2014:Proceedings of the2014 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2014:701-710.
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_10" title="MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//NIPS13:Proceedings of the 26th International Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2013:3111-3119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">
                                        <b>[10]</b>
                                        MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//NIPS13:Proceedings of the 26th International Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2013:3111-3119.
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_11" title="TANG J, QU M, WANG M Z, et al.LINE:large-scale information network embedding[C]//WWW 2015:Proceedings of the24th International Conference on World Wide Web.Republic and Canton of Geneva, Switzerland:International World Wide Web Conferences Steering Committee, 2015:1067-1077." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LINE:large-scale information network embedding">
                                        <b>[11]</b>
                                        TANG J, QU M, WANG M Z, et al.LINE:large-scale information network embedding[C]//WWW 2015:Proceedings of the24th International Conference on World Wide Web.Republic and Canton of Geneva, Switzerland:International World Wide Web Conferences Steering Committee, 2015:1067-1077.
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_12" title="GROVER A, LESKOVEC J.Node2vec:scalable feature learning for networks[C]//SIGKDD 2016:Proceedings of the 22nd ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2016:855-864." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Node2vec:Scalable Feature Learning for Networks">
                                        <b>[12]</b>
                                        GROVER A, LESKOVEC J.Node2vec:scalable feature learning for networks[C]//SIGKDD 2016:Proceedings of the 22nd ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2016:855-864.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_13" title="侯建华, 邓雨, 陈思萌, 等.基于深度特征和相关滤波器的视觉目标跟踪[J].中南民族大学学报 (自然科学版) , 2018, 37 (2) :67-73. (HOU J H, DENG Y, CHEN S M.Visual object tracking based on deep features and correlation filter[J].Journal of South-Central University for Nationalities (Natural Science Edition) , 2018, 37 (2) :67-73.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNZK201802016&amp;v=MjQzOTMzenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyN0tQeVBSWmJHNEg5bk1yWTlFWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        侯建华, 邓雨, 陈思萌, 等.基于深度特征和相关滤波器的视觉目标跟踪[J].中南民族大学学报 (自然科学版) , 2018, 37 (2) :67-73. (HOU J H, DENG Y, CHEN S M.Visual object tracking based on deep features and correlation filter[J].Journal of South-Central University for Nationalities (Natural Science Edition) , 2018, 37 (2) :67-73.) 
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_14" title="HE K M, ZHANG X Y, REN S Q, et al.Deep residual learning for image recognition[C]//CVPR 2016:Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[14]</b>
                                        HE K M, ZHANG X Y, REN S Q, et al.Deep residual learning for image recognition[C]//CVPR 2016:Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2016:770-778.
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_15" title="HUANG G, LIU Z, VAN DER MAATEN L, et al.Densely connected convolutional networks[C]//CVPR 2017:Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:2261-2269." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">
                                        <b>[15]</b>
                                        HUANG G, LIU Z, VAN DER MAATEN L, et al.Densely connected convolutional networks[C]//CVPR 2017:Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:2261-2269.
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_16" title="SZEGEDY C, LIU W, JIA Y Q, et al.Going deeper with convolutions[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[16]</b>
                                        SZEGEDY C, LIU W, JIA Y Q, et al.Going deeper with convolutions[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:1-9.
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_17" title="齐金山, 梁循, 李志宇, 等.大规模复杂信息网络表示学习:概念、方法与挑战[J].计算机学报, 2018, 41 (10) :2394-2420. (QIN J S, LIANG X, LI Z Y, et al.Representation learning of large-scale complex information network:concepts, methods and challenges[J].Chinese Journal of Computers, 2018, 41 (10) :2394-2420.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201810015&amp;v=MDM1NDhIOW5OcjQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjdLTHo3QmRyRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        齐金山, 梁循, 李志宇, 等.大规模复杂信息网络表示学习:概念、方法与挑战[J].计算机学报, 2018, 41 (10) :2394-2420. (QIN J S, LIANG X, LI Z Y, et al.Representation learning of large-scale complex information network:concepts, methods and challenges[J].Chinese Journal of Computers, 2018, 41 (10) :2394-2420.) 
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_18" title="IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//ICML2015:Proceedings of the 2015 32nd International Conference on Machine Learning.Cambridge, MA:MIT Press, 2015:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">
                                        <b>[18]</b>
                                        IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//ICML2015:Proceedings of the 2015 32nd International Conference on Machine Learning.Cambridge, MA:MIT Press, 2015:448-456.
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_19" title="ZHANG M H, CHEN Y X.Link prediction based on graph neural networks[EB/OL].[2018-09-13].https://arxiv.org/abs/1802.09691." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Link prediction based on graph neural networks">
                                        <b>[19]</b>
                                        ZHANG M H, CHEN Y X.Link prediction based on graph neural networks[EB/OL].[2018-09-13].https://arxiv.org/abs/1802.09691.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-02-19 13:39</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(06),1632-1638 DOI:10.11772/j.issn.1001-9081.2018112279            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于密集连接卷积神经网络的链路预测模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%96%87%E6%B6%9B&amp;code=10167615&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王文涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E6%B7%8B%E6%B6%9B&amp;code=41275238&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴淋涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E7%83%A8&amp;code=37856031&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄烨</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%AE%B9%E6%B3%A2&amp;code=11387956&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱容波</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8D%97%E6%B0%91%E6%97%8F%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0185453&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中南民族大学计算机科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的基于网络表示学习的链路预测算法主要通过捕获网络节点的邻域拓扑信息构造特征向量来进行链路预测, 该类算法通常只注重从网络节点的单一邻域拓扑结构中学习信息, 而对多个网络节点在链路结构上的相似性方面研究不足。针对此问题, 提出一种基于密集连接卷积神经网络 (DenseNet) 的链路预测模型 (DenseNet-LP) 。首先, 利用基于网络表示学习算法node2vec生成节点表示向量, 并利用该表示向量将网络节点的结构信息映射为三维特征数据;然后, 利用密集连接卷积神经网络来捕捉链路结构的特征, 并建立二分类模型实现链路预测。在四个公开的数据集上的实验结果表明, 相较于网络表示学习算法, 所提模型链路预测结果的ROC曲线下方面积 (AUC) 值最大提高了18个百分点。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%93%BE%E8%B7%AF%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">链路预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BD%91%E7%BB%9C%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">网络表示学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%8A%82%E7%82%B9%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">节点表示;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王文涛 (1967—) , 男, 河北邯郸人, 副教授, 博士, 主要研究方向:计算机网络与控制;;
                                </span>
                                <span>
                                    *吴淋涛 (1994—) , 男, 湖南茶陵人, 硕士研究生, 主要研究方向:计算机网络、数据挖掘;2017110246@mail.scuec.edu.cn;
                                </span>
                                <span>
                                    黄烨 (1993—) , 男, 湖北大悟人, 硕士研究生, 主要研究方向:知识表示、神经网络;;
                                </span>
                                <span>
                                    朱容波 (1978—) , 男, 湖北潜江人, 教授, 博士, 主要研究方向:移动计算、无线网络协议设计与性能优化。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61772562);</span>
                                <span>中南民族大学中央高校基本科研业务费专项基金资助项目 (CZY18014) ;中南民族大学研究生学术创新基金后期资助项目 (3212018hqzz029);</span>
                    </p>
            </div>
                    <h1><b>Link prediction model based on densely connected convolutional network</b></h1>
                    <h2>
                    <span>WANG Wentao</span>
                    <span>WU Lintao</span>
                    <span>HUANG Ye</span>
                    <span>ZHU Rongbo</span>
            </h2>
                    <h2>
                    <span>College of Computer Science, South-Central University for Nationalities</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The current link prediction algorithms based on network representation learning mainly construct feature vectors by capturing the neighborhood topology information of network nodes for link prediction. However, those algorithms usually only focus on learning information from the single neighborhood topology of network nodes, while ignore the researches on similarity between multiple nodes in link structure. Aiming at these problems, a new Link Prediction model based on Densely connected convolutional Network (DenseNet-LP) was proposed. Firstly, the node representation vectors were generated by the network representation learning algorithm called node2 vec, and the structure information of the network nodes was mapped into three dimensional feature information by these vectors. Then, DenseNet was used to to capture the features of link structure and establish a two-category classification model to realize link prediction. The experimental results on four public datasets show that, the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) value of the prediction result of the proposed model is increased by up to 18 percentage points compared to the result of network representation learning algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=link%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">link prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=network%20representation%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">network representation learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=node%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">node representation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Wentao, born in 1967, Ph. D. , associate professor. His research interests include computer network and control. ;
                                </span>
                                <span>
                                    WU Lintao, born in 1994, M. S. candidate. His research interests include computer network, data mining. ;
                                </span>
                                <span>
                                    HUANG Ye, born in 1993, M. S. candidate. His research interests include knowledge representation, neural network. ;
                                </span>
                                <span>
                                    ZHU Rongbo, born in 1978, Ph. D. , professor. His research interests include mobile computing, protocol design and performance optimization for wireless network.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (61772562);</span>
                                <span>the Fundamental Research Funds for the Central Universities of South-Central University for Nationalities (CZY18014) ;the Academic Innovation Research Fund for Graduates of South-Central University for Nationalities (3212018hqzz029);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="42">真实世界的复杂系统通常都可以构建为网络形式, 其节点代表系统中不同的实体, 边代表这些实体之间的联系。链路预测是指通过已知的网络结构和属性等信息, 预测网络中尚未产生连接的两个节点间产生连接的可能性<citation id="257" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在电商网络中, 可以为用户推荐感兴趣的商品;在科学家合作网络中, 可以对科学家之间潜在的合作关系进行预测;在社交网络中, 可以帮助用户推荐他们感兴趣的用户;在生物领域的蛋白质作用网络中, 可以挖掘那些潜在的相互作用。毫无疑问, 链路预测的广泛应用已使其成为了复杂网络研究中的热点领域之一。</p>
                </div>
                <div class="p1">
                    <p id="43">现有的链路预测算法可以分为:基于相似性的算法和基于学习的算法。基于相似性的算法是假设节点之间越相似则它们之间存在链接的可能性就越大<citation id="267" type="reference"><link href="221" rel="bibliography" /><link href="223" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 通过定义一个函数来计算节点间的相似性, 该函数可以利用某些网络信息如网络拓扑结构或节点属性来计算节点间的相似性, 最后利用节点间的相似度来预测节点间产生链接的可能性, 其预测精度的高低很大程度上取决于能否很好地选取网络结构特征<citation id="258" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。早期的链路预测研究多使用启发式的分数来度量节点间的相似性, 经典的启发式方法有共同邻居 (Common Neighbors, CN) <citation id="259" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、Jaccard<citation id="260" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Adamic-Adar<citation id="261" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和优先偏好 (Preferential Attachment, PA) 等, 但是它们仅利用了单一的局部结构信息, 无法捕捉节点间的深层拓扑关系, 对不同网络的适应性较差。基于学习的算法则构建一个能够提取网络特征的模型, 用已有的网络信息来训练模型, 最后利用训练好的模型来预测节点间是否会产生链接。近年来, 网络表示学习模型<citation id="262" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>已经在多种网络处理和分析任务上验证了其有效性, 网络表示学习模型将网络信息转换为低维实值向量, 这些向量可用于可视化、节点分类和链路预测等任务。Perozzi等<citation id="263" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出的DeepWalk算法, 通过随机游走将游走的路径当作句子, 并使用Skip-gram<citation id="264" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>模型来学习节点的表示向量, 最终在网络分析任务上取得了较大的性能提升。随后, 又出现了基于简单神经网络的LINE算法<citation id="265" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和改进DeepWalk的node2vec算法<citation id="266" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>也利用学习到的节点向量完成了链路预测任务, 但是该类算法只考虑了网络全局拓扑信息, 而忽略了链路结构的相似性。</p>
                </div>
                <div class="p1">
                    <p id="44">链路预测最直观的假设是, 如果两个节点之间越相似, 则它们之间最有可能产生连边。基于网络表示学习的方法, 仅利用了节点的特征向量去度量节点间的相似性, 而不能有效地捕捉到链路结构的相似性特征, 即产生链路的两个节点的局部结构相似性。深度神经网络因其强大的特征学习与表达能力, 近年来在图像分类、目标检测与目标识别等应用中取得了极大的进展<citation id="268" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。卷积神经网络的核心思想是构造不同的感受野抽取图像的局部特征, 而卷积神经网络高效的原因就是局部特征提取能力。一般来说, 网络越深所能学到的东西就越多, 但是简单地加深网络层数会导致网络能力的退化。CVPR2016 (the 2016 IEEE Conference on Computer Vision and Pattern Recognition) 上提到的残差网络 (Residual Network, ResNet) <citation id="269" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>通过在原网络的结构上加上一个恒等映射解决了网络层数进一步加深带来的退化问题, 但是由于恒等映射和非线性变化的输出通过相加的方式结合, 会妨碍信息在整个网络的传播。密集连接卷积神经网络 (Densely Connected Convolutional Network, DenseNet) <citation id="270" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>受GoogLeNet<citation id="271" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>启发, DenseNet是将上一层得到的特征图通过串联的方式结合, 这样对特征的极致利用达到了更好的效果, 更有利于信息在整个网络的传播。</p>
                </div>
                <div class="p1">
                    <p id="45">现有的基于节点相似性的算法采用简单的一阶、多阶邻居信息, 导致该类方法在扩展性方面受到了严重的挑战<citation id="272" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>;基于学习的算法采用随机游走策略或者改进的随机游走策略来获得节点的邻域结构信息, 例如DeepWalk算法的随机游走策略就存在很大的随机性;node2vec算法采样策略虽然在深度和广度取了一个平衡值, 但是依然不能够提取到有效的链路的结构。LINE和node2vec等算法都可归类到浅层神经网络, 而浅层神经网络并不能捕捉到高度非线性的网络结构从而导致产生非最优的网络表示结果。</p>
                </div>
                <div class="p1">
                    <p id="46">因此, 现有研究存在如下两个问题:①基于随机游走的链路预测算法, 随机游走采样策略具有一定的盲目性<citation id="273" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 因此不能够有效地获得节点的邻域结构信息;②浅层的神经网络算法不能够有效地捕捉高度非线性结构<citation id="274" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 例如链路结构特征。为此, 本文作了如下改进:</p>
                </div>
                <div class="p1">
                    <p id="47">1) 针对问题①提出通过提取网络节点的子图作为节点的邻域结构信息, 因为子图中包含了一些复杂的非线性模式, 而这些模式实际上决定了链路的形成。</p>
                </div>
                <div class="p1">
                    <p id="48">2) 针对问题②提出利用深度卷积神经网络去捕捉链路结构的相似性, 因为深度神经网络能够学习一种深层的非线性网络结构, 具有更强的表征能力。例如深度卷积神经网络的局部特征提取能力很强, 尤其是在网格数据上的表现, 因此将两个节点的子图信息构造为矩阵形式, 并通过深度卷积神经网络来提取。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="50" name="50">1.1 node2vec<b>算法</b></h4>
                <div class="p1">
                    <p id="51">node2vec算法与DeepWalk相同, 也是类比word2vec模型<citation id="275" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>实现的, 只是在随机游走的算法上与DeepWalk不同。DeepWalk是完全随机的, 而node2vec算法给出了一个计算式, 式 (1) 中起主要作用的是<i>p</i>和<i>q</i>两个参数。</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>q</mi></mrow></msub><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>/</mo><mi>p</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>d</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>x</mi></mrow></msub><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>x</mi></mrow></msub><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>/</mo><mi>q</mi><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>x</mi></mrow></msub><mo>=</mo><mn>2</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">其中:<i>p</i>是控制访问走过的节点, 即往回走;<i>q</i>是控制访问还没有走过的节点, 即向外走。</p>
                </div>
                <div class="p1">
                    <p id="54">node2vec改进了随机游走的策略, 同时考虑到局部和宏观的信息, 所以相较于其他的表示学习算法有着强扩展性。因此选择node2vec学习到的表示向量作为本文算法的潜在特征表示。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">1.2 DenseNet<b>模型</b></h4>
                <div class="p1">
                    <p id="56">相比ResNet, Huang等<citation id="276" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出的DenseNet是一个更激进的密集连接机制:即互相连接所有层, 具体来说就是每个层都会接受其前面所有层作为其额外的输入。其网络结构主要由Dense Block (密集连接块) 和Transition (过渡层, Conv (卷积) +Pooling (池化) ) 组成, 如图1所示。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 密集连接卷积神经网络的网络结构" src="Detail/GetImg?filename=images/JSJY201906014_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 密集连接卷积神经网络的网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Network structure of DenseNet</p>

                </div>
                <div class="p1">
                    <p id="58">在传统的卷积神经网络中, 第<i>l</i>层的输出作为第<i>l</i>+1层的输入, 简单地理解, 从输入到输出是单连接, 即网络有<i>l</i>层 (输入层不考虑) , 那么就是<i>l</i>个连接;ResNet网络模型中, 网络的某层与前面的某层 (一般是2～3层) 除了从输入到输出的连接外, 还有一个从输入到输出的短路连接 (恒等映射) 在一起, 连接方式是通过元素相加;而在DenseNet中, 网络模型的某层与前面某层有<i>l</i> (<i>l</i>+1) /2个连接, 可参考图1, 相比ResNet这是一种密集连接。DenseNet是直接连接来自不同层的特征图, 这可以实现特征重用, 提升效率。</p>
                </div>
                <div class="p1">
                    <p id="59">传统的神经网络在<i>l</i>层的输出用公式表达为:</p>
                </div>
                <div class="p1">
                    <p id="60"><i>x</i><sub><i>l</i></sub>=<i>H</i><sub><i>l</i></sub> (<i>x</i><sub><i>l</i>-1</sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="61">而对于ResNet, 增加了来自上一层输入的恒等映射函数:</p>
                </div>
                <div class="p1">
                    <p id="62"><i>x</i><sub><i>l</i></sub>=<i>x</i><sub><i>l</i>-1</sub>+<i>H</i><sub><i>l</i></sub> (<i>x</i><sub><i>l</i>-1</sub>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="63">在DenseNet中, 会连接前面所有层作为输入:</p>
                </div>
                <div class="p1">
                    <p id="64"><i>x</i><sub><i>l</i></sub>=<i>H</i><sub><i>l</i></sub> ([<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, …, <i>x</i><sub><i>l</i>-1</sub>])      (4) </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>H</i><sub><i>l</i></sub> (·) 代表的是非线性转换函数, 它是一个组合的操作, 其包括一系列的BN (Batch Normalization) <citation id="277" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、修正线性函数 (Rectified Linear Unit, ReLU) 、Pooling及Conv操作。需要注意的是, 这里的<i>l</i>和<i>l</i>-1层之间可能实际包含多个卷积层。[<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, …, <i>x</i><sub><i>l</i>-1</sub>]表示将0到<i>l</i>-1层的输出特征图作深度级联, 即在深度上作通道的合并。</p>
                </div>
                <div class="p1">
                    <p id="66">因此, DenseNet所做的工作就是在保证网络中层与层之间最大限度的信息传输前提下, 直接将所有层连接起来。密集连接网络的这种Dense Block设计, 使得这个块中每个卷积层的输出特征图的数量都很小, Transition模块是连接两个相邻的Dense Block, 并且通过Pooling使得特征图的大小降低, 同时这种连接方式使得特征和梯度的传递更加有效, 网络也就更加容易训练。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag">2 基于DenseNet的链路预测方法</h3>
                <div class="p1">
                    <p id="68">本文将链路预测问题转化为二分类问题, 并使用DenseNet网络模型来处理二分类问题。首先, 通过网络表示学习算法得到网络的节点表示向量, 同时对网络中的每个节点提取一个子图;然后, 利用节点表示向量来对子图中的节点序列进行排序, 并将排好序的节点序列映射为一个矩阵, 将相应的两个节点对应的矩阵整合为三维数据;最后, 将三维数据输入到DenseNet模型, 判断是否存在连边。另外, 为了叙述方便, 提出的方法描述为基于子图表示学习的链路预测方法, 整体流程如图2所示。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 所提方法整体流程" src="Detail/GetImg?filename=images/JSJY201906014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 所提方法整体流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Overall flow chart of the proposed method</p>

                </div>
                <h4 class="anchor-tag" id="70" name="70">2.1 <b>子图提取算法</b></h4>
                <div class="p1">
                    <p id="71">图中包含了一些复杂非线性的模式, 而这些实际上决定了链路的形式<citation id="278" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。为了学习图的结构特征, 本文提出的基于密集连接卷积神经网络 (DenseNet) 的链路预测模型 (Link Prediction model based on DenseNet, DenseNet-LP) 为每个节点提取一个对应的子图, 从而获得每个节点的局部结构。</p>
                </div>
                <div class="p1">
                    <p id="72"><b>定义</b>1 给定一个无向图<i>G</i>= (<i>V</i>, <i>E</i>) , 其中<i>V</i>={<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …, <i>v</i><sub><i>n</i></sub>}是节点集合, <i>E</i>⊆<i>V</i>×<i>V</i>是边的集合, 对于节点<i>x</i>⊆<i>V</i>, 节点<i>x</i>对应的<i>h</i>-hop子图<i>G</i><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>x</mi><mi>h</mi></msubsup></mrow></math></mathml>是从图<i>G</i>的节点结合{<i>y</i>|<i>d</i> (<i>y</i>, <i>x</i>) ≤<i>h</i>}及其对应的边构造而成, 其中, <i>d</i> (<i>y</i>, <i>x</i>) 表示节点<i>x</i>到节点<i>y</i>的最短路径。</p>
                </div>
                <div class="p1">
                    <p id="74">算法1 子图提取。</p>
                </div>
                <div class="area_img" id="280">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201906014_28000.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="280">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201906014_28001.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="89">其中:<i>h</i>表示生成子图所包含的跳数;<i>N</i> (<i>v</i>) 表示节点<i>v</i>的1-hop邻居节点集合;<i>G</i> (·) 表示从原图中生成包含目标节点集合的子图。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">2.2 <b>节点排序算法</b></h4>
                <div class="p1">
                    <p id="91">为了把卷积神经网络应用于网络结构表示学习, 关键问题是如何在网络结构上定义感受野。因此, 算法的第一步就是把每个节点的局部结构作为感受野的输入, 关于如何获得节点的局部结构在2.1节已经作了说明。由于卷积操作对数据输入的顺序是敏感的, 对于无序数据则较难提取到有效的特征, 而节点的局部网络拓扑结构是无序的, 因此算法的第二步是把每个节点的局部结构变成一个有序的序列。</p>
                </div>
                <div class="p1">
                    <p id="92">为了对节点进行排序, 就需要度量每个节点的重要程度, 因此利用node2vec算法生成网络中每个节点的向量表示, 假定<b><i>X</i></b>=[<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>d</i></sub>]表示任意<i>x</i>节点的<i>d</i>维向量表示, <b><i>Y</i></b>=[<i>y</i><sub>1</sub>, <i>y</i><sub>2</sub>, …, <i>y</i><sub><i>d</i></sub>]表示任意节点<i>y</i>的<i>d</i>维向量表示。由于余弦距离被广泛采用度量多维空间中两点之间的相关性, 所以本文也利用各节点在多维空间上的余弦距离来表征各节点在网络结构上的相似度。在此, 以相似度作为判别重要程度的指标, 并给出定义2。</p>
                </div>
                <div class="p1">
                    <p id="93"><b>定义</b>2  网络中任意节点<i>x</i>、<i>y</i>之间的潜在网络结构相似性为:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>cos</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mi>x</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mi>x</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt><mo>⋅</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mi>y</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">算法的描述框架如下。</p>
                </div>
                <div class="p1">
                    <p id="96">算法2 节点排序。</p>
                </div>
                <div class="area_img" id="281">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201906014_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="107" name="107">2.3 <b>节点对维度转化</b></h4>
                <div class="p1">
                    <p id="108">为了完成链路预测的任务, 就需要预测两节点间的关系。将网络节点对中的节点所对应的节点序列映射为邻接矩阵, 矩阵大小为<i>k</i>×<i>k</i>×2, 2代表的是两个节点。具体流程见算法3。</p>
                </div>
                <div class="p1">
                    <p id="109">算法3 节点序列到矩阵的映射。</p>
                </div>
                <div class="area_img" id="282">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201906014_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="282">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201906014_28201.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="122">为了简单说明2.1～2.3节所做的工作, 在此用图3来说明。首先针对网络中节点, 例如节点<i>x</i>和<i>y</i>, 按照算法1提取对应的子图, 然后对子图中的节点按照算法2进行排序, 将排好序的节点按照算法3映射为相应的矩阵, 最后将两个矩阵在深度上进行拼接。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_123.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 网络子图信息转化整体流程" src="Detail/GetImg?filename=images/JSJY201906014_123.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 网络子图信息转化整体流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_123.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Whole process of network subgraph information transformation</p>

                </div>
                <h4 class="anchor-tag" id="124" name="124">2.4 <b>模型预测方法</b></h4>
                <div class="p1">
                    <p id="125">如2.1～2.3节所述, 利用目标节点的邻域生成对应子图, 然后将节点对的两个子图映射为两个子图的邻接矩阵并整合为三维特征数据形式, 若节点对之间存在链接就将对应的标签设为1, 否则为0。密集连接卷积神经网络的特点是对特征的极致利用, 因此, 网络可以学到更为丰富的内容, 即更加丰富的节点邻域结构信息, 即使是在深层的网络层次, 也能够学到丰富的信息。在链路预测中, 通常感兴趣的是节点对, 而不是单个节点。例如, 在网络中预测的是两个节点之间是否存在连边的可能性, 通过将网络数据转换, 这样将链路预测问题转化为二分类问题, 并使用分类效果较好的密集连接卷积神经网络模型来实现链路预测任务。</p>
                </div>
                <div class="p1">
                    <p id="126">在模型训练时使用交叉熵损失作为优化目标, 在反向传播时更新参数, 交叉熵损失是评估模型预测值分布与真实值分布的差异大小, 二分类下交叉熵损失定义如下:</p>
                </div>
                <div class="p1">
                    <p id="127" class="code-formula">
                        <mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>y</mi><mo>, </mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>Ν</mi></munderover><mo>-</mo></mstyle><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mrow><mi>ln</mi></mrow><mspace width="0.25em" /><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mi>ln</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="128">其中:<i>y</i>是真实的标签分布;<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml>是预测的标签分布;<i>N</i>是样本总数, 即训练的数据样本数。</p>
                </div>
                <h3 id="130" name="130" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="131" name="131">3.1 <b>实验数据集</b></h4>
                <div class="p1">
                    <p id="132">本文实验采用了分别在4个不同领域具有代表性的真实网络数据集, 忽略网络连边的权重与方向, 分别如下:</p>
                </div>
                <div class="p1">
                    <p id="133">1) <i>USAir</i> (<i>USAir line</i>) 。由332个机场之间的航线构成的网络, 包含2 126条航线, 网络中的每个节点对应一个机场, 如果在两个机场之间存在一条直达航线, 那么两个机场之间存在一条连边。</p>
                </div>
                <div class="p1">
                    <p id="134">2) <i>PB</i> (<i>PoliticalBlogs</i>) 。一个美国政治博客网, 由1 222个节点、19 021条边组成。网络节点表示的是博客页面, 边表示博客页面之间的超链接。</p>
                </div>
                <div class="p1">
                    <p id="135">3) <i>Metabolic</i>。一个线虫代谢网络, 由453个节点和2 025条边构成。网络中的节点代表的是代谢物, 两个节点之间的连边代表着生化反应。</p>
                </div>
                <div class="p1">
                    <p id="136">4) <i>King James</i>。一个词汇共现网络, 由1 773个节点和9 131条边构成。网络中的节点表示名词, 两个节点之间的连边表示两个名词出现在同一语句中。</p>
                </div>
                <div class="p1">
                    <p id="137">表1进一步给出了这4个数据集的网络拓扑结构特征, 其中:|<i>V</i>|表示节点数, |<i>E</i>|表示连边数, 〈<i>k</i>〉表示平均度, 〈<i>CC</i>〉表示平均聚集系数, <i>r</i>表示同配系数。</p>
                </div>
                <div class="area_img" id="138">
                    <p class="img_tit"><b>表</b>1 <b>网络拓扑结构特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Topological features of networks</p>
                    <p class="img_note"></p>
                    <table id="138" border="1"><tr><td>数据集</td><td>|<i>V</i>|</td><td>|<i>E</i>|</td><td>〈<i>k</i>〉</td><td>〈<i>CC</i>〉</td><td><i>r</i></td></tr><tr><td>USAir</td><td>332</td><td>2 126</td><td>12.810</td><td>0.749</td><td>-0.208 0</td></tr><tr><td><br />PB</td><td>1 222</td><td>16 714</td><td>27.360</td><td>0.360</td><td>-0.221 0</td></tr><tr><td><br />Metabolic</td><td>453</td><td>2 025</td><td>8.940</td><td>0.647</td><td>0.226 0</td></tr><tr><td><br />King James</td><td>1 773</td><td>9 131</td><td>18.501</td><td>0.163</td><td>-0.048 9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">3.2 <b>基准方法</b></h4>
                <div class="p1">
                    <p id="140">本文所提模型是一种基于网络结构的链路预测模型。除了<i>DeepWalk</i>、<i>node</i>2<i>vec</i>和<i>LINE</i>网络表示学习算法外, 本文还选取4种常用的传统经典方法作为基准方法进行性能对比, 即<i>CN</i>、<i>Jaccard</i>、<i>Adamic</i>-<i>Adar</i> (<i>AA</i>) 和<i>PA</i>指标。下面分别对其作简要介绍。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141">1) <i>CN</i>。</h4>
                <div class="p1">
                    <p id="142">基本假设为如果两个尚未连边的节点有更多的共同邻居, 那么它们更倾向于连边, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="143"><i>s</i><mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mrow><mtext>C</mtext><mtext>Ν</mtext></mrow></msubsup></mrow></math></mathml>=|<i>Γ</i> (<i>x</i>) ∩<i>Γ</i> (<i>y</i>) |      (7) </p>
                </div>
                <div class="p1">
                    <p id="145">其中, <i>Γ</i> (<i>x</i>) 表示节点<i>x</i>的邻居集合。</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146">2) Jaccard (Jac) 。</h4>
                <div class="p1">
                    <p id="147">用于计算集合的相似度, 定义为:</p>
                </div>
                <div class="p1">
                    <p id="148" class="code-formula">
                        <mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mrow><mtext>J</mtext><mtext>a</mtext><mtext>c</mtext><mtext>c</mtext><mtext>a</mtext><mtext>r</mtext><mtext>d</mtext></mrow></msubsup><mo>=</mo><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo>/</mo><msqrt><mrow><mi>k</mi><msub><mrow></mrow><mi>x</mi></msub><mi>k</mi><msub><mrow></mrow><mi>y</mi></msub></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="149">其中, <i>k</i><sub><i>x</i></sub>表示节点<i>x</i>的度数。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">3) AA。</h4>
                <div class="p1">
                    <p id="151">其思想是度小的共同邻居节点的贡献大于度大的共同邻居节点, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="152" class="code-formula">
                        <mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mrow><mtext>A</mtext><mtext>A</mtext></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>z</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mi>k</mi><msub><mrow></mrow><mi>z</mi></msub></mrow></mfrac></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="153" name="153">4) PA。</h4>
                <div class="p1">
                    <p id="154">该指标考虑的是终节点自身度数的影响, 终节点度数越高, 那么这两个节点之间的连接概率就越大, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="155"><i>s</i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mrow><mtext>Ρ</mtext><mtext>A</mtext></mrow></msubsup></mrow></math></mathml>=<i>k</i><sub><i>x</i></sub><i>k</i><sub><i>y</i></sub>      (10) </p>
                </div>
                <h4 class="anchor-tag" id="157" name="157">5) Deepwalk。</h4>
                <div class="p1">
                    <p id="158">第一个将深度学习使用到网络表示学习中的算法, 使用随机游走获得局部的网络信息, 通过游走等价句子学习出隐式表征, 然后这些隐式表征把网络关系编码到统计模型易于使用的连续低维实数向量空间中。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159">6) node2vec。</h4>
                <div class="p1">
                    <p id="160">一种类似于DeepWalk的隐式表征方法, 但是该算法通过设置两个超参数, 使得随机游走在深度和广度方面取得一个平衡, 比起DeepWalk, 该算法具有强拓展性。</p>
                </div>
                <h4 class="anchor-tag" id="161" name="161">7) LINE。</h4>
                <div class="p1">
                    <p id="162">该方法将学习的<i>d</i>维特征表示分为两部分:第一部分, 在直接邻居节点上模拟BFS (Breadth-First Search) 来学习<i>d</i>/2维的特征;第二部分, 严格地从距离源节点2-hop的节点中采样学习剩下的<i>d</i>/2维特征。</p>
                </div>
                <h4 class="anchor-tag" id="163" name="163">3.3 <b>评估指标</b></h4>
                <div class="p1">
                    <p id="164">为了评估算法的准确性, 实验将数据集随机且独立地划分为训练集和测试集, 90%用作训练集, 10%用作测试集, 同时保证训练集和测试集中的网络具有连通性。常见的评判算法准确率的指标有受试者工作特征 (<i>Receiver Operating Characteristic</i>, <i>ROC</i>) 曲线下方面积 (<i>Area Under the ROC Curve</i>, <i>AUC</i>) 和<i>Precision</i>。其中, <i>AUC</i>是从整体上衡量算法的准确度;<i>Precision</i>只考虑对排在前<i>L</i>位的边是否预测准确。因此, 本文选用AUC和Precision两个值进行算法精度的评价。</p>
                </div>
                <div class="p1">
                    <p id="165">1) 在链路预测算法计算出所有节点间存在边的分数值之后, AUC指标可以描述为在测试集中随机选取一条存在连边的分数值比随机选取一条不存在连边的分数值高的概率。通常, AUC值最少大于0.5, AUC值越高, 则算法的精度就越高, 最高不超过1。计算式定义如下:</p>
                </div>
                <div class="p1">
                    <p id="166"><i>AUC</i>= (<i>N</i>′+0.5<i>N</i>″) /<i>N</i>      (11) </p>
                </div>
                <div class="p1">
                    <p id="167">其中:<i>N</i>表示独立重复比较次数;<i>N</i>′表示在测试集中存在连边的分数比不存在连边的分数值高的次数;<i>N</i>″表示在测试集中存在连边的分数与不存在连边的分数值相等的次数。</p>
                </div>
                <div class="p1">
                    <p id="168">2) Precision定义为在前<i>L</i>个预测边中被预测准确的比例。如果有<i>m</i>个预测准确, 即排在<i>L</i>的边中有<i>m</i>个在测试集中, 则Precision定义为:</p>
                </div>
                <div class="p1">
                    <p id="169"><i>Precision</i>=<i>m</i>/<i>L</i>      (12) </p>
                </div>
                <div class="p1">
                    <p id="170">显然, Precision越大预测越准确。如果两个算法AUC相同, 而算法1的Precision大于算法2, 说明算法1更好, 因为其倾向于把真正连边的节点对排在前面。</p>
                </div>
                <div class="p1">
                    <p id="171">同样地, 在使用Precision评估方法的准确率时, 会涉及到<i>L</i>的取值问题。目前, <i>L</i>取值有两种方法:一是固定值;二是根据实验数据规模取值。在本文实验中, 按照数据规模取值。</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172">3.4 <b>实验环境和设置</b></h4>
                <div class="p1">
                    <p id="173">为模拟链路预测任务, 从原网络<i>G</i>= (<i>V</i>, <i>E</i>) 中随机地移除10%的边, 记作<i>E</i><sup><i>p</i></sup>, 在移除边的同时保证网络的连通性, 生成新的网络<i>G</i>′= (<i>V</i>, <i>E</i>′) , 其中, <i>E</i><sup><i>p</i></sup>∩<i>E</i>′=∅, <i>E</i>′、<i>E</i><sup><i>p</i></sup>分别是训练集和测试集中的正类, 然后分别添加与正类等量不存在的边作为负类, 添加负类时保证训练集和测试集交集为空。</p>
                </div>
                <div class="p1">
                    <p id="174">实验硬件环境:Intel Core i3- 8100 (3.6 GHz×4) CPU, 16 GB内存, GTX 1060 (3 GB) 显卡。</p>
                </div>
                <div class="p1">
                    <p id="175">实验软件环境:Windows 10操作系统, DeepWalk、node2vec和LINE模型算法采用Python2.7实现, 所提算法是在Python3.5上实现。</p>
                </div>
                <div class="p1">
                    <p id="176">实验参数设置如下:</p>
                </div>
                <div class="p1">
                    <p id="177">1) 子图提取算法<i>h</i>-hop数:一般设定<i>h</i>∈{2, 3}, 实验中<i>h</i>=3取得较好的效果, 因此, 本文设置<i>h</i>=3。</p>
                </div>
                <div class="p1">
                    <p id="178">2) 子图映射为邻接矩阵:实验时设定<i>k</i>∈{32, 64, 128}, 通过实验对比, 如图4所示, <i>k</i>=64, AUC预测精度相对较好, 因此选择64×64大小。</p>
                </div>
                <div class="p1">
                    <p id="179">3) DeepWalk和node2vec模型算法参数:滑动窗口大小<i>w</i>=10, 重新随机游走遍历次数<i>γ</i>=10, 每次随机游走遍历步长<i>l</i>=80, 向量空间维度<i>d</i>=128, node2vec的超参数<i>p</i>, <i>q</i>∈{0.25, 0.50, 1, 2, 4}。另外两个模型生成的节点表示向量按式 (12) 计算相应的边特征向量, 边特征向量由文献<citation id="279" type="reference">[<a class="sup">15</a>]</citation>提到的哈达玛积 (Hadamard product, Hadamard) 计算, 然后建立逻辑回归模型进行链路预测。</p>
                </div>
                <div class="p1">
                    <p id="180"><i>F</i><sub> (<i>u</i>, <i>v</i>) </sub>=[<b><i>f</i></b> (<i>u</i>) ⨂<b><i>f</i></b> (<i>v</i>) ]<sub><i>i</i></sub>=<i>f</i><sub><i>i</i></sub> (<i>u</i>) *<i>f</i><sub><i>i</i></sub> (<i>v</i>)      (12) </p>
                </div>
                <div class="p1">
                    <p id="181">其中: <b><i>f</i></b> (<i>u</i>) 表示节点<i>u</i>的特征向量; <i>f</i><sub><i>i</i></sub> (<i>u</i>) 表示特征向量第<i>i</i>维的值。</p>
                </div>
                <div class="p1">
                    <p id="182">4) 网络模型参数:网络结构详细参数见表2所示。</p>
                </div>
                <div class="area_img" id="183">
                                            <p class="img_tit">
                                                <b>表</b>2 <b>网络结构参数细节</b>
                                                    <br />
                                                Tab. 2 Parameter details of network structure
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201906014_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 网络结构参数细节" src="Detail/GetImg?filename=images/JSJY201906014_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="184" name="184">3.5 <b>结果分析</b></h4>
                <div class="p1">
                    <p id="185">将本文所提方法在3.1节中所提到的4个数据集上进行实验, 为了更加准确呈现预测结果, 在所有数据集上重复独立实验20次, 并计算这20次实验的<i>AUC</i>平均值作为最后的预测结果。在4个数据集上的预测精度<i>AUC</i>值的实验结果如图4所示。同众基准算法进行对比的结果如表3所示。</p>
                </div>
                <div class="area_img" id="186">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_186.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 参数k对AUC值的影响" src="Detail/GetImg?filename=images/JSJY201906014_186.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 参数<i>k</i>对AUC值的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_186.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Influence of parameter <i>k</i> on AUC</p>

                </div>
                <div class="p1">
                    <p id="187">图4中曲线分别为算法中矩阵维度<i>k</i>∈{32, 64, 128}对应的预测结果。当<i>k</i>取32时, 其预测效果在USAir和King James数据集上还不如基准算法, 表明<i>k</i>值取值较小, 节点的邻域结构信息不足, 对链路结构信息的捕获的帮助不大;当<i>k</i>取64时, 其预测效果已经有了较大的提升, 表明此时的节点邻域结构信息对于捕捉链路结构的相似性帮助是较大的;当<i>k</i>取128时, 其预测结果较<i>k</i>取32时整体效果要好, 并且均高于基准算法的精度。但是在数据集USAir和PB两个数据集上<i>k</i>取128的预测效果没有<i>k</i>取64时的效果好, 表明节点的邻域结构较宽泛, 容易取到一些“噪声”数据, 这些数据对于链路的预测帮助不大, 甚至会造成信息的冗余, 最后导致预测的效果并不理想, 而且<i>k</i>值取值越大, 计算的复杂度更高。因此综合考虑各因素, 在实验中设置<i>k</i>=64。</p>
                </div>
                <div class="p1">
                    <p id="188">结合表1和表3来看:本文所提出的DenseNet-LP方法比传统经典的方法表现要好, 最高提升了36个百分点;比网络表示学习方法方法, 最高提升18个百分点。这表明从子图中更能够提取到链路的结构特征。传统的方法, 例如CN和AA在USAir和PB网络上预测效果良好, 是由于这两个网络结构中平均节点度、平均聚类系数等网络属性较高, 表明节点之间的紧密程度较高, 因此采用此类方法能够取得较好的结果;但在其他网络上性能表现不佳, 例如King James网络的聚类系数很小, 表明节点之间的紧密程度很低, 并且它的同配系数也很低, 表明网络中度值相近的节点少, 从而导致这一类方法的预测结果较低。结合这两点说明传统的链路预测方法的预测效果和网络结构属性关联性较大, 方法的泛化性能不佳。</p>
                </div>
                <div class="p1">
                    <p id="189">通过表3可以看出, 网络表示学习方法相较传统的方法性能要稳定, 例如在King James上表现优于传统的方法, 这是因为网络表示学习方法利用随机游走策略能发掘节点间的隐含关系, 而传统的方法只利用了共同邻居这一单一的网络信息。但是在一些特殊网络中, 比如说节点的平均度和聚集系数比较大的时候, 简单的传统方法还是能够取得较好的表现, 这是因为它们能够较好地利用这些网络特性从而得出这两个节点的相似度高。然而, 本文所提出的DenseNet-LP方法既能够学习到节点的表示向量又能够捕捉到链路结构的相似性, 所以能够有效地提升表现性能。</p>
                </div>
                <div class="p1">
                    <p id="191">表4给出了DenseNet-LP方法和几个基准算法的链路预测精度对比。由表4可以看出, 除了King James网络外, DenseNet-LP方法的精度都优于众基准算法, 是因为从子图中能够学习到链路的结构特征, 从而能够作出更为准确的预测。基于启发式的方法其预测效果较差, 从表4中前4个算法的预测精度可以看出来, 其预测值大部分都没有0.5, 意味着这类算法在这几个实验网络中预测精度还不如完全随机预测的好。而基于网络表示学习的算法是基于路径相似性指标的链路预测, 并利用学习模型学习到了节点的潜在表示特征, 所以其预测精度相较启发式方法好很多, 最高值达0.87。</p>
                </div>
                <div class="area_img" id="192">
                                            <p class="img_tit">
                                                <b>表</b>3 <b>不同方法的链路预测</b>AUC<b>值比较</b>
                                                    <br />
                                                Tab. 3 Comparison of AUC values of link prediction by different methods
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_19200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201906014_19200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_19200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 不同方法的链路预测AUC值比较" src="Detail/GetImg?filename=images/JSJY201906014_19200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">注:“*”是对应数据下AUC的最大值。</p>

                </div>
                <div class="area_img" id="193">
                                            <p class="img_tit">
                                                <b>表</b>4 <b>不同方法的链路预测</b>Precision<b>值比较</b>
                                                    <br />
                                                Tab. 4 Comparison of Precision values of link prediction by different methods
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201906014_19300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201906014_19300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201906014_19300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 不同方法的链路预测Precision值比较" src="Detail/GetImg?filename=images/JSJY201906014_19300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">注:“*”是对应数据下Precision的最大值。</p>

                </div>
                <h3 id="194" name="194" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="195">针对现有的基于网络表示学习方法在链路预测任务中考虑的是节点单一的邻域拓扑信息, 而忽略了多节点在链路结构上相似性的问题, 本文提出了一种基于密集连接卷积神经网络的链路预测模型 (<i>DenseNet</i>-<i>LP</i>) 。首先, 针对目标节点生成子图, 利用表示学习算法<i>node</i>2<i>vec</i>生成的节点特征表示向量辅助子图中的节点进行排序;然后, 将排好序的节点映射为邻接矩阵, 并整合为三维信息;最后, 利用密集连接卷积神经网络模型进行链路预测。实验结果表明, 本文所提模型<i>DenseNet</i>-<i>LP</i>相较现有众多的链路预测算法有着更加准确的预测结果。尽管本文对基于网络结构的链路预测算法研究取得了一些成果, 但仍有很多问题待解决, 例如在下一步可以尝试在网络结构的基础上结合节点属性信息来进行链路预测问题上的研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="219">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100530194&amp;v=MTk2MjlNbndaZVp0RmlubFVyM0lKMW9kYXhBPU5pZk9mYks3SHRET3JvOUZZZWdQRFhVOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>LYU L Y, ZHOU T.Link prediction in complex networks:a survey[J].Physica A:Statistical Mechanics and its Applications, 2011, 390 (6) :1150-1170.
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accuracy test for link prediction in terms of similarity index:The case of WS and BA models">

                                <b>[2]</b>AHN M W, JUNG W S.Accuracy test for link prediction in terms of similarity index:the case of WS and BA models[J].Physica A:Statistical Mechanics and its Applications, 2015, 429:177-183.
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600722187&amp;v=MTI2MjNRVE1ud1plWnRGaW5sVXIzSUoxb2RheEE9TmlmT2ZiSzlIOVBPcVk5Rlkra05EWFErb0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>HOFFMAN M, STEINLEY D, BRUSCO M J.A note on using the adjusted rand index for link prediction in networks[J].Social Networks, 2015, 42:72-79.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201708020&amp;v=MjQwODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvaFdyN0tMejdCZDdHNEg5Yk1wNDlIWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>刘思, 刘海, 陈启买, 等.基于网络表示学习与随机游走的链路预测算法[J].计算机应用, 2017, 37 (8) :2234-2239. (LIU S, LIU H, CHEN Q M, et al.Link prediction algorithm based on network representation learning and random walk[J].Journal of Computer Applications, 2017, 37 (8) :2234-2239.) 
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering and preferential attachment in growing networks">

                                <b>[5]</b>NEWMAN M E.Clustering and preferential attachment in growing networks[J].Physical Review E:Statistical, Nonlinear, and Soft Matter Physics, 2001, 64 (2 Pt 2) :025102.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Etude comparative de la distribution florale dans une portion des Alpes et des Jura">

                                <b>[6]</b>JACCARD P.Etude comparative de la distribution florale dans une portion des Alpes et du Jura[J].Bulletin de la SociétéVaudoise des Sciences Naturelles, 1901, 37:547-579.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100484987&amp;v=MTk5NTQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lKMW9kYXhBPU5pZk9mYks3SHRET3JvOUZZT01MQlhRK29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>ADAMIC L A, ADAR E.Friends and neighbors on the Web[J].Social Networks, 2003, 25 (3) :211-230.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201708003&amp;v=MTg3NTZxQnRHRnJDVVI3cWZadVpzRnkvaFdyN0tOVGZBZHJHNEg5Yk1wNDlGWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>涂存超, 杨成, 刘知远, 等.网络表示学习综述[J].中国科学:信息科学, 2017, 47 (8) :980-996. (TU C C, YANG C, LIU Z Y, et al.Network representation learning:an overview[J].SCIEN-TIA SINICA Informationis, 2017, 47 (8) :980-996.) 
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deepwalk:Online learning of social representations">

                                <b>[9]</b>PEROZZI B, AI-RFOU R, SKIENA S.Deep Walk:online learning of social representations[C]//KDD 2014:Proceedings of the2014 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2014:701-710.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">

                                <b>[10]</b>MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//NIPS13:Proceedings of the 26th International Conference on Neural Information Processing Systems.North Miami Beach, FL:Curran Associates Inc., 2013:3111-3119.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LINE:large-scale information network embedding">

                                <b>[11]</b>TANG J, QU M, WANG M Z, et al.LINE:large-scale information network embedding[C]//WWW 2015:Proceedings of the24th International Conference on World Wide Web.Republic and Canton of Geneva, Switzerland:International World Wide Web Conferences Steering Committee, 2015:1067-1077.
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Node2vec:Scalable Feature Learning for Networks">

                                <b>[12]</b>GROVER A, LESKOVEC J.Node2vec:scalable feature learning for networks[C]//SIGKDD 2016:Proceedings of the 22nd ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2016:855-864.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNZK201802016&amp;v=MTE4NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2hXcjdLUHlQUlpiRzRIOW5Nclk5RVlvUUs=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>侯建华, 邓雨, 陈思萌, 等.基于深度特征和相关滤波器的视觉目标跟踪[J].中南民族大学学报 (自然科学版) , 2018, 37 (2) :67-73. (HOU J H, DENG Y, CHEN S M.Visual object tracking based on deep features and correlation filter[J].Journal of South-Central University for Nationalities (Natural Science Edition) , 2018, 37 (2) :67-73.) 
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[14]</b>HE K M, ZHANG X Y, REN S Q, et al.Deep residual learning for image recognition[C]//CVPR 2016:Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2016:770-778.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">

                                <b>[15]</b>HUANG G, LIU Z, VAN DER MAATEN L, et al.Densely connected convolutional networks[C]//CVPR 2017:Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2017:2261-2269.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[16]</b>SZEGEDY C, LIU W, JIA Y Q, et al.Going deeper with convolutions[C]//CVPR 2015:Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:1-9.
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201810015&amp;v=MDQ5NjZxZlp1WnNGeS9oV3I3S0x6N0Jkckc0SDluTnI0OUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>齐金山, 梁循, 李志宇, 等.大规模复杂信息网络表示学习:概念、方法与挑战[J].计算机学报, 2018, 41 (10) :2394-2420. (QIN J S, LIANG X, LI Z Y, et al.Representation learning of large-scale complex information network:concepts, methods and challenges[J].Chinese Journal of Computers, 2018, 41 (10) :2394-2420.) 
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">

                                <b>[18]</b>IOFFE S, SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//ICML2015:Proceedings of the 2015 32nd International Conference on Machine Learning.Cambridge, MA:MIT Press, 2015:448-456.
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Link prediction based on graph neural networks">

                                <b>[19]</b>ZHANG M H, CHEN Y X.Link prediction based on graph neural networks[EB/OL].[2018-09-13].https://arxiv.org/abs/1802.09691.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201906014" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201906014&amp;v=MTU4OTBac0Z5L2hXcjdLTHo3QmQ3RzRIOWpNcVk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
