<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991842603750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903014%26RESULT%3d1%26SIGN%3dwQ52Q%252fmld%252bm38sHw9eEd1YYRhJY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903014&amp;v=MTExNDdmWnVacEZpRGxXN3JOTHo3QmQ3RzRIOWpNckk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 人脸质量评价模型 ">1 人脸质量评价模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="1.1 &lt;b&gt;网络模型结构&lt;/b&gt;">1.1 <b>网络模型结构</b></a></li>
                                                <li><a href="#52" data-title="1.2 &lt;b&gt;数据准备及训练&lt;/b&gt;">1.2 <b>数据准备及训练</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#58" data-title="2 实验结果与分析 ">2 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="3 结语 ">3 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="图1 人脸质量评价网络模型">图1 人脸质量评价网络模型</a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;人脸数据集统计&lt;/b&gt;"><b>表</b>1 <b>人脸数据集统计</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;训练模型的部分参数&lt;/b&gt;"><b>表</b>2 <b>训练模型的部分参数</b></a></li>
                                                <li><a href="#63" data-title="图2 训练损失与迭代次数的关系">图2 训练损失与迭代次数的关系</a></li>
                                                <li><a href="#64" data-title="图3 测试准确率与迭代次数的关系">图3 测试准确率与迭代次数的关系</a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;模型在不同测试集上的测试结果&lt;/b&gt;"><b>表</b>3 <b>模型在不同测试集上的测试结果</b></a></li>
                                                <li><a href="#69" data-title="图4 测试集部分图片的得分结果">图4 测试集部分图片的得分结果</a></li>
                                                <li><a href="#73" data-title="图5 模型对不同因素的评分结果展示">图5 模型对不同因素的评分结果展示</a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;不同模型的准确率对比&lt;/b&gt;"><b>表</b>4 <b>不同模型的准确率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="91">


                                    <a id="bibliography_1" title="徐晓艳.人脸识别技术综述[J].电子测试, 2015 (5X) :30-35. (XU X Y.Survey of face recognition technology[J].Electronic Test, 2015 (5X) :30-35.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WDZC201510013&amp;v=MzAwMjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3JOTWluUmJiRzRIOVROcjQ5RVo0UUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        徐晓艳.人脸识别技术综述[J].电子测试, 2015 (5X) :30-35. (XU X Y.Survey of face recognition technology[J].Electronic Test, 2015 (5X) :30-35.) 
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_2" title="DODGE S, KARAM L.Understanding how image quality affects deep neural networks[C]//Proceedings of the 2016 8th International Conference on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2016:11-16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding how image quality affects deep neural networks">
                                        <b>[2]</b>
                                        DODGE S, KARAM L.Understanding how image quality affects deep neural networks[C]//Proceedings of the 2016 8th International Conference on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2016:11-16.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_3" title="KARAHAN S, YILDIRUM M K, KIRTAC K, et al.How image degradations affect deep CNN-based face recognition?[C]//Proceedings of the 2016 International Conference of the Biometrics Special Interest Group.Piscataway, NJ:IEEE, 2016:22-29." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=How image degradations affect deep CNN-based face recognition?">
                                        <b>[3]</b>
                                        KARAHAN S, YILDIRUM M K, KIRTAC K, et al.How image degradations affect deep CNN-based face recognition?[C]//Proceedings of the 2016 International Conference of the Biometrics Special Interest Group.Piscataway, NJ:IEEE, 2016:22-29.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_4" title="ISO/IEC 19794-5.Information technology-biometric data interchange formats-Part 5:face image data[S].New York:A-merican National Standard Institute, 2001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Information technology-biometric data interchange formats-Part 5:face image data">
                                        <b>[4]</b>
                                        ISO/IEC 19794-5.Information technology-biometric data interchange formats-Part 5:face image data[S].New York:A-merican National Standard Institute, 2001.
                                    </a>
                                </li>
                                <li id="99">


                                    <a id="bibliography_5" title="ICAO 9303.International civil aviation organization:machine readable travel documents[S].[S.l.]:International Civil Aviation Organization, 2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Machine Readable Travel Documents">
                                        <b>[5]</b>
                                        ICAO 9303.International civil aviation organization:machine readable travel documents[S].[S.l.]:International Civil Aviation Organization, 2006.
                                    </a>
                                </li>
                                <li id="101">


                                    <a id="bibliography_6" title="BERRANI S A, GARCIA C.Enhancing face recognition from video sequences using robust statistics[C]//Proceedings of the 2005IEEE Conference on Advanced Video and Signal based Surveillance.Washington, DC:IEEE Computer Society, 2005:324-329." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancing face recognition from video sequences using robust statistics">
                                        <b>[6]</b>
                                        BERRANI S A, GARCIA C.Enhancing face recognition from video sequences using robust statistics[C]//Proceedings of the 2005IEEE Conference on Advanced Video and Signal based Surveillance.Washington, DC:IEEE Computer Society, 2005:324-329.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_7" title="YANG Z, AI H, WU B, et al.Face pose estimation and its application in video shot selection[C]//ICPR&#39;04:Proceedings of the 17th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2004, 1:322-325." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face pose estimation and its application in video shot selection">
                                        <b>[7]</b>
                                        YANG Z, AI H, WU B, et al.Face pose estimation and its application in video shot selection[C]//ICPR&#39;04:Proceedings of the 17th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2004, 1:322-325.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_8" title="GAO X, LI S Z, LIU R, et al.Standardization of face image sample quality[C]//Proceedings of the 2007 International Conference on Biometrics, LNCS 4642.Berlin:Springer, 2007:242-251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Standardization of face image sample quality">
                                        <b>[8]</b>
                                        GAO X, LI S Z, LIU R, et al.Standardization of face image sample quality[C]//Proceedings of the 2007 International Conference on Biometrics, LNCS 4642.Berlin:Springer, 2007:242-251.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_9" title="SELLAHEWA H, JASSIM S A.Image-quality-based adaptive face recognition[J].IEEE Transactions on Instrumentation and Measurement, 2010, 59 (4) :805-813." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image-Quality-Based Adaptive Face Recognition">
                                        <b>[9]</b>
                                        SELLAHEWA H, JASSIM S A.Image-quality-based adaptive face recognition[J].IEEE Transactions on Instrumentation and Measurement, 2010, 59 (4) :805-813.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_10" title="WONG Y K, CHEN S K, MAU S, et al.Patch-based probabilistic image quality assessment for face selection and improved videobased face recognition[C]//Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition Workshops.Piscataway, NJ:IEEE, 2011:74-81." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Patch-based probabilistic image quality assessment for face selection and improved video-based face recognition">
                                        <b>[10]</b>
                                        WONG Y K, CHEN S K, MAU S, et al.Patch-based probabilistic image quality assessment for face selection and improved videobased face recognition[C]//Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition Workshops.Piscataway, NJ:IEEE, 2011:74-81.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_11" title="HINTON G E, SALAKHUTDINOV R R.Reducing the dimensionality of data with neural networks[J].Science, 2006, 313 (5786) :504-507." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reducing the dimensionality of data with neural networks">
                                        <b>[11]</b>
                                        HINTON G E, SALAKHUTDINOV R R.Reducing the dimensionality of data with neural networks[J].Science, 2006, 313 (5786) :504-507.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_12" title="YI D, LEI Z, LIAO S C, et al.Learning face representation from scratch[J].ar Xiv Preprint, 2014, 2014:ar Xiv.1411.7923." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning face representation from scratch">
                                        <b>[12]</b>
                                        YI D, LEI Z, LIAO S C, et al.Learning face representation from scratch[J].ar Xiv Preprint, 2014, 2014:ar Xiv.1411.7923.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_13" title="PHILLIPS P J, MOON H, RIZVI S A, et al.The FERET evaluation methodology for face-recognition algorithms[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (10) :1090-1104." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The FERET evaluation methodology for face-recognition algorithms">
                                        <b>[13]</b>
                                        PHILLIPS P J, MOON H, RIZVI S A, et al.The FERET evaluation methodology for face-recognition algorithms[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (10) :1090-1104.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_14" title="ZHANG L, ZHANG L, LI L.Illumination quality assessment for face images:a benchmark and a convolutional neural networks based model[C]//Proceedings of the 2017 International Conference on Neural Information Processing, LNCS 10636.Berlin:Springer, 2017:583-593." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Illumination quality assessment for face images:a benchmark and a convolutional neural networks based model">
                                        <b>[14]</b>
                                        ZHANG L, ZHANG L, LI L.Illumination quality assessment for face images:a benchmark and a convolutional neural networks based model[C]//Proceedings of the 2017 International Conference on Neural Information Processing, LNCS 10636.Berlin:Springer, 2017:583-593.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-19 13:45</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),695-699 DOI:10.11772/j.issn.1001-9081.2018071588            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的人脸图像质量评价</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">李秋珍</a>
                                <a href="javascript:;">栾朝阳</a>
                                <a href="javascript:;">汪双喜</a>
                </h2>
                    <h2>

                    <span>武汉数字工程研究所</span>
                    <span>华中科技大学计算机科学与技术学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对人脸识别过程中人脸图像质量较低造成的低识别率问题, 提出了一种基于卷积神经网络的人脸图像质量评价模型。首先建立一个8层的卷积神经网络模型, 提取人脸图像质量的深层语义信息;然后在无约束环境下收集人脸图像, 并通过传统的图像处理方法以及人工筛选进行过滤, 得到的数据集用以进行模型参数的训练;其次通过在图形处理器 (GPU) 上加速训练, 得到用于拟合人脸图像到类别的映射关系;最后将输入在高质量图像类别的概率作为图像的质量得分, 建立人脸图像的质量打分机制。实验结果表明, 与VGG-16网络相比, 所提模型准确率降低了0.21个百分点, 但是参数规模减小了98%, 极大地提高了模型运算效率;同时所提模型在人脸模糊、光照、姿态和遮挡方面都具有较强的判别能力。因此, 可将该模型应用在实时人脸识别系统中, 在不影响系统运行效率的前提下提高系统的准确性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像质量评价;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸图像质量评价;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *李秋珍 (1976—) , 女, 湖北浠水人, 高级工程师, 硕士, 主要研究方向:图像质量评价、人工智能;电子邮箱qiuzhen_li@foxmail.com;
                                </span>
                                <span>
                                    栾朝阳 (1991—) , 男, 河南新乡人, 硕士, 主要研究方向:计算机视觉、深度学习;;
                                </span>
                                <span>
                                    汪双喜 (1989—) , 男, 湖北武汉人, 工程师, 硕士, 主要研究方向:图像处理、深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>“十三五”装备预研领域基金 (61401320501);</span>
                    </p>
            </div>
                    <h1><b>Quality evaluation of face image based on convolutional neural network</b></h1>
                    <h2>
                    <span>LI Qiuzhen</span>
                    <span>LUAN Chaoyang</span>
                    <span>WANG Shuangxi</span>
            </h2>
                    <h2>
                    <span>Wuhan Digital Engineering Institute</span>
                    <span>School of Computer Science and Technology, Huazhong University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the low recognition rate caused by low quality of face images in the process of face recognition, a face image quality evaluation model based on convolutional neural network was proposed. Firstly, an 8-layer convolutional neural network model was built to extract deep semantic information of face image quality. Secondly, face images were collected in unconstrained environment, and were filtered by traditional image processing method and manual selecting, then the dataset obtained was used to train the model parameters. Thirdly, by accelerating training on GPU (Graphics Processing Unit) , the mapping relationship of fitted face images to categories was obtained. Finally, the input probability of high-quality image category was taken as the image quality score, and the face image quality scoring mechanism was established. Experimental results show that compared with VGG-16 network, the precision rate of the proposed model is reduced by 0.21 percentage points, but the scale of the parameters is reduced by 98%, which greatly improves the efficiency of the model. At the same time, the proposed model has strong discriminant ability in aspects such as face blur, illumination, posture and occlusion. Therefore, the proposed model can be applied to real-time face recognition system to improve the accuracy of the system without affecting the efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20quality%20evaluation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image quality evaluation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=quality%20evaluation%20of%20face%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">quality evaluation of face image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Qiuzhen, born in 1976, M. S. , senior engineer. Her research interests include image quality evaluation, artificial intelligence.;
                                </span>
                                <span>
                                    LUAN Chaoyang, born in 1991, M. S. His research interests include computer vision, deep learning.;
                                </span>
                                <span>
                                    WANG Shuangxi, born in 1989, M. S. , engineer. His research interests include image processing, deep learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-01</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the“13th Five-Year Plan”Equipment Pre-Research Field Fund (61401320501);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="32">近年来, 伴随着计算机视觉技术的飞速发展, 人脸识别已经成为工业界和学术界研究的热点。人脸识别即根据某种模式判断物体或者物体的一部分是否满足人脸结构, 并依据其特征信息标识出其身份的过程, 具体可分为:人脸检测、特征提取和人脸检索。人脸识别作为身份校验的一种重要方式, 在安全认证方面具有极其重要的意义。传统的门禁卡、身份证等认证方式, 极其不方便且容易被盗用, 给人们的日常生活带来许多麻烦。而人脸识别作为一种生物认证的手段, 具有安全、可靠、简单、友好等特点, 备受人们的青睐;因此, 人脸识别技术在机器学习、计算机视觉、模式识别等科研领域具有极其重要的研究意义<citation id="119" type="reference"><link href="91" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="33">然而, 随着人脸识别系统的大范围应用、场景环境的多样性以及复杂性, 监控系统抓取的同一个人的人脸图像呈现的效果差别很大, 比如图像模糊、光照不均匀、非正脸等因素, 这些因素导致人脸图像的特征不明显或者缺失, 严重影响到人脸图像识别的准确度。有研究指出, 人脸识别的准确性不仅仅与识别算法的优劣有关, 还与人脸图像的质量高低有关<citation id="120" type="reference"><link href="93" rel="bibliography" /><link href="95" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。因此, 如何过滤掉低质量人脸图像、保留高质量人脸图像是目前人脸识别领域面临的一个巨大挑战。</p>
                </div>
                <div class="p1">
                    <p id="34">目前, 国际上公认的人脸图像质量标准ISO/IEC 19794-5 (International Organization for Standardization/International Electro technical Commission 19794-5) <citation id="121" type="reference"><link href="97" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和ICAO 9303 (International Civil Aviation Organization 9303) <citation id="122" type="reference"><link href="99" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 给用于证件照中的高质量人脸图像提供了参考依据。基于这些标准, 科研工作者提出了许多分析人脸图像质量的方法, 可以总结为两类:一类是分析人脸图像质量是如何影响检测和识别的性能, 一般通过在低质量图像的测试来分析模型的健壮性;另一类研究是通过辨别低质量的图像来克服实际场景中低质量图像带来的问题。Berrani等<citation id="123" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>最早研究了人脸图像质量问题, 并采用了PCA (Principal Component Analysis) 算法来移除低质量的人脸图像。然而由于监控视频场景中低质量的图像占据多数, 所以这种方法在监控视频场景中无法得到好的效果。目前已知的大部分人脸图像质量评价方法都是基于对人脸特殊属性的分析, 这也是最直接的方案。Yang等<citation id="124" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>使用一种树形结构来对姿态进行估计, 并把结果用来评估人脸质量。Gao等<citation id="125" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>利用人脸的不对称性来量化人脸的非均匀光照和姿态。Sellahewa等<citation id="126" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>通过计算与一张特殊的标准参考图像的差异来获得人脸图像质量分数。Wong等<citation id="127" type="reference"><link href="109" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用了概率模型, 通过训练均匀光照、中性表情的正脸图像来评估高质量的可能性, 但是这种方法的效果取决于筛选的高质量人脸图像。</p>
                </div>
                <div class="p1">
                    <p id="35">虽然现有的人脸图像的质量评价很多, 但大多数方法都是通过分析其客观因素, 比如是否对称、亮度是否均匀、是否有较高的对比度等, 或是挑选一张标准图像定义为“基准脸”, 计算捕获的人脸图像与“基准脸”的差异来衡量人脸图像的质量。这些方法主观性较强, 在复杂的环境中适应性较差。</p>
                </div>
                <div class="p1">
                    <p id="36">自从Hinton等<citation id="128" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>于2006年发表论文提出深度学习的概念, 并在2012年采用深度学习赢得了ImageNet图像分类比赛的冠军后, 深度学习即成为了学术界的研究热点之一。深度卷积神经网络 (Convolutional Neural Network, CNN) 在图像的分类方面表现出色, 同时其提取的特征向量更具有表达性。因此本文提出了通过CNN来评估人脸图像质量的方法, 以此来解决人脸识别系统中图像质量问题。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag">1 人脸质量评价模型</h3>
                <div class="p1">
                    <p id="38">人脸图像质量评价可以被看作一个二分类问题, 人脸图像被分为两类:一类是高质量人脸图像, 另一类是低质量人脸图像。通过模型来将输入映射到质量标签空间中, 在人脸识别时首先判断输入人脸图像的质量高低, 将质量低的进行剔除, 质量高的保留以进行后续处理。下面将对本文提出的人脸质量评价网络模型进行详细介绍。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">1.1 <b>网络模型结构</b></h4>
                <div class="p1">
                    <p id="40">本文设计的人脸质量评价网络模型是由5层卷积层 (Convolution) 、3层降采样层 (即池化层Pool) 和3层全连接层 (Fully Connected, FC) 堆叠而成的深度CNN, 其中还使用了PRelu (Parametric Rectified Linear Unit) 激活层、LRN (Local Response Normalization) 层和Dropout层等多种不同类型的结构, 这些多种类型结构的组合共同拟合出从样本空间到标签空间的映射关系。人脸质量评价网络模型如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="41">从图1可以看出, 除了第3个、第4个卷积层 (Conv) 外, 其他3个卷积层后都接着降采样层 (即池化层Pool) 。网络的输入尺寸是112×112×3的三通道人脸图像。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903014_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 人脸质量评价网络模型" src="Detail/GetImg?filename=images/JSJY201903014_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 人脸质量评价网络模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903014_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Network model of face quality evaluation</p>

                </div>
                <div class="p1">
                    <p id="43">第1个卷积层 (Conv1) 使用96个11×11×3的卷积核对输入进行卷积运算, 移动步长为4个像素, 因此输出的特征图尺寸为 (112-11) /4+1=26个像素。由于有96个卷积核, 所以最后会生成的特征图的规模为26×26×96。这些特征图先经过PRelu1激活函数操作后, 再经过一个最大池化层Pool1的处理, 池化核的尺寸为3×3, 移动步长为2, 则池化后图像的宽高分别为 (26-3) /2+1=13个像素, 数量为96个。</p>
                </div>
                <div class="p1">
                    <p id="44">第2个卷积层 (Conv2) 的输入是13×13×96尺寸的特征图, 并在特征图每个通道的周围各填充2个像素, 再通过256个5×5×96的卷积核处理, 移动步长为1, 输出的特征图尺寸为 (13-5+2×2) /1+1=13, 有256个。输出的结果经过PRelu2激活后再经过一个最大池化层Pool2的处理, 池化核的大小是3×3, 移动步长是2, 得到输出的特征图规模为6×6×256。</p>
                </div>
                <div class="p1">
                    <p id="45">第3个卷积层 (Conv3) 使用3×3大小的卷积核, 移动步长为1, 该层同样在输入图像每通道的周围填充了一个像素, 使得输出的尺寸跟输入一致。该层卷积核数量为384个, 产生的输出特征图规模为6×6×384。</p>
                </div>
                <div class="p1">
                    <p id="46">第4个卷积层 (Conv4) 的参数与第3个卷积层 (Conv3) 一样, 输入是6×6×384的特征图, 经过填充和卷积运算, 得到的输出特征图规模依然为6×6×384。</p>
                </div>
                <div class="p1">
                    <p id="47">第5个卷积层 (Conv5) 使用的卷积核尺寸仍为3×3, 数量为256个, 移动步长为1个像素。对输入特征图各通道的上下左右填充一个像素后, 经过卷积核的卷积运算, 产生了6×6×256个特征图。这些特征图经过激活层PRelu5后, 输入到一个池化层Pool5。该池化层采用3×3大小的池化核, 移动步长为2。最后的输出特征图为3×3×256。</p>
                </div>
                <div class="p1">
                    <p id="48">第6层全连接层 (FC6) 的输入尺寸为3×3×256, 采用3×3×256尺寸的滤波器对输入进行卷积运算, 每个滤波器都会生成一个一维的运算结果。共有64个这样规模的滤波器, 所以最后的输出为64维的向量, 再通过PRelu6激活函数和Dropout6操作后, 得到本层最后64维的输出值。该层的参数总数为3×3×256×64=147 456。</p>
                </div>
                <div class="p1">
                    <p id="49">第7层全连接层 (FC7) 的神经元与第6层的输出结果进行全连接, 共有64个神经元, 所以最后的输出为64个数据。该层的参数总数为64×64=4 096。</p>
                </div>
                <div class="p1">
                    <p id="50">第8层全连接层 (FC8) 共输出两个值, 与第7层全连接层 (FC7) 的所有神经元进行全连接, 输出网络最终的训练值。该层的参数总数为64×2=128。</p>
                </div>
                <div class="p1">
                    <p id="51">最后的Softmax层是该网络的终点, 采用Softmax损失函数来计算训练的结果与实际值之间的误差, 该误差越小, 表明网络的分类效果越好。通过反向传播算法不断优化网络参数, 减小损失函数值, 直到其收敛, 即可得到最终的网络模型参数。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">1.2 <b>数据准备及训练</b></h4>
                <div class="p1">
                    <p id="53">由于人脸质量评价没有统一明确的定义, 目前学术界还没有一套公开标准的人脸图像质量评价数据集可供选择。其他许多公开的人脸数据集, 比如:CASIA-WebFace (Institute of Automation, Chinese Academy of Sciences WebFace) <citation id="129" type="reference"><link href="113" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、LFW (Labeled Faces in the Wild) 、FERET (Face Recognition Technology) <citation id="130" type="reference"><link href="115" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等, 大多是在有约束的环境中采集的, 图像质量普遍偏高, 导致高质量人脸图像和低质量人脸图像的比例分布不均, 对模型的训练有误导作用。</p>
                </div>
                <div class="p1">
                    <p id="54">本文实验所使用的人脸数据集, 是利用监控设备, 在实际无约束条件下采集的。使用了FFmpeg (Fast Forward MPEG) 抓取视频流数据, 通过MTCNN (Multi-Task Cascaded Convolutional Network) 人脸检测算法检测视频帧中人脸的位置, 裁剪后将图像数据保存在本地磁盘上。总共收集有效人脸图像498 459张。</p>
                </div>
                <div class="p1">
                    <p id="55">对这些人脸图像, 首先对人脸图像的光照、模糊度、姿态进行计算, 采用的方法分别为:通过图像直方图对光照均匀度进行判别, 使用PnP (Perspective-n-Point) 方法对人脸姿态进行估计, 采用Brenner梯度函数对人脸模糊度进行分析;然后将这三种因素的得分归一化后加权计算总得分, 用总得分进行粗分类;最后人工筛选进行精细分类。这些人脸图像共分为三类, 一类是高质量人脸图像数据集 (High Quality Face Dataset, HQFD) , 这类数据集中的人脸图像具有面部清晰、五官分明、呈对称分布, 且光照均匀、无遮挡的特点;一类是低质量人脸图像数据集 (Low Quality Face Dataset, LQFD) , 这类数据集中的人脸图像的特点是模糊、侧脸、光照分布不均或者遮挡严重;还有一类是介于高质量和低质量图像之间, 难以界定的数据集MQFD (Middle Quality Face Dataset) , 一般面部的轻微遮挡、表情夸张等属于这类数据集。通过清洗筛选, 最终得到的人脸图像数量如表1所示。</p>
                </div>
                <div class="area_img" id="56">
                    <p class="img_tit"><b>表</b>1 <b>人脸数据集统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Face dataset statistics</p>
                    <p class="img_note"></p>
                    <table id="56" border="1"><tr><td><br />数据集</td><td>图片总数</td></tr><tr><td><br />HQFD</td><td>71 338</td></tr><tr><td><br />MQFD</td><td>65 899</td></tr><tr><td><br />LQFD</td><td>81 401</td></tr><tr><td><br />总计</td><td>218 638</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="57">为了使CNN提取人脸图像具有辨识度的质量特征, 更好地拟合人脸图像到质量空间的映射关系, 训练模型时只选取HQFD和LQFD两个数据集, 其中令HQFD的样本标签为1, LQFD的样本标签为0。对HQFD和LQFD两个数据集再进行划分, 分别划分为训练集、验证集和测试集, 比例为3∶1∶1。对数据集进行预处理, 计算所有图像像素的均值和标准差, 然后将图像的像素值减去均值后除以标准差作标准化处理;并且在模型训练过程中, 对输入图像进行镜像操作, 即图像像素左右翻转, 这样数据集规模将增大一倍。</p>
                </div>
                <h3 id="58" name="58" class="anchor-tag">2 实验结果与分析</h3>
                <div class="p1">
                    <p id="59">本文采用了深度学习框架Caffe进行模型的训练和测试, 运行环境是Ubuntu14.04, 硬件平台使用了GPU加速训练, 其型号是GeForce GTX TITAN X。模型的部分训练参数如表2所示。</p>
                </div>
                <div class="area_img" id="60">
                    <p class="img_tit"><b>表</b>2 <b>训练模型的部分参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Partial parameters of training model</p>
                    <p class="img_note"></p>
                    <table id="60" border="1"><tr><td><br />参数</td><td>值</td><td></td><td>参数</td><td>值</td></tr><tr><td><br />base_lr</td><td>0.001</td><td></td><td>stepsize</td><td>50 000</td></tr><tr><td><br />lr_policy</td><td>“step”</td><td></td><td>max_iter</td><td>100 000</td></tr><tr><td><br />gamma</td><td>0.1</td><td></td><td>solver_mode</td><td>GPU</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="61">由于该训练是个二分类问题, 且数据特征的差异较明显, 所以在训练时该模型的准确率很快就得到了巨大的提升, 最后的测试准确率稳定在了99.41%。图2、图3分别展示了模型训练损失和测试准确率随迭代次数的变化关系。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903014_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练损失与迭代次数的关系" src="Detail/GetImg?filename=images/JSJY201903014_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练损失与迭代次数的关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903014_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Relationship between training loss and iteration times</p>

                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903014_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 测试准确率与迭代次数的关系" src="Detail/GetImg?filename=images/JSJY201903014_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 测试准确率与迭代次数的关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903014_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Relationship between test accuracy and iteration times</p>

                </div>
                <div class="p1">
                    <p id="65">从图2、图3中可以看出, 随着迭代次数的增加, 模型很快达到了收敛, 大约在迭代了15 000次后, 模型的测试准确率也达到了99%以上。当训练完成后, 模型的损失函数值处于稳定的收敛状态, 此时网络的参数达到了最优。</p>
                </div>
                <div class="p1">
                    <p id="66">模型训练完成后, 在测试数据集上进行测试。在低质量数据集上, 正确分类的占比为99.1%, 在高质量数据集上, 测试的准确性为98.7%, 整体的测试准确性达到了98.9%, 如表3所示, 说明模型在测试集上仍具有很好的分类效果。</p>
                </div>
                <div class="area_img" id="67">
                    <p class="img_tit"><b>表</b>3 <b>模型在不同测试集上的测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Model test results on different test sets</p>
                    <p class="img_note"></p>
                    <table id="67" border="1"><tr><td><br />测试集</td><td>总样本数</td><td>正确分类数</td><td>准确率/%</td></tr><tr><td><br />HQFD</td><td>14 268</td><td>14 082</td><td>98.7</td></tr><tr><td><br />LQFD</td><td>16 280</td><td>16 133</td><td>99.1</td></tr><tr><td><br />ALL</td><td>30 548</td><td>30 215</td><td>98.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="68">由于Softmax的输出表示输入属于每一类的概率值, 属于高质量一类的概率值越高, 则输入是高质量人脸图像的可能性越大。本文使用属于高质量一类的概率值作为对输入图像的质量评分。用打分方法对测试集人脸图像进行打分, 同时在通过电脑合成的两张完美人脸上用本文提出的方法进行打分, 打分的部分结果如图4所示。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 测试集部分图片的得分结果" src="Detail/GetImg?filename=images/JSJY201903014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 测试集部分图片的得分结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903014_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Score results of part test set images</p>

                </div>
                <div class="p1">
                    <p id="70">图4说明了人脸遮挡、模糊、光照不均匀、姿态等因素较差时, 得分也较低, 而两张完美人脸的得分都为1, 属于高质量人脸图像。同时对打分结果进行统计分析, 高质量的人脸图像的得分大部分高于0.8, 而在低质量测试集上, 大约90%的图像得分都低于0.1, 说明模型在测试集上仍具有较好的表现。</p>
                </div>
                <div class="p1">
                    <p id="71">为了验证模型在人脸模糊、光照、姿态以及遮挡方面的性能, 本实验使用公开数据集Color FERET、FIIQD (Illumination Quality Assessment for Face Images DataSet) <citation id="131" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和FDDB (Face Detection Data Set and Benchmark) , 分别验证模型在人脸姿态、光照和遮挡上的表现性能, 并取部分Color FERET数据集进行高斯模糊, 来验证模型在人脸模糊上的表现性能。实验结果表明, 模型对人脸图像的模糊因素具有明显的区分度, 在模糊度高于一定值后, 模型给出的评分急剧降低, 越模糊的人脸图像得到的评分越低, 如图5 (a) 所示。在光照方面, 模型对光照不均匀、光线较暗的人脸图像评分很低, 对光线均匀的人脸图像评分很高, 说明模型在光照方面表现出优越的性能, 如图5 (b) 所示。在人脸姿态方面, 对于偏转小于45°的人脸, 模型都评判为高质量, 而偏转角度过大的人脸都被评判为低质量, 说明模型对人脸姿态也有很强的适应性, 如图5 (c) 所示。在遮挡方面, 对于少量遮挡, 且能够清晰辨别出五官的前提下, 模型打分较高, 对于遮挡住面部五官的少量遮挡或者大范围遮挡的情况下, 模型给出的得分较低, 实验结果如图5 (d) 所示。</p>
                </div>
                <div class="p1">
                    <p id="72">上述实验表明:本文提出的用于人脸图像质量评价的CNN模型, 在人脸图像模糊、光照、姿态和遮挡方面都表现较好, 具有一定的判别能力;同时模型的参数较少, 只有9.5 MB, 但是达到了较高的判别准确率, 其前向传播一次耗时为4.1 ms, 运算速度快, 能够实时响应, 可用于人脸识别系统中人脸质量的实时评价。表4列出了数据集在不同网络结构下的准确率等信息, 可以看出, 在准确率相差不大的情况下, 该模型的参数规模比AlexNet (Alex Network) 、VGG-16 (Visual Geometry Group) 、VGG-19分别降低了95.6%、98.1%、98.2%, 运算效率得到极大的提高。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903014_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 模型对不同因素的评分结果展示" src="Detail/GetImg?filename=images/JSJY201903014_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 模型对不同因素的评分结果展示  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903014_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Model scoring results for different factors</p>

                </div>
                <div class="p1">
                    <p id="74">本文模型在实际应用中, 可根据实际情况设定一个阈值, 当评分高于该阈值时, 判定是高质量人脸图像, 可进行后续步骤处理, 否则判定是低质量人脸图像, 进行抛弃。</p>
                </div>
                <div class="area_img" id="75">
                    <p class="img_tit"><b>表</b>4 <b>不同模型的准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Accuracy comparison of different models</p>
                    <p class="img_note"></p>
                    <table id="75" border="1"><tr><td><br />序号</td><td>网络模型</td><td>模型大小/MB</td><td>准确率/%</td></tr><tr><td><br />1</td><td>AlexNet</td><td>217.0</td><td>99.74</td></tr><tr><td><br />2</td><td>VGG-16</td><td>513.0</td><td>99.83</td></tr><tr><td><br />3</td><td>VGG-19</td><td>533.0</td><td>99.71</td></tr><tr><td><br />4</td><td>Our Method</td><td>9.5</td><td>99.62</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">3 结语</h3>
                <div class="p1">
                    <p id="77">本文针对人脸识别中的低质量图像造成识别准确率低下的问题提出了解决方案。将人脸质量评价转化为二分类问题, 采用流行的CNN对训练集进行学习, 提取人脸图像的深层质量特征, 并加以分类。网络模型在测试集上达到了98.9%的分类准确率。通过将人脸图像属于高质量一类的概率作为其质量评价, 建立了人脸质量打分机制。最后实验结果表明, 模型对人脸图像的模糊、光照、姿态和遮挡等因素造成的影响具有较强的判别能力, 同时具有较高的运算效率。下一步工作是不断提高模型的准确性和适应性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="91">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WDZC201510013&amp;v=MDUxMDhIOVROcjQ5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXN3JOTWluUmJiRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>徐晓艳.人脸识别技术综述[J].电子测试, 2015 (5X) :30-35. (XU X Y.Survey of face recognition technology[J].Electronic Test, 2015 (5X) :30-35.) 
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding how image quality affects deep neural networks">

                                <b>[2]</b>DODGE S, KARAM L.Understanding how image quality affects deep neural networks[C]//Proceedings of the 2016 8th International Conference on Quality of Multimedia Experience.Piscataway, NJ:IEEE, 2016:11-16.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=How image degradations affect deep CNN-based face recognition?">

                                <b>[3]</b>KARAHAN S, YILDIRUM M K, KIRTAC K, et al.How image degradations affect deep CNN-based face recognition?[C]//Proceedings of the 2016 International Conference of the Biometrics Special Interest Group.Piscataway, NJ:IEEE, 2016:22-29.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Information technology-biometric data interchange formats-Part 5:face image data">

                                <b>[4]</b>ISO/IEC 19794-5.Information technology-biometric data interchange formats-Part 5:face image data[S].New York:A-merican National Standard Institute, 2001.
                            </a>
                        </p>
                        <p id="99">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Machine Readable Travel Documents">

                                <b>[5]</b>ICAO 9303.International civil aviation organization:machine readable travel documents[S].[S.l.]:International Civil Aviation Organization, 2006.
                            </a>
                        </p>
                        <p id="101">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancing face recognition from video sequences using robust statistics">

                                <b>[6]</b>BERRANI S A, GARCIA C.Enhancing face recognition from video sequences using robust statistics[C]//Proceedings of the 2005IEEE Conference on Advanced Video and Signal based Surveillance.Washington, DC:IEEE Computer Society, 2005:324-329.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face pose estimation and its application in video shot selection">

                                <b>[7]</b>YANG Z, AI H, WU B, et al.Face pose estimation and its application in video shot selection[C]//ICPR'04:Proceedings of the 17th International Conference on Pattern Recognition.Washington, DC:IEEE Computer Society, 2004, 1:322-325.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Standardization of face image sample quality">

                                <b>[8]</b>GAO X, LI S Z, LIU R, et al.Standardization of face image sample quality[C]//Proceedings of the 2007 International Conference on Biometrics, LNCS 4642.Berlin:Springer, 2007:242-251.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image-Quality-Based Adaptive Face Recognition">

                                <b>[9]</b>SELLAHEWA H, JASSIM S A.Image-quality-based adaptive face recognition[J].IEEE Transactions on Instrumentation and Measurement, 2010, 59 (4) :805-813.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Patch-based probabilistic image quality assessment for face selection and improved video-based face recognition">

                                <b>[10]</b>WONG Y K, CHEN S K, MAU S, et al.Patch-based probabilistic image quality assessment for face selection and improved videobased face recognition[C]//Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition Workshops.Piscataway, NJ:IEEE, 2011:74-81.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reducing the dimensionality of data with neural networks">

                                <b>[11]</b>HINTON G E, SALAKHUTDINOV R R.Reducing the dimensionality of data with neural networks[J].Science, 2006, 313 (5786) :504-507.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning face representation from scratch">

                                <b>[12]</b>YI D, LEI Z, LIAO S C, et al.Learning face representation from scratch[J].ar Xiv Preprint, 2014, 2014:ar Xiv.1411.7923.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The FERET evaluation methodology for face-recognition algorithms">

                                <b>[13]</b>PHILLIPS P J, MOON H, RIZVI S A, et al.The FERET evaluation methodology for face-recognition algorithms[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (10) :1090-1104.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Illumination quality assessment for face images:a benchmark and a convolutional neural networks based model">

                                <b>[14]</b>ZHANG L, ZHANG L, LI L.Illumination quality assessment for face images:a benchmark and a convolutional neural networks based model[C]//Proceedings of the 2017 International Conference on Neural Information Processing, LNCS 10636.Berlin:Springer, 2017:583-593.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903014" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903014&amp;v=MTExNDdmWnVacEZpRGxXN3JOTHo3QmQ3RzRIOWpNckk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="4" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
