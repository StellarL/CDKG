<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136666347502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907038%26RESULT%3d1%26SIGN%3dqXDKGApo0pP4TX1OFvkV%252f0Ks16c%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907038&amp;v=MDc4NjRkN0c0SDlqTXFJOUdiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVWJ2QUx6N0I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="2 AKAZE-SIFT算法 ">2 AKAZE-SIFT算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="2.1 AKAZE&lt;b&gt;特征检测&lt;/b&gt;">2.1 AKAZE<b>特征检测</b></a></li>
                                                <li><a href="#87" data-title="2.2 SIFT&lt;b&gt;特征描述&lt;/b&gt;">2.2 SIFT<b>特征描述</b></a></li>
                                                <li><a href="#89" data-title="2.3 &lt;b&gt;特征匹配与提纯&lt;/b&gt;">2.3 <b>特征匹配与提纯</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="3 匹配评价标准 ">3 匹配评价标准</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#95" data-title="3.1 &lt;b&gt;点对匹配正确的判断&lt;/b&gt;">3.1 <b>点对匹配正确的判断</b></a></li>
                                                <li><a href="#106" data-title="3.2 &lt;b&gt;召回率&lt;/b&gt;">3.2 <b>召回率</b></a></li>
                                                <li><a href="#109" data-title="3.3 &lt;b&gt;精准率&lt;/b&gt;">3.3 <b>精准率</b></a></li>
                                                <li><a href="#112" data-title="3.4 F1&lt;b&gt;值&lt;/b&gt;">3.4 F1<b>值</b></a></li>
                                                <li><a href="#115" data-title="3.5 &lt;b&gt;提取用时&lt;/b&gt;">3.5 <b>提取用时</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="4.1 &lt;b&gt;模拟倾斜摄影的图像变化&lt;/b&gt;">4.1 <b>模拟倾斜摄影的图像变化</b></a></li>
                                                <li><a href="#130" data-title="4.2 &lt;b&gt;结果分析&lt;/b&gt;">4.2 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#147" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="图1 本文算法流程">图1 本文算法流程</a></li>
                                                <li><a href="#86" data-title="图2 特征点检测">图2 特征点检测</a></li>
                                                <li><a href="#129" data-title="图3 图像模拟变化">图3 图像模拟变化</a></li>
                                                <li><a href="#139" data-title="图4 四种算法的&lt;i&gt;F&lt;/i&gt;1值比较">图4 四种算法的<i>F</i>1值比较</a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;所提算法与典型算法实验结果比较&lt;/b&gt;"><b>表</b>1 <b>所提算法与典型算法实验结果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="165">


                                    <a id="bibliography_1" title=" 杨国东, 王民水.倾斜摄影测量技术应用及展望[J].测绘与空间地理信息, 2016, 39 (1) :13-15, 18. (YANG G D, WANG M S.The tilt photographic measuration technique and expectation [J].Geomatics and Spatial Information Technology, 2016, 39 (1) :13-15, 18.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DBCH201601004&amp;v=MjQ2MThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pJUy9JWnJHNEg5Zk1ybzlGWUk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         杨国东, 王民水.倾斜摄影测量技术应用及展望[J].测绘与空间地理信息, 2016, 39 (1) :13-15, 18. (YANG G D, WANG M S.The tilt photographic measuration technique and expectation [J].Geomatics and Spatial Information Technology, 2016, 39 (1) :13-15, 18.) 
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_2" title=" 邢帅, 徐青, 刘军, 等.多源卫星遥感影像的光束法区域网平差[J].测绘学报, 2009, 38 (2) :125-130. (XING S, XU Q, LIU J, et al.Bundle block adjustment with multi-source satellite remote sensing images [J].Acta Geodaetica et Cartographica Sinica, 2009, 38 (2) :125-130.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB200902009&amp;v=MTQ0MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pKaVhUYkxHNEh0ak1yWTlGYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         邢帅, 徐青, 刘军, 等.多源卫星遥感影像的光束法区域网平差[J].测绘学报, 2009, 38 (2) :125-130. (XING S, XU Q, LIU J, et al.Bundle block adjustment with multi-source satellite remote sensing images [J].Acta Geodaetica et Cartographica Sinica, 2009, 38 (2) :125-130.) 
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_3" title=" 张祖勋, 张剑清.城市建模的途径与关键技术[J].世界科技研究与发展, 2003 (3) :23-29. (ZHANG Z X, ZHANG J Q.Solutions and core techniques of city modeling [J].World Science-Technology Research and Development, 2003 (3) :23-29.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJKF200303005&amp;v=MDI0MjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKTmlmQWFMRzRIdExNckk5RllZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         张祖勋, 张剑清.城市建模的途径与关键技术[J].世界科技研究与发展, 2003 (3) :23-29. (ZHANG Z X, ZHANG J Q.Solutions and core techniques of city modeling [J].World Science-Technology Research and Development, 2003 (3) :23-29.) 
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_4" title=" LOWE D G.Object recognition from local scale-invariant features [C]// Proceedings of the 7th IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 1999:1150-1157." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Recognition from Local Scale-Invariant Features">
                                        <b>[4]</b>
                                         LOWE D G.Object recognition from local scale-invariant features [C]// Proceedings of the 7th IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 1999:1150-1157.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_5" title=" LOWE D G.Distinctive image features from scale-invariant keypoints [J].International Journal of Computer Vision, 2004, 60 (2) :91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MTUyMjRWTHJOSVY4PU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXJs&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         LOWE D G.Distinctive image features from scale-invariant keypoints [J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_6" title=" BAY H, TUYTELAARS T, GOOL L V.SURF:speeded up robust features [C]// Proceedings of the 2006 European Conference on Computer Vision, LNCS 3951.Berlin:Springer, 2006:404-417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Surf:Speeded up robust features">
                                        <b>[6]</b>
                                         BAY H, TUYTELAARS T, GOOL L V.SURF:speeded up robust features [C]// Proceedings of the 2006 European Conference on Computer Vision, LNCS 3951.Berlin:Springer, 2006:404-417.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_7" title=" BRADSKI G, KONOLIGE K, RABAUD V, et al.ORB:an efficient alternative to SIFT or SURF [C]// Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:2564-2571." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to SIFT or SURF">
                                        <b>[7]</b>
                                         BRADSKI G, KONOLIGE K, RABAUD V, et al.ORB:an efficient alternative to SIFT or SURF [C]// Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:2564-2571.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_8" title=" ALCANTARILLA P F, BARTOLI A, DAVISON A J.KAZE features [C]// Proceedings of the 2012 European Conference on Computer Vision, LNCS 7577.Berlin:Springer, 2012:214-227." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=KAZE features">
                                        <b>[8]</b>
                                         ALCANTARILLA P F, BARTOLI A, DAVISON A J.KAZE features [C]// Proceedings of the 2012 European Conference on Computer Vision, LNCS 7577.Berlin:Springer, 2012:214-227.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_9" title=" ALCANTARILLA P F, NUEVO J, BARTOLI A J.Fast explicit diffusion for accelerated features in nonlinear scale spaces [C]// Proceedings of the 2013 British Machine Vision Conference.Durham, UK:BMVA Press, 2013:1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast explicit diffusion for accelerated features in nonlinear scale spaces">
                                        <b>[9]</b>
                                         ALCANTARILLA P F, NUEVO J, BARTOLI A J.Fast explicit diffusion for accelerated features in nonlinear scale spaces [C]// Proceedings of the 2013 British Machine Vision Conference.Durham, UK:BMVA Press, 2013:1-11.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_10" title=" 张一.无人机遥感影像点特征匹配算法研究[D].郑州:解放军信息工程大学, 2015:39. (ZHANG Y.Research on point feature matching algorithms of UAV remote sensing images [D].Zhengzhou:PLA Information Engineering University, 2015:39.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016058382.nh&amp;v=MjQwMzMzenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pWRjI2R0xPOUZ0TEVyWkViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         张一.无人机遥感影像点特征匹配算法研究[D].郑州:解放军信息工程大学, 2015:39. (ZHANG Y.Research on point feature matching algorithms of UAV remote sensing images [D].Zhengzhou:PLA Information Engineering University, 2015:39.) 
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_11" title=" 王晓红, 邓仕雄, 何志伟, 等.结合SURF算法和单应性矩阵的无人机影像匹配[J].测绘通报, 2018 (7) :38-42. (WANG X H, DENG S X, HE Z W, et al.Study of UAV image matching based on SURF algorithm and homography matrix [J].Bulletin of Surveying and Mapping, 2018 (7) :38-42.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB201807010&amp;v=MDUwMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVnI3SkppWGZiTEc0SDluTXFJOUVaSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         王晓红, 邓仕雄, 何志伟, 等.结合SURF算法和单应性矩阵的无人机影像匹配[J].测绘通报, 2018 (7) :38-42. (WANG X H, DENG S X, HE Z W, et al.Study of UAV image matching based on SURF algorithm and homography matrix [J].Bulletin of Surveying and Mapping, 2018 (7) :38-42.) 
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_12" title=" 宋伟, 王永波.基于改进AKAZE算法的无人机影像匹配[J].电子测量与仪器学报, 2018, 32 (8) :96-102. (SONG W, WANG Y B.UAV image registration based on improved AKAZE algorithm [J].Journal of Electronic Measurement and Instrumentation, 2018, 32 (8) :96-102.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201808014&amp;v=MDI1NzN5L2dWcjdKSVRmQ2Q3RzRIOW5NcDQ5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         宋伟, 王永波.基于改进AKAZE算法的无人机影像匹配[J].电子测量与仪器学报, 2018, 32 (8) :96-102. (SONG W, WANG Y B.UAV image registration based on improved AKAZE algorithm [J].Journal of Electronic Measurement and Instrumentation, 2018, 32 (8) :96-102.) 
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_13" title=" 张春美, 龚志辉, 黄艳.几种特征点提取算法的性能评估及改进[J].测绘科学技术学报, 2008, 25 (3) :231-234. (ZHANG C M, GONG Z H, HUANG Y.Performance evaluation and improvement of several feature point detectors [J].Journal of Geomatics Science and Technology, 2008, 25 (3) :231-234.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFJC200803022&amp;v=MjE4ODFyQ1VSN3FmWnVac0Z5L2dWcjdKTHl2QmJiRzRIdG5Nckk5SFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张春美, 龚志辉, 黄艳.几种特征点提取算法的性能评估及改进[J].测绘科学技术学报, 2008, 25 (3) :231-234. (ZHANG C M, GONG Z H, HUANG Y.Performance evaluation and improvement of several feature point detectors [J].Journal of Geomatics Science and Technology, 2008, 25 (3) :231-234.) 
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_14" title=" 叶沅鑫, 慎利.面向遥感影像匹配的特征点检测算子性能评估[J].西南交通大学学报, 2016, 51 (6) :1170-1176. (YE Y X, SHEN L.Performance evaluation of interest point detectors for remote sensing image matching [J].Journal of Southwest Jiaotong University, 2016, 51 (6) :1170-1176.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNJT201606017&amp;v=MTc5MzBac0Z5L2dWcjdKUFNQQmVyRzRIOWZNcVk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         叶沅鑫, 慎利.面向遥感影像匹配的特征点检测算子性能评估[J].西南交通大学学报, 2016, 51 (6) :1170-1176. (YE Y X, SHEN L.Performance evaluation of interest point detectors for remote sensing image matching [J].Journal of Southwest Jiaotong University, 2016, 51 (6) :1170-1176.) 
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_15" title=" 胡佳怡, 赵栋梁, 刘荣, 等.基于特征的影像匹配算法性能评估[J].北京测绘, 2018, 32 (2) :179-185. (HU J Y, ZHAO D L, LIU R, et al.Performance evaluation of feature-based image matching algorithms [J].Beijing Surveying and Mapping, 2018, 32 (2) :179-185.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJCH201802007&amp;v=MDczNzFzRnkvZ1ZyN0pKeWZJWnJHNEg5bk1yWTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         胡佳怡, 赵栋梁, 刘荣, 等.基于特征的影像匹配算法性能评估[J].北京测绘, 2018, 32 (2) :179-185. (HU J Y, ZHAO D L, LIU R, et al.Performance evaluation of feature-based image matching algorithms [J].Beijing Surveying and Mapping, 2018, 32 (2) :179-185.) 
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_16" title=" 贾雯晓, 张贵仓, 汪亮亮, 等.基于SIFT和改进的RANSAC图像配准算法[J].计算机工程与应用, 2018, 54 (2) :203-207. (JIA W X, ZHANG G C, WANG L L, et al.Image registration algorithm based on SIFT and improved RANSAC [J].Computer Engineering and Applications, 2018, 54 (2) :203-207.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201802033&amp;v=MzE4MzMzenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pMejdNYWJHNEg5bk1yWTlHWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         贾雯晓, 张贵仓, 汪亮亮, 等.基于SIFT和改进的RANSAC图像配准算法[J].计算机工程与应用, 2018, 54 (2) :203-207. (JIA W X, ZHANG G C, WANG L L, et al.Image registration algorithm based on SIFT and improved RANSAC [J].Computer Engineering and Applications, 2018, 54 (2) :203-207.) 
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_17" title=" 陈艺虾, 孙权森, 徐焕宇, 等.SURF算法和RANSAC算法相结合的遥感图像匹配方法[J].计算机科学与探索, 2012, 6 (9) :822-828. (CHEN Y X, SUN Q S, XU H Y, et al.Matching method of remote sensing images based on SURF algorithm and RANSAC algorithm [J].Journal of Frontiers of Computer Science and Technology, 2012, 6 (9) :822-828.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201209007&amp;v=MjMyMTg3SkxqWGZmYkc0SDlQTXBvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         陈艺虾, 孙权森, 徐焕宇, 等.SURF算法和RANSAC算法相结合的遥感图像匹配方法[J].计算机科学与探索, 2012, 6 (9) :822-828. (CHEN Y X, SUN Q S, XU H Y, et al.Matching method of remote sensing images based on SURF algorithm and RANSAC algorithm [J].Journal of Frontiers of Computer Science and Technology, 2012, 6 (9) :822-828.) 
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_18" title=" 高帅华, 安巧绒.RANSAC在影像匹配中的应用[J].中国科技信息, 2018 (6) :69-70. (GAO S H, AN Q R.Application of RANSAC in image matching [J].China Science and Technology Information, 2018 (6) :69-70.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXJK201806031&amp;v=MDM5MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pQVFhCWmJHNEg5bk1xWTlHWllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         高帅华, 安巧绒.RANSAC在影像匹配中的应用[J].中国科技信息, 2018 (6) :69-70. (GAO S H, AN Q R.Application of RANSAC in image matching [J].China Science and Technology Information, 2018 (6) :69-70.) 
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_19" title=" 代玉强, 杨絮, 熊昊, 等.SIFT特征算法改进研究[J].现代计算机 (专业版) , 2018 (17) :55-59. (DAI Y Q, YANG X, XIONG H, et al.Research on the improvement of SIFT feature algorithm [J].Modern Computer (Professional Edition) , 2018 (17) :55-59." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201817012&amp;v=MjgyNjFTbkJmYkc0SDluTnFJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVnI3SlA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         代玉强, 杨絮, 熊昊, 等.SIFT特征算法改进研究[J].现代计算机 (专业版) , 2018 (17) :55-59. (DAI Y Q, YANG X, XIONG H, et al.Research on the improvement of SIFT feature algorithm [J].Modern Computer (Professional Edition) , 2018 (17) :55-59.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_20" title=" 陈虹, 肖越, 肖成龙, 等.基于SIFT算子融合最大相异系数的自适应图像匹配算法[J].计算机应用, 2018, 38 (5) :1410-1414. (CHEN H, XIAO Y, XIAO C L, et al.Adaptive image matching algorithm based on SIFT operator fused with maximum dissimilarity coefficient [J].Journal of Computer Applications, 2018, 38 (5) :1410-1414.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805033&amp;v=MjIxNDk5bk1xbzlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pMejdCZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         陈虹, 肖越, 肖成龙, 等.基于SIFT算子融合最大相异系数的自适应图像匹配算法[J].计算机应用, 2018, 38 (5) :1410-1414. (CHEN H, XIAO Y, XIAO C L, et al.Adaptive image matching algorithm based on SIFT operator fused with maximum dissimilarity coefficient [J].Journal of Computer Applications, 2018, 38 (5) :1410-1414.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-10 07:00</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),2093-2097 DOI:10.11772/j.issn.1001-9081.2018122564            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>适用于倾斜影像的加速KAZE-SIFT特征提取算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%84%E5%8D%95&amp;code=41379262&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薄单</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%AE%97%E6%98%A5&amp;code=28614602&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李宗春</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%99%93%E5%8D%97&amp;code=32314813&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王晓南</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B9%94%E6%B6%B5%E6%96%87&amp;code=42202202&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">乔涵文</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E5%9C%B0%E7%90%86%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0199248&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息工程大学地理空间信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E6%B4%9B%E9%98%B3%E7%94%B5%E5%AD%90%E8%A3%85%E5%A4%87%E8%AF%95%E9%AA%8C%E4%B8%AD%E5%BF%83&amp;code=0146460&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国洛阳电子装备试验中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统正摄影像的特征提取算法处理倾斜影像匹配效果不佳的问题, 在已有特征提取算法的基础上, 提出了一种适用于倾斜影像的特征提取算法——加速KAZE-尺度不变特征变换 (AKAZE-SIFT) 算法。首先, 为保证特征检测的准确性与独特性, 采用充分保留图像轮廓信息的加速KAZE (AKAZE) 算子进行特征检测;其次, 为提升特征描述的稳定性, 采用稳健的尺度不变特征变换 (SIFT) 算子进行特征描述;然后, 依据目标特征向量和候选特征向量间的欧氏距离确定粗匹配点对;最后, 采用随机抽样一致性算法进行单应性约束, 提高匹配纯度。模拟影像在倾斜摄影条件下的模糊、旋转、亮度、视角和尺度变化, 对特征提取算法性能进行评估, 实验结果表明, AKAZE-SIFT算法相比SIFT算法和AKAZE算法召回率分别提高了12.8%和5.3%, 精准率提高了6.5%和6.1%, F1值提升了13.8%和5.6%;提取效率优于SIFT算法, 略逊于AKAZE。AKAZE-SIFT算法具有良好的检测和描述能力, 更适用于倾斜影像特征提取。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9FKAZE%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速KAZE算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%BA%E5%BA%A6%E4%B8%8D%E5%8F%98%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尺度不变特征变换算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%80%BE%E6%96%9C%E5%BD%B1%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">倾斜影像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征匹配;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    薄单 (1985—) , 男, 安徽太和人, 工程师, 硕士研究生, 主要研究方向:计算机视觉、精密工程测量;;
                                </span>
                                <span>
                                    *李宗春 (1973—) , 男, 山东日照人, 教授, 博士, 主要研究方向:精密工程测量、计算机视觉;电子邮箱13838092876@139.com;
                                </span>
                                <span>
                                    王晓南 (1986—) , 男, 河南内乡人, 工程师, 主要研究方向:大地测量、工程测量;;
                                </span>
                                <span>
                                    乔涵文 (1993—) , 女, 湖北枣阳人, 助理工程师, 主要研究方向:大地测量、工程测量。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-02</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金青年基金资助项目 (41701463);</span>
                                <span>河南省科技攻关项目 (172102210020);</span>
                    </p>
            </div>
                    <h1><b>Accelerated KAZE-SIFT feature extraction algorithm for oblique images</b></h1>
                    <h2>
                    <span>BO Dan</span>
                    <span>LI Zongchun</span>
                    <span>WANG Xiaonan</span>
                    <span>QIAO Hanwen</span>
            </h2>
                    <h2>
                    <span>Institute of Geospatial Information, Information Engineering University</span>
                    <span>Luoyang Electronic Equipment Testing Center</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Concerning that traditional vertical image feature extraction algorithms have poor effect on oblique image matching, a feature extraction algorithm, based on Accelerated KAZE (AKAZE) and Scale Invariant Feature Transform (SIFT) algorithm called AKAZE-SIFT was proposed. Firstly, in order to guarantee the accuracy and distinctiveness of image feature detection, AKAZE operator, which fully preserves the contour information of image, was utilized for feature detection. Secondly, the robust SIFT operator was used to improve the stability of feature description. Thirdly, the rough matching point pairs were determined by the Euclidean distance between object feature point vector and candidate feature point vectors. Finally, the homography constraint was applied to improve the matching purity by random sample consensus algorithm. To evaluate the performance of the feature extraction algorithm, the blur, rotation, brightness, viewpoint and scale changes under the condition of oblique photography were simulated. The experimental results show that compared with SIFT algorithm and AKAZE algorithm, the recall of AKAZE-SIFT is improved by 12.8% and 5.3% respectively, the precision of AKAZE-SIFT is increased by 6.5% and 6.1% respectively, the F1 measure of AKAZE-SIFT is elevated by 13.8% and 5.6% respectively and the efficiency of the proposed algorithm is higher than that of SIFT and slightly worse than that of AKAZE. For the excellent detection and description performance, AKAZE-SIFT algorithm is more suitable for oblique image feature extraction.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Accelerated%20KAZE%20(AKAZE)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Accelerated KAZE (AKAZE) algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Scale%20Invariant%20Feature%20Transform%20(SIFT)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Scale Invariant Feature Transform (SIFT) algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=oblique%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">oblique image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature matching;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    BO Dan, born in 1985, M. S. candidate, engineer. His research interests include computer vision, precision engineering survey. ;
                                </span>
                                <span>
                                    LI Zongchun, born in 1973, Ph. D. , professor. His research interests include precision engineering survey, computer vision. ;
                                </span>
                                <span>
                                    WANG Xiaonan, born in 1986, engineer. His research interests include geodetic survey, engineering survey.;
                                </span>
                                <span>
                                    QIAO Hanwen, born in 1993, assistant engineer. Her research interests include geodetic survey, engineering survey.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-02</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China Youth Foud (41701463);</span>
                                <span>the Key Scientific and Technological Project of Henan Province (172102210020);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="44">倾斜摄影测量技术通过多视角摄影获取建筑物顶部和侧面信息, 克服了传统垂直摄影测量因拍摄视角单一, 只能获得建筑物的高度和顶部纹理信息的不足, 得到了迅猛的发展。常用无人机搭载5台相机, 从1个下视方向和4个侧视方向采集影像, 并由定位定姿系统 (Position and Orientation System, POS) 记录摄影位置、飞行航高、航速和航向等信息。倾斜影像经过特征匹配、多视影像联合平差、密集匹配, 构建地物三维模型。</p>
                </div>
                <div class="p1">
                    <p id="45">由于倾斜影像受多相机焦距和倾角不一致影响, 图像尺度和亮度差异明显;受旋偏角和视角影响, 图像旋转和视角变化剧烈;受云雾、光线和视线影响, 模糊、阴影和遮挡现象突出, 导致影像特征难以实现良好的重现性和高度的独特性。简单应用传统基于垂直正摄影像的特征匹配算法, 往往出现匹配数量少且匹配正确率低, 严重影响影像联合平差的精度<citation id="205" type="reference"><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><link href="169" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 故对倾斜影像提取优质高效的特征是倾斜摄影测量技术的关键。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="47">自Lowe<citation id="210" type="reference"><link href="171" rel="bibliography" /><link href="173" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>提出尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法以来, 众多学者在其基础上提出了一系列的特征提取算法, 如加速稳健特征 (Speeded Up Robust Feature, SURF) <citation id="206" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、ORB (Oriented FAST and Rotated BRIEF) <citation id="207" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、KAZE<citation id="208" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、加速KAZE (Accelerated KAZE, AKAZE) <citation id="209" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法等, 用来解决图像特征匹配的问题。</p>
                </div>
                <div class="p1">
                    <p id="48">SIFT算法很好地保持了尺度、旋转和亮度不变性, 作为主流算法, 广泛应用在遥感图像的自动配准中, 但该算法计算量大、耗时长。SURF算法在SIFT算法的基础上进行了改进, 引入积分图像的概念, 对高斯差分进行了简化, 把卷积运算转化为简易的加减运算, 降低了算法复杂度, 在提高程序运行速度的同时, 提取效果与SIFT算法相当。SIFT和SURF算法使用高斯滤波构建图像尺度空间时, 对图像的轮廓和噪声同时进行了高斯平滑, 模糊了轮廓信息, 造成边界模糊和细节丢失, 影响特征定位的独特性和准确性。为解决上述问题, KAZE特征算法引入非线性扩散滤波的方法, 构建非线性尺度空间, 具有鲁棒性强、匹配效果好的优点, 但运行效率明显低于其他算法, 限制了其在工程实践中的应用。AKAZE算法作为KAZE算法的加速版本, 采用改进的局部差分二值描述符 (Modified-Local Difference Binary descriptor, M-LDB) , 大幅缩短了特征提取的时间。AKAZE算法通过非线性滤波构建尺度空间, 自适应滤除噪声和细枝末节的同时, 保留图像轮廓的关键特征信息, 但由于M-LDB描述符的稳定性弱于SIFT描述符, 使得AKAZE算法总体表现不如SIFT算法<citation id="211" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="49">文献<citation id="212" type="reference">[<a class="sup">11</a>]</citation>针对无人机影像受拍摄条件或区域复杂环境的影响, 匹配效果不佳的问题, 提出了SURF算法和单应性约束结合的方法, 对无人机影像进行特征匹配。文献<citation id="213" type="reference">[<a class="sup">12</a>]</citation>为了稳定、高效、精确地进行无人影像匹配, 提出一种改进的AKAZE算法, 首先利用AKAZE算法构造非线性尺度空间检测特征点, 然后利用学习安排的三元组 (Learned Arrangements of Three patCH, LATCH) 描述符对获取的特征点进行描述。文献<citation id="214" type="reference">[<a class="sup">13</a>]</citation>对近景影像和普通影像数据进行研究, 评估了几种特征提取算法在旋转、亮度及尺度等方面的性能。文献<citation id="215" type="reference">[<a class="sup">14</a>]</citation>对遥感影像进行研究, 在光谱、时相及尺度方面分析了特征提取算法的稳定性。文献<citation id="216" type="reference">[<a class="sup">15</a>]</citation>对密集城区、稀疏城区、平原及高山的正摄影像进行特征匹配实验, 指出SURF-SIFT算法具有良好的性能, AKAZE算法次之。</p>
                </div>
                <div class="p1">
                    <p id="50">上述文献主要研究无人机正摄影像, 缺少针对倾斜影像特征提取算法的性能评估研究。倾斜影像的影像配准, 更加注重特征提取质量和匹配效果, 为此, 结合高性能特征提取算法, 本文提出一种适用于倾斜影像的AKAZE-SIFT特征提取算法。首先, 为保证特征检测的独特性和准确性, 在非线性尺度空间中, 采用AKAZE算子检测特征;其次, 采用稳健的SIFT算子描述特征向量;然后, 根据特征向量的欧氏距离进行粗匹配;最后, 采用单应性约束的随机抽样一致性 (RANdom SAmple Consensus, RANSAC) <citation id="217" type="reference"><link href="195" rel="bibliography" /><link href="197" rel="bibliography" /><link href="199" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>算法提高匹配纯度。本文提出的特征匹配算法流程如图1所示。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">2 AKAZE-SIFT算法</h3>
                <h4 class="anchor-tag" id="52" name="52">2.1 AKAZE<b>特征检测</b></h4>
                <div class="p1">
                    <p id="53">AKAZE作为加速的KAZE算法, 采用快速显式扩散 (Fast Explicit Diffusion, FED) 算法替代加性算子分裂 (Additive Operator Splitting, AOS) 算法构建非线性尺度空间。既保留了非线性尺度空间特征检测的独特性和准确性的优点, 又较KAZE算法提高了计算速度。AKAZE算法首先通过FED算法构建非线性尺度空间, 然后利用Hessian矩阵行列式检测特征点位置。</p>
                </div>
                <div class="area_img" id="54">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法流程" src="Detail/GetImg?filename=images/JSJY201907038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="55" name="55">2.1.1 构建非线性尺度空间</h4>
                <div class="p1">
                    <p id="56">AKAZE算法使用各向异性扩散公式, 通过非线性扩散滤波器构造尺度空间, 使得亮度在平缓区域扩散快, 在边缘处扩散慢, 充分保留了图像边缘和细节。非线性扩散滤波的各向异性扩散公式可表示为:</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">L</mi></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mtext>d</mtext><mtext>i</mtext><mtext>v</mtext></mrow></math></mathml> (c (x, y, t) ·ᐁ<b><i>L</i></b>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="59">式中:<b><i>L</i></b>为图像亮度矩阵;div、<i>c</i> (<i>x</i>, <i>y</i>, <i>t</i>) 和ᐁ分别表示散度函数、传导函数和梯度函数; (<i>x</i>, <i>y</i>) 为图像坐标;时间<i>t</i>为尺度参数。</p>
                </div>
                <div class="p1">
                    <p id="60">传导函数<i>c</i> (<i>x</i>, <i>y</i>, <i>t</i>) 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>c</i> (<i>x</i>, <i>y</i>, <i>t</i>) =<i>g</i> (|ᐁ<b><i>L</i></b><sub><i>σ</i></sub> (<i>x</i>, <i>y</i>, <i>t</i>) |)      (2) </p>
                </div>
                <div class="p1">
                    <p id="62">式中:ᐁ<b><i>L</i></b><sub><i>σ</i></sub>表示图像<b><i>L</i></b>经过尺度因子<i>σ</i>高斯平滑后的梯度图像;<i>g</i> (·) 为传导函数, 默认采用优先保留宽度较大区域的<i>g</i><sub>2</sub>函数。<i>g</i><sub>2</sub>函数可表示为:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>g</i><sub>2</sub> (|ᐁ<b><i>L</i></b><sub><i>σ</i></sub>|) =1/ (1+|ᐁ<b><i>L</i></b><sub><i>σ</i></sub>|<sup>2</sup>/<i>λ</i><sup>2</sup>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="64">式中:参数<i>λ</i>为控制扩散程度的对比度因子。</p>
                </div>
                <div class="p1">
                    <p id="65">对比度因子<i>λ</i>依据梯度图像ᐁ<b><i>L</i></b><sub><i>σ</i></sub>直方图的分位值计算, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><mo>=</mo><mfrac><mrow><mi>b</mi><mi>i</mi><mi>n</mi></mrow><mrow><mi>Ν</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>B</mi><mi>i</mi><mi>n</mi><mi>s</mi></mrow></mfrac><mo>×</mo><mi>Μ</mi><mi>a</mi><mi>x</mi><mi>G</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">式中:<i>NumberofBins</i>为梯度直方图的分位数量;<i>MaxGradient</i>为梯度直方图的最大梯度;<i>bin</i>为梯度直方图达到70%时的分位值。</p>
                </div>
                <div class="p1">
                    <p id="68">对输入图像进行高斯滤波, 将平滑后的影像降采样2倍形成下一组影像, 重复降采样过程, 构建影像金字塔 (<i>O</i>组<i>S</i>子层) 。图像尺度因子<i>σ</i><sub><i>i</i></sub>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>σ</i><sub><i>i</i></sub> (<i>o</i>, <i>s</i>) =2<sup><i>o</i>+<i>s</i>/<i>S</i></sup>      (5) </p>
                </div>
                <div class="p1">
                    <p id="70">式中:<i>i</i>∈[0, 1, …, <i>O</i>·<i>S</i>];<i>o</i>∈[0, 1, …, <i>O</i>-1];<i>s</i>∈[0, 1, …, <i>S</i>-1]。</p>
                </div>
                <div class="p1">
                    <p id="71">由于非线性扩散滤波模型是以时间为单位, 需要建立尺度<i>σ</i><sub><i>i</i></sub>到扩散时间<i>t</i><sub><i>i</i></sub>之间的转换关系, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="72"><i>t</i><sub><i>i</i></sub>=<i>σ</i><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></math></mathml>/2      (6) </p>
                </div>
                <div class="p1">
                    <p id="74">根据各向异性扩散式 (1) , 显式构建非线性尺度空间, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="75"><b><i>L</i></b><sup><i>i</i>+1</sup>= (<b><i>I</i></b>+<i>τ</i><b><i>A</i></b> (<b><i>L</i></b><sup><i>i</i></sup>) ) <b><i>L</i></b><sup><i>i</i></sup>      (7) </p>
                </div>
                <div class="p1">
                    <p id="76">式中:<b><i>I</i></b>为单位矩阵;<b><i>A</i></b> (<b><i>L</i></b><sup><i>i</i></sup>) 为<b><i>L</i></b><sup><i>i</i></sup>的传导矩阵;<i>τ</i>为时间步长。</p>
                </div>
                <div class="p1">
                    <p id="77">根据先验估计<b><i>L</i></b><sup><i>i</i>+1, 0</sup>=<b><i>L</i></b><sup><i>i</i></sup>, 不断迭代生成<b><i>L</i></b><sup><i>i</i>+1, <i>n</i></sup>, 迭代过程可表示为:</p>
                </div>
                <div class="p1">
                    <p id="78"><b><i>L</i></b><sup><i>i</i>+1, <i>j</i>+1</sup>= (<b><i>I</i></b>+<i>τ</i><sub><i>j</i></sub><b><i>A</i></b> (<b><i>L</i></b><sup><i>i</i></sup>) ) <b><i>L</i></b><sup><i>i</i>+1, <i>j</i></sup>; <i>j</i>∈[0, 1, …, <i>n</i>-1]      (8) </p>
                </div>
                <div class="p1">
                    <p id="79">式中:<i>n</i>为迭代次数;<i>τ</i><sub><i>j</i></sub>=<i>τ</i><sub>max</sub>/[2cos<sup>2</sup> (π (2<i>j</i>+1) / (4<i>n</i>+2) ) ];<i>τ</i><sub>max</sub>为满足显式扩展稳定性条件的最大步长。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">2.1.2 特征检测</h4>
                <div class="p1">
                    <p id="81">非线性尺度空间构建后, 采用<i>Hessian</i>矩阵检测特征点位置, 此处采取与<i>SIFT</i>相同的检测策略, 即寻找归一化后不同尺度的<i>Hessian</i>矩阵行列式<i>L</i><sub>Hessian</sub>的局部极值点, <i>L</i><sub>Hessian</sub>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="82"><i>L</i><sub>Hessian</sub>=<i>σ</i><sup>2</sup> (<i>L</i><sub><i>xx</i></sub><i>L</i><sub><i>yy</i></sub>-<i>L</i><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="84">式中:<i>L</i><sub><i>xx</i></sub>、<i>L</i><sub><i>yy</i></sub>分别为水平方向和垂直方向的二阶导数;<i>L</i><sub><i>xy</i></sub>为二阶交叉导数。</p>
                </div>
                <div class="p1">
                    <p id="85">在非线性尺度空间内, 比较当前点与上下两层及当前层 (3×3邻域) 的26个点的值, 判断其是否为极值点, 从而确定特征点的位置, 如图2所示。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907038_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 特征点检测" src="Detail/GetImg?filename=images/JSJY201907038_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 特征点检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907038_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Feature point detection</p>

                </div>
                <h4 class="anchor-tag" id="87" name="87">2.2 SIFT<b>特征描述</b></h4>
                <div class="p1">
                    <p id="88">首先, 在非线性尺度空间内, 建立梯度方向直方图, 求取特征点的主方向;其次, 以特征点为中心, 将特征点邻域内图像梯度的位置和方向旋转至主方向, 实现描述符的旋转不变性;然后, 在特征点邻域内对影像特征进行描述, 把12×12的邻域划分成4×4个等间隔子区域, 计算每个子区域8个方向的梯度方向直方图, 形成128维<i>SIFT</i>特征向量。由于关于<i>SIFT</i>特征描述的研究<citation id="218" type="reference"><link href="193" rel="bibliography" /><link href="195" rel="bibliography" /><link href="201" rel="bibliography" /><link href="203" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>较多, 此处不再赘述。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2.3 <b>特征匹配与提纯</b></h4>
                <div class="p1">
                    <p id="90">特征向量生成后, 根据向量间的欧氏距离<i>E</i>进行特征匹配。<i>E</i>值越小, 表明两个向量越相似。欧氏距离<i>E</i>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><mo>, </mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>1</mn><mn>2</mn><mn>8</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>b</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">式中:特征向量<b><i>a</i></b>= (<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>…, <i>a</i><sub>128</sub>) ;<b><i>b</i></b>= (<i>b</i><sub>1</sub>, <i>b</i><sub>2</sub>, …, <i>b</i><sub>128</sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="93">由于相似的纹理特征, 在匹配的特征点对中, 存在大量的误匹配点对, 需要对匹配结果提纯, 减少错误匹配数量, 提高特征匹配效果。本文采用单应性约束的RANSAC算法<citation id="219" type="reference"><link href="195" rel="bibliography" /><link href="197" rel="bibliography" /><link href="199" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>对匹配结果进行提纯。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag">3 匹配评价标准</h3>
                <h4 class="anchor-tag" id="95" name="95">3.1 <b>点对匹配正确的判断</b></h4>
                <div class="p1">
                    <p id="96">在参考图像和待匹配图像上, 若两个特征向量间的欧氏距离<i>E</i>很小, 判断这两个特征点对应同一场景, 认为是同名点对, 坐标分别为 (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) 和 (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) 。参考图像特征点 (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) 经理论单应性矩阵<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Η</mi><mo>^</mo></mover></math></mathml>映射到待匹配图像的理论点位为 (<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>^</mo></mover></math></mathml><sub>1</sub>′, <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml><sub>1</sub>′) , 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>x</mi><mo>^</mo></mover><msub><mrow></mrow><msup><mn>1</mn><mo>′</mo></msup></msub></mtd></mtr><mtr><mtd><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><msup><mn>1</mn><mo>′</mo></msup></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">Η</mi><mo>^</mo></mover><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>1</mn><mn>3</mn></mrow></msub></mtd></mtr><mtr><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>2</mn><mn>3</mn></mrow></msub></mtd></mtr><mtr><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>3</mn><mn>1</mn></mrow></msub></mtd><mtd><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mn>3</mn><mn>2</mn></mrow></msub></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">在待匹配图像上, 理论点位 (<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>^</mo></mover></math></mathml><sub>1</sub>′, <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml><sub>1</sub>′) 与实际匹配点位 (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) 存在偏差, 即重投影误差<i>d</i>, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo>=</mo><msqrt><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>^</mo></mover><msub><mrow></mrow><msup><mn>1</mn><mo>′</mo></msup></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><msup><mn>1</mn><mo>′</mo></msup></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">若<i>d</i>小于经验阈值 (本文设为3像素) , 则认为点对匹配正确;否则认为点对匹配错误。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">3.2 <b>召回率</b></h4>
                <div class="p1">
                    <p id="107">召回率 (<i>Recall</i>) 为两幅相似影像中的正确匹配点对数<i>n</i>与理论特征点对数量<i>M</i>的比值, 反映了特征检测的性能, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="108"><i>Recall</i>= (<i>n</i>/<i>M</i>) ×100%      (13) </p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">3.3 <b>精准率</b></h4>
                <div class="p1">
                    <p id="110">精准率 (<i>Precision</i>) 即匹配正确率, 为两幅图像中正确匹配点对数量<i>n</i>与特征匹配点对数量<i>N</i>的比值, 反映了特征描述的稳定性, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="111"><i>Precision</i>= (<i>n</i>/<i>N</i>) ×100%      (14) </p>
                </div>
                <h4 class="anchor-tag" id="112" name="112">3.4 F1<b>值</b></h4>
                <div class="p1">
                    <p id="113"><i>F</i>1值 (<i>F</i>1-<i>measure</i>) 为召回率和精准率的加权调和均值, 同时兼顾了召回率和精准率, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo stretchy="false">) </mo><mo>/</mo><mn>2</mn></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">3.5 <b>提取用时</b></h4>
                <div class="p1">
                    <p id="116">每个特征提取的平均用时<i>Point</i>_<i>Time</i>为每幅图像提取特征平均用时<i>TIME</i>与提取特征点的数目均值<i>NUM</i>的比值, 反映了特征提取算法的运行效率, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="117"><i>Point</i>_<i>Time</i>=<i>TIME</i>/<i>NUM</i>      (16) </p>
                </div>
                <h3 id="118" name="118" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="119">为测试本文算法效果, 在<i>Windows</i> 7操作系统, <i>CPU</i>为<i>Intel Core i</i>7- 4790<i>M</i>, 内存为8 <i>GB</i>, 编程平台为<i>Microsoft Visual Studio</i> 2013的实验环境下, 基于<i>OpenCV</i> 3.3.1进行实验。以云南玉溪某地倾斜摄影的前视影像作为研究对象, 相机为<i>SONY ILCE</i>- 5100, 倾角45°, 焦距16 <i>mm</i>, 光圈值<i>f</i>/5.6, 曝光时间1/2 000 <i>s</i>, 拍摄时间上午10时许, 天气晴朗无风, 影像尺寸为6 000×4 000。由于原图像较大, 为减少计算时间, 对原图像进行降采样, 压缩后的影像尺寸为1 500×1 000。</p>
                </div>
                <div class="p1">
                    <p id="120">选取应用广泛、性能高的<i>SIFT</i>、<i>SURF</i>、<i>AKAZE</i>算法进行对比实验。此次实验中, 上述4种算法的特征检测子和描述子均采用<i>OpenCV</i>的默认参数。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">4.1 <b>模拟倾斜摄影的图像变化</b></h4>
                <div class="p1">
                    <p id="122">为评价各种算法的稳健性, 模拟倾斜摄影条件下的5种图像变化, 分别描述如下:</p>
                </div>
                <div class="p1">
                    <p id="123"><i>a</i>) 高斯模糊。模拟拍摄时受到噪声影响引起的模糊变化, 对原始影像进行高斯模糊, 模糊半径从0变化到10, 步长为1, 得到11张影像作为<i>a</i>组。</p>
                </div>
                <div class="p1">
                    <p id="124"><i>b</i>) 旋转变化。模拟不同相机朝向和航向变化造成的影像旋转变化, 把影像顺时针旋转0°至180°, 步长20°, 得到10张影像作为<i>b</i>组。</p>
                </div>
                <div class="p1">
                    <p id="125"><i>c</i>) 亮度变化。模拟影像因光照强度改变引起的亮度变化, 图像亮度增量从-125至125, 步长25, 得到11张影像作为<i>c</i>组。</p>
                </div>
                <div class="p1">
                    <p id="126"><i>d</i>) 视角变化。模拟不同视角或相机倾角下, 相同地物在影像上的差异, 将影像沿垂直方向翻转-50°至50°, 步长10°, 得到11张影像作为<i>d</i>组。</p>
                </div>
                <div class="p1">
                    <p id="127"><i>e</i>) 尺度变化。模拟航高变化和相机倾角造成的影像地物尺寸变化, 缩放系数从0.25变化至2.0, 步长0.25, 得到8张影像作为<i>e</i>组。</p>
                </div>
                <div class="p1">
                    <p id="128">通过模拟得到5组图像, 如图3所示 (为简化只显示部分图像) 。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907038_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 图像模拟变化" src="Detail/GetImg?filename=images/JSJY201907038_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 图像模拟变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907038_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Image simulation changes</i></p>

                </div>
                <h4 class="anchor-tag" id="130" name="130">4.2 <b>结果分析</b></h4>
                <div class="p1">
                    <p id="131">对原始前视影像分别与上述模拟图像进行特征匹配与提纯实验, 采用召回率、精准率、<i>F</i>1值和运行时间评估各种特征提取算法的性能。</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">4.2.1 特征提取效果分析</h4>
                <div class="p1">
                    <p id="133"><i>F</i>1值兼顾了召回率和精准率, 综合反映了算法的检测和描述质量。统计4种算法在上述5种模拟条件的<i>F</i>1值, 结果如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="134">在图4 (<i>a</i>) 中, 随着高斯平滑半径的增大, 图像愈发模糊, <i>F</i>1值逐渐降低。由于<i>AKAZE</i>算法采用非线性扩散滤波的方式建立尺度空间, 增强了图像轮廓局部特征的表现能力, 使得特征显著性更高, <i>AKAZE</i>和<i>AKAZE</i>-<i>SIFT</i>算法的<i>F</i>1值高于另两种算法。</p>
                </div>
                <div class="p1">
                    <p id="135">在图4 (<i>b</i>) 中, 在处理图像旋转变化时, 采用局部不变特征的4种算法都能出色地描述图像特征信息, 取得了较好的匹配效果, 但由于<i>SURF</i>算法引入积分图像对高斯差分进行了简化, 降低了描述向量的维度, 在处理旋转变化时, 匹配效果差于其他算法。</p>
                </div>
                <div class="p1">
                    <p id="136">在图4 (<i>c</i>) 中, 在面对亮度均匀变化时, 由于4种算法都采用差分的方法解决了亮度均匀变化的问题, 提取效果相当。</p>
                </div>
                <div class="p1">
                    <p id="137">在图4 (<i>d</i>) 中, 在处理图像视角变化时, 随着图像翻转角度的增加, 4种算法的匹配效果都明显变差, 表明图像视角变化是影响匹配效果的关键因素。其中, 本文算法的<i>F</i>1值高于其他算法。</p>
                </div>
                <div class="p1">
                    <p id="138">在图4 (<i>e</i>) 中, 引入尺度空间构建影像金字塔, 能够很好解决尺度变化的问题, 4种算法的匹配效果相当。随着图像尺寸的缩小, 图像的信息量变小, 特征点的提取数量减少, 且描述向量的显著性变差, 匹配效果明显下降;尺寸放大时, 图像的信息量没有明显丢失, 特征匹配效果缓慢变差。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 四种算法的F1值比较" src="Detail/GetImg?filename=images/JSJY201907038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 四种算法的<i>F</i>1值比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>Comparison of F</i>1 <i>values among four algorithms</i></p>

                </div>
                <div class="p1">
                    <p id="140">为定量分析4种算法的匹配效果, 统计召回率、精准率、<i>F</i>1值在上述5种模拟变化下的均值, 结果如表1所示。</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit"><b>表</b>1 <b>所提算法与典型算法实验结果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Comparisons of experimental results of the proposed algorithm and typical algorithms</i></p>
                    <p class="img_note">%</p>
                    <table id="141" border="1"><tr><td rowspan="2">变化类型</td><td colspan="3"><br /><i>SIFT</i></td><td rowspan="2"></td><td colspan="3"><br /><i>SURF</i></td><td rowspan="2"></td><td colspan="3"><br /><i>AKAZE</i></td><td rowspan="2"></td><td colspan="3"><br /><i>AKAZE</i>-<i>SIFT</i></td></tr><tr><td><br />召回率</td><td>精准率</td><td><i>F</i>1值</td><td><br />召回率</td><td>精准率</td><td><i>F</i>1值</td><td><br />召回率</td><td>精准率</td><td><i>F</i>1值</td><td><br />召回率</td><td>精准率</td><td><i>F</i>1值</td></tr><tr><td>高斯模糊</td><td>24.30</td><td>88.38</td><td>30.49</td><td></td><td>35.34</td><td>84.86</td><td>43.83</td><td></td><td>46.22</td><td>92.35</td><td>56.69</td><td></td><td>46.95</td><td>94.38</td><td>57.40</td></tr><tr><td><br />旋转变化</td><td>79.64</td><td>89.65</td><td>84.30</td><td></td><td>45.19</td><td>61.01</td><td>51.40</td><td></td><td>80.94</td><td>91.72</td><td>85.90</td><td></td><td>83.65</td><td>94.47</td><td>88.65</td></tr><tr><td><br />亮度变化</td><td>70.96</td><td>88.38</td><td>77.33</td><td></td><td>68.03</td><td>84.86</td><td>74.43</td><td></td><td>70.76</td><td>92.35</td><td>77.92</td><td></td><td>72.07</td><td>94.38</td><td>79.34</td></tr><tr><td><br />视角变化</td><td>43.41</td><td>61.67</td><td>50.21</td><td></td><td>33.12</td><td>49.28</td><td>39.03</td><td></td><td>40.97</td><td>57.59</td><td>47.33</td><td></td><td>49.46</td><td>71.18</td><td>57.55</td></tr><tr><td><br />尺度变化</td><td>53.64</td><td>80.36</td><td>60.59</td><td></td><td>45.38</td><td>72.23</td><td>52.53</td><td></td><td>52.57</td><td>75.62</td><td>58.40</td><td></td><td>54.76</td><td>80.42</td><td>61.61</td></tr><tr><td><br />均值</td><td>54.39</td><td>81.69</td><td>60.58</td><td></td><td>45.41</td><td>70.45</td><td>52.24</td><td></td><td>58.29</td><td>81.93</td><td>65.25</td><td></td><td>61.38</td><td>86.97</td><td>68.91</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="142">从表1可以看出, 旋转和亮度变化对匹配效果影响较小;视角和尺度变化是影响匹配效果的主要因素, 这也正是倾斜摄影与垂直摄影的主要差异。其中, <i>AKAZE</i>-<i>SIFT</i>较<i>SIFT</i>算法召回率提高了12.8%, 精准率提高了6.5%, <i>F</i>1值提升了13.8%;较<i>SURF</i>算法召回率提升了35.2%, 精准率提升了23.4%, <i>F</i>1值提升了31.9%;较<i>AKAZE</i>算法召回率提升了5.3%, 精准率提升了6.1%, <i>F</i>1值提升了5.6%。<i>AKAZE</i>-<i>SIFT</i>算法的召回率、精准率、<i>F</i>1值均高于另3种算法, 表明其针对上述变化具有较强的稳健性。</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143">4.2.2 效率分析</h4>
                <div class="p1">
                    <p id="144">由于各种算法提取的点数不同, 这里从每个特征点的提取用时进行对比。统计上述4种算法平均每个特征点的提取用时。</p>
                </div>
                <div class="p1">
                    <p id="145"><i>SIFT</i>算法计算量大, 提取时间约1.39 <i>ms</i>, 用时最长;<i>SURF</i>算法较<i>SIFT</i>算法, 运行效率有明显提升, 提取时间约0.85 <i>ms</i>;由于<i>AKAZE</i>采用了加速的<i>FED</i>算法, 每个特征点的提取时间约0.50 <i>ms</i>, 运行时间最短;<i>AKAZE</i>-<i>SIFT</i>算法作为<i>AKAZE</i>和<i>SIFT</i>的组合算法, 每点特征提取时间为0.80 <i>ms</i>, 约为<i>SIFT</i>和<i>AKAZE</i>算法的均值。本文算法运行效率低于<i>AKAZE</i>, 但优于<i>SIFT</i>和<i>SURF</i>。</p>
                </div>
                <div class="p1">
                    <p id="146">综合考虑影像5个方面的变化, <i>AKAZE</i>-<i>SIFT</i>算法的召回率、精准率和<i>F</i>1值均高于其他算法, 具有良好的检测和描述能力, 匹配效果最好, <i>AKAZE</i>和<i>SIFT</i>算法次之。</p>
                </div>
                <h3 id="147" name="147" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="148">本文针对倾斜影像与正摄影像的差异, 在研究已有特征提取算法的基础上, 设计了一种<i>AKAZE</i>-<i>SIFT</i>特征提取算法。考虑模糊、旋转、亮度、视角及尺度变化的影响, 把<i>AKAZE</i>-<i>SIFT</i>与现有的特征提取算法进行了对比, 以特征匹配召回率、精准率、<i>F</i>1值和提取用时作为评价标准, 评估了4种算法在多视角倾斜影像上的特征提取性能。模拟实验结果表明:视角和尺度变化是影响倾斜影像特征匹配效果的关键因素;而旋转和亮度均匀变化对匹配效果的影响较小。<i>AKAZE</i>-<i>SIFT</i>算法在倾斜影像特征提取时, 具有较高的检测和描述稳定性, 匹配效果优于典型的<i>SIFT</i>、<i>SURF</i>和<i>AKAZE</i>算法, 可作为一种实用的倾斜影像特征提取算法。</p>
                </div>
                <div class="p1">
                    <p id="149">由于本文实验为倾斜影像受各种因素影响的模拟变化, 而真实情况要远复杂于模拟影像, 如模拟时未考虑到地物遮挡和光照不均匀的情况, 故实验时各种算法的匹配正确率要高于真实情况, 下一步考虑在真实数据库上测试提取效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="165">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DBCH201601004&amp;v=MjI5MTN5L2dWcjdKSVMvSVpyRzRIOWZNcm85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 杨国东, 王民水.倾斜摄影测量技术应用及展望[J].测绘与空间地理信息, 2016, 39 (1) :13-15, 18. (YANG G D, WANG M S.The tilt photographic measuration technique and expectation [J].Geomatics and Spatial Information Technology, 2016, 39 (1) :13-15, 18.) 
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB200902009&amp;v=MzE3ODZxZlp1WnNGeS9nVnI3SkppWFRiTEc0SHRqTXJZOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 邢帅, 徐青, 刘军, 等.多源卫星遥感影像的光束法区域网平差[J].测绘学报, 2009, 38 (2) :125-130. (XING S, XU Q, LIU J, et al.Bundle block adjustment with multi-source satellite remote sensing images [J].Acta Geodaetica et Cartographica Sinica, 2009, 38 (2) :125-130.) 
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJKF200303005&amp;v=MTQ0MDc0SHRMTXJJOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVnI3Sk5pZkFhTEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 张祖勋, 张剑清.城市建模的途径与关键技术[J].世界科技研究与发展, 2003 (3) :23-29. (ZHANG Z X, ZHANG J Q.Solutions and core techniques of city modeling [J].World Science-Technology Research and Development, 2003 (3) :23-29.) 
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Recognition from Local Scale-Invariant Features">

                                <b>[4]</b> LOWE D G.Object recognition from local scale-invariant features [C]// Proceedings of the 7th IEEE International Conference on Computer Vision.Piscataway, NJ:IEEE, 1999:1150-1157.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjUzMDBZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpcmxWTHJOSVY4PU5qN0Jhck80SHRIT3A0eEZiZXNP&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> LOWE D G.Distinctive image features from scale-invariant keypoints [J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Surf:Speeded up robust features">

                                <b>[6]</b> BAY H, TUYTELAARS T, GOOL L V.SURF:speeded up robust features [C]// Proceedings of the 2006 European Conference on Computer Vision, LNCS 3951.Berlin:Springer, 2006:404-417.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to SIFT or SURF">

                                <b>[7]</b> BRADSKI G, KONOLIGE K, RABAUD V, et al.ORB:an efficient alternative to SIFT or SURF [C]// Proceedings of the 2011 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2011:2564-2571.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=KAZE features">

                                <b>[8]</b> ALCANTARILLA P F, BARTOLI A, DAVISON A J.KAZE features [C]// Proceedings of the 2012 European Conference on Computer Vision, LNCS 7577.Berlin:Springer, 2012:214-227.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast explicit diffusion for accelerated features in nonlinear scale spaces">

                                <b>[9]</b> ALCANTARILLA P F, NUEVO J, BARTOLI A J.Fast explicit diffusion for accelerated features in nonlinear scale spaces [C]// Proceedings of the 2013 British Machine Vision Conference.Durham, UK:BMVA Press, 2013:1-11.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016058382.nh&amp;v=MDk0NTVxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKVkYyNkdMTzlGdExFclpFYlBJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 张一.无人机遥感影像点特征匹配算法研究[D].郑州:解放军信息工程大学, 2015:39. (ZHANG Y.Research on point feature matching algorithms of UAV remote sensing images [D].Zhengzhou:PLA Information Engineering University, 2015:39.) 
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB201807010&amp;v=MTU4ODJDVVI3cWZadVpzRnkvZ1ZyN0pKaVhmYkxHNEg5bk1xSTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 王晓红, 邓仕雄, 何志伟, 等.结合SURF算法和单应性矩阵的无人机影像匹配[J].测绘通报, 2018 (7) :38-42. (WANG X H, DENG S X, HE Z W, et al.Study of UAV image matching based on SURF algorithm and homography matrix [J].Bulletin of Surveying and Mapping, 2018 (7) :38-42.) 
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201808014&amp;v=MDk4MzFzRnkvZ1ZyN0pJVGZDZDdHNEg5bk1wNDlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 宋伟, 王永波.基于改进AKAZE算法的无人机影像匹配[J].电子测量与仪器学报, 2018, 32 (8) :96-102. (SONG W, WANG Y B.UAV image registration based on improved AKAZE algorithm [J].Journal of Electronic Measurement and Instrumentation, 2018, 32 (8) :96-102.) 
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFJC200803022&amp;v=MDcyODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKTHl2QmJiRzRIdG5Nckk5SFpvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张春美, 龚志辉, 黄艳.几种特征点提取算法的性能评估及改进[J].测绘科学技术学报, 2008, 25 (3) :231-234. (ZHANG C M, GONG Z H, HUANG Y.Performance evaluation and improvement of several feature point detectors [J].Journal of Geomatics Science and Technology, 2008, 25 (3) :231-234.) 
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNJT201606017&amp;v=MDM2Mzh0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKUFNQQmVyRzRIOWZNcVk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 叶沅鑫, 慎利.面向遥感影像匹配的特征点检测算子性能评估[J].西南交通大学学报, 2016, 51 (6) :1170-1176. (YE Y X, SHEN L.Performance evaluation of interest point detectors for remote sensing image matching [J].Journal of Southwest Jiaotong University, 2016, 51 (6) :1170-1176.) 
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJCH201802007&amp;v=MjI3NDJmSVpyRzRIOW5Nclk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKSnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 胡佳怡, 赵栋梁, 刘荣, 等.基于特征的影像匹配算法性能评估[J].北京测绘, 2018, 32 (2) :179-185. (HU J Y, ZHAO D L, LIU R, et al.Performance evaluation of feature-based image matching algorithms [J].Beijing Surveying and Mapping, 2018, 32 (2) :179-185.) 
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201802033&amp;v=MDE2MzNZOUdaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVnI3Skx6N01hYkc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 贾雯晓, 张贵仓, 汪亮亮, 等.基于SIFT和改进的RANSAC图像配准算法[J].计算机工程与应用, 2018, 54 (2) :203-207. (JIA W X, ZHANG G C, WANG L L, et al.Image registration algorithm based on SIFT and improved RANSAC [J].Computer Engineering and Applications, 2018, 54 (2) :203-207.) 
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201209007&amp;v=MjAxMzh0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKTGpYZmZiRzRIOVBNcG85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 陈艺虾, 孙权森, 徐焕宇, 等.SURF算法和RANSAC算法相结合的遥感图像匹配方法[J].计算机科学与探索, 2012, 6 (9) :822-828. (CHEN Y X, SUN Q S, XU H Y, et al.Matching method of remote sensing images based on SURF algorithm and RANSAC algorithm [J].Journal of Frontiers of Computer Science and Technology, 2012, 6 (9) :822-828.) 
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXJK201806031&amp;v=MjI0MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKUFRYQlpiRzRIOW5NcVk5R1pZUUs=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 高帅华, 安巧绒.RANSAC在影像匹配中的应用[J].中国科技信息, 2018 (6) :69-70. (GAO S H, AN Q R.Application of RANSAC in image matching [J].China Science and Technology Information, 2018 (6) :69-70.) 
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201817012&amp;v=MjMxOTZxQnRHRnJDVVI3cWZadVpzRnkvZ1ZyN0pQU25CZmJHNEg5bk5xSTlFWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 代玉强, 杨絮, 熊昊, 等.SIFT特征算法改进研究[J].现代计算机 (专业版) , 2018 (17) :55-59. (DAI Y Q, YANG X, XIONG H, et al.Research on the improvement of SIFT feature algorithm [J].Modern Computer (Professional Edition) , 2018 (17) :55-59.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805033&amp;v=Mjg3NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L2dWcjdKTHo3QmQ3RzRIOW5NcW85R1o0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 陈虹, 肖越, 肖成龙, 等.基于SIFT算子融合最大相异系数的自适应图像匹配算法[J].计算机应用, 2018, 38 (5) :1410-1414. (CHEN H, XIAO Y, XIAO C L, et al.Adaptive image matching algorithm based on SIFT operator fused with maximum dissimilarity coefficient [J].Journal of Computer Applications, 2018, 38 (5) :1410-1414.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907038" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907038&amp;v=MDc4NjRkN0c0SDlqTXFJOUdiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVWJ2QUx6N0I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
