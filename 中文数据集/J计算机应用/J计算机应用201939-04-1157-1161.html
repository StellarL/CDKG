<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136782307315000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201904036%26RESULT%3d1%26SIGN%3df1WFYveqdUdA%252fMYOIikxaBwpwdQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201904036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904036&amp;v=MTk4MTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQTHo3QmQ3RzRIOWpNcTQ5R1k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#35" data-title="1 显微定位系统的结构与标定原理 ">1 显微定位系统的结构与标定原理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="1.1 &lt;b&gt;显微定位系统结构和组成&lt;/b&gt;">1.1 <b>显微定位系统结构和组成</b></a></li>
                                                <li><a href="#40" data-title="1.2 &lt;b&gt;显微定位系统标定原理&lt;/b&gt;">1.2 <b>显微定位系统标定原理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 视觉模块移动误差测量 ">2 视觉模块移动误差测量</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="2.1 &lt;b&gt;误差测量原理&lt;/b&gt;">2.1 <b>误差测量原理</b></a></li>
                                                <li><a href="#70" data-title="2.2 &lt;b&gt;误差测量实验&lt;/b&gt;">2.2 <b>误差测量实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#76" data-title="3.1 &lt;b&gt;误差补偿实验&lt;/b&gt;">3.1 <b>误差补偿实验</b></a></li>
                                                <li><a href="#81" data-title="3.2 &lt;b&gt;定位精度实验&lt;/b&gt;">3.2 <b>定位精度实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#89" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="图1 视觉模块结构">图1 视觉模块结构</a></li>
                                                <li><a href="#39" data-title="图2 相机拍照方式">图2 相机拍照方式</a></li>
                                                <li><a href="#69" data-title="图3 网格拼接图">图3 网格拼接图</a></li>
                                                <li><a href="#72" data-title="图4 拼接效果图">图4 拼接效果图</a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;补偿前后&lt;/b&gt;&lt;i&gt;X&lt;/i&gt;、&lt;i&gt;Y&lt;/i&gt;&lt;b&gt;方向误差均值&lt;/b&gt;"><b>表</b>1 <b>补偿前后</b><i>X</i>、<i>Y</i><b>方向误差均值</b></a></li>
                                                <li><a href="#77" data-title="图5 补偿前X、Y方向误差图">图5 补偿前X、Y方向误差图</a></li>
                                                <li><a href="#78" data-title="图6 补偿后X、Y方向误差图">图6 补偿后X、Y方向误差图</a></li>
                                                <li><a href="#85" data-title="图7 补偿前后拼接效果图">图7 补偿前后拼接效果图</a></li>
                                                <li><a href="#86" data-title="图8 重合度示意图">图8 重合度示意图</a></li>
                                                <li><a href="#87" data-title="图9 不同方法采集的图像">图9 不同方法采集的图像</a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;两种拍照方式所获取图片的重合度&lt;/b&gt;"><b>表</b>2 <b>两种拍照方式所获取图片的重合度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="108">


                                    <a id="bibliography_1" title="RULAND T, PAJDLA T, KRUGER L.Globally optimal hand-eye calibration[C]//Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2012:1035-1042." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Globally optimal hand-eye calibration">
                                        <b>[1]</b>
                                        RULAND T, PAJDLA T, KRUGER L.Globally optimal hand-eye calibration[C]//Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2012:1035-1042.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_2" title="ZOU X, ZOU H, LU J.Virtual manipulator-based binocular stereo vision positioning system and errors modelling[J].Machine Vision and Applications, 2012, 23 (1) :43-63." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003808701&amp;v=MTc5OTJIdEhQcDQ5Tlkrc09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpcmxXN3ZPSVZrPU5qN0Jhck80&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        ZOU X, ZOU H, LU J.Virtual manipulator-based binocular stereo vision positioning system and errors modelling[J].Machine Vision and Applications, 2012, 23 (1) :43-63.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_3" title="ZOU X, YE M, LUO C, et al.Fault-tolerant design of a limited universal fruit-picking end-effector based on vision-positioning error[J].Applied Engineering in Agriculture, 2016, 32 (1) :5-18." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fault-tolerant design of a limited universal fruit-picking end-effector based on vision positioning error">
                                        <b>[3]</b>
                                        ZOU X, YE M, LUO C, et al.Fault-tolerant design of a limited universal fruit-picking end-effector based on vision-positioning error[J].Applied Engineering in Agriculture, 2016, 32 (1) :5-18.
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_4" title="KELLY R, MARQUEZ A.Robust asymptotically stable visual servoing of planar robots[J].IEEE Transactions on Robotics and Automation, 1996, 12 (5) :759-766." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust asymptotically stable visual servoing of planar robots">
                                        <b>[4]</b>
                                        KELLY R, MARQUEZ A.Robust asymptotically stable visual servoing of planar robots[J].IEEE Transactions on Robotics and Automation, 1996, 12 (5) :759-766.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_5" title="田浩辰, 张银龙, 赵海文, 等.机械手视觉系统的非均匀标定法研究[J].制造业自动化, 2016, 38 (5) :41-47. (TIAN H C, ZHANG Y L, ZHAO Y W, et al.Non-uniform calibration method research of loading manipulator system based on vision positioning[J].Manufacturing Automation, 2016, 38 (5) :41-47.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXGY201605012&amp;v=MjA1MTlQTHpYTWQ3RzRIOWZNcW85RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        田浩辰, 张银龙, 赵海文, 等.机械手视觉系统的非均匀标定法研究[J].制造业自动化, 2016, 38 (5) :41-47. (TIAN H C, ZHANG Y L, ZHAO Y W, et al.Non-uniform calibration method research of loading manipulator system based on vision positioning[J].Manufacturing Automation, 2016, 38 (5) :41-47.) 
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_6" title="刘苏宜, 王国荣, 石永华.激光视觉机器人焊接中摄像机和手眼的同时标定[J].华南理工大学学报 (自然科学版) , 2008, 36 (2) :74-77, 82. (LIU S Y, WANG G R, SHI Y H.Simultaneous calibration of camera and hand-eye in robot welding with laser vision[J].Journal of South China University of Technology (Natural Science Edition) , 2008, 36 (2) :74-77, 82.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG200802016&amp;v=MDAzMjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQTFNQSGFiRzRIdG5Nclk5RVlvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        刘苏宜, 王国荣, 石永华.激光视觉机器人焊接中摄像机和手眼的同时标定[J].华南理工大学学报 (自然科学版) , 2008, 36 (2) :74-77, 82. (LIU S Y, WANG G R, SHI Y H.Simultaneous calibration of camera and hand-eye in robot welding with laser vision[J].Journal of South China University of Technology (Natural Science Edition) , 2008, 36 (2) :74-77, 82.) 
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_7" title="胡小平, 左富勇, 谢珂.微装配机器人手眼标定方法研究[J].仪器仪表学报, 2012, 33 (7) :1521-1526. (HU X P, ZUO F Y, XIE K.Research on hand-eye calibration method for micro-assembly robot[J].Chinese Journal of Scientific Instrument, 2012, 33 (7) :1521-1526.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201207012&amp;v=MTU2NzFNcUk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQUER6VGJMRzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        胡小平, 左富勇, 谢珂.微装配机器人手眼标定方法研究[J].仪器仪表学报, 2012, 33 (7) :1521-1526. (HU X P, ZUO F Y, XIE K.Research on hand-eye calibration method for micro-assembly robot[J].Chinese Journal of Scientific Instrument, 2012, 33 (7) :1521-1526.) 
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_8" title="魏振忠, 张博, 张广军.双机器人系统的快速手眼标定方法[J].光学精密工程, 2011, 19 (8) :1895-1902. (WEI Z Z, ZHANGB, ZHANG G J.Rapid hand-eye calibration of dual robot system[J].Optics and Precision Engineering, 2011, 19 (8) :1895-1902.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201108027&amp;v=MTA1NDhadVpzRnlEaFZiN1BJalhCWTdHNEg5RE1wNDlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        魏振忠, 张博, 张广军.双机器人系统的快速手眼标定方法[J].光学精密工程, 2011, 19 (8) :1895-1902. (WEI Z Z, ZHANGB, ZHANG G J.Rapid hand-eye calibration of dual robot system[J].Optics and Precision Engineering, 2011, 19 (8) :1895-1902.) 
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_9" title="温卓漫, 王延杰, 邸男, 等.基于合作靶标的在轨手眼标定[J].仪器仪表学报, 2014, 35 (5) :1005-1012. (WEN Z M, WANGY J, DI N, et al.On-orbit hand-eye calibration using cooperative target[J].Chinese Journal of Scientific Instrument, 2014, 35 (5) :1005-1012.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201405007&amp;v=MDczMjk5WE1xbzlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFZiN1BQRHpUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        温卓漫, 王延杰, 邸男, 等.基于合作靶标的在轨手眼标定[J].仪器仪表学报, 2014, 35 (5) :1005-1012. (WEN Z M, WANGY J, DI N, et al.On-orbit hand-eye calibration using cooperative target[J].Chinese Journal of Scientific Instrument, 2014, 35 (5) :1005-1012.) 
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_10" title="张强, 曲道奎, 徐方, 等.基于误差分布估计的机器人手眼标定方法研究[J].计算机测量与控制, 2018, 26 (4) :246-249. (ZHANG Q, QU D K, XU F, et al.Error distribution estimation based robot hand-eye calibration[J].Computer Measurement&amp;amp;Control, 2018, 26 (4) :246-249.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZCK201804064&amp;v=MDU5ODFyQ1VSN3FmWnVac0Z5RGhWYjdQTHpmSVpiRzRIOW5NcTQ5RFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        张强, 曲道奎, 徐方, 等.基于误差分布估计的机器人手眼标定方法研究[J].计算机测量与控制, 2018, 26 (4) :246-249. (ZHANG Q, QU D K, XU F, et al.Error distribution estimation based robot hand-eye calibration[J].Computer Measurement&amp;amp;Control, 2018, 26 (4) :246-249.) 
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_11" title="ZHANG Z.A flexible new technique for camera calibration[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (11) :1330-1334." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A flexible new technique for camera calibration">
                                        <b>[11]</b>
                                        ZHANG Z.A flexible new technique for camera calibration[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (11) :1330-1334.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_12" title="叶溯, 叶玉堂, 刘娟秀, 等.补强片自动贴片系统高精度手眼标定方法[J].应用光学, 2015, 36 (1) :71-76. (YE S, YE YT, LIU J X, et al.High-precision hand-eye calibration method for automatic stiffness bonder[J].Journal of Applied Optics, 2015, 36 (1) :71-76.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYGX201501014&amp;v=MzAzNTdiN1BQRFRNZHJHNEg5VE1ybzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        叶溯, 叶玉堂, 刘娟秀, 等.补强片自动贴片系统高精度手眼标定方法[J].应用光学, 2015, 36 (1) :71-76. (YE S, YE YT, LIU J X, et al.High-precision hand-eye calibration method for automatic stiffness bonder[J].Journal of Applied Optics, 2015, 36 (1) :71-76.) 
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_13" title="郭永刚, 葛庆平, 姜长胜.基于傅里叶变换的红外热波图像拼接[J].计算机应用研究, 2007, 24 (1) :227-228. (GUO Y G, GE Q P, JIANG C S.FFT-based image mosaicing of infrared thermal wave images[J].Application Research of Computers, 2007, 24 (1) :227-228.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200701071&amp;v=MTYyMTFNcm85Q1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQTHo3U1pMRzRIdGI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        郭永刚, 葛庆平, 姜长胜.基于傅里叶变换的红外热波图像拼接[J].计算机应用研究, 2007, 24 (1) :227-228. (GUO Y G, GE Q P, JIANG C S.FFT-based image mosaicing of infrared thermal wave images[J].Application Research of Computers, 2007, 24 (1) :227-228.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-05 11:08</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(04),1157-1161 DOI:10.11772/j.issn.1001-9081.2018091895            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>光学显微定位系统定位精度分析</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E9%9B%84&amp;code=37238480&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈雄</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E6%B9%98%E5%86%9B&amp;code=07576048&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹湘军</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A8%8A%E7%A7%91&amp;code=33942523&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">樊科</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E4%BF%8A&amp;code=33468535&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢俊</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%96%B9%E5%86%9C%E4%B8%9A%E6%9C%BA%E6%A2%B0%E4%B8%8E%E8%A3%85%E5%A4%87%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8D%8E%E5%8D%97%E5%86%9C%E4%B8%9A%E5%A4%A7%E5%AD%A6)&amp;code=0221203&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南方农业机械与装备关键技术教育部重点实验室(华南农业大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E7%9C%81%E7%94%9F%E7%89%A9%E5%8C%BB%E8%8D%AF%E8%AE%A1%E7%AE%97%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%B9%BF%E5%B7%9E%E7%94%9F%E7%89%A9%E5%8C%BB%E8%8D%AF%E4%B8%8E%E5%81%A5%E5%BA%B7%E7%A0%94%E7%A9%B6%E9%99%A2)&amp;code=1046503&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东省生物医药计算重点实验室(中国科学院广州生物医药与健康研究院)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了提高光学显微定位系统对细胞微生物识别定位的精度:一方面, 必须改进手眼标定方法;另一方面, 需要提高全局图像识别的准确性, 因此, 提出一种两步法对系统进行手眼标定。首先, 通过标定固定靶标来确定系统原点, 并得到视觉模块相对于系统原点的转换关系;然后, 根据每次拍照的起始点位置、拍照的数量和移动的步长求解出全局图像相对于系统原点的转换关系;最后, 为了进一步提高全局转换关系的准确度, 提出一种基于傅里叶变换的误差矫正方法, 利用傅里叶变换求解出视觉模块在移动过程中的误差, 并加入系统进行补偿。实验结果表明, 误差补偿之后, 系统<i>X</i>轴方向的误差均值从10.23μm降为-0.002μm, <i>Y</i>轴方向的误差均值从6.9μm降为-0.50μm, 显微定位系统的平均定位精度达到了99%以上。结果表明, 所提方法可很好地用于光学显微定位系统对细胞微生物进行高精度的自动化抓取。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%98%BE%E5%BE%AE%E5%AE%9A%E4%BD%8D%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">显微定位系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手眼标定;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AF%E5%B7%AE%E7%9F%AB%E6%AD%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">误差矫正;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">傅里叶变换;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈雄 (1993—) , 男, 湖北孝感人, 硕士研究生, 主要研究方向:机器视觉、图像处理;;
                                </span>
                                <span>
                                    *邹湘军 (1957—) , 女, 湖南衡阳人, 教授, 博士生导师, 博士, 主要研究方向:机器视觉、图像处理、农业机器人;电子邮箱xjzou1@163.com;
                                </span>
                                <span>
                                    樊科 (1985—) , 男, 四川成都人, 副研究员, 博士, 主要研究方向:机器视觉、图像处理、光学工程、自动化。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (31571568);</span>
                    </p>
            </div>
                    <h1><b>Positioning accuracy analysis of optical micropositioning system</b></h1>
                    <h2>
                    <span>CHEN Xiong</span>
                    <span>ZOU Xiangjun</span>
                    <span>FAN Ke</span>
                    <span>LU Jun</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of Key Technology on Agricultural Machine and Equipment, Ministry of Education (South China Agricultural University)</span>
                    <span>Guangdong Provincial Key Laboratory of Biocomputing (Guangzhou Institute of Biomedicine and Health, Chinese Academy of Sciences)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the accuracy of identification and localization of cell microorganisms by optical micropositioning system, on the one hand, the hand-eye calibration method should be optimized, on the other hand, the accuracy of global image recognition should be improved. Aiming at those, a two-step method for hand-eye calibration of the system was proposed. Firstly, the origin of the system was determined by calibrating the fixed target, and the transformation relationship of the vision module to the origin of the system was obtained. Then, according to the starting point position of each photograph, the number of photoing and the step size of movement, the transformation relationship of the global image to the origin of the system was solved. Finally, in order to further improve the accuracy of the global transformation relationship, an error correction method based on Fourier transform was used to obtain the error of the visual module in movement, then the error was added into the system for compensation. Experimental results show that after error compensation, the micropositioning system has the error mean value in <i>X</i>-axis direction reduced from 10.23 μm to-0.002 μm, the error mean value in <i>Y</i>-axis direction reduced from 6.9 μm to-0.50 μm, and the average positioning accuracy over 99%. The results show that the proposed method can be applied to the optical micropositioning system for high-precision automated capture of cell microorganisms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=micropositioning%20system&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">micropositioning system;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hand-eye%20calibration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hand-eye calibration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=error%20correction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">error correction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fourier%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fourier transform;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHEN Xiong, born in 1993, M. S. candidate. His research interests include machine vision, image processing.;
                                </span>
                                <span>
                                    ZOU Xiangjun, born in 1957, Ph. D. , professor. Her research interests include machine vision, image processing, agricultural robots.;
                                </span>
                                <span>
                                    FAN Ke, born in 1985, Ph. D. , associate research fellow. His research interests include machine vision, image processing, optical engineering, automation.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-10</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Natural Science Foundation of China (31571568);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="32">光学显微定位系统是一种应用于细胞微生物领域的自动化识别定位系统。该系统首先通过视觉模块获得细胞微生物清晰完整的成像, 并通过识别算法对目标进行视觉定位, 之后, 将目标图像坐标转换到自动化挑取系统 (机械手) 坐标, 并发送给机械手进行自动化挑取, 其中, 图像坐标到机械手坐标的转换过程即为手眼标定<citation id="134" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。由于本文所采用的光学显微定位系统制造安装精度较高, 因此, 忽略视觉系统的非线性问题和机械手结构的非线性问题<citation id="135" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 那么, 为了提高系统的精度, 只能通过降低视觉模块和机械手模块之间的手眼标定误差, 并对误差进行补偿<citation id="136" type="reference"><link href="112" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="33">对于手眼标定国内外学者都作了大量研究。Kelly等<citation id="137" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了一个典型的视觉机器人系统, 设计了一个定点控制器以补偿摄像机内部参数以及手眼关系转换矩阵的不确定性, 并且获得了局部收敛的稳定的结果, 但要求已知机器人重力项参数;田浩辰等<citation id="138" type="reference"><link href="116" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种局部线性化的像机标定算法, 采用基于粗定位和精确定位两步走的算法实现了机械手的精确对位;刘苏宜等<citation id="139" type="reference"><link href="118" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种同时标定摄像机和机器人手眼的方法, 该方法依据机器人手眼矩阵和机器人手爪对基坐标系位姿矩阵之间的特定关系, 进行一次标定实验能同时求解出摄像机参数和机器人手眼关系矩阵;胡小平等<citation id="140" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>针对微装配机器人提出了一种固定视觉的手眼系统标定算法, 该方法通过3个空间点在机械手基坐标系中的坐标, 采用P3P (Perspective-3-Point) 位姿测量原理获得相应空间点在摄像机坐标系中的坐标, 建立了标定方程组, 并基于最小二乘法标定出了手眼系统之间的转换矩阵;魏振忠等<citation id="141" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了基于法兰盘的双机器人手眼标定方法, 但该方法要求的机械结构相当复杂, 在单机器人手眼标定时难以实现;温卓漫等<citation id="142" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一种基于合作靶标的在轨手眼标定方法, 仅需3个特征点的图像坐标就能计算摄像机外部参数, 并运用P3P方法求解位姿确保了高精度, 而矩阵重排的方法使得机械臂只需要转动很小的角度, 就可以完成手眼标定;张强等<citation id="143" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出了一种基于误差分布估计的加权最小二乘鲁棒估计方法, 以提高机器人手眼标定的精度。以上研究者提出的方法大多针对宏观物体, 精度要求均未达到微米级, 且相机位置固定, 而本文系统主要用于细胞微生物的识别定位, 精度要求为微米级, 且为了获得大视场和高清晰度的图像, 相机位置需要不断地移动, 因此, 不能采用传统的方法对本文系统进行手眼标定。</p>
                </div>
                <div class="p1">
                    <p id="34">针对以上问题, 本文提出了一种两步法对系统进行手眼标定:1) 标定系统原点, 在系统初始状态下, 相机位置不变, 采用传统的固定靶标的方式对系统的原点进行标定, 系统的原点设置为拍摄靶标图像时机械手所在的位置坐标;2) 确定全局转换关系, 根据每次拍照的起始点位置, 以及拍照的数量和移动的步长确定全局转换关系。然而, 根据此方法进行手眼标定, 系统依然存在较大误差, 而误差主要是由于视觉模块在移动过程中每次移动的距离存在误差, 使得相邻的图像之间存在一定的偏移量, 因此而产生了图像的全局定位误差。为了进一步提高系统的精度, 本文提出了一种基于傅里叶变换的方法来矫正该误差, 首先, 采用傅里叶变换求解系统拍摄的相邻两张图片的实际重叠量, 并与人为设定的理论重叠量进行比较, 便可得到视觉模块在移动过程中的误差, 之后, 多次测量分别求取<i>X</i>和<i>Y</i>方向的误差均值, 并将误差均值加入系统的控制单元进行补偿。实验结果表明, 显微定位系统的视觉模块的误差均值明显降低, 系统的整体平均定位精度达到99%以上, 可以满足细胞微生物的识别定位要求。</p>
                </div>
                <h3 id="35" name="35" class="anchor-tag">1 显微定位系统的结构与标定原理</h3>
                <h4 class="anchor-tag" id="36" name="36">1.1 <b>显微定位系统结构和组成</b></h4>
                <div class="p1">
                    <p id="37">显微定位系统主要由视觉模块和机械手模块组成。视觉模块由相机、镜头、反射镜、闪光灯组成, 相机为Andor科学级sCMOS相机Zyla5.5, 晶片尺寸为16.6×14.0 mm, 镜头分为4倍镜、10倍镜和20倍镜, 当使用10倍镜镜头时, 成像精度为0.65 μm/pixel。视觉模块的结构如图1所示, 它共分为上下两层, 以细胞培养皿为界, 上面为闪光灯, 下方为镜头、反射镜、相机, 上下两个部分均安装在由光栅尺组成的三坐标移动平台上, 由光栅尺进行联合控制运动, 其中光栅尺的精度为0.2 μm, 在进行拍照时, 上方的闪光灯与下方的相机同步运动, 移动一定的步长时, 闪光灯开启, 相机获取图片。机械手模块的挑取装置安装在闪光灯所在的移动平台上, 可由光栅尺单独进行移动控制。由于成像区域较大, 无法通过一次成像获得完整的区域, 因此, 采用了一种如图2所示的Z字型的拍照方式对整个区域进行依次成像, 最后将图像进行拼接。</p>
                </div>
                <div class="area_img" id="38">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_038.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 视觉模块结构" src="Detail/GetImg?filename=images/JSJY201904036_038.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 视觉模块结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_038.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Structure of vision module</p>

                </div>
                <div class="area_img" id="39">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 相机拍照方式" src="Detail/GetImg?filename=images/JSJY201904036_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 相机拍照方式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Movement method of camera</p>

                </div>
                <h4 class="anchor-tag" id="40" name="40">1.2 <b>显微定位系统标定原理</b></h4>
                <div class="p1">
                    <p id="41">由于本文系统制造精度和安装精度都较高, 视觉模块坐标系和机械手模块坐标系的水平度和垂直度均较好, 因此, 在进行系统手眼标定的过程中, 忽略视觉模块坐标系和机械手模块坐标系之间的旋转变换, 只考虑坐标系之间的平移变换。标定的过程分为两步:基于靶标进行系统原点的标定和进行全局区域的标定。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42">1.2.1 基于靶标的系统原点标定方法</h4>
                <div class="p1">
                    <p id="43">描述相机成像的物理模型为小孔模型<citation id="144" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。由于成像模块在拍照过程中, 镜头会随着培养基表面的地貌特征而改变, 因此相机的焦距在不断地改变, 且相机的制造精度较高, 径向畸变和切向畸变可以忽略, 因此, 在进行坐标转换的过程中, 不能采用传统方法对相机进行标定, 获取内外参数, 而是直接采用相机本身的参数, 每个像素点所代表的物理尺寸为<i>pixel</i>_<i>um</i>=0.65 μm/pixel进行转换。转换矩阵如式 (1) :</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mo>_</mo><mi>u</mi><mi>m</mi><mo>⋅</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>u</mi></mtd></mtr><mtr><mtd><mi>v</mi></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>m</mtext><mtext>g</mtext></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Μ</mi><mo>+</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45">其中:img为图像坐标系;obj为靶标所在平面的坐标系;<b><i>M</i></b>为转换矩阵。设靶标中心点的坐标为 (0, 0) , 将视觉模块移动到靶标正上方拍摄图片, 则可求出图像坐标 (<i>u</i>, <i>v</i>) , 那么转换矩阵<b><i>M</i></b>便可得知。整个转换都在二维平面内进行, 空间<i>Z</i>坐标由地貌扫描时确定。此时图像上的任意一点便可通过矩阵变换找出对应的空间坐标<citation id="145" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。机械手末端的工具坐标系<i>X</i><sub>tool</sub>与靶标坐标系<i>X</i><sub>obj</sub>之间的转换关系, 如式 (2) , 工具坐标系<i>X</i><sub>tool</sub>与机械手坐标系<i>X</i><sub>rob</sub>之间的转换关系如式 (3) , 因为工具安装在机械手上, 所以工具相对于机械手的位置不变, <sup>tool</sup><b><i>H</i></b><sub>rob</sub>为固定值, 由设计安装参数便可得到。则图像坐标便可通过坐标转换变为机械手坐标系下的坐标, 便于进行移动拍照时的全局定位。</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mi>z</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext></mrow></msub><mo>=</mo><msup><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext></mrow></msup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext></mrow></msub><mspace width="0.25em" /><mo>⋅</mo><mspace width="0.25em" /><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mi>z</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mi>z</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>o</mtext><mtext>b</mtext></mrow></msub><mo>=</mo><msup><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext></mrow></msup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>o</mtext><mtext>b</mtext></mrow></msub><mspace width="0.25em" /><mo>⋅</mo><mspace width="0.25em" /><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mi>z</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47"><i>X</i><sub>tool</sub>到<i>X</i><sub>obj</sub>之间的转换通过固定靶标的方法进行标定得到。首先视觉模块移动到靶标上方拍摄靶标图片, 计算出靶标标志点的图像坐标, 并转换为<i>X</i><sub>obj</sub>坐标, 之后, 机械手工具末端尽可能靠近靶标中心点, 得到此时的<i>X</i><sub>tool</sub>坐标, 如此便可计算出<i>X</i><sub>tool</sub>到<i>X</i><sub>obj</sub>之间的转换关系<sup>obj</sup><b><i>H</i></b><sub>tool</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48">1.2.2 全局区域标定方法</h4>
                <div class="p1">
                    <p id="49">在拍摄大目标区域时, 视觉模块需要按照一定的规律和步长进行移动, 在不考虑坐标系之间旋转变换的情况下, 机械手坐标系下的全局变换可以简化为相对于系统原点的二维平移变换, 变换方式如式 (4) 所示:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>o</mtext><mtext>b</mtext></mrow></msub><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>u</mi></mtd></mtr><mtr><mtd><mi>v</mi></mtd></mtr></mtable><mo>]</mo></mrow><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>m</mtext><mtext>g</mtext></mrow></msub><mo>⋅</mo><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mo>_</mo><mi>u</mi><mi>m</mi><mo>+</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr></mtable><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">其中:<image id="104" type="formula" href="images/JSJY201904036_10400.jpg" display="inline" placement="inline"><alt></alt></image>为全局的机械手下的二维坐标;<image id="105" type="formula" href="images/JSJY201904036_10500.jpg" display="inline" placement="inline"><alt></alt></image>为拼接图片中目标点的图像坐标, 主要由图片所在全局图像的位置和目标点所在图片的位置确定;<image id="106" type="formula" href="images/JSJY201904036_10600.jpg" display="inline" placement="inline"><alt></alt></image>为拍照起始点相对于系统原点的坐标。图像的<i>Z</i>坐标由地貌扫描结果而来, 由此, 便可将全局的图像坐标转换为机械手下的全局三维坐标, 之后, 通过<sup>tool</sup><b><i>H</i></b><sub>rob</sub>转换矩阵, 转换为机械手工具末端坐标, 便于进行细胞微生物挑取。然而, 在视觉模块移动的过程中, 每次移动的步长都会有所偏差, 如果直接将图像按照顺序拼接起来计算全局图像坐标<image id="107" type="formula" href="images/JSJY201904036_10700.jpg" display="inline" placement="inline"><alt></alt></image>, 图像的接缝处会存在较大误差, 而且, 误差会随着拍摄距离的增加而累积, 因此, 需要对视觉模块的移动误差进行矫正。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 视觉模块移动误差测量</h3>
                <h4 class="anchor-tag" id="61" name="61">2.1 <b>误差测量原理</b></h4>
                <div class="p1">
                    <p id="62">假设, 相邻图像之间只存在平移变换, 定义图片<i>f</i><sub>1</sub>、 <i>f</i><sub>2</sub>, 使得<i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) = <i>f</i><sub>1</sub> (<i>x</i>+<i>x</i><sub>0</sub>, <i>y</i>+<i>y</i><sub>0</sub>) , 则对应的傅里叶变换<i>F</i><sub>1</sub>和<i>F</i><sub>2</sub>的关系为:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>F</i><sub>2</sub> (<i>u</i>, <i>v</i>) =<i>F</i><sub>1</sub> (<i>u</i>, <i>v</i>) e<sup>-j (<i>ux</i><sub>0</sub>+<i>vy</i><sub>0</sub>) </sup>      (5) </p>
                </div>
                <div class="p1">
                    <p id="64">且对应频域中两个图像的互功率谱为:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mo>*</mo></msup></mrow><mrow><mrow><mo>|</mo><mrow><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mo>*</mo></msup></mrow><mo>|</mo></mrow></mrow></mfrac><mo>=</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mtext>j</mtext><mo stretchy="false"> (</mo><mi>u</mi><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>v</mi><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">其中:<i>F</i><sub>1</sub> (<i>u</i>, <i>v</i>) 、<i>F</i><sub>2</sub> (<i>u</i>, <i>v</i>) 分别为<i>f</i><sub>1</sub>、 <i>f</i><sub>2</sub>的傅里叶变换;<i>F</i><sup>*</sup><sub>1</sub> 为<i>F</i><sub>1</sub>的复共轭。通过对互功率谱进行反变换, 就可得到一个冲击函数<i>σ</i> (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>) <citation id="146" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。此函数在偏移位置处有明显的脉冲, 在其他位置的值接近于零, 因此, 可以通过求解此冲击函数的最大值所对应的<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, 就可以得到两图像间的横向偏移量和纵向偏移量。</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mfrac><mrow><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mo>*</mo></msup></mrow><mrow><mrow><mo>|</mo><mrow><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mo>*</mo></msup></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mspace width="0.25em" /><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">为了验证傅里叶变换算法的准确性, 本文采用了高精度的网格进行拍照拼接实验。其中整个网格的大小为4 mm×4 mm, 每格的大小为200 μm×200 μm, 拍摄时从左下角依次往上拍, 共拍摄12张图片, 分为4行3列。从中选取了左右相邻的两张图片进行拼接, 其中图3 (a) 为直接拼接图, 图3 (b) 为傅里叶变换拼接图, 由图可知, 采用傅里叶变换可以对图片进行很好的拼接, 同时, 可以得到相邻图片之间的实际重叠量。因此, 可以采用傅里叶变换的方法进对系统的移动误差进行测量和补偿。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 网格拼接图" src="Detail/GetImg?filename=images/JSJY201904036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 网格拼接图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Mesh switching diagram</p>

                </div>
                <h4 class="anchor-tag" id="70" name="70">2.2 <b>误差测量实验</b></h4>
                <div class="p1">
                    <p id="71">为了进一步测量视觉模块的移动误差, 本文设计了一个实验。选取高精度的微流控芯片作为拍照对象, 芯片的结构尺寸为43 <i>mm</i>×27 <i>mm</i>, 芯片内部由一些三棱柱和圆柱组成, 三棱柱三角形的边长为53 <i>μm</i>, 圆柱的直径为10 <i>μm</i>, 在拍照时, 采用10倍镜拍摄, 成像精度为0.65 <i>μm</i>/<i>pixel</i>, 按照<i>Z</i>字形的拍照方式进行, 调节相机移动的步长, 使得相邻图片之间存在150 <i>μm</i>的重叠量, 共拍摄了702张图片。之后对相邻的图片进行拼接, 其中图4 (<i>a</i>) 为左右拼接的效果图, 图4 (<i>b</i>) 为上下拼接的效果图, 由拼接算法便可得到相邻图片之间的实际重叠量, 而实际重叠量与理论重叠量150 <i>μm</i>之间的差值, 便是显微定位系统视觉模块移动的误差值。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 拼接效果图" src="Detail/GetImg?filename=images/JSJY201904036_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 拼接效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>Stitching result</i></p>

                </div>
                <div class="p1">
                    <p id="73">由于所拍摄的区域中有些位置特征较少, 无法实现较好拼接效果, 所以拍摄的702张图片并不能全部作为实验的样本, 本文只选取了拼接较好的图像对作为误差实验的样本, 即偏移量在阈值范围内。在计算X方向误差时, 需要对左右相邻的图片进行拼接, 实验中共采集了633对有效样本, 其误差图如图5 (<i>a</i>) 所示, 由图可知, X方向误差值绝大部分在8～14 <i>μm</i>区间波动, 均值为10.18 <i>μm</i>, 其中存在两个较为明显的突变值, 主要是由于机械结构的固有误差所造成的, 因为光栅尺虽然精度较高, 但是依然存在部分位置的直线度不够好, 所以造成了X方向的误差突变;在计算Y方向误差时, 需要对上下相邻的图片进行拼接, 实验中共采集了652对有效样本, 其误差图如图5 (<i>b</i>) 所示, 由图可知, Y方向误差存在一个突变值, 且这个突变发生在拍摄的转折点, 而大部分值在4～10 <i>μm</i>区间波动, 均值为6.71 <i>μm</i>。为保证实验数据的准确性, 在相同的拍照方式下, 移动微流控芯片的位置进行实验, 共测试了10组不同位置的数据, <i>X</i>方向误差波动规律和<i>Y</i>方向误差波动规律均相同, 其补偿前<i>X</i>方向和<i>Y</i>方向误差均值如表1所示。</p>
                </div>
                <div class="area_img" id="74">
                                            <p class="img_tit">
                                                <b>表</b>1 <b>补偿前后</b><i>X</i>、<i>Y</i><b>方向误差均值</b>
                                                    <br />
                                                Tab. 1 Error mean value in <i>X</i> and <i>Y</i> directions before and after compensation
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201904036_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 补偿前后X、Y方向误差均值" src="Detail/GetImg?filename=images/JSJY201904036_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="75" name="75" class="anchor-tag">3 实验与结果分析</h3>
                <h4 class="anchor-tag" id="76" name="76">3.1 <b>误差补偿实验</b></h4>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 补偿前X、Y方向误差图" src="Detail/GetImg?filename=images/JSJY201904036_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 补偿前X、Y方向误差图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 5 <i>Error in</i> X <i>and</i> Y <i>directions before compensation</i></p>

                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 补偿后X、Y方向误差图" src="Detail/GetImg?filename=images/JSJY201904036_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 补偿后X、Y方向误差图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Error in</i> X <i>and</i> Y <i>directions after compensation</i></p>

                </div>
                <div class="p1">
                    <p id="79">由第2章的误差测量实验可知, <i>X</i>方向和<i>Y</i>方向误差均在一定范围内波动, 且<i>X</i>方向的误差均值在7 μm左右, <i>Y</i>方向的误差均值在10 μm左右, 且均为正数。因此, 系统在进行移动拍照时, 相邻图像之间<i>X</i>方向的实际移动距离高于理论移动距离7 μm左右, 而<i>Y</i>方向的实际移动距离高于理论移动距离10 μm左右, 为了降低视觉模块在移动拍照时的误差, 本文采用了固定误差补偿的方式, 在视觉模块进行移动拍照时, 对<i>X</i>方向的移动步长减小7 μm, 对<i>Y</i>方向的移动步长减小10 μm。为验证方法的可行性, 本文采用与2.1.2节相同的拍照测量方式, 补偿后的<i>X</i>方向误差图和<i>Y</i>方向误差图分别如图6所示, 共拍摄了10组不同位置的样本, 10组样本补偿后的<i>X</i>方向和<i>Y</i>方向的误差均值如表1所示。从表1可知:<i>X</i>方向的误差在进行补偿之后大多数降到了3 μm以内, 且误差的均值降低为0.002 μm;而<i>Y</i>方向的误差在进行补偿之后大多数降到了5 μm以内, 且误差的均值降低为-0.48 μm, 相对于补偿之前, 误差均值有所降低。</p>
                </div>
                <div class="p1">
                    <p id="80">同时, 为了更加直观地展现误差补偿的效果, 本文设计了另外一个实验, 分别将补偿前和补偿后所拍摄的图片随机选取两张相邻的图片直接进行拼接, 图7 (a) 、 (b) 分别为补偿前和补偿后所拼接的图片, 由图可知, 在进行误差补偿之后, 相邻图像之间的拼接误差有所降低, 全局图像的拼接质量有所提高。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">3.2 <b>定位精度实验</b></h4>
                <div class="p1">
                    <p id="82">3.1节的误差补偿实验已经证明通过本文方法可以基本消除视觉模块在连续拍照过程中的误差, 并且得到较为准确和完整的全局图像。同时, 由于系统的精度要求较高, 而机械手直径约为1 <i>mm</i>, 很难对微米级别的误差进行度量, 因此为了精确验证系统的精度, 本文设计了以下实验:首先通过视觉模块进行图像采集, 之后将采集的图像直接拼接起来, 并求得全局图像中不同特征点的图像坐标, 例如, 图9 (<i>a</i>) 、 (<i>b</i>) 中<i>A</i>1的坐标;然后, 将图像坐标按照式 (4) 转换为机械手下的坐标;将该坐标输入系统, 使得机械手模块与视觉模块同步移动到该点上方, 之后采用视觉模块获取当前位置的图像。定义重合度 (<i>Contact Ratio</i>, <i>CR</i>) 为:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>A</mi><mstyle displaystyle="true"><mo>∩</mo><mi>B</mi></mstyle><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>A</mi><mstyle displaystyle="true"><mo>∪</mo><mi>B</mi></mstyle><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">重合度计算方法示意图如图8所示, <i>A</i>为连续图像采集时目标点所在的原始图片 (如图9 (a) ) , <i>B</i>为移动视觉模块所拍摄的图片 (如图9 (b) ) , 利用傅里叶变换求解出重叠区域的面积<i>A</i>∩<i>B</i>。共拍摄9组不同距离的数据, 重合度计算结果如表2所示。从表2可知, 采用本文方法对于图像的平均定位精度达到了99%以上, 可以满足细胞细胞微生物的定位要求。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 补偿前后拼接效果图" src="Detail/GetImg?filename=images/JSJY201904036_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 补偿前后拼接效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Switching results before and after compensation</p>

                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 重合度示意图" src="Detail/GetImg?filename=images/JSJY201904036_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 重合度示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Schematic diagram of contact ratio</p>

                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201904036_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同方法采集的图像" src="Detail/GetImg?filename=images/JSJY201904036_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同方法采集的图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201904036_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Images acquired by different methods</p>

                </div>
                <div class="area_img" id="88">
                    <p class="img_tit"><b>表</b>2 <b>两种拍照方式所获取图片的重合度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Overlap ratio of pictures obtained by two photographing methods</p>
                    <p class="img_note"></p>
                    <table id="88" border="1"><tr><td>序号</td><td><i>CR</i>/%</td><td>序号</td><td><i>CR</i>/%</td><td>序号</td><td><i>CR</i>/%</td></tr><tr><td><br />1</td><td>99.4</td><td>4</td><td>99.2</td><td>7</td><td>98.8</td></tr><tr><td><br />2</td><td>99.3</td><td>5</td><td>99.1</td><td>8</td><td>99.0</td></tr><tr><td><br />3</td><td>99.2</td><td>6</td><td>98.9</td><td>9</td><td>98.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="89" name="89" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="90">本文基于显微定位系统较高的定位精度要求, 首先采用两步法对系统进行手眼标定, 完成图像坐标到机械手坐标的转换;之后, 针对两步法中全局转换的误差, 提出了一种基于傅里叶变换的方法来提高视觉模块的移动精度, 以此来进一步提高系统的定位精度。实验结果表明, 显微定位系统的视觉模块的移动精度得到了有效提高, 系统整体的平均定位精度达到了99%以上, 基本满足细胞微生物的识别定位要求。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="108">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Globally optimal hand-eye calibration">

                                <b>[1]</b>RULAND T, PAJDLA T, KRUGER L.Globally optimal hand-eye calibration[C]//Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2012:1035-1042.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003808701&amp;v=Mjk2NTBzT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlybFc3dk9JVms9Tmo3QmFyTzRIdEhQcDQ5Tlkr&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>ZOU X, ZOU H, LU J.Virtual manipulator-based binocular stereo vision positioning system and errors modelling[J].Machine Vision and Applications, 2012, 23 (1) :43-63.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fault-tolerant design of a limited universal fruit-picking end-effector based on vision positioning error">

                                <b>[3]</b>ZOU X, YE M, LUO C, et al.Fault-tolerant design of a limited universal fruit-picking end-effector based on vision-positioning error[J].Applied Engineering in Agriculture, 2016, 32 (1) :5-18.
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust asymptotically stable visual servoing of planar robots">

                                <b>[4]</b>KELLY R, MARQUEZ A.Robust asymptotically stable visual servoing of planar robots[J].IEEE Transactions on Robotics and Automation, 1996, 12 (5) :759-766.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXGY201605012&amp;v=MDkzMDc0SDlmTXFvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVmI3UEx6WE1kN0c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>田浩辰, 张银龙, 赵海文, 等.机械手视觉系统的非均匀标定法研究[J].制造业自动化, 2016, 38 (5) :41-47. (TIAN H C, ZHANG Y L, ZHAO Y W, et al.Non-uniform calibration method research of loading manipulator system based on vision positioning[J].Manufacturing Automation, 2016, 38 (5) :41-47.) 
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG200802016&amp;v=MzEyNjViRzRIdG5Nclk5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQTFNQSGE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>刘苏宜, 王国荣, 石永华.激光视觉机器人焊接中摄像机和手眼的同时标定[J].华南理工大学学报 (自然科学版) , 2008, 36 (2) :74-77, 82. (LIU S Y, WANG G R, SHI Y H.Simultaneous calibration of camera and hand-eye in robot welding with laser vision[J].Journal of South China University of Technology (Natural Science Edition) , 2008, 36 (2) :74-77, 82.) 
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201207012&amp;v=MDM2NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVmI3UFBEelRiTEc0SDlQTXFJOUVab1E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>胡小平, 左富勇, 谢珂.微装配机器人手眼标定方法研究[J].仪器仪表学报, 2012, 33 (7) :1521-1526. (HU X P, ZUO F Y, XIE K.Research on hand-eye calibration method for micro-assembly robot[J].Chinese Journal of Scientific Instrument, 2012, 33 (7) :1521-1526.) 
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201108027&amp;v=MjgxMjdmWnVac0Z5RGhWYjdQSWpYQlk3RzRIOURNcDQ5SFk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>魏振忠, 张博, 张广军.双机器人系统的快速手眼标定方法[J].光学精密工程, 2011, 19 (8) :1895-1902. (WEI Z Z, ZHANGB, ZHANG G J.Rapid hand-eye calibration of dual robot system[J].Optics and Precision Engineering, 2011, 19 (8) :1895-1902.) 
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201405007&amp;v=MDkxOTFNcW85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQUER6VGJMRzRIOVg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>温卓漫, 王延杰, 邸男, 等.基于合作靶标的在轨手眼标定[J].仪器仪表学报, 2014, 35 (5) :1005-1012. (WEN Z M, WANGY J, DI N, et al.On-orbit hand-eye calibration using cooperative target[J].Chinese Journal of Scientific Instrument, 2014, 35 (5) :1005-1012.) 
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZCK201804064&amp;v=MTg2MDNJWmJHNEg5bk1xNDlEWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFZiN1BMemY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>张强, 曲道奎, 徐方, 等.基于误差分布估计的机器人手眼标定方法研究[J].计算机测量与控制, 2018, 26 (4) :246-249. (ZHANG Q, QU D K, XU F, et al.Error distribution estimation based robot hand-eye calibration[J].Computer Measurement&amp;Control, 2018, 26 (4) :246-249.) 
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A flexible new technique for camera calibration">

                                <b>[11]</b>ZHANG Z.A flexible new technique for camera calibration[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (11) :1330-1334.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYGX201501014&amp;v=MzA4NDBQRFRNZHJHNEg5VE1ybzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlEaFZiN1A=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>叶溯, 叶玉堂, 刘娟秀, 等.补强片自动贴片系统高精度手眼标定方法[J].应用光学, 2015, 36 (1) :71-76. (YE S, YE YT, LIU J X, et al.High-precision hand-eye calibration method for automatic stiffness bonder[J].Journal of Applied Optics, 2015, 36 (1) :71-76.) 
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200701071&amp;v=MzAzODg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeURoVmI3UEx6N1NaTEc0SHRiTXJvOUNaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>郭永刚, 葛庆平, 姜长胜.基于傅里叶变换的红外热波图像拼接[J].计算机应用研究, 2007, 24 (1) :227-228. (GUO Y G, GE Q P, JIANG C S.FFT-based image mosaicing of infrared thermal wave images[J].Application Research of Computers, 2007, 24 (1) :227-228.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201904036" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201904036&amp;v=MTk4MTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5RGhWYjdQTHo3QmQ3RzRIOWpNcTQ5R1k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZJTWYxaVVtWjVZcnN4dE5mQUIrND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
