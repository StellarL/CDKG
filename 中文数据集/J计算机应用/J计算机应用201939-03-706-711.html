<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991906822500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903016%26RESULT%3d1%26SIGN%3d282BZ6T7z2GWgJOxtaz2YD5xH0A%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903016&amp;v=MjIyNDU3cWZadVpwRmlEbFc3dkpMejdCZDdHNEg5ak1ySTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="1.1 &lt;b&gt;稀疏编码&lt;/b&gt;">1.1 <b>稀疏编码</b></a></li>
                                                <li><a href="#46" data-title="1.2 &lt;b&gt;局部约束线性编码&lt;/b&gt;">1.2 <b>局部约束线性编码</b></a></li>
                                                <li><a href="#53" data-title="1.3 &lt;b&gt;弹性网模型&lt;/b&gt;">1.3 <b>弹性网模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="2 本文方法 ">2 本文方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="2.1 EH-NLSC&lt;b&gt;模型&lt;/b&gt;">2.1 EH-NLSC<b>模型</b></a></li>
                                                <li><a href="#69" data-title="2.2 EH-NLSC&lt;b&gt;算法的求解&lt;/b&gt;">2.2 EH-NLSC<b>算法的求解</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#92" data-title="3 实验结果及分析 ">3 实验结果及分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="3.1 &lt;b&gt;实验数据集和实验设置&lt;/b&gt;">3.1 <b>实验数据集和实验设置</b></a></li>
                                                <li><a href="#106" data-title="3.2 &lt;b&gt;实验设计及结果分析&lt;/b&gt;">3.2 <b>实验设计及结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="图1 EH-NLSC算法框架">图1 EH-NLSC算法框架</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验中使用的数据集&lt;/b&gt;"><b>表</b>1 <b>实验中使用的数据集</b></a></li>
                                                <li><a href="#110" data-title="图2 三种方法训练得到的字典">图2 三种方法训练得到的字典</a></li>
                                                <li><a href="#111" data-title="图3 原图与本文方法重建结果对比">图3 原图与本文方法重建结果对比</a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;表&lt;/b&gt;2 Scene-15&lt;b&gt;数据集上的分类准确率&lt;/b&gt;"><b>表</b>2 Scene-15<b>数据集上的分类准确率</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;表&lt;/b&gt;3 Caltech-101&lt;b&gt;数据集上的分类准确率&lt;/b&gt;"><b>表</b>3 Caltech-101<b>数据集上的分类准确率</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表&lt;/b&gt;4 Corel-10&lt;b&gt;数据集上的分类准确率&lt;/b&gt;"><b>表</b>4 Corel-10<b>数据集上的分类准确率</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表&lt;/b&gt;5 Caltech-256&lt;b&gt;数据集上的分类准确率&lt;/b&gt;"><b>表</b>5 Caltech-256<b>数据集上的分类准确率</b></a></li>
                                                <li><a href="#126" data-title="图4 &lt;i&gt;λ&lt;/i&gt;和&lt;i&gt;β&lt;/i&gt;对分类结果的影响">图4 <i>λ</i>和<i>β</i>对分类结果的影响</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" SIVIC J, ZISSERMAN A. Video Google: a text retrieval approach to object matching in videos [C] // ICCV &#39;03: Proceedings of the 9th International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1470-1477." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video google: A text retrieval approach to object matching in videos">
                                        <b>[1]</b>
                                         SIVIC J, ZISSERMAN A. Video Google: a text retrieval approach to object matching in videos [C] // ICCV &#39;03: Proceedings of the 9th International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1470-1477.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" LAZEBNIK S, SCHMID C, PONCE J. Beyond bags of features: spatial pyramid matching for recognizing natural scene categories [C]// CVPR &#39;06: Proceedings of the 2006 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2006: 2169-2178." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond bags of features:spatial pyramid matching for recognizing natural scene categories">
                                        <b>[2]</b>
                                         LAZEBNIK S, SCHMID C, PONCE J. Beyond bags of features: spatial pyramid matching for recognizing natural scene categories [C]// CVPR &#39;06: Proceedings of the 2006 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2006: 2169-2178.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" YANG J C, YU K, GONG Y H, et al. Linear spatial pyramid matching using sparse coding for image classification [C]// CVPR &#39;09: Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2009: 1794-1801." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linear spatial pyramid matching using sparse cod-ing for image classification">
                                        <b>[3]</b>
                                         YANG J C, YU K, GONG Y H, et al. Linear spatial pyramid matching using sparse coding for image classification [C]// CVPR &#39;09: Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2009: 1794-1801.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" ZOU H, HASTIE T. Regularization and variable selection via the elastic net [J]. Journal of the Royal Statistical Society, 2005, 67 (2) : 301-320." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001256895&amp;v=MDE1MjRGaS9rVzcvQUpGOD1OaWZjYXJPNEh0SE5yWXBEYk9JS1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         ZOU H, HASTIE T. Regularization and variable selection via the elastic net [J]. Journal of the Royal Statistical Society, 2005, 67 (2) : 301-320.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" ZHANG Z, LAI Z H, XU Y, et al. Discriminative elastic-net regularized linear regression [J]. IEEE Transactions on Image Processing, 2017, 26 (3) : 1466-1481." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative elastic-net regularized linear regression">
                                        <b>[5]</b>
                                         ZHANG Z, LAI Z H, XU Y, et al. Discriminative elastic-net regularized linear regression [J]. IEEE Transactions on Image Processing, 2017, 26 (3) : 1466-1481.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 张勇, 张阳阳, 程洪, 等.基于非负弹性网稀疏编码算法的图像分类方法[J].计算机工程, 2017, 43 (7) :239-243. (ZHNAG Y, ZHANG Y Y, CHENG H, et al. Image classification method based on non-negative elastic net sparse coding algorithm[J]. Computer Engineering, 2017, 43 (7) : 239-243.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707041&amp;v=MzI2MTA1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkpMejdCYmJHNEg5Yk1xSTlCWllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         张勇, 张阳阳, 程洪, 等.基于非负弹性网稀疏编码算法的图像分类方法[J].计算机工程, 2017, 43 (7) :239-243. (ZHNAG Y, ZHANG Y Y, CHENG H, et al. Image classification method based on non-negative elastic net sparse coding algorithm[J]. Computer Engineering, 2017, 43 (7) : 239-243.) 
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" SHEN B, LIU B D, WANG Q F. Elastic net regularized dictionary learning for image classification [J]. Multimedia Tools and Applications, 2016, 75 (15) : 8861-8874." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Elastic Net Regularized Dictionary Learning for Image Classification">
                                        <b>[7]</b>
                                         SHEN B, LIU B D, WANG Q F. Elastic net regularized dictionary learning for image classification [J]. Multimedia Tools and Applications, 2016, 75 (15) : 8861-8874.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" YU K, ZHANG T, GONG Y. Nonlinear learning using local coordinate coding [EB/OL]. [2018- 06- 12]. http://www.doc88.com/p-6971813767934.html." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear learning using local coordinate coding">
                                        <b>[8]</b>
                                         YU K, ZHANG T, GONG Y. Nonlinear learning using local coordinate coding [EB/OL]. [2018- 06- 12]. http://www.doc88.com/p-6971813767934.html.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" WANG J, YANG J, YU K, et al. Locality-constrained linear coding for image classification [C]// CVPR &#39;10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2010: 3360-3367." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locality-constrained linear coding for image classification">
                                        <b>[9]</b>
                                         WANG J, YANG J, YU K, et al. Locality-constrained linear coding for image classification [C]// CVPR &#39;10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2010: 3360-3367.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 刘培娜, 刘国军, 郭茂组, 等.非负局部约束线性编码图像分类算法[J].自动化学报, 2015, 41 (7) :1235-1243. (LIU P N, LIU G J, GUO M Z, et al. Image classification based on non-negative locality constrained linear coding[J]. Acta Automatica Sinica, 2015, 41 (7) : 1235-1243.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201507002&amp;v=MDg0MzZxQnRHRnJDVVI3cWZadVpwRmlEbFc3dkpLQ0xmWWJHNEg5VE1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘培娜, 刘国军, 郭茂组, 等.非负局部约束线性编码图像分类算法[J].自动化学报, 2015, 41 (7) :1235-1243. (LIU P N, LIU G J, GUO M Z, et al. Image classification based on non-negative locality constrained linear coding[J]. Acta Automatica Sinica, 2015, 41 (7) : 1235-1243.) 
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" WU J, REHG J M. Beyond the Euclidean distance: creating effective visual codebooks using the Histogram intersection kernel [C]// ICCV &#39;09: Proceedings of the 2009 IEEE 12th International Conference on Computer Vision. Piscataway, NJ: IEEE, 2009: 630-637." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond the Euclidean distance:Creating effective visual codebooks using the Histogram Intersection Kernel">
                                        <b>[11]</b>
                                         WU J, REHG J M. Beyond the Euclidean distance: creating effective visual codebooks using the Histogram intersection kernel [C]// ICCV &#39;09: Proceedings of the 2009 IEEE 12th International Conference on Computer Vision. Piscataway, NJ: IEEE, 2009: 630-637.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" CHEN H, XIE K, WANG H, et al. Scene image classification using locality-constrained linear coding based on histogram intersection [J]. Multimedia Tools and Applications, 2018, 77 (3) :4081-4092." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scene image classification using locality-constrained linear coding based on histogram intersection">
                                        <b>[12]</b>
                                         CHEN H, XIE K, WANG H, et al. Scene image classification using locality-constrained linear coding based on histogram intersection [J]. Multimedia Tools and Applications, 2018, 77 (3) :4081-4092.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" LEE H, BATTLE A, RAINA R, et al. Efficient sparse coding algorithms [C]// NIPS &#39;06: Proceedings of the 19th International Conference on Neural Information Processing Systems. Cambridge, MA: MIT Press, 2006: 801-808." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient sparse coding algorithms">
                                        <b>[13]</b>
                                         LEE H, BATTLE A, RAINA R, et al. Efficient sparse coding algorithms [C]// NIPS &#39;06: Proceedings of the 19th International Conference on Neural Information Processing Systems. Cambridge, MA: MIT Press, 2006: 801-808.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" GAO S, TSANG I W-H, CHIA L-T, et al. Local features are not lonely-Laplacian sparse coding for image classification [C]// CVPR &#39;10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2010: 3555-3561." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local Features Are Not Lonely-Laplacian Sparse Coding for Image Classification">
                                        <b>[14]</b>
                                         GAO S, TSANG I W-H, CHIA L-T, et al. Local features are not lonely-Laplacian sparse coding for image classification [C]// CVPR &#39;10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2010: 3555-3561.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" HAN H, LIU S, GAN L. Non-negativity and dependence constrained sparse coding for image classification [J]. Journal of Visual Communication and Image Representation. 2015, 26 (C) : 247-254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200075632&amp;v=MjgwNjRaZVp0RmlubFVyakpLRjRjYmhNPU5pZk9mYks4SDlQTnJZOUZaT3dLQ244N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         HAN H, LIU S, GAN L. Non-negativity and dependence constrained sparse coding for image classification [J]. Journal of Visual Communication and Image Representation. 2015, 26 (C) : 247-254.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     史莹.基于Laplacian稀疏编码的图像分类研究[D].武汉:武汉理工大学, 2016:30-31. (SHI Y. Image classification based on Laplacian sparse coding[D].Wuhan: Wuhan University of Technology, 2016:30-31.) </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" CAI D. Four face databases in matlab format [DB/OL]. [2018- 03- 29]. http://www.cad.zju.edu.cn/home/ dengcai/Data/FaceData.htm.This work is partially supported by the Fundamental Research Funds for the Central Universities (2018IB016) .WAN Yuan, born in 1976, Ph. D., professor. Her research interests include machine learning, image processing, pattern recognition.ZHANG Jinghui, born in 1990, M. S. candidate. Her research interests include pattern recognition, image processing.CHEN Zhiping, born in 1995. His research interests include pattern recognition, image processing.MENG Xiaojing, born in 1996, M. S. candidate. Her research interests include pattern recognition, image processing." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Four face databases in matlab format">
                                        <b>[17]</b>
                                         CAI D. Four face databases in matlab format [DB/OL]. [2018- 03- 29]. http://www.cad.zju.edu.cn/home/ dengcai/Data/FaceData.htm.This work is partially supported by the Fundamental Research Funds for the Central Universities (2018IB016) .WAN Yuan, born in 1976, Ph. D., professor. Her research interests include machine learning, image processing, pattern recognition.ZHANG Jinghui, born in 1990, M. S. candidate. Her research interests include pattern recognition, image processing.CHEN Zhiping, born in 1995. His research interests include pattern recognition, image processing.MENG Xiaojing, born in 1996, M. S. candidate. Her research interests include pattern recognition, image processing.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-26 12:43</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),706-711 DOI:10.11772/j.issn.1001-9081.2018071483            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于弹性网和直方图相交的非负局部稀疏编码</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E6%BA%90&amp;code=10154632&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万源</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%99%AF%E4%BC%9A&amp;code=40018484&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张景会</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B2%BB%E5%B9%B3&amp;code=41275247&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈治平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%9F%E6%99%93%E9%9D%99&amp;code=40059242&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孟晓静</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=0065699&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉理工大学理学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对稀疏编码模型在字典基的选择时忽略了群效应, 且欧氏距离不能有效度量特征与字典基之间距离的问题, 提出基于弹性网和直方图相交的非负局部稀疏编码方法 (EH-NLSC) 。首先, 在优化函数中引入弹性网模型, 消除字典基选择数目的限制, 能够选择多组相关特征而排除冗余特征, 提高了编码的判别性和有效性。然后, 在局部性约束中引入直方图相交, 重新定义特征与字典基之间的距离, 确保相似的特征可以共享其局部的基。最后采用多类线性支持向量机进行分类。在4个公共数据集上的实验结果表明, 与局部线性约束的编码算法 (LLC) 和基于非负弹性网的稀疏编码算法 (NENSC) 相比, EH-NLSC的分类准确率分别平均提升了10个百分点和9个百分点, 充分体现了其在图像表示和分类中的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏编码;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%B9%E6%80%A7%E7%BD%91%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">弹性网模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B4%E6%96%B9%E5%9B%BE%E7%9B%B8%E4%BA%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">直方图相交;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    万源 (1976—) , 女, 湖北武汉人, 教授, 博士, 主要研究方向:机器学习、图像处理、模式识别;;
                                </span>
                                <span>
                                    *张景会 (1990—) , 女, 河南商丘人, 硕士研究生, 主要研究方向:模式识别、图像处理;电子邮箱Jingzhang@whut.edu.cn;
                                </span>
                                <span>
                                    陈治平 (1995—) , 男, 湖北大冶人, 主要研究方向:模式识别、图像处理;;
                                </span>
                                <span>
                                    孟晓静 (1996—) , 女, 河南濮阳人, 硕士研究生, 主要研究方向:模式识别、图像处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>中央高校基本科研业务费资助项目 (2018IB016);</span>
                    </p>
            </div>
                    <h1><b>Non-negative local sparse coding algorithm based on elastic net and histogram intersection</b></h1>
                    <h2>
                    <span>WAN Yuan</span>
                    <span>ZHANG Jinghui</span>
                    <span>CHEN Zhiping</span>
                    <span>MENG Xiaojing</span>
            </h2>
                    <h2>
                    <span>College of Science, Wuhan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the problems that group effect is neglected when selecting dictionary bases in sparse coding models, and distance between a features and a dictionary base can not be effectively measured by Euclidean distance, Non-negative Local Sparse Coding algorithm based on Elastic net and Histogram intersection (EH-NLSC) was proposed. Firstly, with elastic-net model introduced in the optimization function to remove the restriction on selected number of dictionary bases, multiple groups of correlation features were selected and redundant features were eliminated, improving the discriminability and effectiveness of the coding. Then, histogram intersection was introduced in the locality constraint of the coding, and the distance between the feature and the dictionary base was redefined to ensure that similar features share their local bases. Finally, multi-class linear Support Vector Machine (SVM) was adopted to realize image classification. The experimental results on four public datasets show that compared with LLC (Locality-constrained Linear Coding for image classification) and NENSC (Non-negative Elastic Net Sparse Coding) , the classification accuracy of EH-NLSC is increased by 10 percentage points and 9 percentage points respectively on average, proving its effectiveness in image representation and classification.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20coding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse coding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=elastic%20net%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">elastic net model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=locality&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">locality;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=histogram%20intersection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">histogram intersection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WAN Yuan, born in 1976, Ph. D. , professor. Her research interests include machine learning, image processing, pattern recognition.;
                                </span>
                                <span>
                                    ZHANG Jinghui, born in 1990, M. S. candidate. Her research interests include pattern recognition, image processing.;
                                </span>
                                <span>
                                    CHEN Zhiping, born in 1995. His research interests include pattern recognition, image processing.;
                                </span>
                                <span>
                                    MENG Xiaojing, born in 1996, M. S. candidate. Her research interests include pattern recognition, image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-18</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Fundamental Research Funds for the Central Universities (2018IB016);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="38">图像分类是计算机视觉领域的一个重要研究方向, 广泛应用于生物特征识别、网络图像检索和机器人视觉等领域, 其关键在于如何提取特征对图像有效表示。稀疏编码是图像特征表示的有效方法。考虑到词袋 (Bag of Words, BoW) 模型<citation id="127" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>和空间金字塔匹配 (Spatial Pyramid Matching, SPM) 模型<citation id="128" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>容易造成量化误差, Yang等<citation id="129" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>结合SPM模型提出利用稀疏编码的空间金字塔的图像分类算法 (Spatial Pyramid Matching using Sparse Coding, ScSPM) , 在图像的不同尺度上进行稀疏编码, 取得了较好的分类效果。在稀疏编码模型中, 由于ℓ<sub>1</sub>范数在字典基选择时只考虑稀疏性而忽略了群体效应, Zou等<citation id="130" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出一种新的正则化方法, 将弹性网作为正则项和变量选择方法。Zhang等<citation id="131" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出判别式弹性网正则化线性回归 (Elastic-Net regularized Linear Regression, ENLR ) , 引入鲁棒弹性网络正则化方法, 以提高学习投影矩阵的紧凑性和有效性。张勇等<citation id="132" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在目标函数中引入ℓ<sub>2</sub>范数正则项, 提出基于非负弹性网的稀疏编码算法 (Non-negative Elastic Net Sparse Coding, NENSC) , 提高了编码的判别性和有效性。Shen等<citation id="133" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>建议在字典原子选择时使用弹性网作为正则项, 提出弹性网正则项的字典学习算法 (Elastic Net regularized Dictionary Learning, ENDL) , 这不仅得益于类似ℓ<sub>1</sub>范数的稀疏性, 而且还鼓励分组效应, 有助于改善图像表示的分类效果。Yu等<citation id="134" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>发现相比于稀疏性, 局部性更重要, 并且局部性必然推导出稀疏性, 但反之未必。Wang等<citation id="135" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将局部性约束引入到稀疏编码中来代替稀疏性约束, 提出局部线性约束的编码算法 (Locality-constrained Linear Coding for image classification, LLC) , 极大地提高了图像的分类性能。但是该方法对近邻数<i>k</i>很敏感, 导致编码过程极不稳定, 因此刘培娜等<citation id="136" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>在优化问题中引入非负性约束, 提出非负LLC算法。在表示特征与码本之间的距离时, 欧氏距离应用最多, 然而尺度不变特征变换 (Scale-Invariant Feature Transform, SIFT) 特征是局部图像块梯度方向直方图的统计量, Wu等<citation id="137" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>已经证明直方图相交在具有直方图特征的学习任务中比欧氏距离更有效, 提出一种超越欧氏距离的度量方法——直方图相交相似性度量方法来创建有效的可视化码本。为了解决这个问题, Chen等<citation id="138" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了一种改进的LLC算法用于场景图像分类, 称为基于直方图相交的局部约束线性编码 (Locality-constrained Linear Coding based on Histogram Intersection, HILLC) 。</p>
                </div>
                <div class="p1">
                    <p id="39">针对文献<citation id="139" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</citation>在字典基的选择时只考虑了稀疏性而忽略了群体效应, 及文献<citation id="140" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>在局部性约束中利用欧氏距离不能有效地度量特征与字典基的距离的问题, 本文提出基于弹性网和直方图相交的非负局部稀疏编码 (Non-negative Local Sparse Coding based on Elastic net and Histogram intersection, EH-NLSC) 模型。在编码模型中引入了弹性网作为正则项, 可以得到类似于ℓ<sub>1</sub>范数约束的稀疏性, 而且鼓励分组效应, 提高编码的判别性和有效性;并在优化函数中引入局部性约束和非负性约束, 有效利用特征之间的局部信息, 改善编码的不稳定性并保持相似编码的一致性, 并且通过引入直方图相交, 重新定义特征向量与字典元素之间的距离。实验表明, 相比于其他现有算法, EH-NLSC的分类性能更高。</p>
                </div>
                <h3 id="40" name="40" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="41">本章简要描述稀疏编码、局部约束线性编码和弹性网模型。设图像的特征矩阵为<b><i>X</i></b>=[<b><i>x</i></b><sub>1</sub>, <b><i>x</i></b><sub>2</sub>, …, <b><i>x</i></b><sub><i>N</i></sub>]∈<b>R</b><sup><i>D</i>×<i>N</i></sup>, <b><i>U</i></b>=[<b><i>u</i></b><sub>1</sub>, <b><i>u</i></b><sub>2</sub>, …, <b><i>u</i></b><sub><i>K</i></sub>]∈<b>R</b><sup><i>D</i>×<i>M</i></sup>为字典, 以及相应的稀疏编码<b><i>V</i></b>=[<b><i>v</i></b><sub>1</sub>, <b><i>v</i></b><sub>2</sub>, …, <b><i>v</i></b><sub><i>N</i></sub>]∈<b>R</b><sup><i>M</i>×<i>N</i></sup>。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42">1.1 <b>稀疏编码</b></h4>
                <div class="p1">
                    <p id="43">由于向量量化方法很容易导致量化误差, 并且<i>K</i>-means方法可能会使语义信息丢失, 因此Yang等结合SPM提出了基于SPM的稀疏编码方法 (ScSPM) 。其核心问题是学习<i>M</i>空间中的超完备 (即<i>M</i>≥<i>D</i>, 基向量的个数远大于维数) 字典<b><i>U</i></b>, 并选取其中尽可能少的基向量来表示原始的特征向量。稀疏编码具体的优化模型如下:</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi mathvariant="bold-italic">V</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>λ</mi></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>≤</mo><mn>1</mn><mi>；</mi><mo>∀</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Μ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45">其中:‖<b><i>v</i></b><sub><i>i</i></sub>‖<sub>1</sub>是对<b><i>v</i></b><sub><i>i</i></sub>进行稀疏约束的ℓ<sub>1</sub>范数;<b><i>u</i></b><sub><i>j</i></sub>是字典<b><i>U</i></b>的第<i>j</i>列元素;<i>λ</i>为正则化系数, 用来平衡重构误差和编码的稀疏性, 对于式 (1) , 一般采取交替固定<b><i>U</i></b> (或<b><i>V</i></b>) 来优化<b><i>V</i></b> (或<b><i>U</i></b>) 的方法达到最优解。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46">1.2 <b>局部约束线性编码</b></h4>
                <div class="p1">
                    <p id="47">Yu等指出局部性比稀疏性更重要, 因为局部性可以推出稀疏性, 但稀疏性不能推出局部性。Wang等指出局部非零系数通常被分配给编码特征附近的基。因此, LLC方法用字典中的许多基来表示特征描述子, 相似的特征通过共享它们的局部的基来获得相似的编码, 从而提高了稀疏编码的不稳定性。局部约束线性编码具体的优化问题如下:</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi mathvariant="bold-italic">V</mi></mrow></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>λ</mi></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mn>1</mn><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mi>；</mi><mo>∀</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">其中:⊙代表逐元素相乘 (对于列向量) ;<i>λ</i>为正则化参数;<b><i>d</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>M</i></sup>是一个局部适应器, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="50"><b><i>d</i></b><sub><i>i</i></sub> =exp (<i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>U</i></b>) /<i>σ</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="51"><i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>U</i></b>) =[<i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub>1</sub>) , …, <i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub><i>M</i></sub>) ]<sup>T </sup></p>
                </div>
                <div class="p1">
                    <p id="52">其中:<i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub><i>j</i></sub>) 是特征描述子<b><i>x</i></b><sub><i>i</i></sub>与字典基<b><i>u</i></b><sub><i>j</i></sub>之间的欧氏距离;<i>σ</i>是一个用来调整权重衰减的参数;约束条件1<sup>T </sup><b><i>v</i></b><sub><i>i</i></sub>=1代表了LLC编码的平移不变性。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53">1.3 <b>弹性网模型</b></h4>
                <div class="p1">
                    <p id="54">Shen等<citation id="141" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>通过增加‖<b><i>v</i></b><sub><i>i</i></sub>‖<sub>2</sub>提出了弹性网模型, 该模型可以将高度相关的特征一起选出来, 具有较强的特征选择能力。不仅保证了编码的稀疏性, ℓ<sub>2</sub>范数控制了特征描述子的敏感性, 提高了编码的判别性和有效性。弹性网模型如下:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi mathvariant="bold-italic">V</mi></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>γ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mn>1</mn><mo>, </mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo>≥</mo><mn>0</mn><mi>；</mi><mo>∀</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Μ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">其中<i>λ</i>, <i>γ</i>均为非负正则项参数。当<i>γ</i>为0时, 即为ScSPM模型;当<i>λ</i>为0时, 式 (3) 是著名的岭回归 (Ridge Regression) 。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">2 本文方法</h3>
                <div class="p1">
                    <p id="58">以上这些方法都能在一定程度上减小重构误差, 但仍然存在以下几个不足: 1) 编码模型中的ℓ<sub>1</sub>范数只考虑了稀疏性, 忽略了群体效应, 图像特征不能找到与同一类图像对应的字典基;2) 特征之间缺乏局部性和非负性约束, 相似的特征可能会被编码成不同的码字;3) 利用欧氏距离来计算特征描述子和字典之间的距离不够有效。基于以上3个问题, 本文提出基于弹性网和直方图相交的非负局部稀疏编码模型。首先, 针对第1个问题, 将弹性网模型应用到稀疏编码中, 即在编码模型中添加ℓ<sub>2</sub>范数, 将有效且相关的特征一起选出来, 充分考虑了字典基选择时的群体效应, 有助于消除字典中所选原子数的限制, 保留判别性特征并消除冗余特征 (如图1:与SC相比, EH-NLSC选择多个相关的基, 虚线箭头为去除的冗余特征) , 有效提高了编码的有效性;然后, 引入局部性和非负性, 确保相似特征共享局部的基 (如图1:<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>共享局部的基) , 改善编码的不稳定性;最后, 通过引入直方图相交, 重新定义特征向量与字典基之间的距离, 使得图像表示更准确有效。再利用空间金字塔匹配SPM将图像划分为<i>L</i><sub>0</sub>、<i>L</i><sub>1</sub>和<i>L</i><sub>2</sub>三层, 并对每层的空间金字塔区域进行最大值融合 (Max Pooling, MP) , 将三层分别得到的编码连接起来, 得到图像的最终特征表示。最后利用支持向量机 (Support Vector Machine, SVM) 进行训练和分类。</p>
                </div>
                <div class="p1">
                    <p id="59">图1为本文提出的EH-NLSC模型的框架, 其中, 在学习字典和编码阶段, 图中给出了传统的稀疏编码 (Sparse Coding, SC) 方法与本文的EH-NLSC的对比, 虚线框为传统的稀疏编码方法, 实线框为本文学习字典和稀疏编码的核心内容。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903016_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 EH-NLSC算法框架" src="Detail/GetImg?filename=images/JSJY201903016_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 EH-NLSC算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903016_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Framework of EH-NLSC algorithm</p>

                </div>
                <h4 class="anchor-tag" id="61" name="61">2.1 EH-NLSC<b>模型</b></h4>
                <div class="p1">
                    <p id="62">本文结合弹性网模型, 将ℓ<sub>2</sub>范数引入到稀疏编码的目标函数中, 并在优化问题中的添加局部性约束, 将非负性添加到优化问题的约束条件中, 最终形成EH-NLSC, 即为图1中实线框内的核心内容。具体的优化问题如下所示:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi mathvariant="bold-italic">V</mi></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>β</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>≤</mo><mn>1</mn><mo>, </mo><mi mathvariant="bold-italic">U</mi><mo>≥</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">V</mi><mo>≥</mo><mn>0</mn><mo>, </mo><mo>∀</mo><mi>j</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中:<b><i>X</i></b>=[<b><i>x</i></b><sub>1</sub>, <b><i>x</i></b><sub>2</sub>, …, <b><i>x</i></b><sub><i>N</i></sub>]∈<b>R</b><sup><i>D</i>×<i>N</i></sup>为非负的特征矩阵, <b><i>U</i></b>和<b><i>V</i></b>为非负字典和相应的稀疏编码, <i>λ</i>和<i>β</i>为非负正则参数, ‖<b><i>v</i></b><sub><i>i</i></sub>‖<sub>2</sub>为编码<b><i>v</i></b><sub><i>i</i></sub>的ℓ<sub>2</sub>范数。本文对LLC中计算特征向量与字典基的欧氏距离进行改进, 提出一种直方图相交的相似性度量方法, <b><i>d</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>M</i></sup>是一个局部适应器, 定义为:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mi>σ</mi><mrow><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">U</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">其中:<i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>U</i></b>) = [<i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub>1</sub>) , <i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub>2</sub>) , …, <i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub><i>M</i></sub>) ]<sup>T </sup>, <i>dist</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>u</i></b><sub><i>j</i></sub>) 表示特征描述子<b><i>x</i></b><sub><i>i</i></sub>和字典基<b><i>u</i></b><sub><i>j</i></sub>之间的距离;<i>σ</i>为调节权重衰减的参数。该距离利用直方图相交来计算, 直方图相交距离计算方法为:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mrow><mi>min</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>, </mo><mi>u</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中, 这里的直方图分别指的是特征描述子<b><i>X</i></b>和字典<b><i>U</i></b>, <i>M</i>为两个直方图的维度 (即特征和字典的尺寸) , <i>x</i><sub><i>ik</i></sub>和<i>u</i><sub><i>jk</i></sub>分别表示直方图<b><i>x</i></b><sub><i>i</i></sub>和<b><i>u</i></b><sub><i>j</i></sub>的第<i>k</i>个元素。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2 EH-NLSC<b>算法的求解</b></h4>
                <div class="p1">
                    <p id="70">对于式 (4) , 由于同时优化目标函数中的<b><i>U</i></b>和<b><i>V</i></b>, 该问题是非凸的, 这样很难找到一个全局最小值, 但当分别优化<b><i>U</i></b>或<b><i>V</i></b>是凸的, 交替优化<b><i>U</i></b>和<b><i>V</i></b>就会存在全局最优解。</p>
                </div>
                <div class="p1">
                    <p id="71">首先, 固定<b><i>X</i></b>和<b><i>V</i></b>, 优化非负字典<b><i>U</i></b>, 优化问题转化为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">U</mi></munder><mspace width="0.25em" /><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">U</mi><mo>≥</mo><mn>0</mn><mo>, </mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>≤</mo><mn>1</mn><mo>, </mo><mo>∀</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Μ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式 (7) 是一个二次约束最小二乘问题, 可以采用迭代投影梯度下降法来求解, 本文采取Lagrange对偶方法<citation id="142" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>可以更有效地进行求解。设<i>λ</i>=[<i>λ</i><sub>1</sub>, <i>λ</i><sub>2</sub>, …, <i>λ</i><sub><i>M</i></sub>], <i>λ</i><sub><i>i</i></sub>表示与第<i>i</i>个不等式约束‖<b><i>u</i></b><sub><i>j</i></sub>‖<sup>2</sup>-1≤0相关的Lagrange乘子, 则式 (7) 对应的Lagrange函数为:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>λ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">在Lagrange对偶函数中引入对角矩阵<i>Λ</i>∈<b>R</b><sup><i>M</i>×<i>M</i></sup>, <i>Λ</i>=diag (<i>λ</i>) , 将式 (8) 转化为矩阵迹的形式:</p>
                </div>
                <div class="p1">
                    <p id="76"><i>L</i> (<b><i>U</i></b>, <i>Λ</i>) =‖<b><i>X</i></b>-<b><i>U</i></b><b><i>V</i></b>‖<sup>2</sup><sub>F</sub>+tr (<b><i>U</i></b><sup>T</sup><b><i>U</i></b><i>Λ</i>) -tr (<i>Λ</i>) =</p>
                </div>
                <div class="p1">
                    <p id="77">tr (<b><i>X</i></b><sup>T</sup><b><i>X</i></b>) -2tr (<b><i>U</i></b><sup>T</sup><b><i>X</i></b><b><i>V</i></b><sup>T</sup>) +tr (<b><i>V</i></b><sup>T</sup><b><i>U</i></b><sup>T</sup><b><i>U</i></b><b><i>V</i></b>) +tr (<b><i>U</i></b><sup>T</sup><b><i>U</i></b><i>Λ</i>) -tr (<i>Λ</i>) </p>
                </div>
                <div class="p1">
                    <p id="78">令Lagrange对偶函数<i>L</i> (<b><i>U</i></b>, <i>λ</i>) 关于<b><i>U</i></b>的梯度为零, 可得:</p>
                </div>
                <div class="p1">
                    <p id="79"><b><i>U</i></b>= (<b><i>X</i></b><b><i>V</i></b><sup>T</sup>) (<b><i>V</i></b><b><i>V</i></b><sup>T</sup>+<i>Λ</i>) <sup>-1</sup>      (9) </p>
                </div>
                <div class="p1">
                    <p id="80">则式 (7) 中的目标函数可以转化为:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">Λ</mi></munder><mspace width="0.25em" /><mspace width="0.25em" /><mtext>t</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">V</mi><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi mathvariant="bold-italic">Λ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">V</mi><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>-</mo><mi mathvariant="bold-italic">Λ</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtable><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo></mtd><mtd><mi mathvariant="bold-italic">Λ</mi><mo>≥</mo><mn>0</mn></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">对于此式采用共轭梯度法求解, 解出<i>Λ</i><sup>*</sup>代入式 (9) 可得具有局部约束的非负字典<b><i>U</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="83"><b><i>U</i></b><sup>*</sup>= (<b><i>X</i></b><b><i>V</i></b><sup>T</sup>) (<b><i>V</i></b><b><i>V</i></b><sup>T</sup>+<i>Λ</i><sup>*</sup>) <sup>-1</sup></p>
                </div>
                <div class="p1">
                    <p id="84">再固定<b><i>X</i></b>和<b><i>U</i></b>, 优化稀疏编码<b><i>V</i></b>, 相应的优化问题为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">V</mi></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi>d</mi><mo>⊙</mo><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo><mi>β</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">V</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">V</mi><mo>≥</mo><mn>0</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中:<b><i>d</i></b>=[<b><i>d</i></b><sub>1</sub>, <b><i>d</i></b><sub>2</sub>, …, <b><i>d</i></b><sub><i>N</i></sub>]∈<b>R</b><sup><i>M</i>×<i>N</i></sup>。首先将式 (11) 转化为矩阵迹的形式, 利用Lagrange乘数法 (Lagrange Multiplier Method, LMM) , 在目标函数中引入Lagrange乘子<i>ζ</i>, <i>ζ</i>=[<i>ζ</i><sub><i>ij</i></sub>], <i>ζ</i><sub><i>ij</i></sub>≥0, 根据KKT (Karush-Kuhn-Tucker) 条件可得稀疏编码<b><i>V</i></b>的更新规则为:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup><msqrt><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mrow><mtext>Τ</mtext><mspace width="0.25em" /></mrow></msup><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mspace width="0.25em" /></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mrow><mtext>Τ</mtext><mspace width="0.25em" /></mrow></msup><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">V</mi><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mi>λ</mi><mspace width="0.25em" /><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">e</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi mathvariant="bold-italic">V</mi><mspace width="0.25em" /><mo>+</mo><mspace width="0.25em" /><mi>β</mi><mi mathvariant="bold-italic">V</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mspace width="0.25em" /></mrow></msub></mrow></mfrac></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中:diag (<b><i>e</i></b><sub><i>i</i></sub>) 是以<b><i>e</i></b><sub><i>i</i></sub>为对角元素的对角矩阵, <b><i>e</i></b><sub><i>i</i></sub>=[<i>d</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml>, <i>d</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml>, …, <i>d</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>Ν</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>]为<i>N</i>维的行向量。</p>
                </div>
                <h3 id="92" name="92" class="anchor-tag">3 实验结果及分析</h3>
                <div class="p1">
                    <p id="93">本章设计了两组仿真实验来验证EH-NLSC算法的性能和效果, 其中3.1节给出实验所用数据集和实验设置, 实验设置包括本文所对比的方法以及参数设置;3.2节介绍本文的两组实验设计内容及结果分析。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">3.1 <b>实验数据集和实验设置</b></h4>
                <div class="p1">
                    <p id="95">本文选择4个数据集对EH-NLSC方法进行验证, 分别为Corel-10、Scene-15、Caltech-101、Caltech-256, 表1给出了所选数据集的信息。</p>
                </div>
                <div class="p1">
                    <p id="96">为了验证本文方法的有效性, 将本文方法与以下几种方法进行对比分析:</p>
                </div>
                <div class="p1">
                    <p id="97">1) ScSPM。利用稀疏编码的空间金字塔匹配的图像分类算法<citation id="143" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 在图像的不同尺度上进行稀疏编码, 并结合空间金字塔匹配方法进行图像表示。</p>
                </div>
                <div class="p1">
                    <p id="98">2) LLC。利用局部约束将每个特征描述符投影到其局部坐标系中, 并通过最大池融合投影坐标以生成最终表示<citation id="144" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="99">3) ENDL。使用弹性网作为正则项来选择特征编码中的原子, 这不仅可以得到类似于ℓ<sub>1</sub>范数的稀疏性, 而且还鼓励群体效应, 有助于改善图像表示<citation id="145" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="100">4) NENSC。利用非负稀疏编码算法和弹性网模型, 在稀疏编码优化模型中引入ℓ<sub>2</sub>范数作为正则项, 增加编码系数的非负性约束<citation id="146" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="101">5) LScSPM。LScSPM (ScSPM based on Laplacian) <citation id="147" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用局部特征之间的依赖关系, 使用Laplacian矩阵较好地刻画局部特征的相似性;此外, 将拉普拉斯矩阵合并到稀疏编码的目标函数中, 以保持编码的一致性。</p>
                </div>
                <div class="p1">
                    <p id="102">6) Lap-NMF-SPM。Lap-NMF-SPM (NMF and graph Laplacian based on Spatial Pyramid Matching) <citation id="148" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>使用非负矩阵分解来约束码本和相应的编码系数的非负性, 利用图拉普拉斯正则化方法保持局部和相似特征之间的依赖性。</p>
                </div>
                <div class="p1">
                    <p id="103">7) HILLC。使用直方图相交来描述特征向量与码本之间的距离。对于每个特征向量, 搜索<i>K</i>最近邻 (<i>K</i>-Nearest Neighbor, <i>K</i>NN) 来构造一个局部码本<citation id="149" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="104">在特征提取阶段, 利用16×16的滑动窗口, 步长为8进行SIFT特征提取, 每个局部特征描述子均为128维, 即<i>D</i>=128;在字典训练阶段, 固定字典的大小为<i>M</i>=1 024, 然后对于4个数据集, 选取不同的训练样本和测试样本。对于Corel-10和Scene-15两个数据集, 从每类中分别随机选择50和100幅图像作为训练样本, 剩余的作为测试样本。而对于Caltech-10和Caltech-256数据集, 从每类分别随机选择15、30和15、30、45、60幅图像作为训练样本, 剩余的作为测试样本。关于优化问题中涉及的参数<i>λ</i>、 <i>β</i>以及<i>σ</i>, 分别设置 <i>λ</i>∈[0.1, 0.4], <i>β</i>∈[0.1, 0.4], <i>σ</i>=100。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表</b>1 <b>实验中使用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Datasets used in experiments</p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />数据集</td><td>类别数</td><td>每类图像总数</td><td>图像总数</td></tr><tr><td><br />Corel-10</td><td>10</td><td>100</td><td>1 000</td></tr><tr><td><br />Scene-15</td><td>15</td><td>200～400</td><td>4 485</td></tr><tr><td><br />Caltech-101</td><td>101</td><td>31～800</td><td>9 144</td></tr><tr><td><br />Caltech-256</td><td>256</td><td>≥80</td><td>29 780</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">3.2 <b>实验设计及结果分析</b></h4>
                <h4 class="anchor-tag" id="107" name="107">3.2.1 实验1:三种方法所得字典比较</h4>
                <div class="p1">
                    <p id="108">首先, 对SC、LSC以及本文方法EH-NLSC训练所得到的字典图予以显示, 如图2所示。为了提高字典的表示能力, 必须保证字典原子能够合理地遍布于潜在的子空间, 并且原始的训练样本具有大量的冗余信息和噪声干扰, 因此需要采用精简且具有区分度的字典来提高识别精度。由灰度图可以看出, 本文方法EH-NLSC学习到的字典具有更多的可判别属性, 其中灰色像素反映图像中原始特征的更多特性, 比如EH-NLSC方法学习到的字典具有更好的局部性、非负性、带通性和方向性 (图2 (a) 、 (b) 来自文献<citation id="150" type="reference">[<a class="sup">16</a>]</citation>) 。</p>
                </div>
                <div class="p1">
                    <p id="109">为了更好地说明本文算法的有效性, 选取Yale数据集<citation id="151" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>对图像进行重建, 随机选取部分图像。在训练阶段, 利用EH-NLSC算法交替优化目标函数, 得到完备字典<b><i>U</i></b>和稀疏编码矩阵<b><i>V</i></b>;在测试阶段, 对于新的单幅输入图像, 利用训练得到的字典<b><i>U</i></b>及式 (12) 计算其稀疏系数<b><i>v</i></b><sub><i>i</i></sub>;在重建阶段, 利用完备字典<b><i>U</i></b>和稀疏系数<b><i>v</i></b><sub><i>i</i></sub>对图像进行重建。如图3所示, 从图像的视觉效果来看, 重建的图像比较清晰, 但得到的结果局部细节边缘模糊, 这是由于在EH-NLSC优化函数中添加了局部性约束, 使得图像的重建系数是稀疏的, 同时在图像重建时也造成图像信息的损失, 因此重建图像的部分局部细节模糊。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903016_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 三种方法训练得到的字典" src="Detail/GetImg?filename=images/JSJY201903016_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 三种方法训练得到的字典  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903016_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Dictionaries trained by three methods</p>

                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903016_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 原图与本文方法重建结果对比" src="Detail/GetImg?filename=images/JSJY201903016_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 原图与本文方法重建结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903016_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Comparison of original image and reconstruction results by EH-NLSC</p>

                </div>
                <h4 class="anchor-tag" id="112" name="112">3.2.2 实验2:不同方法平均分类准确率比较</h4>
                <div class="p1">
                    <p id="113">表2, 3分别为EH-NLSC算法与ScSPM、LLC、ENDL、HILLSC和NENSC五种方法在Scene-15, Caltech-101两个数据集上的分类效果;表4, 5分别为EH-NLSC算法与ScSPM、LLC、LScSPM和Lap-NMF-SPM四种方法在Corel-10和Caltech-256数据集上的分类效果。</p>
                </div>
                <div class="p1">
                    <p id="114">从表2的结果可以看出, 本文的EH-NLSC算法取得了更好的效果。与LLC方法相比, EH-NLS的分类准确率提高了10个百分点, 与HILLSC方法相比, 分类准确率提高了5.5个百分点, 原因是对Scene-15场景分类, 每个局部图像块包含丰富的纹理和轮廓, 虽然这三种方法都可以对特征进行局部约束, 但是在本文方法中, 通过使用弹性网模型作为正则项, 在稀疏编码的优化函数中引入ℓ<sub>2</sub>范数, 鼓励字典基选择时的群体效应, 将高度相关且判别性很高的特征一起选出来, 也将冗余特征去除掉, 有效控制了特征描述子的敏感性。另外, EH-NLSC与HILLSC均优于LLC, 由于在局部性约束中通过引入直方图相交来代替原来的特征向量与码本之间的欧氏距离, 与SIFT特征是基于直方图的统计量保持一致, 因此取得较好的分类效果。</p>
                </div>
                <div class="area_img" id="115">
                    <p class="img_tit"><b>表</b>2 Scene-15<b>数据集上的分类准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Classification accuracy on dataset Scene-15 </p>
                    <p class="img_note">%</p>
                    <table id="115" border="1"><tr><td><br />算法</td><td>平均分类准确率</td></tr><tr><td><br />ScSPM</td><td>81.12±0.45</td></tr><tr><td><br />LLC</td><td>81.53±0.87</td></tr><tr><td><br />ENDL</td><td>82.25±0.56</td></tr><tr><td><br />NENSC</td><td>82.51±0.72</td></tr><tr><td><br />HILLSC</td><td>86.34±0.46</td></tr><tr><td><br />EH-NLSC</td><td>91.82±0.67</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="116">表3显示了本文方法EH-NLSC和几种方法在Caltech-101数据集上的性能比较。</p>
                </div>
                <div class="area_img" id="117">
                    <p class="img_tit"><b>表</b>3 Caltech-101<b>数据集上的分类准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Classification accuracy on dataset Caltech-101 </p>
                    <p class="img_note">%</p>
                    <table id="117" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="2"><br />训练图像数目</td></tr><tr><td><br />15</td><td>30</td></tr><tr><td><br />ScSPM</td><td>66.87±0.45</td><td>72.10±1.14</td></tr><tr><td><br />LLC</td><td>68.57±0.88</td><td>72.54±0.71</td></tr><tr><td><br />ENDL</td><td>70.42±0.40</td><td>77.55±0.54</td></tr><tr><td><br />NENSC</td><td>67.31±0.87</td><td>73.83±0.81</td></tr><tr><td><br />EH-NLSC</td><td>73.34±0.62</td><td>78.89±0.39</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="118">同样地, EH-NLSC方法的分类准确率比其他几种方法效果都要好, 首先相比于ScSPM、ENDL和NENSC, 本文方法在优化问题中引入局部性约束, 确保相似的特征共享其局部的基, 使得编码过程更加稳定。另外, 添加对字典和编码的非负性约束, 使优化问题只涉及加法运算, 从而保留更多的有效特征。相比于LLC方法, EH-NLSC在计算特征描述子与码本之间的距离时, 利用的是直方图相交相似性度量, 因此可以更好地保留局部信息;同时在稀疏编码模型中引入了弹性网正则项, 鼓励分组效应, 选择具有判别信息的特征, 更加有利于特征表示。</p>
                </div>
                <div class="p1">
                    <p id="119">为了充分证明EH-NLSC方法在图像分类中的有效性, 本文在Corel-10和Caltech-256数据集上设计了另外一组实验, 对比方法为ScSPM、LLC、LScSPM和Lap-NMF-SPM。对比结果如表4和表5, 从实验结果可以看出, EH-NLSC方法在两个数据集上的分类准确率均优于其他方法, 尤其优于ScSPM。ScSPM、LScSPM和Lap-NMF-SPM这三种方法, 由于局部信息的缺失, 导致图像的特性不能被准确且有效地表示出来。由于EH-NLSC在优化函数中引入了局部性约束, 确保相似的特征具有相似的编码, 保留更多局部信息。与LLC方法相比, EH-NLSC算法的分类准确率提升了6个百分点, 这是因为LLC虽然考虑到了局部性约束, 但是在衡量特征向量和码本之间的相似性时用的是欧氏距离, 而SIFT特征本是直方图统计的结果, 因此利用直方图相交代替欧氏距离更为准确。另外, EH-NLSC将弹性网模型用作正则项, 使得具有判别信息的特征均被选出, 并且将多余无关的特征去除, 有效提高了图像表示的准确性。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表</b>4 Corel-10<b>数据集上的分类准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Classification accuracy on dataset Corel-10 </p>
                    <p class="img_note">%</p>
                    <table id="120" border="1"><tr><td><br />算法</td><td>平均分类准确率</td></tr><tr><td><br />ScSPM</td><td>86.76±1.18</td></tr><tr><td><br />LLC</td><td>87.83±1.03</td></tr><tr><td><br />LScSPM</td><td>88.43±0.75</td></tr><tr><td><br />Lap-NMF-SPM</td><td>91.24±0.95</td></tr><tr><td><br />EH-NLSC</td><td>93.64±0.78</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表</b>5 Caltech-256<b>数据集上的分类准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 5 Classification accuracy on dataset Caltech-256 </p>
                    <p class="img_note"> %</p>
                    <table id="121" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="4"><br />训练图像数目</td></tr><tr><td><br />15</td><td>30</td><td>45</td><td>60</td></tr><tr><td><br />ScSPM</td><td>27.52±0.42</td><td>33.86±0.55</td><td>37.35±1.64</td><td>40.08±0.79</td></tr><tr><td><br />LLC</td><td>31.27±0.85</td><td>34.17±0.33</td><td>35.93±0.51</td><td>37.58±0.49</td></tr><tr><td><br />LScSPM</td><td>29.88±0.15</td><td>35.67±0.33</td><td>38.37±0.46</td><td>40.35±0.24</td></tr><tr><td><br />Lap-NMF-SPM</td><td>35.24±0.83</td><td>37.46±0.32</td><td>39.87±0.75</td><td>41.35±0.72</td></tr><tr><td><br />EH-NLSC</td><td>35.89±0.56</td><td>38.87±0.59</td><td>41.65±0.53</td><td>43.61±0.47</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="122" name="122">3.2.3 实验3:参数灵敏度分析</h4>
                <div class="p1">
                    <p id="123">本实验研究了不同的参数设置在4个标准数据集上对分类效果的影响, 将<i>λ</i>和<i>β</i>分别设为0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 其分类结果变化如图4所示。从图4中可以看出:在Scene-15和Corel-10两个数据集上, 当<i>λ</i>=0.3, <i>β</i>=0.2时, 分类效果达到最优;而在Caltech-101和Caltech-256数据集上, <i>λ</i>=0.3, <i>β</i>=0.1时效果最佳。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="125">本文提出一种新的稀疏编码框架, 称为基于弹性网和直方图相交的非负局部稀疏编码, 并将其与空间金字塔和最大池融合相结合来获得用于图像分类的编码模型。通过将弹性网引入到稀疏编码模型中, 本文的EH-NLSC在保持稀疏性的基础上, 鼓励分组效应, 可以有效地选择判别性特征, 并将冗余特征去除, 因此EH-NLSC比普通稀疏编码方法具有更好的鉴别能力。另外, 在图像分类中, 局部性约束已经被证明是非常重要的, 本文利用局部性约束编码, 使得相似的特征共享局部的基, 并保持相似特征具有相似编码。并通过引入直方图相交重新定义特征向量与字典元素之间的距离, 与通过直方图统计的特征保持一致。已经评估了所提方法在几个公共数据集上的分类效果, 实验证明了EH-NLSC算法的有效性。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903016_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 λ和β对分类结果的影响" src="Detail/GetImg?filename=images/JSJY201903016_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 <i>λ</i>和<i>β</i>对分类结果的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903016_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Influence of <i>λ</i> and <i>β</i> on classification results</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video google: A text retrieval approach to object matching in videos">

                                <b>[1]</b> SIVIC J, ZISSERMAN A. Video Google: a text retrieval approach to object matching in videos [C] // ICCV '03: Proceedings of the 9th International Conference on Computer Vision. Washington, DC: IEEE Computer Society, 2003, 2: 1470-1477.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond bags of features:spatial pyramid matching for recognizing natural scene categories">

                                <b>[2]</b> LAZEBNIK S, SCHMID C, PONCE J. Beyond bags of features: spatial pyramid matching for recognizing natural scene categories [C]// CVPR '06: Proceedings of the 2006 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2006: 2169-2178.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linear spatial pyramid matching using sparse cod-ing for image classification">

                                <b>[3]</b> YANG J C, YU K, GONG Y H, et al. Linear spatial pyramid matching using sparse coding for image classification [C]// CVPR '09: Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2009: 1794-1801.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001256895&amp;v=MDg4Njl4b3hjTUg3UjdxZForWnVGaS9rVzcvQUpGOD1OaWZjYXJPNEh0SE5yWXBEYk9JS1kzazV6QmRoNGo5OVNYcVJy&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> ZOU H, HASTIE T. Regularization and variable selection via the elastic net [J]. Journal of the Royal Statistical Society, 2005, 67 (2) : 301-320.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative elastic-net regularized linear regression">

                                <b>[5]</b> ZHANG Z, LAI Z H, XU Y, et al. Discriminative elastic-net regularized linear regression [J]. IEEE Transactions on Image Processing, 2017, 26 (3) : 1466-1481.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707041&amp;v=MjU4MzE0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzd2Skx6N0JiYkc0SDliTXFJOUJaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 张勇, 张阳阳, 程洪, 等.基于非负弹性网稀疏编码算法的图像分类方法[J].计算机工程, 2017, 43 (7) :239-243. (ZHNAG Y, ZHANG Y Y, CHENG H, et al. Image classification method based on non-negative elastic net sparse coding algorithm[J]. Computer Engineering, 2017, 43 (7) : 239-243.) 
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Elastic Net Regularized Dictionary Learning for Image Classification">

                                <b>[7]</b> SHEN B, LIU B D, WANG Q F. Elastic net regularized dictionary learning for image classification [J]. Multimedia Tools and Applications, 2016, 75 (15) : 8861-8874.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear learning using local coordinate coding">

                                <b>[8]</b> YU K, ZHANG T, GONG Y. Nonlinear learning using local coordinate coding [EB/OL]. [2018- 06- 12]. http://www.doc88.com/p-6971813767934.html.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locality-constrained linear coding for image classification">

                                <b>[9]</b> WANG J, YANG J, YU K, et al. Locality-constrained linear coding for image classification [C]// CVPR '10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE, 2010: 3360-3367.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201507002&amp;v=MDg5MjJDVVI3cWZadVpwRmlEbFc3dkpLQ0xmWWJHNEg5VE1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘培娜, 刘国军, 郭茂组, 等.非负局部约束线性编码图像分类算法[J].自动化学报, 2015, 41 (7) :1235-1243. (LIU P N, LIU G J, GUO M Z, et al. Image classification based on non-negative locality constrained linear coding[J]. Acta Automatica Sinica, 2015, 41 (7) : 1235-1243.) 
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond the Euclidean distance:Creating effective visual codebooks using the Histogram Intersection Kernel">

                                <b>[11]</b> WU J, REHG J M. Beyond the Euclidean distance: creating effective visual codebooks using the Histogram intersection kernel [C]// ICCV '09: Proceedings of the 2009 IEEE 12th International Conference on Computer Vision. Piscataway, NJ: IEEE, 2009: 630-637.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scene image classification using locality-constrained linear coding based on histogram intersection">

                                <b>[12]</b> CHEN H, XIE K, WANG H, et al. Scene image classification using locality-constrained linear coding based on histogram intersection [J]. Multimedia Tools and Applications, 2018, 77 (3) :4081-4092.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient sparse coding algorithms">

                                <b>[13]</b> LEE H, BATTLE A, RAINA R, et al. Efficient sparse coding algorithms [C]// NIPS '06: Proceedings of the 19th International Conference on Neural Information Processing Systems. Cambridge, MA: MIT Press, 2006: 801-808.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local Features Are Not Lonely-Laplacian Sparse Coding for Image Classification">

                                <b>[14]</b> GAO S, TSANG I W-H, CHIA L-T, et al. Local features are not lonely-Laplacian sparse coding for image classification [C]// CVPR '10: Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Washington, DC: IEEE Computer Society, 2010: 3555-3561.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200075632&amp;v=MDgzOTI2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSktGNGNiaE09TmlmT2ZiSzhIOVBOclk5RlpPd0tDbjg3b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> HAN H, LIU S, GAN L. Non-negativity and dependence constrained sparse coding for image classification [J]. Journal of Visual Communication and Image Representation. 2015, 26 (C) : 247-254.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 史莹.基于Laplacian稀疏编码的图像分类研究[D].武汉:武汉理工大学, 2016:30-31. (SHI Y. Image classification based on Laplacian sparse coding[D].Wuhan: Wuhan University of Technology, 2016:30-31.) 
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Four face databases in matlab format">

                                <b>[17]</b> CAI D. Four face databases in matlab format [DB/OL]. [2018- 03- 29]. http://www.cad.zju.edu.cn/home/ dengcai/Data/FaceData.htm.This work is partially supported by the Fundamental Research Funds for the Central Universities (2018IB016) .WAN Yuan, born in 1976, Ph. D., professor. Her research interests include machine learning, image processing, pattern recognition.ZHANG Jinghui, born in 1990, M. S. candidate. Her research interests include pattern recognition, image processing.CHEN Zhiping, born in 1995. His research interests include pattern recognition, image processing.MENG Xiaojing, born in 1996, M. S. candidate. Her research interests include pattern recognition, image processing.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903016&amp;v=MjIyNDU3cWZadVpwRmlEbFc3dkpMejdCZDdHNEg5ak1ySTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
