<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136448058252500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJY201911028%26RESULT%3d1%26SIGN%3d%252baXLa27yHZs4Q1pYwJlPOY09NMA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911028&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911028&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911028&amp;v=MDg4NzdyN0lMejdCZDdHNEg5ak5ybzlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 算法流程 ">1 算法流程</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="2 本文方法 ">2 本文方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="2.1 &lt;b&gt;图像预处理&lt;/b&gt;">2.1 <b>图像预处理</b></a></li>
                                                <li><a href="#68" data-title="2.2 &lt;b&gt;分割网络架构&lt;/b&gt;">2.2 <b>分割网络架构</b></a></li>
                                                <li><a href="#84" data-title="2.3 &lt;b&gt;精分割&lt;/b&gt;">2.3 <b>精分割</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="3 实验结果及分析 ">3 实验结果及分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="3.1 &lt;b&gt;客观评估指标&lt;/b&gt;">3.1 <b>客观评估指标</b></a></li>
                                                <li><a href="#101" data-title="3.2 &lt;b&gt;实验结果与分析&lt;/b&gt;">3.2 <b>实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 本文算法流程">图1 本文算法流程</a></li>
                                                <li><a href="#55" data-title="图2 训练集患者的七种模态MRI及病灶标签(横断面)">图2 训练集患者的七种模态MRI及病灶标签(横断面)</a></li>
                                                <li><a href="#75" data-title="图3 残差块结构示意图">图3 残差块结构示意图</a></li>
                                                <li><a href="#82" data-title="图4 基于3D深度残差网络与级联U-Net的分割架构">图4 基于3D深度残差网络与级联U-Net的分割架构</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表&lt;/b&gt;1 SPES&lt;b&gt;测试集分割评估指标比较&lt;/b&gt;"><b>表</b>1 SPES<b>测试集分割评估指标比较</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表&lt;/b&gt;2 SPES&lt;b&gt;训练集分割评估指标比较&lt;/b&gt;"><b>表</b>2 SPES<b>训练集分割评估指标比较</b></a></li>
                                                <li><a href="#110" data-title="图5 测试集分割结果对比">图5 测试集分割结果对比</a></li>
                                                <li><a href="#112" data-title="图6 训练集分割结果对比">图6 训练集分割结果对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="134">


                                    <a id="bibliography_1" title=" MOZAFFARIAN D,BENJAMIN E J,GO A S,et al.Heart disease and stroke statistics — 2016 update:a report from the American heart association[J].Circulation,2016,133(4):338-360." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Heart disease and stroke statistics-2016 update:a report from the american heart association">
                                        <b>[1]</b>
                                         MOZAFFARIAN D,BENJAMIN E J,GO A S,et al.Heart disease and stroke statistics — 2016 update:a report from the American heart association[J].Circulation,2016,133(4):338-360.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_2" title=" ASTRUP J,SYMON L,BRANSTON N M,et al.Cortical evoked potential and extracellular K+ and H+ at critical levels of brain ischemia[J].Stroke,1977,8(1):51-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWK&amp;filename=SJWK12112900265429&amp;v=MDQyMTljWmJLNkg5RE9wbzlGWnUwS0NINHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVnNWYXhJPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         ASTRUP J,SYMON L,BRANSTON N M,et al.Cortical evoked potential and extracellular K+ and H+ at critical levels of brain ischemia[J].Stroke,1977,8(1):51-57.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_3" title=" MAIER O,MENZE B H,VON DER GABLENTZ J,et al.ISLES 2015 — a public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI[J].Medical Image Analysis,2017,35:250-269." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ISLES 2015-A public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI">
                                        <b>[3]</b>
                                         MAIER O,MENZE B H,VON DER GABLENTZ J,et al.ISLES 2015 — a public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI[J].Medical Image Analysis,2017,35:250-269.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_4" title=" NEETHU S,VENKATARAMAN D.Stroke detection in brain using CT images[C]// Proceedings of the 2014 Artificial Intelligence and Evolutionary Algorithms in Engineering Systems,AISC 324.Berlin:Springer,2015:379-386." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stroke detection in brain using CT images">
                                        <b>[4]</b>
                                         NEETHU S,VENKATARAMAN D.Stroke detection in brain using CT images[C]// Proceedings of the 2014 Artificial Intelligence and Evolutionary Algorithms in Engineering Systems,AISC 324.Berlin:Springer,2015:379-386.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_5" title=" KARTHIKEYAN S M.EZHILARASI M.Automatic stroke lesion segmentation from diffusion weighted MRI images[J].International Journal of Engineering Research &amp;amp; Technology,2016,7(2):111-115." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic stroke lesion segmentation from diffusion weighted MRI images">
                                        <b>[5]</b>
                                         KARTHIKEYAN S M.EZHILARASI M.Automatic stroke lesion segmentation from diffusion weighted MRI images[J].International Journal of Engineering Research &amp;amp; Technology,2016,7(2):111-115.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_6" title=" ELLWAA A,HUSSEIN A,ALNAGGAR E,et al.Brain tumor segmentation using random forest trained on iteratively selected patients[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:129-137." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Brain Tumor Segmantation Using Random Forest Trained on Iteratively Selected Patients">
                                        <b>[6]</b>
                                         ELLWAA A,HUSSEIN A,ALNAGGAR E,et al.Brain tumor segmentation using random forest trained on iteratively selected patients[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:129-137.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_7" title=" SONG B,CHOU C,CHEN X,et al.Anatomy-guided brain tumor segmentation and classification[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:162-170." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Anatomy-guided brain tumor segmentation and classification">
                                        <b>[7]</b>
                                         SONG B,CHOU C,CHEN X,et al.Anatomy-guided brain tumor segmentation and classification[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:162-170.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_8" title=" le FOLGOC L,NORI A V,ANCHA S,et al.Lifted auto-context forests for brain tumor segmentation[C]// Proceedings of the 2016 International Workshop on Brain lesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:171-183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lifted auto-context forests for brain tumor segmentation">
                                        <b>[8]</b>
                                         le FOLGOC L,NORI A V,ANCHA S,et al.Lifted auto-context forests for brain tumor segmentation[C]// Proceedings of the 2016 International Workshop on Brain lesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:171-183.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_9" title=" CHEN L,BENTLEY P,RUECKERT D.Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks[J].NeuroImage:Clinical,2017,15:633-643." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE239B55EC61155EE92445A04A9966DAD&amp;v=Mjk3NzBpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4YjIrd2FnPU5pZk9mY2E2SGRpK3Fvb3dGKzBPRFhrOHVtTWE2RHQ1VFE3aXFHTThjTFNTTWN2ckNPTnZGUw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         CHEN L,BENTLEY P,RUECKERT D.Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks[J].NeuroImage:Clinical,2017,15:633-643.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_10" title=" LUCAS C,KEMMLING A,MAMLOUK A M,et al.Multi-scale neural network for automatic segmentation of ischemic strokes on acute perfusion images[C]// Proceedings of the IEEE 15th International Symposium on Biomedical Imaging.Piscataway:IEEE,2018:1118-1121." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-scale neural network for automatic segmentation of ischemic strokes on acute perfusion images">
                                        <b>[10]</b>
                                         LUCAS C,KEMMLING A,MAMLOUK A M,et al.Multi-scale neural network for automatic segmentation of ischemic strokes on acute perfusion images[C]// Proceedings of the IEEE 15th International Symposium on Biomedical Imaging.Piscataway:IEEE,2018:1118-1121.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_11" title=" KAMNITSAS K,LEDIG C,NEWCOMBE V F J,et al.Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J].Medical Image Analysis,2017,36:61-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES75987FC868EC3E9704EAA1312A88E06D&amp;v=MjcyMzdiUzlGOW5MMmZ4Tll1TjZmMzlNeGhFVDdrb01PWDdoclJCRWNicmhSYnpyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyK3dhZz1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         KAMNITSAS K,LEDIG C,NEWCOMBE V F J,et al.Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J].Medical Image Analysis,2017,36:61-78.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_12" title=" GUERRERO R,QIN C,OKTAY O,et al.White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks[J].NeuroImage:Clinical,2018,17:918-934." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES159641BFB8AF8FD864A7725EEFB4DA52&amp;v=MjY2MTBSUHV4NFY3azU2VDMzbjJXZERDN2JnTkwrZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhiMit3YWc9TmlmT2ZiSzlGOWZJcnYwekZ1Titlbg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         GUERRERO R,QIN C,OKTAY O,et al.White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks[J].NeuroImage:Clinical,2018,17:918-934.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_13" title=" HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:surpassing human-level performance on ImageNet classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Delving deep into rectifiers:Surpassing Human-level performance on ImageNet classification">
                                        <b>[13]</b>
                                         HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:surpassing human-level performance on ImageNet classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     CICEK &#214;,ABDULKADIR A,LIENKAMP S S,et al.3D U-net:learning dense volumetric segmentation from sparse annotation[C]// Proceedings of the 2016 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 9901.Berlin:Springer,2016:424-432.</a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_15" title=" HAECK T,MAES F,SUETENS P.ISLES challenge 2015:automated model-based segmentation of ischemic stroke in MR images[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:246-253." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ISLES challenge 2015:automated model-based segmentation of ischemic stroke in MR images">
                                        <b>[15]</b>
                                         HAECK T,MAES F,SUETENS P.ISLES challenge 2015:automated model-based segmentation of ischemic stroke in MR images[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:246-253.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_16" title=" FENG C,ZHAO D,HUANG M.Segmentation of ischemic stroke lesions in multi-spectral MR images using weighting suppressed FCM and three phase level set[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:233-245." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation of ischemic stroke lesions in multi-spectral MR images using weighting suppressed FCM and three phase level set">
                                        <b>[16]</b>
                                         FENG C,ZHAO D,HUANG M.Segmentation of ischemic stroke lesions in multi-spectral MR images using weighting suppressed FCM and three phase level set[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:233-245.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_17" title=" HAVAEI M,DUTIL F,PAL C,et al.A convolutional neural network approach to brain tumor segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:195-208." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network approach to brain tumor segmentation">
                                        <b>[17]</b>
                                         HAVAEI M,DUTIL F,PAL C,et al.A convolutional neural network approach to brain tumor segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:195-208.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_18" title=" MCKINLEY R,H&#196;NI L,WIEST R,et al.Segmenting the ischemic penumbra:a decision forest approach with automatic threshold finding[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:275-283." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmenting the ischemic penumbra:a decision forest approach with automatic threshold finding">
                                        <b>[18]</b>
                                         MCKINLEY R,H&#196;NI L,WIEST R,et al.Segmenting the ischemic penumbra:a decision forest approach with automatic threshold finding[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:275-283.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_19" title=" MAIER O,WILMS M,HANDELS H.Image features for brain lesion segmentation using random forests[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:119-130." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image features for brain lesion segmentation using random forests">
                                        <b>[19]</b>
                                         MAIER O,WILMS M,HANDELS H.Image features for brain lesion segmentation using random forests[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:119-130.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_20" title=" ROBBEN D,CHRISTIAENS D,RANGARAJAN J,et al.A voxel-wise,cascaded classification approach to ischemic stroke lesion segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:254-265." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A voxel-wise,cascaded classification approach to ischemic stroke lesion segmentation">
                                        <b>[20]</b>
                                         ROBBEN D,CHRISTIAENS D,RANGARAJAN J,et al.A voxel-wise,cascaded classification approach to ischemic stroke lesion segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:254-265.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-08-19 09:03</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(11),3274-3279 DOI:10.11772/j.issn.1001-9081.2019040717            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于</b>3<b>D深度残差网络与级联U-Net的缺血性脑卒中病灶分割算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%B9%B3&amp;code=08047513&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E7%90%9B&amp;code=40894568&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高琛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E8%8E%89&amp;code=14200803&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱莉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E4%BF%8A&amp;code=25460323&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵俊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%99%B6&amp;code=26264859&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张晶</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%94%E7%BB%B4%E9%93%AD&amp;code=25989747&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孔维铭</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%98%8C%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0252160&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南昌大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E8%A7%A3%E6%94%BE%E5%86%9B%E7%AC%AC%E4%B9%9D%E5%9B%9B%E5%8C%BB%E9%99%A2&amp;code=1018584&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民解放军第九四医院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了解决人工勾画缺血性脑卒中病灶费时费力且易引入主观差异的问题,提出了一种基于三维(3D)深度残差网络与级联U-Net的自动分割算法。首先,为了有效利用图像的3D上下文信息并改善类不平衡现象,将脑卒中核磁共振图像(MRI)采样成图像块作为网络输入;然后,利用基于3D深度残差网络与级联U-Net的分割模型对图像块进行特征提取,获得粗分割结果;最后,对粗分割结果进行精分割处理。在ISLES数据集上的实验结果表明,该算法的Dice系数可达到0.81,精确度可达到0.81,灵敏度可达到0.81,平均对称表面距离(ASSD)距离系数为1.32,HD为22.67。所提算法与3D U-Net算法、基于水平集算法、基于模糊C均值(FCM)算法和基于卷积神经网络(CNN)算法相比分割性能更好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%80%A5%E6%80%A7%E7%BC%BA%E8%A1%80%E6%80%A7%E8%84%91%E5%8D%92%E4%B8%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">急性缺血性脑卒中;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E5%8A%A8%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自动分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A3%81%E5%85%B1%E6%8C%AF%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">磁共振图像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王平(1958—)，女，河南安阳人，教授，主要研究方向:图像处理、模式识别;;
                                </span>
                                <span>
                                    高琛(1993—)，女，江西上饶人，硕士研究生，主要研究方向:图像处理、机器学习;;
                                </span>
                                <span>
                                    *朱莉(1982—)，女，江西南昌人，副教授，博士，主要研究方向:图像处理、机器学习,电子邮箱,Lizhu@ncu.edu.cn;
                                </span>
                                <span>
                                    赵俊(1995—)，女，河南周口人，硕士研究生，主要研究方向:图像处理、机器学习;;
                                </span>
                                <span>
                                    张晶(1994—)，女，河北邯郸人，硕士研究生，主要研究方向:图像处理、机器学习;;
                                </span>
                                <span>
                                    孔维铭(1984—)，男，山东曹县人，硕士研究生，主要研究方向:医学影像分析。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61463035);</span>
                                <span>中国博士后基金资助项目(2016M592117);</span>
                                <span>江西省杰出青年基金资助项目(2018ACB21038);</span>
                                <span>江西省科技厅科技支撑计划项目(20151BBG70057);</span>
                                <span>江西省教育厅科技项目(GJJ14137);</span>
                    </p>
            </div>
                    <h1><b>Segmentation algorithm of ischemic stroke lesion based on</b> 3<b>D deep residual network and cascade U-Net</b></h1>
                    <h2>
                    <span>WANG Ping</span>
                    <span>GAO Chen</span>
                    <span>ZHU Li</span>
                    <span>ZHAO Jun</span>
                    <span>ZHANG Jing</span>
                    <span>KONG Weiming</span>
            </h2>
                    <h2>
                    <span>College of Information Engineering, Nanchang University</span>
                    <span>The 94th Hospital of the Chinese People&apos;s Liberation Army</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Artificial identification of ischemic stroke lesion is time-consuming, laborious and easy be added subjective differences. To solve this problem, an automatic segmentation algorithm based on 3 D deep residual network and cascade U-Net was proposed. Firstly, in order to efficiently utilize 3 D contextual information of the image and the solve class imbalance issue, the patches were extracted from the stroke Magnetic Resonance Image(MRI) and put into network. Then, a segmentation model based on 3 D deep residual network and cascade U-Net was used to extract features of the image patches, and the coarse segmentation result was obtained. Finally, the fine segmentation process was used to optimize the coarse segmentation result. The experiment results show that, on the dataset of Ischemic Stroke LEsion Segmentation(ISLES), for the proposed algorithm, the Dice similarity coefficient reached 0.81, the recall reached 0.81 and the precision reached 0.81, the distance coefficient Average Symmetric Surface Distance(ASSD) reached 1.32 and Hausdorff Distance(HD) reached 22.67. Compared with 3 D U-Net algorithm, level set algorithm, Fuzzy C-Means(FCM) algorithm and Convolutional Neural Network(CNN) algorithm, the proposed algorithm has better segmentation performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=acute%20ischemic%20stroke&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">acute ischemic stroke;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=automatic%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">automatic segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-dimensional&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-dimensional;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Magnetic%20Resonance%20Image(MRI)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Magnetic Resonance Image(MRI);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Ping, born in 1958, professor. Her research interests include image processing, pattern recognition. ;
                                </span>
                                <span>
                                    GAO Chen, born in 1993, M. S. candidate. Her research interests include image processing, machine learning. ;
                                </span>
                                <span>
                                    ZHU Li, born in 1982, Ph. D., associate professor. Her research interests include image processing, machine learning. ;
                                </span>
                                <span>
                                    ZHAO Jun, born in 1995, M. S. candidate. Her research interests include image processing, machine learning. ;
                                </span>
                                <span>
                                    ZHANG Jing, born in 1994, M. S. candidate. Her research interests include image processing, machine learning. ;
                                </span>
                                <span>
                                    KONG Weiming, born in 1984, M. S. candidate. His research interests include medical image analysis.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-26</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61463035);</span>
                                <span>the China Postdoctoral Science Foundation(2016M592117);</span>
                                <span>the Outstanding Youth Fund Project in Jiangxi Province(2018ACB21038);</span>
                                <span>the Science and Technology Support Project of Jiangxi Science and Technology Department(20151BBG70057);</span>
                                <span>the Science and Technology Project of Jiangxi Education Department(GJJ14137);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="44">脑卒中是世界上最常见的脑血管疾病,也是最常见的死亡和致残疾病之一。脑卒中可分为缺血性卒中和出血性卒中, 其中缺血性卒中的发病率远高于出血性卒中,占脑卒中总数的87%<citation id="174" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。缺血性脑卒中是由脑供血障碍引起的脑组织缺氧,并因血流在接下来的几小时内中断太严重或中断时间过长导致的脑细胞逐渐坏死,最终形成不可逆的受损梗塞核心。如果血流恢复得足够快,脑组织可能不会永久损坏,这种围绕着缺血性损伤核心的潜在可逆性损伤的组织区域,被称为“缺血半影”<citation id="175" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。根据脑卒中发病后经过的时间,可将病灶阶段细分为急性(0～24 h)、亚急性(24 h～2 week)和慢性(超过2 week)<citation id="176" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。急性缺血性脑卒中的典型症状是局灶性神经功能缺损的突然发作,如失语、偏盲、感觉丧失等。这些症状可能发展成慢性疾病(例如痴呆、偏瘫等),在很大程度上影响了患者的生活并且医疗开销也会急剧增高。急性期的及时诊断和治疗对脑卒中患者的康复和预后至关重要,医生需要在卒中发作后的3 h内快速定位并量化病灶。但人工描绘急性脑卒中病灶费时费力且会引入观察者间的主观差异性。自动分割算法可以准确、客观地评估病灶,且具有可重复、可扩展等优点,现已成为医学图像计算领域的一个主要研究热点。</p>
                </div>
                <div class="p1">
                    <p id="45">以往有很多分割脑卒中病灶的方法,基于纹理的特征提取算法就常用于脑卒中病灶的分割中,比如Neethu等<citation id="177" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>先用Gabor滤波方法对图像进行边缘和轮廓的提取,再利用区域生长进行脑卒中区域的分割。另一种则是由Karthikeyan等<citation id="178" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出的,该算法先用灰度共生矩阵(Gray Level Co-occurrence Matrix, GLCM)从图像中提取特征,然后再用神经网络模型对提取的特征进行分类。但基于纹理的特征提取一般只能用来对图像的局部缺血性脑卒中进行分析;且这些方法用的都是较低级的图像特征(图像灰度信息或边缘信息),对于低信噪比且存在伪影的图像的分割缺乏鲁棒性。近年来也有许多基于随机森林的脑卒中病灶分割方法<citation id="182" type="reference"><link href="144" rel="bibliography" /><link href="146" rel="bibliography" /><link href="148" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>结果较好,但基于随机森林的方法较依赖于人工提取特征,步骤相对复杂。当前基于深度学习的算法已广泛应用到医学图像处理工作中,其具有很强的模型能力,并且能够更好地提取图像特征,尤其在特征不明显的图像中更能体现其优势。在脑卒中分割中一些深度学习的方法获得了良好的分割效果,比如,Chen等<citation id="179" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一种融合了卷积网络、空洞卷积和全连接条件随机场的DeepLab算法,且该方法在ISLES(Ischemic Stroke LEsion Segmentation)大赛中获得了优异的成绩。Lucas等<citation id="180" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出了一种改进的U型全卷积神经网络架构。但这些方法都只考虑了二维切片信息,忽略了医学图像的三维上下文信息。为了能充分利用三维医学影像的深度信息,2017年,Kamnitsas等<citation id="181" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了一种多尺度三维卷积神经网络(Three-dimensional Convolutional Neural Network, 3D CNN)的方法实现了对亚急性缺血性脑卒中病灶的三维分割。</p>
                </div>
                <div class="p1">
                    <p id="46">本文面向急性缺血性脑卒中的辅助性诊断,将深度学习的方法引入急性缺血性脑卒中核磁共振图像(Magnetic Resonance Images, MRI)的分析中,提出了一种基于3D深度残差网络与级联U-Net的分割新算法。新算法将采样的MRI图像块作为网络的输入,可以避免医学图像中常出现的类不平衡现象并可得到更细致的分割。新算法在网络结构中加入了残差模块和级联思想,使其在避免梯度消失问题的同时也可更高精度地分割出病灶。用该算法对ISLES 2015的急性缺血性脑卒中数据进行分割,结果表明本算法可得到较高的分割精度,且具有速度快、无需参考专家先验知识等优势,对今后急性缺血性卒中的计算机辅助诊断研究有很大的参考价值。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 算法流程</h3>
                <div class="p1">
                    <p id="48">本文用基于3D深度残差网络与级联U-Net的分割新算法对急性缺血性脑卒中进行病灶分割,该研究方法的整个算法流程如图1所示, 其中T1c、T2、脑血流量(Cerebral Blood Flow, CBF)、脑血容量(Cerebral Blood Volume, CBV)、扩散加权成像(Diffusion Weighted Imaging, DWI)、血流达峰时间(Time maximum,Tmax)和对比剂峰值时间(Time To Peak, TTP)为七种不同模态的磁共振图像。</p>
                </div>
                <div class="p1">
                    <p id="49">首先,为了有效地利用三维上下文信息并改善类不平衡现象,对训练集和测试集的MRI数据进行图像块采样操作;然后,将训练集图像块输入基于3D深度残差网络与级联U-Net的分割模型中进行特征提取及训练,在固定分割模型参数后对测试集MRI数据进行分割;最后,为了优化粗分割结果降低假阳性,对分割结果进行进一步的精分割处理。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法流程" src="Detail/GetImg?filename=images/JSJY201911028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of the proposed algorithm</p>

                </div>
                <h3 id="51" name="51" class="anchor-tag">2 本文方法</h3>
                <h4 class="anchor-tag" id="52" name="52">2.1 <b>图像预处理</b></h4>
                <h4 class="anchor-tag" id="53" name="53">2.1.1 数据集介绍</h4>
                <div class="p1">
                    <p id="54">本文方法在缺血性脑卒中挑战赛ISLES2015(http://www.isles-challenge.org/ISLES2015/)所提供的数据集上进行了实验。该数据集提供亚急性脑卒中病变分割扫描影像(Sub-Acute Stroke Lesion Segmentation, SISS)和急性脑卒中病变分割扫描影像(Stroke Perfusion Estimation, SPES)。其中SPES数据集包含了从伯尔尼大学医院选取的50例急性缺血性患者的临床图像。医院用一台3T MR扫描仪(Siemens Magnetom Trio)和一台1.5T MR扫描仪(Siemens Magnetom Avanto)来获取DWI和灌注成像(Perfusion Imaging, PWI),最终每位患者都配有T1c、T2、CBF、CBV、DWI、Tmax和TTP七种模态的MRI,各模态间都已配准并进行了颅骨剥离处理,图像分辨率都为2×2×2。该数据集将30例MRI数据作为训练集并公开了由权威专家手动标注的病灶标签如图2所示,测试集则包含20位患者的七种模态MRI但没有公开病灶标签。</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练集患者的七种模态MRI及病灶标签(横断面)" src="Detail/GetImg?filename=images/JSJY201911028_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练集患者的七种模态MRI及病灶标签(横断面)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Seven modality MRI and lwsion labels for patients in training dataset (transverse plane)</p>

                </div>
                <h4 class="anchor-tag" id="56" name="56">2.1.2 图像块提取</h4>
                <div class="p1">
                    <p id="57">本文的图像块提取工作包括以下3个步骤:</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58">1)强度归一化。</h4>
                <div class="p1">
                    <p id="59">强度归一化就是在保留具有诊断价值的灰度差异的同时,为了减小并消除图像中灰度不一致的现象而进行的图像转换方法,以便计算机自动分析处理。通过减去图像灰度值的均值再除以方差,使其灰度分布达到均值为0、标准差为1的正态分布。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60">2)图像块采样。</h4>
                <div class="p1">
                    <p id="61">在医学图像中一般健康组织占比远超过病灶,会出现医学图像分割中常见的类不平衡问题,为了解决该问题,本文用以病灶为中心的采样方式<citation id="183" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将图像采样成小块作为网络的输入。这里用<i>N</i><sub>Patch</sub>表示提取图像块的个数,在本实验中<i>N</i><sub>Patch</sub>=10 000,<i>N</i><sub>Lesion</sub>表示病灶体素数,<i>T</i>表示采样图像块的中心间隔。训练集图像块提取步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="62">①找出训练集标签中的病灶区体素,计算体素个数<i>N</i><sub>Lesion</sub>并记录病灶体素坐标位置。</p>
                </div>
                <div class="p1">
                    <p id="63">②为了使病灶大小不同的病例可以输入相同数量的采样图像块,本研究将采样方式分为以下两种情况。若<i>N</i><sub>Patch</sub>&lt;<i>N</i><sub>Lesion</sub>,采样间隔<i>T</i>=<i>N</i><sub>Lesion</sub>/<i>N</i><sub>Patch</sub>即每间隔<i>T</i>个病灶体素就提取其作为采样图像块的中心体素;若<i>N</i><sub>Patch</sub>&gt;<i>N</i><sub>Lesion</sub>,采样间隔<i>T</i>=<i>N</i><sub>Lesion</sub>/(<i>N</i><sub>Patch</sub>-<i>N</i><sub>Lesion</sub>),即先将所有病灶体素作为图像块的中心体素,然后再次提取间隔为<i>T</i>的病灶体素作为剩余图像块的中心体素。</p>
                </div>
                <div class="p1">
                    <p id="64">③在确定图像块中心体素之后,对这些中心体素进行随机偏移,随机移位Δ<i>x</i>、Δ<i>y</i>的范围为提取图像块大小的一半。最后,以24×24×8的大小提取图像块。</p>
                </div>
                <div class="p1">
                    <p id="65">以上述方法提取训练集的图像块,可以保证输入的图像块都包含病灶,让模型可以学习病灶及病灶边沿区域的特征,同时避免了训练时出现负样本扰乱分割模型的情况。测试集图像块则以均匀采样的方式提取。确定测试集图像块中心后,以24×24×8的大小提取图像块。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">3)数据增广。</h4>
                <div class="p1">
                    <p id="67">数据增广目的是扩增更多的训练数据来提高网络性能并避免出现过拟合现象。通过对提取的图像块进行90°、180°、270°的旋转来使训练数据扩大。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">2.2 <b>分割网络架构</b></h4>
                <h4 class="anchor-tag" id="69" name="69">2.2.1 基于残差学习的特征提取</h4>
                <div class="p1">
                    <p id="70">残差学习的基本思想是利用多层卷积拟合一种残差映射<i>F</i>(<i>x</i>),相对于直接学习目标近似恒等映射更易优化。假设输入变量为<i>x</i>,残差学习就是通过“捷径连接”(shortcut connection)直接把输入<i>x</i>传到输出作为初始结果,输出结果为:</p>
                </div>
                <div class="p1">
                    <p id="71"><i>H</i>(<i>x</i>)=<i>F</i>(<i>x</i>)+<i>x</i>      (1)</p>
                </div>
                <div class="p1">
                    <p id="72">当<i>F</i>(<i>x</i>)=0时,<i>H</i>(<i>x</i>)=<i>x</i>,也就是所谓的恒等映射。这样残差的学习目标不再是一个完整的输出,而是目标值<i>H</i>(<i>x</i>)和<i>x</i>的差值,即:</p>
                </div>
                <div class="p1">
                    <p id="73"><i>F</i>(<i>x</i>)=<i>H</i>(<i>x</i>)-<i>x</i>      (2)</p>
                </div>
                <div class="p1">
                    <p id="74">残差学习中的“捷径连接”可以跳过一个层或多个层,执行恒等映射,该方式可以避免因网络加深导致的梯度消失等问题,使网络更好地优化。因此,本文在卷积层中引入残差学习,残差块结构如图3所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 残差块结构示意图" src="Detail/GetImg?filename=images/JSJY201911028_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 残差块结构示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Structural diagram of residual block</p>

                </div>
                <div class="p1">
                    <p id="76">残差块由两个核大小为3×3×3的卷积层和一个随机失活层(dropout)构成。因为PReLU(Parametric Rectified Linear Unit)激活函数可以使网络更快地过滤出不相关的信息,更适合其训练<citation id="184" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>,所以在残差模块中,用PReLU作为卷积层的激活函数,PReLU激活函数如式(3)所示:</p>
                </div>
                <div class="p1">
                    <p id="77"><i>g</i>(<i>x</i>)=max(0,<i>x</i>)+<i>a</i><sub><i>i</i></sub> min(0,<i>x</i>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="78">其中,<i>a</i><sub><i>i</i></sub>表示控制激活函数负部分倾斜的系数。为了加快网络收敛,卷积层中还加入了批量归一化(Batch Normalization, BN)处理。在残差模块中引入随机失活层(失活概率设置为0.2),可以使部分神经元在训练中失活,避免参数过拟合,从而提高网络的泛化性能。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">2.2.2 缺血性脑卒中分割网络模型</h4>
                <div class="p1">
                    <p id="80">针对缺血性脑卒中病灶特征的复杂性(如病灶边缘模糊、形态各异),设计了基于3D深度残差网络与级联U-Net分割模型,该模型引入了残差模块和级联思想,使网络在改善优化困难问题的同时进一步提高了分割精度。</p>
                </div>
                <div class="p1">
                    <p id="81">本文算法的分割架构如图4所示,该架构由一个非对称型残差U-Net和一个三层下采样U-Net级联构成。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于3D深度残差网络与级联U-Net的分割架构" src="Detail/GetImg?filename=images/JSJY201911028_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于3D深度残差网络与级联U-Net的分割架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Segmentation architecture based on 3D deep residual network and cascade U-Net</p>

                </div>
                <div class="p1">
                    <p id="83">在一级非对称型残差U-Net中,用残差模块进行特征提取,在每个残差模块后用一个步长为2、核大小为2×2×2的池化层进行下采样操作,本架构还在一级残差U-Net的编码部分设置了Bottleneck层,即在每一个池化层后加入1×1×1的卷积层对输出特征层通道数进行加倍,帮助完成下一层的残差学习。一级非对称型残差U-Net的解码部分则由卷积层和上采样层组成,其中上采样层是核大小为3×3×3、步长为2的反卷积层,通过上采样操作特征图的大小可恢复为原尺寸,但上采样不可恢复池化操作时丢失的空间信息,因此用一个跳跃连接将上采样的特征图与编码器中相同大小的特征图进行融合,待充分融合底层的空间信息和高层的特征信息后,输出特征图。二级U-Net则是对一级非对称型残差U-Net输出的特征图进行二次特征提取,即将一级非对称残差U-Net解码器中经过两次上采样后的特征图与编码器中第一层输出的特征图级联到一起继续训练。在二级U-Net中用3×3×3大小的卷积层和步长为2、核大小为2×2×2的池化层进行编码,然后用卷积和上采样进行解码,为了使网络参数减少,二级U-Net中同样用像素级相加的融合操作进行跳跃连接。最后,用一个1×1×1的卷积层将多通道数映射为2,再将通道数为2的特征图送入Softmax分类器中,得到脑卒中病灶分割概率图(每一个值即代表该像素点属于病灶的概率值)即分割输出结果。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">2.3 <b>精分割</b></h4>
                <div class="p1">
                    <p id="85">在得到各图像块粗分割结果后,将各图像块根据其中心坐标还原回原先位置。但由于图像块分割结果是对重合处取概率平均,且以类概率作为病灶区体素值的结果会导致假阳性提高,从而会产生误差。为了优化分割结果,除去伪缺血点进而降低假阳性,本方法用如下两个步骤提高分割精度:</p>
                </div>
                <div class="p1">
                    <p id="86">1)设定类概率阈值<i>h</i>,将高于阈值处的体素值置为1,低于阈值处的体素置为0,即粗分割结果中会出现一些类概率很低的体素值,而该区域并不属于病灶区,需设定阈值将其设为健康区域。</p>
                </div>
                <div class="p1">
                    <p id="87">2)分割结果中会出现一些小的伪病灶点,所以在步骤1)后可通过计算三维连通域体积来进一步过滤掉伪缺血点。<i>pre</i>(<i>x</i>,<i>y</i>,<i>z</i>)表示经过步骤1)后的分割结果中的体素(健康区:<i>pre</i>(<i>x</i>,<i>y</i>,<i>z</i>)=0,脑卒中病灶区:<i>pre</i>(<i>x</i>,<i>y</i>,<i>z</i>)=1)。<i>v</i>(<i>n</i>)表示<i>pre</i>中第<i>n</i>个连通域的体积,<i>V</i><sub>max</sub>为<i>pre</i>中体积最大的连通域的体积。若<i>v</i>(<i>n</i>)/<i>V</i><sub>max</sub>&lt;<i>θ</i><sub>1</sub>,将第<i>n</i>个三维连通域移除,即将第<i>n</i>个三维连通域内的<i>pre</i>(<i>x</i>,<i>y</i>,<i>z</i>)置为0。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">3 实验结果及分析</h3>
                <h4 class="anchor-tag" id="89" name="89">3.1 <b>客观评估指标</b></h4>
                <div class="p1">
                    <p id="90">为了评估提出的分割方法性能,本文用Dice系数、精确度(precision)、灵敏度(recall)、平均对称表面距离(Average Symmetric Surface Distance,ASSD)和霍夫曼距离(Hausdorff Distance, HD)来进行分割精度评价。其中,定义正确分割为病灶的区域为真阳性(True Positive, TP);定义被错误分割为病灶区实则为非病灶的区域为假阳性(False Positive,FP);定义被错误分割为非病灶区实则为病灶的区域为假阴性(False Negative, FN)。Dice是分割结果与病灶标签间的一个重叠度度量。Dice、精确度和灵敏度的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>i</mi><mi>c</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">虽然Dice、精确度及灵敏度都可用基于体积的重叠度来度量分割结果的准确度,但两个重叠度大的区域可能在边界上存在差异,这里用基于距离的度量尺度(平均对称表面距离和霍夫曼距离)来衡量此差异,且平均对称表面距离和霍夫曼距离相同,指标越小,代表分割精度越高。设<i>A</i>为病灶标签表面的点,<i>B</i>为分割结果表面的点。平均对称表面距离定义如下所示:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>S</mi><mi>D</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow><mspace width="0.25em" /></munderover><mrow><munderover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow><mspace width="0.25em" /></munderover></mrow></mstyle><mspace width="0.25em" /><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><mrow><mrow><mo>|</mo><mi>A</mi><mo>|</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97"><i>ASSD</i>(<i>A</i>,<i>B</i>)=[<i>ASD</i>(<i>A</i>,<i>B</i>)+<i>ASD</i>(<i>B</i>,<i>A</i>)]/2      (8)</p>
                </div>
                <div class="p1">
                    <p id="98">其中,ASD(Average Surface Distance)为平均表面距离;<i>d</i>(<i>a</i>,<i>b</i>)为<i>A</i>,<i>B</i>点的欧氏距离且<i>ASD</i>(<i>A</i>,<i>B</i>)≠<i>ASD</i>(<i>B</i>,<i>A</i>)。</p>
                </div>
                <div class="p1">
                    <p id="99">霍夫曼距离表示病灶标签和分割结果表面点间的最大距离,可表示分割结果中的离群值。霍夫曼距离:</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Η</mi><mi>D</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><mspace width="0.25em" /><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>,</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mspace width="0.25em" /><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">3.2 <b>实验结果与分析</b></h4>
                <div class="p1">
                    <p id="102">本文使用第2章介绍的ISLES2015 SPES数据集进行实验,在ubuntu16.04上使用以tensorflow为后端的keras开源库搭建模型。本文采用自适应优化器Adadelta对损失函数进行优化。训练时,残差模块中的dropout层的随机失活率设为0.2,训练批大小取16,epoch设置为12。</p>
                </div>
                <div class="p1">
                    <p id="103">对ISLES2015 SPES数据集进行分割的实验结果表明,本文算法可高精度地分割出脑卒中病灶。经多次实验,在精分割步骤中设定类概率阈值<i>h</i>=0.4,连通域体积比值<i>θ</i><sub>1</sub>=0.2可获得最优分割结果。为了进一步论证本文算法的优越性,本文还选用了基于3D U-Net的算法<citation id="185" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>作为对比实验,3D U-Net在精分割步骤中设定类概率阈值<i>h</i>=0.4,连通域体积比值<i>θ</i><sub>1</sub>=0.1可获得最优分割结果。</p>
                </div>
                <div class="p1">
                    <p id="104">而为了进一步分析本文提出的算法,还分别选用了基于水平集算法<citation id="186" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、基于模糊C均值(Fuzzy C-Means,FCM)聚类算法<citation id="187" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>和基于多尺度CNN算法<citation id="188" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>与本文算法比较,分割指标比较如表1、2所示。</p>
                </div>
                <div class="area_img" id="105">
                                            <p class="img_tit">
                                                <b>表</b>1 SPES<b>测试集分割评估指标比较</b>
                                                    <br />
                                                Tab. 1 Comparison of segmentation evaluation indicators for SPES test set
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201911028_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 SPES测试集分割评估指标比较" src="Detail/GetImg?filename=images/JSJY201911028_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="106">
                                            <p class="img_tit">
                                                <b>表</b>2 SPES<b>训练集分割评估指标比较</b>
                                                    <br />
                                                Tab. 2 Comparison of segmentation evaluation indicators for SPES training set
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201911028_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 SPES训练集分割评估指标比较" src="Detail/GetImg?filename=images/JSJY201911028_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="107">实验结果表明:1)本文算法得到的Dice、精确度和灵敏度均高于其他四种算法,具有明显的算法优势;2)本文算法得到的分割距离系数ASSD和HD在四种算法中最优,说明本文算法的分割结果误差最小。</p>
                </div>
                <div class="p1">
                    <p id="108">由表1可以看出基于水平集的算法分割效果最差,虽然基于水平集的分割方法具有拓扑适应性强的优点,常用于分割拓扑结构复杂的组织器官及病灶,但由于缺血性脑卒中病灶边界模糊,基于水平集的算法<citation id="189" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>无法准确定位病灶边缘,分割误差较大。基于FCM的算法<citation id="190" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>分割性能虽然有所提高,但该算法是先用FCM的算法进行粗分割,再结合基于水平集的算法进行细化分割,步骤相对复杂、分割效率低。基于多尺度CNN的深度学习算法<citation id="191" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>也可获得较高的分割精度,但该算法用二维的切片图像作为网络的输入,不能很好地利用三维图像的上下文信息,且基于CNN的分割方法是用逐像素的分类完成分割,这样会增加网络计算量,影响分割效率。本文提出的基于3D深度残差网络与级联U-Net是一个端对端的训练,在提升分割精度的同时也可保证分割效率,且与3D U-Net的分割结果相比,本文算法的分割精度更高,误差更小,分割性能更具优越性。在对ISLES2015数据的分割结果中,一些基于随机森林的方法<citation id="192" type="reference"><link href="168" rel="bibliography" /><link href="170" rel="bibliography" /><link href="172" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>也有较好的分割性能,但随机森林的方法需要人工确定并提取特征,操作复杂不满足全自动分割方式,而本文方法可以高精度地自动分割出病灶,无需人工干预。</p>
                </div>
                <div class="p1">
                    <p id="109">测试集和训练集的病灶分割结果图如图5、6所示(图中标注Case17_slice48表示第17个病例中第48层的横断面切片)。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 测试集分割结果对比" src="Detail/GetImg?filename=images/JSJY201911028_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 测试集分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Comparison of the segmentation results of test set</p>

                </div>
                <div class="p1">
                    <p id="111">图6将本文方法在训练集上的分割结果与专家的标注结果进行比较,可以看出本文方法的分割结果与病灶标签基本重合,可准确定位出病灶位置并高精度地分割出病灶轮廓。但对于小缺血点的分割(测试患者Case27_slice43所示)仍存在不足,需要在后续研究中用改进预处理等方法提高小病灶的分割精准度。综上所述,本文算法能快速地自动检测并高精度分割出病灶, 可进一步用于基于MRI的缺血性脑卒中的诊断,帮助医生更为快速准确地判定患病情况。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911028_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 训练集分割结果对比" src="Detail/GetImg?filename=images/JSJY201911028_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 训练集分割结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911028_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Comparison of the segmentation results of training set</p>

                </div>
                <h3 id="113" name="113" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="114">本文提出了一种辅助医生诊断急性缺血性脑卒中的新算法。首先对MRI进行图像块提取处理,然后用基于3D深度残差网络与级联U-Net的分割网络对采样图像块进行特征提取并得到粗分割结果,最后用基于三维连通域等算法对其进行优化精分割,从而实现对急性缺血性脑卒中MRI的自动分割。本文方法在公开的急性缺血性脑卒中数据集上进行分割,实验结果表明本文算法获得的Dice、精确度、灵敏度和分割距离系数都明显优于对比算法。综上所述,本文提出的基于3D深度残差网络与级联U-Net的新算法具有分割精度高、速度快且不需要人工干预等优点,为急性缺血性脑卒中患者设计了一个特定的脑卒中自动分割模型,可进一步帮助医生客观地诊断、评估病灶并规划治疗。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="134">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Heart disease and stroke statistics-2016 update:a report from the american heart association">

                                <b>[1]</b> MOZAFFARIAN D,BENJAMIN E J,GO A S,et al.Heart disease and stroke statistics — 2016 update:a report from the American heart association[J].Circulation,2016,133(4):338-360.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWK&amp;filename=SJWK12112900265429&amp;v=MTY5OTZheEk9TmlmY1piSzZIOURPcG85Rlp1MEtDSDR3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZzVg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> ASTRUP J,SYMON L,BRANSTON N M,et al.Cortical evoked potential and extracellular K+ and H+ at critical levels of brain ischemia[J].Stroke,1977,8(1):51-57.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ISLES 2015-A public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI">

                                <b>[3]</b> MAIER O,MENZE B H,VON DER GABLENTZ J,et al.ISLES 2015 — a public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI[J].Medical Image Analysis,2017,35:250-269.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stroke detection in brain using CT images">

                                <b>[4]</b> NEETHU S,VENKATARAMAN D.Stroke detection in brain using CT images[C]// Proceedings of the 2014 Artificial Intelligence and Evolutionary Algorithms in Engineering Systems,AISC 324.Berlin:Springer,2015:379-386.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic stroke lesion segmentation from diffusion weighted MRI images">

                                <b>[5]</b> KARTHIKEYAN S M.EZHILARASI M.Automatic stroke lesion segmentation from diffusion weighted MRI images[J].International Journal of Engineering Research &amp; Technology,2016,7(2):111-115.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Brain Tumor Segmantation Using Random Forest Trained on Iteratively Selected Patients">

                                <b>[6]</b> ELLWAA A,HUSSEIN A,ALNAGGAR E,et al.Brain tumor segmentation using random forest trained on iteratively selected patients[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:129-137.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Anatomy-guided brain tumor segmentation and classification">

                                <b>[7]</b> SONG B,CHOU C,CHEN X,et al.Anatomy-guided brain tumor segmentation and classification[C]// Proceedings of the 2016 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:162-170.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lifted auto-context forests for brain tumor segmentation">

                                <b>[8]</b> le FOLGOC L,NORI A V,ANCHA S,et al.Lifted auto-context forests for brain tumor segmentation[C]// Proceedings of the 2016 International Workshop on Brain lesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 10154.Berlin:Springer,2016:171-183.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE239B55EC61155EE92445A04A9966DAD&amp;v=MDg2MjZPR1FsZkJyTFUwNXRwaHhiMit3YWc9TmlmT2ZjYTZIZGkrcW9vd0YrME9EWGs4dW1NYTZEdDVUUTdpcUdNOGNMU1NNY3ZyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> CHEN L,BENTLEY P,RUECKERT D.Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks[J].NeuroImage:Clinical,2017,15:633-643.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-scale neural network for automatic segmentation of ischemic strokes on acute perfusion images">

                                <b>[10]</b> LUCAS C,KEMMLING A,MAMLOUK A M,et al.Multi-scale neural network for automatic segmentation of ischemic strokes on acute perfusion images[C]// Proceedings of the IEEE 15th International Symposium on Biomedical Imaging.Piscataway:IEEE,2018:1118-1121.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES75987FC868EC3E9704EAA1312A88E06D&amp;v=MTYzOTN1TjZmMzlNeGhFVDdrb01PWDdoclJCRWNicmhSYnpyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyK3dhZz1OaWZPZmJTOUY5bkwyZnhOWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> KAMNITSAS K,LEDIG C,NEWCOMBE V F J,et al.Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J].Medical Image Analysis,2017,36:61-78.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES159641BFB8AF8FD864A7725EEFB4DA52&amp;v=MjI0NDIyK3dhZz1OaWZPZmJLOUY5ZklydjB6RnVOK2VuUlB1eDRWN2s1NlQzM24yV2REQzdiZ05MK2RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Yg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> GUERRERO R,QIN C,OKTAY O,et al.White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks[J].NeuroImage:Clinical,2018,17:918-934.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Delving deep into rectifiers:Surpassing Human-level performance on ImageNet classification">

                                <b>[13]</b> HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:surpassing human-level performance on ImageNet classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 CICEK Ö,ABDULKADIR A,LIENKAMP S S,et al.3D U-net:learning dense volumetric segmentation from sparse annotation[C]// Proceedings of the 2016 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 9901.Berlin:Springer,2016:424-432.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ISLES challenge 2015:automated model-based segmentation of ischemic stroke in MR images">

                                <b>[15]</b> HAECK T,MAES F,SUETENS P.ISLES challenge 2015:automated model-based segmentation of ischemic stroke in MR images[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:246-253.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation of ischemic stroke lesions in multi-spectral MR images using weighting suppressed FCM and three phase level set">

                                <b>[16]</b> FENG C,ZHAO D,HUANG M.Segmentation of ischemic stroke lesions in multi-spectral MR images using weighting suppressed FCM and three phase level set[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:233-245.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network approach to brain tumor segmentation">

                                <b>[17]</b> HAVAEI M,DUTIL F,PAL C,et al.A convolutional neural network approach to brain tumor segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:195-208.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmenting the ischemic penumbra:a decision forest approach with automatic threshold finding">

                                <b>[18]</b> MCKINLEY R,HÄNI L,WIEST R,et al.Segmenting the ischemic penumbra:a decision forest approach with automatic threshold finding[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:275-283.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image features for brain lesion segmentation using random forests">

                                <b>[19]</b> MAIER O,WILMS M,HANDELS H.Image features for brain lesion segmentation using random forests[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:119-130.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A voxel-wise,cascaded classification approach to ischemic stroke lesion segmentation">

                                <b>[20]</b> ROBBEN D,CHRISTIAENS D,RANGARAJAN J,et al.A voxel-wise,cascaded classification approach to ischemic stroke lesion segmentation[C]// Proceedings of the 2015 International Workshop on Brainlesion:Glioma,Multiple Sclerosis,Stroke and Traumatic Brain Injuries,LNCS 9556.Berlin:Springer,2015:254-265.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201911028" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911028&amp;v=MDg4NzdyN0lMejdCZDdHNEg5ak5ybzlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
