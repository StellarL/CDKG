<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136463640596250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910044%26RESULT%3d1%26SIGN%3d3%252fi4mYfI4G8fQPHY%252bhSp06U8YrA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910044&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910044&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910044&amp;v=MjQ5NTJGeWprVjd2QUx6N0JkN0c0SDlqTnI0OUJZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="1 结合定向配准和幂函数的图像拼接 ">1 结合定向配准和幂函数的图像拼接</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="1.1 &lt;b&gt;特征点的定向配准&lt;/b&gt;">1.1 <b>特征点的定向配准</b></a></li>
                                                <li><a href="#57" data-title="1.2 &lt;b&gt;图像的变形&lt;/b&gt;">1.2 <b>图像的变形</b></a></li>
                                                <li><a href="#72" data-title="1.3 &lt;b&gt;图像的融合&lt;/b&gt;">1.3 <b>图像的融合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="2 实验结果分析 ">2 实验结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="2.1 &lt;b&gt;特征点的配准分析&lt;/b&gt;">2.1 <b>特征点的配准分析</b></a></li>
                                                <li><a href="#87" data-title="2.2 &lt;b&gt;拼接图像效果分析&lt;/b&gt;">2.2 <b>拼接图像效果分析</b></a></li>
                                                <li><a href="#95" data-title="2.3 &lt;b&gt;拼接图像质量分析&lt;/b&gt;">2.3 <b>拼接图像质量分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="3 结语 ">3 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="图1 结合定向配准和幂函数权重的图像拼接方法流程">图1 结合定向配准和幂函数权重的图像拼接方法流程</a></li>
                                                <li><a href="#78" data-title="图2 线性与非线性权重方法的函数对比">图2 线性与非线性权重方法的函数对比</a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;特征点配准的时间消耗、配准的特征点数量和 相对于传统&lt;/b&gt;&lt;i&gt;SIFT&lt;/i&gt;&lt;b&gt;算法的效率提升的百分比&lt;/b&gt;"><b>表</b>1 <b>特征点配准的时间消耗、配准的特征点数量和 相对于传统</b><i>SIFT</i><b>算法的效率提升的百分比</b></a></li>
                                                <li><a href="#93" data-title="图3 各个算法的拼接图像">图3 各个算法的拼接图像</a></li>
                                                <li><a href="#94" data-title="图4 不同权重方法的融合结果">图4 不同权重方法的融合结果</a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同方法融合结果对比&lt;/b&gt;"><b>表</b>2 <b>不同方法融合结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="123">


                                    <a id="bibliography_1" title="LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MTk1NTE5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXJsVTc3TUpGWT1OajdCYXJPNEh0SE9wNHhGYmVzT1kzazV6QmRoNGo5&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_2" title="BAY H,TUYTELAARS T,GOOL L V.SURF:speeded up robust features[C]//Proceedings of the 2006 European Conference on Computer Vision,LNCS 3951.Berlin:Springer,2006:404-417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Surf: Speeded up robust features">
                                        <b>[2]</b>
                                        BAY H,TUYTELAARS T,GOOL L V.SURF:speeded up robust features[C]//Proceedings of the 2006 European Conference on Computer Vision,LNCS 3951.Berlin:Springer,2006:404-417.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_3" title="RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:an efficient alternative to SIFT or SURF[C]//Proceedings of the 2011 IEEEInternational Conference on Computer Vision.Piscataway:IEEE,2011:2564-2571." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to sift or surf">
                                        <b>[3]</b>
                                        RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:an efficient alternative to SIFT or SURF[C]//Proceedings of the 2011 IEEEInternational Conference on Computer Vision.Piscataway:IEEE,2011:2564-2571.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_4" title="BROWN M,LOWE D G.Automatic panoramic image stitching using invariant features[J].International Journal of Computer Vision,2007,74(1):59-73." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002831131&amp;v=MjA1MzVsVTc3TUpGWT1OajdCYXJPNEh0SE9wNHhFWmVnT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rmly&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        BROWN M,LOWE D G.Automatic panoramic image stitching using invariant features[J].International Journal of Computer Vision,2007,74(1):59-73.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_5" title="ZARAGOZA J,CHIN T,BROWN M S,et al.As-projective-aspossible image stitching with moving DLT[C]//Proceedings of the2013 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2339-2346." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=As-projective-as-possible image stitching with moving DLT">
                                        <b>[5]</b>
                                        ZARAGOZA J,CHIN T,BROWN M S,et al.As-projective-aspossible image stitching with moving DLT[C]//Proceedings of the2013 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2339-2346.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_6" title="LIN C,PANKANTI S U,RAMAMURTHY K N,et al.Adaptive as-natural-as-possible image stitching[C]//Proceedings of the2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1155-1163." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive As-Natural-As-Possible Image Stitching">
                                        <b>[6]</b>
                                        LIN C,PANKANTI S U,RAMAMURTHY K N,et al.Adaptive as-natural-as-possible image stitching[C]//Proceedings of the2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1155-1163.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_7" title="BOOKSTEIN F L.Principal warps:thin-plate splines and the decomposition of deformations[J].IEEE Transactions on Pattern A-nalysis and Machine Intelligence,1989,11(6):567-585." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Principal warps: thin-plate splines and the decomposition of deformations">
                                        <b>[7]</b>
                                        BOOKSTEIN F L.Principal warps:thin-plate splines and the decomposition of deformations[J].IEEE Transactions on Pattern A-nalysis and Machine Intelligence,1989,11(6):567-585.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_8" title="SHENG H,LOU C,XU W,et al.A seamless approach to stitching lunar DOMs with TPS[J].Applied Mathematics&amp;amp;Information Sciences,2013,7(2L):555-562." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A seamless approach to stitching lunar DOMs with TPS">
                                        <b>[8]</b>
                                        SHENG H,LOU C,XU W,et al.A seamless approach to stitching lunar DOMs with TPS[J].Applied Mathematics&amp;amp;Information Sciences,2013,7(2L):555-562.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_9" title="CHEN C,HUNG Y,CHENG J.RANSAC-based DARCES:a new approach to fast automatic registration of partially overlapping range images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1999,21(11):1229-1234." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RANSAC-Based DARCES: A New Approach to Fast Automatic Registration of Partially Overlapping Range Images">
                                        <b>[9]</b>
                                        CHEN C,HUNG Y,CHENG J.RANSAC-based DARCES:a new approach to fast automatic registration of partially overlapping range images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1999,21(11):1229-1234.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_10" title="HOSSEIN-NEJAD Z,NASRI M.An adaptive image registration method based on SIFT features and RANSAC transform[J].Computers&amp;amp;Electrical Engineering,2017,62(8):524-537." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES2701DB05B0EE4B86E710FADDCBE2C85C&amp;v=MTYwNTQvc0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhMbTd4S0E9TmlmT2ZiRy9IdEM0M1k5QUZ1dDZlWGhMeHhCbTdUNTlQZzZXMkdGSERMRG5UYg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        HOSSEIN-NEJAD Z,NASRI M.An adaptive image registration method based on SIFT features and RANSAC transform[J].Computers&amp;amp;Electrical Engineering,2017,62(8):524-537.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_11" title="MEYER C R,BOES J L,KIM B,et al.Demonstration of accuracy and clinical versatility of mutual information for automatic multimodality image fusion using affine and thin-plate spline warped geometric deformations[J].Medical Image Analysis,1997,1(3):195-206." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300711881&amp;v=MjgxODRRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSUY4UWJobz1OaWZPZmJLN0h0RE5ySTlGWStvT0JIUTRvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        MEYER C R,BOES J L,KIM B,et al.Demonstration of accuracy and clinical versatility of mutual information for automatic multimodality image fusion using affine and thin-plate spline warped geometric deformations[J].Medical Image Analysis,1997,1(3):195-206.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_12" title="GUO H,HOU Y,ZHAO Y.An image matching algorithm using Thin Plate Splines(TPS)transformation model[J].International Journal of Simulation Systems,Science and Technology,2016,17(8):No.13." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An image matching algorithm using Thin Plate Splines(TPS)transformation model">
                                        <b>[12]</b>
                                        GUO H,HOU Y,ZHAO Y.An image matching algorithm using Thin Plate Splines(TPS)transformation model[J].International Journal of Simulation Systems,Science and Technology,2016,17(8):No.13.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_13" title="LI J,WANG Z,LAI S,et al.Parallax-tolerant image stitching based on robust elastic warping[J].IEEE Transactions on Multimedia,2018,20(7):1672-1687." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallax-tolerant image stitching based on robust elastic warping">
                                        <b>[13]</b>
                                        LI J,WANG Z,LAI S,et al.Parallax-tolerant image stitching based on robust elastic warping[J].IEEE Transactions on Multimedia,2018,20(7):1672-1687.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_14" title="谷雨,周阳,任刚,等.结合最佳缝合线和多分辨率融合的图像拼接[J].中国图象图形学报,2017(6):842-851.(GU Y,ZHOU Y,REN G,et al.Image stitching by combining optimal seam and multi-resolution fusion[J].Journal of Image and Graphics,2017,22(6):842-851.)." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201706014&amp;v=Mjk4MjhIOWJNcVk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5amtWN3ZBUHlyZmJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        谷雨,周阳,任刚,等.结合最佳缝合线和多分辨率融合的图像拼接[J].中国图象图形学报,2017(6):842-851.(GU Y,ZHOU Y,REN G,et al.Image stitching by combining optimal seam and multi-resolution fusion[J].Journal of Image and Graphics,2017,22(6):842-851.).
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_15" title="瞿中,乔高元,林嗣鹏.一种消除图像拼接缝和鬼影的快速拼接算法[J].计算机科学,2015,42(3):280-283.(QU Z,QIAO G Y,LIN S P.Fast image stitching algorithm eliminates seam line and ghosting[J].Computer Science,2015,42(3):280-283.)." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201503058&amp;v=MjE1MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5amtWN3ZBTHo3QmI3RzRIOVRNckk5QWJJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        瞿中,乔高元,林嗣鹏.一种消除图像拼接缝和鬼影的快速拼接算法[J].计算机科学,2015,42(3):280-283.(QU Z,QIAO G Y,LIN S P.Fast image stitching algorithm eliminates seam line and ghosting[J].Computer Science,2015,42(3):280-283.).
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_16" title="HORE A,ZIOU D.Image quality metrics:PSNR vs.SSIM[C]//Proceedings of the 20th International Conference on Pattern Recognition.Piscataway:IEEE,2010:2366-2369." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Quality Metrics:PSNR vs.SSIM">
                                        <b>[16]</b>
                                        HORE A,ZIOU D.Image quality metrics:PSNR vs.SSIM[C]//Proceedings of the 20th International Conference on Pattern Recognition.Piscataway:IEEE,2010:2366-2369.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-25 14:24</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),3060-3064 DOI:10.11772/j.issn.1001-9081.2019020239            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合变形函数和幂函数权重的图像拼接</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%8A%A0%E4%BA%AE&amp;code=41805191&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李加亮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E5%93%81%E7%BE%A4&amp;code=06885716&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋品群</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E8%A5%BF%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0019441&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广西师范大学电子工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对图像拼接算法存在效率低下、特征点错误匹配、重影和拼接缝等问题,提出一种基于尺度不变特征变换、薄板样条函数和幂函数的图像拼接方法。该方法通过对输入图像进行采样匹配,计算输入图像间的点映射关系和重合区域,使用点映射关系对重合区域内的特征点进行定向配准,利用特征点集合计算出图像的局部扭曲模型,使用图像插值方法对图像进行变形映射;采用幂函数权重模型对变形图像中的像素进行平滑过渡,完成图像拼接。实验结果表明,在拼接相同图像的情况下,所提方法与传统的尺度不变特征变换算法相比,特征点配准效率提高了约59.78%,而且得到了更多的特征点对;与经典的图像拼接算法相比,该方法解决了图像的重影和拼接缝的问题,同时提高了图像的质量评估指标的得分。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像拼接;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%88%86%E8%BE%A8%E7%8E%87%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多分辨率融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%8D%E5%BD%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重影;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%8F%98%E5%BD%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像变形;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%BA%E5%BA%A6%E4%B8%8D%E5%8F%98%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尺度不变特征变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9D%83%E9%87%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">权重;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李加亮(1995—),男,河南信阳人,硕士研究生,主要研究方向:图像拼接、目标检测;;
                                </span>
                                <span>
                                    *蒋品群(1970—),男,广西全州人,副教授,博士,主要研究方向:模拟CMOS集成电路设计、嵌入式系统应用。电子邮箱pqjiang@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>广西研究生教育创新计划项目(XYCSZ2019075);</span>
                    </p>
            </div>
                    <h1><b>Image stitching by combining deformation function and power function weight</b></h1>
                    <h2>
                    <span>LI Jialiang</span>
                    <span>JIANG Pinqun</span>
            </h2>
                    <h2>
                    <span>College of Electronic Engineering, Guangxi Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>An image stitching method based on Scale-Invariant Feature Transform(SIFT), thin-plate spline function and power function was proposed to solve the problem of low efficiency, mismatching of feature points, ghosting and stitching seam in image stitching algorithm. The point mapping relationship and overlapping area between the images were calculated by sampling and matching the input images. The local distortion model of the image was calculated by the feature point set, and the deformation of the image was completed by image interpolation. The power function weighting model was used to realize smooth transaction of the pixels in the deformed image to complete the image stitching. Experimental results show that the proposed method improves the registration efficiency of the feature points approximately by 59.78% and obtains more pairs of feature points compared to the traditional SIFT algorithm. Moreover, compared with the classical image stitching algorithm, the method solves the problems of image ghosting and stitching seam, and improves the score of image quality evaluation index.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20stitching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image stitching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-resolution%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-resolution fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ghosting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ghosting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20deformation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image deformation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Scale-Invariant%20Feature%20Transform(SIFT)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Scale-Invariant Feature Transform(SIFT);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=weight&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">weight;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Jialiang,born in 1995,M.S.candidate.His research interests include image stitching,target detection.;
                                </span>
                                <span>
                                    JIANG Pinqun,born in 1970,Ph.D.,professor.His research interests include analog CMOS integrated circuit design,embedded system applications.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-02-13</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Innovation Project of Guangxi Graduate Education(XYCSZ2019075);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="36">图像拼接技术将一组存在重合区域的图像融合,得到一幅包含该组图像信息的新图像,可分为特征点的配准、图像的变形和图像的融合等过程。</p>
                </div>
                <div class="p1">
                    <p id="37">Lowe<citation id="155" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>结合高斯滤波器与尺度空间理论,提出了具有较强稳定性的尺度不变特征变换(Scale Invariant Feature Transform, SIFT)算法。Bay等<citation id="156" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>使用盒式滤波器代替高斯滤波提出加速稳健特征(Speeded Up Robust Features, SURF)算法结合积分图简化计算提升了SIFT算法的效率。Rublee等<citation id="157" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>通过对尺度不变性的图像金字塔应用角点检测,构建二进制串特征描述符提出了快速指向和旋转二进制描述符,提出了快速指向和旋转二进制描述符(Oriented fast and Rotated Brief, ORB)算法,提高了特征点的配准速度,但不具有尺度不变性,且稳定性较差。Brown等<citation id="158" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出自动拼接的算法(AutoStitch)利用全局单应性矩阵对齐图像,解决了微小视差图像的拼接问题,但无法处理大视差图像。Zaragoza等<citation id="159" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>首先将网格优化模型引入图像拼接,提出了尽可能如投影般的图像拼接(As Projective As Possible image stitching, APAP)对图像进行网格化,使用局部单应性矩阵完成图像拼接。Lin等<citation id="160" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>使用线性化的单应性矩阵控制透视变换的逐渐变化,并采用全局相似变换投影图像,提出尽可能自然的自适应图像拼接(Adaptive As Natural As Possible image stitching, AANAP),能够自适应确定图像旋转角度,使拼接图像更加自然。在拼接有曝光度差异以及较大视差的图像时,AutoStitch、APAP和AANAP等算法<citation id="161" type="reference"><link href="129" rel="bibliography" /><link href="131" rel="bibliography" /><link href="133" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>均出现了物体变形、重影与拼接缝等问题。</p>
                </div>
                <div class="p1">
                    <p id="38">为了解决拼接图像的过程中存在的特征点错误匹配,及拼接结果中存在重影和拼接缝等拼接痕迹的问题,本文提出一种定向配准特征点与优化的变形函数相结合的方法使图像的对齐更加精确,采用幂函数权重模型对变形图像的像素进行平滑过渡以消除拼接痕迹的问题。实验结果验证了本文方法能有效解决上述问题,使拼接图像更加自然。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag">1 结合定向配准和幂函数的图像拼接</h3>
                <div class="p1">
                    <p id="40">本文方法的流程如图1所示。具体步骤为:首先在输入图像中提取测试图像,利用ORB算法配准测试图像,得到单应性矩阵,进而在输入图像上确定重合区域;然后利用SIFT算法计算重合区域图像中特征点的描述符,并利用单应性矩阵计算各个特征点对的确切位置,完成特征点的定向匹配,并入测试图像的特征点点集得到配准的特征点集合;再将特征点作为控制点代入优化的薄板样条函数(Thin-Plate Spline,TPS)<citation id="162" type="reference"><link href="135" rel="bibliography" /><link href="137" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>对图像进行网格化变形与对齐;最后使用幂函数模型对变形图像中的像素进行加权过渡,得到高质量的拼接图像。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910044_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 结合定向配准和幂函数权重的图像拼接方法流程" src="Detail/GetImg?filename=images/JSJY201910044_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 结合定向配准和幂函数权重的图像拼接方法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910044_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flow chart of image stitching method combining orientation registration and power function weight</p>

                </div>
                <h4 class="anchor-tag" id="42" name="42">1.1 <b>特征点的定向配准</b></h4>
                <div class="p1">
                    <p id="43">虽然利用传统的特征提取算法如SIFT、SURF、ORB等与随机抽样一致(RANdom SAmple Consensus,RANSAC)<citation id="163" type="reference"><link href="139" rel="bibliography" /><link href="141" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>结合可以提高特征点的配准准确度,但是随着特征点数目的增多RANSAC算法迭代运算次数正相关增长,并且会存在少量的错误匹配点。通常输入图像包含40%左右的重合区域,为选取测试图像的方法提供了可能。为此提出一种新颖的特征点定向配准方法,以少量的运算得到更准确的特征点点集。</p>
                </div>
                <div class="p1">
                    <p id="44">首先在输入图像1的最右端选取测试图像1,在输入图像2的最左端选取测试图像2;其次利用ORB算法将测试图像1在输入图像2上以相同尺寸窗口进行滑动配准,同时将测试图像2在输入图像1上以相同尺寸窗口进行滑动配准,分别得到<i>N</i>个匹配点对(<i>x</i><sub><i>i</i></sub>,<i>y</i><sub><i>i</i></sub>)和(<i>x</i>′<sub><i>i</i></sub>,<i>y</i>′<sub><i>i</i></sub>),<i>i</i>=1,2,…,<i>N</i>;最后,将<i>N</i>对匹配点的坐标代入下列线性方程:</p>
                </div>
                <div class="p1">
                    <p id="45"><i><b>Ax</b></i>=<b>0</b>      (1)</p>
                </div>
                <div class="p1">
                    <p id="46">其中:</p>
                </div>
                <div class="area_img" id="48">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201910044_04800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="50"><b>0</b>=[0 0 … 0]<sup>T</sup>, 表示2<i>N</i>×1维的零矩阵。</p>
                </div>
                <div class="p1">
                    <p id="51">通过求解方程(1),得到矩阵<i><b>x</b></i>的元素,即得到输入图像之间的映射关系矩阵<image id="122" type="formula" href="images/JSJY201910044_12200.jpg" display="inline" placement="inline"><alt></alt></image>。</p>
                </div>
                <div class="p1">
                    <p id="54">使用关系式(2),计算输入图像边界上各个点的映射点,可得到图像间的重合区域。</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>∼</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">定位到图像的重合区域后进行特征点的定向配准。首先使用SIFT算法在重合区域内提取特征点,分别得到SIFT特征点点集1和SIFT特征点点集2;其次利用关系式(1)将SIFT特征点点集1内的各个特征点的坐标进行映射,得到目标位置的坐标,以目标位置为圆心,10个像素为半径作为特征点的待匹配圆形域;最后将SIFT特征点点集1内的各个特征点和位于SIFT特征点点集2相应的圆形域内的特征点进行描述符定向配准,并入测试图像的特征点点集,得到<i>n</i>对配准的特征点(<i>x</i><sub>1</sub><sub><i>i</i></sub>,<i>y</i><sub>1</sub><sub><i>i</i></sub>)和(<i>x</i><sub>2</sub><sub><i>i</i></sub>,<i>y</i><sub>2</sub><sub><i>i</i></sub>),以及(<i>x</i><sub>1</sub><sub><i>i</i></sub>,<i>y</i><sub>1</sub><sub><i>i</i></sub>)的映射点(<i>x</i>′<sub>1</sub><sub><i>i</i></sub>,<i>y</i>′<sub>1</sub><sub><i>i</i></sub>),其中<i>i</i>=1,2,…,<i>n</i>。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">1.2 <b>图像的变形</b></h4>
                <div class="p1">
                    <p id="58">薄板样条函数是一种用于求解插值的函数模型,由于该函数值只与到某个点的距离有关,并且是用以在函数空间中逼近目标函数的基,该函数是一种径向基函数。给定具体控制点的坐标,拟合出一个通过所有控制点,且弯曲度最小的光滑曲面,使所有控制点处的梯度变化最小。</p>
                </div>
                <div class="p1">
                    <p id="59">利用<i>TPS</i>函数对图像进行变形可有效对齐图像<citation id="164" type="reference"><link href="143" rel="bibliography" /><link href="145" rel="bibliography" /><link href="147" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>,消除图像错位、物体变形以及重影等问题。<i>TPS</i>函数可以最小化经过特征点的曲面的总曲率,进而确定最平滑的曲面。<i>TPS</i>函数形式如下:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mi>x</mi><mo>+</mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mi>y</mi><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>φ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">其中:<i>a</i><sub>0</sub>+<i>a</i><sub>1</sub><i>x</i>+<i>a</i><sub>2</sub><i>y</i>表示局部趋势函数,<i>φ</i><sub><i>i</i></sub>(<i>s</i>)=[(<i>x</i><sub><i>i</i></sub>-<i>x</i>)<sup>2</sup>+(<i>y</i><sub><i>i</i></sub>-<i>y</i>)<sup>2</sup>]ln[(<i>x</i><sub><i>i</i></sub>-<i>x</i>)<sup>2</sup>+(<i>y</i><sub><i>i</i></sub>-<i>y</i>)<sup>2</sup>]<sup>0.5</sup>是径向基函数,系数矩阵表示为<i><b>a</b></i>=<sup>T</sup>和<i>ω</i>=<sup>T</sup>。</p>
                </div>
                <div class="p1">
                    <p id="62">将特征点点集(<i>x</i>′<sub>1</sub><sub><i>i</i></sub>,<i>y</i>′<sub>1</sub><sub><i>i</i></sub>)代入下列等式,求解系数矩阵<i><b>a</b></i>和<i>ω</i>,具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">S</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi></mtd><mtd><mi mathvariant="bold-italic">Q</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Q</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd><mtd><mn>0</mn><msub><mrow></mrow><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">ω</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">a</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">F</mi></mtd></mtr><mtr><mtd><mn>0</mn><msub><mrow></mrow><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>λ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle></mrow></mstyle><mo stretchy="false">|</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>,</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo>,</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Q</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub></mtd><mtd><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>2</mn></msub></mtd><mtd><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>n</mi></mrow></msub></mtd><mtd><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>1</mn><mi>n</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">S</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo></mtd><mtd><mn>0</mn></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>φ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo></mtd><mtd><mi>φ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mspace width="0.25em" /></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66"><i><b>S</b></i>是<i>n</i>个特征点与特征点集合内其他点的距离的矩阵形式;<i><b>I</b></i>是单位矩阵;<i>λ</i>是控制曲面平滑度的正则参数。</p>
                </div>
                <div class="p1">
                    <p id="67">本文将特征点集合内所有特征点之间距离的平均值作为正则参数,代替以往的经验值常量。本文方法相对于文献<citation id="165" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>]</citation>能自适应地调整TPS函数映射的曲面平滑程度。</p>
                </div>
                <div class="p1">
                    <p id="68">沿着图像的宽和高的方向将图像划分为密集的网格,将网格中任意点的行和列的值代入式(3),即可得到变形图中相应的坐标。最后利用双线性插值的方法即可快速完成图像的变形。</p>
                </div>
                <div class="p1">
                    <p id="69">为了使拼接图像更为自然,加入以下约束项:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>p</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mn>2</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>q</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">其中:<i><b>I</b></i><sub>1</sub>和<i><b>I</b></i><sub>2</sub>表示待拼接图像经过TPS函数变形后的变形图像;矩阵<i><b>H</b></i><sub><i>q</i></sub>=<i>α</i>·<i><b>H</b></i>+<i>β</i>·<i><b>H</b></i><sub><i>s</i></sub><citation id="166" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>;矩阵<i><b>H</b></i><sub><i>p</i></sub>=<i><b>H</b></i><sub>q</sub>·<i><b>H</b></i><sup> - 1</sup>。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">1.3 <b>图像的融合</b></h4>
                <div class="p1">
                    <p id="73">为解决因曝光度差异和物体运动等导致拼接图像中存在拼接缝和重影等问题,一般方法使用基于线性权重融合的方法对像素进行平滑,虽然解决了拼接缝的问题,但仍然存在重影问题<citation id="167" type="reference"><link href="149" rel="bibliography" /><link href="151" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。本文提出一种基于幂函数的非线性权重模型,对像素进行更加平滑的过渡以解决重影问题。</p>
                </div>
                <div class="p1">
                    <p id="74">在重合区域内将像素的相对位置进行归一化。令任意像素点(<i>i</i>, <i>j</i>)到该行左边界的距离与其所在行左右边界的宽度的比值设为<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mfrac><mrow><mi>j</mi><mo>-</mo><mi>j</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>i</mi></mrow></msub></mrow><mrow><mi>j</mi><msub><mrow></mrow><mrow><mi>R</mi><mi>i</mi></mrow></msub><mo>-</mo><mi>j</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>i</mi></mrow></msub></mrow></mfrac><mo>,</mo><mspace width="0.25em" /><mi>b</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></math></mathml>,其中: <i>j</i>为重合区域内待平滑像素点所在列的数值 <i>j</i><sub><i>Li</i></sub>、 <i>j</i><sub><i>Ri</i></sub>分别为重合区域内待平滑像素点所在行的左端点和右端点的列的数值。将重合区域内任意点的归一化比值<i>b</i><sub>(</sub><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub><sub>)</sub>作为矩阵<i><b>X</b></i>的元素,代入如下列关系式,得到任意位置的幂函数权重数值:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn><mi mathvariant="bold-italic">Ι</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Ι</mi><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup><mo>⋅</mo><mi>ε</mi><mo stretchy="false">(</mo><mn>0</mn><mo>.</mo><mn>5</mn><mi mathvariant="bold-italic">Ι</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mo stretchy="false">(</mo><mn>2</mn><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup><mo>⋅</mo><mi>ε</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo>-</mo><mn>0</mn><mo>.</mo><mn>5</mn><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">其中:<i><b>U</b></i><sub>(</sub><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub><sub>)</sub>(<i><b>X</b></i>)和<i><b>V</b></i><sub>(</sub><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub><sub>)</sub>(<i><b>X</b></i>)分别表示对应变形图像的加权系数;<i>ε</i>(0.5<i><b>I</b></i>-<i><b>X</b></i>)和<i>ε</i>(<i><b>X</b></i>-0.5<i><b>I</b></i>)为阶跃函数;<i><b>I</b></i><sub>(</sub><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub><sub>)</sub>表示与矩阵<i><b>U</b></i><sub>(</sub><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub><sub>)</sub>(<i><b>X</b></i>)同型的单位矩阵的元素1;<i><b>P</b></i><sub>1</sub>(<i>i</i>, <i>j</i>)和<i><b>P</b></i><sub>2</sub>(<i>i</i>, <i>j</i>)分别表示对应变形图像<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>¯</mo></mover></math></mathml><sub>1</sub>和<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>¯</mo></mover></math></mathml><sub>2</sub>内重合区域的像素值;<i><b>P</b></i>(<i>i</i>, <i>j</i>)表示输出图像中重合区域的像素值。</p>
                </div>
                <div class="p1">
                    <p id="77">传统线性权重与本文非线性权重方法的函数对比结果如图2所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910044_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 线性与非线性权重方法的函数对比" src="Detail/GetImg?filename=images/JSJY201910044_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 线性与非线性权重方法的函数对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910044_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Comparison of functions of linear and nonlinear weighting methods</p>

                </div>
                <div class="p1">
                    <p id="79">如图2所示线性权值、幂函数权值分别表示线性权重<citation id="168" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和本文提出的幂函数的权重。由图2可知,从重合区域图像边缘向中心位置逼近的过程中,本文方法的权重变化更加缓慢,也就意味着待平滑的左图在重合区域中心左侧的像素占更大的比例,同样待平滑的右图在重合区域中心右侧的像素比重更多,进而缓解了重合区域中因运动产生的重影问题,同时解决了拼接缝的问题。</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag">2 实验结果分析</h3>
                <div class="p1">
                    <p id="81">本文在<i>Windows</i> 10(3.9 <i>GHz CPU</i>, 4 <i>GB RAM</i>)系统上使用<i>Visual Studio</i> 2017和<i>Matlab</i> 2017进行编程与仿真,验证了本文方法的有效性与优越性。首先比较特征点的配准过程各个阶段的时间消耗;其次分别以<i>AutoStitch</i>、<i>APAP</i>和<i>AANAP</i>算法拼接的图像作为参考与本文实验结果进行主观的视觉分析;最后使用基于本文方法对图像进行变形与拼接,通过多种图像质量评价指标,将分别使用线性函数权重和本文权重平滑拼接的图像进行客观的数据分析。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">2.1 <b>特征点的配准分析</b></h4>
                <div class="p1">
                    <p id="83">如表1所示,分别使用基于定向配准的本文方法和基于传统<i>SIFT</i>算法对10组图像进行特征点的配准实验,分别得到每组特征点配准的时间消耗、配准的特征点数量(用<i>NFP</i>表示该特征点数量,特征点成对出现)和相对于传统<i>SIFT</i>算法的效率提升的百分比(用<i>IPR</i>表示该效率提升百分比)等数据。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表</b>1 <b>特征点配准的时间消耗、配准的特征点数量和 相对于传统</b><i>SIFT</i><b>算法的效率提升的百分比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Time consumption of feature point registration</i>, <i>number of</i><i>feature points registered</i>, <i>and percentage of efficiency</i><i>improvement compared to traditional SIFT algorithm</i></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td><br />实验序号</td><td>方法</td><td>总时间/<i>s</i></td><td><i>NFP</i></td><td><i>IPR</i>/%</td></tr><tr><td rowspan="2"><br />1</td><td><br />传统<i>SIFT</i></td><td>85.07</td><td>924</td><td rowspan="2"><br />68.52</td></tr><tr><td><br />本文方法</td><td>26.78</td><td>1 115</td></tr><tr><td rowspan="2"><br />2</td><td><br />传统<i>SIFT</i></td><td>68.50</td><td>3 516</td><td rowspan="2"><br />77.99</td></tr><tr><td><br />本文方法</td><td>15.07</td><td>3 713</td></tr><tr><td rowspan="2"><br />3</td><td><br />传统<i>SIFT</i></td><td>71.70</td><td>3 256</td><td rowspan="2"><br />54.89</td></tr><tr><td><br />本文方法</td><td>32.34</td><td>3 524</td></tr><tr><td rowspan="2"><br />4</td><td><br />传统<i>SIFT</i></td><td>40.13</td><td>1 235</td><td rowspan="2"><br />77.35</td></tr><tr><td><br />本文方法</td><td>9.08</td><td>1 620</td></tr><tr><td rowspan="2"><br />5</td><td><br />传统<i>SIFT</i></td><td>7.65</td><td>1 099</td><td rowspan="2"><br />53.62</td></tr><tr><td><br />本文方法</td><td>3.55</td><td>1 206</td></tr><tr><td rowspan="2"><br />6</td><td><br />传统<i>SIFT</i></td><td>10.08</td><td>2 307</td><td rowspan="2"><br />51.79</td></tr><tr><td><br />本文方法</td><td>4.86</td><td>3 108</td></tr><tr><td rowspan="2"><br />7</td><td><br />传统<i>SIFT</i></td><td>1.14</td><td>943</td><td rowspan="2"><br />39.34</td></tr><tr><td><br />本文方法</td><td>0.69</td><td>1 636</td></tr><tr><td rowspan="2"><br />8</td><td><br />传统<i>SIFT</i></td><td>17.00</td><td>1 380</td><td rowspan="2"><br />66.25</td></tr><tr><td><br />本文方法</td><td>5.73</td><td>1 528</td></tr><tr><td rowspan="2"><br />9</td><td><br />传统<i>SIFT</i></td><td>3.41</td><td>846</td><td rowspan="2"><br />54.36</td></tr><tr><td><br />本文方法</td><td>1.55</td><td>1 061</td></tr><tr><td rowspan="2"><br />10</td><td><br />传统<i>SIFT</i></td><td>10.08</td><td>2 793</td><td rowspan="2"><br />53.67</td></tr><tr><td><br />本文方法</td><td>4.66</td><td>3 599</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="85">从表1可看出:传统<i>SIFT</i>算法在配准图像特征点阶段的时间消耗均多于本文方法的时间消耗,其原因是,传统<i>SIFT</i>算法对目标图像的特征点进行全局的提取与匹配;而本文方法首先对图像的特征点进行局部的提取,然后对局部的特征点进行定区域的匹配,直接避免了非重合区域图像信息的影响,减少了大量不必要的计算消耗。从表1中的<i>NFP</i>可知,本文方法匹配的特征点数量均多于传统的<i>SIFT</i>算法,其原因是本文方法避免了重合区域内的特征点错误匹配到非重合区域的特征点,以及由于加入了匹配圆形域,同样避免了重合区域内部特征点的错误匹配。从表1中的<i>IPR</i>可知,本文算法较传统<i>SIFT</i>算法的配准效率提升约为40%～77%,10组实验的效率提升平均约为59.78%,因为图像的重合区域占比通常约为40%,在避免了非重合区域图像信息的影响,算法效率提升则会趋向于60%。</p>
                </div>
                <div class="p1">
                    <p id="86">本文算法有效提高了传统<i>SIFT</i>算法的效率,避免了大量的无效计算,并且提升了特征点对的数量。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">2.2 <b>拼接图像效果分析</b></h4>
                <div class="p1">
                    <p id="88">图3为使用<i>AutoStitch</i>、<i>APAP</i>、<i>AANAP</i>以及本文方法拼接实验5的输入图像,得到的各个方法的拼接结果。</p>
                </div>
                <div class="p1">
                    <p id="89">图3第一列为拼接效果图;第二列和第三列图像分别为各个算法的拼接效果图中易产生图像错位、鬼影和拼接缝等问题的局部放大图像。</p>
                </div>
                <div class="p1">
                    <p id="90"><i>AutoStitch</i>、<i>APAP</i>和<i>AANAP</i>算法均出现了明显的问题:第一列,三种算法均产生了拼接缝和物体变形等问题;第二、三列,<i>AutoStitch</i>算法出现错位和拼接缝问题,<i>APAP</i>和<i>AANAP</i>算法出现了明显的拼接缝、鬼影问题;</p>
                </div>
                <div class="p1">
                    <p id="91">本文提出的结合变形函数和幂函数权重的图像拼接方法得到的图像更加自然,解决了因视差导致的图像错位问题,并且消除了拼接缝、重影和物体变形等问题。</p>
                </div>
                <div class="p1">
                    <p id="92">从图4的融合对比结果可看出,本文方法也没有基于线性权重方法存在的重影问题。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910044_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 各个算法的拼接图像" src="Detail/GetImg?filename=images/JSJY201910044_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 各个算法的拼接图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910044_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.3 <i>Stitching image of each algorithm</i></p>

                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910044_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同权重方法的融合结果" src="Detail/GetImg?filename=images/JSJY201910044_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同权重方法的融合结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910044_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.4 <i>Fusion results of different weighting methods</i></p>

                </div>
                <h4 class="anchor-tag" id="95" name="95">2.3 <b>拼接图像质量分析</b></h4>
                <div class="p1">
                    <p id="96">均方误差(<i>Mean Squared Error</i>, <i>MSE</i>)用于衡量“平均误差”,描述处理后的图像与原始图像之间的误差;峰值信噪比(<i>Peak Signal</i>-<i>to</i>-<i>Noise Ratio</i>, <i>PSNR</i>)是基于像素最大信号量与噪声强度的比值,是基于基于误差敏感度的图像质量评估方法;结构相似性(<i>Structural SIMilarity index</i>, <i>SSIM</i>)<citation id="169" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>可以从图像的亮度、对比度和结构等方面衡量两幅图像的相似度。</p>
                </div>
                <div class="p1">
                    <p id="97">仅从视觉上对比不同权重的融合效果具有局限性,可能看不出明显的差异。为此,使用<i>MSE</i>、<i>PSNR</i>和<i>SSIM</i>等3种图像质量评估指标,对本文的10组实验进行客观分析。将10组实验的原图分别用文献<citation id="170" type="reference">[<a class="sup">14</a>]</citation>的线性权重方法和本文方法进行图像融合,将实验的拼接图像与原图像进行对比计算,得到了表2中的数据。</p>
                </div>
                <div class="p1">
                    <p id="98">在表2的<i>MSE</i>对比中,本文方法的指标小于线性权重方法,即本文方法比线性权重方法融合的图像的能量差的均值更小,说明本文拼接的图像与原图更接近;在<i>PSNR</i>对比中,本文方法比线性权重方法的指标更大,说明本文拼接的图像与原图之间的噪声更小,即本文方法的拼接图像失真更小;在<i>SSIM</i>对比中,本文方法比线性权重方法融合的图像得分高,说明本文方法的拼接图像在亮度、对比度和结构上与原图更相似。</p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表</b>2 <b>不同方法融合结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.2 <i>Fusion result comparison of different methods</i></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td><br />实验序号</td><td>方法</td><td><i>MSE</i></td><td><i>PSNR</i>/<i>dB</i></td><td><i>SSIM</i></td></tr><tr><td rowspan="2"><br />1</td><td><br />线性权重方法</td><td>4 893.3</td><td>11.234 8</td><td>0.590 4</td></tr><tr><td><br />本文方法</td><td>4 818.0</td><td>11.302 7</td><td>0.596 4</td></tr><tr><td rowspan="2"><br />2</td><td><br />线性权重方法</td><td>6 879.4</td><td>9.756 7</td><td>0.657 9</td></tr><tr><td><br />本文方法</td><td>6 804.9</td><td>9.804 0</td><td>0.664 3</td></tr><tr><td rowspan="2"><br />3</td><td><br />线性权重方法</td><td>4 392.6</td><td>11.707 1</td><td>0.655 6</td></tr><tr><td><br />本文方法</td><td>4 388.2</td><td>11.711 6</td><td>0.663 7</td></tr><tr><td rowspan="2"><br />4</td><td><br />线性权重方法</td><td>4 700.5</td><td>11.409 3</td><td>0.662 7</td></tr><tr><td><br />本文方法</td><td>4 654.5</td><td>11.452 1</td><td>0.667 2</td></tr><tr><td rowspan="2"><br />5</td><td><br />线性权重方法</td><td>8 272.8</td><td>8.954 3</td><td>0.616 2</td></tr><tr><td><br />本文方法</td><td>8 268.1</td><td>8.956 7</td><td>0.616 7</td></tr><tr><td rowspan="2"><br />6</td><td><br />线性权重方法</td><td>8 178.2</td><td>9.004 2</td><td>0.615 0</td></tr><tr><td><br />本文方法</td><td>8 147.0</td><td>9.020 8</td><td>0.617 9</td></tr><tr><td rowspan="2"><br />7</td><td><br />线性权重方法</td><td>13 691.1</td><td>6.800 7</td><td>0.629 8</td></tr><tr><td><br />本文方法</td><td>13 672.5</td><td>6.806 2</td><td>0.631 6</td></tr><tr><td rowspan="2"><br />8</td><td><br />线性权重方法</td><td>13 365.3</td><td>6.871 6</td><td>0.545 7</td></tr><tr><td><br />本文方法</td><td>13 455.2</td><td>6.842 7</td><td>0.543 3</td></tr><tr><td rowspan="2"><br />9</td><td><br />线性权重方法</td><td>6 732.2</td><td>10.036 2</td><td>0.574 8</td></tr><tr><td><br />本文方法</td><td>6 593.8</td><td>10.131 1</td><td>0.580 9</td></tr><tr><td rowspan="2"><br />10</td><td><br />线性权重方法</td><td>12 204.7</td><td>7.277 9</td><td>0.554 3</td></tr><tr><td><br />本文方法</td><td>12 179.1</td><td>7.287 1</td><td>0.561 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">本文方法的拼接效果图与原图的主观感受更接近,其中原因在于,本文提出的权重系数,在重合区域中心偏左的像素融合中,提升了输入图像1的权重,降低了输入图像2的影响,在重合区域中心偏右的像素融合中,提升了输入图像2的权重,降低了输入图像1的影响,从而能更加平滑地过渡重合区域图像,消除重影问题。通过多组实验验证了本文方法的有效性和优越性。</p>
                </div>
                <h3 id="101" name="101" class="anchor-tag">3 结语</h3>
                <div class="p1">
                    <p id="102">本文结合特征点的分布规律、图像变形和像素平滑的特点改进了图像拼接领域中特征点的提取范围和匹配方法,通过线性组合单应性矩阵和相似变换矩阵对变形模型进行优化,并且提出幂函数权重模型优化传统的线性权重模型,使用<i>AutoStitch</i>、<i>APAP</i>、<i>AANAP</i>等提供的数据集图像进行图像拼接。实验结果表明,该方法能够自动确定图像重合区域和特征点待匹配圆形域,减少了特征点匹配的穷举对象,提升特征点的配准效率;使用线性图像变形模型和幂函数权重模型对图像进行拼接,解决了图像变形、重影、拼接缝等问题,得到了更加自然的拼接图像,但是,本文工作仍有许多不足,如未考虑使用<i>GPU</i>加速技术改进图像拼接算法,下一步工作将针对算法实时性进行研究和优化。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="123">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDMwODdGYmVzT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlybFU3N01KRlk9Tmo3QmFyTzRIdEhPcDR4&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Surf: Speeded up robust features">

                                <b>[2]</b>BAY H,TUYTELAARS T,GOOL L V.SURF:speeded up robust features[C]//Proceedings of the 2006 European Conference on Computer Vision,LNCS 3951.Berlin:Springer,2006:404-417.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to sift or surf">

                                <b>[3]</b>RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:an efficient alternative to SIFT or SURF[C]//Proceedings of the 2011 IEEEInternational Conference on Computer Vision.Piscataway:IEEE,2011:2564-2571.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002831131&amp;v=MDUyMDNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXJsVTc3TUpGWT1OajdCYXJPNEh0SE9wNHhFWmVn&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>BROWN M,LOWE D G.Automatic panoramic image stitching using invariant features[J].International Journal of Computer Vision,2007,74(1):59-73.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=As-projective-as-possible image stitching with moving DLT">

                                <b>[5]</b>ZARAGOZA J,CHIN T,BROWN M S,et al.As-projective-aspossible image stitching with moving DLT[C]//Proceedings of the2013 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2013:2339-2346.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive As-Natural-As-Possible Image Stitching">

                                <b>[6]</b>LIN C,PANKANTI S U,RAMAMURTHY K N,et al.Adaptive as-natural-as-possible image stitching[C]//Proceedings of the2015 IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2015:1155-1163.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Principal warps: thin-plate splines and the decomposition of deformations">

                                <b>[7]</b>BOOKSTEIN F L.Principal warps:thin-plate splines and the decomposition of deformations[J].IEEE Transactions on Pattern A-nalysis and Machine Intelligence,1989,11(6):567-585.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A seamless approach to stitching lunar DOMs with TPS">

                                <b>[8]</b>SHENG H,LOU C,XU W,et al.A seamless approach to stitching lunar DOMs with TPS[J].Applied Mathematics&amp;Information Sciences,2013,7(2L):555-562.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RANSAC-Based DARCES: A New Approach to Fast Automatic Registration of Partially Overlapping Range Images">

                                <b>[9]</b>CHEN C,HUNG Y,CHENG J.RANSAC-based DARCES:a new approach to fast automatic registration of partially overlapping range images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,1999,21(11):1229-1234.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES2701DB05B0EE4B86E710FADDCBE2C85C&amp;v=MDM2NTNCdUhZZk9HUWxmQnJMVTA1dHBoeExtN3hLQT1OaWZPZmJHL0h0QzQzWTlBRnV0NmVYaEx4eEJtN1Q1OVBnNlcyR0ZIRExEblRiL3NDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>HOSSEIN-NEJAD Z,NASRI M.An adaptive image registration method based on SIFT features and RANSAC transform[J].Computers&amp;Electrical Engineering,2017,62(8):524-537.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300711881&amp;v=MTUyNjhyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJRjhRYmhvPU5pZk9mYks3SHRETnJJOUZZK29PQkhRNG9CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>MEYER C R,BOES J L,KIM B,et al.Demonstration of accuracy and clinical versatility of mutual information for automatic multimodality image fusion using affine and thin-plate spline warped geometric deformations[J].Medical Image Analysis,1997,1(3):195-206.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An image matching algorithm using Thin Plate Splines(TPS)transformation model">

                                <b>[12]</b>GUO H,HOU Y,ZHAO Y.An image matching algorithm using Thin Plate Splines(TPS)transformation model[J].International Journal of Simulation Systems,Science and Technology,2016,17(8):No.13.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallax-tolerant image stitching based on robust elastic warping">

                                <b>[13]</b>LI J,WANG Z,LAI S,et al.Parallax-tolerant image stitching based on robust elastic warping[J].IEEE Transactions on Multimedia,2018,20(7):1672-1687.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201706014&amp;v=MTAxMzN5amtWN3ZBUHlyZmJMRzRIOWJNcVk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>谷雨,周阳,任刚,等.结合最佳缝合线和多分辨率融合的图像拼接[J].中国图象图形学报,2017(6):842-851.(GU Y,ZHOU Y,REN G,et al.Image stitching by combining optimal seam and multi-resolution fusion[J].Journal of Image and Graphics,2017,22(6):842-851.).
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201503058&amp;v=MzAzNDFyQ1VSN3FmWnVac0Z5amtWN3ZBTHo3QmI3RzRIOVRNckk5QWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>瞿中,乔高元,林嗣鹏.一种消除图像拼接缝和鬼影的快速拼接算法[J].计算机科学,2015,42(3):280-283.(QU Z,QIAO G Y,LIN S P.Fast image stitching algorithm eliminates seam line and ghosting[J].Computer Science,2015,42(3):280-283.).
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Quality Metrics:PSNR vs.SSIM">

                                <b>[16]</b>HORE A,ZIOU D.Image quality metrics:PSNR vs.SSIM[C]//Proceedings of the 20th International Conference on Pattern Recognition.Piscataway:IEEE,2010:2366-2369.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910044" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910044&amp;v=MjQ5NTJGeWprVjd2QUx6N0JkN0c0SDlqTnI0OUJZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
