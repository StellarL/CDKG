<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136667066096250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907043%26RESULT%3d1%26SIGN%3dzVlG7ty0SQK6LaUg26XazXLsq6s%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907043&amp;v=MDU4NjBGckNVUjdxZlp1WnNGeS9nVjcvSUx6N0JkN0c0SDlqTXFJOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 基于FCN的图像分割算法 ">1 基于FCN的图像分割算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 利用关键点辅助FCN的左心室提取 ">2 利用关键点辅助FCN的左心室提取</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="2.1 &lt;b&gt;左心室关键点定位&lt;/b&gt;">2.1 <b>左心室关键点定位</b></a></li>
                                                <li><a href="#54" data-title="2.2 &lt;b&gt;分割区域筛选及合并&lt;/b&gt;">2.2 <b>分割区域筛选及合并</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="3 实验及分析 ">3 实验及分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="3.1 &lt;b&gt;实验数据&lt;/b&gt;">3.1 <b>实验数据</b></a></li>
                                                <li><a href="#66" data-title="3.2 &lt;b&gt;评价标准&lt;/b&gt;">3.2 <b>评价标准</b></a></li>
                                                <li><a href="#78" data-title="3.3 &lt;b&gt;实验及结果&lt;/b&gt;">3.3 <b>实验及结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="图1 FCN网络结构">图1 FCN网络结构</a></li>
                                                <li><a href="#53" data-title="图2 关键点检测网络结构">图2 关键点检测网络结构</a></li>
                                                <li><a href="#61" data-title="图3 区域筛选示意图">图3 区域筛选示意图</a></li>
                                                <li><a href="#62" data-title="图4 区域合并示意图">图4 区域合并示意图</a></li>
                                                <li><a href="#73" data-title="图5 训练测试样本示例">图5 训练测试样本示例</a></li>
                                                <li><a href="#81" data-title="图6 不同算法实验结果对比">图6 不同算法实验结果对比</a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同算法评价标准下的效果&lt;/b&gt;"><b>表</b>1 <b>不同算法评价标准下的效果</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同关键点筛选效果&lt;/b&gt;"><b>表</b>2 <b>不同关键点筛选效果</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;数据增广后效果对比&lt;/b&gt;"><b>表</b>3 <b>数据增广后效果对比</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;处理每张图平均耗时&lt;/b&gt;"><b>表</b>4 <b>处理每张图平均耗时</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="108">


                                    <a id="bibliography_1" title=" 朱锴, 付忠良, 陶攀, 等.基于自适应均值漂移的超声心动图左心室分割方法[J].生物医学工程学杂志, 2018, 35 (2) :273-279. (ZHU K, FU Z, TAO P, et al.Left ventricle segmentation in echocardiography based on adaptive mean shift[J].Journal of Biomedical Engineering, 2018, 35 (2) :273-279.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SWGC201802016&amp;v=MTEwNDZHNEg5bk1yWTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y3L0lOanJNYmI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         朱锴, 付忠良, 陶攀, 等.基于自适应均值漂移的超声心动图左心室分割方法[J].生物医学工程学杂志, 2018, 35 (2) :273-279. (ZHU K, FU Z, TAO P, et al.Left ventricle segmentation in echocardiography based on adaptive mean shift[J].Journal of Biomedical Engineering, 2018, 35 (2) :273-279.) 
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_2" title=" SADEK I, ELAWADY M, STEFANOVSKI V.Automated breast lesion segmentation in ultrasound images[J].ArXiv Preprint, 2016, 2016:1609.08364." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automated breast lesion segmentation in ultrasound images">
                                        <b>[2]</b>
                                         SADEK I, ELAWADY M, STEFANOVSKI V.Automated breast lesion segmentation in ultrasound images[J].ArXiv Preprint, 2016, 2016:1609.08364.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_3" title=" 朱永杰, 邱天爽.基于改进LGDF模型的超声图像自动分割方法[J].大连理工大学学报, 2016, 56 (1) :28-34. (ZHU Y J, QIU T S.Automated segmentation method for ultrasound image based on improved LGDF model[J].Journal of Dalian University of Technology, 2016, 56 (1) :28-34.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLLG201601005&amp;v=MTQ5MjhadVpzRnkvZ1Y3L0lJU0hIYWJHNEg5Zk1ybzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         朱永杰, 邱天爽.基于改进LGDF模型的超声图像自动分割方法[J].大连理工大学学报, 2016, 56 (1) :28-34. (ZHU Y J, QIU T S.Automated segmentation method for ultrasound image based on improved LGDF model[J].Journal of Dalian University of Technology, 2016, 56 (1) :28-34.) 
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_4" title=" JIANG P, PENG J, ZHANG G, et al.Learning-based automatic breast tumor detection and segmentation in ultrasound images[C]// Proceedings of the 2012 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2012:1587-1590." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning-based automatic breast tumor detection and segmentation in ultrasound images">
                                        <b>[4]</b>
                                         JIANG P, PENG J, ZHANG G, et al.Learning-based automatic breast tumor detection and segmentation in ultrasound images[C]// Proceedings of the 2012 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2012:1587-1590.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_5" title=" NGO T A, LU Z, CARNEIRO G.Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance[J].Medical Image Analysis, 2017, 35:159-171." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic Resonance">
                                        <b>[5]</b>
                                         NGO T A, LU Z, CARNEIRO G.Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance[J].Medical Image Analysis, 2017, 35:159-171.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_6" title=" 纪祥虎, 高思聪, 黄志标, 等.基于Centripetal Catmull-Rom曲线的经食道超声心动图左心室分割方法[J].四川大学学报 (工程科学版) , 2016, 48 (5) :84-90. (JI X H, GAO S C, HUANG Z B, et al.Left ventricle segmentation in transesophageal echocardiography based on Centripetal Catmull-Rom curve[J].Journal of Sichuan University (Engineering Science Edition) , 2016, 48 (5) :84-90.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201605013&amp;v=MDg4MTc3L0lOaTdIWnJHNEg5Zk1xbzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         纪祥虎, 高思聪, 黄志标, 等.基于Centripetal Catmull-Rom曲线的经食道超声心动图左心室分割方法[J].四川大学学报 (工程科学版) , 2016, 48 (5) :84-90. (JI X H, GAO S C, HUANG Z B, et al.Left ventricle segmentation in transesophageal echocardiography based on Centripetal Catmull-Rom curve[J].Journal of Sichuan University (Engineering Science Edition) , 2016, 48 (5) :84-90.) 
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_7" title=" VARGAS-QUINTERO L, ESCALANTE-RAM&#205;REZ B, CAMARGO M L, et al.Left ventricle segmentation in fetal echocardiography using a multi-texture active appearance model based on the steered Hermite transform[J].Computer Methods and Programs in Biomedicine, 2016, 137:231-245." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Left ventricle segmentation in fetal echocardiography using a multi-texture active appearance model based on the steered Hermite transform">
                                        <b>[7]</b>
                                         VARGAS-QUINTERO L, ESCALANTE-RAM&#205;REZ B, CAMARGO M L, et al.Left ventricle segmentation in fetal echocardiography using a multi-texture active appearance model based on the steered Hermite transform[J].Computer Methods and Programs in Biomedicine, 2016, 137:231-245.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_8" title=" LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[8]</b>
                                         LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_9" title=" ZHENG S, JAYASUMANA S, ROMERA-PAREDES B, et al.Conditional random fields as recurrent neural networks[C]// ICCV&#39;15:Proceedings of the 2015 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2015:1529-1537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional random fields as recurrent neural networks">
                                        <b>[9]</b>
                                         ZHENG S, JAYASUMANA S, ROMERA-PAREDES B, et al.Conditional random fields as recurrent neural networks[C]// ICCV&#39;15:Proceedings of the 2015 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2015:1529-1537.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_10" title=" HE K, GKIOXARI G, DOLLAR P, et al.Mask R-CNN[C]// ICCV 2017:Proceedings of the 2017 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2017:2961-2969." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">
                                        <b>[10]</b>
                                         HE K, GKIOXARI G, DOLLAR P, et al.Mask R-CNN[C]// ICCV 2017:Proceedings of the 2017 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2017:2961-2969.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_11" title=" RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]// MICCAI 2015:Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention, LNCS 9351.Berlin:Springer, 2015:234-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">
                                        <b>[11]</b>
                                         RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]// MICCAI 2015:Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention, LNCS 9351.Berlin:Springer, 2015:234-241.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_12" title=" GAO M, XU Z, LU L, et al.Segmentation label propagation using deep convolutional neural networks and dense conditional random field[C]// Proceedings of the 2016 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:1265-1268." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation label propagation using deep convolutional neural networks and dense conditional random field">
                                        <b>[12]</b>
                                         GAO M, XU Z, LU L, et al.Segmentation label propagation using deep convolutional neural networks and dense conditional random field[C]// Proceedings of the 2016 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:1265-1268.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_13" title=" LI Y, YI G, WANG Y, et al.Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks[J].IEEE Transactions on Biomedical Engineering, 2017, 64 (8) :1886-1895." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks">
                                        <b>[13]</b>
                                         LI Y, YI G, WANG Y, et al.Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks[J].IEEE Transactions on Biomedical Engineering, 2017, 64 (8) :1886-1895.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_14" title=" 詹曙, 梁植程, 谢栋栋.前列腺磁共振图像分割的反卷积神经网络方法[J].中国图象图形学报, 2017, 22 (4) :516-522. (ZHAN S, LIANG Z C, XIE D D.Deconvolutional neural network for prostate MRI segmentation[J].Journal of Image and Graphics, 2017, 22 (4) :516-522.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201704011&amp;v=MzE5NjNVUjdxZlp1WnNGeS9nVjcvSVB5cmZiTEc0SDliTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         詹曙, 梁植程, 谢栋栋.前列腺磁共振图像分割的反卷积神经网络方法[J].中国图象图形学报, 2017, 22 (4) :516-522. (ZHAN S, LIANG Z C, XIE D D.Deconvolutional neural network for prostate MRI segmentation[J].Journal of Image and Graphics, 2017, 22 (4) :516-522.) 
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_15" title=" JAFARI M H, GIRGIS H, LIAO Z, et al.A unified framework integrating recurrent fully-convolutional networks and optical flow for segmentation of the left ventricle in echocardiography data[C]// Proceedings of the 2018 International Workshop on Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support.Berlin:Springer, 2018:29-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A unified framework integrating recurrent fully-convolutional networks and optical flow for segmentation of the left ventricle in echocardiography data">
                                        <b>[15]</b>
                                         JAFARI M H, GIRGIS H, LIAO Z, et al.A unified framework integrating recurrent fully-convolutional networks and optical flow for segmentation of the left ventricle in echocardiography data[C]// Proceedings of the 2018 International Workshop on Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support.Berlin:Springer, 2018:29-37.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_16" title=" SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].ArXiv Preprint, 2014, 2014:1409.1556." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[16]</b>
                                         SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].ArXiv Preprint, 2014, 2014:1409.1556.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_17" title=" GRAHAM R L.An efficient algorithm for determining the convex hull of a finite planar set[J].Information Processing Letters, 1978, 7 (1) :53-55." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for determining the convex hull of a finite planar set">
                                        <b>[17]</b>
                                         GRAHAM R L.An efficient algorithm for determining the convex hull of a finite planar set[J].Information Processing Letters, 1978, 7 (1) :53-55.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-09 13:47</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),2121-2124 DOI:10.11772/j.issn.1001-9081.2018112321            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的超声图像左心室分割方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E9%94%B4&amp;code=36173915&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱锴</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%98%E5%BF%A0%E8%89%AF&amp;code=09526100&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">付忠良</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%99%93%E6%B8%85&amp;code=39084756&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈晓清</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%88%90%E9%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%BA%94%E7%94%A8%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=0211714&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院成都计算机应用研究所</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>超声图像左心室的分割在临床上对医生的作用巨大。由于超声图像含有大量噪声, 轮廓特征不明显, 目前的卷积神经网络 (CNN) 方法对左心室分割容易得到不必要的区域, 并且分割目标不完整。为了解决上述问题, 在全卷积神经网络 (FCN) 基础上加入了关键点定位和求取图像凸包方法对分割结果进行优化。首先采用FCN获取初步的分割结果;然后为了去除分割结果中的错误区域, 提出一种CNN定位左心室三个关键点的位置, 通过关键点筛选掉分割结果中不必要的区域;最后为保证剩余区域能够组合成一个完整的心室, 利用求取图像凸包算法将所有有效区域进行合并。实验结果表明, 在超声图像左心室分割效果上, 所提方法能够在普通FCN的基础上获得很大的提升, 在交并比评价标准下, 该方法获取的左心室结果能够比传统CNN方法提升近15%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%A3%B0%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超声图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E9%94%AE%E7%82%B9%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关键点定位;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%87%B8%E5%8C%85&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">凸包;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *朱锴 (1991—) , 男, 贵州安顺人, 博士研究生, 主要研究方向:机器视觉、机器学习;电子邮箱578473077@qq.com;
                                </span>
                                <span>
                                    付忠良 (1967—) , 男, 重庆合川人, 研究员, 博士生导师, 主要研究方向:机器学习;;
                                </span>
                                <span>
                                    陈晓清 (1989—) , 男, 四川凉山人, 博士研究生, 主要研究方向:机器学习、机器视觉。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>四川省科技厅重点研发项目 (2017SZ0010);</span>
                                <span>四川省科技支撑计划项目 (2016JZ0035);</span>
                    </p>
            </div>
                    <h1><b>Left ventricular segmentation method of ultrasound image based on convolutional neural network</b></h1>
                    <h2>
                    <span>ZHU Kai</span>
                    <span>FU Zhongliang</span>
                    <span>CHEN Xiaoqing</span>
            </h2>
                    <h2>
                    <span>Chengdu Institute of Computer Applications, Chinese Academy of Sciences</span>
                    <span>University of Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Ultrasound image segmentation of left ventricle is very important for doctors in clinical practice. As the ultrasound images contain a lot of noise and the contour features are not obvious, current Convolutional Neural Network (CNN) method is easy to obtain unnecessary regions in left ventricular segmentation, and the segmentation regions are incomplete. In order to solve these problems, keypoint location and image convex hull method were used to optimize segmentation results based on Fully Convolutional neural Network (FCN) . Firstly, FCN was used to obtain preliminary segmentation results. Then, in order to remove erroneous regions in segmentation results, a CNN was proposed to locate three keypoints of left ventricle, by which erroneous regions were filtered out. Finally, in order to ensure that the remained area were able to be a complete ventricle, image convex hull algorithm was used to merge all the effective areas together. The experimental results show that the proposed method can greatly improve left ventricular segmentation results of ultrasound images based on FCN. Under the evaluation standard, the accuracy of results obtained by this method can be increased by nearly 15% compared with traditional CNN method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ultrasound%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ultrasound image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=keypoint%20location&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">keypoint location;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convex%20hull&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convex hull;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHU Kai, born in 1991, Ph. D. candidate. His research interests include computer vision, machine learning. ;
                                </span>
                                <span>
                                    FU Zhongliang, born in 1967, research fellow. His research interests include machine learning. ;
                                </span>
                                <span>
                                    CHEN Xiaoqing, born in 1989, Ph. D. candidate. His research interests include machine learning, computer vision.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-23</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the Key Research and Development Project of Sichuan Science and Technology Department (2017SZ0010);</span>
                                <span>the Science and Technology Support Program of Sichuan Province (2016JZ0035);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="38">心脏超声图像是临床医学上评估患者心脏状况的主要手段之一, 其中左心室的大小是判断心脏是否正常的重要生理参数。一般来说医生通过在超声图像上手动描绘左心室轮廓来计算左心室容积大小, 由于手动描绘轮廓很繁琐, 在术中十分不便, 因此设计一种全自动的分割算法能给医生带来极大的便利, 但目前由于超声图像存在如下几个分割难点:一是相对于其他医学图像, 超声图像中存在巨大的斑点噪声, 为图像分割带来了很大的干扰;二是每位患者的生理结构虽然大体类似, 但是个体差异带来的生理结构不规则变化为分割增加了挑战。</p>
                </div>
                <div class="p1">
                    <p id="39">图像分割技术在医学图像中应用很广泛, 通过对关键区域的分割提取, 能够获取病人重要生理结构的形状、大小等信息。传统医学图像分割方案通常先对图像进行预处理, 后采用算法对目标区域分割。传统医学图像分割方法通常分为利用单幅图像本身特征进行的分割方法和采用带标注数据集训练的方法。通常两种方法均需要手工提取图像局部特征来对像素进行聚类或分类。在前一类方法中, 有学者采用基于更为快速的基于区域的卷积神经网络 (Faster Region-based Convolutional Neural Network, Faster RCNN) 结合均值漂移算法的方法对超声图像左心室进行提取<citation id="142" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 也有学者采用规范化切割结合<i>K</i>均值算法对乳房病变区域进行定位<citation id="143" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 还有学者采用局部高斯分布拟合能量模型对超声图像进行定位<citation id="144" type="reference"><link href="112" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。此类算法虽然简单, 不需要依赖其他图像便可完成, 但由于算法仅仅从单一图像提取特征进行分割, 图像鲁棒性较差, 对图像质量要求较高。后一类方法中, Jiang等<citation id="145" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>采用Haar特征结合AdaBoost方法对乳房超声图像进行分割;Ngo等<citation id="146" type="reference"><link href="116" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>采用水平集方法对心脏核磁共振图像左心室进行分割;也有学者利用关键点采用基于活动轮廓模型的方法对目标区域进行定位<citation id="147" type="reference"><link href="118" rel="bibliography" /><link href="120" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。此类方法较为依赖手工特征的选取, 并且基于轮廓的方法需要有较好的初始位置选取。</p>
                </div>
                <div class="p1">
                    <p id="40">近年来, 由于深度学习具有不需要手动设计特征等优势, 该方法在图像分类上的成功也带动了将其在图像分割的运用。2014年Long等<citation id="148" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>首次将深度卷积神经网络 (Convolutional Neural Network, CNN) 运用于图像分割上, 提出了一种全卷积的神经网络 (Fully Convolutional neural Network, FCN) , 该方法对图像中每个像素进行类别预测实现像素级别的语义分割, 并取得了很好的效果, 后有大量学者对FCN进行改进, 并在自然图像上得到了有效的验证<citation id="154" type="reference"><link href="124" rel="bibliography" /><link href="126" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。随着深度学习在自然图像上的成功, 有研究者改进FCN提出了U-Net对生物医学图像进行分割, 尽可能地保留了图像的细节<citation id="149" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 也有学者将FCN结合条件随机场对大脑电子计算机断层扫描图像进行分割, 能够有效地对FCN粗糙的分割进行补充<citation id="150" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>:Li等<citation id="151" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种基于动态CNN的方案对左心室轮廓进行分割;詹曙等<citation id="152" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>采用反卷积神经网络分割核磁共振图像, 大幅减小了分割时间;Jafari等<citation id="153" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>使用U-Net结合长短期记忆网络对超声心动图左心室进行分割。但上述深度学习算法在运用于心室分割中有如下问题:不同于其他医学图像, 超声图像很多左心室边界模糊, 单纯采用卷积神经网络获取的结果很可能包含很多部分, 而不是单一的左心室腔体, 目前的区域筛选办法主要是采用普通的阈值将较小的区域筛选掉, 并没有有效的筛选方法能选取想要进行合并的区域。</p>
                </div>
                <div class="p1">
                    <p id="41">为解决上述问题, 本文提出了一种基于FCN的超声图像左心室分割方案, 算法结合关键点定位对多余的区域进行筛选, 并对余下区域采用图像求凸包算法进行合并, 最终得到左心室腔体。实验表明, 本文算法能够有效地对超声图像左心室进行提取, 与传统的FCN算法相比, 在评价标准上获得更高的精度。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 基于FCN的图像分割算法</h3>
                <div class="p1">
                    <p id="43">基于FCN的图像分割算法是Long等<citation id="155" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出的, 算法去除了普通CNN的全连接层, 改用全卷积的网络结构对图像每个像素进行分类, 达到了像素级别的分割效果。算法大体框架如图1, 网络结构将是根据VGG16<citation id="156" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>改进的, 首先将VGG (Visual Geometry Group) 的全连接层改为卷积核大小为1×1的卷积层, 将全连接层改为了图中conv6和conv7。图像首先经过若干卷积层和池化层进行降采样, 其中卷积层后采用线性整流函数 (Rectified Linear Unit, ReLU) 为激活函数, 池化层采用最大池化, 后采用反卷积操作将图像特征图映射回原图大小, 并对每个像素类别进行预测, 算法采用softmax损失函数。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 FCN网络结构" src="Detail/GetImg?filename=images/JSJY201907043_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 FCN网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Architecture of FCN</p>

                </div>
                <div class="p1">
                    <p id="45">本文采用全卷积网络模型实现经食道超声四腔心切面左心室的初步分割, 本文选取上采样8倍的FCN对左心室分割, 将图像大小缩放为3×256×256作为输入。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 利用关键点辅助FCN的左心室提取</h3>
                <h4 class="anchor-tag" id="47" name="47">2.1 <b>左心室关键点定位</b></h4>
                <div class="p1">
                    <p id="48">由于采用FCN网络得到的分割结果对于某些心室超声图像会包含多个区域结果, 为对这些区域是否为心室区域进行筛选, 本文提出了利用关键点定位对区域筛选的方法。在左心室结构中, 包含心尖、二尖瓣左右根部三个重要关键点的位置, 为对这三个关键点的位置作粗略估计, 本文提出利用卷积神经网络回归的方法对关键点的位置进行定位。</p>
                </div>
                <div class="p1">
                    <p id="49">如图2所示, 本文采用包含8个卷积层和2个全连接层的网络进行关键点定位, 输入图像大小为256像素×256像素, 经过一系列卷积层和池化层的采样之后, 利用2个全连接层输出3个关键点坐标。由于本文定位关键点的位置是辅助图像分割的, 并不需要十分精确的关键位置也能够达到辅助分割的效果。采用的损失函数为欧氏损失函数, 如式 (1) :</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow></mrow></mstyle><mo stretchy="false"> (</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">其中:<i>E</i>代表损失, <i>N</i>为样本数目, <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml>为预测值, <i>y</i>为实际值。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 关键点检测网络结构" src="Detail/GetImg?filename=images/JSJY201907043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 关键点检测网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Architecture of keypoint detection neural network</p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">2.2 <b>分割区域筛选及合并</b></h4>
                <div class="p1">
                    <p id="55">由于超声图像轮廓不清晰, 实验数据量有限, 在实验过程中利用FCN算法得到的结果可能包含的不是同一个区域, 而是图像中很多区域。为对这些区域进行筛选和合并, 本文采用关键点定位对区域进行筛选, 后采用图像求凸算法对区域进行合并。图3展示了区域筛选的实例, 假设图3 (a) 为FCN分割得到的结果, 图3 (b) 为左心室标签和3个关键的位置, 希望保留图 (a) 的区域2和区域3, 去除掉区域1, 传统的区域筛选算法仅仅通过区域大小设置阈值而删除;但若FCN选取结果某些区域较大而且是错误的, 阈值去除区域办法就将得到一些错误的区域, 并且在合并这些非连通区域时将得到更为糟糕的结果, 为此本文提出的关键点定位算法能够有效解决这种问题, 如图 (b) 所示, 本文将定位的三个关键点所构成的三角区域视为筛选区域, 筛选时将和三角区域无交集的区域去除, 这样一来既能筛选掉不需要的大部分区域, 还能保留离分割区域更为接近的区域。即使关键点定位无法达到精准的情况下, 大部分无关区域也能够被剔除。</p>
                </div>
                <div class="p1">
                    <p id="56">对于筛选过的区域, 本文根据求凸算法<citation id="157" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>将剩下相关区域进行合并, 得到最终分割结果。如图4所示2个区域合并的流程如下:</p>
                </div>
                <div class="p1">
                    <p id="57">1) 寻找待合并区域所有边界点, 并确定所有关键点纵坐标最小的<i>P</i>。</p>
                </div>
                <div class="p1">
                    <p id="58">2) 计算其余各点和<i>P</i>构成直线与<i>x</i>轴正向的幅角, 并将所有点按幅角大小<i>α</i>排序, <i>α</i>相同的离<i>P</i>近的排在前, 即各点相对<i>P</i>按逆时针方向排序, 则<i>P</i>后第一个点<i>R</i><sub><i>i</i>+1</sub>位于凸包上, 并将<i>P</i>、<i>R</i><sub><i>i</i>+1</sub>入栈, 按排序将<i>R</i><sub><i>i</i>+1</sub>后<i>R</i><sub><i>i</i>+2</sub>入栈, <i>R</i><sub><i>i</i>+2</sub>为栈顶元素。</p>
                </div>
                <div class="p1">
                    <p id="59">3) 计算当前栈顶元素<i>R</i><sub><i>i</i>+2</sub>和排序在栈顶元素的后一元素<i>R</i><sub><i>i</i>+3</sub>构成射线与<i>R</i><sub><i>i</i>+2</sub>前的栈内元素构成射线位置关系, 若为顺时针旋转, 则<i>R</i><sub><i>i</i>+2</sub>出栈。</p>
                </div>
                <div class="p1">
                    <p id="60">4) 将<i>R</i><sub><i>i</i>+3</sub>压栈并视为栈顶元素, 重复3) 的操作到所有边界点完成, 栈内元素即为最后图像边界点。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 区域筛选示意图" src="Detail/GetImg?filename=images/JSJY201907043_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 区域筛选示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Schematic diagram of region screening</p>

                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 区域合并示意图" src="Detail/GetImg?filename=images/JSJY201907043_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 区域合并示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Schematic diagram of region merging</p>

                </div>
                <h3 id="63" name="63" class="anchor-tag">3 实验及分析</h3>
                <h4 class="anchor-tag" id="64" name="64">3.1 <b>实验数据</b></h4>
                <div class="p1">
                    <p id="65">实验数据采集自四川省某医院麻醉科, 共获取四腔心切面图像533张, 其中248张图像用于训练集制作, 285张图像用于测试集制作。所有图像处理为256像素×256像素。训练集制作过程中除了将左心室轮廓制作标签, 还将左心室心尖及两个二尖瓣跟三个关键点位置标注出。如图5展示了训练集及标签样例。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">3.2 <b>评价标准</b></h4>
                <div class="p1">
                    <p id="67">本文主要采用了像素精度 (Pixel Accuracy, PA) 和像素交并比 (Mean Intersection over Union, MIoU) 对分割准确度进行度量, 像素精度表达如式 (2) 所示:</p>
                </div>
                <div class="p1">
                    <p id="68"><i>R</i><sub>PA</sub>=<i>P</i><sub>T</sub>/<i>P</i><sub>S</sub>×100%      (2) </p>
                </div>
                <div class="p1">
                    <p id="69">其中:<i>P</i><sub>T</sub>代表预测正确的像素数目, <i>P</i><sub>S</sub>代表总像素数目。</p>
                </div>
                <div class="p1">
                    <p id="70">像素交并比精度如式 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mrow><mtext>Μ</mtext><mtext>Ι</mtext><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mtext>Τ</mtext></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>F</mtext></mrow></msub><mo>+</mo><mi>Ρ</mi><msub><mrow></mrow><mtext>Τ</mtext></msub><mo>+</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Τ</mtext></mrow></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">其中:<i>P</i><sub>T</sub>代表预测正确的像素数目, <i>P</i><sub>TF</sub>将正确标记预测为背景的像素数目, <i>P</i><sub>FT</sub>代表将背景预测为心室的像素数目。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 训练测试样本示例" src="Detail/GetImg?filename=images/JSJY201907043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 训练测试样本示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_073.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Example of training and testing</p>

                </div>
                <div class="p1">
                    <p id="74">由于预测类别只有一类, 本文在评价标准中并未将背景加入计算, 因为背景面积较大, 评价效果若将背景加入不能体现分割效果。</p>
                </div>
                <div class="p1">
                    <p id="75">此外, 由于左心室计算规则和预测区域面积有关, 本文还加入了预测区域和真实区域像素数目误差对比, 如式 (4) 所示:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>r</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mtext>Ρ</mtext></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mtext>S</mtext></msub></mrow><mo>|</mo></mrow><mo>/</mo><mi>Ρ</mi><msub><mrow></mrow><mtext>S</mtext></msub><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中<i>P</i><sub>P</sub>代表预测左心室像素数目。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">3.3 <b>实验及结果</b></h4>
                <div class="p1">
                    <p id="79">实验于Ubantu系统上进行, 代码采用基于Caffe框架实现。在第一步训练FCN网络过程中, 本文选用VGG16在自然图像分类结果的模型初始化网络参数, 然后对网络参数进行训练微调, 学习率固定为10<sup>-14</sup>, 训练轮次10<sup>5</sup>, 网络采用带动量的优化方法。在训练关键点网络中, 由于网络参数数目较小, 本文直接对网络进行训练, 学习率为10<sup>-3</sup>, 迭代轮次10<sup>4</sup>。</p>
                </div>
                <div class="p1">
                    <p id="80">本文分别对比了仅仅采用FCN的分割结果, 利用关键点辅助去除无关区域的结果, 以及最后合并区域后的结果。图6展示了基于FCN的几种不同算法带来的实验结果的样例。图中分别展示了原始图像、标注图像、仅仅采用FCN的分割结果、利用FCN和凸化的结果和本文采用FCN结合关键点筛选区域最后合并的结果。从图6中可以看出, 仅仅采用FCN对目标区域分割容易造成区域分散, 不是同一个区域, 并且有的结果容易包含无关区域, 而从样例1采用阈值筛选区域合并的结果和本文用关键点筛选区域带来的结果看, 仅仅用阈值筛选掉小的无关区域不能保证筛选掉所有无关区域。本文算法带来的结果从视觉上更为接近真实标注的结果。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907043_081.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法实验结果对比" src="Detail/GetImg?filename=images/JSJY201907043_081.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法实验结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907043_081.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Experimental results comparison of different algorithms</p>

                </div>
                <div class="p1">
                    <p id="82">表1展示了不同算法在评价标准下的结果。从表中看出, 只采用FCN得到的结果远低于本文采用关键点筛选区域和凸化带来的效果, 而采用关键点筛选区域也比不采用关键点筛选区域带来的效果要好。在只采用FCN时计算区域面积带来的误差也十分巨大, 而采用了凸化及筛选之后大幅度减小了区域面积误差。本文还对采用U-Net算法得到的结果进行对比, 在只采用U-Net的情况下, 检测精度比仅仅采用FCN网络精度高, 但由于U-Net获取图像较为完整, 利用关键点检测和凸化算法筛选合并区域后效果并不如改进FCN精度高。</p>
                </div>
                <div class="area_img" id="83">
                    <p class="img_tit"><b>表</b>1 <b>不同算法评价标准下的效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Result comparison of different algorithm under evaluation standard</p>
                    <p class="img_note"></p>
                    <table id="83" border="1"><tr><td>算法</td><td>PA</td><td>MIoU</td><td>面积<br />误差</td><td></td><td>算法</td><td>PA</td><td>MIoU</td><td>面积<br />误差</td></tr><tr><td>FCN</td><td>64.43</td><td>58.74</td><td>25.88</td><td></td><td>U-Net+凸化</td><td>73.43</td><td>64.47</td><td>9.55</td></tr><tr><td><br />FCN+凸化</td><td>76.92</td><td>66.51</td><td>7.42</td><td></td><td>FCN改进</td><td><b>77.40</b></td><td><b>67.33</b></td><td><b>7.68</b></td></tr><tr><td><br />U-Net</td><td>66.72</td><td>62.55</td><td>21.43</td><td></td><td>U-Net改进</td><td><b>75.11</b></td><td><b>65.14</b></td><td><b>8.92</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="84">表2展示了基于FCN网络的前提下采用本文关键点算法筛选区域和直接采用真实关键点标签来筛选区域带来的结果。从表中可以看出预测关键点位置和真实关键点位置筛选区域效果相差不大。</p>
                </div>
                <div class="p1">
                    <p id="85">此外, 还采用了对数据进行旋转、对比度变换的数据增广方式进行训练, 测试集图像也采用扩充后的图像进行实验。由于FCN在分割过程中得到的结果仅仅是初步结果, 因此, 如表3所示, 可以看到采用扩充后数据训练结果略微好于未采用数据扩充带来的结果。</p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit"><b>表</b>2 <b>不同关键点筛选效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Results of different keypoint screening</p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td><br />算法</td><td>PA</td><td>MIoU</td><td>面积误差</td></tr><tr><td><br />真实关键点</td><td>77.40</td><td>67.33</td><td>8.38</td></tr><tr><td><br />预测关键点</td><td>77.59</td><td>67.45</td><td>7.69</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="87">
                    <p class="img_tit"><b>表</b>3 <b>数据增广后效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Results before and after data augmentation</p>
                    <p class="img_note"></p>
                    <table id="87" border="1"><tr><td><br />算法</td><td>PA</td><td>MIoU</td><td>面积误差</td></tr><tr><td><br />普通训练</td><td>76.55</td><td>66.68</td><td>8.15</td></tr><tr><td><br />数据扩充</td><td>77.12</td><td>67.81</td><td>7.42</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="88">表4展示了基于FCN网络下程序的运行时间, 实验采用机器内存大小为16 GB, CPU为Intel Core i5- 6600, 显卡为GTX Titan X。表中显示了处理每张图像所需平均耗时。从表4中看出, 本文算法几乎不需要额外花费过多时间就能大幅度提高图像分割精度。</p>
                </div>
                <div class="area_img" id="89">
                    <p class="img_tit"><b>表</b>4 <b>处理每张图平均耗时</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Average processing time per image </p>
                    <p class="img_note">s</p>
                    <table id="89" border="1"><tr><td><br />算法</td><td>耗时</td><td></td><td>算法</td><td>耗时</td></tr><tr><td>FCN</td><td>3.12</td><td></td><td>改进FCN</td><td>3.27</td></tr><tr><td><br />FCN+凸化</td><td>3.24</td><td></td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="90" name="90" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="91">本文提出一种超声图像左心室轮廓提取方案, 该方法通过心室关键点定位去除掉FCN网络分割结果带来的冗余区域, 后再通过图像凸化合并剩余区域的方法获取左心室。实验中证明, 结合图像凸化算法能够将分割结果大幅度优化到更为接近真实结果;此外, 关键点的定位筛选区域也能够将部分FCN错分的区域去除, 免去了手动设置阈值无法保证每幅图像都能正确筛选的问题。本文提出的方案能够有效克服全卷积神经网络在超声图像上分割单一目标时的不足。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="108">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SWGC201802016&amp;v=MzEyNzNZOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVjcvSU5qck1iYkc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 朱锴, 付忠良, 陶攀, 等.基于自适应均值漂移的超声心动图左心室分割方法[J].生物医学工程学杂志, 2018, 35 (2) :273-279. (ZHU K, FU Z, TAO P, et al.Left ventricle segmentation in echocardiography based on adaptive mean shift[J].Journal of Biomedical Engineering, 2018, 35 (2) :273-279.) 
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automated breast lesion segmentation in ultrasound images">

                                <b>[2]</b> SADEK I, ELAWADY M, STEFANOVSKI V.Automated breast lesion segmentation in ultrasound images[J].ArXiv Preprint, 2016, 2016:1609.08364.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLLG201601005&amp;v=MTk5MjBJU0hIYWJHNEg5Zk1ybzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvZ1Y3L0k=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 朱永杰, 邱天爽.基于改进LGDF模型的超声图像自动分割方法[J].大连理工大学学报, 2016, 56 (1) :28-34. (ZHU Y J, QIU T S.Automated segmentation method for ultrasound image based on improved LGDF model[J].Journal of Dalian University of Technology, 2016, 56 (1) :28-34.) 
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning-based automatic breast tumor detection and segmentation in ultrasound images">

                                <b>[4]</b> JIANG P, PENG J, ZHANG G, et al.Learning-based automatic breast tumor detection and segmentation in ultrasound images[C]// Proceedings of the 2012 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2012:1587-1590.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic Resonance">

                                <b>[5]</b> NGO T A, LU Z, CARNEIRO G.Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance[J].Medical Image Analysis, 2017, 35:159-171.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201605013&amp;v=MjM3MDRackc0SDlmTXFvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVjcvSU5pN0g=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 纪祥虎, 高思聪, 黄志标, 等.基于Centripetal Catmull-Rom曲线的经食道超声心动图左心室分割方法[J].四川大学学报 (工程科学版) , 2016, 48 (5) :84-90. (JI X H, GAO S C, HUANG Z B, et al.Left ventricle segmentation in transesophageal echocardiography based on Centripetal Catmull-Rom curve[J].Journal of Sichuan University (Engineering Science Edition) , 2016, 48 (5) :84-90.) 
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Left ventricle segmentation in fetal echocardiography using a multi-texture active appearance model based on the steered Hermite transform">

                                <b>[7]</b> VARGAS-QUINTERO L, ESCALANTE-RAMÍREZ B, CAMARGO M L, et al.Left ventricle segmentation in fetal echocardiography using a multi-texture active appearance model based on the steered Hermite transform[J].Computer Methods and Programs in Biomedicine, 2016, 137:231-245.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[8]</b> LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional random fields as recurrent neural networks">

                                <b>[9]</b> ZHENG S, JAYASUMANA S, ROMERA-PAREDES B, et al.Conditional random fields as recurrent neural networks[C]// ICCV'15:Proceedings of the 2015 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2015:1529-1537.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">

                                <b>[10]</b> HE K, GKIOXARI G, DOLLAR P, et al.Mask R-CNN[C]// ICCV 2017:Proceedings of the 2017 IEEE International Conference on Computer Vision.Washington, DC:IEEE Computer Society, 2017:2961-2969.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">

                                <b>[11]</b> RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmentation[C]// MICCAI 2015:Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention, LNCS 9351.Berlin:Springer, 2015:234-241.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation label propagation using deep convolutional neural networks and dense conditional random field">

                                <b>[12]</b> GAO M, XU Z, LU L, et al.Segmentation label propagation using deep convolutional neural networks and dense conditional random field[C]// Proceedings of the 2016 IEEE International Symposium on Biomedical Imaging.Piscataway, NJ:IEEE, 2016:1265-1268.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks">

                                <b>[13]</b> LI Y, YI G, WANG Y, et al.Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks[J].IEEE Transactions on Biomedical Engineering, 2017, 64 (8) :1886-1895.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201704011&amp;v=MDM1MDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9nVjcvSVB5cmZiTEc0SDliTXE0OUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 詹曙, 梁植程, 谢栋栋.前列腺磁共振图像分割的反卷积神经网络方法[J].中国图象图形学报, 2017, 22 (4) :516-522. (ZHAN S, LIANG Z C, XIE D D.Deconvolutional neural network for prostate MRI segmentation[J].Journal of Image and Graphics, 2017, 22 (4) :516-522.) 
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A unified framework integrating recurrent fully-convolutional networks and optical flow for segmentation of the left ventricle in echocardiography data">

                                <b>[15]</b> JAFARI M H, GIRGIS H, LIAO Z, et al.A unified framework integrating recurrent fully-convolutional networks and optical flow for segmentation of the left ventricle in echocardiography data[C]// Proceedings of the 2018 International Workshop on Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support.Berlin:Springer, 2018:29-37.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[16]</b> SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].ArXiv Preprint, 2014, 2014:1409.1556.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for determining the convex hull of a finite planar set">

                                <b>[17]</b> GRAHAM R L.An efficient algorithm for determining the convex hull of a finite planar set[J].Information Processing Letters, 1978, 7 (1) :53-55.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907043" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907043&amp;v=MDU4NjBGckNVUjdxZlp1WnNGeS9nVjcvSUx6N0JkN0c0SDlqTXFJOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
