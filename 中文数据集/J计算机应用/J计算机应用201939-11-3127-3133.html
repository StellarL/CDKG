<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136444424815000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJY201911005%26RESULT%3d1%26SIGN%3d3bTWoUGROxs5VXqyan82snfCt6g%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911005&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911005&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911005&amp;v=MDA1MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMejdCZDdHNEg5ak5ybzlGWVlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="1 相关概念 ">1 相关概念</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="1.1 &lt;b&gt;中文文本预处理&lt;/b&gt;">1.1 <b>中文文本预处理</b></a></li>
                                                <li><a href="#57" data-title="1.2 &lt;b&gt;文本特征选择方法&lt;/b&gt;">1.2 <b>文本特征选择方法</b></a></li>
                                                <li><a href="#80" data-title="1.3 &lt;b&gt;构建情感词向量&lt;/b&gt;">1.3 <b>构建情感词向量</b></a></li>
                                                <li><a href="#88" data-title="1.4 &lt;b&gt;三支决策理论&lt;/b&gt;">1.4 <b>三支决策理论</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="2 三支决策特征选择算法 ">2 三支决策特征选择算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#92" data-title="2.1 &lt;b&gt;算法思路&lt;/b&gt;">2.1 <b>算法思路</b></a></li>
                                                <li><a href="#121" data-title="2.2 &lt;b&gt;算法描述&lt;/b&gt;">2.2 <b>算法描述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#171" data-title="3 实验设计和分析 ">3 实验设计和分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#172" data-title="3.1 &lt;b&gt;数据集&lt;/b&gt;">3.1 <b>数据集</b></a></li>
                                                <li><a href="#176" data-title="3.2 &lt;b&gt;评估方法&lt;/b&gt;">3.2 <b>评估方法</b></a></li>
                                                <li><a href="#182" data-title="3.3 &lt;b&gt;实验方案&lt;/b&gt;">3.3 <b>实验方案</b></a></li>
                                                <li><a href="#186" data-title="3.4 &lt;b&gt;实验结果&lt;/b&gt;">3.4 <b>实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="4 结语 ">4 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;特征和类的关系示意表&lt;/b&gt;"><b>表</b>1 <b>特征和类的关系示意表</b></a></li>
                                                <li><a href="#84" data-title="图1 构建情感词典">图1 构建情感词典</a></li>
                                                <li><a href="#86" data-title="图2 情感权值规则">图2 情感权值规则</a></li>
                                                <li><a href="#170" data-title="图3 面向不平衡文本情感分类的三支决策特征选择算法流程">图3 面向不平衡文本情感分类的三支决策特征选择算法流程</a></li>
                                                <li><a href="#174" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;实验数据集信息&lt;/b&gt;"><b>表</b>2 <b>实验数据集信息</b></a></li>
                                                <li><a href="#188" data-title="&lt;b&gt;表&lt;/b&gt;3 TWD-FS&lt;b&gt;在&lt;/b&gt;COAE2013“&lt;b&gt;蒙牛”数据各维度下的&lt;/b&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;b&gt;值实验结果&lt;/b&gt;"><b>表</b>3 TWD-FS<b>在</b>COAE2013“<b>蒙牛”数据各维度下的</b><i>F</i><sub>1</sub><b>值实验结果</b></a></li>
                                                <li><a href="#190" data-title="图4 TWD-FS在COAE2013“蒙牛”数据各维度下选择出的特征数">图4 TWD-FS在COAE2013“蒙牛”数据各维度下选择出的特征数</a></li>
                                                <li><a href="#194" data-title="图5 六种特征选择算法在COAE2013“蒙牛”数据上的实验结果对比">图5 六种特征选择算法在COAE2013“蒙牛”数据上的实验结果对比</a></li>
                                                <li><a href="#196" data-title="&lt;b&gt;表&lt;/b&gt;4 TWD-FS&lt;b&gt;和其他特征选择算法在不同数据集上的对比结果&lt;/b&gt;"><b>表</b>4 TWD-FS<b>和其他特征选择算法在不同数据集上的对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="228">


                                    <a id="bibliography_1" title=" 赵立东.面向文本情感分类的非平衡数据采样方法研究[D].太原:山西大学,2013.(ZHAO L D.Research on imbalanced data sampling methods for text sentiment classification[D].Taiyuan:Shanxi University,2013.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013325090.nh&amp;v=MTU1MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm5VYnZCVkYyNkhiQzZHOUhGcjVFYlBJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         赵立东.面向文本情感分类的非平衡数据采样方法研究[D].太原:山西大学,2013.(ZHAO L D.Research on imbalanced data sampling methods for text sentiment classification[D].Taiyuan:Shanxi University,2013.)
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_2" title=" 田锋,兰田,CHAO Kuo-Ming,等.领域实例迁移的交互文本非平衡情感分类方法[J].西安交通大学学报,2015,49(4):67-72.(TIAN F,LAN T,CHAO K-M,et al.An unbalanced emotion classification method foe interactive texts based on multiple-domain instance transfer[J].Journal of Xi’an Jiaotong University,2015,49(4):67-72.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201504011&amp;v=MTU1NzR6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2QlBTekJlckc0SDlUTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         田锋,兰田,CHAO Kuo-Ming,等.领域实例迁移的交互文本非平衡情感分类方法[J].西安交通大学学报,2015,49(4):67-72.(TIAN F,LAN T,CHAO K-M,et al.An unbalanced emotion classification method foe interactive texts based on multiple-domain instance transfer[J].Journal of Xi’an Jiaotong University,2015,49(4):67-72.)
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_3" title=" 王中卿.基于不平衡数据的情感分类方法研究[D].苏州:苏州大学,2012.(WANG Z Q.Research on sentiment classification based-upon imbalanced data[D].Soochow:Soochow University,2012.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012387131.nh&amp;v=MTA5ODlkRFBycEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJWRjI2SExDd0c=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王中卿.基于不平衡数据的情感分类方法研究[D].苏州:苏州大学,2012.(WANG Z Q.Research on sentiment classification based-upon imbalanced data[D].Soochow:Soochow University,2012.)
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_4" title=" 王杰,李德玉,王素格.面向非平衡文本情感分类的TSF特征选择方法[J].计算机科学,2016,43(10):206-210.(WANG J,LI D Y,WANG S G.TSF feature selection method for imbalanced text sentiment classification[J].Computer Science,2016,43(10):206-210.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201610039&amp;v=MjIwOTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2Qkx6N0JiN0c0SDlmTnI0OUc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         王杰,李德玉,王素格.面向非平衡文本情感分类的TSF特征选择方法[J].计算机科学,2016,43(10):206-210.(WANG J,LI D Y,WANG S G.TSF feature selection method for imbalanced text sentiment classification[J].Computer Science,2016,43(10):206-210.)
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_5" title=" WASIKOWSKI M,CHEN X.Combating the small sample class imbalance problem using feature selection[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2010,22(10):1388-1400." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combating the small sample class imbalance problem using feature selection">
                                        <b>[5]</b>
                                         WASIKOWSKI M,CHEN X.Combating the small sample class imbalance problem using feature selection[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2010,22(10):1388-1400.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_6" title=" YIN L,GE Y,XIAO K.et al.Feature selection for high-dimensional imbalanced data[J].Neurocomputing,2013,105(4):3-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913301&amp;v=Mjc2MjBxbzlFYmVvTUQzdzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVndXYmhzPU5pZk9mYks3SHRETg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         YIN L,GE Y,XIAO K.et al.Feature selection for high-dimensional imbalanced data[J].Neurocomputing,2013,105(4):3-11.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_7" title=" YU H,WANG X,WANG G.A semi-supervised three-way clustering framework for multi-view data[C]// IJCRS 2017:International Joint Conference on Rough Sets.Berlin:Springer,2017:313-325." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A semi-supervised three-way clustering framework for multi-view data">
                                        <b>[7]</b>
                                         YU H,WANG X,WANG G.A semi-supervised three-way clustering framework for multi-view data[C]// IJCRS 2017:International Joint Conference on Rough Sets.Berlin:Springer,2017:313-325.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_8" title=" 张梅山,邓知龙,车万翔,等.统计与词典相结合的领域自适应中文分词[J].中文信息学报,2012,26(2):8-12.(ZHANG M S,DENG Z L,CHE W X,et al.Combining statistical model and dictionary for domain adaption of Chinese word segmentation[J].Journal of Chinese Information Processing,2012,26(2):8-12.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201202001&amp;v=MTQ4MTh2QktDallmYkc0SDlQTXJZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         张梅山,邓知龙,车万翔,等.统计与词典相结合的领域自适应中文分词[J].中文信息学报,2012,26(2):8-12.(ZHANG M S,DENG Z L,CHE W X,et al.Combining statistical model and dictionary for domain adaption of Chinese word segmentation[J].Journal of Chinese Information Processing,2012,26(2):8-12.)
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_9" title=" 史庆伟,从世源,唐晓亮.LSI_LDA:一种混合特征降维方法[J].计算机应用研究,2017,34(8):2269-2273.(SHI Q W,CONG S Y,TANG X L.LSI_LDA:mixture method for feature dimensionality reduction[J].Application Research of Computers,2017,34(8):2269-2273.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201708007&amp;v=MjUwNjZxZlp1WnNGeW5uVWJ2Qkx6N1NaTEc0SDliTXA0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         史庆伟,从世源,唐晓亮.LSI_LDA:一种混合特征降维方法[J].计算机应用研究,2017,34(8):2269-2273.(SHI Q W,CONG S Y,TANG X L.LSI_LDA:mixture method for feature dimensionality reduction[J].Application Research of Computers,2017,34(8):2269-2273.)
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_10" title=" AL SHAMSI F,AUNG Z.Automatic patent classification by a three-phase model with document frequency matrix and boosted tree[C]// Proceedings of the 2016 5th International Conference on Electronic Devices,Systems and Applications.Piscataway:IEEE,2016:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic patent classification by a three-phase model with document frequency matrix and boosted tree">
                                        <b>[10]</b>
                                         AL SHAMSI F,AUNG Z.Automatic patent classification by a three-phase model with document frequency matrix and boosted tree[C]// Proceedings of the 2016 5th International Conference on Electronic Devices,Systems and Applications.Piscataway:IEEE,2016:1-4.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_11" title=" IBRAHIM O A S,LANDA-SILVA D.Term frequency with average term occurrences for textual information retrieval[J].Soft Computing,2016,20(8):3045-3061." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Term frequency with average term occurrences for textual information retrieval">
                                        <b>[11]</b>
                                         IBRAHIM O A S,LANDA-SILVA D.Term frequency with average term occurrences for textual information retrieval[J].Soft Computing,2016,20(8):3045-3061.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_12" title=" CHEN K,ZHANG Z,LONG J,et al.Turning from TF-IDF to TF-IGM for term weighting in text classification[J].Expert Systems with Applications:an International Journal,2016,66(C):245-260." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Turning from TF-IDF to TF-IGM for term weighting in text classification">
                                        <b>[12]</b>
                                         CHEN K,ZHANG Z,LONG J,et al.Turning from TF-IDF to TF-IGM for term weighting in text classification[J].Expert Systems with Applications:an International Journal,2016,66(C):245-260.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_13" title=" 毛临川,吴根秀,吴恒,等.基于信息增益的最优组合因子Fisher判别法[J].计算机工程与应用,2016,52(19):94-96.(MAO L C,WU G X,WU H,et al.Optimal combination of factor Fisher discrimination method based on information gain[J].Computer Engineering and Applications,2016,52(19):94-96.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201619018&amp;v=MTQ2NDk5Zk5wbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMejdNYWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         毛临川,吴根秀,吴恒,等.基于信息增益的最优组合因子Fisher判别法[J].计算机工程与应用,2016,52(19):94-96.(MAO L C,WU G X,WU H,et al.Optimal combination of factor Fisher discrimination method based on information gain[J].Computer Engineering and Applications,2016,52(19):94-96.)
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_14" title=" 李平,戴月明,王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程,2017,43(12):192-196.(LI P,DAI Y M,WANG Y.Text sentiment analysis based on hybrid chi-square statistic and logistics regression[J].Computer Engineering,2017,43(12):192-196.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712035&amp;v=Mjk4OTNZOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2Qkx6N0JiYkc0SDliTnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         李平,戴月明,王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程,2017,43(12):192-196.(LI P,DAI Y M,WANG Y.Text sentiment analysis based on hybrid chi-square statistic and logistics regression[J].Computer Engineering,2017,43(12):192-196.)
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_15" title=" 段宏湘,张秋余,张墨逸.基于归一化互信息的FCBF特征选择算法[J].华中科技大学学报(自然科学版),2017,45(1):52-56.(DUAN H X,ZHANG Q Y,ZHANG M Y.FCBF algorithm based on normalized mutual information for feature selection[J].Journal of Huazhong University of Science and Technology (Natural Science Edition),2017,45(1):52-56.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201701010&amp;v=MTE5NDc0SDliTXJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2QkxUZkhhYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         段宏湘,张秋余,张墨逸.基于归一化互信息的FCBF特征选择算法[J].华中科技大学学报(自然科学版),2017,45(1):52-56.(DUAN H X,ZHANG Q Y,ZHANG M Y.FCBF algorithm based on normalized mutual information for feature selection[J].Journal of Huazhong University of Science and Technology (Natural Science Edition),2017,45(1):52-56.)
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_16" title=" 张辉宜,谢业名,袁志祥,等.一种基于概率的卡方特征选择方法[J].计算机工程,2016,42(8):194-198.(ZHANG H Y,XIE Y M,YUAN Z X,et al.A method of CHI-square feature selection based on probability[J].Computer Engineering,2016,42(8):194-198.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201608036&amp;v=MjY3NjNCYmJHNEg5Zk1wNDlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMejc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         张辉宜,谢业名,袁志祥,等.一种基于概率的卡方特征选择方法[J].计算机工程,2016,42(8):194-198.(ZHANG H Y,XIE Y M,YUAN Z X,et al.A method of CHI-square feature selection based on probability[J].Computer Engineering,2016,42(8):194-198.)
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_17" title=" 王晨曦,林耀进,刘景华,等.基于最近邻互信息的特征选择算法[J].计算机工程与应用,2016,52(18):74-78.(WANG C X,LIN Y J,LIU J H,et al.Feature selection algorithm based on nearest-neighbor mutual information[J].Computer Engineering and Applications,2016,52(18):74-78.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201618016&amp;v=MTU1MjNVUjdxZlp1WnNGeW5uVWJ2Qkx6N01hYkc0SDlmTnA0OUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         王晨曦,林耀进,刘景华,等.基于最近邻互信息的特征选择算法[J].计算机工程与应用,2016,52(18):74-78.(WANG C X,LIN Y J,LIU J H,et al.Feature selection algorithm based on nearest-neighbor mutual information[J].Computer Engineering and Applications,2016,52(18):74-78.)
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_18" title=" 吴金源,冀俊忠,赵学武,等.基于特征选择技术的情感词权重计算[J].北京工业大学学报,2016,42(1):142-151.(WU J Y,JI J Z,ZHAO X W,et al.Weight calculation of emotional word based on feature selection technique[J].Journal of Beijing University of Technology,2016,42(1):142-151.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJGD201601022&amp;v=MjA5Njg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2Qkp5Zk1hckc0SDlmTXJvOUhab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         吴金源,冀俊忠,赵学武,等.基于特征选择技术的情感词权重计算[J].北京工业大学学报,2016,42(1):142-151.(WU J Y,JI J Z,ZHAO X W,et al.Weight calculation of emotional word based on feature selection technique[J].Journal of Beijing University of Technology,2016,42(1):142-151.)
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_19" title=" YAO Y.The superiority of three-way decisions in probabilistic rough set models[J].Information Sciences,2011,181(6):1080-1096." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601416866&amp;v=MjI4NzdUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZ3V2Jocz1OaWZPZmJLN0h0RE5xWTlFWU9vSkJIby9vQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         YAO Y.The superiority of three-way decisions in probabilistic rough set models[J].Information Sciences,2011,181(6):1080-1096.
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_20" title=" 姚海英.中文文本分类中卡方统计特征选择方法和TF-IDF权重计算方法的研究[D].长春:吉林大学,2016.(YAO H Y.Research on chi-square statistic feature selection method and TF-IDF feature weighting method for chinese text classification[D].Changchun:Jilin University,2016.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016090164.nh&amp;v=MTQ2ODdmWnVac0Z5bm5VYnZCVkYyNkdMT3hIdERLcTVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         姚海英.中文文本分类中卡方统计特征选择方法和TF-IDF权重计算方法的研究[D].长春:吉林大学,2016.(YAO H Y.Research on chi-square statistic feature selection method and TF-IDF feature weighting method for chinese text classification[D].Changchun:Jilin University,2016.)
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_21" title=" 李燕,卫志华,徐凯.基于Lasso算法的中文情感混合特征选择方法研究[J].计算机科学,2018,45(1):39-46.(LI Y,WEI Z H,XU K.Hybrid feature selection method of chinese emotional characteristics based on Lasso algorithm[J].Computer Science,2018,45(1):39-46.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201801009&amp;v=MDQ1MTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2Qkx6N0JiN0c0SDluTXJvOUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         李燕,卫志华,徐凯.基于Lasso算法的中文情感混合特征选择方法研究[J].计算机科学,2018,45(1):39-46.(LI Y,WEI Z H,XU K.Hybrid feature selection method of chinese emotional characteristics based on Lasso algorithm[J].Computer Science,2018,45(1):39-46.)
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_22" title=" 张越兵,苗夺谦,张志飞.基于三支决策的多粒度文本情感分类模型[J].计算机科学,2017,44(12):188-193.(ZHANG Y B,MIAO D Q,ZHANG Z F.Multi-granularity text sentiment classification model based on three-way decisions[J].Computer Science,2017,44(12):188-193.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201712035&amp;v=MTk4NTdidkJMejdCYjdHNEg5Yk5yWTlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         张越兵,苗夺谦,张志飞.基于三支决策的多粒度文本情感分类模型[J].计算机科学,2017,44(12):188-193.(ZHANG Y B,MIAO D Q,ZHANG Z F.Multi-granularity text sentiment classification model based on three-way decisions[J].Computer Science,2017,44(12):188-193.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-07-05 11:24</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(11),3127-3133 DOI:10.11772/j.issn.1001-9081.2019050822            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向不平衡文本情感分类的三支决策特征选择方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E5%BF%97%E8%B6%85&amp;code=40895333&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万志超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%B3%B0&amp;code=11234746&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E7%BB%B4%E6%96%8C&amp;code=11111003&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓维斌</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0174747&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆邮电大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E9%87%8D%E5%BA%86%E5%B8%82%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E9%87%8D%E5%BA%86%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算智能重庆市重点实验室(重庆邮电大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统的特征选择方法在面对不平衡文本情感倾向性分类时会有很大的局限性,这种局限性主要体现在特征维数过高、特征过于稀疏和特征分布不平衡,这会使得分类的准确度大幅度下降。根据不平衡文本情感特征分布的特点,结合三支决策的思想,提出了一种面向不平衡文本情感分类的三支决策特征选择方法(TWD-FS)。该方法将两种有监督特征选择方法相结合,将选择出的特征词进一步筛选,使得最终选择出的特征词同时满足类间离散度最大和类内离散度最小的特点,有效地减少了特征词的数量,降低了特征维度;此外,通过组合正负类情感特征,缓解了情感特征的不平衡性,有效提高了不平衡样本中少数类情感的分类效果。在COAE2013中文微博非平衡数据集等多个数据集上的实验结果表明,所提的特征选择算法TWD-FS可以有效提高不平衡文本情感分类的准确度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%96%87%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不平衡文本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征选择;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%89%E7%9B%91%E7%9D%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">有监督;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E6%94%AF%E5%86%B3%E7%AD%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三支决策;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *万志超(1995—),男,湖北汉川人,硕士研究生,主要研究方向:自然语言处理、机器学习,电子邮箱1573406913@qq.com;
                                </span>
                                <span>
                                    胡峰(1978—),男,湖北天门人,教授,博士,主要研究方向:粗糙集、数据挖掘;;
                                </span>
                                <span>
                                    邓维斌(1978—),男,重庆人,教授,博士,主要研究方向:不确定性决策方法。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-06</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目(2018YFC0832100,2018YFC0832102);</span>
                                <span>国家自然科学基金资助项目(61533020,61751312,61309014);</span>
                                <span>重庆市基础科学与前沿技术研究专项(cstc2017jcyjAX0408);</span>
                    </p>
            </div>
                    <h1><b>Feature selection method for imbalanced text sentiment classification based on three-way decisions</b></h1>
                    <h2>
                    <span>WAN Zhichao</span>
                    <span>HU Feng</span>
                    <span>DENG Weibin</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Chongqing University of Posts and Telecommunications</span>
                    <span>Chongqing Key Laboratory of Computational Intelligence (Chongqing University of Posts and Telecommunications)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional feature selection methods have great limitations in the imbalanced text sentiment tendency classification, which are mainly reflected in the high feature dimension, the sparse characteristics, and the imbalanced feature distribution, making the reduction of classification accuracy. According to the distribution of emotional features of imbalanced texts, a Three-Way Decisions-Feature Selection algorithm(TWD-FS) was proposed for imbalanced text sentiment classification based on three-way decisions. In order to reduce the number of feature words and reduce the feature dimension, two supervised feature selection methods were combined, and the feature words selected were further filtered in order to make them satisfy the characteristics of the maximum between-class scatter degree and the minimum within-class scatter degree. In addition, the imbalance of sentiment features was decreased and the classification accuracy of minority sentiment was effectively improved by combining positive and negative sentiment features. The experimental results on COAE2013 Chinese microblog imbalanced datasets and other datasets show that the proposed feature selection algorithm TWD-FS can effectively improve the accuracy of imbalanced text sentiment classification.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=imbalanced%20text&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">imbalanced text;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=supervised&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">supervised;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-way%20decisions&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-way decisions;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WAN Zhichao, born in 1995, M. S. candidate. His research interests include nature language processing, machine learning. ;
                                </span>
                                <span>
                                    HU Feng, born in 1978, Ph. D., professor. His research interests include rough set, data mining. ;
                                </span>
                                <span>
                                    DENG Weibin, born in 1978, Ph. D., professor. His research interests include decision making under uncertainty.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-05-06</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Key Research and Development Program of China(2018YFC0832100,2018YFC0832102);</span>
                                <span>the National Natural Science Foundation of China(61751312,61533020,61309014);</span>
                                <span>the Chongqing Research Program of Basic Research and Frontier Technology(cstc2017jcyjAX0408);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="48">不平衡文本情感倾向性分析在自然语言处理领域是一个热点研究问题,目前主要的研究方法分为文本采样算法的改进和特征选择算法的优化两种。</p>
                </div>
                <div class="p1">
                    <p id="49">在中文文本采样算法的改进方面,赵立东<citation id="272" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>针对非平衡中文文本情感分类进行数据层面的改进,提出了基于聚类的下采样算法(Cluster-based Under-sampling Algorithm, CUA)和类边界区域的裁剪(Boundary Region Cutting, BRC)的混合采样算法;田锋等<citation id="273" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>利用目标数据集和源数据集的共性特征,提出面向目标数据集实例迁移的数据层面采样方法,缓解交互文本的非平衡问题;王中卿<citation id="274" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出了一种基于样本集成的采样方法,在基于聚类的欠采样框架下利用中心向量平滑解决不平衡情感分类的问题。</p>
                </div>
                <div class="p1">
                    <p id="50">在特征选择算法改进方面,王杰等<citation id="275" type="reference"><link href="234" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出一种新的双边Fisher特征选择算法TSF(Two-Sided Fisher feature selection),通过组合正相关和负相关特征,缓解了特征的不平衡分布;Wasikowski等<citation id="276" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了FAST(Feature Assessment Sliding Thresholds)特征选择算法,在样本数较少的不平衡文本情感倾向性分析中表现较好,但是该算法需要对每一个特征训练一个分类器,大幅增加了算法的复杂度,不适应大规模数据集的应用;Yin等<citation id="277" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种基于类别分解的特征选择算法,同时还提出了一种基于Hellinger距离的特征选择方法,在非平衡文本情感倾向性分类中取得了较好的分类准确度。</p>
                </div>
                <div class="p1">
                    <p id="51">上述研究方法都只是从某一个方面对特征选择算法进行改进,只考虑有监督算法或者半监督算法单方面的不足,导致选择出来的特征不论是类间离散度还是类内聚集度效果都较差;同时单方面考虑特征词对不平衡文本情感倾向性分类的影响,不能有效缓解特征的高维性和特征的不平衡分布,最终使得情感分类的准确率不理想。</p>
                </div>
                <div class="p1">
                    <p id="52">三支决策是一种更一般的、更有效的决策和信息处理模式。三支决策采用不承诺的决策选项,引入两个评价函数<i>α</i>和<i>β</i>将整体<i>C</i>划分为三个部分,然后基于这三个部分进行处理<citation id="278" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。在处理实际应用问题时,会灵活强调这三个部分中的一个或两个,从而避免了错误接受或者错误拒绝造成的损失。基于三支决策这种有效的处理模式,本文结合三支决策的思想,将两个有监督的特征选择算法作为两个评价函数,利用三支决策的划分处理模式筛选出类间离散度和类内聚集度效果更好的特征词,从而降低不平衡文本情感倾向性分析中的特征的维度和不平衡度。</p>
                </div>
                <h3 id="53" name="53" class="anchor-tag">1 相关概念</h3>
                <h4 class="anchor-tag" id="54" name="54">1.1 <b>中文文本预处理</b></h4>
                <div class="p1">
                    <p id="55">针对中文文本的自然语言处理研究首先要进行的就是文本预处理,因为中文文本不能像英文文本那样可以用简单的空格和标点符号完成分词;其次,中文文本的编码是Unicode,还需要对编码进行处理;最后,中文文本中存在很多对情感倾向性分类没有作用的词和标点符号,需要进一步处理。</p>
                </div>
                <div class="p1">
                    <p id="56">中文文本预处理主要是对中文文本进行分词、编码和去停用词。本文采用的是LTP(Language Technology Platform)分词器<citation id="279" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>对中文文本进行分词处理,并在分词过程中使用哈尔滨工业大学停用词表来过滤文本中的无效词和部分标点符号。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">1.2 <b>文本特征选择方法</b></h4>
                <div class="p1">
                    <p id="58">在中文文本向量空间模型中,表示文本的特征项可以选择字、词、短语作为特征,所对应的特征空间维数过高。为了过滤掉一些对文本分类贡献极低的特征词,特征降维的主要方法有特征选择和特征抽取两种:特征选择是根据某一个特征词<i>t</i>对类别<i>C</i>的贡献度,从原始特征集合中选择出一个子集;特征抽取主要考虑的是特征之间的语义相关性,以及特征的类间离散度和类内聚集度,从而实现对特征集合的压缩<citation id="280" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">中文文本特征选择算法分为有监督特征选择算法和无监督特征选择算法两类。无监督特征选择算法有:文档频 (Document Frequency, DF)<citation id="281" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、绝对词频(Term Frequency, TF)<citation id="282" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、词频-逆文档频(Term Frequency-Inverse Document Frequency, TF-IDF)<citation id="283" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>等。有监督特征选择算法主要包括:信息增益(Information Gain, IG)法<citation id="284" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、卡方统计量(CHI-square statistics, CHI)<citation id="285" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、互信息(Mutual Information, MI)法<citation id="286" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>等。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60">1.2.1 双向卡方统计量</h4>
                <div class="p1">
                    <p id="61">卡方统计量(CHI)是一种表示特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间的相关联程度的特征选择算法,它的基础是假设特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间符合具有一阶自由度的<i>x</i><sup>2</sup>分布<citation id="287" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>,因此,特征词<i>t</i><sub><i>i</i></sub>对类别<i>C</i><sub><i>j</i></sub>的卡方统计值越高,它与该类之间的相关性越大,携带的类别信息也就越多,反之则越少。特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>关系如表1所示。</p>
                </div>
                <div class="area_img" id="62">
                    <p class="img_tit"><b>表</b>1 <b>特征和类的关系示意表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Relationships between features and classes</p>
                    <p class="img_note"></p>
                    <table id="62" border="1"><tr><td rowspan="2"><br />特征词</td><td colspan="2"><br />类别</td></tr><tr><td><br /><i>C</i><sub><i>j</i></sub></td><td>～<i>C</i><sub><i>j</i></sub></td></tr><tr><td><br /><i>t</i><sub><i>i</i></sub></td><td><i>A</i><sub><i>i</i>, <i>j</i></sub></td><td><i>B</i><sub><i>i</i>, <i>j</i></sub></td></tr><tr><td><br />～<i>t</i><sub><i>i</i></sub></td><td><i>C</i><sub><i>i</i>, <i>j</i></sub></td><td><i>D</i><sub><i>i</i>, <i>j</i></sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="63">表1中,<i>t</i><sub><i>i</i></sub>表示含有特征词<i>t</i><sub><i>i</i></sub>的文本;～<i>t</i><sub><i>i</i></sub>表示不含有特征词<i>t</i><sub><i>i</i></sub>的文本;<i>C</i><sub><i>j</i></sub>表示属于类别<i>C</i><sub><i>j</i></sub>的文本;～<i>C</i><sub><i>j</i></sub>表示不属于类别<i>C</i><sub><i>j</i></sub>的文本;<i>A</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示含有特征词<i>t</i><sub><i>i</i></sub>且属于类别<i>C</i><sub><i>j</i></sub>的文档的数量;<i>B</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示含有特征词<i>t</i><sub><i>i</i></sub>,但不属于类别<i>C</i><sub><i>j</i></sub>的文档的数量;<i>C</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示文本中不含有特征词<i>t</i><sub><i>i</i></sub>,但属于类别<i>C</i><sub><i>j</i></sub>的文档的数量;<i>D</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示文本中不含有特征词<i>t</i><sub><i>i</i></sub>且不属于类别<i>C</i><sub><i>j</i></sub>的文档的数量。可以看出<i>A</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>和<i>D</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>是正相关,<i>B</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>和<i>C</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>是负相关。</p>
                </div>
                <div class="p1">
                    <p id="64">特征词<i>t</i><sub><i>i</i></sub>对类别<i>C</i><sub><i>j</i></sub>的CHI值为:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>Ν</mi><mo>×</mo><mo stretchy="false">(</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo stretchy="false">(</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>+</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>+</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>+</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>+</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">考虑到特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间存在正相关和负相关关系,以及在文本情感倾向性分析中,如果情感类别只有正、负两类,由于CHI值计算公式的分子会导致在正、负两类情感中都出现的特征词计算出来CHI值是相同的。本文对CHI特征选择算法进行改进,引入修正因子<i>δ</i>(<i>t</i><sub><i>i</i></sub>),</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>δ</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>sgn</mi></mrow><mo stretchy="false">(</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>,</mo></mtd><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mo>-</mo><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>×</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68"><i>δ</i>(<i>t</i><sub><i>i</i></sub>)值的正负性和改进后的特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间的正负相关关系形同,引入修正因子后<i>δ</i>(<i>t</i><sub><i>i</i></sub>)的双向卡方统计量(Two-sided CHI, TCHI)为:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>TCHI</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)=<i>x</i><sup>2</sup>×<i>δ</i>(<i>t</i><sub><i>i</i></sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="70">传统的CHI更倾向于选择和类别负相关的特征词,当<i>A</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>×<i>D</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>≫<i>B</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>×<i>C</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>时,传统卡方统计量计算出来CHI值同样较高,这部分特征词将在特征选择后留下来,但这些特征词和类别是负相关的,会对分类结果造成负影响。引入修正因子<i>δ</i>(<i>t</i><sub><i>i</i></sub>)后的TCHI,会将这些和类别呈现负相关的特征词的TCHI值置为负值,可以有效地将这些负相关的特征词排除。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">1.2.2 互信息法</h4>
                <div class="p1">
                    <p id="72">互信息在统计学中是衡量两个变量相关性的方法<citation id="288" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,在文本情感倾向性分类的应用中,互信息可以用来衡量特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间的关联程度,以便选择出类别代表度最优的特征。特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间的相关性和互信息值成正比,互信息增大,特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>之间的关联程度增大。那么特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>的互信息可以由式(4)计算:</p>
                </div>
                <div class="p1">
                    <p id="73"><i>MI</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)=lb<mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mi>p</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mtext>l</mtext><mtext>b</mtext></mrow></math></mathml><mathml id="200"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="74">式中:</p>
                </div>
                <div class="p1">
                    <p id="75"><i>p</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)=<i>N</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)/<i>N</i>      (5)</p>
                </div>
                <div class="p1">
                    <p id="76"><i>p</i>(<i>t</i><sub><i>i</i></sub>)=<i>N</i>(<i>t</i><sub><i>i</i></sub>)/<i>N</i>      (6)</p>
                </div>
                <div class="p1">
                    <p id="77"><i>p</i>(<i>C</i><sub><i>j</i></sub>)=<i>N</i>(<i>C</i><sub><i>j</i></sub>)/<i>N</i>      (7)</p>
                </div>
                <div class="p1">
                    <p id="78">其中:<i>N</i>(<i>t</i><sub><i>i</i></sub>)表示文本数据集中包含特征<i>t</i><sub><i>i</i></sub>的文档数,<i>N</i>(<i>C</i><sub><i>j</i></sub>)表示文本数据集中归类于类别<i>C</i><sub><i>j</i></sub>的文档数,<i>N</i>表示文本数据集中总的文档数。如果特征词<i>t</i><sub><i>i</i></sub>和类别<i>C</i><sub><i>j</i></sub>无关,则<i>p</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)=<i>p</i>(<i>t</i><sub><i>i</i></sub>)×<i>p</i>(<i>C</i><sub><i>j</i></sub>),那么<i>MI</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)=0,因此在后面特征选择算法中选择互信息值大于0的特征词。</p>
                </div>
                <div class="p1">
                    <p id="79">基于互信息值的特征选择算法考虑到了低频词对分类的贡献,这是其他特征选择算法所没有的优点,但它的缺陷也在于此,互信息法更倾向于选择出现频次低的特征词,即<i>p</i>(<i>t</i><sub><i>i</i></sub>)越小时,<i>MI</i>(<i>t</i><sub><i>i</i></sub>,<i>C</i><sub><i>j</i></sub>)越大,会对分类的准确率造成负影响。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">1.3 <b>构建情感词向量</b></h4>
                <div class="p1">
                    <p id="81">在中文文本情感倾向性分类研究中,充分利用特征词的情感极性信息对提高情感分类的精确度十分重要。特征选择算法实现的功能是特征属性维度约简并挑选出类别代表度高的特征词,在为特征词赋予特征权值之后,还需要根据特征词的情感信息添加情感权值,从而构建情感词向量。</p>
                </div>
                <div class="p1">
                    <p id="83">在中文文本情感倾向性分类中,构建情感词典是核心部分。情感词典可以分为4个部分:积极情感词典、消极情感词典、否定词典和程度副词词典<citation id="289" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。为了得到更加完整的词典,本文在网络上收集了若干情感词典,以及部分行业的专业词典,以提高分类的准确率。情感词典的构建如图1所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 构建情感词典" src="Detail/GetImg?filename=images/JSJY201911005_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 构建情感词典  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Creating sentiment dictionary</p>

                </div>
                <div class="p1">
                    <p id="85">基于情感词典的特征词情感权值计算规则比较简单,本文将每个积极情感词赋予规则权值1,将每个消极情感词赋予规则权值-1,同时假设情感值满足线性叠加原理,基本的情感权值规则如图2所示。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 情感权值规则" src="Detail/GetImg?filename=images/JSJY201911005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 情感权值规则  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Rules of sentimental weights</p>

                </div>
                <div class="p1">
                    <p id="87">假设根据情感词典和情感权值规则处理后的每个特征词的情感权值为<i>W</i>(<i>t</i><sub><i>i</i></sub>),根据特征选择算法得到的词语的特征值为<i>F</i>(<i>t</i><sub><i>i</i></sub>),则最终得到的情感词向量中的情感特征值为<i>S</i>(<i>t</i><sub><i>i</i></sub>)=<i>W</i>(<i>t</i><sub><i>i</i></sub>)×<i>F</i>(<i>t</i><sub><i>i</i></sub>)。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">1.4 <b>三支决策理论</b></h4>
                <div class="p1">
                    <p id="89">Yao<citation id="290" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出的三支决策理论是他根据粗糙集理论和决策粗糙集理论为基础提出的一个决策性处理框架。三支决策理论是对传统的二支决策进行的扩展,在原本的二支决策的基础上增加了处理不确定信息的不承诺决策选项。在处理实际应用问题时,避免了二支决策中只能作出强制接受或强制拒绝的损失。三支决策思想和中国传统中庸思想有密切的关系,基于“度”将一个问题“一分为三”,即表示接受的正域POS、表示延迟决策的边界域BND和表示拒绝的负域BND。在面对不同的实际问题时,三支决策强调的重点也不相同,有时强调正域和负域中的一个或两个,有时强调边界域。</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag">2 三支决策特征选择算法</h3>
                <div class="p1">
                    <p id="91">三支决策理论在对某一实体<i>x</i>∈<i>U</i>进行三支分类时,需要设置评价函数对实体<i>x</i>进行评估,这个评价函数的值就是实体<i>x</i>的决策状态值。根据评价函数的数量,三支决策分为双评价函数和单评价函数两种模式。本文使用的是双评价函数模式,两个评价函数分别是两种有监督特征选择算法,将特征词集合映射到三支决策的三个决策域中。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">2.1 <b>算法思路</b></h4>
                <div class="p1">
                    <p id="93">三支决策特征选择(Three-Way Decisions-Feature Selection, TWD-FS)算法可以划分成两个部分:一是根据评价函数确定三个决策域,二是对三个决策域中的特征词进行处理。引进两个评价函数<i>α</i>和<i>β</i>,即两个有监督特征选择算法,评价函数<i>α</i>对情感倾向类别<i>C</i><sub><i>j</i></sub>选择出的特征词集合定义为<i>αSet</i><sub><i>Cj</i></sub>,评价函数<i>β</i>对情感类别<i>C</i><sub><i>j</i></sub>选择出的特征词集合定义为<i>βSet</i><sub><i>Cj</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="94"><b>定义</b>1 情感倾向类别<i>C</i><sub><i>j</i></sub>的3个决策域:正域<i>POSSet</i><sub><i>Cj</i></sub>、边界域<i>BNDSet</i><sub><i>Cj</i></sub>和负域<i>NEGSet</i><sub><i>Cj</i></sub>判断的规则如下,设情感倾向类别<i>C</i><sub><i>j</i></sub>中的所有特征词的集合为<i>Set</i><sub><i>Cj</i></sub>,<i>Set</i><sub><i>Cj</i></sub>={<i>t</i><sub>1</sub>,<i>t</i><sub>2</sub>,…,<i>t</i><sub><i>n</i></sub>},∀<i>t</i><sub><i>k</i></sub>∈<i>Set</i><sub><i>Cj</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="95">if <i>t</i><sub><i>k</i></sub>∈<i>αSet</i><sub><i>Cj</i></sub> and <i>t</i><sub><i>k</i></sub>∈<i>βSet</i><sub><i>Cj</i></sub></p>
                </div>
                <div class="p1">
                    <p id="96"><i>t</i><sub><i>k</i></sub>∈<i>POSSet</i><sub><i>Cj</i></sub></p>
                </div>
                <div class="p1">
                    <p id="97">if (<i>t</i><sub><i>k</i></sub>∈<i>αSet</i><sub><i>Cj</i></sub> but <i>t</i><sub><i>k</i></sub>∉<i>βSet</i><sub><i>Cj</i></sub>) or (<i>t</i><sub><i>k</i></sub>∈<i>βSet</i><sub><i>Cj</i></sub> but <i>t</i><sub><i>k</i></sub>∉<i>αSet</i><sub><i>Cj</i></sub>)</p>
                </div>
                <div class="p1">
                    <p id="98"><i>t</i><sub><i>k</i></sub>∈<i>BNDSet</i><sub><i>Cj</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="99">if <i>t</i><sub><i>k</i></sub>∉<i>αSet</i><sub><i>Cj</i></sub> and <i>t</i><sub><i>k</i></sub>∉<i>βSet</i><sub><i>Cj</i></sub></p>
                </div>
                <div class="p1">
                    <p id="100"><i>t</i><sub><i>k</i></sub>∈<i>NEGSet</i><sub><i>Cj</i></sub></p>
                </div>
                <div class="p1">
                    <p id="101">其中:<i>C</i><sub><i>j</i></sub>表示第<i>j</i>个情感倾向性类别,<i>t</i><sub><i>k</i></sub>表示归类于类别<i>C</i><sub><i>j</i></sub>样本的特征集合中的第<i>k</i>个特征词。</p>
                </div>
                <div class="p1">
                    <p id="102">本文保留正域<i>POSSet</i><sub><i>Cj</i></sub>中的特征词,排除掉负域<i>NEGSet</i><sub><i>Cj</i></sub>中的特征词,对边界域<i>BNDSet</i><sub><i>Cj</i></sub>中的特征词进行进一步处理,从中选择出类间离散度和类内聚集度较好的特征词进行保留。</p>
                </div>
                <div class="p1">
                    <p id="103"><b>定义</b>2 对于划分到边界域<i>BNDSet</i><sub><i>Cj</i></sub>中的特征词,需要进行进一步判别,以便挑选出对情感倾向类别贡献较高的特征词,即选择出使得文本类间离散度最大,同时类内离散度最小的特征,对情感倾向类别<i>C</i><sub><i>P</i></sub>特征判别率<i>F</i><sub><i>CP</i></sub>(<i>t</i><sub><i>k</i></sub>)定义为:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mrow><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ν</mi><mo>≠</mo><mi>Ρ</mi></mrow></munder><mi>E</mi></mstyle><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ν</mi><mo>≠</mo><mi>Ρ</mi></mrow></munder><mi>D</mi></mstyle><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中:<mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ν</mi><mo>≠</mo><mi>Ρ</mi></mrow></munder><mi>E</mi></mstyle><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>表示类间离散度,<mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>+</mo></mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ν</mi><mo>≠</mo><mi>Ρ</mi></mrow></munder><mi>D</mi></mstyle><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>表示类内离散度。</p>
                </div>
                <div class="p1">
                    <p id="106">令<i>d</i><sub><i>P</i></sub><sub>,</sub><sub><i>i</i></sub>(<i>i</i>=1,2,…,<i>m</i>)表示在<i>P</i>类情感倾向样本集中第<i>i</i>条文本;<i>d</i><sub><i>N</i></sub><sub>, </sub><sub><i>j</i></sub>(<i>N</i>≠<i>P</i>, <i>j</i>=1,2,…,<i>n</i>)表示在<i>N</i>类情感倾向样本集中第<i>j</i>条文本,这里<i>N</i>类情感倾向样本集表示样本集中除<i>P</i>类情感以外的样本集。特征变量<i>d</i><sub><i>P</i></sub><sub>,</sub><sub><i>i</i></sub>(<i>t</i><sub><i>k</i></sub>)和<i>d</i><sub><i>N</i></sub><sub>, </sub><sub><i>j</i></sub>(<i>t</i><sub><i>k</i></sub>)定义如下:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mspace width="0.25em" /><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mspace width="0.25em" /><mtext>o</mtext><mtext>c</mtext><mtext>c</mtext><mtext>u</mtext><mtext>r</mtext><mtext>s</mtext><mspace width="0.25em" /><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>d</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>,</mo><mi>i</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>,</mo></mtd><mtd columnalign="left"><mspace width="0.25em" /><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow></mrow><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mspace width="0.25em" /><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mspace width="0.25em" /><mtext>o</mtext><mtext>c</mtext><mtext>c</mtext><mtext>u</mtext><mtext>r</mtext><mtext>s</mtext><mspace width="0.25em" /><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>d</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow></mrow><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109">则:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mrow><mi>Ν</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>d</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>d</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mi>C</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">通过对归类于边界域<i>BNDSet</i><sub><i>Cj</i></sub>中的特征词,进一步计算其特征判别率<i>F</i><sub><i>Cj</i></sub>(<i>t</i><sub><i>k</i></sub>),这里<i>F</i><sub><i>Cj</i></sub>(<i>t</i><sub><i>k</i></sub>)=<i>F</i><sub><i>CP</i></sub>(<i>t</i><sub><i>k</i></sub>),上面使用<i>F</i><sub><i>CP</i></sub>(<i>t</i><sub><i>k</i></sub>)为了方便公式表示。然后将计算所得值按由大到小排序,选择排序最大的前<i>k</i>个特征词作为对边界域<i>BNDSet</i><sub><i>Cj</i></sub>处理后情感倾向类别<i>C</i><sub><i>j</i></sub>新的特征词,记为<i>FSet</i><sub><i>Cj</i></sub>,则情感倾向类别<i>C</i><sub><i>j</i></sub>的最终特征词集合为<i>TWDSet</i><sub><i>Cj</i></sub>=<i>POSSet</i><sub><i>Cj</i></sub>+<i>FSet</i><sub><i>Cj</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="115"><b>定义</b>3 TWD-FS特征选择算法显示组合正向情感特征和负向情感特征,得到最终的特征集合<i>TWDSet</i>规则如下:</p>
                </div>
                <div class="p1">
                    <p id="116">针对不平衡情感倾向性类别,每个情感类别<i>C</i><sub><i>j</i></sub>选择出的特征集合<i>TWDSet</i><sub><i>Cj</i></sub>,正类情感特征和负类情感特征可以进行显式的组合,假设从<mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>Τ</mi></mstyle><mi>W</mi><mi>D</mi><mi>S</mi><mi>e</mi><mi>t</mi><msub><mrow></mrow><mrow><mi>C</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub></mrow></math></mathml>选择出<i>k</i>个特征,才有如下策略:</p>
                </div>
                <div class="p1">
                    <p id="117">1)从正向情感类别<i>TWDSet</i><sub><i>CPos</i></sub>中选择出<i>k</i><sub><i>Pos</i></sub>个正向类别情感特征。</p>
                </div>
                <div class="p1">
                    <p id="118">2)从负向情感类别<i>TWDSet</i><sub><i>CNeg</i></sub>中选择出<i>k</i><sub><i>Neg</i></sub>=<i>k</i>-<i>k</i><sub><i>Pos</i></sub>个负向类别情感特征。</p>
                </div>
                <div class="p1">
                    <p id="119">3)将上面两步得到的特征<i>k</i><sub><i>Pos</i></sub>和<i>k</i><sub><i>Neg</i></sub>进行组合,其中正相关特征比例为<i>ratio</i>=<i>k</i><sub><i>Pos</i></sub>/<i>k</i><sub><i>Neg</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="120">4)调整<i>ratio</i>的大小,得到最佳的<i>k</i>个特征放入<i>TWDSet</i>。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">2.2 <b>算法描述</b></h4>
                <div class="p1">
                    <p id="122">面向不平衡文本情感分类的三支决策特征选择算法(TWD-FS)具体步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="123">1)对整个文本数据集进行LTP分词和去停用词等预处理,然后对文本集合进行划分,分为训练集和测试集。</p>
                </div>
                <div class="p1">
                    <p id="124">2)引入两个评价函数,改进后的TCHI特征选择算法和MI特征选择算法,对训练集文本中每个情感倾向类别,分别进行这两个评价函数的特征选择操作,得到两个训练集文本特征集合,算法如下。</p>
                </div>
                <div class="p1">
                    <p id="125">算法1 根据两个三支决策评价函数TCHI和MI,对训练集文本每个情感倾向类别<i>C</i><sub><i>j</i></sub>分别生成两个特征集合<i>TCHISet</i><sub><i>Cj</i></sub>和<i>MISet</i><sub><i>Cj</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="126">输入 经过文本预处理后的训练集<i>TrainSet</i>,三支决策评价函数TCHI从每个情感倾向类别筛选出的特征数<i>k</i><sub>1</sub>,三支决策评价函数MI从每个情感倾向类别筛选出的特征数<i>k</i><sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="127">输出 <i>TCHISet</i><sub><i>Cj</i></sub>,<i>MISet</i><sub><i>Cj</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="128">1)初始化。</p>
                </div>
                <div class="p1">
                    <p id="130">CHI选择出的特征候选集合:<i>TCHISet</i><sub><i>Cj</i></sub>=∅;</p>
                </div>
                <div class="p1">
                    <p id="131">MI选择出的特征候选集合:<i>MISet</i><sub><i>Cj</i></sub>=∅。</p>
                </div>
                <div class="p1">
                    <p id="132">2)对<i>TrainSet</i>中情感倾向类别<i>C</i><sub><i>j</i></sub>的每一条文本,根据式(3)计算每条文本中每个特征词的特征权值,只保留特征权值大于0的特征词,然后从中选择最大的前<i>k</i><sub>1</sub>个特征词,将它们放入候选集合<i>TCHISet</i><sub><i>Cj</i></sub>中。</p>
                </div>
                <div class="p1">
                    <p id="134">3)对<i>TrainSet</i>中情感倾向类别<i>C</i><sub><i>j</i></sub>的每一条文本,根据式(4)计算每条文本中每个特征词的特征权值,只保留特征权值大于0的特征词,然后从中选择最大的前<i>k</i><sub>2</sub>个特征词,将它们放入候选集合<i>MISet</i><sub><i>Cj</i></sub>中。</p>
                </div>
                <div class="p1">
                    <p id="136">4)return <i>TCHISet</i><sub><i>Cj</i></sub>,<i>MISet</i><sub><i>Cj</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="138">3)由算法1对每个情感倾向类别<i>C</i><sub><i>j</i></sub>都生成了两个特征集合,然后采用三支决策特征选择算法对特征进一步筛选,选择出对类别贡献较大的特征集合。算法如下:</p>
                </div>
                <div class="p1">
                    <p id="139">算法2 基于三支决策的特征选择算法。</p>
                </div>
                <div class="area_img" id="227">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911005_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="167">4)根据算法2得到三支决策最终特征集合<i>TWDSet</i>,对训练集文本和测试集文本利用情感词典和情感权值规则,生成训练集文本情感词向量和测试集文本情感词向量。</p>
                </div>
                <div class="p1">
                    <p id="168">5)对训练集文本词向量利用Logistics机器学习模型进行训练,然后对测试集文本词向量进行预测,最终输出其情感倾向性类别。</p>
                </div>
                <div class="p1">
                    <p id="169">综上,面向不平衡文本情感分类的三支决策特征选择算法整体流程如图3所示。</p>
                </div>
                <div class="area_img" id="170">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 面向不平衡文本情感分类的三支决策特征选择算法流程" src="Detail/GetImg?filename=images/JSJY201911005_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 面向不平衡文本情感分类的三支决策特征选择算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Flow chart of feature selection method for imbalanced text sentiment classification based on three-way decisions</p>

                </div>
                <h3 id="171" name="171" class="anchor-tag">3 实验设计和分析</h3>
                <h4 class="anchor-tag" id="172" name="172">3.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="173">本文实验所使用的语料库为COAE2013中文“蒙牛”微博测试数据,中文情感分析语料库,包含酒店、服装、水果、平板、洗发水5个领域的评价数据,从中组合正负类样本数量构成不平衡文本情感语料集。所有数据的详细信息如表2所示。</p>
                </div>
                <div class="area_img" id="174">
                                            <p class="img_tit">
                                                <b>表</b>2 <b>实验数据集信息</b>
                                                    <br />
                                                Tab. 2 Information of experimental datasets
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201911005_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 实验数据集信息" src="Detail/GetImg?filename=images/JSJY201911005_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="175">表2分别列出了6个数据集中正向情感和负向情感的样本数和特征数,并计算了二者之间的倾斜度,可以看出这6组数据不仅存在样本数量的不平衡,也存在特征的不平衡。</p>
                </div>
                <h4 class="anchor-tag" id="176" name="176">3.2 <b>评估方法</b></h4>
                <div class="p1">
                    <p id="177">本文使用采用经典的准确率P(Precision),召回率R(Recall)和<i>F</i><sub>1</sub>评价指标,对于二分类问题,可将样例根据其真实类别与学习器预测类别的组合划分为真正例(True Positive, TP)、假正例(False Positive, FP)、真反例(True Negative, TN)和假反例(False Negative, FN)四种情形,令<i>TP</i>、<i>FP</i>、<i>TN</i>和<i>FN</i>分别表示其对应的样例数。计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="178"><i>P</i>=<i>TP</i>/(<i>TP</i>+<i>FP</i>)      (15)</p>
                </div>
                <div class="p1">
                    <p id="179"><i>R</i>=<i>TP</i>/(<i>TP</i>+<i>FN</i>)      (16)</p>
                </div>
                <div class="p1">
                    <p id="180"><i>F</i><sub>1</sub>=(2×<i>P</i>×<i>R</i>)/(<i>P</i>+<i>R</i>)      (17)</p>
                </div>
                <div class="p1">
                    <p id="181">其中:<i>TP</i>表示预测情感为正向情感同时实际情感也是正向情感的文本数;<i>FP</i>表示预测情感为正向情感但实际情感是负向情感的文本数;<i>FN</i>表示预测情感为负向情感但实际情感是正向情感的文本数;<i>TN</i>表示预测情感为负向情感同时实际情感也是负向情感的文本数。</p>
                </div>
                <h4 class="anchor-tag" id="182" name="182">3.3 <b>实验方案</b></h4>
                <div class="p1">
                    <p id="183">本文设计了2个实验来验证TWD-FS特征选择算法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="184">实验1 验证TWD-FS算法的特征降维效果,和TWD-FS降低正向情感特征和负向情感特征在数量上倾斜度的能力。</p>
                </div>
                <div class="p1">
                    <p id="185">实验2 将本文提出的TWD-FS特征选择算法和其他特征选择算法进行比较实验。</p>
                </div>
                <h4 class="anchor-tag" id="186" name="186">3.4 <b>实验结果</b></h4>
                <div class="p1">
                    <p id="187">实验1 三支决策评价函数TCHI从每个情感倾向类别筛选出的特征数<i>k</i><sub>1</sub>,和MI分别从每个情感倾向类别筛选出的特征数<i>k</i><sub>2</sub>,在本实验中选择<i>k</i>=<i>k</i><sub>1</sub>=<i>k</i><sub>2</sub>。根据定义3显式组合正类情感特征和负类情感特征比例<i>ratio</i>。TWD-FS算法中,<i>k</i>和<i>ratio</i>对实验结果产生影响,并选择各个特征维度下最优的<i>ratio</i>。表3列出“蒙牛”数据在各个维度下<i>F</i><sub>1</sub>值结果。</p>
                </div>
                <div class="area_img" id="188">
                    <p class="img_tit"><b>表</b>3 TWD-FS<b>在</b>COAE2013“<b>蒙牛”数据各维度下的</b><i>F</i><sub>1</sub><b>值实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 <i>F</i><sub>1</sub> results of TWD-FS on “Mengniu” data of COAE2013 in various dimensions</p>
                    <p class="img_note"></p>
                    <table id="188" border="1"><tr><td rowspan="2"><br />特征数<i>k</i></td><td colspan="11"><br /><i>ratio</i></td></tr><tr><td><br />0</td><td>0.1</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.5</td><td>0.6</td><td>0.7</td><td>0.8</td><td>0.9</td><td>1.0</td></tr><tr><td><br />100</td><td>0.394 0</td><td>0.627 4</td><td>0.689 9</td><td>0.744 9</td><td>0.843 4</td><td>0.857 1</td><td>0.820 7</td><td>0.820 5</td><td>0.810 4</td><td>0.782 8</td><td>0.733 3</td></tr><tr><td><br />500</td><td>0.648 4</td><td>0.721 2</td><td>0.831 3</td><td>0.839 9</td><td>0.869 8</td><td>0.863 4</td><td>0.833 3</td><td>0.825 1</td><td>0.810 7</td><td>0.730 5</td><td>0.725 4</td></tr><tr><td><br />1 000</td><td>0.671 5</td><td>0.831 5</td><td>0.872 6</td><td>0.891 3</td><td>0.895 3</td><td>0.896 7</td><td>0.886 6</td><td>0.882 6</td><td>0.874 6</td><td>0.860 3</td><td>0.856 6</td></tr><tr><td><br />1 500</td><td>0.666 1</td><td>0.888 6</td><td>0.893 8</td><td>0.896 1</td><td>0.906 1</td><td>0.898 8</td><td>0.895 6</td><td>0.882 4</td><td>0.873 9</td><td>0.850 1</td><td>0.754 6</td></tr><tr><td><br />2 000</td><td>0.681 2</td><td>0.733 5</td><td>0.867 2</td><td>0.899 1</td><td>0.901 4</td><td>0.899 6</td><td>0.888 3</td><td>0.853 5</td><td>0.801 2</td><td>0.796 5</td><td>0.725 3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="189">根据表3可以得出,TWD-FS算法只使用正向情感特征(<i>ratio</i>=1)和只使用负向情感特征(<i>ratio</i>=0),在各个维度上<i>F</i><sub>1</sub>值不能取得最优,在“蒙牛”数据各维度下的<i>F</i><sub>1</sub>值在<i>ratio</i>值为0.4或0.5取得最大值,即在平衡正负类情感特征数量时<i>F</i><sub>1</sub>值到最优。这时还需要考虑特征数量对实验结果的影响,才能使TWD-FS方法的实验结果达到最优。图4表示对不同的特征数<i>k</i>,TWD-FS算法<i>F</i><sub>1</sub>值大时,最终选择出的正向情感特征数和负向情感特征数的信息。</p>
                </div>
                <div class="area_img" id="190">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_190.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 TWD-FS在COAE2013“蒙牛”数据各维度下选择出的特征数" src="Detail/GetImg?filename=images/JSJY201911005_190.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 TWD-FS在COAE2013“蒙牛”数据各维度下选择出的特征数  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_190.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The number of features selected by TWD-FS on “Mengniu” data of COAE2013 in various dimensions</p>

                </div>
                <div class="p1">
                    <p id="191">由表3和图4可以得到,TWD-FS在“蒙牛”数据中,三支决策评价函数TCHI和MI分别从每个情感倾向类别筛选出的1 500个特征词时,文本情感倾向性分类<i>F</i><sub>1</sub>值达到最高。此时的总特征数仅为2 500维,这和数据集刚开始的数万维特征比较得到了大幅度的下降,同时正向特征和负向特征在数量上的倾斜度得到了很大的改善。</p>
                </div>
                <div class="p1">
                    <p id="192">实验2 为了验证提出的TWD-FS特征选择算法的有效性和优越性,将其分别和王杰<citation id="291" type="reference"><link href="234" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的双边Fisher特征选择算法(Two-Sided Fisher, TSF),姚海英<citation id="292" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出的改进的卡方统计量(Improved CHI Square, ICHI),李燕等<citation id="293" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出的基于Lasso的互信息(MI)特征选择算法(Lasso-MI),张越兵等<citation id="294" type="reference"><link href="270" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出的语句级增强情感特征选择算法(Sentence-level Sentiment Strengthing, SSS),传统的信息增益(Information Gain, IG)特征选择算法这五种算法进行对比实验,最终通过十则交叉验证取平均结果。</p>
                </div>
                <div class="p1">
                    <p id="193">图5表示了TWD-FS特征选择算法和其他5种特征选择算法在“蒙牛”数据上<i>F</i><sub>1</sub>值结果。可以看出,本文提出的TWD-FS特征选择算法相较于其他五种特征选择算法在各项指标上有一定的优势,和传统的信息增益特征选择算法IG相比,优势比较突出。</p>
                </div>
                <div class="area_img" id="194">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_194.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 六种特征选择算法在COAE2013“蒙牛”数据上的实验结果对比" src="Detail/GetImg?filename=images/JSJY201911005_194.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 六种特征选择算法在COAE2013“蒙牛”数据上的实验结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_194.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Comparison of six feature selection algorithms on “Mengniu” data of COAE2013</p>

                </div>
                <div class="p1">
                    <p id="195">从表4中可以看出,在进行对比实验的6个领域的数据集中,本文提出的TWD-FS特征选择算法相较于其他改进的特征选择算法,在准确率、召回率和<i>F</i><sub>1</sub>值个指标上有一定的优势;和传统特征选择算法相比尤为突出。其中平板、水果和洗发水这三个领域的情感倾向性分类结果提升较为明显,各指标均提升了3%～6%;蒙牛、酒店和服装这个三个领域情感倾向性分类结果提升较小,各指标均提升了1.5%～3%。通过分析可以得出,提升较高的三个领域的数据集,它们的样本和特征倾斜度较高,也就是正向情感类别和负向情感类别的文本和特征数量的差距较大,本文提出的TWD-FS特征选择算法可以有效地缓解正负类样本和特征的倾斜度。这也充分证明了本文提出的TWD-FS特征选择算法在降低特征维度,缓解样本和特征倾斜度的同时,能够有效提高情感倾向性分类的准确度。</p>
                </div>
                <div class="area_img" id="196">
                                            <p class="img_tit">
                                                <b>表</b>4 TWD-FS<b>和其他特征选择算法在不同数据集上的对比结果</b>
                                                    <br />
                                                Tab. 4 Comparison of TWD-FS and other feature selection algorithms on different datasets
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911005_19600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJY201911005_19600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911005_19600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 TWD-FS和其他特征选择算法在不同数据集上的对比结果" src="Detail/GetImg?filename=images/JSJY201911005_19600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="197" name="197" class="anchor-tag">4 结语</h3>
                <div class="p1">
                    <p id="198">本文针对不平衡文本情感特征分布的特点,结合三支决策的思想,提出了一种面向不平衡文本情感分类的三支决策特征选择算法TWD-FS。有效地将两种有监督特征选择算法的优势结合在一起,更加全面和充分地考虑了特征词对某一个情感倾向类别的贡献度,使得最终选择出的特征词在文本中的类间离散度达到最大,和类内离散度达到最小,具有最佳的情感类别代表度,同时通过显式组合正负类情感特征数量,进一步降低特征的不平衡度。实验结果证明,本文提出的TWD-FS特征选择算法能够有效降低特征维度、文本和特征的倾斜度,同时还能提高情感倾向性分类的准确度。相较于其他特征选择算法,当文本和特征的倾斜度较高时,情感倾向性分类效果提升更加明显;但是本实验仅考虑了两个有监督评价函数筛选出的特征词,对于两者均未选中的特征词直接过滤掉了,这会导致部分文本信息的缺失,并且本文在特征选择阶段,将具有情感倾向的特征词和一般的特征词同等看待,并未考虑具有情感倾向的特征词对情感类别有更高的贡献度。接下来的研究将重点考虑具有情感倾向的特征词在情感类别中的代表度,同时考虑利用采样算法进一步降低文本和特征的倾斜度,以提高情感倾向性分类的准确度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="228">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013325090.nh&amp;v=MDA2NDJDVVI3cWZadVpzRnlublVidkJWRjI2SGJDNkc5SEZyNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 赵立东.面向文本情感分类的非平衡数据采样方法研究[D].太原:山西大学,2013.(ZHAO L D.Research on imbalanced data sampling methods for text sentiment classification[D].Taiyuan:Shanxi University,2013.)
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201504011&amp;v=MTc2MjNVUjdxZlp1WnNGeW5uVWJ2QlBTekJlckc0SDlUTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 田锋,兰田,CHAO Kuo-Ming,等.领域实例迁移的交互文本非平衡情感分类方法[J].西安交通大学学报,2015,49(4):67-72.(TIAN F,LAN T,CHAO K-M,et al.An unbalanced emotion classification method foe interactive texts based on multiple-domain instance transfer[J].Journal of Xi’an Jiaotong University,2015,49(4):67-72.)
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012387131.nh&amp;v=MTg2MzZxQnRHRnJDVVI3cWZadVpzRnlublVidkJWRjI2SExDd0dkRFBycEViUElRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王中卿.基于不平衡数据的情感分类方法研究[D].苏州:苏州大学,2012.(WANG Z Q.Research on sentiment classification based-upon imbalanced data[D].Soochow:Soochow University,2012.)
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201610039&amp;v=MjA2NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm5VYnZCTHo3QmI3RzRIOWZOcjQ5R2JZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 王杰,李德玉,王素格.面向非平衡文本情感分类的TSF特征选择方法[J].计算机科学,2016,43(10):206-210.(WANG J,LI D Y,WANG S G.TSF feature selection method for imbalanced text sentiment classification[J].Computer Science,2016,43(10):206-210.)
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combating the small sample class imbalance problem using feature selection">

                                <b>[5]</b> WASIKOWSKI M,CHEN X.Combating the small sample class imbalance problem using feature selection[J].IEEE Transactions on Knowledge &amp; Data Engineering,2010,22(10):1388-1400.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913301&amp;v=MjQ0MjdFYmVvTUQzdzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyM0lJVndXYmhzPU5pZk9mYks3SHRETnFvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> YIN L,GE Y,XIAO K.et al.Feature selection for high-dimensional imbalanced data[J].Neurocomputing,2013,105(4):3-11.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A semi-supervised three-way clustering framework for multi-view data">

                                <b>[7]</b> YU H,WANG X,WANG G.A semi-supervised three-way clustering framework for multi-view data[C]// IJCRS 2017:International Joint Conference on Rough Sets.Berlin:Springer,2017:313-325.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201202001&amp;v=MjMwNTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5uVWJ2QktDallmYkc0SDlQTXJZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 张梅山,邓知龙,车万翔,等.统计与词典相结合的领域自适应中文分词[J].中文信息学报,2012,26(2):8-12.(ZHANG M S,DENG Z L,CHE W X,et al.Combining statistical model and dictionary for domain adaption of Chinese word segmentation[J].Journal of Chinese Information Processing,2012,26(2):8-12.)
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201708007&amp;v=MjY1MDJDVVI3cWZadVpzRnlublVidkJMejdTWkxHNEg5Yk1wNDlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 史庆伟,从世源,唐晓亮.LSI_LDA:一种混合特征降维方法[J].计算机应用研究,2017,34(8):2269-2273.(SHI Q W,CONG S Y,TANG X L.LSI_LDA:mixture method for feature dimensionality reduction[J].Application Research of Computers,2017,34(8):2269-2273.)
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic patent classification by a three-phase model with document frequency matrix and boosted tree">

                                <b>[10]</b> AL SHAMSI F,AUNG Z.Automatic patent classification by a three-phase model with document frequency matrix and boosted tree[C]// Proceedings of the 2016 5th International Conference on Electronic Devices,Systems and Applications.Piscataway:IEEE,2016:1-4.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Term frequency with average term occurrences for textual information retrieval">

                                <b>[11]</b> IBRAHIM O A S,LANDA-SILVA D.Term frequency with average term occurrences for textual information retrieval[J].Soft Computing,2016,20(8):3045-3061.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Turning from TF-IDF to TF-IGM for term weighting in text classification">

                                <b>[12]</b> CHEN K,ZHANG Z,LONG J,et al.Turning from TF-IDF to TF-IGM for term weighting in text classification[J].Expert Systems with Applications:an International Journal,2016,66(C):245-260.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201619018&amp;v=MTI5NjBMejdNYWJHNEg5Zk5wbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 毛临川,吴根秀,吴恒,等.基于信息增益的最优组合因子Fisher判别法[J].计算机工程与应用,2016,52(19):94-96.(MAO L C,WU G X,WU H,et al.Optimal combination of factor Fisher discrimination method based on information gain[J].Computer Engineering and Applications,2016,52(19):94-96.)
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712035&amp;v=Mjk2NDk5Yk5yWTlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMejdCYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 李平,戴月明,王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程,2017,43(12):192-196.(LI P,DAI Y M,WANG Y.Text sentiment analysis based on hybrid chi-square statistic and logistics regression[J].Computer Engineering,2017,43(12):192-196.)
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201701010&amp;v=MDQ1OTA1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMVGZIYWJHNEg5Yk1ybzlFWklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 段宏湘,张秋余,张墨逸.基于归一化互信息的FCBF特征选择算法[J].华中科技大学学报(自然科学版),2017,45(1):52-56.(DUAN H X,ZHANG Q Y,ZHANG M Y.FCBF algorithm based on normalized mutual information for feature selection[J].Journal of Huazhong University of Science and Technology (Natural Science Edition),2017,45(1):52-56.)
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201608036&amp;v=MzA0NjBGckNVUjdxZlp1WnNGeW5uVWJ2Qkx6N0JiYkc0SDlmTXA0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 张辉宜,谢业名,袁志祥,等.一种基于概率的卡方特征选择方法[J].计算机工程,2016,42(8):194-198.(ZHANG H Y,XIE Y M,YUAN Z X,et al.A method of CHI-square feature selection based on probability[J].Computer Engineering,2016,42(8):194-198.)
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201618016&amp;v=MDcyNTBac0Z5bm5VYnZCTHo3TWFiRzRIOWZOcDQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 王晨曦,林耀进,刘景华,等.基于最近邻互信息的特征选择算法[J].计算机工程与应用,2016,52(18):74-78.(WANG C X,LIN Y J,LIU J H,et al.Feature selection algorithm based on nearest-neighbor mutual information[J].Computer Engineering and Applications,2016,52(18):74-78.)
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJGD201601022&amp;v=MTQwMTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm5VYnZCSnlmTWFyRzRIOWZNcm85SFpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 吴金源,冀俊忠,赵学武,等.基于特征选择技术的情感词权重计算[J].北京工业大学学报,2016,42(1):142-151.(WU J Y,JI J Z,ZHAO X W,et al.Weight calculation of emotional word based on feature selection technique[J].Journal of Beijing University of Technology,2016,42(1):142-151.)
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601416866&amp;v=Mjg3Nzg5RVlPb0pCSG8vb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcjNJSVZ3V2Jocz1OaWZPZmJLN0h0RE5xWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> YAO Y.The superiority of three-way decisions in probabilistic rough set models[J].Information Sciences,2011,181(6):1080-1096.
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016090164.nh&amp;v=Mjg2ODZPeEh0REtxNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJWRjI2R0w=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 姚海英.中文文本分类中卡方统计特征选择方法和TF-IDF权重计算方法的研究[D].长春:吉林大学,2016.(YAO H Y.Research on chi-square statistic feature selection method and TF-IDF feature weighting method for chinese text classification[D].Changchun:Jilin University,2016.)
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201801009&amp;v=MjE3MDJDVVI3cWZadVpzRnlublVidkJMejdCYjdHNEg5bk1ybzlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 李燕,卫志华,徐凯.基于Lasso算法的中文情感混合特征选择方法研究[J].计算机科学,2018,45(1):39-46.(LI Y,WEI Z H,XU K.Hybrid feature selection method of chinese emotional characteristics based on Lasso algorithm[J].Computer Science,2018,45(1):39-46.)
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201712035&amp;v=MzI0MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bm5VYnZCTHo3QmI3RzRIOWJOclk5R1lZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 张越兵,苗夺谦,张志飞.基于三支决策的多粒度文本情感分类模型[J].计算机科学,2017,44(12):188-193.(ZHANG Y B,MIAO D Q,ZHANG Z F.Multi-granularity text sentiment classification model based on three-way decisions[J].Computer Science,2017,44(12):188-193.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201911005" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911005&amp;v=MDA1MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlublVidkJMejdCZDdHNEg5ak5ybzlGWVlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
