<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136459242471250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201910021%26RESULT%3d1%26SIGN%3dK6VIXunIuvte8JnL%252f4qXry1yDvU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910021&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201910021&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910021&amp;v=MTk1MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oV3IzQUx6N0JkN0c0SDlqTnI0OUhaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="1 颈部淋巴结识别 ">1 颈部淋巴结识别</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="1.1 &lt;b&gt;总体框架&lt;/b&gt;">1.1 <b>总体框架</b></a></li>
                                                <li><a href="#60" data-title="1.2 &lt;b&gt;提取候选&lt;/b&gt;">1.2 <b>提取候选</b></a></li>
                                                <li><a href="#87" data-title="1.3 &lt;b&gt;去除假阳性&lt;/b&gt;">1.3 <b>去除假阳性</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="2 实验设计与结果分析 ">2 实验设计与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="2.1 &lt;b&gt;实验数据集&lt;/b&gt;">2.1 <b>实验数据集</b></a></li>
                                                <li><a href="#109" data-title="2.2 &lt;b&gt;模型训练方法&lt;/b&gt;">2.2 <b>模型训练方法</b></a></li>
                                                <li><a href="#111" data-title="2.3 &lt;b&gt;结果分析&lt;/b&gt;">2.3 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#148" data-title="3 结语 ">3 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="图1 颈部淋巴结识别整体框架">图1 颈部淋巴结识别整体框架</a></li>
                                                <li><a href="#59" data-title="图2 级联FCNs">图2 级联FCNs</a></li>
                                                <li><a href="#80" data-title="图3 提取淋巴结分区">图3 提取淋巴结分区</a></li>
                                                <li><a href="#82" data-title="图4 分区内提取候选样本">图4 分区内提取候选样本</a></li>
                                                <li><a href="#94" data-title="图5 本文3D分类网络结构">图5 本文3D分类网络结构</a></li>
                                                <li><a href="#108" data-title="图6 不同形态及分布的淋巴结样本">图6 不同形态及分布的淋巴结样本</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;候选识别阶段不同算法的结果对比&lt;/b&gt;"><b>表</b>1 <b>候选识别阶段不同算法的结果对比</b></a></li>
                                                <li><a href="#129" data-title="图7 不同算法的识别结果">图7 不同算法的识别结果</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;去除假阳性阶段不同算法的结果对比&lt;/b&gt;"><b>表</b>2 <b>去除假阳性阶段不同算法的结果对比</b></a></li>
                                                <li><a href="#141" data-title="图8 总体结果损失">图8 总体结果损失</a></li>
                                                <li><a href="#142" data-title="图9 总体结果准确率">图9 总体结果准确率</a></li>
                                                <li><a href="#145" data-title="图10 不同识别难度的淋巴结样本">图10 不同识别难度的淋巴结样本</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="178">


                                    <a id="bibliography_1" title="PATEL N U,LIND K E,Mc KINNEY K,et al.Clinical validation of a predictive model for the presence of cervical lymph node metastasis in papillary thyroid cancer[J].American Journal of Neuroradiology,2018,39(4):756-761." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRSAB70FA679A6E99EA4FBC0E06B81CE4AB&amp;v=Mjk0ODZ2dENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhieTJ3cUE9TmlmWmZjTEtHZEc2M29sQ2Jab0plWFV3dW1jWG5FME9TQXJpcW1BOWVNSGhRYw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        PATEL N U,LIND K E,Mc KINNEY K,et al.Clinical validation of a predictive model for the presence of cervical lymph node metastasis in papillary thyroid cancer[J].American Journal of Neuroradiology,2018,39(4):756-761.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_2" title="SPINELLI C,TOGNETTI F,STRAMBI S,et al.Cervical lymph node metastases of papillary thyroid carcinoma,in the central and lateral compartments,in children and adolescents:predictive factors[J].World Journal of Surgery,2018,42(8):1-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cervical lymph node metastases of papillary thyroid carcinoma,in the central and lateral compartments,in children and adolescents:predictive factors">
                                        <b>[2]</b>
                                        SPINELLI C,TOGNETTI F,STRAMBI S,et al.Cervical lymph node metastases of papillary thyroid carcinoma,in the central and lateral compartments,in children and adolescents:predictive factors[J].World Journal of Surgery,2018,42(8):1-10.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_3" title="BEJNORDI B E,VETA M,van DIEST P J,et al.Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer[J].JAMA,2017,318(22):2199-2210." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer">
                                        <b>[3]</b>
                                        BEJNORDI B E,VETA M,van DIEST P J,et al.Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer[J].JAMA,2017,318(22):2199-2210.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_4" title="魏骏,何凌,车坤,等.CT图像的颈部淋巴结半自动分割算法[J].计算机工程与设计,2015,36(11):3014-3018.(WEIJ,HE L,CHE K,et al.Semi-automatic detection and segmentation of neck lymph nodes in CT image[J].Computer Engineering and Design,2015,36(11):3014-3018.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201511027&amp;v=MjA5MzZXcjNBTmlmWVpMRzRIOVROcm85SFk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bmg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        魏骏,何凌,车坤,等.CT图像的颈部淋巴结半自动分割算法[J].计算机工程与设计,2015,36(11):3014-3018.(WEIJ,HE L,CHE K,et al.Semi-automatic detection and segmentation of neck lymph nodes in CT image[J].Computer Engineering and Design,2015,36(11):3014-3018.)
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_5" title="KAN Y,DONG D,ZHANG Y,et al.Radiomic signature as a predictive factor for lymph node metastasis in early-stage cervical cancer[J].Journal of Magnetic Resonance Imaging,2019,49(1):304-310." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD6647A33DC451A90888469C63126D7146&amp;v=MjE4MDROaWZjYXJXK0d0YTlySXd4Ris4S0RRMHd6eDRiNGp0N1FRemtyeE0zZjhhVFJMNlpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynkyd3FBPQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        KAN Y,DONG D,ZHANG Y,et al.Radiomic signature as a predictive factor for lymph node metastasis in early-stage cervical cancer[J].Journal of Magnetic Resonance Imaging,2019,49(1):304-310.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_6" title="ESTEVES C,ALLEN-BLANCHETTE C,MAKADIA A,et al.Learning SO(3)equivariant representations with spherical CNNs[EB/OL].[2019-01-10].http://openaccess.thecvf.com/content_ECCV_2018/papers/Carlos_Esteves_Learning_SO3_Equivariant_ECCV_2018_paper.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning SO (3)equivariant representations with spherical CNNs">
                                        <b>[6]</b>
                                        ESTEVES C,ALLEN-BLANCHETTE C,MAKADIA A,et al.Learning SO(3)equivariant representations with spherical CNNs[EB/OL].[2019-01-10].http://openaccess.thecvf.com/content_ECCV_2018/papers/Carlos_Esteves_Learning_SO3_Equivariant_ECCV_2018_paper.pdf.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_7" title="ELSAYED G F,SHANKAR S,CHEUNG B,et al.Adversarial examples that fool both computer vision and time-limited humans[EB/OL].[2019-01-10].http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial examples that fool both computer vision and time-limited humans">
                                        <b>[7]</b>
                                        ELSAYED G F,SHANKAR S,CHEUNG B,et al.Adversarial examples that fool both computer vision and time-limited humans[EB/OL].[2019-01-10].http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans.pdf.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_8" title="RAJPURKAR P,IRVIN J,ZHU K,et al.Che XNet:radiologistlevel pneumonia detection on chest X-rays with deep learning[EB/OL].[2019-01-10].https://arxiv.org/pdf/1711.05225.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Che XNet:radiologistlevel pneumonia detection on chest X-rays with deep learning">
                                        <b>[8]</b>
                                        RAJPURKAR P,IRVIN J,ZHU K,et al.Che XNet:radiologistlevel pneumonia detection on chest X-rays with deep learning[EB/OL].[2019-01-10].https://arxiv.org/pdf/1711.05225.pdf.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_9" title="RAJPURKAR P,HANNUN A Y,HAGHPANAHI M,et al.Cardiologist-level arrhythmia detection with convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1707.01836.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cardiologist-level arrhythmia detection with convolutional neural networks">
                                        <b>[9]</b>
                                        RAJPURKAR P,HANNUN A Y,HAGHPANAHI M,et al.Cardiologist-level arrhythmia detection with convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1707.01836.pdf.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_10" title="LEE J H,BAEK J H,KIM J H,et al.Deep learning-based computer-aided diagnosis system for localization and diagnosis of metastatic lymph nodes on ultrasound:a pilot study[J].Thyroid,2018,28(10):1332-1338." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning-based computer-aided diagnosis system for localization and diagnosis of metastatic lymph nodes on ultrasound:a pilot study">
                                        <b>[10]</b>
                                        LEE J H,BAEK J H,KIM J H,et al.Deep learning-based computer-aided diagnosis system for localization and diagnosis of metastatic lymph nodes on ultrasound:a pilot study[J].Thyroid,2018,28(10):1332-1338.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_11" title="ZHOU B,KHOSLA A,LAPEDRIZA A,et al.Learning deep features for discriminative localization[C]//Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2016:2921-2929." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning deep features for discriminative localization">
                                        <b>[11]</b>
                                        ZHOU B,KHOSLA A,LAPEDRIZA A,et al.Learning deep features for discriminative localization[C]//Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2016:2921-2929.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_12" title="DING J,LI A,HU Z,et al.Accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks[C]//Proceedings of the 2017 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 10435.Berlin:Springer,2017:559-567." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks">
                                        <b>[12]</b>
                                        DING J,LI A,HU Z,et al.Accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks[C]//Proceedings of the 2017 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 10435.Berlin:Springer,2017:559-567.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_13" title="CHRIST P F,ETTLINGER F,GRN F,et al.Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1702.05970.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks">
                                        <b>[13]</b>
                                        CHRIST P F,ETTLINGER F,GRN F,et al.Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1702.05970.pdf.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_14" title="XIE H,YANG D,SUN N,et al.Automated pulmonary nodule detection in CT Images using deep convolutional neural networks[J].Pattern Recognition,2018,85:109-119." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEB10EA11F8A97E877C4C399C5DC0A9A5&amp;v=MjUwNDh4eEVVbVRzT1MzYnIzeGRCQ3JMbFRNdWFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynkyd3FBPU5pZk9mY2JLSDlHNTNvNUVFdU4rQlh0TQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        XIE H,YANG D,SUN N,et al.Automated pulmonary nodule detection in CT Images using deep convolutional neural networks[J].Pattern Recognition,2018,85:109-119.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_15" title="ROTH H R,LU L,SEFF A,et al.A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations[C]//Proceedings of the 2014 International Conference on Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer,2014:520-527." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A New 2.5D Representation for Lymph Node Detection Using Random Sets of Deep Convolutional Neural Network Observations">
                                        <b>[15]</b>
                                        ROTH H R,LU L,SEFF A,et al.A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations[C]//Proceedings of the 2014 International Conference on Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer,2014:520-527.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_16" title="苗光,李朝锋.二维和三维卷积神经网络相结合的CT图像肺结节检测方法[J].激光与光电子学进展,2018,55(5):129-137.(MIAO G,LI C F.Detection of pulmonary nodules CTimages combined with two-dimensional and three-dimensional convolution neural networks[J].Laser&amp;amp;Optoelectronics Progress,2018,55(5):129-137.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805016&amp;v=MjMwMzJGeW5oV3IzQUx5clBaTEc0SDluTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        苗光,李朝锋.二维和三维卷积神经网络相结合的CT图像肺结节检测方法[J].激光与光电子学进展,2018,55(5):129-137.(MIAO G,LI C F.Detection of pulmonary nodules CTimages combined with two-dimensional and three-dimensional convolution neural networks[J].Laser&amp;amp;Optoelectronics Progress,2018,55(5):129-137.)
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_17" title="RONNEBERGER O,FISCHER P,BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 9351.Berlin:Springer,2015:234-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-net:Convolutional networks for biomedical image segmentation">
                                        <b>[17]</b>
                                        RONNEBERGER O,FISCHER P,BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 9351.Berlin:Springer,2015:234-241.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                    IOFFE S,SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[EB/OL].[2019-01-10].https://arxiv.org/pdf/1502.03167.pdf.</a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_19" title="HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:Surpassing human-level performance on Image Net classification[C]//Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Delving deep into rectifiers:Surpassing Human-level performance on ImageNet classification">
                                        <b>[19]</b>
                                        HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:Surpassing human-level performance on Image Net classification[C]//Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_20" title="SHEN C,ROTH H R,ODA H,et al.On the influence of dice loss function in multi-class organ segmentation of abdominal CTusing 3D fully convolutional networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1801.05912.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the influence of dice loss function in multi-class organ segmentation of abdominal CTusing 3D fully convolutional networks">
                                        <b>[20]</b>
                                        SHEN C,ROTH H R,ODA H,et al.On the influence of dice loss function in multi-class organ segmentation of abdominal CTusing 3D fully convolutional networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1801.05912.pdf.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_21" title="RISTER B,YI D,SHIVAKUMAR K,et al.CT organ segmentation using GPU data augmentation,unsupervised labels and IOUloss[EB/OL].[2019-01-10].https://arxiv.org/pdf/1811.11226.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CT organ segmentation using GPU data augmentation,unsupervised labels and IOUloss">
                                        <b>[21]</b>
                                        RISTER B,YI D,SHIVAKUMAR K,et al.CT organ segmentation using GPU data augmentation,unsupervised labels and IOUloss[EB/OL].[2019-01-10].https://arxiv.org/pdf/1811.11226.pdf.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_22" title="CHOY C B,XU D,GWAK J,et al.3D-R2N2:a unified approach for single and multi-view 3D object reconstruction[C]//Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:628-644." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3d-r2n2 A unified approach for single and multi-view 3d object reconstruction">
                                        <b>[22]</b>
                                        CHOY C B,XU D,GWAK J,et al.3D-R2N2:a unified approach for single and multi-view 3D object reconstruction[C]//Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:628-644.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-28 11:13</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(10),2915-2922 DOI:10.11772/j.issn.1001-9081.2019030510            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于级联全卷积神经网络的颈部淋巴结自动识别算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A7%A6%E5%93%81%E4%B9%90&amp;code=25670970&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">秦品乐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%B9%8F%E6%B3%A2&amp;code=42897033&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李鹏波</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%BB%BA%E6%BD%AE&amp;code=34838180&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾建潮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E8%BE%89&amp;code=39853136&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E5%B0%91%E4%BC%9F&amp;code=42897034&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐少伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8C%97%E5%A4%A7%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E9%99%A2&amp;code=0036109&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中北大学大数据学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对现有算法自动识别颈部淋巴结效率不高、存在大量假阳性且整体假阳性去除效果不理想的问题,提出一种基于级联全卷积神经网络(FCN)的颈部淋巴结识别算法。首先,结合医生的先验知识采用级联FCN进行初步识别,即第一个FCN从头颈部计算机断层扫描图像(CT)中提取淋巴结医学分区;然后,第二个FCN从分区内提取候选样本并在三维层面合并这些样本以生成三维图像块;最后,将提出的特征块平均池化引入到三维分类网络中,对输入的不同尺度三维图像块进行二分类以去除假阳性。在颈部淋巴结数据集中,采用级联FCN识别颈部淋巴结的召回率可达97.23%;引入特征块平均池化的三维分类网络的分类准确率可达到98.7%。在去除假阳性之后的准确率可达93.26%。实验结果分析表明,所提算法能有效实现颈部淋巴结的自动识别并取得较高的召回率和准确率,优于目前相关文献报道的算法;且算法简单高效,易于扩展到其他三维医学图像的目标检测任务中。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%88%E9%83%A8%E6%B7%8B%E5%B7%B4%E7%BB%93%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颈部淋巴结检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BE%85%E5%8A%A9%E8%AF%8A%E6%96%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机辅助诊断;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">全卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%81%87%E9%98%B3%E6%80%A7%E5%8E%BB%E9%99%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">假阳性去除;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维医学影像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    秦品乐(1978—),男,山西长治人,副教授,博士,主要研究方向:大数据、机器视觉、三维重建;;
                                </span>
                                <span>
                                    李鹏波(1995—),男,山西运城人,硕士研究生,主要研究方向:机器学习、计算机视觉、数字图像处理;;
                                </span>
                                <span>
                                    *曾建潮(1963—),男,山西太原人,教授,博士生导师,博士,主要研究方向:复杂系统的维护决策和健康管理;电子邮箱zjc@nuc.edu.cn;
                                </span>
                                <span>
                                    朱辉(1993—),男,江西瑞金人,硕士研究生,主要研究方向:机器学习、计算机视觉、数字图像处理;;
                                </span>
                                <span>
                                    徐少伟(1995—),男,山西太原人,硕士研究生,主要研究方向:机器学习、计算机视觉、数字图像处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-27</p>

            </div>
                    <h1><b>Automatic recognition algorithm for cervical lymph nodes using cascaded fully convolutional neural networks</b></h1>
                    <h2>
                    <span>QIN Pinle</span>
                    <span>LI Pengbo</span>
                    <span>ZENG Jianchao</span>
                    <span>ZHU Hui</span>
                    <span>XU Shaowei</span>
            </h2>
                    <h2>
                    <span>School of Data Science and Technology, North University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The existing automatic recognition algorithms for cervical lymph nodes have low efficiency, and the overall false positive removal are unsatisfied, so a cervical lymph node detection algorithm using cascaded Fully Convolutional Neural Networks(FCNs) was proposed. Firstly, combined with the prior knowledge of doctors, the cascaded FCNs were used for preliminary identification, that was, the first FCN was used for extracting the cervical lymph node region from the Computed Tomography(CT) image of head and neck. Then, the second FCN was used to extract the lymph node candidate samples from the region, and merging them at the three-dimensional(3 D) level to generate a 3 D image block. Finally, the proposed feature block average pooling method was introduced into the 3 D classification network, and the 3 D input image blocks with different scales were classified into two classes to remove false positives. On the cervical lymph node dataset, the recall of cervical lymph nodes identified by cascaded FCNs is up to 97.23%, the classification accuracy of the 3 D classification network with feature block average pooling can achieve 98.7%. After removing false positives, the accuracy of final result reaches 93.26%. Experimental results show that the proposed algorithm can realize the automatic recognition of cervical lymph nodes with high recall and accuracy, which is better than the current methods reported in the literatures; it is simple and efficient, easy to extend to other tasks of 3 D medical images recognition.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=cervical%20lymph%20node%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">cervical lymph node detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=computer-aided%20diagnosis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">computer-aided diagnosis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fully%20Convolutional%20Neural(FCN)%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fully Convolutional Neural(FCN) network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=false%20positive%20removal&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">false positive removal;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Three-Dimensional(3D)%20medical%20imaging&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Three-Dimensional(3D) medical imaging;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    QIN Pinle,born in 1978,Ph.D.,associate professor.His research interests include big data,machine vision,3D reconstruction.;
                                </span>
                                <span>
                                    LI Pengbo,born in 1995,M.S.candidate.His research interests include machine learning,computer vision,digital image processing.;
                                </span>
                                <span>
                                    ZENG Jianchao,born in 1963,Ph.D.,professor.His research interests include maintenance decision and health management of complex systems.;
                                </span>
                                <span>
                                    ZHU Hui,born in 1993,M.S.candidate.His research interests include machine learning,computer vision,digital image processing.;
                                </span>
                                <span>
                                    XU Shaowei,born in 1995,M.S.candidate.His research interests include machine learning,computer vision,digital image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-27</p>
                            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="48">颈部淋巴结引流丰富,全身约800枚淋巴结,其中约300枚位于头颈部。淋巴结作为人体非常重要的免疫器官,起着过滤淋巴、清除细菌和异物、产生淋巴细胞和抗体等作用。头颈部肿瘤种类多,约占全身恶性肿瘤的6%,而其中颈部淋巴结转移癌约占头颈部恶性肿瘤总数的75%<citation id="222" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。全身的癌肿一经侵犯淋巴系统,均有可能转移至颈部淋巴结,同时头颈部区域的原发肿瘤也极易引发颈部淋巴结转移,颈部淋巴结的异常往往表示其引流范围内存在感染灶。大量的手术与病理资料证实,头颈部肿瘤的淋巴结转移存在规律,即仅向其邻近区域进行转移。就特定肿瘤而言,还存在淋巴结转移的高危区域<citation id="223" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。研究报告显示,如果及早发现和治疗,颈淋巴癌患者的5年存活率将提高40%左右<citation id="224" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。因此,检测和识别颈部淋巴结对于及早发现和治疗颈部淋巴癌具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="49">在颈部淋巴结诊断中,传统的触诊对肿瘤是否发生转移具有很高的假性结论,需借助医学影像辅助检查。计算机断层扫描(Computed Tomography, CT)是目前检测颈部淋巴结最可靠的方法,它较好地对软组织或器官成像,能良好地显示出病变的区域。在CT图像中,颈部区域的淋巴结与周围组织界限模糊,CT值与周围的软组织相近,且淋巴结的病理复杂、形态小、不规则。颈部淋巴结的生理特征和图像的复杂性使得放射科医师提取非常困难。医生根据各自经验进行判断,费时费力且结论会随各自主观经验判断而存在误差,这导致结果存在大量的假阳性。对淋巴结检测和分析的常用手段是传统的机器学习算法。魏骏等<citation id="225" type="reference"><link href="184" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出基于统计学的半自动分割算法,采用遍历阈值提取淋巴结种子点,加入基于统计学的强制停止条件,对种子点进行区域生长,实现淋巴结分割及其体积的计算。Kan等<citation id="226" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出基于支持向量机的淋巴结判决算法,依据淋巴结及周围软组织生理特征来识别淋巴结区域。</p>
                </div>
                <div class="p1">
                    <p id="50">深度学习作为机器学习的一个重要分支,近几年得到了迅猛发展。随着强大高效的图形处理器(Graphic Processing Unit, GPU)以及大量可用的训练数据出现,卷积神经网络(Convolutional Neural Network, CNN)在视觉识别领域取得多项突破<citation id="227" type="reference"><link href="188" rel="bibliography" /><link href="190" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>,并且在医疗图像上也取得了不错的成就<citation id="228" type="reference"><link href="192" rel="bibliography" /><link href="194" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。与传统的机器学习算法相比,卷积神经网络的优势在于特征提取过程无需人工参与,通过端到端的形式自动提取深层次特征。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 颈部淋巴结识别整体框架" src="Detail/GetImg?filename=images/JSJY201910021_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 颈部淋巴结识别整体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Overall framework of cervical lymph node recognition</p>

                </div>
                <div class="p1">
                    <p id="52">目前深度学习应用于医学影像的检测和分析通常采用两阶段:1)提取候选样本;2)去除假阳性。针对第一阶段,Lee等<citation id="229" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出CNN-GAP算法,将VGG(Visual Geometry Group)网络与全局平均池化(Global Average Pooling, GAP)<citation id="230" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>相结合,在超声图像上绘制热图来定位转移性淋巴结区域并区分良恶性。虽然该算法在超声影像中识别转移性淋巴结存在优势,但不同影像类型的淋巴结形态表现及特征差异较大,且该算法的定位结果较为粗糙,对于CT图像中识别淋巴结的问题并不适用。目前最先进的通用物体检测模型Faster R-CNN(Faster Region-Based Convolutional Networks)在自然图像上表现优异,在医学影像上也有广泛应用。Ding等<citation id="231" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>采用改进的Faster R-CNN,在特征提取网络的最后一层加入反卷积层以恢复更多细粒度特征,能有效提高对CT图像中较小尺寸肺结节的识别能力。该算法虽然在识别小尺寸目标方面存在优势,但易受预设锚框的影响,导致同时识别大小目标的效果较差,且颈部区域杂质较多,容易导致大量假阳性样本,对于CT图像中识别淋巴结的效果并不理想。相对于目标检测算法,基于像素的分割算法能够利用目标周围的上下文信息实现更精确的定位,在算法复杂度和识别结果等方面往往能取得不错的效果。Christ等<citation id="232" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出全卷积神经网络(Fully Convolutional Neural network, FCN)与迁移学习相结合,对CT图像中肝脏内部病变区域进行分割,并使用条件随机场进行后处理得到分割结果。由于颈部区域的淋巴结与周围组织间的界限模糊、血管等杂质较多且淋巴结目标较小,直接分割原始CT图像容易产生较多假阳性样本。为避免这种情况,需要在前处理阶段提取淋巴结感兴趣区域。针对第二阶段,Xie等<citation id="233" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出训练三个模型来分别提取样本的三个轴切面信息,最后对分类结果进行投票,用于去除肺部结节的假阳性。然而该算法中每个模型仅学习二维平面信息,丢失了空间信息,且多网络投票机制消耗资源,造成去假阳性效果不理想。通过单一网络在特征层面融合三个轴切面信息,有助于提高准确率。Roth等<citation id="234" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了新型的2.5D算法,采用样本的三个轴切面组成三通道伪彩图像,输入到二维卷积神经网络进行分类,用于去除腹部及纵膈淋巴结的假阳性。该算法虽然整合了样本的轴切面信息,但对于样本的整体空间信息利用不足,导致对难样例的区分效果不好。将样本输入三维(Three Dimension, 3D)分类网络,网络充分利用样本的完整空间信息学习到更具代表性的判别特征,有助于提高对难样例的判别能力。Ding等<citation id="235" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>与苗光等<citation id="236" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>在去假阳性部分的算法较为相似,以所有候选样本中心点为基准裁剪为相同尺寸,输入到3D网络进行分类,用于去除肺部结节的假阳性。该类算法虽然能保留样本完整的空间信息,取得明显效果,但由于网络中全连接层的影响,仅限于输入固定大小的样本,而淋巴结尺度变化明显,在传统3D网络上表现不佳。为避免这种情况,就要求网络同时兼顾大小目标的识别。</p>
                </div>
                <div class="p1">
                    <p id="53">颈部淋巴结与周围组织间的界限模糊,具有病理复杂、形态小、不规则、分布区域广泛等特点。目前深度学习应用于识别颈部淋巴结领域的研究较少,仍需解决以下两个关键问题:1)由于受到血管等无关组织的干扰,利用深度学习直接从CT图像中提取,将产生大量假阳性样本;2)针对形态尺度差异较大的样本,采用传统3D分类网络同时识别较大目标与较小目标的难度较大,整体去假阳性的效果并不理想。</p>
                </div>
                <div class="p1">
                    <p id="54">针对颈部淋巴结自动识别的关键问题,本文提出基于级联全卷积神经网络的识别算法。针对第一个关键问题,本文提出级联FCN的实现方式,首先提取淋巴结医学分区,继而从分区内提取候选样本。针对第二个关键问题,本文提出特征块平均池化理念,替代传统3D网络的全连接层以便允许网络输入不同尺度样本。与传统方法相比,本文算法能有效解决深度学习应用于识别淋巴结的两个关键问题,并大幅提高识别的召回率和准确率。该算法可作为颈部淋巴结的预筛查工具,对医生的辅助诊断治疗具有重要的意义。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">1 颈部淋巴结识别</h3>
                <h4 class="anchor-tag" id="56" name="56">1.1 <b>总体框架</b></h4>
                <div class="p1">
                    <p id="57">整体框架如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="58">本文算法主要分为两个阶段:1)提取淋巴结候选样本;2)去除假阳性。第一阶段:采用级联FCN,首先从CT图像中分割出肌肉等无关组织,得到淋巴结医学分区,进而从分区内提取候选样本;第二阶段:将特征块平均池化引入到3D分类网络中,对输入不同尺度的候选3D样本进行二分类,得到分类结果。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 级联FCNs" src="Detail/GetImg?filename=images/JSJY201910021_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 级联FCNs  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Cascaded FCNs</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60">1.2 <b>提取候选</b></h4>
                <div class="p1">
                    <p id="61">提取淋巴结候选样本作为整个模型中的关键步骤,其目的在于保持高灵敏度的同时限制候选样本的数量。由于两方面的原因,本文采用先提取淋巴结医学分区,然后从分区内提取候选样本的方案:1)颈部淋巴结形态各异且与周围组织间的界限模糊,血管、食道、肌肉等组织干扰淋巴结的识别;2)虽然颈部淋巴结分布广泛,但是分布具有规律性,医学上根据淋巴结相邻的组织器官及血管,将颈部淋巴结分布区域划分为七大分区。故本文采用先提取淋巴结医学分区,然后从分区内提取候选样本的方案。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">1.2.1 改进U-Net网络</h4>
                <div class="p1">
                    <p id="63">本文采用级联FCN提取淋巴结分区及候选样本,如图2所示,具体FCN选用改进的全卷积神经网络U-Net。由于原始的全卷积神经网络U-Net<citation id="237" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>在提取淋巴结问题上表现不佳,故采用改进的U-Net网络:首先将网络输入大小调整为CT图像的大小;其次,网络层数较深导致计算量过大,使得网络只能接受较小批次的图像,网络训练速度较慢,故在网络中添加批量归一化(Batch Normalization, BN)<citation id="238" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,激活函数替换为Leaky-ReLU(Leaky Rectified Liner Uints)<citation id="239" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>,加速网络收敛,并提高网络的泛化能力,减少过拟合;最后,对于分割医学影像时面临的类别严重不平衡问题,损失函数采用联合损失,即加权交叉熵损失(Cross Entropy, CE)、Dice损失<citation id="240" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、交并比损失(Intersection over Union, IOU)<citation id="241" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>的损失之和,将总损失减少的范围限定在损失域的子集来加速网络收敛,提升分割精度。整体损失函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="64"><i>L</i><sub>total</sub>=<i>L</i><sub>CE</sub>+<i>L</i><sub>Dice</sub>+<i>L</i><sub>IOU</sub>      (1)</p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>L</i><sub>total</sub>表示为整体损失函数;<i>L</i><sub>CE</sub>表示为加权交叉熵损失函数;<i>L</i><sub>Dice</sub>表示为Dice损失函数;<i>L</i><sub>IOU</sub>表示为交并比损失函数。</p>
                </div>
                <div class="p1">
                    <p id="66">加权交叉熵损失函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mtext>E</mtext></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>w</mi><mo stretchy="false">)</mo><mo>+</mo><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mi>w</mi><mo stretchy="false">)</mo><mi>L</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>w</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>y</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">(1-<i>y</i><sub><i>k</i></sub>)·lb (1-<i><b>p</b></i><sub><i>k</i></sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="71">其中:<i>w</i>表示为<i>y</i><sub><i>k</i></sub>=1的权重;<i>L</i><sub><i>k</i></sub>(<i><b>p</b></i><sub><i>k</i></sub>)表示为对于像素<i>k</i>的交叉熵损失函数。</p>
                </div>
                <div class="p1">
                    <p id="72">Dice损失函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>i</mtext><mtext>c</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mn>2</mn><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中: <i><b>p</b></i>∈[0,1]<sup><i>n</i></sup>表示为具有<i>n</i>个网络输出的预测值组成的一维向量,<i>n</i>为预测的像素数量; <i><b>y</b></i>∈{0,1}<sup><i>n</i></sup>表示二值真值标签向量,正类为1,负类为0。</p>
                </div>
                <div class="p1">
                    <p id="75">交并比损失函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>Ι</mtext><mtext>Ο</mtext><mtext>U</mtext></mrow></msub><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中: <i><b>p</b></i>∈[0,1]<sup><i>n</i></sup>表示为具有<i>n</i>个网络输出的预测值组成的一维向量,<i>n</i>为预测的像素数量; <i><b>y</b></i>∈{0,1}<sup><i>n</i></sup>表示二值真值标签向量,正类为1,负类为0。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">1.2.2 提取候选样本</h4>
                <div class="p1">
                    <p id="79">从<i>CT</i>图像中提取淋巴结分区如图3所示。由于颈部淋巴结医学分区的形状变化过于明显,不易直接提取,故选择根据医生的先验知识,从<i>CT</i>图像上剥离肌肉等无关组织,进而得到淋巴结分区。具体实现为:1)将图像范围调整为-140～260 <i>HU</i>(<i>Hounsfield</i>),采用改进<i>U</i>-<i>Net</i>分割出肌肉等无关组织;2)将图像范围调整为20～80 <i>HU</i>后减去无关组织部分,得到淋巴结医学分区。经过咨询放射科医师,将图像范围调整为-140～260 <i>HU</i>的原因为该范围下肌肉等组织与淋巴结之间的界限相对明显,有助于剥离无关组织的同时,尽可能保留所有真实淋巴结,保证淋巴结的高召回率。之后将调整为20～80 <i>HU</i>的原因为该范围下淋巴结显示效果最为明显且干扰因素较少,以便更精确地提取淋巴结候选样本。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 提取淋巴结分区" src="Detail/GetImg?filename=images/JSJY201910021_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 提取淋巴结分区  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.3 <i>Extracting lymph node region</i></p>

                </div>
                <div class="p1">
                    <p id="81">从分区内提取淋巴结候选样本如图4所示。在20～80 <i>HU</i>范围的淋巴结分区图像中,采用第二个改进<i>U</i>-<i>Net</i>基于淋巴结的标注真值进行训练,从分区内提取淋巴结候选样本,之后将候选样本的掩码轮廓转化为对应的最小外接矩形框,达到提取淋巴结候选样本的目的。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 分区内提取候选样本" src="Detail/GetImg?filename=images/JSJY201910021_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 分区内提取候选样本  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.4 <i>Extracting candidate samples from region</i></p>

                </div>
                <h4 class="anchor-tag" id="83" name="83">1.2.3 合并候选样本</h4>
                <div class="p1">
                    <p id="84">为了获取候选样本的空间信息,需要合并<i>CT</i>序列中多层切片之间的候选样本,通过坐标之间的欧氏距离合并相近的候选样本,并利用3<i>D</i>非极大值抑制(<i>Non Maximum Suppression</i>,<i>NMS</i>)减少候选样本数量。通过判断候选3<i>D</i>样本与真值3<i>D</i>样本之间的体素交并比<citation id="242" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>来确定候选样本的正负标签。其定义为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><msub><mrow></mrow><mrow><mtext>Ι</mtext><mtext>Ο</mtext><mtext>U</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ι</mi><mo>,</mo><mi>J</mi><mo>,</mo><mi>Κ</mi></mrow></munderover><mi>m</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>⋅</mo><mi>Ι</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">h</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>〗</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ι</mi><mo>,</mo><mi>J</mi><mo>,</mo><mi>Κ</mi></mrow></munderover><mi>m</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>Ι</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">h</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>〗</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中:<i>I</i>(·) 为指示函数;<i><b>m</b></i>∈{0,1}为二值向量,当体素(<i>i</i>, <i>j</i>,<i>k</i>)位于候选3D样本内部时为1,否则为0;<i><b>h</b></i>∈{0,1}为二值向量,当体素(<i>i</i>, <i>j</i>,<i>k</i>)位于颈部真值淋巴结3D样本内部时为1,否则为0。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">1.3 <b>去除假阳性</b></h4>
                <div class="p1">
                    <p id="88">提取候选阶段之后,生成较多的候选3<i>D</i>样本,主要由血管与淋巴结组成,两者在二维平面上灰度值接近,形态大小相似,无法区分,而在三维空间中,血管呈现柱状结构,而淋巴结呈现为结状,两者的立体形态截然不同,故去除假阳性时必须结合样本的空间信息。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">1.3.1 网络结构</h4>
                <div class="p1">
                    <p id="90">3<i>D</i>分类网络以<i>VGG</i>网络结构为基础,其结构如图5所示,由6个三维卷积层、3个三维最大池化层、特征块平均池化层及二分类层组成。第一、二层是连续的两个卷积层,由32个3×3×3的卷积核组成,第三、四层是连续的两个卷积层,由64个3×3×3的卷积核组成,第五、六层是连续的两个卷积层,由128个3×3×3的卷积核组成,其中每个三维卷积层的步长均为1、填充均为0。连续卷积之后加入空间批量归一化、修正线性单元,以提取淋巴结内部的空间信息。第一个三维最大池化层由32个1×2×2的最大池组成,第二个三维最大池化层由64个2×2×2的最大池组成,第三个三维最大池化层由128个2×2×2的最大池组成,其中每个三维最大池化层后均加入参数为0.5的<i>Dropout</i>层,以避免过拟合,提高模型稳定性。之后特征块平均池化取代传统3<i>D</i>网络的全连接层,以允许网络输入不同尺度3<i>D</i>样本进行训练;最后接入二分类层,采用二值交叉熵(<i>Binary Cross Entropy</i>, <i>BCE</i>)作为损失函数,输出分类结果。</p>
                </div>
                <div class="p1">
                    <p id="91">二值交叉熵损失函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>C</mtext><mtext>E</mtext></mrow></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mover accent="true"><mi>r</mi><mo>^</mo></mover></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mtext>l</mtext><mtext>b</mtext><mspace width="0.25em" /><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">其中:<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>r</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>表示为网络输出第<i>i</i>个样本的预测值; <i>r</i><sub><i>i</i></sub>表示为第<i>i</i>个样本对应的真值标签。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文3D分类网络结构" src="Detail/GetImg?filename=images/JSJY201910021_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文3D分类网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Proposed 3D classification network structure</p>

                </div>
                <h4 class="anchor-tag" id="95" name="95">1.3.2 特征块池化</h4>
                <div class="p1">
                    <p id="96">不同尺度3<i>D</i>样本x×y×z输入网络后,首先通过特征提取网络,结合样本原始空间信息提取潜在的深层特征,输出128个m×n×k的三维特征块。通过特征块池化方式提取每个特征块的一个值,代表该特征块的深层次特征,最终计算得到128个神经元的值,用以代表输入的3<i>D</i>样本整体的深层次特征。最后将128维深层次特征输入到二分类层进行判别,输出分类结果。最终实现基于特征块池化的3<i>D</i>网络允许输入不同尺度的3<i>D</i>样本进行训练的目的。</p>
                </div>
                <div class="p1">
                    <p id="97">对于特征块池化方式,本文提出两种:特征块最大池化(<i>Feature Block Maximum Pooling</i>, <i>FBMP</i>)和特征块平均池化(<i>Feature Block Average Pooling</i>, <i>FBAP</i>)。前者仅提取每个特征块内部的最大激活值,容易导致过拟合,不能代表该特征块的整体激活信息;后者通过计算每个特征块内部激活值的均值,汇总整体激活信息,起到正则化作用,防止过拟合,代表该特征块的整体激活信息。</p>
                </div>
                <div class="p1">
                    <p id="98">针对每个特征块,特征块最大池化的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="99"><i>V</i><sub>FBMP</sub>=max(<i>V</i>(<i>i</i>, <i>j</i>,<i>k</i>))      (9)</p>
                </div>
                <div class="p1">
                    <p id="100">其中: <i>V</i>(<i>i</i>, <i>j</i>,<i>k</i>)为三维特征块内部体素(<i>i</i>, <i>j</i>,<i>k</i>)的激活值;max(·)为最大值函数。</p>
                </div>
                <div class="p1">
                    <p id="101">针对每个特征块,特征块平均池化的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>B</mtext><mtext>Μ</mtext><mtext>Ρ</mtext></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ι</mi><mo>,</mo><mi>J</mi><mo>,</mo><mi>Κ</mi></mrow></munderover><mi>V</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mspace width="0.25em" /><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中: <i>V</i>(<i>i</i>, <i>j</i>,<i>k</i>)为三维特征块内部体素(<i>i</i>, <i>j</i>,<i>k</i>)的激活值;<i>N</i>为三维特征块的体素总数。</p>
                </div>
                <div class="p1">
                    <p id="104">对比传统3D网络,基于特征块池化的3D网络优势在于:1)基本不改变3D样本大小,完整保留样本的原始空间信息;2)针对形态尺度差异较大的3D样本,同时兼顾较大目标与较小目标的识别;3)在不增加计算量的前提下使得网络训练时间更短、精度更高。</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag">2 实验设计与结果分析</h3>
                <h4 class="anchor-tag" id="106" name="106">2.1 <b>实验数据集</b></h4>
                <div class="p1">
                    <p id="107">实验数据集来源于山西省肿瘤医院<i>CT</i>放射科,影像类型为静脉增强的头颈部<i>CT</i>序列图像,原始图像大小为512×512 <i>pixel</i>,切片厚度为0.625 <i>mm</i>。参照标准由4名经验丰富的专家手工注释。为了保证注释的完整性和准确性,4名放射科医师对每张头颈部<i>CT</i>图像标注两遍,结果包含两种真值:组织区域掩码、淋巴结掩码。第一遍由4名专家手动标注组织区域掩码,以便提取淋巴结医学分区;第二遍由4名专家独立标注淋巴结掩码。图6为数据集中不同形态及分布的颈部淋巴结样本。最终挑选出直径大于3 <i>mm</i>并由3名及以上专家共同注释的颈部淋巴结。最终获得70例,共计2 220张<i>CT</i>图像,其中包含1 140张颈部淋巴结图像。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同形态及分布的淋巴结样本" src="Detail/GetImg?filename=images/JSJY201910021_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同形态及分布的淋巴结样本  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.6 <i>Different forms and distributions of lymph node samples</i></p>

                </div>
                <h4 class="anchor-tag" id="109" name="109">2.2 <b>模型训练方法</b></h4>
                <div class="p1">
                    <p id="110">实验数据分为两部分:80%用于训练级联<i>FCN</i>模型和训练3<i>D</i>分类模型;剩余的20%作为测试数据来测试淋巴结的召回率、准确率等。针对数据增强,级联<i>FCN</i>模型的数据集使用随机镜像翻转、随机正负30°内旋转、随机裁剪及弹性形变等数据增强策略;3<i>D CNN</i>模型训练的数据集,由于正样本数量较少,为保持正负样本均衡,首先在(x, y,z)三个方向进行内的随机平移,然后根据3<i>D</i>样本的中心坐标进行三个角度的随机旋转进行增广,最后保持正负样本的比例接近1∶1。针对模型优化,级联<i>FCN</i>模型采用随机梯度下降(<i>Stochastic Gradient Descent</i>, <i>SGD</i>)算法,学习率初始化为0.01,衰减率设为0.1,批处理大小设置为8,动量设置为0.9,训练轮次为100,并在第30、60、90轮次时衰减学习率;三维分类模型除批处理大小设置为16以外,其余训练参数均与<i>FCN</i>模型保持一致。所有训练的网络模型均在<i>GPU Tesla M</i>40上使用<i>Pytorch</i>深度学习框架实现,全部模型训练约为12.5 <i>h</i>,测试所有病例的总时间约为120 <i>s</i>(15例<i>CT</i>序列,包含450张<i>CT</i>图像)。</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111">2.3 <b>结果分析</b></h4>
                <h4 class="anchor-tag" id="112" name="112">2.3.1 评价指标</h4>
                <div class="p1">
                    <p id="113">针对级联<i>FCN</i>模型,采用召回率来分析提取候选样本的性能。召回率<i>r</i>的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="114"><i>r</i>=<i>T</i><sub>t</sub>/(<i>T</i><sub>t</sub>+<i>F</i><sub>f</sub>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="115">其中:<i>T</i><sub>t</sub>为所有被检测出的真实颈部淋巴结的个数;<i>F</i><sub>f</sub>为所有未检测出的真实颈部淋巴结的个数;<i>T</i><sub>t</sub>+<i>F</i><sub>f</sub>为理论上检测到的所有真实颈部淋巴结的个数。</p>
                </div>
                <div class="p1">
                    <p id="116">针对3D分类模型,由于在去除假阳性过程中需要同时保证正负类的分类精度,而准确率(Accuracy, ACC)可以充分反映分类网络准确识别真阳性和假阴性的比率,故采用准确率来分析其对候选样本的分类性能。准确率<i>ACC</i>的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>C</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><msub><mrow></mrow><mtext>t</mtext></msub><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mtext>f</mtext></msub></mrow><mrow><mi>Τ</mi><msub><mrow></mrow><mtext>t</mtext></msub><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mtext>f</mtext></msub><mo>+</mo><mi>F</mi><msub><mrow></mrow><mtext>t</mtext></msub><mo>+</mo><mi>F</mi><msub><mrow></mrow><mtext>f</mtext></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中:<i>T</i><sub>t</sub>为所有被正确分类的淋巴结数量;<i>T</i><sub>f</sub>为所有被正确分类的负类数量;<i>F</i><sub>t</sub>为被误分类为淋巴结的负类数量;<i>F</i><sub>f</sub>为被误分类的淋巴结数量。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">2.3.2 候选识别结果与分析</h4>
                <div class="p1">
                    <p id="120">在候选识别阶段,通过对比召回率、每次扫描假阳性数、耗时等因素,分析不同提取算法对于提取候选的影响。为保证公平比较,除对比算法不同之外,采用同一批颈部淋巴结数据集并使用相同的数据增强策略。该阶段对提取候选的主流方法及本文方法进行对比实验,包括:<i>Ding</i>等<citation id="243" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出的改进<i>Faster R</i>-<i>CNN</i>算法,<i>Ronneberger</i>等<citation id="244" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出的<i>U</i>-<i>Net</i>算法,苗光等<citation id="245" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出的改进<i>U</i>-<i>Net</i>算法。基线算法为对比测试,在<i>FCN</i>提取淋巴结医学分区的基础上形态学提取候选。本文算法为级联<i>FCN</i>算法。</p>
                </div>
                <div class="p1">
                    <p id="121">表1中的数据可作如下对比:</p>
                </div>
                <div class="p1">
                    <p id="122">1)第1～2行为目标检测与语义分割的对比。<i>Improved Faster R</i>-<i>CNN</i>算法作为主流的医学影像目标检测框架,凭借设计优秀的区域候选网络(<i>Region Proposal Network</i>, <i>RPN</i>)及锚框设置取得相对较高的召回率,但由于<i>CT</i>图中颈部区域血管、食道、肌肉等无关组织的干扰,产生大量假阳性样本,对最终识别结果造成很大影响。分割模型<i>U</i>-<i>Net</i>通过分析目标周围上下文信息来限制假阳性样本数量,相较<i>Faster R</i>-<i>CNN</i>网络结构简单,在假阳性样本数量及运行时间上优势明显,但召回率相对较低。</p>
                </div>
                <div class="p1">
                    <p id="123">2)第2～3行为改进分割网络的对比。<i>U</i>-<i>Net</i>虽然限制假阳性样本数量,且相对耗时最少,但由于网络过深,导致网络训练速度较慢,召回率较差。<i>Improved U</i>-<i>Net</i>在网络结构中加入批量归一化、<i>Leaky</i>-<i>Relu</i>等,并采用联合损失进行训练,使得网络训练快速收敛,并提高网络的泛化能力,在其他指标表现相当的前提下召回率相较于<i>U</i>-<i>Net</i>有一定提升。</p>
                </div>
                <div class="p1">
                    <p id="124">3)第3～5行为单阶段与两阶段提取的对比。<i>Improved U</i>-<i>Net</i>虽然在运算耗时较少的前提下达到较高的召回率,但由于颈部区域众多干扰因素影响,候选样本数量仍然较高。而基线算法和本文算法通过两阶段的方式,先提取淋巴结感兴趣区域,避免无关组织干扰,在提高召回率的同时大幅减少假阳性样本数量,但由于多阶段的影响造成耗时增加。</p>
                </div>
                <div class="p1">
                    <p id="125">4)第4～5行为传统形态学方法与分割网络的对比。基线算法通过<i>FCN</i>提取淋巴结分区来避免无关组织干扰,使得召回率及假阳性样本数量均保持较好的水平,但在分区内仅依据淋巴结形态特点筛选符合条件的轮廓来提取候选样本,存在部分杂质轮廓被错误提取为候选样本。</p>
                </div>
                <div class="p1">
                    <p id="126">本文算法在基线算法基础上,采用<i>FCN</i>取代形态学,网络能够学习更深层次且更丰富的特征来提取候选,达到保持高召回率的同时限制候选样本数量,但相比其他所有算法耗时最长。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表</b>1 <b>候选识别阶段不同算法的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>.1 <i>Result comparison of different algorithms in</i><i>candidate identification stage</i></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td>算法</td><td>系统</td><td>召回率/<br />%</td><td>每次扫描<br />假阳性数</td><td>耗时/<br /><i>s</i></td></tr><tr><td>文献[12]算法</td><td><i>Improved Faster R</i>-<i>CNN</i></td><td>97.18</td><td>78</td><td>4</td></tr><tr><td><br />文献[17]算法</td><td><i>U</i>-<i>Net</i></td><td>91.23</td><td>36</td><td><b>2</b></td></tr><tr><td><br />文献[16]算法</td><td>Improved U-Net</td><td>93.65</td><td>33</td><td>3</td></tr><tr><td><br />基线算法</td><td>FCN</td><td>96.72</td><td>28</td><td>5</td></tr><tr><td><br />本文算法</td><td>Cascaded FCNs</td><td><b>97.23</b></td><td><b>16</b></td><td>6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法的识别结果" src="Detail/GetImg?filename=images/JSJY201910021_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法的识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Recognition results of different methods</p>

                </div>
                <h4 class="anchor-tag" id="130" name="130">2.3.3 去除假阳性结果与分析</h4>
                <div class="p1">
                    <p id="131">在去除假阳性阶段,通过对比准确率、耗时等因素,分析不同算法对于分类识别性能的影响。训练时为保证公平比较,除对比算法不同之外,采用同一批淋巴结候选样本数据并使用相同的数据增强策略。该阶段对去假阳性的主流方法及本文方法进行对比实验,包括:Xie等<citation id="246" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的多网络投票算法,Roth等<citation id="247" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出的2.5D CNN,苗光等<citation id="248" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出的3D CNN算法。基线算法为对比测试,基于特征块最大池化的3D CNN算法。本文算法为基于特征块平均池化的3D CNN算法。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表</b>2 <b>去除假阳性阶段不同算法的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab.2 Result comparison of different algorithms in false positives removal stage</p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />算法</td><td>系统</td><td>准确率/%</td><td>耗时/s</td></tr><tr><td><br />文献[14]算法</td><td>2D CNN</td><td>86.5</td><td>8</td></tr><tr><td><br />文献[15]算法</td><td>2.5D CNN</td><td>94.4</td><td><b>2</b></td></tr><tr><td><br />文献[16]算法</td><td>3D CNN</td><td>97.2</td><td>5</td></tr><tr><td><br />基线算法</td><td>3D CNN_ FBMP</td><td>98.2</td><td>3</td></tr><tr><td><br />本文算法</td><td>3D CNN_ FBAP</td><td><b>98.7</b></td><td>3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">表2中的数据可作如下对比:</p>
                </div>
                <div class="p1">
                    <p id="134">1)第1～2行为轴切面信息融合方式的对比。2D CNN算法训练三个模型分别提取三个轴切面信息,最后融合分类结果,其中每个模型仅学习单个轴切面的二维信息,导致其在准确率和运行时间等方面均表现不佳;2.5D CNN算法采用单一的二维网络将三个轴切面信息在特征层面融合,使得准确率和运行时间等方面相较于2D CNN提升明显,它相比其他所有算法耗时最少。</p>
                </div>
                <div class="p1">
                    <p id="135">2)第2～3行为不同网络类型的对比。2.5D CNN算法将轴切面组成三通道伪彩图像,仅利用轴切面信息,对于样本整体的空间信息利用不足,导致对难样例的区分效果较差,准确率难以继续提升。而3D CNN算法充分利用样本的完整空间信息学习到更具代表性的判别特征,有助于提高对难样例的识别能力,但由于网络参数及计算量增加,导致相较于2D CNN耗时增加。</p>
                </div>
                <div class="p1">
                    <p id="136">3)第3～5行为全连接与特征块池化的对比。3D CNN算法由于全连接层的存在,网络训练时需输入固定大小的样本,导致损失一些对分类结果非常重要的深层次特征,相较于基于特征块池化的网络准确率不佳,且全连接层导致耗时增加。基线算法与本文算法将3D CNN的全连接层替换为特征块池化,允许网络输入不同尺度的样本,兼顾较大目标与较小目标的识别,在网络参数减少的同时起着正则化作用,使得在准确率和耗时等方面相较于3D CNN有一定提升。</p>
                </div>
                <div class="p1">
                    <p id="137">4)第4～5行为不同特征块池化的对比。基线算法将3D CNN的全连接层替换为特征块最大池化,由于最大池化仅提取每个三维特征块内部的最大激活值,容易导致过拟合。</p>
                </div>
                <div class="p1">
                    <p id="138">相比基线算法,本文算法通过特征块平均池化替换特征块最大池化,计算每个三维特征块内部激活值的均值,汇总整体激活信息,起到正则化作用,防止过拟合,相比其他所有算法在运行耗时相对较少的情况下取得最高的准确率。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">2.3.4 整体结果与分析</h4>
                <div class="p1">
                    <p id="140">整体算法流程分为两阶段:第一阶段,采用级联FCN提取淋巴结医学分区及分区内提取候选样本,然后合成对应的候选3D样本。第二阶段,针对输入数据,若候选3D样本的深度过小,则插值到网络输入的最小尺度;否则不调整,最大限度保留样本的空间信息。针对网络,3D CNN_FBAP对输入的不同尺度候选样本进行分类,得到分类结果。从图8～9中可看出,在去除假阳性之后,最终准确率稳定在93.26%。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 总体结果损失" src="Detail/GetImg?filename=images/JSJY201910021_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 总体结果损失  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Loss of overall results</p>

                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 总体结果准确率" src="Detail/GetImg?filename=images/JSJY201910021_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 总体结果准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Accuracy of overall results</p>

                </div>
                <div class="p1">
                    <p id="143">本文算法在自动识别颈部淋巴结时,仍然存在一些局限性:</p>
                </div>
                <div class="p1">
                    <p id="144">1)在提取候选阶段,如图10所示,易识别样本分布独立、易于识别;部分难样例为与周围组织存在粘连且灰度值相近,在提取分区时需要很高的识别精度。而级联FCN的识别精度有限,可能导致某些淋巴结被误认为肌肉等多余组织而产生错误分割的情况。针对这种情况,将探索更适合这种情况下的识别算法。</p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201910021_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同识别难度的淋巴结样本" src="Detail/GetImg?filename=images/JSJY201910021_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 不同识别难度的淋巴结样本  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201910021_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Lymph node samples with different recognition difficulties</p>

                </div>
                <div class="p1">
                    <p id="146">2)在生成候选3D样本阶段,依据坐标之间欧氏距离将距离接近的样本进行合并,由于可能出现正样本和负样本的欧氏距离更接近的情况,导致合并后的候选3D样本并非理想的3D样本。针对这种情况,将尝试提出更适合的距离度量算法来克服这种局限性。</p>
                </div>
                <div class="p1">
                    <p id="147">3)相比其他算法,本文算法虽然在召回率及准确率等方面存在优势,但整体识别耗时相对较长。针对这种情况,将尝试端到端的网络来保持识别优势的同时缩短耗时。</p>
                </div>
                <h3 id="148" name="148" class="anchor-tag">3 结语</h3>
                <div class="p1">
                    <p id="149">针对现有算法识别颈部淋巴结效率不高,存在大量假阳性且整体假阳性去除效果不理想的问题, 本文提出了一种新的基于级联全卷积神经网络的识别算法。实验结果表明,针对提取候选样本,采用级联FCN可以保持高灵敏度的同时限制候选样本的数量;针对目标形态尺度差异较为明显的3D样本,基于特征块平均池化的3D分类网络允许输入不同尺度的3D样本,充分利用3D样本的原始空间信息去学习更深层次的判别特征,获得最优的分类精度。在3D医学图像的研究中,该算法相对简单高效,且能够更为精确地执行检测任务,对临床的诊断和治疗具有重要的意义。下一步将利用PSPNet(Pyramid Scene Parsing Network)、Mask R-CNN(Mask Region-Based Convolutional Networks)等较为复杂但精度更高的分割网络来提取淋巴结样本,并探索将多阶段网络融合为端到端网络,以便提高精度的同时减少耗时。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="178">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRSAB70FA679A6E99EA4FBC0E06B81CE4AB&amp;v=MTIwNTdjTEtHZEc2M29sQ2Jab0plWFV3dW1jWG5FME9TQXJpcW1BOWVNSGhRY3Z0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJ5MndxQT1OaWZaZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>PATEL N U,LIND K E,Mc KINNEY K,et al.Clinical validation of a predictive model for the presence of cervical lymph node metastasis in papillary thyroid cancer[J].American Journal of Neuroradiology,2018,39(4):756-761.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cervical lymph node metastases of papillary thyroid carcinoma,in the central and lateral compartments,in children and adolescents:predictive factors">

                                <b>[2]</b>SPINELLI C,TOGNETTI F,STRAMBI S,et al.Cervical lymph node metastases of papillary thyroid carcinoma,in the central and lateral compartments,in children and adolescents:predictive factors[J].World Journal of Surgery,2018,42(8):1-10.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer">

                                <b>[3]</b>BEJNORDI B E,VETA M,van DIEST P J,et al.Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer[J].JAMA,2017,318(22):2199-2210.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201511027&amp;v=Mjg1MThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluaFdyM0FOaWZZWkxHNEg5VE5ybzlIWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>魏骏,何凌,车坤,等.CT图像的颈部淋巴结半自动分割算法[J].计算机工程与设计,2015,36(11):3014-3018.(WEIJ,HE L,CHE K,et al.Semi-automatic detection and segmentation of neck lymph nodes in CT image[J].Computer Engineering and Design,2015,36(11):3014-3018.)
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD6647A33DC451A90888469C63126D7146&amp;v=MTgxNDVRMHd6eDRiNGp0N1FRemtyeE0zZjhhVFJMNlpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4Ynkyd3FBPU5pZmNhclcrR3RhOXJJd3hGKzhLRA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>KAN Y,DONG D,ZHANG Y,et al.Radiomic signature as a predictive factor for lymph node metastasis in early-stage cervical cancer[J].Journal of Magnetic Resonance Imaging,2019,49(1):304-310.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning SO (3)equivariant representations with spherical CNNs">

                                <b>[6]</b>ESTEVES C,ALLEN-BLANCHETTE C,MAKADIA A,et al.Learning SO(3)equivariant representations with spherical CNNs[EB/OL].[2019-01-10].http://openaccess.thecvf.com/content_ECCV_2018/papers/Carlos_Esteves_Learning_SO3_Equivariant_ECCV_2018_paper.pdf.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial examples that fool both computer vision and time-limited humans">

                                <b>[7]</b>ELSAYED G F,SHANKAR S,CHEUNG B,et al.Adversarial examples that fool both computer vision and time-limited humans[EB/OL].[2019-01-10].http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans.pdf.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Che XNet:radiologistlevel pneumonia detection on chest X-rays with deep learning">

                                <b>[8]</b>RAJPURKAR P,IRVIN J,ZHU K,et al.Che XNet:radiologistlevel pneumonia detection on chest X-rays with deep learning[EB/OL].[2019-01-10].https://arxiv.org/pdf/1711.05225.pdf.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cardiologist-level arrhythmia detection with convolutional neural networks">

                                <b>[9]</b>RAJPURKAR P,HANNUN A Y,HAGHPANAHI M,et al.Cardiologist-level arrhythmia detection with convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1707.01836.pdf.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning-based computer-aided diagnosis system for localization and diagnosis of metastatic lymph nodes on ultrasound:a pilot study">

                                <b>[10]</b>LEE J H,BAEK J H,KIM J H,et al.Deep learning-based computer-aided diagnosis system for localization and diagnosis of metastatic lymph nodes on ultrasound:a pilot study[J].Thyroid,2018,28(10):1332-1338.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning deep features for discriminative localization">

                                <b>[11]</b>ZHOU B,KHOSLA A,LAPEDRIZA A,et al.Learning deep features for discriminative localization[C]//Proceedings of the 2016IEEE Conference on Computer Vision and Pattern Recognition.Piscataway:IEEE,2016:2921-2929.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks">

                                <b>[12]</b>DING J,LI A,HU Z,et al.Accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks[C]//Proceedings of the 2017 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 10435.Berlin:Springer,2017:559-567.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks">

                                <b>[13]</b>CHRIST P F,ETTLINGER F,GRN F,et al.Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1702.05970.pdf.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEB10EA11F8A97E877C4C399C5DC0A9A5&amp;v=MTI1MzhFVW1Uc09TM2JyM3hkQkNyTGxUTXVhQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGJ5MndxQT1OaWZPZmNiS0g5RzUzbzVFRXVOK0JYdE14eA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>XIE H,YANG D,SUN N,et al.Automated pulmonary nodule detection in CT Images using deep convolutional neural networks[J].Pattern Recognition,2018,85:109-119.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A New 2.5D Representation for Lymph Node Detection Using Random Sets of Deep Convolutional Neural Network Observations">

                                <b>[15]</b>ROTH H R,LU L,SEFF A,et al.A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations[C]//Proceedings of the 2014 International Conference on Medical Image Computing and Computer-Assisted Intervention.Berlin:Springer,2014:520-527.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805016&amp;v=MTMzMTgzQUx5clBaTEc0SDluTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>苗光,李朝锋.二维和三维卷积神经网络相结合的CT图像肺结节检测方法[J].激光与光电子学进展,2018,55(5):129-137.(MIAO G,LI C F.Detection of pulmonary nodules CTimages combined with two-dimensional and three-dimensional convolution neural networks[J].Laser&amp;Optoelectronics Progress,2018,55(5):129-137.)
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-net:Convolutional networks for biomedical image segmentation">

                                <b>[17]</b>RONNEBERGER O,FISCHER P,BROX T.U-Net:convolutional networks for biomedical image segmentation[C]//Proceedings of the 2015 International Conference on Medical Image Computing and Computer-Assisted Intervention,LNCS 9351.Berlin:Springer,2015:234-241.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                IOFFE S,SZEGEDY C.Batch normalization:accelerating deep network training by reducing internal covariate shift[EB/OL].[2019-01-10].https://arxiv.org/pdf/1502.03167.pdf.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Delving deep into rectifiers:Surpassing Human-level performance on ImageNet classification">

                                <b>[19]</b>HE K,ZHANG X,REN S,et al.Delving deep into rectifiers:Surpassing human-level performance on Image Net classification[C]//Proceedings of the 2015 IEEE International Conference on Computer Vision.Piscataway:IEEE,2015:1026-1034.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the influence of dice loss function in multi-class organ segmentation of abdominal CTusing 3D fully convolutional networks">

                                <b>[20]</b>SHEN C,ROTH H R,ODA H,et al.On the influence of dice loss function in multi-class organ segmentation of abdominal CTusing 3D fully convolutional networks[EB/OL].[2019-01-10].https://arxiv.org/pdf/1801.05912.pdf.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CT organ segmentation using GPU data augmentation,unsupervised labels and IOUloss">

                                <b>[21]</b>RISTER B,YI D,SHIVAKUMAR K,et al.CT organ segmentation using GPU data augmentation,unsupervised labels and IOUloss[EB/OL].[2019-01-10].https://arxiv.org/pdf/1811.11226.pdf.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3d-r2n2 A unified approach for single and multi-view 3d object reconstruction">

                                <b>[22]</b>CHOY C B,XU D,GWAK J,et al.3D-R2N2:a unified approach for single and multi-view 3D object reconstruction[C]//Proceedings of the 2016 European Conference on Computer Vision,LNCS 9912.Berlin:Springer,2016:628-644.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201910021" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201910021&amp;v=MTk1MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5oV3IzQUx6N0JkN0c0SDlqTnI0OUhaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
