<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136662044846250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907011%26RESULT%3d1%26SIGN%3da9G50%252fBEJm49FbQok3MW5j3vAbQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907011&amp;v=MDE3OThyQUx6N0JkN0c0SDlqTXFJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 词嵌入法 ">1 词嵌入法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="2 LSTM网络 ">2 LSTM网络</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="3 情感与语义信息融合方法 ">3 情感与语义信息融合方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="3.1 &lt;b&gt;生成语义向量&lt;/b&gt;">3.1 <b>生成语义向量</b></a></li>
                                                <li><a href="#56" data-title="3.2 &lt;b&gt;生成情感向量&lt;/b&gt;">3.2 <b>生成情感向量</b></a></li>
                                                <li><a href="#61" data-title="3.3 &lt;b&gt;语义向量融合情感向量&lt;/b&gt;">3.3 <b>语义向量融合情感向量</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="4 实验 ">4 实验</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="4.1 &lt;b&gt;实验数据&lt;/b&gt;">4.1 <b>实验数据</b></a></li>
                                                <li><a href="#78" data-title="4.2 &lt;b&gt;实验设计&lt;/b&gt;">4.2 <b>实验设计</b></a></li>
                                                <li><a href="#90" data-title="4.3 &lt;b&gt;实验流程&lt;/b&gt;">4.3 <b>实验流程</b></a></li>
                                                <li><a href="#97" data-title="4.4 &lt;b&gt;实验结果与分析&lt;/b&gt;">4.4 <b>实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#104" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#66" data-title="图1 两种融合方法的网络结构">图1 两种融合方法的网络结构</a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验数据信息&lt;/b&gt;"><b>表</b>1 <b>实验数据信息</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;词典词汇量&lt;/b&gt;"><b>表</b>2 <b>词典词汇量</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同模型的实验结果&lt;/b&gt;"><b>表</b>3 <b>不同模型的实验结果</b></a></li>
                                                <li><a href="#100" data-title="图2 不同模型的accuracy-epochs变化">图2 不同模型的accuracy-epochs变化</a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;情感资源与向量维数的实验结果&lt;/b&gt;"><b>表</b>4 <b>情感资源与向量维数的实验结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="121">


                                    <a id="bibliography_1" title=" 吴鹏, 应杨, 沈思.基于双向长短期记忆模型的网民负面情感分类研究[J].情报学报, 2018, 37 (08) :845-853. (WU P, YING Y, SHEN S.Negative emotions of online users&#39; analysis based on bidirectional long short-term memory[J].Journal of the China Society for Scientific and Technical Information, 2018, 37 (8) :845-853.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201808011&amp;v=MDQwNzN5L25WTHJBTkMvVGJMRzRIOW5NcDQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         吴鹏, 应杨, 沈思.基于双向长短期记忆模型的网民负面情感分类研究[J].情报学报, 2018, 37 (08) :845-853. (WU P, YING Y, SHEN S.Negative emotions of online users&#39; analysis based on bidirectional long short-term memory[J].Journal of the China Society for Scientific and Technical Information, 2018, 37 (8) :845-853.) 
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_2" title=" 赵刚, 徐赞.基于机器学习的商品评论情感分析模型研究[J].信息安全研究, 2017, 3 (2) :166-170. (ZHAO G, XU Z.Research on the sentiment analysis model of product reviews based on machine learning[J].Journal of Information Security Research, 2017, 3 (2) :166-170.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAQY201702010&amp;v=MDI1ODU3RzRIOWJNclk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHJBUFN6YWQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         赵刚, 徐赞.基于机器学习的商品评论情感分析模型研究[J].信息安全研究, 2017, 3 (2) :166-170. (ZHAO G, XU Z.Research on the sentiment analysis model of product reviews based on machine learning[J].Journal of Information Security Research, 2017, 3 (2) :166-170.) 
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_3" title=" TETSUYA N, JEONGHEE Y.Sentiment analysis:Capturing favorability using natural language processing [C]// Proceedings of the 2nd International Conference on Knowledge Capture.New York:ACM, 2003:70-77." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis:Capturing favorability using natural language processing">
                                        <b>[3]</b>
                                         TETSUYA N, JEONGHEE Y.Sentiment analysis:Capturing favorability using natural language processing [C]// Proceedings of the 2nd International Conference on Knowledge Capture.New York:ACM, 2003:70-77.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_4" title=" WEI J, HUNG H H, ROHINI K S.OpinionMiner:a novel machine learning system for Web opinion mining and extraction [C]// Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2009:1195-1204." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OpinionMiner:A novel machine learning system for web opinion mining and extraction">
                                        <b>[4]</b>
                                         WEI J, HUNG H H, ROHINI K S.OpinionMiner:a novel machine learning system for Web opinion mining and extraction [C]// Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2009:1195-1204.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_5" title=" ZOU H, TANG X, XIE B, et al.Sentiment classification using machine learning techniques with syntax features [C]// Proceedings of the 2015 International Conference on Computational Science and Computational Intelligence.Piscataway, NJ:IEEE, 2015:175-179." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sentiment classification using machine learning techniques with syntax features">
                                        <b>[5]</b>
                                         ZOU H, TANG X, XIE B, et al.Sentiment classification using machine learning techniques with syntax features [C]// Proceedings of the 2015 International Conference on Computational Science and Computational Intelligence.Piscataway, NJ:IEEE, 2015:175-179.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_6" title=" YIN R, LI P, WANG B.Sentiment lexical-augmented convolutional neural networks for sentiment analysis [C]// Proceedings of the 2017 IEEE 2nd International Conference on Data Science in Cyberspace.Piscataway, NJ:IEEE, 2017:630-635." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sentiment lexical-augmented convolutional neural networks for sentiment analysis">
                                        <b>[6]</b>
                                         YIN R, LI P, WANG B.Sentiment lexical-augmented convolutional neural networks for sentiment analysis [C]// Proceedings of the 2017 IEEE 2nd International Conference on Data Science in Cyberspace.Piscataway, NJ:IEEE, 2017:630-635.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_7" title=" 於雯, 周武能.基于LSTM的商品评论情感分析[J].计算机系统应用, 2018, 27 (8) :159-163. (YU W, ZHOU W N.Sentiment analysis of commodity reviews based on LSTM[J].Computer Systems and Applications, 2018, 27 (8) :159-163.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201808026&amp;v=MDgyNDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHJBUFRuU2Q3RzRIOW5NcDQ5SFlvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         於雯, 周武能.基于LSTM的商品评论情感分析[J].计算机系统应用, 2018, 27 (8) :159-163. (YU W, ZHOU W N.Sentiment analysis of commodity reviews based on LSTM[J].Computer Systems and Applications, 2018, 27 (8) :159-163.) 
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_8" title=" 丁晟春, 吴靓婵媛, 李红梅.基于SVM的中文微博观点倾向性识别[J].情报学报, 2016, 35 (12) :1235-1243. (DING S C, WU J C Y, LI H M.SVM-based Chinese microblogging viewpoint orientation recognition[J].Journal of the China Society for Scientific and Technical Information, 2016, 35 (12) :1235-1243.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201612001&amp;v=MTgwMDNUYkxHNEg5Zk5yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMckFOQy8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         丁晟春, 吴靓婵媛, 李红梅.基于SVM的中文微博观点倾向性识别[J].情报学报, 2016, 35 (12) :1235-1243. (DING S C, WU J C Y, LI H M.SVM-based Chinese microblogging viewpoint orientation recognition[J].Journal of the China Society for Scientific and Technical Information, 2016, 35 (12) :1235-1243.) 
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_9" title=" BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2003, 3:1137-1155." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Neural Probabilistic Language Model">
                                        <b>[9]</b>
                                         BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2003, 3:1137-1155.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_10" title=" MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">
                                        <b>[10]</b>
                                         MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_11" title=" 何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2017, 40 (4) :773-790. (HE Y X, SUN S T, NIU F F, et al.An emotional semantic enhanced deep learning model for microblog emotion analysis [J].Chinese Journal of Computers, 2017, 40 (4) :773-790.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704001&amp;v=MzA1NTBiTXE0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkxyQUx6N0Jkckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2017, 40 (4) :773-790. (HE Y X, SUN S T, NIU F F, et al.An emotional semantic enhanced deep learning model for microblog emotion analysis [J].Chinese Journal of Computers, 2017, 40 (4) :773-790.) 
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_12" title=" YANG Z, YANG D, DYER C, et al.Hierarchical attention networks for document classification [C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2016:1480-1489." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical attention networks for document classification">
                                        <b>[12]</b>
                                         YANG Z, YANG D, DYER C, et al.Hierarchical attention networks for document classification [C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2016:1480-1489.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_13" title=" WANG Y Q, HUANG M L, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:606-615." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">
                                        <b>[13]</b>
                                         WANG Y Q, HUANG M L, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:606-615.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_14" title=" ALEC Y, ABHISHEK.V.Deep CNN-LSTM with combined kernels from multiple branches for IMDB review sentiment analysis [C]// Proceedings of the 2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference.Piscataway, NJ:IEEE, 2017:540-546." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep CNN-LSTM with combined kernels from multiple branches for IMDB review sentiment analysis">
                                        <b>[14]</b>
                                         ALEC Y, ABHISHEK.V.Deep CNN-LSTM with combined kernels from multiple branches for IMDB review sentiment analysis [C]// Proceedings of the 2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference.Piscataway, NJ:IEEE, 2017:540-546.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_15" title=" MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space [C]// Proceedings of the 2013 International Conference on Learning Representations.Scottsdale, Arizona:[s.n.], 2013:1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Efficient Estimation of Word Representations in Vector Space,&amp;quot;">
                                        <b>[15]</b>
                                         MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space [C]// Proceedings of the 2013 International Conference on Learning Representations.Scottsdale, Arizona:[s.n.], 2013:1-12.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     谭松波.酒店评论数据[EB/OL].[2018- 10- 20].http://www.datatang.com/data/11970. (TAN S B.Hotel review data [EB/OL].[2018- 10- 20].http://www.datatang.com/data/11970.) </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-08 13:01</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),1931-1935 DOI:10.11772/j.issn.1001-9081.2018112375            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>融合情感与语义信息的情感分析方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%9F%E4%BB%95%E6%9E%97&amp;code=40717769&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孟仕林</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E8%95%B4%E9%BE%99&amp;code=35866726&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵蕴龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%85%B3%E4%B8%9C%E6%B5%B7&amp;code=34115389&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关东海</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BF%9F%E8%B1%A1%E5%B9%B3&amp;code=33943587&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">翟象平</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0014291&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京航空航天大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%A7%E4%B8%9A%E5%8C%96%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=0069758&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">软件新技术与产业化协同创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在使用词嵌入法进行词转向量时, 两个反义词会转换成相近的向量。如果这两个词是情感词, 将会导致词的情感信息的丢失, 这在情感分析任务中是不合理的。为了解决这个问题, 提出了一种在词嵌入的基础上增加情感向量来获取情感信息的方法。首先利用情感词典资源构建情感向量, 将其与词嵌入法得到的词向量融合在一起;然后采用双向长短期记忆 (BiLSTM) 网络获取文本的特征;最后对文本的情感进行分类。在4个数据集上分别对该方法与未融合情感向量的方法进行了实验。实验结果表明所提方法分类准确度与F1值都高于未融合方法, 说明了加入情感向量有助于提高情感分析的性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E5%B5%8C%E5%85%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词嵌入;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E8%AF%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感词;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E5%90%91%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双向长短期记忆网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孟仕林 (1994—) , 男, 安徽界首人, 硕士研究生, CCF会员, 主要研究方向:数据挖掘、情感分析;;
                                </span>
                                <span>
                                    *赵蕴龙 (1975—) , 男, 黑龙江哈尔滨人, 教授, 博士, CCF会员, 主要研究方向:无线网络、群体计算、说话人识别、数据挖掘、可穿戴计算技术;电子邮箱zhaoyunlong@nuaa.edu.cn;
                                </span>
                                <span>
                                    关东海 (1981—) , 男, 黑龙江哈尔滨人, 副教授, 博士, CCF会员, 主要研究方向:语音识别、数据挖掘、人工智能;;
                                </span>
                                <span>
                                    翟象平 (1984—) , 男, 山东淄博人, 副教授, 博士, CCF会员, 主要研究方向:普适计算、蜂群无人系统、群体智能、数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国防基础科研计划资助项目 (JCKY2016605B006);</span>
                                <span>江苏省“六大人才高峰”高层次人才项目 (XYDXXJS-031);</span>
                                <span>中央高校基本科研业务费专项 (90YAH16042);</span>
                    </p>
            </div>
                    <h1><b>Sentiment analysis method combining sentiment and semantic information</b></h1>
                    <h2>
                    <span>MENG Shilin</span>
                    <span>ZHAO Yunlong</span>
                    <span>GUAN Donghai</span>
                    <span>ZHAI Xiangping</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics</span>
                    <span>Collaborative Innovation Center of Novel Software Technology and Industrialization</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>When using word embedding method for word-to-vector, two antonyms are converted into similar vectors. If they are sentiment words, it will lead to the loss of sentimental information, which is unreasonable in sentiment analysis task. To solve this problem, a method of adding sentiment vectors to obtain sentiment information based on word embedding was proposed. Firstly, the sentiment vector was constructed by using sentiment lexicon, and combined with word vector obtained by word embedding method. Then, a bidirectional Long Short Term Memory (BiLSTM) network was used to obtain the characteristics of text. Finally, the sentiment of text was classified. Experiments of the proposed method and the method without fusing sentimental vector were carried out on four datasets. The experimental results show that the classification accuracy and F1 score of the proposed method are higher than those of the method without fusion, which indicates that adding sentimental vectors is beneficial to improve the performance of sentiment analysis.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=word%20embedding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">word embedding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20word&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment word;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=bidirectional%20LSTM%20(BiLSTM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">bidirectional LSTM (BiLSTM) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    MENG Shilin, born in 1994, M. S. candidate. His research interests include data mining, sentiment analysis. ;
                                </span>
                                <span>
                                    ZHAO Yunlong, born in 1975, Ph. D. , professor. His research interests include wireless network, crowd computing, speaker recognition, data mining, wearable computing technology. ;
                                </span>
                                <span>
                                    GUAN Donghai, born in 1981, Ph. D. , associate professor. His research interests include speech recognition, data mining, artificial intelligence. ;
                                </span>
                                <span>
                                    ZHAI Xiangping, born in 1984, Ph. D. , associate professor. His research interests include ubiquitous computing, swarm unmanned system, collective intelligence, data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-03</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Defense Basic Scientific Research Program (JCKY2016605B006);</span>
                                <span>the Six Talent Peaks Project of Jiangsu Province (XYDXXJS-031);</span>
                                <span>the Fundamental Research Funds for the Central Universities (90YAH16042);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="36">随着社交网络与电子商务的发展, 网民在上网的过程中会产生大量带有情感的评论数据。这些海量的评论数据引起了越来越多学者的关注, 他们可以使用网民对热点事件的评论来了解大众的舆论倾向<citation id="153" type="reference"><link href="121" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 进一步管理、引导和控制事件的发展。也可以使用购物者对商品的评论数据<citation id="154" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>来了解商品的质量, 对未来的购物行为起到一定的参考。目前对文本评论的情感分析主要分为两种方法:基于情感词典<citation id="155" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>的方法与基于机器学习<citation id="156" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的方法。基于情感词典的方法是利用句子中的情感词与一些影响情感的词的组合来判断句子的情感倾向, 它能很好地利用情感词来反映句子的情感倾向, 不过这种方法非常依赖情感词库的构建, 并且同一个词在不同的领域内所表达的情感倾向可能是不同的, 所以这种方法有一定的局限性。基于机器学习的方法是利用标记好的文本训练一个分类器, 其中重要的两个步骤是构造特征与选择分类器。构造特征是将词转化为能表示情感的向量, 主要的方法有词袋法与词嵌入法。分类器主要有支持向量机 (Support Vector Machine, SVM) 、朴素贝叶斯 (Naive Bayes) 、卷积神经网络 (Convolution Neural Network, CNN) 与长短期记忆 (Long Short Term Memory, LSTM) 网络<citation id="157" type="reference"><link href="129" rel="bibliography" /><link href="131" rel="bibliography" /><link href="133" rel="bibliography" /><link href="135" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">近几年, 深度神经网络在图像识别与语音识别领域了较大的突破, 于是大家也将这一方法应用到情感分析的研究上。Bengio等<citation id="158" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用神经网络语言模型学习每个词的分布式表示与词序列的概率函数, 将每个词转化成低维、连续的向量。Mikolov等<citation id="159" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>通过对频繁出现的词进行子抽样来加速词向量的训练, 同时也提出了负采样的方法。通过语言模型获得的词向量在一定程度上能表达句子的语义信息, 它能很好地代替词袋法来解决自然语言处理中的一些问题。不过针对情感分析这个问题, 词向量并不能反映出一个词的情感倾向, 比如“好”与“坏”这两个词的词向量非常相似, 这是不太合理的, 因此, 有一些学者开始研究如何利用句子中表达情感信息的成分来提高情感分类效果, 比如句子中包含的表情符号和一些情感词<citation id="160" type="reference"><link href="121" rel="bibliography" /><link href="131" rel="bibliography" /><link href="141" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">6</a>,<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="38">循环神经网络 (Recurrent Neural Network, RNN) 是一种具有记忆功能的神经网络, 适合序列数据的建模, 它在语音识别、自然语言处理等领域取得了成功。Yang等<citation id="161" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了基于注意力机制的网络, 改进了6种文本分类任务的效果;Wang等<citation id="162" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>通过使用基于注意力的长短期记忆网络来处理Aspect-level的情感分析问题;Alec等<citation id="163" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>通过使用CNN与LSTM层的多个分支的组合核来描述一种新的情感分析方法, 在互联网电影数据库 (Internet Movie DataBase, IMDB) 评论情绪数据集中取得了最高的准确度。本文使用双向长短期记忆 (Bidirectional Long Short Term Memory, BiLSTM) 网络分类器进行情感的预测, 它用两个不同的循环层分别从正向和反向对数据进行扫描, 不仅利用了过去的数据, 还利用了未来的数据, 进一步提高了网络性能。</p>
                </div>
                <div class="p1">
                    <p id="39">综上所述, 本文提出了一种融合情感与语义信息的情感分析方法, 即利用情感词的情感信息构造出情感向量, 与语言模型生成的向量 (称之为语义向量) 相结合来表示文本, 使用双向LSTM作为分类器, 充分学习文本的序列特征, 对商品评论与电影评论数据进行情感分析。</p>
                </div>
                <h3 id="40" name="40" class="anchor-tag">1 词嵌入法</h3>
                <div class="p1">
                    <p id="41">词嵌入是将词映射到低维密集向量的方法, 解决了使用词袋法带来的稀疏问题。它是从大量文本语料中以无监督的方式学习语义知识的一种模型, 通过学习文本来用词向量的方式表征词的语义信息, 即通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。在众多词嵌入方法中, skim-gram模型是使用较广泛的一种, skim-gram使用输入层、隐含层、softmax层三层神经网络训练出一个模型, 根据词共现法将句子中的词构造成 (输入词、输出词) 的单词对。再将单词对转成one-hot编码的形式输入到神经网络中训练, 模型采用了负采样的方法选择性地更新权重矩阵, 降低了训练代价并且改善所得到词向量的质量。网络训练完成后, 获得隐含层的权重矩阵<b><i>W</i></b><sup><i>n</i>*<i>d</i></sup>, 权重矩阵的每一行就代表一个词的词向量, 这里本文称为语义向量, <i>n</i>表示语料中词的个数, <i>d</i>表示词向量的维数。经过词嵌入方法的转化, 词和文本的语义向量表示如下:</p>
                </div>
                <div class="p1">
                    <p id="42"><b><i>w</i></b><sub><i>i</i></sub>= <b><i>row</i></b> (<b><i>W</i></b>, <i>i</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="43"><b><i>S</i></b><sub><i>W</i></sub>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>n</i></sub>]      (2) </p>
                </div>
                <div class="p1">
                    <p id="44">其中:<b><i>w</i></b><sub><i>i</i></sub>表示第<i>i</i>个词的语义向量, <b><i>S</i></b><sub><i>W</i></sub>表示文本文本的语义向量, <b><i>row</i></b>代表取行向量。通过skim-gram模型得到的词向量可以很好地捕捉语义单元之间潜在的语义关系, 且训练语料越多, 词向量蕴含意义越丰富。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">2 LSTM网络</h3>
                <div class="p1">
                    <p id="46">长短期记忆 (<i>LSTM</i>) 网络是循环神经网络的一种, 它既保留了循环神经网络处理序列数据的能力, 又解决了序列学习过程时存在的长期依赖问题, 避免梯度消失和梯度爆炸现象。<i>LSTM</i>通过“记忆单元”和“门”控制器的巧妙设计实现序列数据学习能力的提升, 它由记忆单元、输入门、遗忘门和输出门四个主要元素组成。其中:遗忘门<b><i>f</i></b>决定记忆单元前一个状态信息的留存, 输入门<b><i>i</i></b>控制记忆单元中当前时刻信息的输入, 记忆单元<b><i>c</i></b>根据当前输入信息更新记忆状态, 再由输出门<b><i>o</i></b>判断记忆单元对下一个状态的输出结果。下面是LSTM的结构和计算公式:</p>
                </div>
                <div class="p1">
                    <p id="47"><b><i>f</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>f</i></sub>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>f</i></sub>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="48"><b><i>i</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>i</i></sub>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>i</i></sub>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="49" class="code-formula">
                        <mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>*</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="50">其中:<b><i>h</i></b><sub><i>t</i></sub>表示<i>t</i>时刻记忆单元的状态, <b><i>x</i></b><sub><i>t</i></sub>表示<i>t</i>时刻的信息输入, <b><i>W</i></b>是权重矩阵, <b><i>b</i></b>是函数的偏置项, <i>σ</i>是sigmoid函数。</p>
                </div>
                <div class="p1">
                    <p id="51">双向长短期记忆模型由两层LSTM模型组成:一层学习顺序输入数据的特征, 另一层学习逆序输入数据的特征, 这种结构使得双向LSTM可以更充分学习输入序列数据中词语的上下文信息, 在后续内容中BiLSTM即代表双向LSTM。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">3 情感与语义信息融合方法</h3>
                <div class="p1">
                    <p id="53">情感与语义信息融合方法是将语义向量与情感向量结合作为情感分析任务的输入, 利用双向<i>LSTM</i>分类器对标记好的数据进行训练, 生成情感分类器。主要包括:生成语义向量、生成情感向量、语义向量融合情感向量。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">3.1 <b>生成语义向量</b></h4>
                <div class="p1">
                    <p id="55">本文使用<i>Google</i>开源的工具<i>Word</i>2<i>vec</i><citation id="164" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>获取语义向量, 以新闻数据作为训练语料, 共现窗口设置为5, 输出向量维数设为100。经过<i>Word</i>2<i>vec</i>工具训练之后每个词被转化成100维的语义向量。在对文本进行数字化表示的时候, 由于文本的长度长短不一, 为了保持文本序列的一致性, 本文取前100个词的语义向量, 如果文本的词汇数量小于100, 不足的词数使用等维度的全0向量补充, 这样一段文本就可以用100个语义向量序列表示。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56">3.2 <b>生成情感向量</b></h4>
                <div class="p1">
                    <p id="57">使用<i>Word</i>2<i>vec</i>工具生成的语义向量能很好表示词语的语义信息, 但是缺少了词的情感信息。为了弥补这一缺点, 本文针对此情感倾向构造出情感向量。受到基于情感词典方法的启发, 本文发现影响文本情感的词不仅仅有积极情感词与消极情感词, 还包括一些否定词、转折词与主张词, 这些词按照一定的语法结构综合地影响文本的情感倾向, 因此本文将词分成6大类, 分别是积极词、消极词、中性词、否定词、转折词与主张词, 采用类似<i>one</i>-<i>hot</i>编码的方式构造一个6维的向量, 这6维代表着6类词语, 如果一个词属于其中的一类, 则相应位置的数值置为1, 其余置为0。比如“喜欢”这个词的词性是属于积极的, 那它的情感向量就表示为[1, 0, 0, 0, 0, 0]。</p>
                </div>
                <div class="p1">
                    <p id="58">上述方法生成的情感向量包含词的情感信息, 然后将其应用到情感分析任务中。在对词进行分类的步骤中, 本文参考了台湾大学的<i>NTUSD</i> (<i>National Taiwan University Sentimental Dictionary</i>) 简体中文情感词典中的积极词词典、消极词词典, 并构造了常用的否定词词典、转折词词典和主张词词典, 一共5种词典。利用上述5种词典将文本中的词进行分类, 如果一个词不存在于5种词典中的任何一种, 则该词被认为是中性词。一段文本经过上述的方法可以表示成情感向量序列:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>e</mi><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mtext> </mtext><mi>w</mi><mo>∈</mo><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><msub><mrow></mrow><mi>n</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>w</mi><mo>∉</mo><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><msub><mrow></mrow><mi>n</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi>E</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">e</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">e</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">e</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中:<b><i>e</i></b><sub><i>i</i></sub>表示第<i>i</i>个词<i>w</i>的情感向量, <i>dict</i><sub><i>n</i></sub>表示第<i>n</i>个情感词典, <b><i>S</i></b><sub><i>E</i></sub>表示文本的情感向量序列。同语义情感向量的操作一样, 选取序列中的前100个情感向量表示该文本, 不足100的使用等维度的全0向量补齐。进一步地考虑每一类词语对情感倾向的影响效果有所不同, 比如转折词的影响程度就大于主张词的影响程度, 因此对每一类词都赋予不同的权重, 并且对于情感向量中为0的值使用[-0.2, 0.2]区间的一个随机值来代替, 降低情感向量的稀疏性。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">3.3 <b>语义向量融合情感向量</b></h4>
                <div class="p1">
                    <p id="62">生成了词的语义向量与情感向量之后, 如何融合这两种向量是一个非常重要的问题。本文提出了两种融合方法:一种是在神经网络的输入层将语义向量和情感向量串联起来构成一个词的词向量;一种是在神经网络的双向<i>LSTM</i>层将语义向量的输出结果与情感向量的输出结果串联在一起。这两种融合方法分别对应不用的网络结构, 在下面的公式与图中, “+”表示串联操作。</p>
                </div>
                <div class="p1">
                    <p id="63">第一种在输入层将语义向量与情感向量融合, 每一词就由100维的语义向量和6维的情感向量串联表示, 一共106维, 一段评论文本<b><i>S</i></b>就由100个106维的向量序列表示。将融合后的向量序列输入到双向LSTM网络中进行情感分类:</p>
                </div>
                <div class="p1">
                    <p id="64"><b><i>S</i></b>=<b><i>S</i></b><sub><i>W</i></sub>+<b><i>S</i></b><sub><i>E</i></sub>=[<b><i>w</i></b><sub>1</sub>+<b><i>e</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>+<b><i>e</i></b><sub>2</sub>, …, <b><i>w</i></b><sub>100</sub>+<b><i>e</i></b><sub>100</sub>]      (11) </p>
                </div>
                <div class="p1">
                    <p id="65">第二种是将语义向量序列与情感向量序列分别输入到双向LSTM网络中, 网络的输出结果进行融合再送入全连接层中, 最后经过输出层输出情感分析结果。融合的方式也有许多种, 本文经过实验探讨了串联、求和与求平均三种融合方式的效果, 结果发现采用串联的融合效果最好。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907011_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 两种融合方法的网络结构" src="Detail/GetImg?filename=images/JSJY201907011_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 两种融合方法的网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907011_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Network structure of two fusion methods</p>

                </div>
                <h3 id="67" name="67" class="anchor-tag">4 实验</h3>
                <h4 class="anchor-tag" id="68" name="68">4.1 <b>实验数据</b></h4>
                <div class="p1">
                    <p id="69">本次实验的数据集共有4个, 如下所示:</p>
                </div>
                <div class="p1">
                    <p id="70">1) 商品评论数据。从淘宝商场平台上爬取, 涉及到五类商品, 评论的积极性与消极性在平台上已经作好了标注。</p>
                </div>
                <div class="p1">
                    <p id="71">2) 电影影评数据。从豆瓣网上爬取, 本文将影评中评分为5星的评论设置为积极评论, 评价为1星的设置为消极评论。</p>
                </div>
                <div class="p1">
                    <p id="72">3) 酒店评论数据。谭松波<citation id="166" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>收集整理了一个较大规模的酒店评论语料, 语料从携程网上自动采集, 并经过整理而成。</p>
                </div>
                <div class="p1">
                    <p id="73">4) 自然语言处理及中文计算会议 (<i>Natural Language Processing and Chinese Computing</i>, <i>NLPCC</i>) 2014任务2数据。该语料共包含中文和英文两种语言, 本文使用其中的中文数据, 主要是商品评论, 可以被应用于篇章级或者句子级的情感分析任务。</p>
                </div>
                <div class="p1">
                    <p id="74">每个数据集都按2∶8的比例分成训练集与验证集, 训练集用于训练情感分类模型, 测试集用于评价模型效果。4个数据集的详细信息如表1所示。</p>
                </div>
                <div class="area_img" id="75">
                    <p class="img_tit"><b>表</b>1 <b>实验数据信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Experimental data information</i></p>
                    <p class="img_note"></p>
                    <table id="75" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="2"><br />情感</td><td rowspan="2">总计</td><td colspan="2"><br />划分</td></tr><tr><td><br />积极</td><td>消极</td><td><br />训练集</td><td>测试集</td></tr><tr><td><br />商品评论</td><td>12 003</td><td>12 000</td><td>24 003</td><td>19 202</td><td>4 801</td></tr><tr><td><br />电影评论</td><td>8 211</td><td>6 580</td><td>14 791</td><td>11 832</td><td>2 959</td></tr><tr><td><br />酒店评论</td><td>7 000</td><td>3 000</td><td>10 000</td><td>8 000</td><td>2 000</td></tr><tr><td><br /><i>NLPCC</i>2014</td><td>5 000</td><td>5 000</td><td>10 000</td><td>8 000</td><td>2 000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="76">在构建词的情感向量时, 本文构造了5个词典, 其中积极词词典、消极词词典参考了<i>NTUSD</i>台湾大学简体中文情感词典, 本文方法将词典中较长的短语去除, 加入了一些常用的带有情感倾向的评论词。否定词词典、转折词词典与主张词词典是从常用的中文文本中总结得到的。这些词典的词汇量如表2。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表</b>2 <b>词典词汇量</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Vocabularies of lexicons</i></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td><br />词典</td><td>词汇量</td><td>举例</td></tr><tr><td><br />积极词</td><td>3 452</td><td>美观、自信、轻巧</td></tr><tr><td><br />消极词</td><td>8 201</td><td>丑、生硬、失望</td></tr><tr><td><br />否定词</td><td>33</td><td>不是、没有、并非</td></tr><tr><td><br />转折词</td><td>13</td><td>可是、不过、然而</td></tr><tr><td><br />主张词</td><td>38</td><td>感觉、发现、认为</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">4.2 <b>实验设计</b></h4>
                <div class="p1">
                    <p id="79">本文采用语义向量+<i>SVM</i>、语义向量+双向<i>LSTM</i>、语义向量+<i>CNN</i>、语义+情感向量+双向<i>LSTM</i>、语义向量+分层注意力网络<i>HN</i>-<i>ATT</i> (<i>Hierarchical ATTention Networks</i>) 这几个模型进行情感分析实验。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">1) <i>SVM</i>。</h4>
                <div class="p1">
                    <p id="81">支持向量机是传统机器学习算法中较为常用的一种, 它通过寻找一个超平面将数据进行分类。本文将文本序列的语义向量的平均值作为特征, <i>SVM</i>模型作为分类器, 来研究传统机器学习算法用于情感分类的效果。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">2) <i>CNN</i>。</h4>
                <div class="p1">
                    <p id="83">卷积神经网络在图像识别领域获得较大的成果, 它能够更好地获取图像的局部特征。本文采用文本的语义向量序列为特征, <i>CNN</i>为分类器, 研究卷积神经网络在本文情感分类的效果。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">3) 双向<i>LSTM</i>。</h4>
                <div class="p1">
                    <p id="85">长短期记忆网络作为<i>RNN</i>的一种改进, 对处理序列数据有较好的性能。本文使用文本的语义向量序列作为输入, 双向<i>LSTM</i>网络为分类器, 通过实验研究循环神经网络对文本序列的处理效果。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">4) 语义+情感向量+双向<i>LSTM</i>。</h4>
                <div class="p1">
                    <p id="87">作为本文提出的情感信息融合方法, 实验中将情感向量与语义向量分别作为特征输入到模型中, 采用3.3节中的两种方法进行融合, 双向<i>LSTM</i>网络为分类器, 通过实验研究“情感融合”的有效性。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">5) 语义向量+<i>HN</i>-<i>ATT</i>。</h4>
                <div class="p1">
                    <p id="89">文献<citation id="167" type="reference">[<a class="sup">11</a>]</citation>中提出的层次注意力网络, 通过注意力机制对每个词赋予不用的权重, 实验中将语义向量作为特征输入。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">4.3 <b>实验流程</b></h4>
                <h4 class="anchor-tag" id="91" name="91">4.3.1 文本预处理</h4>
                <div class="p1">
                    <p id="92">文本是由词组成的, 首先要将文本分割成词的序列。实验中使用<i>jieba</i>分词工具对文本进行分词, 之后对每一个词进行词转向量操作, 经过上述两步之后, 一个评论文本就转化成一段词向量序列, 取前100个词向量表示这个文本, 将其输入到模型中去。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">4.3.2 模型构建与测试</h4>
                <div class="p1">
                    <p id="94">实验一共构建5种分类模型, <i>SVM</i>模型接收语义向量的平均值, 使用<i>RBF</i> (<i>Radial Basis Function</i>) 核函数构建超平面进行分类。<i>CNN</i>采用卷积提取数据的特征, 实验中卷积核大小为3×3, 卷积核个数为200。<i>LSTM</i>网络的输出单元为200, 双向<i>LSTM</i>输出结果的融合方式为取平均值。<i>HN</i>-<i>ATT</i>网络中门控制单元<i>GRU</i> (<i>Gated Recurrent Unit</i>) 的维数为100。在<i>CNN</i>、双向<i>LSTM</i>模型和<i>HN</i>-<i>ATT</i>模型中都加入了<i>maxpooling</i>层与<i>dropout</i>层, <i>maxpooling</i>层的池化大小为3, 步长为3, <i>dropout</i>的参数设置为0.5;这三个模型训练时采用的损失函数为交叉熵损失函数, 优化器为<i>Adam</i>, 训练的batch-size为64, epochs为12。实验将数据按8∶2的比例分成训练集与测试集, 训练集用于训练模型, 测试集测试模型的分类性能, 采用的评价指标为模型分类的准确度accuracy与F1得分值 (如表3) 。</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit"><b>表</b>3 <b>不同模型的实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 3 Experimental results of different models</p>
                    <p class="img_note"></p>
                    <table id="95" border="1"><tr><td rowspan="2">情感分析模型</td><td colspan="2"><br />商品评论数据</td><td rowspan="2"></td><td colspan="2"><br />电影评论数据</td><td rowspan="2"></td><td colspan="2"><br />酒店评论数据</td><td rowspan="2"></td><td colspan="2"><br />NLPCC2014数据</td></tr><tr><td><br />accuracy</td><td>F1</td><td><br />accuracy</td><td>F1</td><td><br />accuracy</td><td>F1</td><td><br />accuracy</td><td>F1</td></tr><tr><td>SVM</td><td>0.904 4</td><td>0.903 2</td><td></td><td>0.785 4</td><td>0.810 3</td><td></td><td>0.855 8</td><td>0.899 4</td><td></td><td>0.851 9</td><td>0.749 2</td></tr><tr><td><br />CNN</td><td>0.911 9</td><td>0.914 9</td><td></td><td>0.829 7</td><td>0.843 9</td><td></td><td>0.887 9</td><td>0.922 1</td><td></td><td>0.915 8</td><td>0.917 7</td></tr><tr><td><br />BiLSTM</td><td>0.931 7</td><td>0.931 3</td><td></td><td>0.864 5</td><td>0.880 9</td><td></td><td>0.891 4</td><td>0.923 0</td><td></td><td>0.929 4</td><td>0.932 2</td></tr><tr><td><br />M-BiLSTM1</td><td><b>0.937</b><b>9</b></td><td><b>0.936</b><b>8</b></td><td><b></b></td><td><b>0.877</b><b>7</b></td><td><b>0.890</b><b>3</b></td><td></td><td>0.904 4</td><td>0.932 7</td><td></td><td><b>0.939</b><b>0</b></td><td><b>0.939</b><b>7</b></td></tr><tr><td><br />M-BiLSTM2</td><td>0.936 7</td><td>0.936 0</td><td></td><td>0.872 3</td><td>0.884 3</td><td></td><td>0.906 9</td><td>0.933 6</td><td></td><td>0.936 0</td><td>0.937 3</td></tr><tr><td><br />HN-ATT</td><td>0.936 5</td><td>0.935 9</td><td></td><td>0.873 2</td><td>0.885 1</td><td></td><td><b>0.911</b><b>4</b></td><td><b>0.935</b><b>7</b></td><td></td><td>0.938 4</td><td>0.939 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="96">另外, 为了研究情感向量维数和情感资源对分类效果的影响, 又分别设计了以下两种实验:1) 构建三维的情感向量, 每一维表示积极词、消极词和中性词, 除去否定词、转折词与主张词这三维信息。模型采用“语义+情感向量”的双向LSTM模型。2) 情感向量仍然使用6维, 但是情感词典的容量减少为原来的一半, 使用的模型不变。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">4.4 <b>实验结果与分析</b></h4>
                <div class="p1">
                    <p id="98">实验中使用Keras深度学习框架搭建网络模型, 分别采用商品评论和电影评论作为实验数据来测试4种模型的效果。</p>
                </div>
                <div class="p1">
                    <p id="99">图2展示的是几种神经网络模型在电影影评数据上测试的accuracy-epochs变化。图中M-BiLSTM1、M-BiLSTM2表示融合了情感向量与语义向量的两种模型, 可以看出本文提出的两种融合模型的测试效果要优于BiLSTM模型与CNN模型。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同模型的accuracy-epochs变化" src="Detail/GetImg?filename=images/JSJY201907011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同模型的accuracy-epochs变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Accuracy-epochs changes of different models</p>

                </div>
                <div class="p1">
                    <p id="101">从表3中可以发现:SVM模型与CNN和BiLSTM模型相比, 其分类的准确度与F1得分值都较低, 说明传统的机器学习方法在情感分析中表现的性能要低于深度学习方法。CNN模型与BiLSTM模型相比较起来, BiLSTM的准确度与F1得分值都略高于CNN, 说明双向LSTM网络能更好地获取到文本的上下文信息, 更适合于处理序列数据。融合了情感向量与语义向量的模型与BiLSTM模型相比, 性能略高。其中在商品评论数据集的测试中, M-BiLSTM1比BiLSTM准确度高了0.62个百分点, F1提高了0.55个百分点;在电影评论数据集的测试中, M-BiLSTM1比BiLSTM准确度提高了1.32个百分点, F1提高了0.94个百分点;在酒店评论数据的测试中, M-BiLSTM2比BiLSTM准确度提高了1.55个百分点, F1提高了1.06个百分点;在NLPCC2014数据的测试中, M-BiLSTM1比BiLSTM准确度提高了0.96个百分点, F1提高了0.75个百分点;由此可以看出加入了情感向量对分类性能有了一定的提升。在本文的方法与HN-ATT方法的对比中, 商品评论、电影评论、NLPCC2014三个数据集上的实验效果高于HN-ATT, 酒店评论数据的实验效果低于HN-ATT;说明本文提出的方法在大部分数据上取得了较好的实验效果。</p>
                </div>
                <div class="p1">
                    <p id="102">在研究情感向量维数和情感资源对分类效果的实验时, 使用的数据集为电影评论数据, 模型的融合方式为第一种融合方式。得到的实验结果如表4所示。从中可以看出:1) 使用3维情感向量的分类效果略低于6维, 缺少了否定词、转折词与主张词这3维的信息, 情感分类的效果有所降低。说明否定词、转折词与主张词都会对情感分类产生影响。2) 将情感词典容量减半会降低分类的效果, 由于情感词典缺少对词的分类, 生成的情感向量就丢失了情感信息。如果情感词典的资源足够丰富和准确, 那么情感向量就能更好地提高分类效果。</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表</b>4 <b>情感资源与向量维数的实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 4 Experimental results of sentimental resources and vector dimensions</p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td><br />情感向量构造</td><td>accuracy</td><td>F1</td></tr><tr><td><br />3维向量+全部情感资源</td><td>0.872 9</td><td>0.888 2</td></tr><tr><td><br />6维向量+一半情感资源</td><td>0.869 6</td><td>0.883 0</td></tr><tr><td><br />6维向量+全部情感资源</td><td><b>0.877</b><b>7</b></td><td><b>0.890</b><b>3</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="104" name="104" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="105">在情感分析的研究任务中, 采用词嵌入法+深度神经网络是目前常用的做法。本文提出的融合情感与语义信息的方法是在词嵌入法生成词向量的基础上, 根据词的情感信息构建了情感向量, 将二者融合一起应用到情感分析任务中。通过两个数据集的实验验证, 该方法能够提高情感分析的性能, 说明词的情感信息对文本的情感极性判断是有影响的;同时实验中还比较了卷积神经网络与长短时记忆网络在情感分析中的性能, 结果得出长短时记忆网络更适合处理类似文本的序列数据。通过实验本文发现词的情感信息对情感分析任务有一定影响, 在今后的工作中将研究基于主题和目标的细粒度的情感分析方法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="121">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201808011&amp;v=MDkyNDBOQy9UYkxHNEg5bk1wNDlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMckE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 吴鹏, 应杨, 沈思.基于双向长短期记忆模型的网民负面情感分类研究[J].情报学报, 2018, 37 (08) :845-853. (WU P, YING Y, SHEN S.Negative emotions of online users' analysis based on bidirectional long short-term memory[J].Journal of the China Society for Scientific and Technical Information, 2018, 37 (8) :845-853.) 
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAQY201702010&amp;v=MDgzNTQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHJBUFN6YWQ3RzRIOWJNclk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 赵刚, 徐赞.基于机器学习的商品评论情感分析模型研究[J].信息安全研究, 2017, 3 (2) :166-170. (ZHAO G, XU Z.Research on the sentiment analysis model of product reviews based on machine learning[J].Journal of Information Security Research, 2017, 3 (2) :166-170.) 
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis:Capturing favorability using natural language processing">

                                <b>[3]</b> TETSUYA N, JEONGHEE Y.Sentiment analysis:Capturing favorability using natural language processing [C]// Proceedings of the 2nd International Conference on Knowledge Capture.New York:ACM, 2003:70-77.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OpinionMiner:A novel machine learning system for web opinion mining and extraction">

                                <b>[4]</b> WEI J, HUNG H H, ROHINI K S.OpinionMiner:a novel machine learning system for Web opinion mining and extraction [C]// Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York:ACM, 2009:1195-1204.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sentiment classification using machine learning techniques with syntax features">

                                <b>[5]</b> ZOU H, TANG X, XIE B, et al.Sentiment classification using machine learning techniques with syntax features [C]// Proceedings of the 2015 International Conference on Computational Science and Computational Intelligence.Piscataway, NJ:IEEE, 2015:175-179.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sentiment lexical-augmented convolutional neural networks for sentiment analysis">

                                <b>[6]</b> YIN R, LI P, WANG B.Sentiment lexical-augmented convolutional neural networks for sentiment analysis [C]// Proceedings of the 2017 IEEE 2nd International Conference on Data Science in Cyberspace.Piscataway, NJ:IEEE, 2017:630-635.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201808026&amp;v=MDcxNzMzenFxQnRHRnJDVVI3cWZadVpzRnkvblZMckFQVG5TZDdHNEg5bk1wNDlIWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 於雯, 周武能.基于LSTM的商品评论情感分析[J].计算机系统应用, 2018, 27 (8) :159-163. (YU W, ZHOU W N.Sentiment analysis of commodity reviews based on LSTM[J].Computer Systems and Applications, 2018, 27 (8) :159-163.) 
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201612001&amp;v=MTA4ODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHJBTkMvVGJMRzRIOWZOclk5RlpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 丁晟春, 吴靓婵媛, 李红梅.基于SVM的中文微博观点倾向性识别[J].情报学报, 2016, 35 (12) :1235-1243. (DING S C, WU J C Y, LI H M.SVM-based Chinese microblogging viewpoint orientation recognition[J].Journal of the China Society for Scientific and Technical Information, 2016, 35 (12) :1235-1243.) 
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Neural Probabilistic Language Model">

                                <b>[9]</b> BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2003, 3:1137-1155.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">

                                <b>[10]</b> MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[J].Advances in Neural Information Processing Systems, 2013, 26:3111-3119.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704001&amp;v=MTY4NzJxNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMckFMejdCZHJHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2017, 40 (4) :773-790. (HE Y X, SUN S T, NIU F F, et al.An emotional semantic enhanced deep learning model for microblog emotion analysis [J].Chinese Journal of Computers, 2017, 40 (4) :773-790.) 
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical attention networks for document classification">

                                <b>[12]</b> YANG Z, YANG D, DYER C, et al.Hierarchical attention networks for document classification [C]// Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, PA:Association for Computational Linguistics, 2016:1480-1489.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">

                                <b>[13]</b> WANG Y Q, HUANG M L, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification [C]// Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, PA:Association for Computational Linguistics, 2016:606-615.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep CNN-LSTM with combined kernels from multiple branches for IMDB review sentiment analysis">

                                <b>[14]</b> ALEC Y, ABHISHEK.V.Deep CNN-LSTM with combined kernels from multiple branches for IMDB review sentiment analysis [C]// Proceedings of the 2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference.Piscataway, NJ:IEEE, 2017:540-546.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Efficient Estimation of Word Representations in Vector Space,&amp;quot;">

                                <b>[15]</b> MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space [C]// Proceedings of the 2013 International Conference on Learning Representations.Scottsdale, Arizona:[s.n.], 2013:1-12.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 谭松波.酒店评论数据[EB/OL].[2018- 10- 20].http://www.datatang.com/data/11970. (TAN S B.Hotel review data [EB/OL].[2018- 10- 20].http://www.datatang.com/data/11970.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907011&amp;v=MDE3OThyQUx6N0JkN0c0SDlqTXFJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
