<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136661766721250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201907005%26RESULT%3d1%26SIGN%3dn2yaVyUzagDfWJedUasdaRH8g5E%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907005&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201907005&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907005&amp;v=MjIzOTBqTXFJOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkx6SUx6N0JkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 网络结构 ">1 网络结构</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 视频帧提取 ">2 视频帧提取</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="3 双卷积特征提取 ">3 双卷积特征提取</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="3.1 &lt;i&gt;ResNet&lt;/i&gt;&lt;b&gt;基本原理&lt;/b&gt;">3.1 <i>ResNet</i><b>基本原理</b></a></li>
                                                <li><a href="#63" data-title="3.2 &lt;b&gt;双提取机制&lt;/b&gt;">3.2 <b>双提取机制</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="4 基于&lt;i&gt;LSTM&lt;/i&gt;序列 ">4 基于<i>LSTM</i>序列</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#77" data-title="5 实验及结果分析 ">5 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="5.1 &lt;b&gt;数据集&lt;/b&gt;">5.1 <b>数据集</b></a></li>
                                                <li><a href="#80" data-title="5.2 &lt;b&gt;网络环境配置及训练&lt;/b&gt;">5.2 <b>网络环境配置及训练</b></a></li>
                                                <li><a href="#83" data-title="5.3 &lt;b&gt;结果分析&lt;/b&gt;">5.3 <b>结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="6 结语 ">6 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="图1 车辆预警示意图">图1 车辆预警示意图</a></li>
                                                <li><a href="#42" data-title="图2 车辆行为动态识别网络模型">图2 车辆行为动态识别网络模型</a></li>
                                                <li><a href="#61" data-title="图3 ResNet网络结构">图3 ResNet网络结构</a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;网络参数&lt;/b&gt;"><b>表</b>1 <b>网络参数</b></a></li>
                                                <li><a href="#74" data-title="图4 LSTM记忆单元">图4 LSTM记忆单元</a></li>
                                                <li><a href="#76" data-title="图5 双层深度LSTM模型">图5 双层深度LSTM模型</a></li>
                                                <li><a href="#82" data-title="图6 车辆行为数据集">图6 车辆行为数据集</a></li>
                                                <li><a href="#86" data-title="图7 &lt;i&gt;m&lt;/i&gt;取值对识别准确率的影响">图7 <i>m</i>取值对识别准确率的影响</a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;各类行为识别结果&lt;/b&gt;"><b>表</b>2 <b>各类行为识别结果</b></a></li>
                                                <li><a href="#93" data-title="图8 全样本准确率、损失值变化">图8 全样本准确率、损失值变化</a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;模型对比结果&lt;/b&gt;"><b>表</b>3 <b>模型对比结果</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;车辆特征检测对比&lt;/b&gt;"><b>表</b>4 <b>车辆特征检测对比</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;不同算法的准确率对比&lt;/b&gt;"><b>表</b>5 <b>不同算法的准确率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="119">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     陈放.高级驾驶辅助系统ADAS浅谈[J].各界, 2018 (1) :188-191. (CHEN F.A dissertation on advanced driver assistance system[J].All Circles, 2018 (1) :188-191.) </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_2" title=" KASPER D, WEIDL G, DANG T, et al.Object-oriented Bayesian networks for detection of lane change maneuvers[J].IEEE Intelligent Transportation Systems Magazine, 2012, 4 (3) :19-31." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object-Oriented Bayesian Networks for Detection of Lane Change Maneuvers">
                                        <b>[2]</b>
                                         KASPER D, WEIDL G, DANG T, et al.Object-oriented Bayesian networks for detection of lane change maneuvers[J].IEEE Intelligent Transportation Systems Magazine, 2012, 4 (3) :19-31.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_3" title=" GADEPALLY V, KRISHNAMURTHY A, OZGUNER U.A framework for estimating driver decisions near intersections [J].IEEE Transactions on Intelligent Transportation Systems, 2014, 15 (2) :637-646." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A framework for estimating driver decisions near intersections">
                                        <b>[3]</b>
                                         GADEPALLY V, KRISHNAMURTHY A, OZGUNER U.A framework for estimating driver decisions near intersections [J].IEEE Transactions on Intelligent Transportation Systems, 2014, 15 (2) :637-646.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_4" title=" 黄鑫, 肖世德, 宋波.监控视频中的车辆异常行为检测[J].计算机系统应用, 2018, 27 (2) :125-131. (HUANG X, XIAO S D, SONG B.Detection of vehicle&#39;s abnormal behaviors in surveillance video[J].Computer Systems and Applications, 2018, 27 (2) :125-131.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201802020&amp;v=MzI0NDhadVpzRnkvblZMeklQVG5TZDdHNEg5bk1yWTlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         黄鑫, 肖世德, 宋波.监控视频中的车辆异常行为检测[J].计算机系统应用, 2018, 27 (2) :125-131. (HUANG X, XIAO S D, SONG B.Detection of vehicle&#39;s abnormal behaviors in surveillance video[J].Computer Systems and Applications, 2018, 27 (2) :125-131.) 
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_5" title=" 黄慧玲, 杨明, 王春香, 等.基于前方车辆行为识别的碰撞预警系统[J].华中科技大学学报 (自然科学版) , 2015, 43 (s1) :117-121. (HUANG H L, YANG M, WANG C X, et al.Collision warning system based on forward vehicle behavior recognition[J].Journal of Huazhong University of Science and Technology (Natural Science Edition) , 2015, 43 (s1) :117-121.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG2015S1029&amp;v=MjM2NDZHNEg5U3ZybzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMeklMVGZIYWI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         黄慧玲, 杨明, 王春香, 等.基于前方车辆行为识别的碰撞预警系统[J].华中科技大学学报 (自然科学版) , 2015, 43 (s1) :117-121. (HUANG H L, YANG M, WANG C X, et al.Collision warning system based on forward vehicle behavior recognition[J].Journal of Huazhong University of Science and Technology (Natural Science Edition) , 2015, 43 (s1) :117-121.) 
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_6" title=" DONAHUE J, HENDRICKS L A, ROHRBACH M, et al.Long-term recurrent convolutional networks for visual recognition and description[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:2625-2634." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Long-term recurrent convolutional networks for visual recognition and description">
                                        <b>[6]</b>
                                         DONAHUE J, HENDRICKS L A, ROHRBACH M, et al.Long-term recurrent convolutional networks for visual recognition and description[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:2625-2634.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_7" title=" HOCHREITER S, SCHMIDHUBER J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDM5MDdQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUoxd1RhUkk9TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         HOCHREITER S, SCHMIDHUBER J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_8" title=" 殷昊, 李寿山, 贡正仙, 等.基于多通道LSTM的不平衡情绪分类方法[J].中文信息学报, 2018, 32 (1) :139-145. (YIN H, LI S S, GONG Z X, et al.Imbalanced emotion classification based on multi-channel LSTM[J].Journal of Chinese Information Processing, 2018, 32 (1) :139-145.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201801020&amp;v=MDAyMDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHpJS0NqWWZiRzRIOW5Ncm85SFpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         殷昊, 李寿山, 贡正仙, 等.基于多通道LSTM的不平衡情绪分类方法[J].中文信息学报, 2018, 32 (1) :139-145. (YIN H, LI S S, GONG Z X, et al.Imbalanced emotion classification based on multi-channel LSTM[J].Journal of Chinese Information Processing, 2018, 32 (1) :139-145.) 
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_9" title=" 郑毅, 李凤, 张丽, 等.基于长短时记忆网络的人体姿态检测方法[J].计算机应用, 2018, 38 (6) :1568-1574. (ZHENG Y, LI F, ZHANG L, et al.Pose detection and classification with LSTM network[J].Journal of Computer Applications, 2018, 38 (6) :1568-1574.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806008&amp;v=MDEzMjZHNEg5bk1xWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMeklMejdCZDc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         郑毅, 李凤, 张丽, 等.基于长短时记忆网络的人体姿态检测方法[J].计算机应用, 2018, 38 (6) :1568-1574. (ZHENG Y, LI F, ZHANG L, et al.Pose detection and classification with LSTM network[J].Journal of Computer Applications, 2018, 38 (6) :1568-1574.) 
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_10" title=" GRAVES A.Supervised Sequence Labelling with Recurrent Neural Networks[M].Berlin:Springer, 2012:385." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised sequence labelling">
                                        <b>[10]</b>
                                         GRAVES A.Supervised Sequence Labelling with Recurrent Neural Networks[M].Berlin:Springer, 2012:385.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_11" title=" 曹晋其, 蒋兴浩, 孙锬锋.基于训练图CNN特征的视频人体动作识别算法[J].计算机工程, 2017, 43 (11) :234-238. (CAO J Q, JIANG X H, SUN T F.Video human action recognition algorithm based on trained image CNN features[J].Computer Engineering, 2017, 43 (11) :234-238.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201711039&amp;v=MTc5MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L25WTHpJTHo3QmJiRzRIOWJOcm85R2JZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         曹晋其, 蒋兴浩, 孙锬锋.基于训练图CNN特征的视频人体动作识别算法[J].计算机工程, 2017, 43 (11) :234-238. (CAO J Q, JIANG X H, SUN T F.Video human action recognition algorithm based on trained image CNN features[J].Computer Engineering, 2017, 43 (11) :234-238.) 
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_12" title=" SIMONYAN K, ZISSERMAN A.Two-stream convolutional net-works for action recognition in videos[C]// Proceedings of the 2014 International Conference on Neural Information Processing Systems.Montr&#233;al:[s.n.], 2014:568-576." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Two-stream convolutional networks for action recognition in videos">
                                        <b>[12]</b>
                                         SIMONYAN K, ZISSERMAN A.Two-stream convolutional net-works for action recognition in videos[C]// Proceedings of the 2014 International Conference on Neural Information Processing Systems.Montr&#233;al:[s.n.], 2014:568-576.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_13" title=" NG J.Y, MATTHEW H, VIJAYANARASIMHAN S, et al.Beyond short snippets:deep networks for video classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:4694-4702." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond short snippets:Deep networks for video classification">
                                        <b>[13]</b>
                                         NG J.Y, MATTHEW H, VIJAYANARASIMHAN S, et al.Beyond short snippets:deep networks for video classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:4694-4702.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_14" title=" CHEN H F, CHEN J, HU R M, et al.Action recognition with temporal scale-invariant deep learning framework[J].China Communications, 2017, 14 (2) :163-172." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTO201702017&amp;v=MjAyMzJyWTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMeklQeXJmWWJHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         CHEN H F, CHEN J, HU R M, et al.Action recognition with temporal scale-invariant deep learning framework[J].China Communications, 2017, 14 (2) :163-172.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_15" title=" DENG J, DONG W, SOCHER R, et al.ImageNet:a large-scale hierarchical image database [C]// Proceedings of the 2009 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2009:248-255." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet:A large-scale hierarchical image database">
                                        <b>[15]</b>
                                         DENG J, DONG W, SOCHER R, et al.ImageNet:a large-scale hierarchical image database [C]// Proceedings of the 2009 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2009:248-255.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     HE K M, ZHANG X Y, REN S Q, et.al.Deep residual learning for image recognition [C]// Proceedings of the 2016 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2016:770-778.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-29 07:00</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(07),1894-1898 DOI:10.11772/j.issn.1001-9081.2018122448            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于长短期记忆的车辆行为动态识别网络</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%AB%E6%98%9F&amp;code=03082577&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卫星</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B9%90%E8%B6%8A&amp;code=37635889&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">乐越</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A9%E6%B1%9F%E6%B4%AA&amp;code=00003928&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">韩江洪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%86%E9%98%B3&amp;code=07068981&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陆阳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%88%E8%82%A5%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0083575&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">合肥工业大学计算机与信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%89%E5%85%A8%E5%85%B3%E9%94%AE%E5%B7%A5%E4%B8%9A%E6%B5%8B%E6%8E%A7%E6%8A%80%E6%9C%AF%E6%95%99%E8%82%B2%E9%83%A8%E5%B7%A5%E7%A8%8B%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83(%E5%90%88%E8%82%A5%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">安全关键工业测控技术教育部工程研究中心(合肥工业大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>高级辅助驾驶装置采用机器视觉技术实时处理摄录的行车前方车辆视频, 动态识别并预估其姿态和行为。针对该类识别算法精度低、延迟大的问题, 提出一种基于长短期记忆 (LSTM) 的车辆行为动态识别深度学习算法。首先, 提取车辆行为视频中的关键帧;其次, 引入双卷积网络并行对关键帧的特征信息进行分析, 再利用LSTM网络对提取出的特性信息进行序列建模;最后, 通过输出的预测得分判断出车辆行为类别。实验结果表明, 所提算法识别准确率可达95.6%, 对于单个视频的识别时间只要1.72 s;基于自建数据集, 改进的双卷积算法相比普通卷积网络在准确率上提高8.02%, 与传统车辆行为识别算法相比准确率提高6.36%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%A6%E8%BE%86%E8%A1%8C%E4%B8%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">车辆行为;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E7%BA%A7%E8%BE%85%E5%8A%A9%E9%A9%BE%E9%A9%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高级辅助驾驶;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    卫星 (1980—) , 男, 安徽合肥人, 副教授, 博士, CCF会员, 主要研究方向:物联网工程、离散事件动态系统;;
                                </span>
                                <span>
                                    *乐越 (1994—) , 男, 安徽宣城人, 硕士研究生, CCF会员, 主要研究方向:分布式控制;电子邮箱1564876183@qq.com;
                                </span>
                                <span>
                                    韩江洪 (1954—) , 男, 安徽庐江人, 教授, 博士生导师, 硕士, 主要研究方向:计算机网络与通信、计算机控制、汽车电子;;
                                </span>
                                <span>
                                    陆阳 (1967—) , 男, 安徽合肥人, 教授, 博士生导师, 博士, CCF高级会员, 主要研究方向:分布式控制、无线通信网络、工业物联网。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划专项 (2018YFC0604404);</span>
                    </p>
            </div>
                    <h1><b>Vehicle behavior dynamic recognition network based on long short-term memory</b></h1>
                    <h2>
                    <span>WEI Xing</span>
                    <span>LE Yue</span>
                    <span>HAN Jianghong</span>
                    <span>LU Yang</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Information Engineering, Hefei University of Technology</span>
                    <span>Engineering Research Center of Safety Critical Industry Measure and Control Technology, Ministry of Education (Hefei University of Technology)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the advanced assisted driving device, machine vision technology was used to process the video of vehicles in front in real time to dynamically recognize and predict the posture and behavior of vehicle. Concerning low precision and large delay of this kind of recognition algorithm, a deep learning algorithm for vehicle behavior dynamic recognition based on Long Short-Term Memory (LSTM) was proposed. Firstly, the key frames in vehicle behavior video were extracted. Secondly, a dual convolutional network was introduced to analyze the feature information of key frames in parallel, and then LSTM network was used to sequence the extracted characteristic information. Finally, the output predicted score was used to determine the behavior type of vehicle. The experimental results show that the proposed algorithm has an accuracy of 95.6%, and the recognition time of a single video is only 1.72 s. The improved dual convolutional network algorithm improves the accuracy by 8.02% compared with ordinary convolutional network and increases by 6.36% compared with traditional vehicle behavior recognition algorithm based on a self-built dataset.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=vehicle%20behavior&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">vehicle behavior;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20Short-Term%20Memory%20(LSTM)%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long Short-Term Memory (LSTM) network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=advanced%20assisted%20driving&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">advanced assisted driving;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WEI Xing, born in 1980, Ph. D. , associate professor. His research interests include Internet of things engineering, discrete event dynamic system. ;
                                </span>
                                <span>
                                    LE Yue, born in 1994, M. S. candidate. His research interests include distributed control. ;
                                </span>
                                <span>
                                    HAN Jianghong, born in 1954, M. S. , professor. His research interests include computer network and communication, computer control, automotive electronics.;
                                </span>
                                <span>
                                    LU Yang, born in 1967, Ph. D. , professor. His research interests include distributed control, wireless communication network, industrial Internet of things.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-11</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>partially supported by the National Key Research Development Program of China (2018YFC0604404);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="36">随着智能汽车行业的蓬勃发展, 无人驾驶技术的运用在各个领域中所占的比重也越来越大。其中, 高级辅助驾驶系统 (Advanced Driving Assistant System, ADAS) 是以与未来科技互连的无人驾驶技术为基础, 通过应用感知技术探测车辆周围行驶环境, 依据获得的车辆行为信息执行相应操作从而保障驾驶员的人身安全<citation id="151" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。对前方行驶车辆的行为姿态分析是ADAS技术的重要手段之一, 功能的主要实现是通过安装在车辆内的前置摄像头对前方车辆进行拍摄, 对其直行、左转、右转、变道、掉头等动态姿态行为进行识别, 从而对驾驶员进行预警和提示 (如图1) 。</p>
                </div>
                <div class="p1">
                    <p id="37">目前, 在车辆行为识别领域, 已经有许多基于传统机器视觉算法的研究。如:2012年, Kasper等<citation id="152" type="reference"><link href="121" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>使用贝叶斯网络对高速公路场景中车辆典型行为进行分类;2014年Gadepally等<citation id="153" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等使用隐马尔可夫模型 (Hidden Markov Model, HMM) 对车辆行为进行分析;2018年, 黄鑫等<citation id="154" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>使用视觉背景提取 (Visual Background extractor, ViBe) 算法得到车辆的前景图像, 利用金字塔光流法 (Lucas-Kanada, L-K) 和均值漂移算法, 再通过运动特征熵和运动特征标量到聚类中心的欧氏距离这两种方法判断车辆有无异常行为;黄慧玲等<citation id="155" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一种基于车辆行为识别的汽车前方碰撞预警方法, 通过梯度方向直方图 (Histograms of Oriented Gradients, HOG) 和支持向量机 (Support Vector Machine, SVM) 来训练检索前方车辆, 再结合卡尔曼滤波对车辆跟踪, 最后使用HMM算法对车辆行为进行建模, 识别前方车辆行为。但是, 很多传统算法的视频都是在路口高位定点拍摄, 更加适合对背景相对固定的车辆行为进行识别, 并且传统算法的检测和识别精度无法达到实际需求。近些年, 深度学习已经在各个领域取得重大进展, 解决了许多传统技术无法解决的难题。在视频识别和分类这一任务上, Donahue等<citation id="156" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在2015年提出了采用长短期记忆 (Long Short-Term Memory, LSTM) 网络来解决视频流时序分类这一难题。LSTM由Hochreiter等<citation id="157" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在1997年提出, 是一种时间递归神经网络。由于存在梯度消失和梯度爆炸等问题, 标准的循环网络在长序列上的学习效果不佳。相比之下, LSTM使用记忆单元来访问、修改、存储内部状态, 能够更好地探寻长序列之间的联系, 因此在自然语言、语音、动作姿态等序列领域有惊人的表现<citation id="160" type="reference"><link href="133" rel="bibliography" /><link href="135" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。Graves<citation id="158" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>于2013年对LSTM进行了改良和推广, 使其能更好地学习序列特征。2017年, 曹晋其等<citation id="159" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>采用卷积神经网络 (Convolutional Neural Network, CNN) 和LSTM相结合的方式对人体行为进行识别, 利用图像中的RGB数据识别视频人体动作, 使用现有的CNN模型从图像中提取特征, 并采用长短记忆递归神经网络进行训练分类;同时, 采用双卷积和关键帧选取的方法, 可以大幅度提高人体行为分类的正确率<citation id="161" type="reference"><link href="141" rel="bibliography" /><link href="143" rel="bibliography" /><link href="145" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。目前, 尚未有利用LSTM网络解决类似于车辆行为动态识别方面的研究。</p>
                </div>
                <div class="area_img" id="38">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 车辆预警示意图" src="Detail/GetImg?filename=images/JSJY201907005_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 车辆预警示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_038.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Schematic diagram of vehicle warning</p>

                </div>
                <div class="p1">
                    <p id="39">综上所述, 针对传统车辆行为识别算法准确率较低和实用性差等问题, 为了有效检测前方车辆并对其运动状态进行理解和识别, 本文提出了一种基于长短期记忆的车辆行为动态识别网络, 该模型对于车辆行为的动态识别非常有效, 且模型收敛的速度很快。</p>
                </div>
                <h3 id="40" name="40" class="anchor-tag">1 网络结构</h3>
                <div class="p1">
                    <p id="41">本文网络模型如图2所示, 主要训练过程如下:</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 车辆行为动态识别网络模型" src="Detail/GetImg?filename=images/JSJY201907005_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 车辆行为动态识别网络模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Network model of vehicle behavior dynamic identification</p>

                </div>
                <div class="p1">
                    <p id="43">第一步 对输入的解帧后的视频流进行关键帧提取, 并依据关键帧数量和关键帧所在子视频中的位置因素等进行对比实验。</p>
                </div>
                <div class="p1">
                    <p id="44">第二步 使用双CNN模型提取出关键帧中的车辆特征, 其中双CNN模型参数是由ImageNet数据集<citation id="162" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>训练得到。根据分类结果与车辆和环境特征的多元性及特殊性, 提出的双网络结构将分别专注于常规特征以及细微特征变化。双CNN模型的选择对最终的动态行为分类结果起着至关重要的作用, 本文会在稍后的实验中进行讨论。</p>
                </div>
                <div class="p1">
                    <p id="45">第三步 将双CNN模型提取出的车辆行为特征融合后输入到LSTM网络框架中, 进而分析序列间特征得到各类车辆行为预判得分, 最终得到视频车辆的行为分类。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 视频帧提取</h3>
                <div class="p1">
                    <p id="47">定义一个视频的序列为<b><i>V</i></b>=[<b><i>v</i></b><sub>1</sub>, <b><i>v</i></b><sub>2</sub>, …, <b><i>v</i></b><sub><i>n</i></sub>], 其中<b><i>v</i></b><sub>1</sub>, <b><i>v</i></b><sub>2</sub>, …, <b><i>v</i></b><sub><i>n</i></sub>分别表示不同的视频帧。设<i>m</i> (<i>m</i>&lt;<i>n</i>) 为需要提取关键帧的数量, 则可把视频序列分成<i>m</i>份:</p>
                </div>
                <div class="p1">
                    <p id="48"><b><i>V</i></b>=[<b><i>M</i></b><sub>1</sub>, <b><i>M</i></b><sub>2</sub>, …, <b><i>M</i></b><sub><i>j</i></sub>, …, <b><i>M</i></b><sub><i>m</i></sub>]      (1) </p>
                </div>
                <div class="p1">
                    <p id="49">其中每一个子视频序列为<b><i>M</i></b><sub><i>j</i></sub>=[<b><i>v</i></b><sub><i>k</i><sub><i>p</i></sub></sub>, <b><i>v</i></b><sub><i>k</i><sub><i>p</i></sub>+1</sub>, …, <b><i>v</i></b><sub><i>k</i><sub><i>q</i></sub></sub>] (1≤<i>j</i>≤<i>n</i>, <i>k</i><sub><i>q</i></sub>-<i>k</i><sub><i>p</i></sub>≤<i>n</i>/<i>m</i>) , 其中<i>k</i><sub><i>p</i></sub>和<i>k</i><sub><i>q</i></sub>分别表示子视频<b><i>M</i></b><sub><i>j</i></sub>中第一个和最后一个视频帧的索引。当选取的<i>m</i>值较为合理时, 相同子视频包含帧特征信息基本相同, 不同子视频序列之间特征变化明显。在子视频序列<b><i>M</i></b><sub><i>j</i></sub>中提取关键帧进行后续实验。本文分别提取每个子视频第一帧、中间帧和最后一帧作为关键帧进行实验, 并根据不同<i>m</i>值进行对比实验。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag">3 双卷积特征提取</h3>
                <h4 class="anchor-tag" id="51" name="51">3.1 <i>ResNet</i><b>基本原理</b></h4>
                <div class="p1">
                    <p id="52">根据万能近似定理 (<i>Universal Approximation Theorem</i>, <i>UAT</i>) , 当单层的前馈网络有足够大的容量的时候, 它可以表示任何函数;但是, 由于单层网络在结构上过于庞大, 容易造成过拟合等现象。在卷积神经网络中, 随着层数的增多, 可以提取不同<i>level</i>的特征, 从而使得整个网络表达的特征更加丰富, 并且, 越深的神经网络提取出的特征会越抽象, 更加具有语义信息, 但是, 神经网络深度的提升不能单单通过层与层的简单堆叠来实现, 并且由于存在梯度消失等问题, 深层神经网络往往难以训练, 因此需要构建结构合理的多层网络来更好地提取图像的信息特征。</p>
                </div>
                <div class="p1">
                    <p id="53">深度残差网络 (<i>deep Residual Network</i>, <i>ResNet</i>) 在2015年被提出<citation id="163" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 在<i>ImageNet</i>分类任务上获得比赛第一名, 因为它独有的特性, 可以允许网络尽可能地深。<i>ResNet</i>中引入了残差网络结构 (图3 (<i>a</i>) 所示) , 相比其他卷积网络增加了网络层数和深度, 不仅能有效避免梯度弥散或梯度爆炸, 同时也能很好地解决网络的退化问题。其核心思想是引入一个恒等快捷连接, 将原始所需要学习的函数<i>H</i> (<b><i>x</i></b>) 转换成<i>F</i> (<b><i>x</i></b>) +<b><i>x</i></b> (如式 (2) ) , 这两种表达的效果相同, 但是优化的难度却并不相同, 假设<i>F</i> (<b><i>x</i></b>) 的优化会比<i>H</i> (<b><i>x</i></b>) 简单得多。为了方便计算, 达到更好优化训练的效果, 可以把式 (1) 转换为学习一个残差函数, 如式 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="54"><i>H</i> (<b><i>x</i></b>) =<i>F</i> (<b><i>x</i></b>) +<b><i>x</i></b>      (2) </p>
                </div>
                <div class="p1">
                    <p id="55"><i>F</i> (<b><i>x</i></b>) =<i>H</i> (<b><i>x</i></b>) -<b><i>x</i></b>      (3) </p>
                </div>
                <div class="p1">
                    <p id="56">当<i>F</i> (<b><i>x</i></b>) =0, 构成了一个恒等映射<i>H</i> (<b><i>x</i></b>) =<b><i>x</i></b>, 同时可以更方便拟合残差。用<i>σ</i>表示非线性函数ReLU (Rectified Linear Unit) , <b><i>W</i></b><sub>1</sub>, <b><i>W</i></b><sub>2</sub>, <b><i>W</i></b><sub><i>a</i></sub>, <b><i>W</i></b><sub><i>b</i></sub>表示权重, <i>F</i> (<b><i>x</i></b>) 和<i>H</i> (<b><i>x</i></b>) 分别表示为:</p>
                </div>
                <div class="p1">
                    <p id="57"><i>F</i> (<b><i>x</i></b>) =<b><i>W</i></b><sub>2</sub><i>σ</i> (<b><i>W</i></b><sub>1</sub><b><i>x</i></b>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="58"><i>H</i> (<b><i>x</i></b>) =<i>F</i> (<b><i>x</i></b>, {<b><i>W</i></b><sub><i>a</i></sub>}) +<b><i>x</i></b>      (5) </p>
                </div>
                <div class="p1">
                    <p id="59">当输入输出两者维度不同, 需要给<b><i>x</i></b>执行一个线性映射来匹配维度:</p>
                </div>
                <div class="p1">
                    <p id="60"><i>H</i> (<b><i>x</i></b>) =<i>F</i> (<b><i>x</i></b>, {<b><i>W</i></b><sub><i>a</i></sub>}) +<b><i>W</i></b><sub><i>b</i></sub><b><i>x</i></b>      (6) </p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 ResNet网络结构" src="Detail/GetImg?filename=images/JSJY201907005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 ResNet网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Network structure of ResNet</p>

                </div>
                <div class="p1">
                    <p id="62">ResNet使用两种残差单元, 如图3 (b) 、 (c) 所示, 图3 (b) 对应的是浅层网络, 而图3 (c) 对应的是深层网络。对于短路连接这种方式, 当输入和输出的维度相同时, 可以直接将输入加到输出上。当维度不一致时 (通常是维度会增加一倍) 就不能直接相加。第一种方法是使用补零法来增加维度, 进行下采样, 使用步长为2的池化层, 这种方式不会增加额外的参数。第二种方法是采用新的映射, 通过1×1的卷积来增加维度, 较为方便稳定。本文使用的是第二种方法。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">3.2 <b>双提取机制</b></h4>
                <div class="p1">
                    <p id="64">本文设计双深度卷积网络来对视频帧中的车辆特征进行学习和提取。图2中的<i>CNN</i>1和<i>CNN</i>2分别使用<i>ResNet</i>- 50和改进的<i>ResNet</i>- 34网络模型, 网络结构如表1所示。为了保持精度同时减少相应的计算量, 本文的<i>CNN</i>1网络 (<i>ResNet</i>- 50) 采用图2 (<i>c</i>) 所示的残差结构, 结构中的中间3×3的卷积层首先在一个降维1×1卷积层下减少了计算, 然后在另一个1×1的卷积层下做了还原。由于在车辆行为检测过程中, 视频帧中的转向灯、红绿灯等特征 (车辆变道转向等行为) 不明显, 因此, 考虑对<i>ResNet</i>- 34网络模型进行相应改进来作为本实验的<i>CNN</i>2网络模型。实验中, 针对图像中相对较小的特征, 本文采用扩大卷积核的方式来增大感受野从而获取更多的细节特征, 具体做法是将<i>ResNet</i>- 34前5层卷积核大小由原始的7×7与3×3的组合改为7×7, 6到15层卷积核将原来的3×3改为5×5。</p>
                </div>
                <div class="area_img" id="65">
                    <p class="img_tit"><b>表</b>1 <b>网络参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>Network parameters</i></p>
                    <p class="img_note"></p>
                    <table id="65" border="1"><tr><td><br />网络层</td><td><i>ResNet</i>- 34</td><td><i>ResNet</i>- 50</td><td>改进的<br /><i>ResNet</i>- 34</td><td>输出<br />大小</td></tr><tr><td><br /><i>Conv</i>1</td><td>7×7, 64</td><td>7×7, 64</td><td>7×7, 64</td><td>112×112</td></tr><tr><td><br /><i>Conv</i>2_<i>x</i></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>7</mn><mo>×</mo><mn>7</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr><mtr><mtd><mn>7</mn><mo>×</mo><mn>7</mn><mo>, </mo><mn>6</mn><mn>4</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td>56×56</td></tr><tr><td><br /><i>Conv</i>3_<i>x</i></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>4</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>4</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>5</mn><mo>×</mo><mn>5</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>5</mn><mo>×</mo><mn>5</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>4</mn></mrow></math></td><td>28×28</td></tr><tr><td><br /><i>Conv</i>4_<i>x</i></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>6</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>1</mn><mtext> </mtext><mn>0</mn><mn>2</mn><mn>4</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>6</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>5</mn><mo>×</mo><mn>5</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>5</mn><mo>×</mo><mn>5</mn><mo>, </mo><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>6</mn></mrow></math></td><td>14×14</td></tr><tr><td><br /><i>Conv</i>5_<i>x</i></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mo>, </mo><mn>2</mn><mn>0</mn><mn>4</mn><mn>8</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mo>, </mo><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>×</mo><mn>3</mn></mrow></math></td><td>7×7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="66">此外, 在两个<i>CNN</i>训练完成后, 用1×1×512的卷积网络来代替<i>CNN</i>1和<i>CNN</i>2中的全连接层及之后<i>softmax</i>层, 用卷积提取的方式使两个卷积网络输出为1×1×512维度特征;然后再使用首尾相接的融合方法对<i>CNN</i>1和<i>CNN</i>2的输出进行融合, 作为<i>LSTM</i>神经网络的输入。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag">4 基于<i>LSTM</i>序列</h3>
                <div class="p1">
                    <p id="68">车辆行为视频的连续关键帧是随着时间进行演变的过程, 针对这一特性本文选择<i>LSTM</i>网络框架对车辆行为进行建模。<i>LSTM</i>相比循环神经网络 (<i>Recurrent Neural Network</i>, <i>RNN</i>) , 其算法中加入了一个判断信息筛选的“处理器”记忆单元, 如图4所示。每个单元中设置了三扇门, 分别为输入门<b><i>I</i></b><sub><i>t</i></sub>、输出门<b><i>O</i></b><sub><i>t</i></sub>和遗忘门<b><i>F</i></b><sub><i>t</i></sub>, 它们分别对应着车辆运动姿态数据序列的写入、读取和先前状态的重置操作。假设<b><i>x</i></b><sub><i>t</i></sub>表示在时间<i>t</i>下的输入, <b><i>W</i></b><sub><i>i</i></sub>, <b><i>W</i></b><sub><i>f</i></sub>, <b><i>W</i></b><sub><i>o</i></sub>, <b><i>W</i></b><sub><i>c</i></sub>表示权重矩阵;<b><i>b</i></b><sub><i>i</i></sub>, <b><i>b</i></b><sub><i>f</i></sub>, <b><i>b</i></b><sub><i>o</i></sub>, <b><i>b</i></b><sub><i>c</i></sub>是偏置向量, <i>σ</i>表示为logistic sigmoid函数, <b><i>H</i></b><sub><i>t</i></sub>为单元<i>t</i>时刻的输出。<b><i>C</i></b><sub><i>t</i></sub>表示记忆单元在<i>t</i>时刻的状态, 则LSTM单元在<i>t</i>时刻的更新过程如下:</p>
                </div>
                <div class="p1">
                    <p id="69"><b><i>I</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>i</i></sub>×[<b><i>H</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>i</i></sub>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="70"><b><i>F</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>f</i></sub>×[<b><i>H</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>f</i></sub>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="71"><b><i>O</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>o</i></sub>×[<b><i>H</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>o</i></sub>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="72"><b><i>C</i></b><sub><i>t</i></sub>=<b><i>F</i></b><sub><i>t</i></sub>×<b><i>C</i></b><sub><i>t</i>-1</sub>+<b><i>I</i></b><sub><i>t</i></sub>×tanh (<b><i>W</i></b><sub><i>c</i></sub>×[<b><i>H</i></b><sub><i>t</i>-1</sub>, <b><i>x</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sub><i>c</i></sub>)      (10) </p>
                </div>
                <div class="p1">
                    <p id="73"><b><i>H</i></b><sub><i>t</i></sub>=<b><i>O</i></b><sub><i>t</i></sub>×tanh (<b><i>C</i></b><sub><i>t</i></sub>)      (11) </p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 LSTM记忆单元" src="Detail/GetImg?filename=images/JSJY201907005_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 LSTM记忆单元  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 LSTM memory unit</p>

                </div>
                <div class="p1">
                    <p id="75">为了抓取车辆动态行为的语义信息, 提高结果的分类准确率, 决定采用一种双层深度LSTM表示模型, 可以挖掘更深层的序列之间的特征。网络模型如图5所示, 把本文第3章介绍的双卷积网络所提取出<i>m</i>个特征值按序输入双层结构的LSTM序列模型中, 每个记忆单元学习当时输入的车辆特征, 并通过单元的遗忘门以及其前后状态对车辆行为状态进行分析。采用many to one (即多对一) 的输入输出方式, 每个输入都是1×1×1 024的向量, 在经过双层的LSTM网络后, 输出为1×1×6 (6对应着直行、左转、右转、左变道、右变道、掉头) 的分类向量并将其通过softmax函数, 最后得出车辆行为类别的预测得分。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 双层深度LSTM模型" src="Detail/GetImg?filename=images/JSJY201907005_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 双层深度LSTM模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Double layer depth LSTM model</p>

                </div>
                <h3 id="77" name="77" class="anchor-tag">5 实验及结果分析</h3>
                <h4 class="anchor-tag" id="78" name="78">5.1 <b>数据集</b></h4>
                <div class="p1">
                    <p id="79">本文用于特征提取的双卷积网络使用<i>ImageNet</i>数据集进行训练, <i>ImageNet</i>数据集有1 400多万幅图片, 涵盖2万多个类别。本文把数据集中的卡车、轿车标签统一换成了车辆标签。本文使用合作项目中的大量视频数据以及自行搭建的车载实验平台所采集的视频数据来训练<i>LSTM</i>网络模型。车辆视频数据归分为6个类, 分别为直行、左变道、右变道、调头、左转、右转, 每个类中有300多个视频, 视频集中包含白天、傍晚、阴天、雨天等多种不同天气环境及不同路况下拍摄的数据。视频拍摄过程中将摄像头固定于车辆前玻璃正前方, 对车辆正前方目标车辆的行驶行为进行拍摄, 数据采集真实可靠。在本文实验中, 车辆数据如图6所示, 将数据集中的2 218个视频随机分为训练集、验证集和测试集, 其中训练集视频数量为1 330, 验证集视频数量为443, 测试集视频数量为445。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">5.2 <b>网络环境配置及训练</b></h4>
                <div class="p1">
                    <p id="81">实验使用的服务器基于<i>Ubuntu</i> 16.04, 64位操作系统, 使用的深度学习框架是<i>tensorflow</i>, <i>GPU</i>为<i>GeForce GTX</i> 1080<i>Ti</i>。首先用<i>ImageNet</i>数据集对双卷积网络进行训练, 然后在用训练好的双卷积网络对关键帧进行特征提取以便于训练<i>LSTM</i>神经网络。每个关键帧都降采样到224×224大小, <i>LSTM</i>网络隐含层的维度为1 024。在训练<i>LSTM</i>神经网络中, 本文使用<i>Adam</i>优化器中的随机梯度下降算法来学习参数, 学习率设置为10<sup>-5</sup>, 训练的批处理大小<i>Batch</i>为12, 权重衰减 (<i>decay</i>) 为0.000 1, 数据集迭代次数为50。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 车辆行为数据集" src="Detail/GetImg?filename=images/JSJY201907005_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 车辆行为数据集  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Vehicle behavior dataset</i></p>

                </div>
                <h4 class="anchor-tag" id="83" name="83">5.3 <b>结果分析</b></h4>
                <h4 class="anchor-tag" id="84" name="84">5.3.1 m取值不同关键帧的实验结果</h4>
                <div class="p1">
                    <p id="85">由图7可知, 在车右转这一类车辆行为中, 在提取数据帧方式相同的情况下, <i>m</i>值由6到10之间, 识别正确率迅速上升并达到峰值, 之后开始趋于稳定, 当<i>m</i>取值大于12时, 准确率开始略微下降;针对3种不同的子序列取帧方式, 识别的正确率随着<i>m</i>值变化的总体趋势相同, 差距较小。综合而言, 选取子视频的中间帧, 识别效果最优, 整体识别最好。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 m取值对识别准确率的影响" src="Detail/GetImg?filename=images/JSJY201907005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 <i>m</i>取值对识别准确率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Effect of <i>m</i> value on recognition accuracy</p>

                </div>
                <h4 class="anchor-tag" id="87" name="87">5.3.2 行为识别结果</h4>
                <div class="p1">
                    <p id="88">本实验将拆分出来的训练集用于训练模型, 验证集用于评估模型, 预测车辆行为识别结果的好坏, 并验证模型选择的合理性及模型参数的最优性。最后采用已经训练好的网络模型来预测测试集中的视频数据, 得出测试车辆不同行为的准确率, 不同车辆行为类别在数据测试集上的准确率如表2所示。</p>
                </div>
                <div class="area_img" id="89">
                    <p class="img_tit"><b>表</b>2 <b>各类行为识别结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Recognition results of different behavior types</i></p>
                    <p class="img_note"></p>
                    <table id="89" border="1"><tr><td>行为类别</td><td>测试样本数</td><td>准确率/%</td><td></td><td>行为类别</td><td>测试样本数</td><td>准确率/%</td></tr><tr><td>直行</td><td>85</td><td>96.7</td><td></td><td>左变道</td><td>65</td><td>92.9</td></tr><tr><td><br />右转</td><td>78</td><td>95.6</td><td></td><td>右变道</td><td>65</td><td>93.8</td></tr><tr><td><br />左转</td><td>79</td><td>95.4</td><td></td><td>调头</td><td>73</td><td>98.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="90">由表2可知, 在各种天气环境及不同路况, 当车辆行为是直行、左转、右转以及调头的准确率较高, 可以达到95%以上;而左变道、右变道准确率略低, 仅有93%左右。</p>
                </div>
                <div class="p1">
                    <p id="91">实验将数据集按比例随机抽取, 进行多次交叉验证, 行为识别准确率结果如图8 (<i>a</i>) , 损失函数趋势曲线如图8 (<i>b</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="92">由图8 (<i>a</i>) 可见, 在整个训练过程中, 训练集和验证集准确率一直处于上升的趋势, 数据经过10次迭代后, 验证集与训练集准确率相差较大, 经过20次迭代后基本趋于稳定。由此说明, 前期10次迭代过程存在一定的过拟合, 但在后期的迭代中进行了一定的修正, 从而致使识别率逐步提高。由图8 (<i>b</i>) 可知, 损失值在迭代到10次之前, 验证集的损失值下降幅度比训练集大, 之后训练集损失值继续缓慢下降, 验证集损失值趋于稳定。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201907005_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 全样本准确率、损失值变化" src="Detail/GetImg?filename=images/JSJY201907005_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 全样本准确率、损失值变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201907005_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 8 <i>Accuracy and loss value changes of whole sample</i></p>

                </div>
                <h4 class="anchor-tag" id="94" name="94">5.3.3 网络模型对比实验</h4>
                <div class="p1">
                    <p id="95">通过改变相应的网络模型, 针对准确率和对单个视频的识别速度进行算法框架下的内部对比实验。实验结果如表3所示。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表</b>3 <b>模型对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 3 <i>Result of model comparison</i></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td>方案序号</td><td>特征提取</td><td>序列建模</td><td>准确率/%</td><td>识别时间/<i>s</i></td></tr><tr><td>1</td><td><i>ResNet</i>- 50</td><td>双层<i>LSTM</i></td><td>88.5</td><td>1.74</td></tr><tr><td><br />2</td><td><i>ResNet</i>- 50<br /><i>ResNet</i>- 34</td><td>双层<i>LSTM</i></td><td>92.8</td><td>1.75</td></tr><tr><td><br />3</td><td><i>ResNet</i>- 50<br />改进的<i>ResNet</i>- 34</td><td>—</td><td>83.6</td><td>0.82</td></tr><tr><td><br />4</td><td><i>ResNet</i>- 50<br />改进的<i>ResNet</i>- 34</td><td>单层<i>LSTM</i></td><td>93.6</td><td>1.68</td></tr><tr><td><br />5</td><td><i>ResNet</i>- 50<br />改进的<i>ResNet</i>- 34</td><td>双层<i>LSTM</i></td><td>95.6</td><td>1.72</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="97">从表3中可以看出, 检测车辆行为的准确率在各种模型方案下显示不同。通过对比方案1和方案2, 可以看出多一个卷积网络进行特征提取, 准确率提高了4.3个百分点, 但是对于单个视频行为识别速度相近。再对<i>ResNet</i>- 34网络进行2.2节中所述的改进后, 准确率又在原来基础上提高了2.8个百分点。实验过程中发现, 对<i>ResNet</i>- 34网络进行改进后, 直行、左变道、右变道的识别准确率上升更为明显, 说明采用双卷积网络泛化能力强, 性能更高, 能提取更为细微的特征。方案3、方案4和方案5, 都保持了特征提取部分网络不变, 但是方案3不使用<i>LSTM</i>网络的, 这种情况下准确率明显降低很多, 但是单个视频的识别时间减少了一半。方案4使用了单层的<i>LSTM</i>网络来做序列间的特征学习, 准确率比方案5使用双层深度<i>LSTM</i>网络的低2个百分点, 但是网络权重也小了20%左右。</p>
                </div>
                <div class="p1">
                    <p id="98">为了证明本文网络模型在车辆行为识别上的优势, 基于本文视频流数据集, 与现有的一些车辆行为识别的算法进行对比实验。</p>
                </div>
                <div class="p1">
                    <p id="99">从表4中可以看出, 针对视频中车辆特征检测这一角度, 本文提出的车辆特征检测方法可以有效地解决传统方法的某些问题, 比传统的方法更加满足实际中的需求, 且双卷积网络结构检测性能更强, 更能发现细小的特征。</p>
                </div>
                <div class="area_img" id="100">
                    <p class="img_tit"><b>表</b>4 <b>车辆特征检测对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 4 <i>Comparison of vehicle feature detection</i></p>
                    <p class="img_note"></p>
                    <table id="100" border="1"><tr><td><br />算法</td><td>特征检测方法</td><td>适用场景</td><td>检测性能</td></tr><tr><td>文献[4]算法</td><td><i>ViBe</i></td><td>背景相对固定</td><td>一般</td></tr><tr><td><br />文献[5]算法</td><td><i>HOG</i>+<i>SVM</i></td><td>不同背景</td><td>无法检测出较小特征</td></tr><tr><td><br />本文算法</td><td>双卷积网络</td><td>不同条件</td><td>很强</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="101">由表5所示, 在直行、右转、左转、掉头这几个车辆行为识别中, 相比传统车辆行为识别算法, 本文提出的识别网络在各个类别中准确率均是最高, 且平均准确率相比次好的文献<citation id="164" type="reference">[<a class="sup">4</a>]</citation>中的模型提高了6.36%, 获得了更好的分类效果。</p>
                </div>
                <div class="area_img" id="102">
                    <p class="img_tit"><b>表</b>5 <b>不同算法的准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 5 <i>Accuracy comparison of different algorithms</i></p>
                    <p class="img_note">%</p>
                    <table id="102" border="1"><tr><td><br />行为类别</td><td>文献[4]算法</td><td>文献[5]算法</td><td>本文算法</td></tr><tr><td><br />直行</td><td>86.2</td><td>92.3</td><td>96.7</td></tr><tr><td><br />右转</td><td>82.1</td><td>88.9</td><td>95.6</td></tr><tr><td><br />左转</td><td>81.3</td><td>89.1</td><td>95.4</td></tr><tr><td><br />调头</td><td>85.8</td><td>92.7</td><td>98.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">6 结语</h3>
                <div class="p1">
                    <p id="104">针对视频中前方的车辆行为研究这一问题, 提出了基于长短期记忆的车辆行为动态识别网络算法。在车辆行为识别网络设计中, 采用双卷积网络模型对视频中车辆特征进行检测和提取。针对车辆运动状态这一时序问题, 使用<i>LSTM</i>网络进行序列特征深度挖掘, 最终得到行为分类结果。通过对比传统机器视觉的车辆行为分析研究, 本文提出的算法不需要基于先验知识建立车辆姿态模型, 同时可以自适应地学习姿态特征, 并且不受外界因素影响, 对于车辆后方拍摄视角准确率更能满足实际需求, 但是, 本文的研究不能实时有效地识别前方多台车辆的行为, 所以下一步的研究重点主要是在保证准确率的情况下同时识别前方多辆车的动态行为。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="119">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 陈放.高级驾驶辅助系统ADAS浅谈[J].各界, 2018 (1) :188-191. (CHEN F.A dissertation on advanced driver assistance system[J].All Circles, 2018 (1) :188-191.) 
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object-Oriented Bayesian Networks for Detection of Lane Change Maneuvers">

                                <b>[2]</b> KASPER D, WEIDL G, DANG T, et al.Object-oriented Bayesian networks for detection of lane change maneuvers[J].IEEE Intelligent Transportation Systems Magazine, 2012, 4 (3) :19-31.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A framework for estimating driver decisions near intersections">

                                <b>[3]</b> GADEPALLY V, KRISHNAMURTHY A, OZGUNER U.A framework for estimating driver decisions near intersections [J].IEEE Transactions on Intelligent Transportation Systems, 2014, 15 (2) :637-646.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201802020&amp;v=MjkxODVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkx6SVBUblNkN0c0SDluTXJZOUhaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 黄鑫, 肖世德, 宋波.监控视频中的车辆异常行为检测[J].计算机系统应用, 2018, 27 (2) :125-131. (HUANG X, XIAO S D, SONG B.Detection of vehicle's abnormal behaviors in surveillance video[J].Computer Systems and Applications, 2018, 27 (2) :125-131.) 
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG2015S1029&amp;v=MTE1OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnkvblZMeklMVGZIYWJHNEg5U3ZybzlIYlk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 黄慧玲, 杨明, 王春香, 等.基于前方车辆行为识别的碰撞预警系统[J].华中科技大学学报 (自然科学版) , 2015, 43 (s1) :117-121. (HUANG H L, YANG M, WANG C X, et al.Collision warning system based on forward vehicle behavior recognition[J].Journal of Huazhong University of Science and Technology (Natural Science Edition) , 2015, 43 (s1) :117-121.) 
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Long-term recurrent convolutional networks for visual recognition and description">

                                <b>[6]</b> DONAHUE J, HENDRICKS L A, ROHRBACH M, et al.Long-term recurrent convolutional networks for visual recognition and description[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:2625-2634.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MTI5NzJGaW5sVXIzSUoxd1RhUkk9TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> HOCHREITER S, SCHMIDHUBER J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201801020&amp;v=MjA3MTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkx6SUtDallmYkc0SDluTXJvOUg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 殷昊, 李寿山, 贡正仙, 等.基于多通道LSTM的不平衡情绪分类方法[J].中文信息学报, 2018, 32 (1) :139-145. (YIN H, LI S S, GONG Z X, et al.Imbalanced emotion classification based on multi-channel LSTM[J].Journal of Chinese Information Processing, 2018, 32 (1) :139-145.) 
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806008&amp;v=MTE5MTlHRnJDVVI3cWZadVpzRnkvblZMeklMejdCZDdHNEg5bk1xWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 郑毅, 李凤, 张丽, 等.基于长短时记忆网络的人体姿态检测方法[J].计算机应用, 2018, 38 (6) :1568-1574. (ZHENG Y, LI F, ZHANG L, et al.Pose detection and classification with LSTM network[J].Journal of Computer Applications, 2018, 38 (6) :1568-1574.) 
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised sequence labelling">

                                <b>[10]</b> GRAVES A.Supervised Sequence Labelling with Recurrent Neural Networks[M].Berlin:Springer, 2012:385.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201711039&amp;v=MjUxMzZWTHpJTHo3QmJiRzRIOWJOcm85R2JZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5L24=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 曹晋其, 蒋兴浩, 孙锬锋.基于训练图CNN特征的视频人体动作识别算法[J].计算机工程, 2017, 43 (11) :234-238. (CAO J Q, JIANG X H, SUN T F.Video human action recognition algorithm based on trained image CNN features[J].Computer Engineering, 2017, 43 (11) :234-238.) 
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Two-stream convolutional networks for action recognition in videos">

                                <b>[12]</b> SIMONYAN K, ZISSERMAN A.Two-stream convolutional net-works for action recognition in videos[C]// Proceedings of the 2014 International Conference on Neural Information Processing Systems.Montréal:[s.n.], 2014:568-576.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond short snippets:Deep networks for video classification">

                                <b>[13]</b> NG J.Y, MATTHEW H, VIJAYANARASIMHAN S, et al.Beyond short snippets:deep networks for video classification[C]// Proceedings of the 2015 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2015:4694-4702.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTO201702017&amp;v=MTY1NDBGckNVUjdxZlp1WnNGeS9uVkx6SVB5cmZZYkc0SDliTXJZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> CHEN H F, CHEN J, HU R M, et al.Action recognition with temporal scale-invariant deep learning framework[J].China Communications, 2017, 14 (2) :163-172.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet:A large-scale hierarchical image database">

                                <b>[15]</b> DENG J, DONG W, SOCHER R, et al.ImageNet:a large-scale hierarchical image database [C]// Proceedings of the 2009 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2009:248-255.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 HE K M, ZHANG X Y, REN S Q, et.al.Deep residual learning for image recognition [C]// Proceedings of the 2016 IEEE International Conference on Computer Vision and Pattern Recognition.Washington, DC:IEEE Computer Society, 2016:770-778.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201907005" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201907005&amp;v=MjIzOTBqTXFJOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeS9uVkx6SUx6N0JkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxSWmZRblJCWGhwbXU2MEpGM0M3ND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
