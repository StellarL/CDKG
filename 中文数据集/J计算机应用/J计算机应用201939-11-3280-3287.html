<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136448164658750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJY201911029%26RESULT%3d1%26SIGN%3dVrFAUeOB1JvrDQsNanM5qIlV%252fN4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201911029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911029&amp;v=MTY1ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1VyL0lMejdCZDdHNEg5ak5ybzlIYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#65" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="1 基础知识 ">1 基础知识</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="2 维度不确定聚类算法 ">2 维度不确定聚类算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="2.1 &lt;b&gt;部分数据维度不确定的子空间聚类算法&lt;/b&gt;">2.1 <b>部分数据维度不确定的子空间聚类算法</b></a></li>
                                                <li><a href="#115" data-title="2.2 &lt;b&gt;数据集维度不确定子空间聚类算法&lt;/b&gt;">2.2 <b>数据集维度不确定子空间聚类算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="3 值不确定子空间聚类算法 ">3 值不确定子空间聚类算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#145" data-title="3.1 &lt;b&gt;数据值模糊聚类&lt;/b&gt;">3.1 <b>数据值模糊聚类</b></a></li>
                                                <li><a href="#172" data-title="3.2 &lt;b&gt;数据值模糊聚类&lt;/b&gt;">3.2 <b>数据值模糊聚类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#199" data-title="4 基于子空间的复杂高维不确定数据聚类算法 ">4 基于子空间的复杂高维不确定数据聚类算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#220" data-title="5 实验 ">5 实验</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#237" data-title="6 结语 ">6 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#148" data-title="图1 值模糊数据">图1 值模糊数据</a></li>
                                                <li><a href="#204" data-title="图2 算法5流程">图2 算法5流程</a></li>
                                                <li><a href="#222" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验中使用的&lt;/b&gt;&lt;i&gt;UCI&lt;/i&gt;&lt;b&gt;数据集&lt;/b&gt;"><b>表</b>1 <b>实验中使用的</b><i>UCI</i><b>数据集</b></a></li>
                                                <li><a href="#225" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;实验结果分析&lt;/b&gt;"><b>表</b>2 <b>实验结果分析</b></a></li>
                                                <li><a href="#227" data-title="图3 &lt;i&gt;K&lt;/i&gt;取值对UClique算法聚类精度的影响">图3 <i>K</i>取值对UClique算法聚类精度的影响</a></li>
                                                <li><a href="#231" data-title="图4 不确定数据集的聚类结果分析">图4 不确定数据集的聚类结果分析</a></li>
                                                <li><a href="#233" data-title="图5 三种算法的聚类结果分析">图5 三种算法的聚类结果分析</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="285">


                                    <a id="bibliography_1" title=" CRIST&#211;BAL T,PADR&#211;N G,QUESADA-ARENCIBIA A,et al.Systematic approach to analyze travel time in road-based mass transit systems based on data mining[J].IEEE Access,2018,6:32861-32873." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Systematic approach to analyze travel time in road-based mass transit systems based on data mining">
                                        <b>[1]</b>
                                         CRIST&#211;BAL T,PADR&#211;N G,QUESADA-ARENCIBIA A,et al.Systematic approach to analyze travel time in road-based mass transit systems based on data mining[J].IEEE Access,2018,6:32861-32873.
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_2" title=" JEZEWSKI M,CZABANSKI R,LESKI J M.Fuzzy classifier based on clustering with pairs of ε-hyperballs and its application to support fetal state assessment[J].Expert Systems with Applications,2019,118(15):109-126." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAD89A8D1FDD817A4AA4A6DE94F183E0E&amp;v=MDAwNzZyTFUwNXRwaHhiMit3S3M9TmlmT2ZjTE1GdGk5cC90RUVwOTdCSDArdmhKaW16c01UZ3VYcFJaRGVMcVhNTHJxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         JEZEWSKI M,CZABANSKI R,LESKI J M.Fuzzy classifier based on clustering with pairs of ε-hyperballs and its application to support fetal state assessment[J].Expert Systems with Applications,2019,118(15):109-126.
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_3" title=" CHARLES V,TSOLAS I E,GHERMAN T.Satisficing data envelopment analysis:a Bayesian approach for peer mining in the banking sector[J].Annals of Operations Research,2018,269(1/2):81-102." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Satisficing data envelopment analysis:a Bayesian approach for peer mining in the banking sector">
                                        <b>[3]</b>
                                         CHARLES V,TSOLAS I E,GHERMAN T.Satisficing data envelopment analysis:a Bayesian approach for peer mining in the banking sector[J].Annals of Operations Research,2018,269(1/2):81-102.
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_4" title=" FERRERO E,AGARWAL P.Connecting genetics and gene expression data for target prioritisation and drug repositioning[J].Biodata Mining,2018,11(1):7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Connecting genetics and gene expression data for target prioritisation and drug repositioning">
                                        <b>[4]</b>
                                         FERRERO E,AGARWAL P.Connecting genetics and gene expression data for target prioritisation and drug repositioning[J].Biodata Mining,2018,11(1):7.
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_5" title=" FR&#196;NTI P,SIERANOJA S.K-means properties on six clustering benchmark datasets[J].Applied Intelligence,2018,48(12):4743-4759." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=K-means properties on six clustering benchmark datasets">
                                        <b>[5]</b>
                                         FR&#196;NTI P,SIERANOJA S.K-means properties on six clustering benchmark datasets[J].Applied Intelligence,2018,48(12):4743-4759.
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_6" title=" TRIPATHI A,PANWAR K.Modified CURE algorithm with enhancement to identify number of clusters[J].International Journal of Artificial Intelligence and Soft Computing,2016,5(3):226-240." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCW&amp;filename=SJCWADA2318A586C7804E79103A2E0CC287C&amp;v=MDQ0ODdHUWxmQnJMVTA1dHBoeGIyK3dLcz1OaWZJZWNMTWI5UFByb2MwWWVNSmYzc3h6eEptN1RaOFNIeVRybWMxQ3NHV1RiM3NDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         TRIPATHI A,PANWAR K.Modified CURE algorithm with enhancement to identify number of clusters[J].International Journal of Artificial Intelligence and Soft Computing,2016,5(3):226-240.
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_7" title=" ZHENG Z,MA Y,ZHENG H,et al.UGC:real-time,ultra-robust feature correspondence via unilateral grid-based clustering[J].IEEE Access,2018,6:55501-55508." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=UGC:real-time,ultra-robust feature correspondence via unilateral grid-based clustering">
                                        <b>[7]</b>
                                         ZHENG Z,MA Y,ZHENG H,et al.UGC:real-time,ultra-robust feature correspondence via unilateral grid-based clustering[J].IEEE Access,2018,6:55501-55508.
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_8" title=" SEYEDI S A,LOTFI A,MORADI P,et al.Dynamic graph-based label propagation for density peaks clustering[J].Expert Systems with Applications,2019,115:314-328." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES06A4402A463D3DCD73249F355169175A&amp;v=MTEyMjB3S3M9TmlmT2ZiTytiOVhJcjQwMFlPME1lSDlOdkdJVTZUMTVRUW5ocVJjMGY3dVZRci91Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyKw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         SEYEDI S A,LOTFI A,MORADI P,et al.Dynamic graph-based label propagation for density peaks clustering[J].Expert Systems with Applications,2019,115:314-328.
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_9" title=" YANG M S,LAI C Y.A robust EM clustering algorithm for Gaussian mixture models [J].Pattern Recognition,2012,45(11):3950-3961." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737729&amp;v=MzEzOTV3WmVadEZpbmxVcjNJSVZzVmFoRT1OaWZPZmJLN0h0RE5xWTlGWStnSUMzNHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         YANG M S,LAI C Y.A robust EM clustering algorithm for Gaussian mixture models [J].Pattern Recognition,2012,45(11):3950-3961.
                                    </a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_10" title=" BRODINOV&#193; Š,ZAHARIEVA M,FILZMOSER P,et al.Clustering of imbalanced high-dimensional media data[J].Advances in Data Analysis &amp;amp; Classification,2017,12(2):261-284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering of imbalanced high-dimensional media data">
                                        <b>[10]</b>
                                         BRODINOV&#193; Š,ZAHARIEVA M,FILZMOSER P,et al.Clustering of imbalanced high-dimensional media data[J].Advances in Data Analysis &amp;amp; Classification,2017,12(2):261-284.
                                    </a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_11" title=" ZHU W,YAN Y.Joint linear regression and nonnegative matrix factorization based on self-organized graph for image clustering and classification[J].IEEE Access,2018,6:38820-38834." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint linear regression and nonnegative matrix factorization based on self-organized graph for image clustering and classification">
                                        <b>[11]</b>
                                         ZHU W,YAN Y.Joint linear regression and nonnegative matrix factorization based on self-organized graph for image clustering and classification[J].IEEE Access,2018,6:38820-38834.
                                    </a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_12" title=" AAMARI E,LEVRARD C.Stability and minimax optimality of tangential delaunay complexes for manifold reconstruction[J].Discrete &amp;amp; Computational Geometry,2018,59(4):923-971." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stability and minimax optimality of tangential delaunay complexes for manifold reconstruction">
                                        <b>[12]</b>
                                         AAMARI E,LEVRARD C.Stability and minimax optimality of tangential delaunay complexes for manifold reconstruction[J].Discrete &amp;amp; Computational Geometry,2018,59(4):923-971.
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_13" title=" WANG Y,DUAN X,LIU X,et al.A spectral clustering method with semantic interpretation based on axiomatic fuzzy set theory[J].Applied Soft Computing,2018,64:59-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7A9F0EFD3A59DE191D5843FBFB1C5E36&amp;v=MjQwNjhXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyK3dLcz1OaWZPZmJUSkY2Zk0ydmt4WjVvS0JRaE16aDhTbmpwMVRIeVUzbVJIZU1HUk1MbVpDT052RlNpVw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         WANG Y,DUAN X,LIU X,et al.A spectral clustering method with semantic interpretation based on axiomatic fuzzy set theory[J].Applied Soft Computing,2018,64:59-74.
                                    </a>
                                </li>
                                <li id="311">


                                    <a id="bibliography_14" title=" LIU H,ZHANG X,ZHANG X,et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems,2017,126:33-47." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES24E24497651FD1D31EFFDCEC6D0EECBB&amp;v=MDI0NjhyTFUwNXRwaHhiMit3S3M9TmlmT2ZiRzhhOVBJcTRaQ1l1NE9lZ2c0dXhVU24wa0xQQXlYM3hSQmVjZmhOc2p0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         LIU H,ZHANG X,ZHANG X,et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems,2017,126:33-47.
                                    </a>
                                </li>
                                <li id="313">


                                    <a id="bibliography_15" title=" GOYAL P,KUMARI S,SINGH S,et al.A parallel framework for grid-based bottom-up subspace clustering[C]// Proceedings of the 2016 IEEE International Conference on Data Science and Advanced Analytics.Piscataway:IEEE,2016:331-340." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A parallel framework for grid-based bottom-up subspace clustering">
                                        <b>[15]</b>
                                         GOYAL P,KUMARI S,SINGH S,et al.A parallel framework for grid-based bottom-up subspace clustering[C]// Proceedings of the 2016 IEEE International Conference on Data Science and Advanced Analytics.Piscataway:IEEE,2016:331-340.
                                    </a>
                                </li>
                                <li id="315">


                                    <a id="bibliography_16" title=" ZHANG C,FU H,HU Q,et al.Generalized latent multi-view subspace clustering[EB/OL].[2018- 03- 20].https://ieeexplore.ieee.org/document/8502831." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized latent multi-view subspace clustering">
                                        <b>[16]</b>
                                         ZHANG C,FU H,HU Q,et al.Generalized latent multi-view subspace clustering[EB/OL].[2018- 03- 20].https://ieeexplore.ieee.org/document/8502831.
                                    </a>
                                </li>
                                <li id="317">


                                    <a id="bibliography_17" title=" ZHU Y,TING K M,CARMAN M J .Grouping points by shared subspaces for effective subspace clustering[J].Pattern Recognition,2018,83:230-244." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA2C357080A8CC5F4AF2794CA21CFF05D&amp;v=MzAxOTFOWkpvSGZ3ODh1UkppbkQxNlFYdVIzUkEwQ3NUaVJiL3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4YjIrd0tzPU5pZk9mY0s2YmRMSnFJOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         ZHU Y,TING K M,CARMAN M J .Grouping points by shared subspaces for effective subspace clustering[J].Pattern Recognition,2018,83:230-244.
                                    </a>
                                </li>
                                <li id="319">


                                    <a id="bibliography_18" title=" LI X,LU Q,DONG Y,et al.Robust subspace clustering by cauchy loss function[J].IEEE Transactions on Neural Networks and Learning Systems,2018,30(7):2067-2078." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust subspace clustering by cauchy loss function">
                                        <b>[18]</b>
                                         LI X,LU Q,DONG Y,et al.Robust subspace clustering by cauchy loss function[J].IEEE Transactions on Neural Networks and Learning Systems,2018,30(7):2067-2078.
                                    </a>
                                </li>
                                <li id="321">


                                    <a id="bibliography_19" title=" CHEN H,WANG W,FENG X.Structured sparse subspace clustering with grouping-effect-within-cluster[J].Pattern Recognition,2018,10(83):107-118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF5BC573D4A4EAD939349AC3D5538A102&amp;v=MjEwNDlsZkJyTFUwNXRwaHhiMit3S3M9TmlmT2ZjVzliS0xKcUl3eFlKb0xlUTFOeGhVYTZUdDBPUXpoMkJjd2VycmxSTHFkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         CHEN H,WANG W,FENG X.Structured sparse subspace clustering with grouping-effect-within-cluster[J].Pattern Recognition,2018,10(83):107-118.
                                    </a>
                                </li>
                                <li id="323">


                                    <a id="bibliography_20" title=" 范虹,侯存存,朱艳春,等.烟花算法优化的软子空间MR图像聚类算法[J].软件学报,2017,28(11):3080-3093.(FAN H,HOU C C,ZHU Y C,et al.Soft subspace algorithm for MR image clustering based on fireworks optimization algorithm[J].Journal of Software,2017,28(11):3080-3093.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201711021&amp;v=MTk5MTFzRnluZ1VyL0xOeWZUYkxHNEg5Yk5ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         范虹,侯存存,朱艳春,等.烟花算法优化的软子空间MR图像聚类算法[J].软件学报,2017,28(11):3080-3093.(FAN H,HOU C C,ZHU Y C,et al.Soft subspace algorithm for MR image clustering based on fireworks optimization algorithm[J].Journal of Software,2017,28(11):3080-3093.)
                                    </a>
                                </li>
                                <li id="325">


                                    <a id="bibliography_21" title=" 傅文进,吴小俊.基于l_2范数的加权低秩子空间聚类[J].软件学报,2017,28(12):3347-3357.(FU W J,WU X J.Weighted low rank subspace clustering based on l_2 norm[J].Journal of Software,2017,28(12):3347-3357.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201712014&amp;v=MDM1OTVnVXIvTE55ZlRiTEc0SDliTnJZOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         傅文进,吴小俊.基于l_2范数的加权低秩子空间聚类[J].软件学报,2017,28(12):3347-3357.(FU W J,WU X J.Weighted low rank subspace clustering based on l_2 norm[J].Journal of Software,2017,28(12):3347-3357.)
                                    </a>
                                </li>
                                <li id="327">


                                    <a id="bibliography_22" title=" SEIDL T.Nearest neighbor classification[M]// Data Mining in Agriculture.Berlin:Springer,2009:83-106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nearest neighbor classification">
                                        <b>[22]</b>
                                         SEIDL T.Nearest neighbor classification[M]// Data Mining in Agriculture.Berlin:Springer,2009:83-106.
                                    </a>
                                </li>
                                <li id="329">


                                    <a id="bibliography_23" title=" ALTMAN N S.An introduction to kernel and nearest-neighbor nonparametric regression[J].American Statistician,1992,46(3):175-185." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Introduction to Kernel and Nearest Neighbor Nonparametric Regression">
                                        <b>[23]</b>
                                         ALTMAN N S.An introduction to kernel and nearest-neighbor nonparametric regression[J].American Statistician,1992,46(3):175-185.
                                    </a>
                                </li>
                                <li id="331">


                                    <a id="bibliography_24" title=" 肖宇鹏,何云斌,万静,等.基于模糊C-均值的空间不确定数据聚类[J].计算机工程,2015,41(10):47-52.(XIAO Y P,HE Y B,WAN J,et al.Clustering of space uncertain data based on fuzzy C-means[J].Computer Engineering,2015,41(10):47-52.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201510011&amp;v=MTg0MDdmWnVac0Z5bmdVci9MTHo3QmJiRzRIOVROcjQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         肖宇鹏,何云斌,万静,等.基于模糊C-均值的空间不确定数据聚类[J].计算机工程,2015,41(10):47-52.(XIAO Y P,HE Y B,WAN J,et al.Clustering of space uncertain data based on fuzzy C-means[J].Computer Engineering,2015,41(10):47-52.)
                                    </a>
                                </li>
                                <li id="333">


                                    <a id="bibliography_25" title=" 周晓云,孙志挥,张柏礼,等.高维数据流子空间聚类发现及维护算法[J].计算机研究与发展,2006,43(5):834-840.(ZHOU X Y,SUN Z H,ZHANG B L,et al.An efficient discovering and maintenance algorithm of subspace clustering over high dimensional data streams[J].Journal of Computer Research and Development,2006,43(5):834-840.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200605009&amp;v=MTIzMDVMRzRIdGZNcW85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5bmdVci9MTHl2U2Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         周晓云,孙志挥,张柏礼,等.高维数据流子空间聚类发现及维护算法[J].计算机研究与发展,2006,43(5):834-840.(ZHOU X Y,SUN Z H,ZHANG B L,et al.An efficient discovering and maintenance algorithm of subspace clustering over high dimensional data streams[J].Journal of Computer Research and Development,2006,43(5):834-840.)
                                    </a>
                                </li>
                                <li id="335">


                                    <a id="bibliography_26" title=" 孙翌,胡爱.基于多维度关联的机构知识库数据模型的构建与分析[J].现代情报,2018,38(7):95-106.(SUN Y,HU A.Construction and analysis on data model of institutional repository based on multidimensional linked data[J].Journal of Modern Information,2018,38(7):95-106.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDQB201807014&amp;v=MjU5MjRiTEc0SDluTXFJOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5nVXIvTFBTbmE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         孙翌,胡爱.基于多维度关联的机构知识库数据模型的构建与分析[J].现代情报,2018,38(7):95-106.(SUN Y,HU A.Construction and analysis on data model of institutional repository based on multidimensional linked data[J].Journal of Modern Information,2018,38(7):95-106.)
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-09-05 12:49</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(11),3280-3287 DOI:10.11772/j.issn.1001-9081.2019050928            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>高维不确定数据的子空间聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E9%9D%99&amp;code=07002171&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E9%BE%99%E5%90%9B&amp;code=43224073&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑龙君</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E4%BA%91%E6%96%8C&amp;code=07001467&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何云斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%9D%BE&amp;code=15107572&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李松</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%93%88%E5%B0%94%E6%BB%A8%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0003194&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">哈尔滨理工大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>如何降低不确定数据对高维数据聚类的影响是当前的研究难点。针对由不确定数据与维度灾难导致的聚类精度低的问题,采用先将不确定数据确定化,后对确定数据聚类的方法。在将不确定数据确定化的过程中,将不确定数据分为值不确定数据与维度不确定数据,并分别处理以提高算法效率。采用结合期望距离的<i>K</i>近邻(<i>K</i>NN)查询得到对聚类结果影响最小的不确定数据近似值以提高聚类精度。在得到确定数据之后,采用子空间聚类的方式避免维度灾难的影响。实验结果证明,基于Clique的高维不确定数据聚类算法(UClique)在UCI数据集上有较好的表现,有良好的抗噪声能力和伸缩性,在高维数据上能得到较好的聚类结果,在不同的不确定数据集实验中能够得到较高精度的实验结果,体现出算法具有一定的健壮性,能够有效地对高维不确定数据集聚类。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E7%A1%AE%E5%AE%9A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不确定;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Clique%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Clique算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E%E8%BF%91%E9%82%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>近邻;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *万静(1972—),女,江苏泰兴人,教授,博士,主要研究方向:数据库理论与应用、嵌入式系统,电子邮箱,wanjha@163.com;
                                </span>
                                <span>
                                    郑龙君(1993—),男,黑龙江佳木斯人,硕士研究生,主要研究方向:数据挖掘、空间数据聚类;;
                                </span>
                                <span>
                                    何云斌(1972—),男,福建平潭人,教授,博士,主要研究方向:数据库理论与应用;;
                                </span>
                                <span>
                                    李松(1977—),男,江苏沛县人,副教授,博士,主要研究方向:数据库理论与应用、数据挖掘、数据查询。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目(61872105);</span>
                                <span>黑龙江教育厅科学技术研究项目(1253lz004);</span>
                                <span>黑龙江省留学归国人员科学基金资助项目(LC2018030);</span>
                    </p>
            </div>
                    <h1><b>Subspace clustering algorithm for high dimensional uncertain data</b></h1>
                    <h2>
                    <span>WAN Jing</span>
                    <span>ZHENG Longjun</span>
                    <span>HE Yunbin</span>
                    <span>LI Song</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, Harbin University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>How to reduce the impact of uncertain data on high dimensional data clustering is the difficulty of current research. Aiming at the problem of low clustering accuracy caused by uncertain data and curse of dimensionality, the method of determining the uncertain data and then clustering the certain data was adopted. In the process of determining the uncertain data, uncertain data were divided into value uncertain data and dimension uncertain data, and were processed separately to improve algorithm efficiency. <i>K</i>-Nearest Neighbor(<i>K</i>NN) query combined with expected distance was used to obtain the approximate value of uncertain data with the least impact on the clustering results, so as to improve the clustering accuracy. After determining the uncertain data, the method of subspace clustering was adopted to avoid the impact of the curse of dimensionality. The experimental results show that high-dimensional uncertain data clustering algorithm based on Clique for Uncertain data(UClique) has good performance on UCI datasets, has good anti-noise performance and scalability, can obtain better clustering results on high dimensional data, and can achieve the experimental results with higher accuracy on different uncertain datasets, showing that the algorithm is robust and can effectively cluster high dimensional uncertain data.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=high-dimension&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">high-dimension;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=uncertain&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">uncertain;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Clique(Clique%20for%20all%20data)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Clique(Clique for all data) algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EK%3C%2Fi%3E-Nearest%20Neighbor(%3Ci%3EK%3C%2Fi%3ENN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>K</i>-Nearest Neighbor(<i>K</i>NN);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WAN Jing, born in 1972, Ph. D., professor. Her research interests include database theory and application, embedded system. ;
                                </span>
                                <span>
                                    ZHENG Longjun, born in 1993, M. S. candidate. His research interests include data mining, spatial data clustering. ;
                                </span>
                                <span>
                                    HE Yunbin, born in 1972, Ph. D., professor. His research interests include database theory and application. ;
                                </span>
                                <span>
                                    LI Song, born in 1977, Ph. D., associate professor. His research interests include database theory and application, data mining, data query.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-03</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61872105);</span>
                                <span>the Science and Technology Research Project of Heilongjiang Education Department(1253lz004);</span>
                                <span>the Science Foundation for Returned Scholars of Heilongjiang Province(LC2018030);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="65" name="65" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="66">数据挖掘已经被广泛应用到日常生活与工作中,在诸多领域都扮演着重要的角色,例如交通<citation id="337" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、医疗<citation id="338" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、金融<citation id="339" type="reference"><link href="289" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、制药<citation id="340" type="reference"><link href="291" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等。聚类是数据挖掘中的一种无先验条件的无监督分析方法。将数据集中的数据根据各自的特征分成不同的簇,簇间尽可能相异,簇内尽可能相似。聚类的方法多种多样,经典的聚类方法有基于划分的聚类方法<citation id="341" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、基于层次的聚类方法<citation id="342" type="reference"><link href="295" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、基于网格的聚类方法<citation id="343" type="reference"><link href="297" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、基于密度的聚类方法<citation id="344" type="reference"><link href="299" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,还有基于模型的聚类方法<citation id="345" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。伴随着学者们的努力研究,新的聚类方法被提出,例如高维数据的聚类方法<citation id="346" type="reference"><link href="303" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、图像聚类<citation id="347" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="67">高维数据的聚类容易受到维度灾难的影响,传统的聚类方法不能有效地对高维数据聚类。经过国内外学者的不断研究,高维数据的聚类方法可以被分为以下3种:基于降维的聚类<citation id="348" type="reference"><link href="307" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、基于子空间的聚类和其他的聚类方法<citation id="349" type="reference"><link href="309" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。子空间聚类方法是选出部分数据作为高维数据的子空间,在子空间上聚类代替在整个数据集上聚类。子空间聚类在加权方法上分为软子空间聚类算法与硬子空间聚类算法,在搜索方法上可分为自下而上的子空间聚类算法与自上而下的子空间聚类算法。</p>
                </div>
                <div class="p1">
                    <p id="68">Liu等<citation id="350" type="reference"><link href="311" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出基于SMDM(Self-adapted Mixture Distance Measure)的聚类算法,解决了不确定数据聚类效率低的问题,算法提出了自适应的混合距离,降低了不确定数据对聚类结果的影响。算法在聚类效果、伸缩性等方面有良好的表现,由于算法中核密度估计的计算量较大,算法在对高维数据聚类时效果不明显。针对高维数据的维度灾难问题,Goyal等<citation id="351" type="reference"><link href="313" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了ENCLUS(ENtropy-based CLUStering)算法,证明了在普通的低秩子空间聚类效果更好,算法采用ORT(Optimal Rigid Transform)得到更适合的子空间集合,但文中大量的对子空间优化步骤影响了算法的效率,导致算法的伸缩性较差。由于高维数据聚类过程精度都难以得到保证,Zhang等<citation id="352" type="reference"><link href="315" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出lLMSC(linear Latent Multi-view Subspace Clustering)算法与gMLSC(generalized Latent Multi-view Subspace Clustering)算法,采用对多个视图的潜在表示来探索数据点之间的关系,可以有效处理噪声。引入神经网络来探索更广泛的关系,可以有效提高聚类精度。但是针对不同类别的数据,算法的效果不够理想,因为线性模型不足以在任何情况下模拟不同视图之间的相关性,而且无法得到全局最优解,因此算法的普适性较差。随后Zhu等<citation id="353" type="reference"><link href="317" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出CSSub(Clustering by Shared Subspaces)算法,该算法提出新的子空间聚类框架,使相邻的核心点能够根据它们共享的子空间数量聚类,将候选子空间选择和聚类划分为两个独立的过程,算法的普适性得到提高。但是受到了子空间聚类的限制,算法对子空间的质量比较敏感。针对这个问题,Li等<citation id="354" type="reference"><link href="319" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出基于CLF(Cauchy Loss Function)的子空间聚类算法,提出了采用CLF抑制噪声,减小噪声对算法的影响。算法从理论上证明了阻效应,能够保持原始数据的局部结构,提高子空间的质量,但算法对参数<i>c</i>和<i>λ</i>敏感。为了避免算法对参数的敏感问题,Chen等<citation id="355" type="reference"><link href="321" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出SSSC(Structured Sparse Subspace Clustering)算法。算法定义了一个新的分组效应集群(Grouping-Effect-Within-Cluster, GEWC),并结合分割矩阵提出了一种新的惩罚方法,避免参数影响的同时,提高了算法的聚类精度。而范虹等<citation id="356" type="reference"><link href="323" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出基于烟花算法优化的软子空间聚类算法(Soft Subspace Clustering based on Fireworks Optimization Algorithm, FWASSC)算法,设计了新的目标函数,弥补了对噪声敏感的缺点,设计了新的隶属度计算方法,提高了聚类精度。同时傅文进等<citation id="357" type="reference"><link href="325" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>从全局结构到局部结构的子空间聚类方法(Global structure and Local structure of data for Subspace Clustering, GLSC)算法,利用高斯核函数对<i>l</i><sub>2</sub>范数加权,得到了较好的聚类结果。文献<citation id="358" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</citation>算法的共同问题是大量迭代计算导致算法耗时较长。</p>
                </div>
                <div class="p1">
                    <p id="69">本文采用子空间聚类算法对高维不确定数据聚类。Clique算法是经典的子空间聚类算法,适合对高维数据聚类,但是并不适合对不确定数据聚类。针对高维不确定数据的聚类问题,根据Clique算法提出改进。高维不确定数据分为维度不确定与值不确定两种情况:维度不确定又分为部分数据维度不确定与数据集维度不确定;值不确定分为值模糊与缺失值。针对这4种情况下分别提出算法:在针对高维部分数据不确定的情况下采用结合均值和方差的Clique算法;在针对高维数据集维度不确定的情况下,通过计算维度之间的相关性得到确定的维度集合,结合Clique算法聚类;针对高维数据的值模糊与存在缺失值的情况,提出结合<i>K</i>近邻(<i>K</i>-Nearest Neighbor, <i>K</i>NN)算法的Clique算法。</p>
                </div>
                <div class="p1">
                    <p id="70">本文的贡献主要有4个方面:</p>
                </div>
                <div class="p1">
                    <p id="71">1)针对高维不确定数据中,部分数据维度不确定的情况提出了针对维度不确定数据的Clique(Clique for Uncertain Dimension of Partial Data, UDPClique)算法,根据不同维度的维度特点,将不确定数据划分到相应维度。</p>
                </div>
                <div class="p1">
                    <p id="72">2)针对数据集维度不确定的高维不确定数据提出针对维度不确定数据集的Clique(Clique for Uncertain Dimensions of Datasets, UDDClique)算法,根据维度之间的关联程度判断不确定维度的确定程度,得到确定的维度。</p>
                </div>
                <div class="p1">
                    <p id="73">3)针对空间位置模糊的高维不确定数据提出针对模糊数据的Clique(Clique for Fuzzy Value range, UFVClique)算法,根据不确定数据在确定数据集中的<i>K</i>近邻分布情况判断不确定数据的所属网格,利用网格的邻近性聚类。</p>
                </div>
                <div class="p1">
                    <p id="74">4)针对存在缺失值的高维不确定数据提出针对缺失数据的Clique(Clique for Missing Values, UMVClique)算法,根据不确定数据在确定数据集中的<i>K</i>近邻,填补缺失值。</p>
                </div>
                <h3 id="75" name="75" class="anchor-tag">1 基础知识</h3>
                <div class="p1">
                    <p id="76"><b>定理</b>1 反单调性<citation id="359" type="reference"><link href="327" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。如果数据集<i>S</i>在<i>k</i>-1维空间是密集的,那么在任意的<i>k</i>维空间中数据集<i>S</i>也是密集的。</p>
                </div>
                <div class="p1">
                    <p id="77"><b>定义</b>1 最近邻(Nearest Neighbor,NN)查询<citation id="360" type="reference"><link href="329" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。给定数据对象集合<i>P</i>和一个查询点<i>q</i>,最近邻查询就是在集合<i>P</i>中找到一个数据对象子集,满足下面条件:</p>
                </div>
                <div class="p1">
                    <p id="78"><i>NN</i>(<i>q</i>)={<i>p</i>∈<i>P</i>|∀<i>o</i>∈<i>P</i>,<i>dist</i>(<i>q</i>,<i>p</i>)≤<i>dist</i>(<i>q</i>,<i>o</i>)}      (1)</p>
                </div>
                <div class="p1">
                    <p id="80"><b>定义</b>2 <i>K</i>近邻查询<citation id="361" type="reference"><link href="329" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。给定数据对象集合<i>P</i>和一个查询点 <i>q</i>,<i>K</i>最近邻查询就是在集合<i>P</i>中找到<i>K</i>个数据,这<i>K</i>个数据距离<i>q</i>的距离小于其他数据距离<i>q</i>的距离。</p>
                </div>
                <div class="p1">
                    <p id="81"><b>定义</b>3 空间不确定数据<citation id="362" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。在<i>m</i>维空间<b>R</b><sup><i>m</i></sup>中,给定一组不确定空间数据对象<i>O</i>={<i>o</i><sub>1</sub>,<i>o</i><sub>2</sub>,…,<i>o</i><sub><i>n</i></sub>},距离函数<i>d</i>:<b>R</b><sup>2</sup><sup><i>m</i></sup>→<b>R</b>,对于每个不确定空间数据对象<i>o</i><sub><i>i</i></sub>,都有一个概率密度函数<i>f</i><sub><i>i</i></sub>:<b>R</b><sup><i>m</i></sup>→<b>R</b>定义不确定对象的分布。根据概率密度函数得到:<i>f</i><sub><i>i</i></sub>(<i><b>x</b></i>)≥0,∀<i><b>x</b></i>∈<b>R</b><sup><i>m</i></sup>,∫<sub><i><b>x</b></i></sub><sub>∈</sub><sub><b>R</b></sub><sub><sup><i>m</i></sup></sub><i>f</i><sub><i>i</i></sub>(<i><b>x</b></i>)d<i><b>x</b></i>=1通过期望距离衡量不确定对象的相似度。</p>
                </div>
                <div class="p1">
                    <p id="82"><b>定义</b>4 期望距离<citation id="363" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。不确定空间对象<i>o</i><sub><i>i</i></sub>和任意点<i>p</i>的期望距离定义:</p>
                </div>
                <div class="p1">
                    <p id="83"><i>ED</i>(<i>o</i><sub><i>i</i></sub>,<i>p</i>)=∫<sub><i><b>x</b></i></sub><sub>∈</sub><sub><i>Ai</i></sub><i>f</i><sub><i>i</i></sub>(<i><b>x</b></i>)<i>Dist</i>(<i><b>x</b></i>,<i>p</i>)d<i><b>x</b></i>; <i>p</i>∈<b>R</b><sup><i>k</i></sup>      (2)</p>
                </div>
                <div class="p1">
                    <p id="84">假设<i>A</i>={<i>A</i><sub>1</sub>,<i>A</i><sub>2</sub>,…,<i>A</i><sub><i>k</i></sub>}是一个有界、全部有序域的集合,<i>S</i>=<i>A</i><sub>1</sub>,<i>A</i><sub>2</sub>,…,<i>A</i><sub><i>k</i></sub>是一个<i>k</i>维的数值空间,其中<i>A</i><sub>1</sub>,<i>A</i><sub>2</sub>,…,<i>A</i><sub><i>k</i></sub>表示<i>S</i>的<i>k</i>个维。<i>k</i>维数据<i>X</i>=〈<i><b>x</b></i><sub>1</sub>,<i><b>x</b></i><sub>2</sub>,…,<i><b>x</b></i><sub><i>k</i></sub>〉表示<i>S</i>上的数据在<i>t</i>时刻的一个点集,其中<i><b>x</b></i><sub><i>i</i></sub>=〈<i>x</i><sub><i>i</i></sub><sub>1</sub>,<i>x</i><sub><i>i</i></sub><sub>2</sub>,…,<i>x</i><sub><i>ik</i></sub>〉表示一个数据点,<i>x</i><sub><i>ij</i></sub>为数据点<i><b>x</b></i><sub><i>i</i></sub>的第<i>j</i>维的值。</p>
                </div>
                <div class="p1">
                    <p id="85"><b>定义</b>5 子空间<citation id="364" type="reference"><link href="333" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。数值空间<i>Sub</i>=<i>A</i><sub><i>t</i></sub><sub>1</sub>×<i>A</i><sub><i>t</i></sub><sub>2</sub>×…×<i>A</i><sub><i>tg</i></sub>,其中<i>g</i>小于维数<i>k</i>,并且当<i>i</i>&lt;<i>j</i>,<i>t</i><sub><i>i</i></sub>&lt;<i>t</i><sub><i>j</i></sub>时,称<i>Sub</i>为<i>S</i>的一个子空间。</p>
                </div>
                <div class="p1">
                    <p id="86"><b>定义</b>6 多维度关联<citation id="365" type="reference"><link href="335" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>。维度是具有某一相同特征数据的集合,多维度则是从不同层次、不同角度呈现数据,数据之间可以有交叉。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag">2 维度不确定聚类算法</h3>
                <div class="p1">
                    <p id="88">高维数据的不确定性可以分为值不确定和维度不确定,针对维度不确定的情况采用子空间聚类算法。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2.1 <b>部分数据维度不确定的子空间聚类算法</b></h4>
                <div class="p1">
                    <p id="90">日常生活中存在一些维度不确定的高维数据,这些数据在数据集中是游离的,在聚类过程中会降低聚类精度。本节针对这种情况提出<i>UDPClique</i>算法。</p>
                </div>
                <div class="p1">
                    <p id="91">高维数据中存在部分数据不确定的情况,针对数据的维度不确定导致聚类精度低的问题, 提出<i>UDPClique</i>算法。根据不确定数据在不同维度的差异,可以判断出不确定数据的维度分布,可以将不确定数据确定化。采用<i>Clique</i>算法对确定的数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="92">高维数据集中的数据的特点与维度相关,不同维度中的数据特点不同。针对这一情况,按照维度特点将不确定数据划分到最相似的维度中,可以最大限度地减小不确定数据对聚类精度的影响。虽然存在划分错误的可能,但由于划分是符合维度的数据特点,所以对聚类精度的影响不大。</p>
                </div>
                <div class="p1">
                    <p id="93">假设存在不确定数据<i>u</i><sub><i>i</i></sub>={<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub>,…,<i>a</i><sub><i>j</i></sub>},其中<i>i</i>代表不确定数据在数据集中的位置,<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub>,…,<i>a</i><sub><i>j</i></sub>代表不确定数据<i>j</i>个维度的值。可以通过计算不确定数据在各个维度与维度均值的差异来判断不确定数据的维度划分。差异的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>d</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中:<i>m</i><sub><i>k</i></sub>(<i>a</i><sub><i>i</i></sub>)代表在第<i>k</i>个维度的差异值,<mathml id="239"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>d</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>k</mi></msub></mrow></math></mathml>代表在第<i>k</i>个维度的均值。</p>
                </div>
                <div class="p1">
                    <p id="96">将数据集的维度按照方差大小排列,方差计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munderover><mrow><msqrt><mrow><mo stretchy="false">(</mo><mi>d</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mrow><mover accent="true"><mi>d</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>k</mi></msub></mrow><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">其中:<i>Va</i><sub><i>k</i></sub>为第<i>k</i>个维度的方差,<i>d</i><sub><i>k</i></sub><sub>(</sub><sub><i>i</i></sub><sub>)</sub>表示第<i>k</i>个维度中第<i>i</i>个数据的值,<mathml id="240"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>d</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>k</mi></msub></mrow></math></mathml>为第<i>k</i>个维度的均值,<i>n</i><sub><i>k</i></sub>表示第<i>k</i>个维度的数据总数。</p>
                </div>
                <div class="p1">
                    <p id="99">均值和方差可以有效体现一个数据集的数据特征,方差可以反映出数据集的密集程度,方差越小的数据集越密集,方差越大的数据集越稀疏。均值可以在一定程度上体现数据集中数据的分布情况,但会受到数据集的密集程度的影响。方差小的数据集,其均值所体现的数据集的位置分布更准确,方差大的数据集,其均值所体现的数据集位置分布准确性较低。根据这两点,将不确定数据未知维度的值划分到更相似的维度,能够最大限度地保证聚类精度。但首先要按照数据集方差从大到小的顺序依次划分不确定数据的维度。保证密集的维度首先被划分,密集的维度均值的代表性强,对划分的准确度要求高; 而稀疏的维度,对划分的准确度要求低。</p>
                </div>
                <div class="p1">
                    <p id="100">算法1的具体步骤为:首先将数据分为确定数据和不确定数据,并将确定数据按维度划分,得到维度集。采用式(4)计算每个维度集方差,并按照方差大小排列维度集,采用式(3)计算每个维度集的均值,根据均值将不确定数据划分维度。得到确定数据集,采用Clique算法对确定数据集聚类。</p>
                </div>
                <div class="area_img" id="280">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="280">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="114">由文献<citation id="366" type="reference">[<a class="sup">23</a>]</citation>可得步骤8)Clique算法的时间复杂度为<i>O</i>(<i>ck</i>+<i>kn</i>),其中<i>k</i>为数据集维数,<i>n</i>为数据集数据总数,<i>c</i>为簇的个数;步骤1)、2)的时间复杂度为<i>O</i>(<i>n</i>);步骤3)～7)的时间复杂度为<i>O</i>(<i>kn</i>+<i>k</i>)。那么算法1的时间复杂度为<i>O</i>((<i>c</i>+1)<i>k</i>+(2<i>k</i>+1)<i>n</i>)。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">2.2 <b>数据集维度不确定子空间聚类算法</b></h4>
                <div class="p1">
                    <p id="116">针对数据集维度不确定的高维数据提出<i>UDDClique</i>聚类算法,利用维度之间的关联性得到数据集的确定维度,并采用<i>Clique</i>算法对数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="117">日常生活中经常会碰到记录散乱的数据,数据中存在缺失值、脏数据等情况。这种情况大量出现在高维数据中的某一维度或多个维度中,数据集的维度确定性降低,聚类质量会受到影响。高维数据具有稀疏性,当数据集的维度不确定时,数据集的稀疏程度会受影响,聚类的难度增加。高维数据的维度之间具有相关性,相关的维度之间存在相应的关联规则,如果某一个维度和多个维度具有强的关联性,那么这个维度存在的可能性就比较高,对于数据集来讲这个维度的信息比较重要,对聚类分析帮助比较大。根据这个特点对数据集维度不确定的数据聚类。</p>
                </div>
                <div class="p1">
                    <p id="118"><b>定义</b>7 维度相关度。存在高维数据集<i>C</i>={<i>d</i><sub>1</sub>,<i>d</i><sub>2</sub>,…,<i>d</i><sub><i>n</i></sub>},数据集<i>C</i>中拥有维度<i>a</i>与维度<i>b</i>。假设维度<i>a</i>中一共存在<i>n</i>个数据在维度<i>b</i>中也能够找到,那么维度<i>a</i>与维度<i>b</i>的相关度为<i>n</i>。记为:</p>
                </div>
                <div class="p1">
                    <p id="119"><i>co</i>(<i>a</i>|<i>b</i>)=<i>co</i>(<i>b</i>|<i>a</i>)=<i>n</i>      (5)</p>
                </div>
                <div class="p1">
                    <p id="120"><b>定义</b>8 维度关联度。存在高维数据集<i>C</i>,数据集<i>C</i>中拥有维度<i>a</i>与其他维度。维度<i>a</i>与其他维度的相关度的和,为维度<i>a</i>与数据集<i>C</i>的关联度。公式为:</p>
                </div>
                <div class="p1">
                    <p id="121"><mathml id="241"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mi>o</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>c</mi></mstyle><mi>o</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">|</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></math></mathml>; <i>i</i>≠<i>a</i>      (6)</p>
                </div>
                <div class="p1">
                    <p id="122">其中:<i>a</i>为第<i>a</i>个维度,<i>k</i>为数据集的维数。</p>
                </div>
                <div class="p1">
                    <p id="123">采用数据集矩阵计算各个维度的相关度。数据集矩阵的生成方式:以数据作为矩阵横轴,以维度作为竖轴。每一个数据在存在的维度上为1,不存在的维度上为0, 这样矩阵每一列代表一个数据存在于哪些维度,每一行代表每一个维度拥有哪些数据。通过矩阵可以很方便地得到维度密度与维度相关度。维度密度是维度中集合数据的个数,记为<i>d</i><sub><i>a</i></sub>(<i>a</i>代表在第<i>a</i>个维度)。</p>
                </div>
                <div class="p1">
                    <p id="124">在针对高维数据的子空间聚类算法中,维度密度是子空间生成的一个标准。在针对高维不确定数据时,维度密度无法体现维度存在的可能性。在维度密度的基础上结合维度相关度,即可以保证数据量足够多,足以保证维度的确定性。可选维度公式为:</p>
                </div>
                <div class="p1">
                    <p id="125"><i>ch</i><sub><i>i</i></sub>=<i>co</i><sub><i>i</i></sub>×<i>d</i><sub><i>i</i></sub>      (7)</p>
                </div>
                <div class="p1">
                    <p id="126">高维数据聚类算法的计算复杂,子空间聚类方法通过在子数据集的聚类来减小计算量,子空间中的数据要在一定程度上能够代替整个数据集。首先子空间中的数据要足够多,才有聚类分析的价值; 其次子空间中的数据要足够重要,无关的数据只会增加聚类的复杂性。在高维不确定数据集中,维度集确定性也是子空间选择数据的标准,不确定数据会增加聚类的时间并降低聚类精度。根据子空间数据的特点选取子空间,将维度密度大而且关联性强的维度用作生成子空间。保证了子空间中有足够多并足够重要的数据,数据的确定性也得到了保证。采用均值作为维度选择阈值,维度关联度是在维度密度的基础上得到的,维度关联度大的维度维度密度必然大,反之则不成立。针对这一点,根据式(7)得到的数据会呈现明显的两极分化,以均值作为阈值可以有效区分维度之间的差异。计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="127" class="code-formula">
                        <mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>c</mi></mstyle><mi>h</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="128">在得到确定维度并生成确定数据集后,采用Clique算法对确定数据集聚类。结合维度相关性将不确定维度确定化可以最大限度地提高聚类精度。根据式(8)将适合聚类的维度选择出来,生成确定数据集,针对确定的高维数据集Clique算法可以有效地聚类。</p>
                </div>
                <div class="p1">
                    <p id="129">算法2步骤:首先生成数据矩阵,从矩阵中可以得到每个维度的维度密度,可以得到维度之间的相关度,并计算维度关联度。通过计算维度关联度与维度密度可以得到维度准确性,并依据维度确定性得到确定维度。用Clique算法对确定的数据集聚类。</p>
                </div>
                <div class="area_img" id="281">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="142">由文献<citation id="367" type="reference">[<a class="sup">23</a>]</citation>可得步骤7)Clique算法的时间复杂度为<i>O</i>(<i>ck</i>+<i>kn</i>),<i>k</i>为数据集维数,<i>n</i>为数据集数据总数,<i>c</i>为簇的个数。假设数据集拥有<i>k</i>个维度,拥有<i>n</i>个数据:步骤1)生成矩阵的时间复杂度为<i>O</i>(<i>n</i>);步骤2)～5)得到每个维度的维度相关度、维度关联度、维度确定性所需要的时间复杂度为<i>O</i>(<i>n</i>);步骤6)计算维度确定性阈值并得到确定维度的时间复杂度为<i>O</i>(<i>k</i>),那么算法2的时间复杂度为<i>O</i>((<i>c</i>+1)<i>k</i>+(<i>k</i>+2)<i>n</i>)。</p>
                </div>
                <h3 id="143" name="143" class="anchor-tag">3 值不确定子空间聚类算法</h3>
                <div class="p1">
                    <p id="144">2.1节、2.2节主要分析了高维不确定数据中的数据集维度不确定和部分数据维度不确定两种情况。本章针对高维不确定数据中的数值模糊和数据值缺失问题,分别提出了相应的聚类算法。</p>
                </div>
                <h4 class="anchor-tag" id="145" name="145">3.1 <b>数据值模糊聚类</b></h4>
                <div class="p1">
                    <p id="146">在高维数据中的模糊数据会降低聚类精度,增加聚类的难度。本文提出结合K<i>NN</i>算法的子空间算法<i>UFVClique</i>,解决高维数据集中数据模糊的聚类问题。</p>
                </div>
                <div class="p1">
                    <p id="147">高维不确定数据中的值模糊问题为主要的研究目标,不确定数据的维数是确定的。不确定数据由一组概率样本数据点定义,概率样本数由随机采样生成。针对高维不确定数据集,采用先划分子空间再将不确定数据确定化的方法,减少计算步骤。针对各个子空间中的不确定数据,采用式(2)计算不确定数据的距离,并结合K<i>NN</i>算法的网格划分方法,将不确定数据确定化。在得到确定数据集后由<i>Clique</i>算法对确定数据集聚类。如图1所示, 图中不确定数据没有确定的位置。</p>
                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911029_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 值模糊数据" src="Detail/GetImg?filename=images/JSJY201911029_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 值模糊数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911029_148.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Value fuzzy data</i></p>

                </div>
                <div class="p1">
                    <p id="149">根据<i>Clique</i>算法首先划分子空间并对子空间作网格划分处理。由于本节中不确定数据的维度是确定的,子空间划分与网格划分过程并不会受到不确定数据的影响。</p>
                </div>
                <div class="p1">
                    <p id="150">采用K<i>NN</i>算法在子空间内查找距离不确定数据最近的<i>K</i>个数据,并根据这<i>K</i>个数据的网格归属情况划分不确定数据。不确定数据与确定数据的距离计算由式(2)给出。根据不确定数据到确定数据的距离,可以得到不确定数据对于确定数据所属网格的网格归属度,公式为:</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><mi>r</mi><mi>i</mi><mi>B</mi><mi>l</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∏</mo><mrow><mi>k</mi><mo>∈</mo><mi>g</mi><mi>r</mi><mi>i</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mfrac><mi>r</mi><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>Κ</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">其中:<i>i</i>为不确定数据,<i>s</i>为网格,<i>K</i>为网格内的确定数据,<i>d</i>(<i>i</i>,<i>K</i>)为不确定数据<i>i</i>到确定数据<i>K</i>的距离,<i>r</i>为网格最长边长度。判断一个不确定数据是否属于一个网格的条件有两个:一是,网格中的数据与不确定数据的距离;二是,网格中数据的个数。只有当网格中的数据距离不确定数据足够近而且足够多时,才能判定不确定数据属于这个网格。式(9)根据网格邻近性,以网格边长作为距离比较标准,使不相邻网格的网格归属度小于1。通过Clique算法的密集网格选取过程将稀疏网格排除。在网格密度与网格距离上保证了不确定数据网格划分的准确性。</p>
                </div>
                <div class="p1">
                    <p id="153">通过计算不确定数据与<i>K</i>个最近邻数据所属网格的网格归属度得到不确定数据的网格归属度集合:</p>
                </div>
                <div class="p1">
                    <p id="154"><i>bel</i>(<i>i</i>)={<i>griBl</i>(<i>i</i>,<i>s</i><sub>1</sub>),<i>griBl</i>(<i>i</i>,<i>s</i><sub>2</sub>),…,<i>griBl</i>(<i>i</i>,<i>s</i><sub><i>K</i></sub>)}      (10)</p>
                </div>
                <div class="p1">
                    <p id="156">其中:<i>griBl</i>(<i>i</i>,<i>s</i><sub><i>K</i></sub>)为不确定数据在网格<i>s</i><sub><i>K</i></sub>的网格归属度。根据不确定数据的网格归属度集合,计算Max(<i>griBl</i>(<i>i</i>,<i>s</i><sub><i>K</i></sub>))是否大于1:如果大于1,那么将不确定数据数据划分到这个网格中;如果小于1,那么不确定数据为孤立数据,不作划分。</p>
                </div>
                <div class="p1">
                    <p id="157">采用<i>K</i>NN算法的不确定数据网格划分方法将所有不确定数据划分到相应网格中,生成确定数据集,并采用Clique算法聚类。针对不确定数据采用<i>K</i>NN算法将不确定数据确定化,可以最大限度地避免由不确定数据引起的聚类精度低的问题。根据<i>k</i>个数据的分布情况判断不确定数据的分布,比只根据期望距离判断不确定数据的分布准确性高。Clique算法可以有效地针对确定的高维数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="158">算法3的具体步骤:按照Clique算法选取密集维度生成子空间并在子空间内划分网格。采用<i>K</i>NN算法结合式(9)、(10)计算不确定数据的网格归属,利用网格的邻近性,将不确定数据确定化。当数据集中不存在不确定数据时,采用Clique算法将数据集聚类。</p>
                </div>
                <div class="area_img" id="282">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="171">步骤1)的时间复杂度为<i>O</i>(<i>n</i>),<i>n</i>为数据集中数据个数。步骤2:划分数据集的时间复杂度为<i>O</i>(<i>n</i>)。由文献<citation id="368" type="reference">[<a class="sup">22</a>]</citation>可得,步骤3)<i>K</i>NN的时间复杂度为<i>O</i>(<i>n</i> log <i>n</i>),<i>n</i>为数据集数据总数。假设数据集的维数为<i>k</i>,数据规模为<i>n</i>,存在<i>m</i>个不确定数据。那么步骤3)～6)查找<i>m</i>个不确定数据的<i>K</i>NN时间复杂度为<i>O</i>(<i>mn</i> log <i>n</i>),将不确定数据确定化的时间复杂度为<i>O</i>(<i>k</i>)。由文献<citation id="369" type="reference">[<a class="sup">23</a>]</citation>可得步骤7)Clique算法的时间复杂度为<i>O</i>(<i>ck</i>+<i>kn</i>)。算法3的时间复杂度为<i>O</i>((<i>c</i>+1)<i>k</i>+(<i>k</i>+1)<i>n</i>+<i>mn</i> log <i>n</i>)。</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172">3.2 <b>数据值模糊聚类</b></h4>
                <div class="p1">
                    <p id="173">数据在录入时会产生缺失值,导致数据的确定性下降。传统处理数据缺失值的方法有4种:丢弃缺失值、填补缺失值、预测缺失值和直接分析。针对存在缺失值的高维数据集聚类算法,提出<i>UMVClique</i>算法,采用K<i>NN</i>的方式填补缺失值生成确定数据集,采用<i>Clique</i>算法对确定的数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="174"><b>定义</b>9 数据维度缺失度。存在高维缺失值<i>a</i>,<i>a</i>在<i>n</i>个维度存在空值,那么<i>n</i>就是<i>a</i>的数据维度缺失度,简称缺失度。</p>
                </div>
                <div class="p1">
                    <p id="175">根据定理1可以推出,<i>k</i>-1维确定数据的最近邻也是<i>k</i>维不确定数据的最近邻,可以根据不确定数据在确定维度的<i>K</i>个最近邻,填补不确定数据的缺失值,保障了数据集的完整,避免了聚类精度的丢失。UMVClique算法主要分为3个步骤:首先根据Clique算法生成子空间,其次将子空间内的缺失值填补,最后采用Clique算法对确定数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="176">首先计算不确定数据的缺失度,并将不确定数据按照缺失度从小到大的顺序排列。缺失度高的数据填补难度高,同理缺失度高的数据填补准确度低,先对缺失度低的不确定数据填补,可以在一定程度上保障填补的准确性并缩短填补时间。</p>
                </div>
                <div class="p1">
                    <p id="177">查找距离不确定数据在确定维度的<i>K</i>个最近的数据,<i>m</i>代表密集维度的个数,<i>n</i>代表不确定数据所缺失的维数。由于不确定数据在<i>m</i>-<i>n</i>维中的值是确定的,采用欧氏距离计算在单个维度中两个数据的距离,那么在<i>m</i>-<i>n</i>维中不确定数据与确定数据的距离计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="178" class="code-formula">
                        <mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mi>n</mi></mrow></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><mo>-</mo><mi>n</mi></mrow></munderover><mo stretchy="false">(</mo></mstyle><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="179">其中:<i>u</i><sub><i>i</i></sub>为不确定数据在第<i>i</i>维的值,<i>c</i><sub><i>i</i></sub>为确定数据在第<i>i</i>维的值。</p>
                </div>
                <div class="p1">
                    <p id="180">根据式(11)计算不确定数据在<i>m</i>-<i>n</i>维的<i>K</i>个最近邻数据,并根据这<i>K</i>个数据填补第<i>n</i>维中缺失数据,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="181" class="code-formula">
                        <mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><mo>-</mo><mi>n</mi></mrow></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="182">其中<i>j</i>为不确定数据所在的存在空值的维度,根据式(12)将缺失值填补。</p>
                </div>
                <div class="p1">
                    <p id="183">采用式(11)计算不确定数据在无缺失值的维度的<i>K</i>近邻,并根据式(12)填补不确定数据,生成确定数据集,采用Clique算法将确定数据集聚类,Clique算法可以有效地对高维数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="184">算法4的具体步骤:先将数据集中的缺失部分填补,再将数据集聚类。填补的过程为,先将数据集分为两个部分,一部分为缺失值,另一部分为确定数据。将缺失值按缺失度从小到大的顺序排列,并按顺序将缺失值与确定数据集中的数据比较,将相似度最大的<i>K</i>个确定数据的均值填补到缺失值中,得到确定数据并放入确定数据集中,直到没有缺失值存在时再对数据集聚类。</p>
                </div>
                <div class="area_img" id="283">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="198">由文献<citation id="370" type="reference">[<a class="sup">23</a>]</citation>可得,步骤8)Clique算法的时间复杂度为<i>O</i>(<i>ck</i>+<i>kn</i>),<i>k</i>为数据集维数,<i>n</i>为数据集数据总数,<i>c</i>为簇的个数。由文献<citation id="371" type="reference">[<a class="sup">22</a>]</citation>可得,步骤4)<i>K</i>NN的时间复杂度为<i>O</i>(<i>n</i> log <i>n</i>),<i>n</i>为数据集数据总数。步骤1)的时间复杂度为<i>O</i>(<i>n</i>)。步骤2)～3)的时间复杂度为<i>O</i>(<i>m</i>)。步骤4)～7)计算不确定数据在<i>k</i>-1维的<i>K</i>NN数据的时间复杂度为<i>O</i>(<i>m</i>(<i>k</i>-1)×(<i>n</i>-1) log <i>n</i>)。填补缺失值的时间复杂度为<i>O</i>(<i>km</i>),那么算法4的时间复杂度为<i>O</i>(<i>m</i>((<i>k</i>-1)(<i>n</i>-1) log <i>n</i>+<i>k</i>+2)+<i>ck</i>+(<i>k</i>+1)<i>n</i>)。</p>
                </div>
                <h3 id="199" name="199" class="anchor-tag">4 基于子空间的复杂高维不确定数据聚类算法</h3>
                <div class="p1">
                    <p id="200">在2.1节与2.2节中,针对部分数据维度不确定与数据集维度不确定的情况,分别采用均值和方差与维度相似的方法将不确定数据确定化,并由<i>Clique</i>算法对确定的数据集聚类。在3.1节、3.2节中,针对数据值模糊与缺失值的情况,采用K<i>NN</i>算法将不确定数据确定化,并采用<i>Clique</i>算法对确定数据集聚类。</p>
                </div>
                <div class="p1">
                    <p id="201">针对复杂的高维不确定数据提出<i>UClique</i>算法。算法可以对复杂的高维不确定数据聚类,结合算法1、2、3、4各自的特点对复杂的高维不确定数据聚类。</p>
                </div>
                <div class="p1">
                    <p id="202">针对复杂的高维不确定数据,按照先确定维度后确定数据的方式。高维数据中维度是数据值的载体,先对维度确定化有利于减少计算步骤。在将不确定维度确定化的过程中,首先确定数据集的维度再确定部分数据的维度。高维数据集聚类过程中首先要降维,不确定维度确定化过程可以和降维过程同时进行,有利于减小算法的时间复杂度。高维模糊数据的聚类涉及大量的期望距离计算,对缺失值的聚类过程比对模糊数据的聚类要快,而且填补缺失值是在划分子空间之后在网格化分之前,模糊数据确定化是在网格化分之后。所以在将不确定数据值的确定化过程中,先填补缺失值,后将模糊数据网格化。例如在数据集维度不确定而且存在缺失值时,可以首先采用<i>UDDClique</i>算法得到确定的维度,再采用<i>UMVClique</i>算法将缺失值填补得到确定数据集,最后采用<i>Clique</i>算法将确定数据集聚类。同样在其他的情况混合出现时,可以分别采用相应的解决方法对数据聚类。</p>
                </div>
                <div class="p1">
                    <p id="203">算法5的具体步骤:首先判断数据集是否存在维度不确定,如果有判断是数据集的维度不确定还是部分数据维度不确定。数据集维度不确定,采用算法2; 部分数据不确定采用算法1。如果只是数据不确定,判断是数据模糊还是有空值,如果是数据模糊,采用算法3; 如果是有缺失值,采用算法4。流程如图2所示。</p>
                </div>
                <div class="area_img" id="204">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911029_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 算法5流程" src="Detail/GetImg?filename=images/JSJY201911029_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 算法5流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911029_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Flow chart of algorithm</i> 5</p>

                </div>
                <div class="area_img" id="284">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201911029_28400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="219">假设数据集的维数为<i>s</i>,数据规模为<i>n</i>,存在<i>m</i>个不确定数据。根据UDPClique算法的时间复杂度,那么步骤4)和步骤9)的时间复杂度为<i>O</i>(<i>cs</i>+<i>sn</i>+<i>mn</i>+<i>km</i>)。根据UDDClique算法的时间复杂度,那么步骤2)和步骤9)的时间复杂度为<i>O</i>(<i>k</i>+<i>n</i>+<i>ck</i>+<i>kn</i>)。根据UFVClique算法的时间复杂度,那么步骤8)和步骤9)的时间复杂度为<i>O</i>((<i>c</i>+1)<i>k</i>+(<i>k</i>+1)<i>n</i>+<i>mn</i> log <i>n</i>)。根据UMVClique算法的时间复杂度,那么步骤6)和步骤9)的时间复杂度为<i>O</i>(<i>m</i>((<i>k</i>-1)(<i>n</i>-1) log <i>n</i>+<i>k</i>+2)+<i>ck</i>+(<i>k</i>+1)<i>n</i>)。由于步骤1)、3)、5)、7)为判断条件时间复杂度为<i>O</i>(1)。那么算法5的时间复杂度为:<i>O</i>(<i>m</i>((<i>k</i>-1)(<i>n</i>-1) log <i>n</i>+<i>k</i>+2)+<i>ck</i>+(<i>k</i>+1)<i>n</i>)。</p>
                </div>
                <h3 id="220" name="220" class="anchor-tag">5 实验</h3>
                <div class="p1">
                    <p id="221">为了检验本文算法的准确性和效率,本文的实验环境是2.5 <i>GHz Intel i</i>5 <i>CPU</i>,内存4 <i>GB</i>,操作系统为<i>Window</i>7。实验数据采用的是<i>UCI</i>(<i>University of California</i>-<i>Irvine</i>)数据库中的数据集<i>Iris</i>、<i>Wine</i>、<i>Seed</i>、<i>Zoo</i>。由于<i>UCI</i>数据集是经典的测试机器学习数据集,具有信息完整、数据种类多的特点,适合根据不同的实验类型测试算法的各方面数据。本文主要考察高维数据集测试算法在高维数据中的表现,还被用于生成不同类型的不确定数据集,测试算法针对存在不确定数据的高维数据集中的表现。数据集的类别数与实例数由表1给出。</p>
                </div>
                <div class="area_img" id="222">
                    <p class="img_tit"><b>表</b>1 <b>实验中使用的</b><i>UCI</i><b>数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 1 <i>UCI data sets used in the experiment</i></p>
                    <p class="img_note"></p>
                    <table id="222" border="1"><tr><td><br />数据集序号</td><td>数据集</td><td>类别数</td><td>实例数</td><td>维数</td></tr><tr><td><br />1</td><td><i>Wine</i></td><td>3</td><td>178</td><td>13</td></tr><tr><td><br />2</td><td><i>Iris</i></td><td>3</td><td>150</td><td>4</td></tr><tr><td><br />3</td><td><i>Seed</i></td><td>3</td><td>210</td><td>7</td></tr><tr><td><br />4</td><td><i>Zoo</i></td><td>7</td><td>101</td><td>17</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="223">本文采用不同的方式生成不同的不确定数据集,以对算法进行多方面的测量。由于<i>ENCLUS</i>算法针对不确定数据能够得到良好的聚类结果,<i>FDBSCAN</i>-<i>SMDM</i>(<i>Fast DBSCAN algorithm</i>-<i>SMDM</i>)算法针对高维数据能够得到良好的聚类结果,实验过程中选取文献<citation id="372" type="reference">[<a class="sup">15</a>]</citation>中的<i>ENCLUS</i>算法与文献<citation id="373" type="reference">[<a class="sup">14</a>]</citation>中的<i>FDBSCAN</i>-<i>SMDM</i>算法作为比较算法。分别测量算法在不同的不确定数据集之下聚类精度、<i>CPU</i>时间、算法的伸缩性以及抗噪声能力。每组实验重复10次取均值作为最终的实验结果,并提供方差作为对算法准确鲁棒性的参考。</p>
                </div>
                <div class="p1">
                    <p id="224">表2是<i>UClique</i>算法,<i>FDBSCAN</i>-<i>SMDM</i>算法与<i>ENCLUS</i>算法在<i>UCI</i>数据集上的比较。由实验结果可以看出,<i>ENCLUS</i>算法、<i>FDBSCAN</i>-<i>SMDM</i>算法和<i>UClique</i>算法按照准确率由高到低的顺序依次排列,三个算法准确率差距小,从整体上看三个算法的准确率都很高。而且三个算法的准确率方差较小,算法具有较好的鲁棒性。但是在所用时间上,<i>ENCLUS</i>算法、<i>UClique</i>算法和<i>FDBSCAN</i>-<i>SMDM</i>算法按照所用时间从短到长的顺序排列。<i>UClique</i>算法存在大量将不确定数据确定化步骤,例如针对数据集维度不确定时的维度选择方法等,可以将不确定数据确定化,起到规范数据集的作用。但是在针对少量不确定数据存在的数据集,起到的作用小,效果不明显,大量时间用在不确定数据确定化和距离函数计算上。<i>FDBSCAN</i>-<i>SMDM</i>采用双加权的方式对不确定数据聚类,对高维数据不敏感,面对高维不确定数数据集,所消耗的时间较长而且聚类效果不明显。</p>
                </div>
                <div class="area_img" id="225">
                    <p class="img_tit"><b>表</b>2 <b>实验结果分析</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Tab</i>. 2 <i>Analysis of experimental results</i></p>
                    <p class="img_note"></p>
                    <table id="225" border="1"><tr><td rowspan="2">数据集</td><td colspan="3"><br /><i>ENCLUS</i></td><td rowspan="2"></td><td colspan="3"><br /><i>FDBSCAN</i>-<i>SMDM</i></td><td rowspan="2"></td><td colspan="3"><br /><i>UClique</i></td></tr><tr><td><br />正确率/%</td><td>方差/%</td><td>时间/<i>ms</i></td><td><br />正确率/%</td><td>方差/%</td><td>时间/<i>ms</i></td><td><br />正确率/%</td><td>方差/%</td><td>时间/<i>ms</i></td></tr><tr><td><i>Wine</i></td><td>96.24</td><td>0.17</td><td>148</td><td></td><td>98.27</td><td>0.13</td><td>43</td><td></td><td>97.21</td><td>0.14</td><td>100</td></tr><tr><td><br /><i>Iris</i></td><td>96.83</td><td>0.26</td><td>152</td><td></td><td>98.77</td><td>0.20</td><td>44</td><td></td><td>98.49</td><td>0.21</td><td>103</td></tr><tr><td><br /><i>Seed</i></td><td>96.92</td><td>0.14</td><td>151</td><td></td><td>98.82</td><td>0.12</td><td>43</td><td></td><td>98.60</td><td>0.14</td><td>101</td></tr><tr><td><br /><i>Zoo</i></td><td>97.16</td><td>0.16</td><td>117</td><td></td><td>98.24</td><td>0.22</td><td>119</td><td></td><td>98.59</td><td>0.13</td><td>119</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="226">图3是最近邻个数<i>K</i>的取值对UClique算法精度影响的实验结果,可以看出:在<i>K</i>值取5～15时,精度单调递增;在<i>K</i>取20时,精度下降。由此可以推断出<i>K</i>的最佳取值范围在10～15。</p>
                </div>
                <div class="area_img" id="227">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911029_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 K取值对UClique算法聚类精度的影响" src="Detail/GetImg?filename=images/JSJY201911029_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>K</i>取值对UClique算法聚类精度的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911029_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Influence of <i>K</i> on clustering accuracy of UClique algorithm</p>

                </div>
                <div class="p1">
                    <p id="228">采用4种方式生成4种不同的不确定数据集。不确定数据集1为维度不确定数据集,在确定数据集中任取2个维度<i>a</i>,<i>b</i>。将维度<i>a</i>中的数据任意去掉一半生成新的维度<i>a</i>′,将维度<i>b</i>中的任意一半添加到<i>b</i>中生成新的维度<i>b</i>′,将维度<i>a</i>中的任意一半数据与维度<i>b</i>中的任意一半数据混合生成维度<i>c</i>′,并任取(0,1]中任意数值作为维度存在度映射到数据集的所有维度上。不确定数据集2为部分数据维度不确定数据集,在确定数据集中任取<i>k</i>个数据生成不确定数据。<i>k</i>为数据集维数,任取(0,1]中任意数值作为维度存在度映射到每个不确定数据所存在的维度上。不确定数据集3为数值模糊数据集,在每个维度上任取数据集中2%的数据按照文献<citation id="374" type="reference">[<a class="sup">24</a>]</citation>中不确定数据集生成方法生成数值模糊数据集。不确定数据集4为缺失值数据集,在每个维度上任取1%的数据将其数值定义为缺失值。</p>
                </div>
                <div class="p1">
                    <p id="229">图4(a)是三种算法对4种高维不确定数据集的聚类精度实验结果。数据集1是高维维度不确定数据集,数据集2是高维部分数据维度不确定数据集,数据集3是高维值模糊数据集,数据集4是高维缺失值数据集。从图中可以看出,在数据集1～3中算法聚类精度按照Uclique、FDBSCAN-SMDM和ENCLUS从高到低的顺序排列,而数据集4中稍有不同。4个数据集都是高维不确定数据集,ENCLUS算法适合对高维数据集的聚类,针对不确定数据聚类效果差,而FDBSCAN-SMDM算法适合针对不确定数据集聚类,针对高维数据聚类效果较差。数据集4是缺失值数据集,FDBSCAN-SMDM和ENCLUS算法的聚类效果较差。UClique算法针对这4种数据集可以有效地聚类,在聚类精度上UClique算法最高。</p>
                </div>
                <div class="p1">
                    <p id="230">图4(b)是三个算法在4个不确定数据集上的时间实验,在所用时间上FDBSCAN-SMDM、UClique和ENCLUS按照从多到少的顺序排列。UClique算法中计算期望距离和将不确定数据确定化需要大量的计算,占用了较长时间,而FDBSCAN-SMDM算法中对加权等步骤占用了较长时间,FDBSCAN-SMDM针对高维数据聚类效果较差。</p>
                </div>
                <div class="area_img" id="231">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911029_231.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不确定数据集的聚类结果分析" src="Detail/GetImg?filename=images/JSJY201911029_231.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不确定数据集的聚类结果分析  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911029_231.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Analysis of clustering results of uncertain datasets (accuracy)</p>

                </div>
                <div class="p1">
                    <p id="232">采用仿真数据集来进行接下来的实验,仿真数据集的特点是用户可以通过输入参数来控制数据集的维度、结构、大小和在各个维度上的取值范围等等。分别测试数据规模、噪声、维数对算法精度的影响,实验结果如图5。</p>
                </div>
                <div class="area_img" id="233">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201911029_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 三种算法的聚类结果分析" src="Detail/GetImg?filename=images/JSJY201911029_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 三种算法的聚类结果分析  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201911029_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Analysis of clustering results of three algorithms</p>

                </div>
                <div class="p1">
                    <p id="234">由图5所示,在数据规模不断增加的情况下,三种算法的聚类精度都在不断下降,并逐渐收敛。UClique算法与ENCLUS算法采用子空间聚类的方法,对于大规模数据有一定的免疫能力,FDBSCAN-SMDM算法也对数据规模不敏感,所以在数据规模达到一定程度之后聚类精度会逐渐平稳, 可以得出UClique算法伸缩性良好。</p>
                </div>
                <div class="p1">
                    <p id="235">在数据规模与维数不变的情况下,噪声不断增加,三种算法的精度按UClique、FDBSCAN-SMDM和ENCLUS从大到小的顺序排列。在噪声不断增加的情况下,三种算法精度都有不同程度的下降但是整体下降幅度小,具有较好的稳定性。可以得出UClique算法对噪声有一定的耐受性。</p>
                </div>
                <div class="p1">
                    <p id="236">在数据规模不变的情况下,维数不断增加,三种算法的精度按UClique、FDBSCAN-SMDM和ENCLUS从大到小的顺序排列。在维数不断增加的情况下,三种算法的精度都有不同程度的下降但是整体下降幅度小,聚类精度一直维持在较高的标准。可以得出UClique算法的维数伸缩性良好。</p>
                </div>
                <h3 id="237" name="237" class="anchor-tag">6 结语</h3>
                <div class="p1">
                    <p id="238">针对高维不确定数据中的不同情况分别提出了解决方法:针对高维数据中部分数据维度不确定的情况,提出了<i>UDPClique</i>算法,采用结合均值和方差将不确定数据确定化;针对数据集维度不确定的高维不确定数据提出了<i>UDDClique</i>算法,采用计算维度相似度的方式得到数据集的确定维度;针对值范围模糊的高维不确定数据提出<i>UFVClique</i>算法,采用K<i>NN</i>算法判断不确定数据的所归属的网格;针对含有缺失值高维不确定数据提出了<i>UMVClique</i>算法,采用K<i>NN</i>算法填补缺失值。最终采用<i>Clique</i>算法对确定数据集聚类。最后提出了<i>UClique</i>算法,针对复杂的高维不确定数据聚类。经理论分析与实验验证,本文算法可以很好地对高维不确定数据聚类,算法的伸缩性与抗噪声能力较好。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="285">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Systematic approach to analyze travel time in road-based mass transit systems based on data mining">

                                <b>[1]</b> CRISTÓBAL T,PADRÓN G,QUESADA-ARENCIBIA A,et al.Systematic approach to analyze travel time in road-based mass transit systems based on data mining[J].IEEE Access,2018,6:32861-32873.
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAD89A8D1FDD817A4AA4A6DE94F183E0E&amp;v=MTIyMjdoeGIyK3dLcz1OaWZPZmNMTUZ0aTlwL3RFRXA5N0JIMCt2aEppbXpzTVRndVhwUlpEZUxxWE1McnFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> JEZEWSKI M,CZABANSKI R,LESKI J M.Fuzzy classifier based on clustering with pairs of ε-hyperballs and its application to support fetal state assessment[J].Expert Systems with Applications,2019,118(15):109-126.
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Satisficing data envelopment analysis:a Bayesian approach for peer mining in the banking sector">

                                <b>[3]</b> CHARLES V,TSOLAS I E,GHERMAN T.Satisficing data envelopment analysis:a Bayesian approach for peer mining in the banking sector[J].Annals of Operations Research,2018,269(1/2):81-102.
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Connecting genetics and gene expression data for target prioritisation and drug repositioning">

                                <b>[4]</b> FERRERO E,AGARWAL P.Connecting genetics and gene expression data for target prioritisation and drug repositioning[J].Biodata Mining,2018,11(1):7.
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=K-means properties on six clustering benchmark datasets">

                                <b>[5]</b> FRÄNTI P,SIERANOJA S.K-means properties on six clustering benchmark datasets[J].Applied Intelligence,2018,48(12):4743-4759.
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCW&amp;filename=SJCWADA2318A586C7804E79103A2E0CC287C&amp;v=MTQ0NDljTE1iOVBQcm9jMFllTUpmM3N4enhKbTdUWjhTSHlUcm1jMUNzR1dUYjNzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyK3dLcz1OaWZJZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> TRIPATHI A,PANWAR K.Modified CURE algorithm with enhancement to identify number of clusters[J].International Journal of Artificial Intelligence and Soft Computing,2016,5(3):226-240.
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=UGC:real-time,ultra-robust feature correspondence via unilateral grid-based clustering">

                                <b>[7]</b> ZHENG Z,MA Y,ZHENG H,et al.UGC:real-time,ultra-robust feature correspondence via unilateral grid-based clustering[J].IEEE Access,2018,6:55501-55508.
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES06A4402A463D3DCD73249F355169175A&amp;v=MTI5NTBPR1FsZkJyTFUwNXRwaHhiMit3S3M9TmlmT2ZiTytiOVhJcjQwMFlPME1lSDlOdkdJVTZUMTVRUW5ocVJjMGY3dVZRci91Q09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> SEYEDI S A,LOTFI A,MORADI P,et al.Dynamic graph-based label propagation for density peaks clustering[J].Expert Systems with Applications,2019,115:314-328.
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737729&amp;v=MjQ5NzJZK2dJQzM0d29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXIzSUlWc1ZhaEU9TmlmT2ZiSzdIdEROcVk5Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> YANG M S,LAI C Y.A robust EM clustering algorithm for Gaussian mixture models [J].Pattern Recognition,2012,45(11):3950-3961.
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering of imbalanced high-dimensional media data">

                                <b>[10]</b> BRODINOVÁ Š,ZAHARIEVA M,FILZMOSER P,et al.Clustering of imbalanced high-dimensional media data[J].Advances in Data Analysis &amp; Classification,2017,12(2):261-284.
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint linear regression and nonnegative matrix factorization based on self-organized graph for image clustering and classification">

                                <b>[11]</b> ZHU W,YAN Y.Joint linear regression and nonnegative matrix factorization based on self-organized graph for image clustering and classification[J].IEEE Access,2018,6:38820-38834.
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stability and minimax optimality of tangential delaunay complexes for manifold reconstruction">

                                <b>[12]</b> AAMARI E,LEVRARD C.Stability and minimax optimality of tangential delaunay complexes for manifold reconstruction[J].Discrete &amp; Computational Geometry,2018,59(4):923-971.
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7A9F0EFD3A59DE191D5843FBFB1C5E36&amp;v=MTE5NDNCckxVMDV0cGh4YjIrd0tzPU5pZk9mYlRKRjZmTTJ2a3haNW9LQlFoTXpoOFNuanAxVEh5VTNtUkhlTUdSTUxtWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> WANG Y,DUAN X,LIU X,et al.A spectral clustering method with semantic interpretation based on axiomatic fuzzy set theory[J].Applied Soft Computing,2018,64:59-74.
                            </a>
                        </p>
                        <p id="311">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES24E24497651FD1D31EFFDCEC6D0EECBB&amp;v=MjUzMDBOaWZPZmJHOGE5UElxNFpDWXU0T2VnZzR1eFVTbjBrTFBBeVgzeFJCZWNmaE5zanRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0cGh4YjIrd0tzPQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> LIU H,ZHANG X,ZHANG X,et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems,2017,126:33-47.
                            </a>
                        </p>
                        <p id="313">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A parallel framework for grid-based bottom-up subspace clustering">

                                <b>[15]</b> GOYAL P,KUMARI S,SINGH S,et al.A parallel framework for grid-based bottom-up subspace clustering[C]// Proceedings of the 2016 IEEE International Conference on Data Science and Advanced Analytics.Piscataway:IEEE,2016:331-340.
                            </a>
                        </p>
                        <p id="315">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized latent multi-view subspace clustering">

                                <b>[16]</b> ZHANG C,FU H,HU Q,et al.Generalized latent multi-view subspace clustering[EB/OL].[2018- 03- 20].https://ieeexplore.ieee.org/document/8502831.
                            </a>
                        </p>
                        <p id="317">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA2C357080A8CC5F4AF2794CA21CFF05D&amp;v=MTQyMTJSYi9yQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHBoeGIyK3dLcz1OaWZPZmNLNmJkTEpxSTlOWkpvSGZ3ODh1UkppbkQxNlFYdVIzUkEwQ3NUaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> ZHU Y,TING K M,CARMAN M J .Grouping points by shared subspaces for effective subspace clustering[J].Pattern Recognition,2018,83:230-244.
                            </a>
                        </p>
                        <p id="319">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust subspace clustering by cauchy loss function">

                                <b>[18]</b> LI X,LU Q,DONG Y,et al.Robust subspace clustering by cauchy loss function[J].IEEE Transactions on Neural Networks and Learning Systems,2018,30(7):2067-2078.
                            </a>
                        </p>
                        <p id="321">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF5BC573D4A4EAD939349AC3D5538A102&amp;v=MjMyMjdsUkxxZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRwaHhiMit3S3M9TmlmT2ZjVzliS0xKcUl3eFlKb0xlUTFOeGhVYTZUdDBPUXpoMkJjd2Vycg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> CHEN H,WANG W,FENG X.Structured sparse subspace clustering with grouping-effect-within-cluster[J].Pattern Recognition,2018,10(83):107-118.
                            </a>
                        </p>
                        <p id="323">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201711021&amp;v=MjgyNzNvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5nVXIvTE55ZlRiTEc0SDliTnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 范虹,侯存存,朱艳春,等.烟花算法优化的软子空间MR图像聚类算法[J].软件学报,2017,28(11):3080-3093.(FAN H,HOU C C,ZHU Y C,et al.Soft subspace algorithm for MR image clustering based on fireworks optimization algorithm[J].Journal of Software,2017,28(11):3080-3093.)
                            </a>
                        </p>
                        <p id="325">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201712014&amp;v=MjI0NDNUYkxHNEg5Yk5yWTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1VyL0xOeWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 傅文进,吴小俊.基于l_2范数的加权低秩子空间聚类[J].软件学报,2017,28(12):3347-3357.(FU W J,WU X J.Weighted low rank subspace clustering based on l_2 norm[J].Journal of Software,2017,28(12):3347-3357.)
                            </a>
                        </p>
                        <p id="327">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nearest neighbor classification">

                                <b>[22]</b> SEIDL T.Nearest neighbor classification[M]// Data Mining in Agriculture.Berlin:Springer,2009:83-106.
                            </a>
                        </p>
                        <p id="329">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Introduction to Kernel and Nearest Neighbor Nonparametric Regression">

                                <b>[23]</b> ALTMAN N S.An introduction to kernel and nearest-neighbor nonparametric regression[J].American Statistician,1992,46(3):175-185.
                            </a>
                        </p>
                        <p id="331">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201510011&amp;v=MDY1NTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeW5nVXIvTEx6N0JiYkc0SDlUTnI0OUU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> 肖宇鹏,何云斌,万静,等.基于模糊C-均值的空间不确定数据聚类[J].计算机工程,2015,41(10):47-52.(XIAO Y P,HE Y B,WAN J,et al.Clustering of space uncertain data based on fuzzy C-means[J].Computer Engineering,2015,41(10):47-52.)
                            </a>
                        </p>
                        <p id="333">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200605009&amp;v=MjMyNTlHRnJDVVI3cWZadVpzRnluZ1VyL0xMeXZTZExHNEh0Zk1xbzlGYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 周晓云,孙志挥,张柏礼,等.高维数据流子空间聚类发现及维护算法[J].计算机研究与发展,2006,43(5):834-840.(ZHOU X Y,SUN Z H,ZHANG B L,et al.An efficient discovering and maintenance algorithm of subspace clustering over high dimensional data streams[J].Journal of Computer Research and Development,2006,43(5):834-840.)
                            </a>
                        </p>
                        <p id="335">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDQB201807014&amp;v=MTY5MjBQU25hYkxHNEg5bk1xSTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1VyL0w=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> 孙翌,胡爱.基于多维度关联的机构知识库数据模型的构建与分析[J].现代情报,2018,38(7):95-106.(SUN Y,HU A.Construction and analysis on data model of institutional repository based on multidimensional linked data[J].Journal of Modern Information,2018,38(7):95-106.)
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201911029" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201911029&amp;v=MTY1ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnluZ1VyL0lMejdCZDdHNEg5ak5ybzlIYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dERktQNlNvSG5VV2tqWXgrbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
