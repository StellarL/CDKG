<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138991773541250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJY201903012%26RESULT%3d1%26SIGN%3dC6FGsLxW25ie0dg9mDXQCYMoBjY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJY201903012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903012&amp;v=MDIwNjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3M09MejdCZDdHNEg5ak1ySTlFWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#43" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="1.1 &lt;b&gt;蚁群算法&lt;/b&gt;">1.1 <b>蚁群算法</b></a></li>
                                                <li><a href="#58" data-title="1.2 &lt;b&gt;反向学习策略&lt;/b&gt;">1.2 <b>反向学习策略</b></a></li>
                                                <li><a href="#84" data-title="1.3 &lt;b&gt;自适应惯性权重值&lt;/b&gt;">1.3 <b>自适应惯性权重值</b></a></li>
                                                <li><a href="#88" data-title="1.4 &lt;b&gt;博弈论基础&lt;/b&gt;">1.4 <b>博弈论基础</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="2 基于蚁群算法的多Agent规划方法 ">2 基于蚁群算法的多Agent规划方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="2.1 &lt;b&gt;种群初始化&lt;/b&gt;">2.1 <b>种群初始化</b></a></li>
                                                <li><a href="#109" data-title="2.2 &lt;b&gt;自适应信息素强度值&lt;/b&gt;">2.2 <b>自适应信息素强度值</b></a></li>
                                                <li><a href="#114" data-title="2.3 &lt;b&gt;信息素挥发因子&lt;/b&gt;">2.3 <b>信息素挥发因子</b></a></li>
                                                <li><a href="#117" data-title="2.4 &lt;b&gt;信息素更新规则&lt;/b&gt;">2.4 <b>信息素更新规则</b></a></li>
                                                <li><a href="#125" data-title="2.5 &lt;b&gt;基于改进蚁群算法的多&lt;/b&gt;Agent&lt;b&gt;路径规划算法&lt;/b&gt;">2.5 <b>基于改进蚁群算法的多</b>Agent<b>路径规划算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="3 基于博弈论的多Agent动态避碰方法 ">3 基于博弈论的多Agent动态避碰方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#137" data-title="3.1 &lt;b&gt;多&lt;/b&gt;Agent&lt;b&gt;之间的碰撞检测&lt;/b&gt;">3.1 <b>多</b>Agent<b>之间的碰撞检测</b></a></li>
                                                <li><a href="#147" data-title="3.2 &lt;b&gt;多&lt;/b&gt;Agent&lt;b&gt;动态避障博弈模型&lt;/b&gt;">3.2 <b>多</b>Agent<b>动态避障博弈模型</b></a></li>
                                                <li><a href="#162" data-title="3.3 &lt;b&gt;基于博弈论的多&lt;/b&gt;Agent&lt;b&gt;动态避碰算法&lt;/b&gt;">3.3 <b>基于博弈论的多</b>Agent<b>动态避碰算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#200" data-title="4 实验仿真与分析 ">4 实验仿真与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#202" data-title="4.1 Agent&lt;b&gt;路径规划实验分析&lt;/b&gt;">4.1 Agent<b>路径规划实验分析</b></a></li>
                                                <li><a href="#213" data-title="4.2 &lt;b&gt;多&lt;/b&gt;Agent&lt;b&gt;动态避障分析&lt;/b&gt;">4.2 <b>多</b>Agent<b>动态避障分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#223" data-title="5 结语 ">5 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#204" data-title="图1 路径规划对比 (文献算法和本文算法) ">图1 路径规划对比 (文献算法和本文算法) </a></li>
                                                <li><a href="#205" data-title="图2 迭代次数对比 (文献算法和本文算法) ">图2 迭代次数对比 (文献算法和本文算法) </a></li>
                                                <li><a href="#206" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;性能对比结果 (文献&lt;/b&gt;&lt;b&gt;算法和本文算法&lt;/b&gt;) "><b>表</b>1 <b>性能对比结果 (文献</b><b>算法和本文算法</b>) </a></li>
                                                <li><a href="#209" data-title="图3 路径规划对比 (文献算法和本文算法) ">图3 路径规划对比 (文献算法和本文算法) </a></li>
                                                <li><a href="#210" data-title="图4 迭代次数对比 (文献算法和本文算法) ">图4 迭代次数对比 (文献算法和本文算法) </a></li>
                                                <li><a href="#211" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;性能对比结果 (文献&lt;/b&gt;&lt;b&gt;算法和本文算法&lt;/b&gt;) "><b>表</b>2 <b>性能对比结果 (文献</b><b>算法和本文算法</b>) </a></li>
                                                <li><a href="#215" data-title="图5 本文算法多Agent路径规划">图5 本文算法多Agent路径规划</a></li>
                                                <li><a href="#220" data-title="图6 最短路径迭代次数对比">图6 最短路径迭代次数对比</a></li>
                                                <li><a href="#221" data-title="图7 50次实验平均路径长度对比">图7 50次实验平均路径长度对比</a></li>
                                                <li><a href="#222" data-title="图8 多Agent的Nash均衡收敛曲线对比">图8 多Agent的Nash均衡收敛曲线对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="269">


                                    <a id="bibliography_1" title="BENNET D J, MCINNES C R.Distributed control of multi-robot systems using bifurcating potential fields[J].Robotics and Autonomous Systems, 2010, 58 (3) :256-264." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501998953&amp;v=MTQ2OTNiSzdIdEROcW85RWJlSUhCWGs2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpKS0Y0Y2FCUT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        BENNET D J, MCINNES C R.Distributed control of multi-robot systems using bifurcating potential fields[J].Robotics and Autonomous Systems, 2010, 58 (3) :256-264.
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_2" title="DORIGO M, MANIEZZO V, COLORNI A.Ant system:optimization by a colony of cooperating Agents[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 1996, 26 (1) :29-41." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ant system: optimization by a colony of cooperating agents">
                                        <b>[2]</b>
                                        DORIGO M, MANIEZZO V, COLORNI A.Ant system:optimization by a colony of cooperating Agents[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 1996, 26 (1) :29-41.
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_3" title="KOVACS B, SZAYER G, TAJTI F, et al.A novel potential field method for path planning of mobile robots by adapting animal motion attributes[J].Robotics and Autonomous Systems, 2016, 82 (C) :24-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel potential field method for path planning of mobile robots by adapting animal motion attributes">
                                        <b>[3]</b>
                                        KOVACS B, SZAYER G, TAJTI F, et al.A novel potential field method for path planning of mobile robots by adapting animal motion attributes[J].Robotics and Autonomous Systems, 2016, 82 (C) :24-34.
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_4" title="QIAN W J, ZHOU L F, YANG L, et al.An improved ant colony algorithm of three dimensional path planning[C]//Proceedings of the2017 10th International Symposium on Computational Intelligence and Design.Piscataway, NJ:IEEE, 2017, 1:119-122." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An improved ant colony algorithm of three dimensional path planning">
                                        <b>[4]</b>
                                        QIAN W J, ZHOU L F, YANG L, et al.An improved ant colony algorithm of three dimensional path planning[C]//Proceedings of the2017 10th International Symposium on Computational Intelligence and Design.Piscataway, NJ:IEEE, 2017, 1:119-122.
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_5" title="DARWISH A H, JOUKHADAR A, KASHKASH M.Using the bees algorithm for wheeled mobile robot path planning in an indoor dynamic environment[J].Cogent Engineering, 2018, 5 (1) :1-23." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using the bees algorithm for wheeled mobile robot path planning in an indoor dynamic environment">
                                        <b>[5]</b>
                                        DARWISH A H, JOUKHADAR A, KASHKASH M.Using the bees algorithm for wheeled mobile robot path planning in an indoor dynamic environment[J].Cogent Engineering, 2018, 5 (1) :1-23.
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_6" title="裴振兵, 陈雪波.改进蚁群算法及其在机器人避障中的应用[J].智能系统学报, 2015, 10 (1) :90-96. (PEI Z B, CHEN X B.Improved ant colony algorithm and its application in obstacle avoidance for robot[J].CAAI Transactions on Intelligent Systems, 2015, 10 (1) :90-96.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNXT201501017&amp;v=MjAwNjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNzNPUHlQVGVyRzRIOVRNcm85RVk0UUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        裴振兵, 陈雪波.改进蚁群算法及其在机器人避障中的应用[J].智能系统学报, 2015, 10 (1) :90-96. (PEI Z B, CHEN X B.Improved ant colony algorithm and its application in obstacle avoidance for robot[J].CAAI Transactions on Intelligent Systems, 2015, 10 (1) :90-96.) 
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_7" title="柳长安, 鄢小虎, 刘春阳, 等.基于改进蚁群算法的移动机器人动态路径规划方法[J].电子学报, 2011, 39 (5) :1220-1224. (LIUC A, YAN X H, LIU C Y, et al.Dynamic path planning for mobile robot based on improved ant colony optimization algorithm[J].Acta Electronica Sinica, 2011, 39 (5) :1220-1224.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201105042&amp;v=MTU2OTE0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzczT0lUZlRlN0c0SDlETXFvOUJab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        柳长安, 鄢小虎, 刘春阳, 等.基于改进蚁群算法的移动机器人动态路径规划方法[J].电子学报, 2011, 39 (5) :1220-1224. (LIUC A, YAN X H, LIU C Y, et al.Dynamic path planning for mobile robot based on improved ant colony optimization algorithm[J].Acta Electronica Sinica, 2011, 39 (5) :1220-1224.) 
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_8" title="YUAN Z, YU H, HUANG M.Improved ant colony optimization algorithm for intelligent vehicle path planning[C]//Proceedings of the 2017 International Conference on Industrial Informatics-Computing Technology, Intelligent Technology, Industrial Information Integration.Piscataway, NJ:IEEE, 2017:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved ant colony optimization algorithm for intelligent vehicle path planning">
                                        <b>[8]</b>
                                        YUAN Z, YU H, HUANG M.Improved ant colony optimization algorithm for intelligent vehicle path planning[C]//Proceedings of the 2017 International Conference on Industrial Informatics-Computing Technology, Intelligent Technology, Industrial Information Integration.Piscataway, NJ:IEEE, 2017:1-4.
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_9" title="ZOUARI W, ALAYA I, TAGINA M.A hybrid ant colony algorithm with a local search for the strongly correlated knapsack problem[C]//Proceedings of the 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications.Piscataway, NJ:IEEE, 2017:527-533." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hybrid ant colony algorithm with a local search for the strongly correlated knapsack problem">
                                        <b>[9]</b>
                                        ZOUARI W, ALAYA I, TAGINA M.A hybrid ant colony algorithm with a local search for the strongly correlated knapsack problem[C]//Proceedings of the 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications.Piscataway, NJ:IEEE, 2017:527-533.
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_10" title="屈鸿, 黄利伟, 柯星.动态环境下基于改进蚁群算法的机器人路径规划研究[J].电子科技大学学报, 2015, 44 (2) :260-265. (QU H, HUANG L W, KE X.Research of improved ant colony based robot path planning under dynamic environment[J].Journal of University of Electronic Science and Technology of China, 2015, 44 (2) :260-265.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201502020&amp;v=MTE1MDJDVVI3cWZadVpwRmlEbFc3M09JU2JQZHJHNEg5VE1yWTlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        屈鸿, 黄利伟, 柯星.动态环境下基于改进蚁群算法的机器人路径规划研究[J].电子科技大学学报, 2015, 44 (2) :260-265. (QU H, HUANG L W, KE X.Research of improved ant colony based robot path planning under dynamic environment[J].Journal of University of Electronic Science and Technology of China, 2015, 44 (2) :260-265.) 
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_11" title="MYLVAGANAM T, SASSANO M, ASTOLFI A.A constructive differential game approach to collision avoidance in multi-Agent systems[C]//Proceedings of the 2014 American Control Conference on Portland.Piscataway, NJ:IEEE, 2014:311-316." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A constructive differential game approach to collision avoidance in multi-agent systems">
                                        <b>[11]</b>
                                        MYLVAGANAM T, SASSANO M, ASTOLFI A.A constructive differential game approach to collision avoidance in multi-Agent systems[C]//Proceedings of the 2014 American Control Conference on Portland.Piscataway, NJ:IEEE, 2014:311-316.
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_12" title="MYLVAGANAM T, SASSANO M, ASTOLFI A.A differential game approach to multi-Agent collision avoidance[J].IEEETransactions on Automatic Control, 2017, 62 (8) :4229-4235." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A differential game approach to multi-agent collision avoidance">
                                        <b>[12]</b>
                                        MYLVAGANAM T, SASSANO M, ASTOLFI A.A differential game approach to multi-Agent collision avoidance[J].IEEETransactions on Automatic Control, 2017, 62 (8) :4229-4235.
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_13" title="TIZHOOSH H R.Opposition-based learning:a new scheme for machine intelligence[C]//CIMCA&#39;05:Proceedings of the 2005International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce.Washington, DC:IEEE Computer Society, 2005, 1:695-701." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Opposition-based learning:A new scheme for machine intelligence">
                                        <b>[13]</b>
                                        TIZHOOSH H R.Opposition-based learning:a new scheme for machine intelligence[C]//CIMCA&#39;05:Proceedings of the 2005International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce.Washington, DC:IEEE Computer Society, 2005, 1:695-701.
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_14" title="杜继永, 张凤鸣, 李建文, 等.一种具有初始化功能的自适应惯性权重粒子群算法[J].信息与控制, 2012, 41 (2) :165-169. (DU J Y, ZHANG F M, LI J W, et al.A particle swarm optimization algorithm with initialized adaptive inertia weights[J].Information and Control, 2012, 41 (2) :165-169.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXYK201202006&amp;v=MDU4OTBQTXJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzczT1BUWFNaYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        杜继永, 张凤鸣, 李建文, 等.一种具有初始化功能的自适应惯性权重粒子群算法[J].信息与控制, 2012, 41 (2) :165-169. (DU J Y, ZHANG F M, LI J W, et al.A particle swarm optimization algorithm with initialized adaptive inertia weights[J].Information and Control, 2012, 41 (2) :165-169.) 
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_15" title="施锡全.博弈论[M].上海:上海财经大学出版社, 2000:29-80. (SHI X Q.Game Theory[M].Shanghai:Shanghai University of Finance and Economics Press, 2000:29-80.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810493981999&amp;v=MDkwMTlJS0Z3U1ZWMjdHYnU1SHRYRnJJWk5aZUlHQlJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5pVXJm&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        施锡全.博弈论[M].上海:上海财经大学出版社, 2000:29-80. (SHI X Q.Game Theory[M].Shanghai:Shanghai University of Finance and Economics Press, 2000:29-80.) 
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_16" title="FUDENBERG D, LEVINE D K.The Theory of Learning in Games[M].Cambridge:MIT Press, 1996:177-198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Theory of Learning in Games">
                                        <b>[16]</b>
                                        FUDENBERG D, LEVINE D K.The Theory of Learning in Games[M].Cambridge:MIT Press, 1996:177-198.
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_17" title="丁占文, 蔡超英, 杨宏林, 等.不完全博弈学习过程的虚拟行动规则[J].运筹学学报, 2010, 14 (3) :91-100. (DING Z W, CAI CY, YANG H L, et al.Rule of fictitious play in the learning process with incomplete learning times[J].Operations Research Transactions, 2010, 14 (3) :91-100.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YCXX201003013&amp;v=MzI0ODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3M09QQzdUZHJHNEg5SE1ySTlFWjRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        丁占文, 蔡超英, 杨宏林, 等.不完全博弈学习过程的虚拟行动规则[J].运筹学学报, 2010, 14 (3) :91-100. (DING Z W, CAI CY, YANG H L, et al.Rule of fictitious play in the learning process with incomplete learning times[J].Operations Research Transactions, 2010, 14 (3) :91-100.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-09-29 09:43</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJY" target="_blank">计算机应用</a>
                2019,39(03),681-687 DOI:10.11772/j.issn.1001-9081.2018071601            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于蚁群算法及博弈论的多Agent路径规划算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E5%BB%B6%E6%96%8C&amp;code=07252802&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑延斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%9E%97%E6%9E%97&amp;code=37799172&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王林林</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B8%AD%E9%B9%8F%E9%9B%AA&amp;code=40728558&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">席鹏雪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A8%8A%E6%96%87%E9%91%AB&amp;code=32919212&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">樊文鑫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A9%E6%A2%A6%E4%BA%91&amp;code=40728559&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">韩梦云</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0109057&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南师范大学计算机与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%99%BA%E6%85%A7%E5%95%86%E5%8A%A1%E4%B8%8E%E7%89%A9%E8%81%94%E7%BD%91%E6%8A%80%E6%9C%AF%E6%B2%B3%E5%8D%97%E7%9C%81%E5%B7%A5%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%B2%B3%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智慧商务与物联网技术河南省工程实验室河南师范大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对多Agent路径规划问题, 提出了一个两阶段的路径规划算法。首先, 利用改进的蚁群算法来为每个Agent规划出一条从起始点到目标点, 不与环境中静态障碍物碰撞的最优路径。在蚁群算法的改进中引入反向学习方法来对蚂蚁位置进行初始化分布, 提高了算法的全局搜索能力;利用粒子群算法中的自适应惯性权重因子来调节信息素强度<i>Q</i>值, 使其自适应地变化, 避免陷入局部最优;对信息素挥发因子<i>ρ</i>进行调节, 提高算法的迭代速度。其次, 若多Agent之间存在动态碰撞, 利用博弈论构建多Agent之间的动态避障模型, 并利用虚拟行动法来解决博弈的求解问题及多Nash均衡的选择问题, 确保每个Agent能够快速学习到最优Nash均衡。仿真实验结果表明改进蚁群算法与传统蚁群算法相比在搜索精度与搜索速度上有明显的提高, 与Mylvaganam的多Agent动态避障算法相比, 所提算法减小了路径总长度并提高了收敛速度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9AAgent&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多Agent;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">路径规划;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8D%E5%90%91%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">反向学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蚁群算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%9A%E5%BC%88%E8%AE%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">博弈论;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郑延斌 (1964—) , 男, 河南内乡人, 教授, 博士, CCF会员, 主要研究方向:虚拟现实、多智能体系统、对策论;;
                                </span>
                                <span>
                                    *王林林 (1993—) , 女, 河南周口人, 硕士研究生, 主要研究方向:虚拟现实、多智能体系统;电子邮箱2836368394@qq.com;
                                </span>
                                <span>
                                    席鹏雪 (1993—) , 女, 河南新乡人, 硕士研究生, 主要研究方向:虚拟现实、多智能体系统;;
                                </span>
                                <span>
                                    樊文鑫 (1994—) , 男, 河南郑州人, 硕士研究生, 主要研究方向:虚拟现实、多智能体系统;;
                                </span>
                                <span>
                                    韩梦云 (1993—) , 女, 河南安阳人, 硕士研究生, 主要研究方向:虚拟现实、汉字识别。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-02</p>

                    <p>

                            <b>基金：</b>
                                                        <span>河南省科技攻关项目 (142300410349, 132102210538);</span>
                                <span>河南省软科学项目 (142400411001);</span>
                                <span>河南师范大学青年基金资助项目 (2017QK20);</span>
                    </p>
            </div>
                    <h1><b>Multi-Agent path planning algorithm based on ant colony algorithm and game theory</b></h1>
                    <h2>
                    <span>ZHENG Yanbin</span>
                    <span>WANG Linlin</span>
                    <span>XI Pengxue</span>
                    <span>FAN Wenxin</span>
                    <span>HAN Mengyun</span>
            </h2>
                    <h2>
                    <span>College of Computer and Information Engineering, Henan Normal University</span>
                    <span>Henan Engineering Laboratory of Intellectual Business and Internet of Things Technologies (Henan Normal University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A two-stage path planning algorithm was proposed for multi-Agent path planning. Firstly, an improved ant colony algorithm was used to plan an optimal path for each Agent from the starting point to the target point without colliding with the static obstacles in the environment. The reverse learning method was introduced to an improved ant colony algorithm to initialize the ant positions and increase the global search ability of the algorithm. The adaptive inertia weighted factor in the particle swarm optimization algorithm was used to adjust the pheromone intensity <i>Q</i> value to make it adaptively change to avoid falling into local optimum. The pheromone volatilization factor <i>ρ</i> was adjusted to speed up the iteration of the algorithm. Then, if there were dynamic collisions between multiple Agents, the game theory was used to construct a dynamic obstacle avoidance model between them, and the virtual action method was used to solve the game and select multiple Nash equilibria, making each Agent quickly learn the optimal Nash equilibrium. The simulation results show that the improved ant colony algorithm has a significant improvement in search accuracy and search speed compared with the traditional ant colony algorithm. And compared with Mylvaganam's multi-Agent dynamic obstacle avoidance algorithm, the proposed algorithm reduces the total path length and improves the convergence speed.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-Agent&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-Agent;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=path%20planning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">path planning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reverse%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reverse learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ant%20colony%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ant colony algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=game%20theory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">game theory;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHENG Yanbin, born in 1964, Ph. D. , professor. His research interests include virtual reality, multi-Agent system, game theory.;
                                </span>
                                <span>
                                    WANG Linlin, born in 1993, M. S. candidate. Her research interests include virtual reality, multi-Agent system.;
                                </span>
                                <span>
                                    XI Pengxue, born in 1993, M. S. candidate. Her research interests include virtual reality, multi-Agent system.;
                                </span>
                                <span>
                                    FAN Wenxin, born in 1994, M. S. candidate. His research interests include virtual reality, multi-Agent system.;
                                </span>
                                <span>
                                    HAN Mengyun, born in 1993, M. S. candidate. Her research interests include virtual reality, Chinese character recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-02</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Science and Technology Research Project of Henan Province (142300410349, 132102210538);</span>
                                <span>the Soft Science Project of Henan Province (142400411001);</span>
                                <span>the Youth Fund of Henan Normal University (2017QK20);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="40">多Agent路径规划问题是指在多Agent环境中为每个Agent找出一条从起点到终点的最优无碰路径<citation id="303" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。路径规划问题是MAS (Multi-Agent System, MAS) 研究的核心问题之一, 受到国内外许多研究者的关注。蚁群算法<citation id="304" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>是一种基于仿生学的全局优化启发式正反馈算法, 已成功应用于众多优化问题中, 在路径规划问题中效果尤为显著<citation id="310" type="reference"><link href="273" rel="bibliography" /><link href="275" rel="bibliography" /><link href="277" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。然而蚁群算法应用规划问题中仍然存在收敛速度慢、易陷入局部最优的缺陷, 为此国内外研究者提出了一些改进, 如:裴振兵等<citation id="305" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>通过自适应地调整信息素启发因子及期望启发因子来提高蚁群算法的迭代速度, 提出广义信息素更新规则使算法避免陷入局部最优;柳长安等<citation id="306" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出利用狼群分配原则的方法来对蚁群算法中最差路径上释放的信息素进行删除, 从而提高了找到最短路径的速度;Yuan等<citation id="307" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>通过对启发式函数和路径选择策略进行改进来提高算法的迭代速度;Zouari等<citation id="308" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将2-opt算法引入到蚁群算法中来减少找到最短路径的时间;屈鸿等<citation id="309" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>根据限定信息素强度的上下界, 并使陷入死锁的蚂蚁采取回退策略来解决死锁问题, 从而完成机器人路径规划。</p>
                </div>
                <div class="p1">
                    <p id="41">多Agent环境中, 受资源约束的影响, Agent在运动过程中相互之间可能发生碰撞。上述方法只考虑静态障碍的避碰问题, 不能解决Agent之间的动态碰撞问题。由于在动态避障过程中, 每个Agent的行为决策要受到环境中其他Agent行为决策的影响, 研究者提出了基于博弈论的多Agent控制方法<citation id="311" type="reference"><link href="289" rel="bibliography" /><link href="291" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>, 这些方法以避障为目的, 规划出的路径可以确保不与静态障碍物或其他Agent发生碰撞, 然而难以确保每个Agent的路径最优, 另外当多个Nash平衡存在的情况下, 会出现震荡现象。</p>
                </div>
                <div class="p1">
                    <p id="42">本文提出一种多Agent路径规划方法, 该方法分为两个阶段:第一阶段为静态避障, 利用改进蚁群算法为每个Agent规划出一条无碰最优路径;第二个阶段为动态避障, 是在前面得到最优路径的基础上所作的微调, 用于解决Agent之间的碰撞问题。利用博弈论来构建多Agent动态避障模型, 在求解该模型的过程中, 利用虚拟行动法确保每个Agent都能快速学习到最优Nash均衡解, 从而解决多Agent之间的动态避碰问题。</p>
                </div>
                <h3 id="43" name="43" class="anchor-tag">1 相关知识</h3>
                <h4 class="anchor-tag" id="44" name="44">1.1 <b>蚁群算法</b></h4>
                <h4 class="anchor-tag" id="45" name="45">1.1.1 栅格间转移概率</h4>
                <div class="p1">
                    <p id="46">在蚁群算法中, 蚂蚁<i>s</i>会根据路径上的残留信息素浓度的大小来选择下一步要走的栅格, 在时刻<i>t</i>蚂蚁<i>s</i>从点<i>m</i>转移到<i>n</i>的转移概率公式如下所示:</p>
                </div>
                <div class="area_img" id="267">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJY201903012_26700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="49">其中:<i>J</i><sub><i>s</i></sub> (<i>m</i>) 表示待选路径所组成的集合;路径上的信息素浓度用<i>τ</i><sub><i>mn</i></sub> (<i>t</i>) 表示;<i>η</i><sub><i>mn</i></sub> (<i>t</i>) 表示启发式信息, <i>d</i><sub><i>mn</i></sub>表示从点<i>m</i>到点<i>n</i>之间的欧氏距离;<i>d</i><sub><i>ng</i></sub>表示下一节点到目标点之间的欧氏距离;<i>α</i>表示信息素浓度的启发因子;<i>β</i>为启发因子的期望值。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">1.1.2 信息素更新规则</h4>
                <div class="p1">
                    <p id="51">当迭代完成之后路径上的信息素需要更新, 更新值由历史留下的信息素值与将要留下的信息素值所决定, 更新公式为:</p>
                </div>
                <div class="p1">
                    <p id="52"><i>τ</i><sub><i>mn</i></sub> (<i>t</i>+1) = (1-<i>ρ</i>) <i>τ</i><sub><i>mn</i></sub> (<i>t</i>) +Δ<i>τ</i><sub><i>mn</i></sub> (<i>t</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mtext>Δ</mtext></mstyle><mi>τ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">其中:Δ<i>τ</i><sub><i>mn</i></sub> (<i>t</i>) 为从节点<i>m</i>到节点<i>n</i>的信息素增量值;Δ<i>τ</i><mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup></mrow></math></mathml> (<i>t</i>) 则表示残留信息素值。</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>τ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Q</mi><mo>/</mo><mi>L</mi><msup><mrow></mrow><mi>s</mi></msup><mo>, </mo><mtext> </mtext><mi>s</mi><mtext>从</mtext><mtext>节</mtext><mtext>点</mtext><mi>m</mi><mtext>到</mtext><mtext>节</mtext><mtext>点</mtext><mi>n</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中:<i>Q</i>为常数表示信息素强度值;<i>L</i><sup><i>s</i></sup>表示蚂蚁<i>s</i>搜索到的路径长度。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58">1.2 <b>反向学习策略</b></h4>
                <div class="p1">
                    <p id="59">Tizhoosh<citation id="312" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>在2005年基于相反数或对立点的概念提出了反向学习策略。在随后的发展中, 该方法被应用于解决一些优化问题中。反向坐标定义如下。</p>
                </div>
                <div class="p1">
                    <p id="60"><b>定义</b>1 假设<i>x</i>在一维空间中的坐标是-5, 目标点的坐标为10, 那么<i>x</i>反向点<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml>的坐标点为5, 且点<i>x</i>到目标点的距离为15, 点<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml>到目标点的距离为5。比较可得, 反向点靠近目标点。<i>x</i>的反向坐标<mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml>的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>¯</mo></mover><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo>-</mo><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中:<i>x</i>∈[<i>a</i>, <i>b</i>]是一个初始的一维搜索区间, 且<i>a</i>、<i>b</i>为实数。把上述定义应用到高维空间可表示成定义2。</p>
                </div>
                <div class="p1">
                    <p id="66"><b>定义</b>2 在<i>W</i>维空间中的一个点<i>P</i>可表示为<i>P</i> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>w</i></sub>) , 其中<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>w</i></sub>∈<b>R</b>, 且<i>x</i><sub><i>l</i></sub>∈[<i>a</i><sub><i>l</i></sub>, <i>b</i><sub><i>l</i></sub>], ∀<i>i</i>={1, 2, …, <i>w</i>}。则点<i>P</i>对应的反向点<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml>可表示为<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml> (<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub>1</sub>, <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub>2</sub>, …, <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub><i>w</i></sub>) , 其中<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub><i>l</i></sub>表示为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mi>a</mi><msub><mrow></mrow><mi>l</mi></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>l</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>l</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">应用到优化的过程中, 则反向机制的优化过程如定义3。</p>
                </div>
                <div class="p1">
                    <p id="75"><b>定义</b>3 反向学习可以描述为:假设<i>f</i> (<i>x</i>) 是已知问题的函数方程, <i>W</i>维空间中的点<i>P</i><sub><i>l</i></sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>w</i></sub>) 是函数方程<i>f</i> (<i>x</i>) 一个解, 且<i>x</i><sub><i>l</i></sub>∈[<i>a</i><sub><i>l</i></sub>, <i>b</i><sub><i>l</i></sub>], ∀<i>i</i>={1, 2, …, <i>w</i>}, 则<i>P</i><sub><i>l</i></sub>的反向点为<mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><sub><i>l</i></sub> (<mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub>1</sub>, <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub>2</sub>, …, <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml><sub><i>w</i></sub>) 。计算<i>P</i><sub><i>l</i></sub>和<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><sub><i>l</i></sub>在函数<i>f</i> (<i>x</i>) 中的函数值。如果<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo><mo>&gt;</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, 则用反向点<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><sub><i>l</i></sub>代替<i>P</i><sub><i>l</i></sub>;否则保留<i>P</i><sub><i>l</i></sub>。因此通过不断地计算点<i>P</i><sub><i>l</i></sub>与反向点<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><sub><i>l</i></sub>的<i>f</i> (<i>x</i>) 值选择其中最优值。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">1.3 <b>自适应惯性权重值</b></h4>
                <div class="p1">
                    <p id="85">粒子在寻优过程中, 惯性权重w应该是保持动态变化的。<i>ω</i>取值较大时, 粒子的全局搜索能力较强;反之局部搜索的能力较强。由于粒子在寻优过程中, 会逐渐靠近最优点, 粒子的惯性权重应该随着迭代次数自适应的变化, 因此粒子的自适应惯性权重更新公式<citation id="313" type="reference"><link href="295" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><mo>=</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mfrac><mrow><mi>k</mi><mo stretchy="false"> (</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">其中:<i>ω</i><sub>max</sub>和<i>ω</i><sub>min</sub>分别是粒子惯性权重的最大值和最小值;<i>k</i>为当前迭代次数, <i>K</i><sub>max</sub>为最大迭代次数。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">1.4 <b>博弈论基础</b></h4>
                <div class="p1">
                    <p id="89">博弈论是研究相互影响、相互依存局中人理性行为的数学工具, 是研究理性局中人如何交互的方法<citation id="314" type="reference"><link href="297" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。由于局中人的相互依存性, 博弈中的决策必须建立在对其他局中人决策的预测之上。</p>
                </div>
                <div class="p1">
                    <p id="90"><b>定义</b>4 非合作博弈是一个三元组。</p>
                </div>
                <div class="p1">
                    <p id="91"><i>G</i>=〈<i>N</i>, <i>A</i><sub><i>i</i></sub>, <i>U</i><sub><i>i</i></sub>〉, <i>i</i>∈<i>N</i>, <i>N</i>={1, 2, …, <i>n</i>}为局中人的集合, <i>A</i><sub><i>i</i></sub>为局中人<i>i</i>的行为集合, <i>U</i><sub><i>i</i></sub>为局中人的效用函数。<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mo>=</mo><mrow><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>A</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow></math></mathml>为所有局中人的联合行动。为方便起见, 局中人的联合行为:∀<i>a</i>∈<i>A</i>, <i>a</i>= (<i>a</i><sub><i>i</i></sub>, <i>a</i><sub>-<i>i</i></sub>) , <i>a</i><sub>-<i>i</i></sub>={<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, …, <i>a</i><sub><i>i</i>-1</sub>, <i>a</i><sub><i>i</i>+1</sub>, …, <i>a</i><sub>-<i>i</i></sub>}。</p>
                </div>
                <div class="p1">
                    <p id="93"><b>定义</b>5 设<i>G</i>=〈<i>N</i>, <i>A</i><sub><i>i</i></sub>, <i>U</i><sub><i>i</i></sub>〉, <i>i</i>∈<i>N</i>, 如果存在一个联合行为<i>a</i><sup>*</sup>∈<i>A</i>, 满足条件:</p>
                </div>
                <div class="p1">
                    <p id="94">∀<i>i</i>∈<i>N</i>, ∀<i>a</i>′<sub><i>i</i></sub>∈<i>ACT</i>, <i>U</i> (<i>a</i><sup>*</sup><sub><i>i</i></sub>, <i>a</i><sup>*</sup><sub><i>i</i>-1</sub>) ≥<i>U</i> (<i>a</i>′<sub><i>i</i></sub>, <i>a</i>′<sub><i>i</i>-1</sub>) </p>
                </div>
                <div class="p1">
                    <p id="95">则称<i>a</i><sup>*</sup>为博弈<i>G</i>的Nash均衡。</p>
                </div>
                <div class="p1">
                    <p id="96">Nash均衡是对博弈结局的一致性预测, 如果所有局中人都预测某特定的Nash均衡会出现, 则该Nash平衡就会出现, 不会因为某个局中人认为不符合自己的利益而失败。达到Nash均衡后, 任何局中人都不存在单方面提高自身的效用而降低其他局中人效用的动机, 故Nash均衡是博弈的稳定解。</p>
                </div>
                <h3 id="97" name="97" class="anchor-tag">2 基于蚁群算法的多Agent规划方法</h3>
                <div class="p1">
                    <p id="98">当每个Agent的起点和目标点确定后, 就可以为每个Agent规划出一条不与环境中静态障碍物碰撞的路径。研究发现在路径寻优和自组织性方面蚁群算法存在很大的优势, 然而传统蚁群算法存在易陷入局部最优及迭代速度慢的缺陷<citation id="315" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 为此本文对传统蚁群算法作如下改进。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">2.1 <b>种群初始化</b></h4>
                <div class="p1">
                    <p id="100">蚂蚁在解问题空间中找到最短路径的时间与蚂蚁初始化时在解空间中的分布存在正比关系, 距离最佳位置近的蚂蚁找到最短路径的时间比距离最佳位置远的蚂蚁要短。</p>
                </div>
                <div class="p1">
                    <p id="101">因此为了快速找到最短路径, 在蚁群算法中引入反向学习策略对蚂蚁进行位置初始化, 通过与当前种群与反向种群的位置进行对比找出较优的种群。</p>
                </div>
                <div class="p1">
                    <p id="102">基于反向学习算法的种群位置初始化过程表述如下:</p>
                </div>
                <div class="p1">
                    <p id="103">1) 随机初始化种群:</p>
                </div>
                <div class="p1">
                    <p id="104"><i>M</i><sub><i>a</i></sub> (<i>t</i>=0) ={<i>x</i><sub><i>mn</i></sub>}; <i>m</i>=1, 2, …, <i>M</i>, <i>n</i>=1, 2      (8) </p>
                </div>
                <div class="p1">
                    <p id="105">2) 计算反向种群:</p>
                </div>
                <div class="p1">
                    <p id="106"><i>M</i><sub><i>a</i></sub>′ (<i>t</i>=0) ={ <i>x</i><sub><i>mn</i></sub>′}, <i>x</i><sub><i>mn</i></sub>′=<i>x</i><sub>min, <i>n</i></sub> + <i>x</i><sub>max, <i>n</i></sub>-<i>x</i><sub><i>mn</i></sub>      (9) </p>
                </div>
                <div class="p1">
                    <p id="107">其中:<i>x</i><sub>min, <i>n</i></sub>和<i>x</i><sub>max, <i>n</i></sub>分别表示种群<i>x</i><sub><i>m</i></sub>的最小值和最大值。</p>
                </div>
                <div class="p1">
                    <p id="108">3) 从组合种群{ <i>M</i><sub><i>a</i></sub> (<i>t</i> = 0) ∪<i>M</i><sub><i>a</i></sub>′ (<i>t</i> = 0) } 中选择<i>M</i>个适应度值较好的蚂蚁位置作为初始种群, 从而使蚂蚁能够增强全局搜索的能力。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">2.2 <b>自适应信息素强度值</b></h4>
                <div class="p1">
                    <p id="110">信息素强度<i>Q</i>为蚂蚁循环一周时在路径上所释放的信息总量, <i>Q</i>值越大, 表示蚁群算法的收敛速度越快;但是一旦<i>Q</i>值过大时, 蚂蚁会过多地集中于一条路径上从而导致算法的全局搜索能力变差, 极易陷入局部最优。因此为了调整好二者之间的关系, 本文引入粒子群算法中自适应惯性权重值来调节<i>Q</i>值的大小使其能够在搜索的过程中自适应的变化, 从而兼顾好全局与局部搜索的关系。具体公式如下:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mo stretchy="false"> (</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mfrac><mrow><mi>k</mi><mo stretchy="false"> (</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>ω</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow></mfrac><mo stretchy="false">) </mo><mo>⋅</mo><mi>Q</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">其中, <i>ω</i><sub>max</sub>和<i>ω</i><sub>min</sub>分别是粒子惯性权重的最大值和最小值;<i>k</i>为当前迭代次数, <i>K</i><sub>max</sub>为最大迭代次数。</p>
                </div>
                <div class="p1">
                    <p id="113">引入粒子群算法中的自适应惯性权重值的方法来调节信息素强度值可以使信息素强度值自适应地变化, 避免蚂蚁陷入局部最优。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114">2.3 <b>信息素挥发因子</b></h4>
                <div class="p1">
                    <p id="115">信息素挥发因子<i>ρ</i>的大小也是影响路径信息素量大小的因素, 从而影响蚁群算法的全局搜索能力和收敛速度。在传统的蚁群算法中挥发因子<i>ρ</i>是 (0, 1) 上的一个常数, 如果给定的<i>ρ</i>值过大, 表明路径上的信息素量减少, 从而导致算法收敛速度降低;若给定的<i>ρ</i>过小, 路径上的信息素量会增大, 导致算法快速收敛, 虽然节约了算法的搜索时间, 但可能导致算法陷入局部最优解。因此本文利用式 (11) 对挥发因子<i>ρ</i>作如下改进, 使挥发因子<i>ρ</i>随着迭代次数的改变而自适应地变化, 具体公式如下:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mfrac><mrow><mi>k</mi><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow></mfrac></mrow></msup><mo stretchy="false">) </mo><mi>ρ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="117" name="117">2.4 <b>信息素更新规则</b></h4>
                <div class="p1">
                    <p id="118">当迭代完成之后路径上的信息素需要更新, 更新值由历史留下的信息素值与将要留下的信息素值所决定, 更新公式为:</p>
                </div>
                <div class="p1">
                    <p id="119"><i>τ</i><sub><i>mn</i></sub> (<i>t</i>+1) = (1-<i>ρ</i><sup>*</sup>) <i>τ</i><sub><i>mn</i></sub> (<i>t</i>) +Δ<i>τ</i><sub><i>mn</i></sub> (<i>t</i>)      (12) </p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mtext>Δ</mtext></mstyle><msup><mrow></mrow><mo>*</mo></msup><mi>τ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">其中:Δ<i>τ</i><sub><i>mn</i></sub> (<i>t</i>) 为从节点<i>m</i>到节点<i>n</i>的信息素增量值;Δ<sup>*</sup><i>τ</i><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup></mrow></math></mathml> (<i>t</i>) 则表示残留信息素值。</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><msup><mrow></mrow><mo>*</mo></msup><mi>τ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mi>s</mi></msubsup><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Q</mi><msup><mrow></mrow><mo>*</mo></msup><mo>/</mo><mi>L</mi><msup><mrow></mrow><mi>s</mi></msup><mo>, </mo><mtext> </mtext><mi>s</mi><mtext>从</mtext><mtext>节</mtext><mtext>点</mtext><mi>m</mi><mtext>到</mtext><mtext>节</mtext><mtext>点</mtext><mi>n</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">其中<i>Q</i><sup>*</sup>为表示信息素强度值。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">2.5 <b>基于改进蚁群算法的多</b>Agent<b>路径规划算法</b></h4>
                <div class="p1">
                    <p id="126">通过以上分析, 引入反向学习策略可以增强算法的全局搜索能力, 利用粒子群算法惯性权重值调节信息素强度<i>Q</i>值可避免蚂蚁陷入局部最优, 对挥发因子进行调节提高了算法的迭代速度。改进后的蚁群算法流程如下:</p>
                </div>
                <div class="p1">
                    <p id="127">步骤1 初始化蚁群算法中的参数, 蚂蚁数量<i>M</i>、最大循环次数<i>K</i><sub>max</sub>、启发因子∂、期望值<i>β</i>。</p>
                </div>
                <div class="p1">
                    <p id="128">步骤2 利用反向学习方法即式 (8) 、 (9) 对蚂蚁的位置初始化。</p>
                </div>
                <div class="p1">
                    <p id="129">步骤3 启动蚁群, 蚂蚁根据状态转移规则选择下一个要途经的栅格, 若该栅格移动至相邻栅格路径上的信息素值为0, 则返回到上一个搜索的栅格, 并将其设置为障碍栅格。</p>
                </div>
                <div class="p1">
                    <p id="130">步骤4 重复步骤2, 直到所有的蚂蚁都完成路径的搜索。</p>
                </div>
                <div class="p1">
                    <p id="131">步骤5 计算并记录下各蚂蚁的路径长度<i>L</i><sup><i>s</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="132">步骤6 依据式 (12) 、 (13) 、 (14) 进行信息素的全局更新。</p>
                </div>
                <div class="p1">
                    <p id="133">步骤7 若蚁群全部收敛到一条路径或达到最大循环次数<i>K</i><sub>max</sub>, 则循环结束;否则转步骤2。</p>
                </div>
                <div class="p1">
                    <p id="134">步骤8 输出全局最优路径, 算法结束。</p>
                </div>
                <h3 id="135" name="135" class="anchor-tag">3 基于博弈论的多Agent动态避碰方法</h3>
                <div class="p1">
                    <p id="136">利用改进的蚁群算法可以为每个Agent规划出一条与环境中静态障碍物之间无碰撞的最优路径。然而多Agent环境中, 受资源的约束, Agent在运动过程中会相互发生碰撞, 即动态碰撞的问题。由于每个Agent都是按照规划的路径前进, 为了避免碰撞, 每个Agent需要从行为集合{不变, 改变运动方向, 改变运动速度, 等待}中选择一种行为来执行。碰撞发生在多个Agent之间, 因此Agent的行为决策要受到环境中其他Agent的行为决策的影响, 博弈论为这种相互影响的决策问题提供了很好的数学模型。本文利用博弈论来构建多Agent动态避障模型, 把多Agent之间的避碰问题转换为求解该博弈模型的Nash均衡解问题, 并利用虚拟行动法来确保每个Agent能够快速学习到最优Nash均衡解。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">3.1 <b>多</b>Agent<b>之间的碰撞检测</b></h4>
                <div class="p1">
                    <p id="138">多Agent集合记为<i>Ag</i> (<i>Ag</i>= (1, 2, …, <i>m</i>) ) , <i>Agent</i><sub><i>i</i></sub> (<i>i</i>∈<i>Ag</i>) 表示第<i>i</i>个Agent, 设Agent的感知距离为<i>Ls</i>。</p>
                </div>
                <div class="p1">
                    <p id="139"><b>定义</b>6 ∀<i>i</i>∈<i>Ag</i>, <i>Agent</i><sub><i>i</i></sub>的邻居集合表示为<i>B</i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="140"><i>B</i><sub><i>i</i></sub>={<i>j</i>|<i>j</i>∈<i>Ag</i>, ‖<i>P</i><sub><i>i</i></sub>-<i>P</i><sub><i>j</i></sub>‖≤<i>Ls</i>}      (15) </p>
                </div>
                <div class="p1">
                    <p id="141">其中<i>P</i><sub><i>i</i></sub>, <i>P</i><sub><i>j</i></sub>为<i>Agent</i><sub><i>i</i></sub>和<i>Agent</i><sub><i>j</i></sub>当前所处的位置, ‖·‖表示两点之间的欧氏距离。</p>
                </div>
                <div class="p1">
                    <p id="142">由于只有邻居中的Agent才有可能发生碰撞, 因此为了便于计算, 假设每个Agent都能获取其邻居集合中的Agent的速度信息<i>v</i> (包含大小和方向) 等, Agent的半径为<i>r</i>。</p>
                </div>
                <div class="p1">
                    <p id="143"><b>定义</b>7 <i>Agent</i><sub><i>i</i></sub>的可能障碍区<i>POS</i><sub><i>i</i></sub> (Possible Of Square) 是一个长方形区域, 其宽是<i>Agent</i><sub><i>i</i></sub>的直径2<i>r</i>, 长是当前<i>Agent</i><sub><i>i</i></sub>的速度值与仿真间隔<i>T</i>的乘积。当Agent的运动速度为0时, 该区域就是<i>Agent</i><sub><i>i</i></sub>自身的包围盒。</p>
                </div>
                <div class="p1">
                    <p id="144"><b>定义</b>8 <i>Agent</i><sub><i>i</i></sub>的可能障碍集<i>POA</i><sub><i>i</i></sub> (Possible Of Agent) 为:</p>
                </div>
                <div class="p1">
                    <p id="145"><i>POA</i><sub><i>i</i></sub>={<i>j</i>|<i>j</i>∈<i>B</i><sub><i>i</i></sub>∧ (<i>POS</i><sub><i>i</i></sub>∩<i>POS</i><sub><i>j</i></sub>≠∅) ∧ (<i>j</i>≠<i>i</i>) }      (16) </p>
                </div>
                <div class="p1">
                    <p id="146">其中, ∅表示空集合。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147">3.2 <b>多</b>Agent<b>动态避障博弈模型</b></h4>
                <div class="p1">
                    <p id="148"><b>定义</b>9 由于只有邻居中的Agent才可能发生碰撞, 因此局中人集合<i>N</i>定义为:</p>
                </div>
                <div class="p1">
                    <p id="149" class="code-formula">
                        <mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>B</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="150"><b>定义</b>10 局中人<i>Agent</i><sub><i>i</i></sub>能够选择的行动的集合称为行动集合<i>A</i> (每个Agent的行动集合相同) , 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="151"><i>A</i>={NC, ST, CV, CD}      (18) </p>
                </div>
                <div class="p1">
                    <p id="152">NC (No Change) 表示Agent不作变化继续按照原始路径行走;ST (Stop) 表示Agent停止等待;CV (Change Velocity) 表示Agent速度产生加速减速变化;CD (Change Direction) 表示Agent转变方向行走。</p>
                </div>
                <div class="p1">
                    <p id="153">设避障成功, 每个Agent得到的奖赏为<i>R</i><sub>1</sub>, 避障过程中Agent选择不同行为的消耗为<i>XH</i> (<i>a</i><sub><i>i</i></sub>) , <i>a</i><sub><i>i</i></sub>∈<i>ACT</i>, 不同的行为消耗是不同的, 且<i>XH</i> (<i>NC</i>) =0。</p>
                </div>
                <div class="p1">
                    <p id="154"><b>定义</b>11 在联合行为<i>a</i>下, 局中人<i>i</i>的收益定义如下:</p>
                </div>
                <div class="p1">
                    <p id="155" class="code-formula">
                        <mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mfrac><mrow><mi>L</mi><mi>L</mi></mrow><mrow><mi>Μ</mi><mi>Ι</mi><mi>Ν</mi><mi>L</mi></mrow></mfrac><mo>-</mo><mi>X</mi><mi>Η</mi><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="156">其中:<i>LL</i>为运动过程中两个Agent之间的安全距离, <mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>Ι</mi><mi>Ν</mi><mi>L</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>j</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><mo stretchy="false">) </mo></mrow></math></mathml>是<i>Agent</i><sub><i>i</i></sub>与其感知区域中所有Agent之间距离的最小值, 当某个成员距离小于<i>LL</i>时, 该最小值定义为0。</p>
                </div>
                <div class="p1">
                    <p id="158"><b>定义</b>12 多Agent避碰博弈为<i>G</i>= (<i>N</i>, <i>A</i>, <i>U</i>) , 其中<i>N</i>表示局中人的集合, <i>A</i>是博弈过程Agent的行为集合, <i>U</i>是效用函数。</p>
                </div>
                <div class="p1">
                    <p id="159">在避障过程中, 如果Agent的行为选择为改变方向或改变速度, 则当避障结束后, 需要把方向和速度还原, 不仅有一定的消耗, 而且还需要一定的距离才能完成, 因此设<i>FL</i>为Agent完成变化和还原需要的最短距离, 当Agent和其目标点的距离小于<i>FL</i>时, 就不能选择CV和CD行为。为此为Agent定义了优先级, 表示Agent行为选择的优先级。</p>
                </div>
                <div class="p1">
                    <p id="160"><b>定义</b>13 成员的优先级。设<i>FL</i>为可以进行运动变化的最小距离, ∀<i>i</i>∈<i>N</i>, 如果‖<i>P</i><sub><i>i</i></sub>-<i>P</i><sub><i>g</i></sub>‖≤<i>FL</i>, 则<i>Agent</i><sub><i>i</i></sub>的优先级为1, 否则为0。其中<i>P</i><sub><i>g</i></sub>表示<i>Agent</i><sub><i>i</i></sub>的目标点的位置。</p>
                </div>
                <div class="p1">
                    <p id="161"><b>定义</b>14 设<i>NE</i>是博弈<i>G</i>中所有Nash均衡策略的集合, 如:∃<i>s</i><sup>*</sup>∈<i>NE</i>, 对∀<i>s</i>′∈<i>NE</i>-{<i>s</i><sup>*</sup>}, 都有<i>U</i> (<i>s</i><sup>*</sup>) ≥<i>U</i> (<i>s</i>′) 且至少存在一个<i>j</i>∈<i>N</i>, 使得<i>U</i> (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i><sup>*</sup><sub>-<i>j</i></sub>) &gt;<i>U</i> (<i>s</i>′) , 则称<i>s</i><sup>*</sup>为最优Nash均衡。</p>
                </div>
                <h4 class="anchor-tag" id="162" name="162">3.3 <b>基于博弈论的多</b>Agent<b>动态避碰算法</b></h4>
                <div class="p1">
                    <p id="163">由于多Agent之间的动态避障问题可以描述为一个博弈模型G, 由Nash定理知, 博弈G至少存一个Nash均衡解 (定义5) 。然而Nash定理只指出均衡的存在性, 如何求得均衡解是一个比较复杂的问题。另外当博弈G中存在多个均衡时, 如何确保博弈中每个Agent选择相同的均衡就尤为重要 (即均衡的选择问题) 。博弈学习中的虚拟行动方法<citation id="316" type="reference"><link href="299" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>为博弈求解及均衡选择问题提供很好的解决方案, 算法1给出了详细的描述。其中<i>q</i><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>a</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msubsup></mrow></math></mathml> (<i>t</i>) ) 表示<i>t</i>时刻局中人<i>i</i>选择行为集合中某个行为<i>a</i><sub><i>j</i></sub>的概率。</p>
                </div>
                <div class="p1">
                    <p id="165">算法1 基于虚拟行动的Agent行为选择算法。</p>
                </div>
                <div class="area_img" id="268">
                                <img alt="" src="Detail/GetImg?filename=images/JSJY201903012_26800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="182">在重复博弈的过程中, 每个局中人都知道其他参与人是在根据一个固定的混合策略分布<i>q</i><sub>-<i>i</i></sub> (<i>t</i>) 来选取他们的行为组合, 虽然该混合策略分布是不知道的, 他可以从行为历史中学习到其他参与人的混合策略分布<i>q</i><sub>-<i>i</i></sub> (<i>t</i>) 如式 (20) 、 (21) 。参与人<i>i</i>在学习时刻<i>t</i>实际行为选择是他在时刻<i>t</i>关于其他参与人行为策略的后验信念的最优反应如式 (23) 。故如果博弈G存在多个Nash均衡的话, 算法1确保收敛到最优Nash均衡 (详见文献<citation id="317" type="reference">[<a class="sup">16</a>,<a class="sup">17</a>]</citation>) 。由于Nash均衡是多Agent的稳定解, 一旦达到均衡, 每个Agent都没有偏离该均衡解而去追求更高效用的意图, 另外由式 (19) 知道, 达到均衡后, Agent相互之间的距离都不会小于安全距离<i>LL</i>, 故解决了多Agent之间的动态避障问题。</p>
                </div>
                <div class="p1">
                    <p id="183"><b>定理</b>1 如果避障博弈G存在最优Nash均衡解, 则算法1学习得到的均衡解一定是该最优Nash均衡解。</p>
                </div>
                <div class="p1">
                    <p id="184">证明 (反证法) 设<i>s</i>″为由算法1学习得到的Nash均衡, 设<i>s</i><sup>*</sup>为避障博弈G的最优Nash均衡, 且<i>s</i>″≠<i>s</i><sup>*</sup>。</p>
                </div>
                <div class="p1">
                    <p id="185">由定义14知, 对最优Nash均衡<i>s</i><sup>*</sup>:</p>
                </div>
                <div class="p1">
                    <p id="186">若∀<i>j</i>∈<i>N</i>, 都有<i>U</i> (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i><sup>*</sup><sub>-<i>j</i></sub>) &gt;<i>U</i> (<i>s</i>′) , 则参与博弈的所有Agent都会选择策略<i>s</i><sup>*</sup>, 故由算法1学习得到的均衡就是<i>s</i><sup>*</sup>, 故<i>s</i>″=<i>s</i><sup>*</sup>, 与假设矛盾。</p>
                </div>
                <div class="p1">
                    <p id="187">若只存在一个<i>j</i>∈<i>N</i>, 满足<i>U</i> (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i><sup>*</sup><sub>-<i>j</i></sub>) &gt;<i>U</i> (<i>s</i>′) 。由式 (23) 知, 在其他Agent效用不变的情况下, <i>Agent</i><sub><i>j</i></sub>的最优响应应该是<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>U</i> (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i><sup>*</sup><sub>-<i>j</i></sub>) =<i>U</i> (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i>′<sub>-<i>j</i></sub>) , 故算法1学习得到策略<i>s</i>″= (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i>′<sub>-<i>j</i></sub>) = (<i>s</i><sup>*</sup><sub><i>j</i></sub>, <i>s</i><sup>*</sup><sub>-<i>j</i></sub>) =<i>s</i><sup>*</sup>, 与假设矛盾。</p>
                </div>
                <div class="p1">
                    <p id="188">其他情况证明相似。 证毕。</p>
                </div>
                <div class="p1">
                    <p id="189">算法2 基于博弈论的多Agent避障算法。</p>
                </div>
                <div class="p1">
                    <p id="190">步骤1 在仿真时间<i>t</i>内, 每个Agent根据式 (15) 计算邻居集合:</p>
                </div>
                <div class="p1">
                    <p id="191">步骤2 利用式 (17) 计算局中人集合<i>N</i>, 如果∃<i>i</i>∈<i>N</i>, 满足 (<i>v</i><sub><i>i</i></sub>=0 or <i>B</i><sub><i>i</i></sub>=∅) 则<i>N</i>=<i>N</i>-<i>i</i>;</p>
                </div>
                <div class="p1">
                    <p id="192">步骤3 每个Agent根据定义7计算其可能障碍区POS;</p>
                </div>
                <div class="p1">
                    <p id="193">步骤4 每个Agent根据式 (16) 计算可能障碍集POA, 如果某个<i>Agent</i><sub><i>i</i></sub>, <i>POA</i><sub><i>i</i></sub>=∅, 则<i>N</i>=<i>N</i>-<i>i</i>;</p>
                </div>
                <div class="p1">
                    <p id="194">步骤5 根据定义13计算每个Agent的动作选择优先级;</p>
                </div>
                <div class="p1">
                    <p id="195">步骤6 利用算法1得到Nash均衡解;</p>
                </div>
                <div class="p1">
                    <p id="196">步骤7 执行选择行为;</p>
                </div>
                <div class="p1">
                    <p id="197">步骤8 如果Agent<sub>i</sub>达到目标点, 则速度变为0;</p>
                </div>
                <div class="p1">
                    <p id="198">步骤9 对每个Agent如果<i>a</i><sub><i>i</i></sub>≠<i>NC</i>, 则执行相应的还原行为 (即把速度或方向还原成避障前的值) ;</p>
                </div>
                <div class="p1">
                    <p id="199">步骤10 算法结束。</p>
                </div>
                <h3 id="200" name="200" class="anchor-tag">4 实验仿真与分析</h3>
                <div class="p1">
                    <p id="201">分两阶段来验证本文所提出的算法的有效性。首先是对第一阶段, 每个Agent的无静态碰撞的最优路径的验证 (4.1节) ;对多Agent之间的动态避障问题, 第3章给出了理论说明, 利用算法1和算法2能够得到最优的Nash均衡, 解决Agent之间的动态碰撞问题。本章利用5个Agent之间的动态避障问题来验证算法的有效性 (4.2节) 。</p>
                </div>
                <h4 class="anchor-tag" id="202" name="202">4.1 Agent<b>路径规划实验分析</b></h4>
                <div class="p1">
                    <p id="203">为了验证本文算法的适用性分别在不同的环境下对本文算法进行实验验证, 首先利用本文算法与文献<citation id="318" type="reference">[<a class="sup">2</a>]</citation>及文献<citation id="319" type="reference">[<a class="sup">10</a>]</citation>算法在20×20的栅格环境中对单个Agent的路径进行实验对比, 使用文献<citation id="320" type="reference">[<a class="sup">10</a>]</citation>中同样的参数:迭代次数<i>K</i><sub>max</sub>=200, 期望值<i>β</i>=5.0, 蚂蚁数量<i>M</i>=50, 启发因子<i>α</i>=1.5, 惯性权重的最大最小取值为:<i>ω</i><sub>max</sub>=0.9, <i>ω</i><sub>min</sub>=0.4, 但是本文算法中信息素强度值<i>Q</i>及信息素蒸发因子<i>ρ</i>是自适应变化的, 经过实验验证可以得到如图1所示多Agent的路径规划图以及图2所示的三种算法的迭代次数图, 经过100次实验取得平均值得到表1所示对比结果。</p>
                </div>
                <div class="area_img" id="204">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 路径规划对比 (文献[2, 10]算法和本文算法)" src="Detail/GetImg?filename=images/JSJY201903012_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 路径规划对比 (文献<citation id="321" type="reference">[<a class="sup">2</a>,<a class="sup">10</a>]</citation>算法和本文算法)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_204.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Comparison of path planning (literature <citation id="322" type="reference"><link href="271" rel="bibliography" /><link href="287" rel="bibliography" />[2, 10]</citation> algorithms and the proposed algorithm) </p>

                </div>
                <div class="area_img" id="205">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_205.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 迭代次数对比 (文献[2, 10]算法和本文算法)" src="Detail/GetImg?filename=images/JSJY201903012_205.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 迭代次数对比 (文献<citation id="323" type="reference">[<a class="sup">2</a>,<a class="sup">10</a>]</citation>算法和本文算法)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_205.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Comparison of iterations (literature <citation id="324" type="reference"><link href="271" rel="bibliography" /><link href="287" rel="bibliography" />[2, 10]</citation> algorithms and the proposed algorithm) </p>

                </div>
                <div class="area_img" id="206">
                    <p class="img_tit"><b>表</b>1 <b>性能对比结果 (文献</b><citation id="325" type="reference">[<a class="sup">2</a>,<a class="sup">10</a>]</citation><b>算法和本文算法</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 1 Performance comparison result (literature <citation id="326" type="reference">[<a class="sup">2</a>,<a class="sup">10</a>]</citation> algorithms and the proposed algorithm) </p>
                    <p class="img_note"></p>
                    <table id="206" border="1"><tr><td><br />算法</td><td>时耗/ms</td><td>最短路径长度</td><td>迭代次数</td></tr><tr><td><br />文献[2]算法</td><td>891</td><td>31.556 3</td><td>81</td></tr><tr><td><br />文献[10]算法</td><td>336</td><td>30.384 8</td><td>23</td></tr><tr><td><br />本文算法</td><td>330</td><td>30.384 8</td><td>19</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="207">通过表1中的数据可以看出, 本文算法加入自适应惯性权重值调节信息素强度<i>Q</i>值及自适应的调节信息素蒸发因子<i>ρ</i>可以避免蚂蚁陷入局部最优值, 从而提高算法的迭代速度。从三种算法的对比结果中可以看出, 本文算法在时耗、最短路径长度及迭代次数方面都优于文献<citation id="327" type="reference">[<a class="sup">2</a>]</citation>与文献<citation id="328" type="reference">[<a class="sup">10</a>]</citation>中算法。</p>
                </div>
                <div class="p1">
                    <p id="208">为了验证本文算法的适用性, 随机生成20×20栅格环境利用本文算法及文献<citation id="329" type="reference">[<a class="sup">2</a>]</citation>与文献<citation id="330" type="reference">[<a class="sup">6</a>]</citation>中算法对单个Agent在路径规划上进行对比验证, 得到的结果如图3所示路径规划图及图4所示的迭代次数对比图, 实验中所用参数为:迭代次数<i>K</i><sub>max</sub>=200, 期望值<i>β</i>=7.0, 蚂蚁数量<i>M</i>=30, 启发因子<i>α</i>=1, 惯性权重的最大最小取值为:<i>ω</i><sub>max</sub>=0.9, <i>ω</i><sub>min</sub>=0.4。经过100次实验取得平均值得到的结果如表2所示。</p>
                </div>
                <div class="area_img" id="209">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 路径规划对比 (文献[2, 6]算法和本文算法)" src="Detail/GetImg?filename=images/JSJY201903012_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 路径规划对比 (文献<citation id="331" type="reference">[<a class="sup">2</a>,<a class="sup">6</a>]</citation>算法和本文算法)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_209.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Comparison of path planning (literature <citation id="332" type="reference"><link href="271" rel="bibliography" /><link href="279" rel="bibliography" />[2, 6]</citation> algorithms and the proposed algorithm) </p>

                </div>
                <div class="area_img" id="210">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_210.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 迭代次数对比 (文献[2, 6]算法和本文算法)" src="Detail/GetImg?filename=images/JSJY201903012_210.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 迭代次数对比 (文献<citation id="333" type="reference">[<a class="sup">2</a>,<a class="sup">6</a>]</citation>算法和本文算法)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_210.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison of iterations (literature <citation id="334" type="reference"><link href="271" rel="bibliography" /><link href="279" rel="bibliography" />[2, 6]</citation> algorithms and the proposed algorithm) </p>

                </div>
                <div class="area_img" id="211">
                    <p class="img_tit"><b>表</b>2 <b>性能对比结果 (文献</b><citation id="335" type="reference">[<a class="sup">2</a>,<a class="sup">6</a>]</citation><b>算法和本文算法</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Tab. 2 Performance comparison result (literature <citation id="336" type="reference">[<a class="sup">2</a>,<a class="sup">6</a>]</citation> algorithms and the proposed algorithm) </p>
                    <p class="img_note"></p>
                    <table id="211" border="1"><tr><td><br />算法</td><td>迭代次数</td><td>最短路径长度</td></tr><tr><td><br />文献[2]算法</td><td>90</td><td>35.071 4</td></tr><tr><td><br />文献[6]算法</td><td>38</td><td>31.194 2</td></tr><tr><td><br />本文算法</td><td>25</td><td>30.102 1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="212">通过以上的对比结果可以看出, 在最短路径的寻找过程中, 本文算法在信息素挥发值上的改进能够明显提高算法的迭代速度, 在最短路径长度上优于文献<citation id="337" type="reference">[<a class="sup">2</a>]</citation>以及文献<citation id="338" type="reference">[<a class="sup">6</a>]</citation>中算法。</p>
                </div>
                <h4 class="anchor-tag" id="213" name="213">4.2 <b>多</b>Agent<b>动态避障分析</b></h4>
                <div class="p1">
                    <p id="214">对5个Agent进行仿真, 利用本文避障方法来解决多个Agent之间的碰撞问题, 本文中所说的Agent的半径<i>r</i>根据经验值<i>r</i>=2, 其中Agent1 (A1) 的起点与终点栅格为 (1, 179) , Agent2 (A2) 的起点与终点栅格为 (181, 48) , Agent3 (A3) 的起点与终点栅格为 (101, 180) , Agent4 (A4) 的起点与终点栅格为 (47, 289) , Agent5 (A5) 的起点与终点栅格为 (364, 55) 。经过实验可以得到如图5所示为5个Agent的路径规划图, 图6所示的加入博弈论的迭代次数图。</p>
                </div>
                <div class="area_img" id="215">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文算法多Agent路径规划" src="Detail/GetImg?filename=images/JSJY201903012_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文算法多Agent路径规划  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_215.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Multi-Agent path planning by the proposed algorithm</p>

                </div>
                <div class="p1">
                    <p id="216">从图5中Agent之间的运行路线虽然存在交点, 但是经过调用博弈论的多Agent动态避碰算法可以解决Agent之间的碰撞问题。如在图5中的B点Agent2与Agent3会利用碰撞检测方法检测到两者即将在B点处发生碰撞, 则根据算法1及避障算法2两者产生一个博弈的过程, 因此可以得到Agent2选择等待直到Agent3过去, 这样避免了两者之间的碰撞;而在C点处Agent3、Agent4、Agent5同时检测到三者之间会在C点处发生碰撞, 因此三者之间会产生一个博弈的过程, 这时经过算法2可以得到由于Agent3距离目标点较近因此为了减少损失不必要作过多的行为变化, 从而其有较高的优先级, 这时只需微调方向后再回到原始蚁群算法规划好的路径就可以避免与Agent4与Agent5的碰撞;如图5中加粗虚线部分, 而 Agent4与Agent5之间也会产生一个博弈的过程, 利用算法2可以得到Agent4相比与Agent5会有较高的优先选择行为的权利, 因此Agent5选择等待直到Agent3与Agent4过去, 这样避免了三者之间的碰撞;在接下来的运动过程中虽然Agent之间的运行路线存在交点, 但是Agent不是同时到达的, 因此不会发生碰撞。因为本文考虑到对全局路径的规划, 对比文献<citation id="339" type="reference">[<a class="sup">12</a>]</citation>中算法可以得到图6所示的5个Agent寻得最短路径的迭代次数对比, 经过50次实验利用原始蚁群算法也即文献<citation id="340" type="reference">[<a class="sup">2</a>]</citation>中算法不考虑Agent之间碰撞的情况下及本文与文献<citation id="341" type="reference">[<a class="sup">12</a>]</citation>中的算法得到的平均路径长度的对比。</p>
                </div>
                <div class="p1">
                    <p id="217">从图6中可以看出, 本文引入博弈论的避障方法能够避免Agent之间的碰撞, 使每个Agent快速收敛到最短路径。从图7中可以看出, 本文算法与传统算法相比经过50次实验得到的平均路径长度较大, 但是相比文献<citation id="342" type="reference">[<a class="sup">12</a>]</citation>中的算法, 本文算法的平均路径长度较优。此外为了验证本文算法的有效性, 通过100次实验获得了如图8所示的本文算法与文献<citation id="343" type="reference">[<a class="sup">12</a>]</citation>中算法多Agent的Nash均衡值收敛曲线对比。</p>
                </div>
                <div class="p1">
                    <p id="218">通过图8可以看出, 本文算法在实验85次左右收敛到Nash均衡值而文献<citation id="344" type="reference">[<a class="sup">12</a>]</citation>中算法会出现震荡现象。</p>
                </div>
                <div class="p1">
                    <p id="219">综合以上的对比实验, 可以看出本文算法在寻找全局最优路径的过程中能够很好地解决Agent之间的碰撞, 从而快速找到无碰路径。</p>
                </div>
                <div class="area_img" id="220">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 最短路径迭代次数对比" src="Detail/GetImg?filename=images/JSJY201903012_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 最短路径迭代次数对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Iterations comparison of the shortest path</p>

                </div>
                <div class="area_img" id="221">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 50次实验平均路径长度对比" src="Detail/GetImg?filename=images/JSJY201903012_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 50次实验平均路径长度对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_221.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Average path length comparison of 50 experiments</p>

                </div>
                <div class="area_img" id="222">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJY201903012_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 多Agent的Nash均衡收敛曲线对比" src="Detail/GetImg?filename=images/JSJY201903012_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 多Agent的Nash均衡收敛曲线对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJY201903012_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Nash equilibrium convergence curve comparison of multi-Agent</p>

                </div>
                <h3 id="223" name="223" class="anchor-tag">5 结语</h3>
                <div class="p1">
                    <p id="224">多Agent路径规划问题是MAS研究的核心问题之一, 然而现有的方法着眼于静态障碍物的避碰问题, 故不能解决Agent之间的动态避障问题。本文提出一个两阶段的多Agent路径规划方法:第一阶段, 利用改进的蚁群算法为每个Agent规划出一条不与环境中静态障碍物碰撞的最优路径;第二阶段, 如果在运动的过程中, Agent之间发生动态碰撞, 利用博弈论方法建立多Agent动态避障博弈模型, 并利用虚拟行动法使每个Agent能够快速学习到最优Nash均衡解。在多Agent的路径规划中具有较好的应用价值, 仿真实验验证了该算法的有效性和合理性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="269">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501998953&amp;v=MDMwMzdNbndaZVp0RmlubFVyakpLRjRjYUJRPU5pZk9mYks3SHRETnFvOUViZUlIQlhrNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>BENNET D J, MCINNES C R.Distributed control of multi-robot systems using bifurcating potential fields[J].Robotics and Autonomous Systems, 2010, 58 (3) :256-264.
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ant system: optimization by a colony of cooperating agents">

                                <b>[2]</b>DORIGO M, MANIEZZO V, COLORNI A.Ant system:optimization by a colony of cooperating Agents[J].IEEE Transactions on Systems, Man, and Cybernetics, Part B:Cybernetics, 1996, 26 (1) :29-41.
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel potential field method for path planning of mobile robots by adapting animal motion attributes">

                                <b>[3]</b>KOVACS B, SZAYER G, TAJTI F, et al.A novel potential field method for path planning of mobile robots by adapting animal motion attributes[J].Robotics and Autonomous Systems, 2016, 82 (C) :24-34.
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An improved ant colony algorithm of three dimensional path planning">

                                <b>[4]</b>QIAN W J, ZHOU L F, YANG L, et al.An improved ant colony algorithm of three dimensional path planning[C]//Proceedings of the2017 10th International Symposium on Computational Intelligence and Design.Piscataway, NJ:IEEE, 2017, 1:119-122.
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using the bees algorithm for wheeled mobile robot path planning in an indoor dynamic environment">

                                <b>[5]</b>DARWISH A H, JOUKHADAR A, KASHKASH M.Using the bees algorithm for wheeled mobile robot path planning in an indoor dynamic environment[J].Cogent Engineering, 2018, 5 (1) :1-23.
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNXT201501017&amp;v=MjUxNTQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNzNPUHlQVGVyRzRIOVRNcm8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>裴振兵, 陈雪波.改进蚁群算法及其在机器人避障中的应用[J].智能系统学报, 2015, 10 (1) :90-96. (PEI Z B, CHEN X B.Improved ant colony algorithm and its application in obstacle avoidance for robot[J].CAAI Transactions on Intelligent Systems, 2015, 10 (1) :90-96.) 
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201105042&amp;v=MDM5OTA1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3M09JVGZUZTdHNEg5RE1xbzlCWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>柳长安, 鄢小虎, 刘春阳, 等.基于改进蚁群算法的移动机器人动态路径规划方法[J].电子学报, 2011, 39 (5) :1220-1224. (LIUC A, YAN X H, LIU C Y, et al.Dynamic path planning for mobile robot based on improved ant colony optimization algorithm[J].Acta Electronica Sinica, 2011, 39 (5) :1220-1224.) 
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved ant colony optimization algorithm for intelligent vehicle path planning">

                                <b>[8]</b>YUAN Z, YU H, HUANG M.Improved ant colony optimization algorithm for intelligent vehicle path planning[C]//Proceedings of the 2017 International Conference on Industrial Informatics-Computing Technology, Intelligent Technology, Industrial Information Integration.Piscataway, NJ:IEEE, 2017:1-4.
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hybrid ant colony algorithm with a local search for the strongly correlated knapsack problem">

                                <b>[9]</b>ZOUARI W, ALAYA I, TAGINA M.A hybrid ant colony algorithm with a local search for the strongly correlated knapsack problem[C]//Proceedings of the 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications.Piscataway, NJ:IEEE, 2017:527-533.
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201502020&amp;v=MTU1NTVIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3M09JU2JQZHJHNEg5VE1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>屈鸿, 黄利伟, 柯星.动态环境下基于改进蚁群算法的机器人路径规划研究[J].电子科技大学学报, 2015, 44 (2) :260-265. (QU H, HUANG L W, KE X.Research of improved ant colony based robot path planning under dynamic environment[J].Journal of University of Electronic Science and Technology of China, 2015, 44 (2) :260-265.) 
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A constructive differential game approach to collision avoidance in multi-agent systems">

                                <b>[11]</b>MYLVAGANAM T, SASSANO M, ASTOLFI A.A constructive differential game approach to collision avoidance in multi-Agent systems[C]//Proceedings of the 2014 American Control Conference on Portland.Piscataway, NJ:IEEE, 2014:311-316.
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A differential game approach to multi-agent collision avoidance">

                                <b>[12]</b>MYLVAGANAM T, SASSANO M, ASTOLFI A.A differential game approach to multi-Agent collision avoidance[J].IEEETransactions on Automatic Control, 2017, 62 (8) :4229-4235.
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Opposition-based learning:A new scheme for machine intelligence">

                                <b>[13]</b>TIZHOOSH H R.Opposition-based learning:a new scheme for machine intelligence[C]//CIMCA'05:Proceedings of the 2005International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce.Washington, DC:IEEE Computer Society, 2005, 1:695-701.
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXYK201202006&amp;v=MDA0MzBQTXJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGaURsVzczT1BUWFNaYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>杜继永, 张凤鸣, 李建文, 等.一种具有初始化功能的自适应惯性权重粒子群算法[J].信息与控制, 2012, 41 (2) :165-169. (DU J Y, ZHANG F M, LI J W, et al.A particle swarm optimization algorithm with initialized adaptive inertia weights[J].Information and Control, 2012, 41 (2) :165-169.) 
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810493981999&amp;v=MTg4OTBYRnJJWk5aZUlHQlJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5pVXJmSUtGd1NWVjI3R2J1NUh0&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>施锡全.博弈论[M].上海:上海财经大学出版社, 2000:29-80. (SHI X Q.Game Theory[M].Shanghai:Shanghai University of Finance and Economics Press, 2000:29-80.) 
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Theory of Learning in Games">

                                <b>[16]</b>FUDENBERG D, LEVINE D K.The Theory of Learning in Games[M].Cambridge:MIT Press, 1996:177-198.
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YCXX201003013&amp;v=MzA4MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZpRGxXNzNPUEM3VGRyRzRIOUhNckk5RVo0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>丁占文, 蔡超英, 杨宏林, 等.不完全博弈学习过程的虚拟行动规则[J].运筹学学报, 2010, 14 (3) :91-100. (DING Z W, CAI CY, YANG H L, et al.Rule of fictitious play in the learning process with incomplete learning times[J].Operations Research Transactions, 2010, 14 (3) :91-100.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJY201903012" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903012&amp;v=MDIwNjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRmlEbFc3M09MejdCZDdHNEg5ak1ySTlFWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONFRYTUhIM2RrMzdIS2psYmhhZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
