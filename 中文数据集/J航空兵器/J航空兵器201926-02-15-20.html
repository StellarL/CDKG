<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139863581510000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dHKBQ201902002%26RESULT%3d1%26SIGN%3d%252b5f1kEAr2wyIfsieBMLMnxrddXs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=HKBQ201902002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=HKBQ201902002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKBQ201902002&amp;v=MTIzMTNZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURuVUwzQkxTYkpmN0c0SDlqTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="0 引 言 ">0 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#29" data-title="1 卷积神经网络 ">1 卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#30" data-title="1.1 卷积神经网络算法基本原理">1.1 卷积神经网络算法基本原理</a></li>
                                                <li><a href="#39" data-title="1.2 卷积神经网络的经典结构">1.2 卷积神经网络的经典结构</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="2 卷积神经网络模型的FPGA设计实现 ">2 卷积神经网络模型的FPGA设计实现</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="2.1 卷积神经网络模型的设计实现">2.1 卷积神经网络模型的设计实现</a></li>
                                                <li><a href="#70" data-title="2.2 卷积神经网络模型的设计优化">2.2 卷积神经网络模型的设计优化</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="3 仿真验证及硬件综合 ">3 仿真验证及硬件综合</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#118" data-title="图1 卷积神经网络算法流程示意图">图1 卷积神经网络算法流程示意图</a></li>
                                                <li><a href="#119" data-title="图2 Le Net-5的算法结构图">图2 Le Net-5的算法结构图</a></li>
                                                <li><a href="#120" data-title="图3 Alex＿Net的算法结构图">图3 Alex＿Net的算法结构图</a></li>
                                                <li><a href="#121" data-title="图4 基于FPGA卷积神经网络模型基础模块连接图">图4 基于FPGA卷积神经网络模型基础模块连接图</a></li>
                                                <li><a href="#122" data-title="图5 卷积层基础模块内部数据流示意图">图5 卷积层基础模块内部数据流示意图</a></li>
                                                <li><a href="#123" data-title="图6 池化层基础模块内部框图">图6 池化层基础模块内部框图</a></li>
                                                <li><a href="#124" data-title="图7 全连接层基础模块内部框图">图7 全连接层基础模块内部框图</a></li>
                                                <li><a href="#125" data-title="图8 不同结构的深度卷积神经网络复杂度对比">图8 不同结构的深度卷积神经网络复杂度对比</a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表1 定点小数运算对MNIST测试集错误率的影响&lt;/b&gt;"><b>表1 定点小数运算对MNIST测试集错误率的影响</b></a></li>
                                                <li><a href="#126" data-title="图9 小型卷积神经网络模型">图9 小型卷积神经网络模型</a></li>
                                                <li><a href="#127" data-title="图10 小型卷积神经网络中参数密度分布函数图">图10 小型卷积神经网络中参数密度分布函数图</a></li>
                                                <li><a href="#128" data-title="图11 小型卷积神经网络运行MNIST的波形仿真图">图11 小型卷积神经网络运行MNIST的波形仿真图</a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表2 网络中各层在FPGA上运行的时钟周期数&lt;/b&gt;"><b>表2 网络中各层在FPGA上运行的时钟周期数</b></a></li>
                                                <li><a href="#129" data-title="图12 优化前后网络占用资源对比图">图12 优化前后网络占用资源对比图</a></li>
                                                <li><a href="#130" data-title="图13 优化前后网络功耗使用对比图">图13 优化前后网络功耗使用对比图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="131">


                                    <a id="bibliography_1" title=" 马晓平, 赵良玉.红外导引头关键技术国内外研究现状综述[J].航空兵器, 2018 (3) :3-10.Ma Xiaoping, Zhao Liangyu.An Overview of Infrared Seeker Key Technologies at Home and Abroad[J].Aero Weaponry, 2018 (3) :3-10. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKBQ201803001&amp;v=MTgzNzVGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEblVMM0JMU2JKZjdHNEg5bk1ySTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         马晓平, 赵良玉.红外导引头关键技术国内外研究现状综述[J].航空兵器, 2018 (3) :3-10.Ma Xiaoping, Zhao Liangyu.An Overview of Infrared Seeker Key Technologies at Home and Abroad[J].Aero Weaponry, 2018 (3) :3-10. (in Chinese) 
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     Krizhevsky A, Sutskever I, Hinton G E.ImageNet Classification with Deep Convolutional Neural Networks[C]// Proceedings of the 25th International Conference on Neural Information Processing Systems, 2012:1097-1105.</a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_3" title=" 胡仕友, 赵英海.导弹武器智能精确制导技术发展分析[J].战术导弹技术, 2017 (2) :1-6.Hu Shiyou, Zhao Yinghai.Analysis on the Development of Intelligent Precision Guidance Technology for Missile Weapons[J].Tactical Missile Technology, 2017 (2) :1-6. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSDD201702001&amp;v=MDQ1MDc0SDliTXJZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURuVUwzQlB6N1Bhckc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         胡仕友, 赵英海.导弹武器智能精确制导技术发展分析[J].战术导弹技术, 2017 (2) :1-6.Hu Shiyou, Zhao Yinghai.Analysis on the Development of Intelligent Precision Guidance Technology for Missile Weapons[J].Tactical Missile Technology, 2017 (2) :1-6. (in Chinese) 
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_4" title=" 熊俊辉, 舒孟炯, 秦建飞, 等.导弹智能化技术及作战模式探讨[J].飞航导弹, 2017 (4) :3-5.Xiong Junhui, Shu Mengjiong, Qin Jianfei, et al.Discussion on Missile Intelligent Technology and Operational Mode [J].Aerodynamic Missile Journal, 2017 (4) :3-5. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FHDD201704004&amp;v=MDkwMTVGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEblVMM0JJeVhQYXJHNEg5Yk1xNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         熊俊辉, 舒孟炯, 秦建飞, 等.导弹智能化技术及作战模式探讨[J].飞航导弹, 2017 (4) :3-5.Xiong Junhui, Shu Mengjiong, Qin Jianfei, et al.Discussion on Missile Intelligent Technology and Operational Mode [J].Aerodynamic Missile Journal, 2017 (4) :3-5. (in Chinese) 
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     L&#233;cun Y, Bottou L, Bengio Y, et al.Gradient-Based Learning Applied to Document Recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.</a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_6" title=" Chen Y H, Emer J, Sze V.Eyeriss:A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks[C]// 43rd ACM/IEEE International Symposium on Computer Architecture, Seoul, 2016:367-379." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Eyeriss:a spatial architecture for energy-efficient dataflow for convolutional neural networks">
                                        <b>[6]</b>
                                         Chen Y H, Emer J, Sze V.Eyeriss:A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks[C]// 43rd ACM/IEEE International Symposium on Computer Architecture, Seoul, 2016:367-379.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     丁晓彤.基于FPGA的可配置神经网络全连接层设计及参数压缩[D].西安:西安交通大学, 2017:23-31.Ding Xiaotong.Full Connection Layer Design and Parameters Compression for FPGA-Based Reconfigurable Convolutional Neural Network [D].Xi’an:Xi’an Jiaotong University, 2017:23-31. (in Chinese) </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_8" title=" Shin D, Lee J M, Lee J S, et al.14.2 DNPU:An 8.1 TOPS/W Reconfigurable CNN-RNN Processor for General-Purpose Deep Neural Networks[C]//IEEE International So-lid-State Circuits Conference, San Francisco, 2017:240-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=14.2 DNPU:An 8.1TOPS/W reconfigurable CNN-RNN processor for general-purpose deep neural networks">
                                        <b>[8]</b>
                                         Shin D, Lee J M, Lee J S, et al.14.2 DNPU:An 8.1 TOPS/W Reconfigurable CNN-RNN Processor for General-Purpose Deep Neural Networks[C]//IEEE International So-lid-State Circuits Conference, San Francisco, 2017:240-241.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_9" title=" Cong J, Xiao B J.Minimizing Computation in Convolutional Neural Networks[C]// 24th International Conference on Artificial Neural Networks, Hamburg, 2014:281-290." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Minimizing computation in convolutional neural networks">
                                        <b>[9]</b>
                                         Cong J, Xiao B J.Minimizing Computation in Convolutional Neural Networks[C]// 24th International Conference on Artificial Neural Networks, Hamburg, 2014:281-290.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_10" title=" Chen Tianshi, Du Zidong, Sun Ninghui, et al.DianNao:A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning[J].ACM SIGPLAN Notices, 2014, 49 (4) :269-284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Diannao:a small-footprint highthroughput accelerator for ubiquitous machine-learning">
                                        <b>[10]</b>
                                         Chen Tianshi, Du Zidong, Sun Ninghui, et al.DianNao:A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning[J].ACM SIGPLAN Notices, 2014, 49 (4) :269-284.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_11" title=" Lin D D, Talathi S S, Annapureddy V S.Fixed Point Quantization of Deep Convolutional Networks[C]//Proceedings of the 33rd International Conference on Machine Learning, 2016, 48:2849-2858." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fixed Point Quantization of Deep Convolutional Networks">
                                        <b>[11]</b>
                                         Lin D D, Talathi S S, Annapureddy V S.Fixed Point Quantization of Deep Convolutional Networks[C]//Proceedings of the 33rd International Conference on Machine Learning, 2016, 48:2849-2858.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=HKBQ" target="_blank">航空兵器</a>
                2019,26(02),15-20 DOI:10.12132/ISSN.1673-5048.2018.0073            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于FPGA的卷积神经网络模型设计</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%81%E6%99%93%E5%BD%A4&amp;code=41907304&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">丁晓彤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E4%BD%A9&amp;code=40692669&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐佩</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%BB%E9%B9%8F%E4%B8%BE&amp;code=17686880&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">任鹏举</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A9%BA%E7%A9%BA%E5%AF%BC%E5%BC%B9%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=1700735&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国空空导弹研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%88%AA%E7%A9%BA%E5%88%B6%E5%AF%BC%E6%AD%A6%E5%99%A8%E8%88%AA%E7%A9%BA%E7%A7%91%E6%8A%80%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=1700735&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">航空制导武器航空科技重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6&amp;code=1537420&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安交通大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>武器装备的智能化已经成为一种发展趋势, 卷积神经网络 (CNN) 在图像识别、目标检测和跟踪任务中展现出优异的性能, 因此, 将卷积神经网络算法应用于相关武器有助于提升其在复杂战场环境下的精确目标识别和抗干扰能力。本文提出了一种基于FPGA的卷积神经网络模型设计方法, 并且在Xilinx Virtex-7系列FPGA验证了其功能的正确性。该模型具有可配置、可重构的高灵活性, 移植能力强, 适用范围广。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E8%83%BD%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智能化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FPGA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FPGA;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A6%E5%99%A8%E8%A3%85%E5%A4%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武器装备;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *丁晓彤 (1991-) , 女, 河南洛阳人, 硕士, 研究方向为机器学习及信息处理系统设计。E-mail: dingxiaotong1213@ 163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-10</p>

            </div>
                    <h1><b>Design of FPGA-Based Convolutional Neural Network Model</b></h1>
                    <h2>
                    <span>Ding Xiaotong</span>
                    <span>Xu Pei</span>
                    <span>Ren Pengju</span>
            </h2>
                    <h2>
                    <span>China Airborne Missile Academy</span>
                    <span>Aviation Key Laboratory of Science and Technology on Airborne Guided Weapons</span>
                    <span>Xi'an Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Recently, intellectualization of weapon equipment has become a development trend. Convolutional neural network (CNN) has demonstrated extraordinary performance in image classification, target detection and tracking tasks. Therefore, applying CNN algorithm to weapon equipment can improve the ability of object identification and anti-interference in complex environment. In this paper, a design method of FPGA-based convolutional neural network model is presented, and the function is verified on the Xilinx Virtex-7 series FPGA. The model is reconfigurable and flexible, which has strong transplant ability and wide application range.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=intellectualization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">intellectualization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20identification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object identification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FPGA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FPGA;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=weaponry%20equipment&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">weaponry equipment;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-10</p>
                            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag">0 引 言</h3>
                <div class="p1">
                    <p id="26">卷积神经网络算法是一种高效识别分类算法, 起源于1962年, Hubel和Wiesel在研究猫视觉皮层细胞时发现其独特的网络结构, 提出了感知野 (Receptive Field) 的概念。 1984年日本学者Fukushima基于感知野的概念提出了神经认知机 (Neocognitron) , 可以认为是第一个卷积神经网络<citation id="153" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。 2012年, Alex Krizhevsky提出了一种卷积神经网络算法结构Alex_Net, 在大规模视觉识别挑战 (LSVRC) 分类赛上取得了惊人的成绩, 开启了卷积神经网络的研究热潮<citation id="154" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。 作为人工智能领域机器学习分支中的重要算法, 卷积神经网络近年来已经在多媒体与智能产业中占据优势地位, 在图像识别、 目标分类等方面表现优异。</p>
                </div>
                <div class="p1">
                    <p id="27">在军事上, 随着战场的复杂态势逐步升级, 武器装备需要提升其在复杂战场环境下的精确目标识别与抗干扰能力。 针对这个需求, 可以将卷积神经网络算法应用于武器装备, 利用其出色的目标识别与分类能力提升武器装备的性能, 促进武器装备智能化发展。 目前很多国家都在进行智能武器研究, 美国研制的远程反舰导弹LRASM被称为“人工智能导弹”, 具有末端虚假目标剔除与高价值目标识别锁定的能力<citation id="155" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>; 挪威的NSM反舰导弹装备有双频智能红外成像导引头, 能够区分出中立目标与敌方目标<citation id="156" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。 锁定目标与辨别敌我均可以通过卷积神经网络算法实现, 可见卷积神经网络在军事领域应用的重要性与必要性。 考虑到武器装备的体积、 功耗与实时性的要求, 传统的CPU或GPU将很难满足这些需求。 FPGA是一种现场可编程门阵列, 具有丰富的逻辑门资源, 以并行运算为主, 采用硬件描述语言实现, 具有低功耗、 高速、 高灵活性等优势, 可以快速进行硬件的功能验证和评估, 加快设计迭代速度, 是卷积神经网络算法在智能武器上实现的一种较好方式。</p>
                </div>
                <div class="p1">
                    <p id="28">本文探讨了一种基于FPGA的卷积神经网络模型设计方法, 并针对智能武器的低功耗需求提出该模型的优化方式。</p>
                </div>
                <h3 id="29" name="29" class="anchor-tag">1 卷积神经网络</h3>
                <h4 class="anchor-tag" id="30" name="30">1.1 卷积神经网络算法基本原理</h4>
                <div class="p1">
                    <p id="31">图1所示为卷积神经网络算法流程示意图, 从左至右依次为网络的输入图像、 卷积层、 池化层以及全连接层, 最终输出的是若干分类结果。 卷积神经网络的输入可以是图像的像素, 而不用经过其他操作, 因此, 在图像处理领域运用十分广泛。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 卷积神经网络算法流程示意图" src="Detail/GetImg?filename=images/HKBQ201902002_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 卷积神经网络算法流程示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flow diagram of CNN algorithm</p>

                </div>
                <div class="p1">
                    <p id="35">假设输入图像为单通道灰度图像, 用P表示, 特征窗滑动步长为1, 对P进行卷积操作, 每次卷积操作可表示为</p>
                </div>
                <div class="p1">
                    <p id="36"><i>f</i>=<i>bias</i> + ∑<sub><i>m</i></sub>∑<sub><i>n</i></sub> ( <i>pixel</i><sub><i>mn</i></sub> × <i>weight</i><sub><i>mn</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="37">式中: <i>f</i>为该卷积层输出图像C上的一个像素值; <i>bias</i>为每个特征窗中特定的偏置值; <i>m</i>, <i>n</i>分别为特征窗的长和宽。 卷积操作利用局部感知原理, 在保持像素空间位置信息的同时减少了参数的数量, 卷积后输出图像C, 作为池化层的输入。 池化层又叫采样层, 主要作用是将图像进行采样、 压缩和聚拢, 以减少后面网络的计算量, 同时在一定程度上防止过拟合。 池化层一般有两种方式实现, 平均值池化与最大值池化, 如果选用的是2×2池化窗, 则池化后图像大小为原来的1/4。 图1中池化层的输出用F表示, 将F中的像素按行展开为F<sub>1</sub>作为全连接层的输入, 全连接层的输出用F<sub>2</sub>表示, 即可作为分类结果。 F<sub>1</sub>与F<sub>2</sub>的节点之间两两互连, 是计算量最大、 参数最多的部分。</p>
                </div>
                <div class="p1">
                    <p id="38">从上述过程可以看出, 卷积神经网络是一种前馈网络, 数据流向稳定向前, 未形成环路。 卷积神经网络中参数的初始值需满足高斯分布, 目前常用的训练过程采用反向传播 (BP) 算法, 需要上万张训练图像迭代更新。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">1.2 卷积神经网络的经典结构</h4>
                <div class="p1">
                    <p id="40">目前人工神经网络的实现多集中于软件领域, 工程师们开源了一些卷积神经网络的软件平台, 如Caffe, Tensorflow等, 这些平台可以搭建不同结构的卷积神经网络并完成训练与推理。 近年来新的网络结构层出不穷, 而大多数网络都是在经典网络上改进的, 一种经典的卷积神经网络结构是1986年由Partrick Haffner提出的LeNet-5, 图2所示为LeNet-5算法结构图<citation id="157" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 包括两层卷积层、 池化层和两层全连接层。</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Le Net-5的算法结构图" src="Detail/GetImg?filename=images/HKBQ201902002_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Le Net-5的算法结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Structure diagram of Le Net-5 algorithm</p>

                </div>
                <div class="p1">
                    <p id="44">2012年, Alex Krizhevsky提出的一个经典卷积神经网络算法结构Alex_Net<citation id="158" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。 该网络结构采用ImageNet数据集, 包括训练集1 281 167张图片、 验证集50 000张图片和100 000张测试图片, 分别属于1 000种不同类别。 由于ImageNet数据集中的图像大小并不一致, Alex_Net在使用时先对输入图像进行压缩操作使其固定分辨率为256×256, 又对该图像进行预处理使其成为224×224大小作为网络的输入。 图3所示为Alex_Net的体系结构, 包括八层结构 (五层卷积层和三层全连接层) 。</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Alex＿Net的算法结构图" src="Detail/GetImg?filename=images/HKBQ201902002_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Alex＿Net的算法结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Structure diagram of Alex＿Net algorithm</p>

                </div>
                <h3 id="48" name="48" class="anchor-tag">2 卷积神经网络模型的FPGA设计实现</h3>
                <div class="p1">
                    <p id="49">卷积神经网络中的卷积层以局部感知、 权值共享的方式减少了参数数量, 是卷积神经网络的优势所在, 映射在FPGA上需要保留这种权值共享的模式。 而全连接层参数量、 计算量较大, 用FPGA实现时占用的资源过多, 是后续优化系统的关键部分。 由于不同网络结构中输入图像大小、 卷积窗大小、 个数等均有不同, 本设计是一种基于FPGA的可重构、 可配置的卷积神经网络模型设计, 根据配置参数的不同完成不同卷积神经网络结构在FPGA上的映射。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">2.1 卷积神经网络模型的设计实现</h4>
                <div class="p1">
                    <p id="51">设计的基本思路是依据卷积神经网络算法的功能层设计每层对应的基础模块, 通过配置参数将这些基础模块例化组合, 实现各个功能层的功能。 图4为一个基于FPGA的卷积神经网络模型各层基础模块连接图, C为卷积层基础模块, P为池化层基础模块, F为全连接层基础模块, 图中模型为两层卷积层和一层全连接层, 可通过配置参数调整网络层数及每层基础模块个数。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于FPGA卷积神经网络模型基础模块连接图" src="Detail/GetImg?filename=images/HKBQ201902002_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于FPGA卷积神经网络模型基础模块连接图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Connection diagram of basic modules of CNN on FPGA</p>

                </div>
                <div class="p1">
                    <p id="55">卷积层基础模块的设计受2016年在ISSCC和ISCA两个会议上广泛好评的Eyeriss<citation id="159" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>设计的启发, 该设计的巧妙之处在于对数据流的控制, 图5所示为一个卷积层基础模块, 由处理单元 (PE) 阵列组成, PE实际上是一个乘加器, 每行PE横向自左向右接收特征窗中的一行特征值, 斜向自下而上接收输入图像的像素值, 每个PE完成<i>k</i>组乘加运算, 将结果传入同列的上层PE中相加, 每列累加后的结果由第一层PE输出为部分和 (<i>P</i><sub>sum</sub>) , 对应卷积操作后输出的一个像素。 该设计将数据与权重互配合输入PE, 并行计算多次滑动卷积结果。 本设计也采取了这种数据流控制方式, 但是区别在于每列PE单独采用一个加法器得到<i>P</i><sub>sum</sub>, 节省了加法器个数, 假设阵列每列由<i>k</i>个PE组成, 则完成一次运算较Eyeriss设计节省<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>k</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><msqrt><mi>k</mi></msqrt><mo stretchy="false">]</mo></mrow></math></mathml>个时钟周期。 每个卷积层基础模块C中存储一个特征窗的所有参数, 同一幅图像数据流同时送入本层所有C中, 与C中存储的特征参数做卷积操作, 由于多个特征窗对同一幅图像的卷积操作互不影响, 故采用并行设计完成。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 卷积层基础模块内部数据流示意图" src="Detail/GetImg?filename=images/HKBQ201902002_12200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 卷积层基础模块内部数据流示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Data flow diagram inside the convolutional layer module</p>

                </div>
                <div class="p1">
                    <p id="61">池化层基础模块中设计两种计算方式, 可根据配置选项激活两个模块: 取最大值模块或求平均值模块。 图6所示为池化层基础模块内部框图, 取最大值操作由比较器组多次比较完成, 求平均值操作由输入数据与常数乘加得到, 如求平均值操作的采样窗大小为2×2, 则常数取1/4。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 池化层基础模块内部框图" src="Detail/GetImg?filename=images/HKBQ201902002_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 池化层基础模块内部框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Block diagram inside the pooling layer module</p>

                </div>
                <div class="p1">
                    <p id="65">全连接层的特点是参数数目巨大, 在含有全连接层的模型中, 全连接层参数可以占到整个网络参数的90%以上, 所以目前卷积神经网络优化的手段主要从全连接层入手。 全连接层设计思想与卷积层和池化层相同, 设计全连接层基本模块, 其中输入、 输出端口个数和位宽均可以通过参数进行配置<citation id="160" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。 图7所示为全连接层基本模块的内部结构, 包括存储模块、 基本列模块与地址计数器模块。 存储模块中两个SRAM分别存有训练好的神经网络权重值和偏置值, 通过地址计数器模块控制读取。 基本列模块中包含若干个计算单元, 进行输入数据与对应权重与偏置值的乘加运算。 每个全连接层基本模块得到该全连接层的一个运算结果, 由于全连接层的每个运算结果都涉及该层所有的输入数据, 故从图4中可以看到, 全连接层中每个基础模块F的输入都来自所有池化层基础模块P, 通过数据流控制确保每个全连接层基础模块都能接收到上层所有输出数据。</p>
                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 全连接层基础模块内部框图" src="Detail/GetImg?filename=images/HKBQ201902002_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 全连接层基础模块内部框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Block diagram inside the full connection module</p>

                </div>
                <h4 class="anchor-tag" id="70" name="70">2.2 卷积神经网络模型的设计优化</h4>
                <div class="p1">
                    <p id="71">基于FPGA的卷积神经网络主要完成正向推理过程, 片上存储器存有大量训练完成的参数。 随着卷积神经网络规模不断扩大, 参数数目成倍增加, 运算操作也随之增加, 图8所示为统计的多种深度卷积神经网络 (DCNN) 随着层数增加的参数数目与操作数目的对比图<citation id="161" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。 实现较大规模的卷积神经网络对于FPGA有限的存储与逻辑资源来说是巨大的挑战。 为了解决这个问题, 可以尝试多种优化方式<citation id="162" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同结构的深度卷积神经网络复杂度对比" src="Detail/GetImg?filename=images/HKBQ201902002_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同结构的深度卷积神经网络复杂度对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Complexity comparison of different DCNN</p>

                </div>
                <div class="p1">
                    <p id="75">首先, 在网络准确率变化不大的情况下, 可以通过降低参数精度的方式减少参数占用的存储资源。 软件中训练卷积神经网络均采用浮点型参数, 而在FPGA中, 做浮点运算比做定点运算消耗更多的硬件资源与功耗, 可将卷积神经网络算法中的浮点型参数转化为定点型参数。 中科院计算所在文献<citation id="163" type="reference">[<a class="sup">10</a>]</citation>中统计过卷积神经网络分别采用浮点型与定点型参数时对MNIST手写数字库的识别错误率, 表1所示为定点小数运算对MNIST测试集错误率的影响, 第一行为对照行, 从表中可以得知若训练时的数据保持浮点型, 测试时的数据为定点16位和定点32位时错误率并无变化, 故可将FPGA中存储的数据更换为16位定点型<citation id="164" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。 当网络模型确定后, 可以在定点型参数的基础上继续压缩数据位宽来观察网络最终的正确率变化, 由此选择最适合网络模型的参数位宽。</p>
                </div>
                <div class="p1">
                    <p id="76">除了压缩参数位宽降低精度之外, 还可以通过增加参数“0”值的比例, 选择性地屏蔽乘法运算, 优化资源配置, 从而减少FPGA运行功耗。 图9所示为一个小型卷积神经网络模型, 包括一层卷积池化层与两层全连接层, 在对MNIST数据库训练完成后, 得到网络中所有参数的密度分布函数图如图10所示, 图中显示几乎所有参数都在“0”值附近, 如果将“0”值邻域的值近似取“0”, 即可大大提高网络参数中“0”值比例。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表1 定点小数运算对MNIST测试集错误率的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Effects of fixed-point decimals on MNIST</b></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td><br />测试时所用数据类型</td><td>训练时所用数据类型</td><td>系统错误率</td></tr><tr><td><br />浮点型</td><td>浮点型</td><td>0.82%</td></tr><tr><td><br />16位定点型</td><td>浮点型</td><td>0.83%</td></tr><tr><td><br />32位定点型</td><td>浮点型</td><td>0.83%</td></tr><tr><td><br />16位定点型</td><td>16位定点型</td><td>不收敛</td></tr><tr><td><br />16位定点型</td><td>32位定点型</td><td>0.91%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 小型卷积神经网络模型" src="Detail/GetImg?filename=images/HKBQ201902002_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 小型卷积神经网络模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Model of a small-scale CNN</p>

                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 小型卷积神经网络中参数密度分布函数图" src="Detail/GetImg?filename=images/HKBQ201902002_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 小型卷积神经网络中参数密度分布函数图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Density distribution function diagram of all parameters in a small-scale CNN</p>

                </div>
                <div class="p1">
                    <p id="85">卷积神经网络中常用的激活函数ReLu也有相似功能, 数据经过ReLu函数后小于“0”的参数做归零处理, 因此会得到大量的“0”值参与后续计算。 当数据和参数进行乘法操作之前, FPGA先判定数据或参数是否为“0”, 若为“0”, 则旁路乘法器直接输出“0”值结果。</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag">3 仿真验证及硬件综合</h3>
                <div class="p1">
                    <p id="87">为了验证本设计的正确性, 基于Xilinx公司Virtex-7系列的XC7V2000TFLG1925芯片搭建如图9所示的小型卷积神经模型。 图11所示为卷积层、 全连接层与网络分类结果的输出波形。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 小型卷积神经网络运行MNIST的波形仿真图" src="Detail/GetImg?filename=images/HKBQ201902002_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 小型卷积神经网络运行MNIST的波形仿真图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Waveform simulation of a small-scale CNN on MNIST</p>

                </div>
                <div class="p1">
                    <p id="91">输入一张测试图片, 输出时系统以一个10 bit数据表示数字0～9十个分类。 表2所示为处理一张图片各层花费的网络时钟周期数。</p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表2 网络中各层在FPGA上运行的时钟周期数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Numbers of clock cycles in every layer on FPGA</b></p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td><br />结构</td><td>周期数</td></tr><tr><td><br />输入卷积层</td><td>738</td></tr><tr><td><br />池化层</td><td>6</td></tr><tr><td><br />全连接第一层</td><td>22</td></tr><tr><td><br />全连接第二层</td><td>67</td></tr><tr><td><br />输出层</td><td>14</td></tr><tr><td><br />总计</td><td>847</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="93">搭建的小型卷积神经网络中包含参数约29万个, 按照2.2节中描述的优化方式对整个网络中的系数进行优化, 建立旁路乘法器, 将所有参数由16 bit半精度浮点型压缩为8 bit定点型, 网络准确度在原先97.4%的基础上损失约1.8%。 综合后统计资源与功耗, 优化前后整个网络的资源占有率对比如图12所示, 静态功耗与动态功耗比如图13所示。 可以看到优化后, LUT资源减少约34.9%, BRAM资源减少约38.7%, 静态功耗降低约15.7%, 动态功耗降低约60.9%。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 优化前后网络占用资源对比图" src="Detail/GetImg?filename=images/HKBQ201902002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 优化前后网络占用资源对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.12 Comparison of hardware resources before and after optimization</p>

                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/HKBQ201902002_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 优化前后网络功耗使用对比图" src="Detail/GetImg?filename=images/HKBQ201902002_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 优化前后网络功耗使用对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/HKBQ201902002_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.13 Comparison of power consumption before and after optimization</p>

                </div>
                <h3 id="102" name="102" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="103">本文构建一种基于FPGA的卷积神经网络模型设计方法, 并提出了优化方案。 在Xilinx公司Virtex-7系列的XC7V2000TFLG1925芯片上构建了一个小型卷积神经网络, 通过波形仿真验证了其功能的正确性, 进行综合后比较了优化前后的资源及能耗情况。 结果表明, 可以使用该设计方法在FPGA上实现卷积神经网络, 且优化方案可行, 在降低硬件资源占有率的同时降低了静态与动态功耗, 适用于便携式智能武器装备。</p>
                </div>
                <div class="p1">
                    <p id="104">但是, 智能武器装备的发展需求在不断更新, 卷积神经网络的算法优化也在不断改进, 目前一些表现优异的算法在传统卷积神经网络的基础上增加了特殊功能层, 轻量化网络也在不断发展, 所以卷积神经网络在FPGA上的映射方式仍需进一步研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="131">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKBQ201803001&amp;v=MzE3NDk5bk1ySTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEblVMM0JMU2JKZjdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 马晓平, 赵良玉.红外导引头关键技术国内外研究现状综述[J].航空兵器, 2018 (3) :3-10.Ma Xiaoping, Zhao Liangyu.An Overview of Infrared Seeker Key Technologies at Home and Abroad[J].Aero Weaponry, 2018 (3) :3-10. (in Chinese) 
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 Krizhevsky A, Sutskever I, Hinton G E.ImageNet Classification with Deep Convolutional Neural Networks[C]// Proceedings of the 25th International Conference on Neural Information Processing Systems, 2012:1097-1105.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSDD201702001&amp;v=MzA2OTMzenFxQnRHRnJDVVI3cWZadVpvRmlEblVMM0JQejdQYXJHNEg5Yk1yWTlGWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 胡仕友, 赵英海.导弹武器智能精确制导技术发展分析[J].战术导弹技术, 2017 (2) :1-6.Hu Shiyou, Zhao Yinghai.Analysis on the Development of Intelligent Precision Guidance Technology for Missile Weapons[J].Tactical Missile Technology, 2017 (2) :1-6. (in Chinese) 
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FHDD201704004&amp;v=MDkxNzZVTDNCSXlYUGFyRzRIOWJNcTQ5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 熊俊辉, 舒孟炯, 秦建飞, 等.导弹智能化技术及作战模式探讨[J].飞航导弹, 2017 (4) :3-5.Xiong Junhui, Shu Mengjiong, Qin Jianfei, et al.Discussion on Missile Intelligent Technology and Operational Mode [J].Aerodynamic Missile Journal, 2017 (4) :3-5. (in Chinese) 
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Lécun Y, Bottou L, Bengio Y, et al.Gradient-Based Learning Applied to Document Recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Eyeriss:a spatial architecture for energy-efficient dataflow for convolutional neural networks">

                                <b>[6]</b> Chen Y H, Emer J, Sze V.Eyeriss:A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks[C]// 43rd ACM/IEEE International Symposium on Computer Architecture, Seoul, 2016:367-379.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 丁晓彤.基于FPGA的可配置神经网络全连接层设计及参数压缩[D].西安:西安交通大学, 2017:23-31.Ding Xiaotong.Full Connection Layer Design and Parameters Compression for FPGA-Based Reconfigurable Convolutional Neural Network [D].Xi’an:Xi’an Jiaotong University, 2017:23-31. (in Chinese) 
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=14.2 DNPU:An 8.1TOPS/W reconfigurable CNN-RNN processor for general-purpose deep neural networks">

                                <b>[8]</b> Shin D, Lee J M, Lee J S, et al.14.2 DNPU:An 8.1 TOPS/W Reconfigurable CNN-RNN Processor for General-Purpose Deep Neural Networks[C]//IEEE International So-lid-State Circuits Conference, San Francisco, 2017:240-241.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Minimizing computation in convolutional neural networks">

                                <b>[9]</b> Cong J, Xiao B J.Minimizing Computation in Convolutional Neural Networks[C]// 24th International Conference on Artificial Neural Networks, Hamburg, 2014:281-290.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Diannao:a small-footprint highthroughput accelerator for ubiquitous machine-learning">

                                <b>[10]</b> Chen Tianshi, Du Zidong, Sun Ninghui, et al.DianNao:A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning[J].ACM SIGPLAN Notices, 2014, 49 (4) :269-284.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fixed Point Quantization of Deep Convolutional Networks">

                                <b>[11]</b> Lin D D, Talathi S S, Annapureddy V S.Fixed Point Quantization of Deep Convolutional Networks[C]//Proceedings of the 33rd International Conference on Machine Learning, 2016, 48:2849-2858.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="HKBQ201902002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKBQ201902002&amp;v=MTIzMTNZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURuVUwzQkxTYkpmN0c0SDlqTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25wZXl5TCs5em9qR3A0aXl2VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
