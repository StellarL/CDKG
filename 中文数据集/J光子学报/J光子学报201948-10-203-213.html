

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132479198400000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGZXB201910025%26RESULT%3d1%26SIGN%3dRH3QBXzs5YClAof5CJJGDoOaS6s%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GZXB201910025&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GZXB201910025&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201910025&amp;v=MDc5NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZDbm1WNy9MSWpmVGJMRzRIOWpOcjQ5SFlZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;0 引言&lt;/b&gt; "><b>0 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;1 KCF算法和TLD算法&lt;/b&gt; "><b>1 KCF算法和TLD算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="&lt;b&gt;1.1 KCF算法&lt;/b&gt;"><b>1.1 KCF算法</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;1.2 TLD算法&lt;/b&gt;"><b>1.2 TLD算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;2 本文算法&lt;/b&gt; "><b>2 本文算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;2.1 基于背景惩罚的相关跟踪模块&lt;/b&gt;"><b>2.1 基于背景惩罚的相关跟踪模块</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.2 由粗到精多极值检测算法&lt;/b&gt;"><b>2.2 由粗到精多极值检测算法</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;2.3 自适应学习率更新&lt;/b&gt;"><b>2.3 自适应学习率更新</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;2.4 融合TLD框架的相关滤波算法&lt;/b&gt;"><b>2.4 融合TLD框架的相关滤波算法</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;2.5 算法实现&lt;/b&gt;"><b>2.5 算法实现</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="&lt;b&gt;3 实验结果及分析&lt;/b&gt; "><b>3 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#110" data-title="&lt;b&gt;3.1 Benchmark dataset测试&lt;/b&gt;"><b>3.1 Benchmark dataset测试</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;3.2 红外视频序列集测试&lt;/b&gt;"><b>3.2 红外视频序列集测试</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;4 结论&lt;/b&gt; "><b>4 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="图1 TLD算法框图">图1 TLD算法框图</a></li>
                                                <li><a href="#65" data-title="图2 传统KCF算法在复杂背景下的响应图">图2 传统KCF算法在复杂背景下的响应图</a></li>
                                                <li><a href="#78" data-title="图3 改进相关滤波的响应图">图3 改进相关滤波的响应图</a></li>
                                                <li><a href="#81" data-title="图4 相关滤波跟踪过程中的响应矩阵多极值现象">图4 相关滤波跟踪过程中的响应矩阵多极值现象</a></li>
                                                <li><a href="#85" data-title="图5 干扰响应区域抑制效果图">图5 干扰响应区域抑制效果图</a></li>
                                                <li><a href="#98" data-title="图6 改进TLD算法与ICF算法融合的算法框架图">图6 改进TLD算法与ICF算法融合的算法框架图</a></li>
                                                <li><a href="#107" data-title="图7 算法流程示意图">图7 算法流程示意图</a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表1 算法测试结果&lt;/b&gt;"><b>表1 算法测试结果</b></a></li>
                                                <li><a href="#119" data-title="图8 10种算法的跟踪精度和跟踪成功率的测试结果">图8 10种算法的跟踪精度和跟踪成功率的测试结果</a></li>
                                                <li><a href="#180" data-title="图9 目标遮挡和背景杂波指标的TRE测试结果">图9 目标遮挡和背景杂波指标的TRE测试结果</a></li>
                                                <li><a href="#180" data-title="图9 目标遮挡和背景杂波指标的TRE测试结果">图9 目标遮挡和背景杂波指标的TRE测试结果</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表2 不同跟踪挑战的跟踪成功率和跟踪精度测试结果&lt;/b&gt;"><b>表2 不同跟踪挑战的跟踪成功率和跟踪精度测试结果</b></a></li>
                                                <li><a href="#127" data-title="图10 红外视频序列1跟踪结果(第1、188、395、568、797、913帧)">图10 红外视频序列1跟踪结果(第1、188、395、568、797、913帧)</a></li>
                                                <li><a href="#130" data-title="图11 红外视频序列2跟踪结果(第1、212、399、441、539、561帧)">图11 红外视频序列2跟踪结果(第1、212、399、441、539、561帧)</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" SHI Yong,HAN Chong-zhao.Adaptive UKF method with applications to target tracking[J].&lt;i&gt;Acta Automatic Sinica&lt;/i&gt;,2011,37(6):755-759.石勇,韩崇昭.自适应UKF算法在目标跟踪中的应用[J].自动化学报,2011,37(6):755-759." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201106013&amp;v=MTAzNDg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GQ25tVjcvTEtDTGZZYkc0SDlETXFZOUVaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         SHI Yong,HAN Chong-zhao.Adaptive UKF method with applications to target tracking[J].&lt;i&gt;Acta Automatic Sinica&lt;/i&gt;,2011,37(6):755-759.石勇,韩崇昭.自适应UKF算法在目标跟踪中的应用[J].自动化学报,2011,37(6):755-759.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" WANG Ling-ling,XIN Yun-hong.A small IR target detection and tracking algorithm based on morphological and genetic-particle filter[J].&lt;i&gt;Acta Photonica Sinica&lt;/i&gt;,2013,42(7):849-856.王玲玲,辛云宏.基于形态学与遗传粒子滤波器的红外小目标检测与跟踪算法[J].光子学报,2013,42(7):849-856." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201307021&amp;v=MDA3MDNVUkxPZVplUm1GQ25tVjcvTElqZlRiTEc0SDlMTXFJOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         WANG Ling-ling,XIN Yun-hong.A small IR target detection and tracking algorithm based on morphological and genetic-particle filter[J].&lt;i&gt;Acta Photonica Sinica&lt;/i&gt;,2013,42(7):849-856.王玲玲,辛云宏.基于形态学与遗传粒子滤波器的红外小目标检测与跟踪算法[J].光子学报,2013,42(7):849-856.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" QIAO Li-yong,XU Li-xin,GAO Min .Infrared target tracking using bandwidth adaptive mean shift[J].&lt;i&gt;Infrared and Laser Engineering&lt;/i&gt;,2015,44(1):354 -362.乔立永,徐立新,高敏.带宽自适应均值偏移红外目标跟踪[J].红外与激光工程,2015,44(1):354-362." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201501060&amp;v=MTc1MjhIOVRNcm85RFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZDbm1WNy9MTFRyU1pMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         QIAO Li-yong,XU Li-xin,GAO Min .Infrared target tracking using bandwidth adaptive mean shift[J].&lt;i&gt;Infrared and Laser Engineering&lt;/i&gt;,2015,44(1):354 -362.乔立永,徐立新,高敏.带宽自适应均值偏移红外目标跟踪[J].红外与激光工程,2015,44(1):354-362.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" BABENKO B,YANG M H,BELONGIE S.Robust object tracking with online multiple instance learning[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2011,33(8):1619-1632." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Object Tracking with Online Multiple Instance Learning">
                                        <b>[4]</b>
                                         BABENKO B,YANG M H,BELONGIE S.Robust object tracking with online multiple instance learning[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2011,33(8):1619-1632.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" HARE S,GOLODETZ S,SAFFARI A,&lt;i&gt;et a&lt;/i&gt;l.Struck:structured output tracking with kernels[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2016,38(10):2096-2109." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Struck:Structured output tracking with kernels">
                                        <b>[5]</b>
                                         HARE S,GOLODETZ S,SAFFARI A,&lt;i&gt;et a&lt;/i&gt;l.Struck:structured output tracking with kernels[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2016,38(10):2096-2109.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" KALAL Z,MIKOLAJCZYK K,MATAS J.Tracking-learning-detection[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2012,34(7):1409-1422." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tracking-Learning-Detection">
                                        <b>[6]</b>
                                         KALAL Z,MIKOLAJCZYK K,MATAS J.Tracking-learning-detection[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2012,34(7):1409-1422.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" MA C,YANG X,ZHANG C,&lt;i&gt;et al&lt;/i&gt;.Long-term correlation tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Boston:IEEE,2015:5388-5396." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Long-term correlation tracking">
                                        <b>[7]</b>
                                         MA C,YANG X,ZHANG C,&lt;i&gt;et al&lt;/i&gt;.Long-term correlation tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Boston:IEEE,2015:5388-5396.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" BOLME D S,BEVERIDGE J R,DRAPER B A,&lt;i&gt;et al&lt;/i&gt;.Visual object tracking using adaptive correlation filters[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition,San Francisco:IEEE,2010:2544-2550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">
                                        <b>[8]</b>
                                         BOLME D S,BEVERIDGE J R,DRAPER B A,&lt;i&gt;et al&lt;/i&gt;.Visual object tracking using adaptive correlation filters[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition,San Francisco:IEEE,2010:2544-2550.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" HENRIQUES J F,CASEIRO R,MARTINS P,&lt;i&gt;et al&lt;/i&gt;.High-speed tracking with kernelized correlation filters[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2014,37(3):583-596." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">
                                        <b>[9]</b>
                                         HENRIQUES J F,CASEIRO R,MARTINS P,&lt;i&gt;et al&lt;/i&gt;.High-speed tracking with kernelized correlation filters[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2014,37(3):583-596.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" DANELLJAN M,HAGER G,KHAN F S,&lt;i&gt;et al&lt;/i&gt;.Discriminative scale space tracking[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2016,39(8):1561-1575." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative scale space tracking">
                                        <b>[10]</b>
                                         DANELLJAN M,HAGER G,KHAN F S,&lt;i&gt;et al&lt;/i&gt;.Discriminative scale space tracking[J].&lt;i&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/i&gt;,2016,39(8):1561-1575.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" VALMADRE J,BERTINETTO L,HENRIQUES J,&lt;i&gt;et al&lt;/i&gt;.End-to-end representation learning for correlation filter based tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:5000-5008." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-End Representation Learning for Correlation Filter Based Tracking">
                                        <b>[11]</b>
                                         VALMADRE J,BERTINETTO L,HENRIQUES J,&lt;i&gt;et al&lt;/i&gt;.End-to-end representation learning for correlation filter based tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:5000-5008.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" NAM H,HAN B.Learning multi-domain convolutional neural networks for visual tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Las Vegas:IEEE,2016:4293-4302" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning multi-domain convolutional neural networks for visual tracking">
                                        <b>[12]</b>
                                         NAM H,HAN B.Learning multi-domain convolutional neural networks for visual tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Las Vegas:IEEE,2016:4293-4302
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" HENRIQUES J F,CASEIRO R,MARTINS P,&lt;i&gt;et al&lt;/i&gt;.Exploiting the circulant structure of tracking-by-detection with kernels[C].European Conference on Computer Vision,Heidelberg:Springer,2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">
                                        <b>[13]</b>
                                         HENRIQUES J F,CASEIRO R,MARTINS P,&lt;i&gt;et al&lt;/i&gt;.Exploiting the circulant structure of tracking-by-detection with kernels[C].European Conference on Computer Vision,Heidelberg:Springer,2012:702-715.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" MUELLER M,SNITH N,GHANEM B.Context-aware correlation filter tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:1396-1404." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">
                                        <b>[14]</b>
                                         MUELLER M,SNITH N,GHANEM B.Context-aware correlation filter tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:1396-1404.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" WANG M,LIU Y,HUANG Z.Large margin object tracking with circulant feature maps[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:4021-4029." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large Margin Object Tracking with Circulant Feature Maps">
                                        <b>[15]</b>
                                         WANG M,LIU Y,HUANG Z.Large margin object tracking with circulant feature maps[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:4021-4029.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" WU Y,LIM J,YANG M H.Online object tracking:A benchmark[C].IEEE Conference on Computer Vision and Pattern Recognition,Oregon:IEEE,2013:2411-2418." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">
                                        <b>[16]</b>
                                         WU Y,LIM J,YANG M H.Online object tracking:A benchmark[C].IEEE Conference on Computer Vision and Pattern Recognition,Oregon:IEEE,2013:2411-2418.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" ZHANG K,ZHANG L,YANG M H.Real-time compressive tracking[C].European Conference on Computer Vision,Heidelberg:Springer,2012:864-877." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time compressive tracking">
                                        <b>[17]</b>
                                         ZHANG K,ZHANG L,YANG M H.Real-time compressive tracking[C].European Conference on Computer Vision,Heidelberg:Springer,2012:864-877.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" JIA X,LU H,YANG M H.Visual tracking via adaptive structural local sparse appearance model[C].IEEE Conference on Computer Vision and Pattern Recognition,Rhode Island:IEEE,2012:1822-1829." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual tracking via adaptive structural local sparseappearance model">
                                        <b>[18]</b>
                                         JIA X,LU H,YANG M H.Visual tracking via adaptive structural local sparse appearance model[C].IEEE Conference on Computer Vision and Pattern Recognition,Rhode Island:IEEE,2012:1822-1829.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" ZHONG W,LU H,YANG M H.Robust object tracking via sparse collaborative appearance model[J].IEEE Transactions on Image Processing,2014,23(5):2356-2368." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust objecttracking via sparse collaborative appearance model">
                                        <b>[19]</b>
                                         ZHONG W,LU H,YANG M H.Robust object tracking via sparse collaborative appearance model[J].IEEE Transactions on Image Processing,2014,23(5):2356-2368.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GZXB" target="_blank">光子学报</a>
                2019,48(10),203-213 DOI:10.3788/gzxb20194810.1010001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">复杂红外地面环境下的稳定目标跟踪方法</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%95%E5%9D%9A&amp;code=06565233&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕坚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E5%8D%9A&amp;code=35071756&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%98%99%E9%9A%86%E6%88%90&amp;code=29302871&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">阙隆成</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0178313&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子科技大学光电科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对红外目标相关滤波跟踪过程中由于背景杂波干扰、目标遮挡和目标形变等情况导致的鲁棒性差甚至跟踪目标丢失的问题,提出一种融合跟踪-学习-检测方法和相关滤波理论的红外目标跟踪算法.该算法在传统相关滤波框架基础上,融合目标的方向梯度直方图特征和亮度直方图特征,改善了目标轻微形变导致的模型漂移问题.针对背景杂波和遮挡导致的多峰值响应问题,对目标背景区域的相关响应进行惩罚,建立目标和背景响应的多模态检测机制,实现目标由粗到精的定位,并采用自适应的学习率优化跟踪模型的漂移问题;针对目标被严重遮挡或脱离视野的问题,通过全局目标再检测,实现目标的重捕.实验结果表明,在复杂红外地面环境下,该算法有效地解决了相似目标干扰和目标被严重遮挡导致的目标丢失问题.基于OTB-2015视频基准序列和红外视频序列测试,对比多个主流的相关滤波跟踪算法,该算法在跟踪精度和成功率方面较长时相关滤波跟踪算法分别提升了5.6%和4.1%;在目标遮挡指标测试中,该算法在跟踪精度和成功率方面相较长时相关滤波跟踪算法分别提升了4.6%和6.1%.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%A2%E5%A4%96%E6%8E%A2%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">红外探测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相关滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E9%87%8D%E6%8D%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标重捕;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    吕坚（1977-），男，教授，博士，主要研究方向为红外探测器与光电系统．Email:lvjian@uestc.edu.cn;
                                </span>
                                <span>
                                    *阙隆成（1987-），男，助理研究员，博士，主要研究方向为红外探测器．Email:lcque@uestc.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金（Nos.61235006,61775027);</span>
                    </p>
            </div>
                    <h1><b>Stable Object Tracking Method for Complex Infrared Ground Environment</b></h1>
                    <h2>
                    <span>LÜ Jian</span>
                    <span>DENG Bo</span>
                    <span>QUE Long-cheng</span>
            </h2>
                    <h2>
                    <span>School of Optoelectronic Science and Engineering, University of Electronic Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of tracking failure and less robustness caused by background clutter, occlusion and object deformation in infrared object tracking, an infrared object tracking method combining tracking-learning-detection method and correlation filtering theory was proposed. Based on the traditional correlation filtering framework, the proposed method combines the direction gradient histogram feature and the luminance histogram feature to improve the model drift caused by slight deformation of the target. Aiming at the multi-peak response problem caused by background clutter and occlusion, the response of the target background area was punished, and the multi-modal detection mechanism of target and background response was established to achieve the target from coarse to fine positioning, and the adaptive learning rate was used to optimize the drift problem of the tracking model; Aiming at the problem that the object was severely occluded or the object was out of view, the global re-detection of the target was implemented to achieve the target re-capture. The experimental results show that the proposed algorithm effectively solves the object loss caused by background clutter and occlusion in the complex infrared ground environment. Based on the benchmark OTB-2015 and infrared video sequence test, compared with the mainstream correlation filtering tracking algorithms, the proposed algorithm improves the tracking accuracy and success rate by 5.6% and 4.1% respectively compared with the Long-term Correlation Tracking(LCT) algorithm; In the occlusion index test, the proposed algorithm improves the tracking accuracy and success rate by 4.6% and 6.1% respectively compared with the LCT algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Infrared%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Infrared detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Target%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Target tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Correlation%20filter&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Correlation filter;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Adaptive&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Adaptive;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Object%20recapture&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Object recapture;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China(Nos.61235006,61775027);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>0 引言</b></h3>
                <div class="p1">
                    <p id="42">红外成像运用光电技术检测物体热辐射的特定波段信号,适用于夜晚、雾霾、沙尘等能见度低的天气情况.目标跟踪技术在近些年取得极大的进步,并广泛应用于安防监控、机器人以及人机交互等领域,其作为红外技术发展的关键技术之一,不仅受到红外图像的目标特征不足影响,也受限于跟踪过程中的目标外观形变、相似背景干扰以及遮挡等因素带来的挑战.</p>
                </div>
                <div class="p1">
                    <p id="43">目前目标跟踪模式主要分为:生成模式、判别模式和基于深度学习的三大类.生成类算法是对当前帧目标区域图像建模,在下一帧图像中寻找与模型最相似的区域作为预测目标位置,比较典型的有卡尔曼滤波<citation id="148" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,粒子滤波<citation id="149" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,mean-shift<citation id="150" type="reference"><link href="6" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>滤波等.判别类算法则基于目标正负样本,训练分类器模型,在下一帧图像中根据训练得到的分类器计算最优区域作为预测目标位置,比较典型的方法有多示例学习(Multiple Instance Learning, MIL)<citation id="151" type="reference"><link href="8" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和结构化支持向量机(Structured Support Vector Machine, SSVM)<citation id="152" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等.与生成类算法的主要区别在于,判别类算法在训练分类器中增加了背景信息,因此判别类算法普遍优于生成类算法;比较经典的有跟踪-学习-检测(Tracking-Learning-Dectection, TLD)算法<citation id="153" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和长时相关跟踪(Long-term Correlation Tracking, LCT)算法<citation id="154" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等.近年来,比较主流的一类算法是基于相关滤波(Correlation Filter, CF)的跟踪算法,它们具有精度高、速度快、鲁棒性好等特点.CF类算法通过将输入特征回归为目标高斯分布来训练滤波分类器,在下一帧图像中利用相关滤波计算响应矩阵,将其中响应最大值的位置返回为预测的目标位置.由于利用循环矩阵和快速傅里叶变换的特性,实现计算速度的大幅提升.其中,早期的单通道灰度特征的相关滤波(Minimum Output Sum of Squared Error, MOSSE)<citation id="155" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>算法速度达到了615 FPS,后续的核化相关滤波(Kernelized Correlation Filters, KCF)算法<citation id="156" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在MOSSE的基础上引入了多通道梯度的方向梯度直方图(Histogram of Oriented Gradient, HOG)特征和核函数,判别尺度空间跟踪(Discriminative Scale Space Tracking, DSST)算法<citation id="157" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>则在MOSSE基础上增加了尺度计算估计,利用两个相对独立的相关滤波器可以分别实现目标的跟踪和尺度变换.然而,基于相关滤波的目标跟踪算法由于只返回响应矩阵最大值位置和固定的学习率,因而在应对长期跟踪过程中发生的外观快速变形、相似背景干扰和目标遮挡等情况时,容易导致漂移.基于深度学习的目标跟踪算法,因其更加鲁棒的深度特征、更弱的边界效应等优点,近些年发展迅速,对于深度学习的目标跟踪算法又可细分为基于互补孪生网络(Siamese Networks, SN)框架的跟踪算法和结合深度特征和相关滤波的端到端目标跟踪算法,其中,基于SN典型的算法有CFNet<citation id="158" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等,而另一种的典型有多域卷积神经网络(Multi-Domain Convolutional Neural Networks, MDCNN)<citation id="159" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>等算法.基于深度学习的目标跟踪算法,因其更好的鲁棒性特征,对于相似干扰或轻微形变等具有较强的稳定性,但在解决目标严重遮挡或者目标脱离视野时,仍然无法独立有效地解决,需要配合相应的约束机制和相应的找回模块,这在SN框架下体现极为明显.</p>
                </div>
                <div class="p1">
                    <p id="44">为了解决在复杂红外地面环境下的背景杂波干扰、目标形变以及目标被遮挡等情况导致跟踪鲁棒性差的问题.在相关滤波跟踪算法的基础上提出一种复杂背景下的红外目标跟踪算法(Complex Background Infrared Tracking, CBIT).首先,增加一个在线检测分类器,利用再检测机制配合完成目标重捕,以解决目标被遮挡问题;同时,结合目标背景区域的特征信息对其响应进行约束以抑制相似目标的干扰;最后对强相似目标建立多模态检测机制,实现目标的由粗到精的定位;由多模态计算结果,自适应更新相关滤波模型学习率,解决固定学习率在跟踪遮挡和目标形变时的跟踪漂移问题.实验结果表明,在红外地面复杂背景下,该跟踪算法能有效解决背景相似干扰和目标遮挡的情况,具有较好的准确性和鲁棒性.</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag"><b>1 KCF算法和TLD算法</b></h3>
                <h4 class="anchor-tag" id="46" name="46"><b>1.1 KCF算法</b></h4>
                <div class="p1">
                    <p id="47">相关滤波跟踪算法是一种从信号处理领域扩展到目标跟踪领域的方法,其基本思想是根据当前帧的信息和前一帧的信息训练出相关滤波器,然后对下一帧图像进行相关计算,得到响应矩阵中的最大值位置作为预测的跟踪结果.KCF算法在MOSSE<citation id="160" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>算法和CSK算法<citation id="161" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>的基础上引入循环矩阵来扩展样本,在保留实时性的同时,进一步提高跟踪精度.KCF算法给定的训练样本集{(<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>), <i>i</i> =1, 2,…, <i>l</i>},找到一个线性函数实现样本<i>x</i><sub><i>i</i></sub>和回归目标<i>y</i><sub><i>i</i></sub>的平方误差最小化,即岭回归.参考式(1).</p>
                </div>
                <div class="p1">
                    <p id="48"><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>w</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="49">式中,<i>λ</i>是正则化参数,用来控制过拟合.由岭回归问题存在闭式解<citation id="162" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,将式(1)转换到傅里叶域,即</p>
                </div>
                <div class="p1">
                    <p id="50"><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">w</mi><mo>=</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mi mathvariant="bold-italic">X</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi></mrow><mo>)</mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>y</mi></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="51">式中,<i><b>X</b></i>为<i>l</i>个样本的特征集,<i><b>I</b></i>为单位矩阵,<i><b>X</b></i><sup>H</sup>是<i><b>X</b></i>的共轭转置.当样本线性不可分时,通过引入核函数,将样本投影到高维特征空间,从而使其线性可分,对应的参数<i><b>w</b></i>训练问题简化为式(3),原始空间中的参数<i><b>w</b></i>变成对偶空间中的参数<i><b>a</b></i>.</p>
                </div>
                <div class="p1">
                    <p id="52"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">a</mi><mo>=</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Κ</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi></mrow><mo>)</mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>y</mi></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="53">式中,<i><b>K</b></i>为核函数矩阵,<i><b>a</b></i>是系数<i><b>a</b></i><sub><i>i</i></sub>的向量,代表对偶空间中的解.根据循环矩阵卷积性质,将式(2)和式(3)的计算转化到傅里叶域内,相应地得到.</p>
                </div>
                <div class="p1">
                    <p id="54"><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⊙</mo><mi>F</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo><mo>⊙</mo><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi></mrow></mfrac></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="55"><mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">a</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>k</mi><msup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msup><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi></mrow></mfrac></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="56">因DFT的计算复杂度较低,则算法时间复杂度由<i>O</i>(<i>n</i><sup>3</sup>),降低为<i>O</i>(<i>n</i>log<i>n</i>).最后响应值通过式(6)进行计算.</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>f</mi></mstyle><mo>∧</mo></mover><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mo>∧</mo></mover><msup><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><mi mathvariant="bold-italic">z</mi></mrow></msup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="58">KCF算法也存在着不足:目标快速运动边界效应造成的目标特征变化导致跟踪失败;只返回响应矩阵最大值位置,当响应矩阵出现多峰值时,真实跟踪目标位置可能在非全局最大值外的极大值处;跟踪目标的尺度变化适应性差;采用固定学习率,目标发生形变或者遮挡时会发生跟踪漂移.</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>1.2 TLD算法</b></h4>
                <div class="p1">
                    <p id="60">TLD算法<citation id="163" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>作为经典的长期跟踪算法,算法框架由检测、跟踪和学习3个模块组成,如图1.其核心思想是通过在线学习机制对跟踪器模型和检测器模型不断修正.如果跟踪器跟踪的目标丢失则使用检测器进行全局扫描,并将检测结果提交给学习模块,最终从正样本中选择置信度最高的位置作为输出并更新跟踪器.TLD算法虽然能够一定程度上解决跟踪器的模型漂移问题,但当目标被严重遮挡时,检测器和跟踪器跟踪目标均丢失,进而造成检测器全局检索巨大耗时;同时基于光流法的跟踪器,在目标运动幅度过大或发生大尺度形变时,也易丢失目标.</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 TLD算法框图" src="Detail/GetImg?filename=images/GZXB201910025_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 TLD算法框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Conventional TLD algorithm block diagram</p>

                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>2 本文算法</b></h3>
                <h4 class="anchor-tag" id="63" name="63"><b>2.1 基于背景惩罚的相关跟踪模块</b></h4>
                <div class="p1">
                    <p id="64">由1.1节可知,KCF算法从目标周边循环采样训练再预测,如果目标周边有较大的背景噪声干扰,则会对回归最大响应值产生干扰,如图2.其中白色区域的响应参考图2(b),可以发现当目标形变易造成响应图出现多峰值.如果接下来发现目标发生形变或快速移动,则可能造成目标漂移甚至丢失.</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 传统KCF算法在复杂背景下的响应图" src="Detail/GetImg?filename=images/GZXB201910025_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 传统KCF算法在复杂背景下的响应图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Response diagram of KCF algorithm in complex background</p>

                </div>
                <div class="p1">
                    <p id="66">针对上述问题,从训练样本的区域进行针对性处理.将式(1)修改为式(7).式中,<i><b>A</b></i><sub>0</sub>为目标区域经过循环移位后的目标矩阵,<i>λ</i><sub>1</sub>为控制过拟合的参数.</p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">w</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mn>0</mn></msub><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="68">考虑目标背景信息,如图2,优化式(7)得到式(8).增加目标区域<i><b>A</b></i><sub>0</sub>周边8个区域(目标预测区域的左上、上、右上、左、右、左下、右下8个等面积区域)的相关响应计算,通过检测响应值范围,对其进行筛选惩罚,从而实现对背景杂波有效抑制.</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">w</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mn>0</mn></msub><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="70">式中,<i><b>A</b></i><sub><i>i</i></sub>为上下文背景信息区域对应的循环矩阵,<i>λ</i><sub>2</sub>为控制过拟合参数.</p>
                </div>
                <div class="p1">
                    <p id="71">在构造优化函数时,因增加考虑周边背景信息,将周边背景响应回归至0值<citation id="164" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,再将新回归函数合并,即</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo>,</mo><mi mathvariant="bold-italic">B</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">B</mi><mi mathvariant="bold-italic">w</mi><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">y</mi><mo>¯</mo></mover><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="73">系数矩阵<i><b>B</b></i>由<i><b>A</b></i>构造,背景响应构造为<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>¯</mo></mover></math></mathml>.式中,<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mspace width="0.25em" /><msqrt><mrow><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msqrt><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mspace width="0.25em" /><mo>⋯</mo><mo>,</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>]</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>,</mo><mover accent="true"><mi mathvariant="bold-italic">y</mi><mo>¯</mo></mover><mo>=</mo><mrow><mo>[</mo><mrow><mi>y</mi><mo>,</mo><mspace width="0.25em" /><mn>0</mn><mo>,</mo><mspace width="0.25em" /><mo>⋯</mo><mo>,</mo><mspace width="0.25em" /><mn>0</mn></mrow><mo>]</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>.由此得到该回归的解为</p>
                </div>
                <div class="p1">
                    <p id="74"><mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">w</mi><mo>=</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mi mathvariant="bold-italic">B</mi><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mover accent="true"><mi mathvariant="bold-italic">y</mi><mo>¯</mo></mover></mrow></math></mathml>      (10)</p>
                </div>
                <div class="p1">
                    <p id="75">与式(4)、(5)相似,将式(10)转化到频域内,得到相似形式的式(11).</p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">w</mi></mstyle><mo>∧</mo></mover><mo>=</mo><mfrac><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover><msubsup><mrow></mrow><mn>0</mn><mo>*</mo></msubsup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mo>∧</mo></mover></mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover><msubsup><mrow></mrow><mn>0</mn><mo>*</mo></msubsup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover></mrow></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">a</mi></mstyle><mo>∧</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></math></mathml>      (11)</p>
                </div>
                <div class="p1">
                    <p id="77">使用上述灰度图继续测试,参考图3结果.从图3(b)可知,原始KCF算法灰框内出现了三个类似的响应峰值,先计算背景响应图,再和原响应图进行线性插值,得到图3(c).对比图3(b)可知,除开原始最大响应外,其他都被一定程度惩罚.证明了背景的响应惩罚,有利于改善模型漂移问题.</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 改进相关滤波的响应图" src="Detail/GetImg?filename=images/GZXB201910025_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 改进相关滤波的响应图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Improve the response graph of the correlation filter</p>

                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.2 由粗到精多极值检测算法</b></h4>
                <div class="p1">
                    <p id="80">2.1节的背景惩罚机制,能在一定程度上解决背景杂波引起的模型漂移,但是针对遮挡和杂波干扰混合问题,跟踪模型发生漂移依然无法有效解决.如图4,在复杂场景下的目标跟踪过程中,由于目标遮挡和相似背景的干扰,导致出现多峰值响应问题,通过加入背景惩罚项后虽然多峰值变为单峰值,但最大值已从目标真实响应位置<i>A</i>变为遮挡物的响应位置<i>D</i>,且随着遮挡逐渐严重,目标<i>A</i>开始丢失.</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 相关滤波跟踪过程中的响应矩阵多极值现象" src="Detail/GetImg?filename=images/GZXB201910025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 相关滤波跟踪过程中的响应矩阵多极值现象  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Multi-extremum in the response matrix during correlation tracking</p>

                </div>
                <div class="p1">
                    <p id="82">针对图4所示的目标因遮挡和干扰导致跟踪模型漂移甚至目标丢失的问题,在背景惩罚的基础上由粗到精,建立多模态检测机制,实现目标由粗到精的定位.多峰值遮挡的前向检测算法<citation id="165" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>仅针对出现较多的干扰峰值的情况.当仅仅出现一个峰值相当的遮挡目标时,平均峰值相关能量(Average Peak-to Correlation Energy, APCE)依然处在较大值水平,可能会误判断为目标未被遮挡,导致模型更新,进而引起模型漂移.在APCE基础上,增加对子窗检测窗口进行预判断.如式(12)所示,式中,<i><b>F</b></i><sub>(max,loc)</sub>为目标区域最大响应值,<i><b>F</b></i><sub>(min,Loc)</sub>为最小响应值,<i><b>F</b></i><sub>(</sub><sub><i>r</i></sub><sub>,</sub><sub><i>c</i></sub><sub>,Loc)</sub>为第<i>r</i>行,第<i>c</i>列的响应值.<i><b>F</b></i><sub>Glo</sub>则表示原LMCF检测区域,<i><b>F</b></i><sub>Loc</sub>=<i>β</i><i><b>F</b></i><sub>Glo</sub>,<i>β</i>根据实际应用场景确定.</p>
                </div>
                <div class="p1">
                    <p id="83">UPCE=<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>max</mi><mo>,</mo><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>min</mi><mo>,</mo><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>/</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mo stretchy="false">(</mo><msup><mi>r</mi><mo>′</mo></msup><mo>,</mo><msup><mi>c</mi><mo>′</mo></msup><mo>,</mo><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo></mstyle><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><msup><mi>r</mi><mo>′</mo></msup><mo>,</mo><msup><mi>c</mi><mo>′</mo></msup><mo>,</mo><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>min</mi><mo>,</mo><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>max</mi><mo>,</mo><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>min</mi><mo>,</mo><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>/</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>,</mo><mi>c</mi><mo>,</mo><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">(</mo></mstyle><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>r</mi><mo>,</mo><mi>c</mi><mo>,</mo><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mo stretchy="false">)</mo></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>min</mi><mo>,</mo><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="84">当UPCE&lt;Th,目标被遮挡或被严重干扰(Th为遮挡阈值),需要在上一次UPCE&gt;Th目标位置区域重新计算目标的相关响应值,并对背景区域的相关响应值进行压缩,参考式<i><b>F</b></i><sub>b</sub>=<i><b>F</b></i><sub>mean</sub>+<i>γ</i><i><b>F</b></i><sub>b</sub>,式中<i>γ</i>为压缩系数.以此结果来作为目标预测值.利用图4进行测试验证该方案,结果如图5,可知背景区域和干扰值得到了一定程度的抑制,目标位置没有出现较大的偏移.</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 干扰响应区域抑制效果图" src="Detail/GetImg?filename=images/GZXB201910025_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 干扰响应区域抑制效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Inhibition effect map of the area of interference response</p>

                </div>
                <div class="p1">
                    <p id="86">若UPCE&gt;Th,目标未被遮挡,则计算惩罚背景后融合的最大响应值<i><b>F</b></i>,作为预测跟踪点.将目标和背景的响应,按比例将响应线性叠加,<i><b>F</b></i>=<i>k</i><sub>1</sub>×<i><b>F</b></i><sub>o</sub>+<i>k</i><sub>2</sub>×<i><b>F</b></i><sub>b</sub>;反之,只考虑目标区域的响应,<i><b>F</b></i>=<i>k</i><sub>1</sub>×<i><b>F</b></i><sub>o</sub>,式中,<i><b>F</b></i><sub>b</sub>为背景区域响应矩阵,<i><b>F</b></i><sub>o</sub>为目标区域响应.</p>
                </div>
                <div class="p1">
                    <p id="87">再考虑亮度直方图特征的响应<i><b>F</b></i><sub>hist</sub>,因其对光照敏感、形变不敏感,特征正好和HOG特征互补,对两种特征的响应进行线性加权,参考式(13),实现目标由粗到精的定位,式中,<i>η</i>为权重系数.</p>
                </div>
                <div class="p1">
                    <p id="88"><i><b>F</b></i><sub>all</sub>=<i>η</i><sub>1</sub><i><b>F</b></i>+<i>η</i><sub>2</sub><i><b>F</b></i><sub>hist</sub>      (13)</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>2.3 自适应学习率更新</b></h4>
                <div class="p1">
                    <p id="90">相关滤波算法一般采用固定的学习率和线性模板更新,在目标发生形变时,模型更新的学习率取值固定无法及时更新,容易造成跟踪目标丢失;当学习率取值太大时且目标发生轻微遮挡,相关模型可能误认为遮挡物为跟踪目标,也会导致跟踪失败.结合2.2节遮挡和杂波干扰的分析,设定跟踪稳定标志flag,参考式(14).</p>
                </div>
                <div class="area_img" id="177">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GZXB201910025_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">在式(14)基础上实时计算学习率,如式(15)所示,<i>η</i><sub>std</sub>为正常学习率,这里取值为0.05,<i>γ</i>为学习率调整系数.如果出现两帧及其以上满足严重遮挡条件(UPCE&lt;Th)时,不再进行模板更新.</p>
                </div>
                <div class="area_img" id="178">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GZXB201910025_17800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>2.4 融合TLD框架的相关滤波算法</b></h4>
                <div class="p1">
                    <p id="97">当改进的相关滤波算法在连续多帧出现目标被全遮挡时,需要在新帧中进行再检测找到目标.利用TLD框架的再检测机制,通过其检测器对全图进行检索找到目标,并将改进的相关滤波算法作为TLD算法的跟踪模块,以改善原光流法的漂移问题.当全遮挡在几帧范围时,真实目标尚未移出检测区域<i><b>G</b></i>,目标检测范围仍为跟踪丢失区域<i><b>G</b></i>.但目标遮挡期间发生较大移动时,当目标重新出现后已经不在检测区域,这时需要进行全局扫描匹配.</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 改进TLD算法与ICF算法融合的算法框架图" src="Detail/GetImg?filename=images/GZXB201910025_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 改进TLD算法与ICF算法融合的算法框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 The block diagram of combination algorithm of the improved TLD and ICT</p>

                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>2.5 算法实现</b></h4>
                <div class="p1">
                    <p id="100">本文算法针对红外图像,因此只选用了灰度信息.这里选用HOG特征,以及亮度直方图作为图像特征.目标检测模型采用了Vlfeat工具箱中SVM工具.算法流程如下,跟踪流程示意图如图7.</p>
                </div>
                <div class="p1">
                    <p id="101">1)输入第一帧红外图像和目标区域标注值,提取HOG特征训练滤波模型,训练尺度模型、检测模型和学习模型;</p>
                </div>
                <div class="p1">
                    <p id="102">2)输入下一帧红外图像,对目标搜索区域进行周边8区域扩展,提取目标和背景HOG特征,对目标搜索区域提取亮度直方图特征;</p>
                </div>
                <div class="p1">
                    <p id="103">3)分别计算HOG特征和亮度直方图特征的响应矩阵<i><b>r</b></i><sub>cf</sub>和<i><b>r</b></i><sub>hist</sub>,如果UPCE小于阈值Th,对目标搜索区域外响应值进行惩罚,并对目标搜索区域重新计算<i><b>r</b></i><sub>cf</sub>;</p>
                </div>
                <div class="p1">
                    <p id="104">4)线性归一化响应矩阵<i><b>r</b></i>,找到精确目标位置,以该位置为中心计算最佳尺度;</p>
                </div>
                <div class="p1">
                    <p id="105">5)利用连续帧响应值判断目标跟踪丢失,如果丢失,调用检测模型进行检测,如果目标未丢失更新目标滤波模型、学习模型和检测模型.</p>
                </div>
                <div class="p1">
                    <p id="106">6)返回目标位置.</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 算法流程示意图" src="Detail/GetImg?filename=images/GZXB201910025_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 算法流程示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Flowchart of the proposed tracking algorithm</p>

                </div>
                <h3 id="108" name="108" class="anchor-tag"><b>3 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="109">实验采用两种测试数据集进行测试,第一种OTB-2015<citation id="166" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>数据集视频序列进行测试,第二种采用自建的红外视频序列进行测试.测试环境:编程环境MATLAB为 2016b,系统平台:Intel Core i5, 8G笔记本电脑.</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.1 Benchmark dataset测试</b></h4>
                <div class="p1">
                    <p id="111">通常跟踪算法采用两种精度测试方法<citation id="167" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,一种是仿真得到的跟踪中心点与标定的跟踪中心点的误差值<i>e</i>(<i>d</i>),测试跟踪算法的中心点偏差,另一种是仿真得到的目标跟踪框区域与标定的跟踪框区域的重叠比例值ϕ,测试跟踪算法的尺度变化.计算表达式为</p>
                </div>
                <div class="area_img" id="179">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GZXB201910025_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="114">针对这两种精度测试方法,得到三个测试指标,跟踪中心点误差平均值(Centre Location Error, CLE),跟踪中心点误差小于20个像素(Distance Precision, DP)的比例值,以及跟踪框比例(Overlap Scope, OS)超过0.5的比例值.</p>
                </div>
                <div class="p1">
                    <p id="115">针对跟踪对比算法不同,选用了相关算法如KCF<citation id="168" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、DSST<citation id="169" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、STAPLE_CA(Staple_ Context-aware Correlation Filter Tracking, STAPLE_CACFT)在OTB中简化为STAPLE_CA<citation id="170" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,单分类器算法如Struck<citation id="171" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、CT(Compressive Tracking, CT)<citation id="172" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、ASLA(Adaptive Structural Local Appearance, ASLA)<citation id="173" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,多分类器算法如TLD<citation id="174" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、SCM(Sparse Collaborative Model, SCM)<citation id="175" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>,以及长期跟踪算法比如LCT<citation id="176" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>与本文所提的复杂背景下红外跟踪算法(Complex background Infrared Tracking, CBIT)进行对比.表1列举了10种算法的跟踪中心点误差平均值(CLE),跟踪中心点误差比例值(DP%),跟踪框比例值(OS%)以及处理帧频(Frames Per Second, FPS).表1所示为算法测试结果,其中黑体为结果最好的算法,可以发现CBIT算法在CLE、DP%、OS%上指标相较之前的算法有很大程度提升,相较于长时间跟踪算法LCT算法取得了实质性的提升,但实时性略差于LCT算法.</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表1 算法测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Test results of the proposed algorithm</b></p>
                    <p class="img_note"></p>
                    <table id="116" border="1"><tr><td></td><td>CBIT</td><td>KCF</td><td>DSST</td><td>STAPLE_CA</td><td>STRUCK</td><td>CT</td><td>ASLA</td><td>TLD</td><td>SCM</td><td>LCT</td></tr><tr><td><br />CLE</td><td><b>26.7</b></td><td>41.7</td><td>52.5</td><td>44.2</td><td>69.9</td><td>123.0</td><td>113.0</td><td>69.1</td><td>78.3</td><td>26.9</td></tr><tr><td><br />DP%</td><td><b>74.7</b></td><td>62.3</td><td>66.7</td><td>70.9</td><td>55.9</td><td>27.9</td><td>51.1</td><td>48.8</td><td>61.6</td><td>73.8</td></tr><tr><td><br />OS%</td><td><b>61.9</b></td><td>51.4</td><td>55.4</td><td>58.1</td><td>47.4</td><td>27.6</td><td>43.4</td><td>41.4</td><td>49.9</td><td>59.3</td></tr><tr><td><br />FPS</td><td>10.21</td><td><b>82.0</b></td><td>13.0</td><td>41.9</td><td>3.15</td><td>61.9</td><td>2.80</td><td>22.9</td><td>0.14</td><td>10.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="117">跟踪算法效果一般采用三种方式进行测试:采用首帧图像为初始目标跟踪点测试(One-Pass Evaluation, OPE);采用视频平均分为二十个节点,每个节点为初始目标跟踪点测试(Temporal Robustness Evaluation, TRE);以及采用首帧图像对中心点和尺度进行微小修改后的跟踪测试(Spatial Robustness Evaluation, SRE).为了评测跟踪算法对每个视频不同跟踪点,以及跟踪框选择的鲁棒性,通过采用OPE、TRE和SRE这三种测试进行算法跟踪效果的比对.</p>
                </div>
                <div class="p1">
                    <p id="118">针对跟踪对比算法不同,选用了典型相关算法如KCF、DSST、STAPLE_CA,单分类器算法如Struck、CT、ASLA,多分类器算法如TLD、SCM,以及长期跟踪算法比如LCT与本文算法CBIT进行对比.并采用Benchmark OTB-2015的视频序列进行测试.表1所述十种算法的OPE、TRE和SRE的测试结果如图8,图8(a)为跟踪成功率测试结果,图8(b)为精确度测试结果.如图8,CBIT算法取得了61.5%的平均跟踪成功率以及76.1%平均跟踪精度,相对于最初Benchmark中最佳的STRUCK算法,跟踪成功率指标提升了13.6%,跟踪精确度指标提升了14.7%,相比LCT长期跟踪算法,跟踪成功率指标也提升了5.6%,跟踪精确度指标提升了4.1%,优于对比测试的9个算法.</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 10种算法的跟踪精度和跟踪成功率的测试结果" src="Detail/GetImg?filename=images/GZXB201910025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 10种算法的跟踪精度和跟踪成功率的测试结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Success and precision test results of 10 different tracking algorithms</p>

                </div>
                <div class="p1">
                    <p id="120">目标跟踪算法目前难以解决如,环境光照变化、目标旋转、目标被遮挡、目标非刚性形变、目标出视场、相似目标干扰、目标低分辨率等问题.而在复杂地面环境下的红外目标跟踪,由于背景杂波干扰和遮挡问题,本文算法主要关注目标遮挡和背景相似干扰两个因素,测试结果如图9.</p>
                </div>
                <div class="area_img" id="180">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_18000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 目标遮挡和背景杂波指标的TRE测试结果" src="Detail/GetImg?filename=images/GZXB201910025_18000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 目标遮挡和背景杂波指标的TRE测试结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_18000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 TRE test results under the conditions of occlusion and background clutter</p>

                </div>
                <div class="area_img" id="180">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_18001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 目标遮挡和背景杂波指标的TRE测试结果" src="Detail/GetImg?filename=images/GZXB201910025_18001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 目标遮挡和背景杂波指标的TRE测试结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_18001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 TRE test results under the conditions of occlusion and background clutter</p>

                </div>
                <div class="p1">
                    <p id="123">从图9的遮挡和背景杂波干扰两项指标的测试结果可知,CBIT算法相对于经典的长期跟踪算法LCT和背景抑制跟踪算法STAPLE_CA均取得一定程度的性能提升,证明了所提CBIT算法针对这两类问题的有效性.除了上述两项关键对比测试外,基于OTB-2015实施了其他挑战的跟踪成功率和跟踪精度的对比测试,并将OPE、TRE和SRE的测试结果进行加权平均处理,其最终结果如表2.其中,黑体表示跟踪效果最优指标,斜体表示跟踪效果次优指标,黑斜体则表示性能指标的第三名.从表2可以看出本文所提CBIT算法整体性能表现优异,相对于LCT算法取得了一定的性能指标提升,但在跟踪目标分辨率极低时效果相对较差,因为OTB-2015数据集为可见光图像,而CBIT算法的亮度直方图特征表征能力相对较弱,需要用实际的红外目标进行测试.同时从表2可知,在目标脱离视野后CBIT算法表现较好,这是因为目标的再检测机制的作用.综上,所提CBIT算法能够满足红外目标稳定跟踪的要求,能实现复杂地面环境的红外目标鲁棒跟踪.</p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表2 不同跟踪挑战的跟踪成功率和跟踪精度测试结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Tracking success rate and tracking precision test results for different tracking challenges</b></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td colspan="2"><br />Category</td><td>CBIT</td><td>KCF</td><td>DSST</td><td>STAPL<br />E_CA</td><td>Struck</td><td>CT</td><td>ASLA</td><td>TLD</td><td>SCM</td><td>LCT</td></tr><tr><td><br />Illumination <br />variations</td><td>Success rate<br />Precision</td><td><b>0.574<br />0.687</b></td><td>0.491<br />0.627</td><td><i>0</i>.<i>546</i><br /><b><i>0</i>.<i>651</i></b></td><td>0.533<br />0.627</td><td>0.440<br />0.545</td><td>0.275<br />0.336</td><td>0.439<br />0.517</td><td>0.357<br />0.453</td><td>0.451<br />0.529</td><td><b><i>0</i>.<i>527</i></b><br /><i>0</i>.<i>663</i></td></tr><tr><td><br />Out-of-plane<br />rotation<br />Abrupt<br />motion<br />In-plane<br />rotation<br /><br />Blur<br /><br />Out-of-<br />view<br />Low <br />resolution<br /><br />Deformation<br /><br />Scale <br />variation</td><td>Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision<br />Success rate<br />Precision</td><td><b>0.598<br />0.746<br />0.543<br />0.625<br />0.568<br />0.719<br />0.544</b><br /><b>0.645<br />0.562</b><br /><i>0</i>.<i>581</i><br /><b><i>0</i>.<i>382</i></b><br /><b><i>0</i>.<i>468</i></b><br /><b>0.657<br />0.807<br />0.562<br />0.700</b></td><td>0.493<br />0.646<br />0.446<br /><b><i>0</i>.<i>540</i></b><br />0.492<br />0.639<br /><b><i>0</i>.<i>474</i></b><br />0.570<br /><b><i>0</i>.<i>521</i><br /><i>0</i>.<i>564</i></b><br />0.330<br />0.399<br />0.529<br />0.658<br />0.441<br />0.624</td><td>0.522<br />0.645<br />0.434<br />0.493<br /><i>0</i>.<i>539</i><br /><b><i>0</i>.<i>664</i></b><br />0.460<br />0.530<br />0.466<br />0.505<br /><b>0.416</b><br /><i>0</i>.<i>490</i><br />0.516<br />0.613<br /><i>0</i>.<i>531</i><br />0.660</td><td><b><i>0</i>.<i>544</i></b><br /><b><i>0</i>.<i>668</i></b><br /><b><i>0</i>.<i>464</i></b><br />0.525<br />0.534<br /><b><i>0</i>.<i>664</i></b><br />0.460<br />0.530<br />0.476<br />0.505<br />0.365<br />0.438<br /><b><i>0</i>.<i>587</i></b><br /><b><i>0</i>.<i>706</i></b><br /><b><i>0</i>.<i>527</i></b><br /><b><i>0</i>.<i>656</i></b></td><td>0.442<br />0.571<br />0.462<br />0.535<br />0.445<br />0.572<br />0.459<br />0.545<br />0.436<br />0.466<br /><i>0</i>.<i>397</i><br /><b>0.511</b><br />0.433<br />0.536<br />0.424<br />0.589</td><td>0.274<br />0.374<br />0.228<br />0.255<br />0.274<br />0.374<br />0.209<br />0.249<br />0.254<br />0.228<br />0.124<br />0.267<br />0.294<br />0.366<br />0.280<br />0.399</td><td>0.435<br />0.528<br />0.265<br />0.295<br />0.431<br />0.522<br />0.274<br />0.311<br />0.322<br />0.332<br />0.219<br />0.254<br />0.413<br />0.484<br />0.464<br />0.568</td><td>0.398<br />0.523<br />0.367<br />0.447<br />0.383<br />0.508<br />0.368<br />0.446<br />0.422<br />0.466<br />0.272<br />0.325<br />0.375<br />0.479<br />0.380<br />0.515</td><td>0.453<br />0.483<br />0.285<br />0.315<br />0.441<br />0.539<br />0.287<br />0.323<br />0.351<br />0.371<br />0.281<br />0.321<br />0.444<br />0.531<br />0.489<br />0.596</td><td><i>0</i>.<i>554</i><br /><i>0</i>.<i>721</i><br /><i>0</i>.<i>491</i><br /><i>0</i>.<i>580</i><br /><b><i>0</i>.<i>537</i></b><br /><i>0</i>.<i>691</i><br /><i>0</i>.<i>503</i><br /><i>0</i>.<i>592</i><br /><i>0</i>.<i>549</i><br /><b>0.603</b><br />0.290<br />0.353<br /><i>0</i>.<i>606</i><br /><i>0</i>.<i>756</i><br />0.466<br /><i>0</i>.<i>661</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>3.2 红外视频序列集测试</b></h4>
                <div class="p1">
                    <p id="126">针对复杂背景下的红外目标选用前面表2及图10中测试跟踪效果较好的KCF、DSST、LCT、STAPLE_CA 5个跟踪算法和本文的CBIT算法进行红外视频序列跟踪对比测试.</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 红外视频序列1跟踪结果(第1、188、395、568、797、913帧)" src="Detail/GetImg?filename=images/GZXB201910025_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 红外视频序列1跟踪结果(第1、188、395、568、797、913帧)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Tracking results of infrared video sequence 1 (Frame numbers from top left to bottom right: 1, 188, 395, 568, 797, 913)</p>

                </div>
                <div class="p1">
                    <p id="128">红外视频测试序列1有较长的帧数,目标为由远到近的运动目标,视频包含了尺度变化、相似目标干扰两种典型的跟踪难点.测试结果如图10,所有测试的算法都能稳定地跟踪目标,在188帧出现的轻度相似目标干扰,对5种算法都没有造成漂移.在395帧后随着车速的加快,尺度变化加快,导致测试的算法尺度均出现较大的偏差,尤其KCF算法,在913帧时出现了严重的尺度漂移.</p>
                </div>
                <div class="p1">
                    <p id="129">红外视频序列2为严重的目标遮挡测试视频序列(这里由于场景较远、较宽,仅截取跟踪对象附近区域),该序列可以测试目标跟踪算法的抗严重遮挡性和相似目标、背景杂波的抗干扰性.同样将本文的CBIT算法与前述的4种相关跟踪算法进行了对比,测试结果如图11.</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GZXB201910025_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 红外视频序列2跟踪结果(第1、212、399、441、539、561帧)" src="Detail/GetImg?filename=images/GZXB201910025_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 红外视频序列2跟踪结果(第1、212、399、441、539、561帧)  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GZXB201910025_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Tracking results of infrared video sequence 2 (Frame numbers: 1, 212, 399, 441, 539, 561)</p>

                </div>
                <div class="p1">
                    <p id="131">在212帧前,所有跟踪算法均实现稳定跟踪,在212帧后出现相似目标干扰,在399帧时DSST和KCF算法的跟踪框出现了轻度的移位.在441帧时,目标开始被逐渐遮挡,遮挡时长2 s,期间目标存在多个相似目标干扰.KCF、DSST、LCT、STAPLE_CA 4种相关跟踪算法在发生遮挡后,当后方出现及其相似的车辆目标时(第441、561帧),都出现了错误重捕,在第539帧时,KCF算法跟踪到短时遮挡的快速车辆,由于目标脱离视野,其跟踪框保持在桥上.本文的CBIT由于使用了多模态检测的遮挡判断策略、背景响应惩罚策略和再检测机制,当跟踪目标出遮挡后能够正确重捕目标.</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>4 结论</b></h3>
                <div class="p1">
                    <p id="133">本文提出融合了再检测机制的改进相关滤波跟踪算法,利用HOG特征和亮度直方图特征的加权组合,增强特征的鲁棒性,解决相似目标干扰或轻微形变造成的模板漂移;建立目标背景区域的多峰值响应检测机制,基于检测结果实现背景区域响应的惩罚,进而减少背景杂波、轻微形变的干扰,实现目标由粗到精的定位;同时,根据检测结果建立跟踪模型学习率的自适应更新,优化模型的漂移问题;最后,通过目标的全局再检测模型,完成目标丢失后的重捕.基于OTB-2015基准数据集完成多个主流相关滤波跟踪算法的对比测试,实验结果表明,该算法实现了76.1%平均跟踪精度和61.5%的平均跟踪成功率,相较LCT算法实现了5.6%成功率和4.1%精度的提升.在定性的红外场景对比测试中,该算法明显优于其他跟踪算法,在遇到杂波干扰和严重遮挡时,可稳定跟踪红外目标.后续将进一步优化该算法,保证其实时性.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201106013&amp;v=MTI0NTR6cXFCdEdGckNVUkxPZVplUm1GQ25tVjcvTEtDTGZZYkc0SDlETXFZOUVaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> SHI Yong,HAN Chong-zhao.Adaptive UKF method with applications to target tracking[J].<i>Acta Automatic Sinica</i>,2011,37(6):755-759.石勇,韩崇昭.自适应UKF算法在目标跟踪中的应用[J].自动化学报,2011,37(6):755-759.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201307021&amp;v=MTE3MTFNcUk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZDbm1WNy9MSWpmVGJMRzRIOUw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> WANG Ling-ling,XIN Yun-hong.A small IR target detection and tracking algorithm based on morphological and genetic-particle filter[J].<i>Acta Photonica Sinica</i>,2013,42(7):849-856.王玲玲,辛云宏.基于形态学与遗传粒子滤波器的红外小目标检测与跟踪算法[J].光子学报,2013,42(7):849-856.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201501060&amp;v=MTI0MDllUm1GQ25tVjcvTExUclNaTEc0SDlUTXJvOURaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> QIAO Li-yong,XU Li-xin,GAO Min .Infrared target tracking using bandwidth adaptive mean shift[J].<i>Infrared and Laser Engineering</i>,2015,44(1):354 -362.乔立永,徐立新,高敏.带宽自适应均值偏移红外目标跟踪[J].红外与激光工程,2015,44(1):354-362.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Object Tracking with Online Multiple Instance Learning">

                                <b>[4]</b> BABENKO B,YANG M H,BELONGIE S.Robust object tracking with online multiple instance learning[J].<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,2011,33(8):1619-1632.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Struck:Structured output tracking with kernels">

                                <b>[5]</b> HARE S,GOLODETZ S,SAFFARI A,<i>et a</i>l.Struck:structured output tracking with kernels[J].<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,2016,38(10):2096-2109.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tracking-Learning-Detection">

                                <b>[6]</b> KALAL Z,MIKOLAJCZYK K,MATAS J.Tracking-learning-detection[J].<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,2012,34(7):1409-1422.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Long-term correlation tracking">

                                <b>[7]</b> MA C,YANG X,ZHANG C,<i>et al</i>.Long-term correlation tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Boston:IEEE,2015:5388-5396.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">

                                <b>[8]</b> BOLME D S,BEVERIDGE J R,DRAPER B A,<i>et al</i>.Visual object tracking using adaptive correlation filters[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition,San Francisco:IEEE,2010:2544-2550.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">

                                <b>[9]</b> HENRIQUES J F,CASEIRO R,MARTINS P,<i>et al</i>.High-speed tracking with kernelized correlation filters[J].<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,2014,37(3):583-596.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative scale space tracking">

                                <b>[10]</b> DANELLJAN M,HAGER G,KHAN F S,<i>et al</i>.Discriminative scale space tracking[J].<i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>,2016,39(8):1561-1575.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-End Representation Learning for Correlation Filter Based Tracking">

                                <b>[11]</b> VALMADRE J,BERTINETTO L,HENRIQUES J,<i>et al</i>.End-to-end representation learning for correlation filter based tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:5000-5008.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning multi-domain convolutional neural networks for visual tracking">

                                <b>[12]</b> NAM H,HAN B.Learning multi-domain convolutional neural networks for visual tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Las Vegas:IEEE,2016:4293-4302
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">

                                <b>[13]</b> HENRIQUES J F,CASEIRO R,MARTINS P,<i>et al</i>.Exploiting the circulant structure of tracking-by-detection with kernels[C].European Conference on Computer Vision,Heidelberg:Springer,2012:702-715.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">

                                <b>[14]</b> MUELLER M,SNITH N,GHANEM B.Context-aware correlation filter tracking[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:1396-1404.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large Margin Object Tracking with Circulant Feature Maps">

                                <b>[15]</b> WANG M,LIU Y,HUANG Z.Large margin object tracking with circulant feature maps[C].IEEE Conference on Computer Vision and Pattern Recognition,Honolulu:IEEE,2017:4021-4029.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">

                                <b>[16]</b> WU Y,LIM J,YANG M H.Online object tracking:A benchmark[C].IEEE Conference on Computer Vision and Pattern Recognition,Oregon:IEEE,2013:2411-2418.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time compressive tracking">

                                <b>[17]</b> ZHANG K,ZHANG L,YANG M H.Real-time compressive tracking[C].European Conference on Computer Vision,Heidelberg:Springer,2012:864-877.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual tracking via adaptive structural local sparseappearance model">

                                <b>[18]</b> JIA X,LU H,YANG M H.Visual tracking via adaptive structural local sparse appearance model[C].IEEE Conference on Computer Vision and Pattern Recognition,Rhode Island:IEEE,2012:1822-1829.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust objecttracking via sparse collaborative appearance model">

                                <b>[19]</b> ZHONG W,LU H,YANG M H.Robust object tracking via sparse collaborative appearance model[J].IEEE Transactions on Image Processing,2014,23(5):2356-2368.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GZXB201910025" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201910025&amp;v=MDc5NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZDbm1WNy9MSWpmVGJMRzRIOWpOcjQ5SFlZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9tWklpZnUrUndWTVJRUUd3KzVmcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

