<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142621177607500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201906003%26RESULT%3d1%26SIGN%3dy4LQ9ldZNVUNpoH%252bMAZqof2otlg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201906003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201906003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201906003&amp;v=MjcxMDFyQ1VSN3FmWnVkdkZ5M2tXcjNPSmlYVGJMRzRIOWpNcVk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="1 本文算法 ">1 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="1.1 图嵌入学习">1.1 图嵌入学习</a></li>
                                                <li><a href="#68" data-title="1.2 超图模型">1.2 超图模型</a></li>
                                                <li><a href="#81" data-title="1.3 SSRSHE算法">1.3 SSRSHE算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#207" data-title="2 试验结果与分析 ">2 试验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#209" data-title="2.1 数据集">2.1 数据集</a></li>
                                                <li><a href="#214" data-title="2.2 试验设置">2.2 试验设置</a></li>
                                                <li><a href="#222" data-title="2.3 Indian Pines试验结果与分析">2.3 Indian Pines试验结果与分析</a></li>
                                                <li><a href="#230" data-title="2.4 PaviaU试验结果与分析">2.4 PaviaU试验结果与分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#237" data-title="3 总 结 ">3 总 结</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="图1 SSRSHE算法流程">图1 SSRSHE算法流程</a></li>
                                                <li><a href="#91" data-title="图2 基于稀疏系数的自适应选取近邻构造超边">图2 基于稀疏系数的自适应选取近邻构造超边</a></li>
                                                <li><a href="#211" data-title="图3 Indian Pines高光谱图像">图3 Indian Pines高光谱图像</a></li>
                                                <li><a href="#213" data-title="图4 PaviaU 高光谱图像">图4 PaviaU 高光谱图像</a></li>
                                                <li><a href="#219" data-title="图5 SSRSHE在不同η和ξ参数值下的总体分类精度">图5 SSRSHE在不同η和ξ参数值下的总体分类精度</a></li>
                                                <li><a href="#220" data-title="图6 SSRSHE在不同空间窗口&lt;i&gt;γ&lt;/i&gt;下的总体分类精度">图6 SSRSHE在不同空间窗口<i>γ</i>下的总体分类精度</a></li>
                                                <li><a href="#224" data-title="&lt;b&gt;表1 不同降维算法在Indian Pines数据集上的分类效果&lt;/b&gt;"><b>表1 不同降维算法在Indian Pines数据集上的分类效果</b></a></li>
                                                <li><a href="#227" data-title="&lt;b&gt;表2 不同算法在Indian Pines数据集每类地物上的分类精度&lt;/b&gt;"><b>表2 不同算法在Indian Pines数据集每类地物上的分类精度</b></a></li>
                                                <li><a href="#228" data-title="图7 在Indian Pines数据集上, 各降维算法对应的全分类结果">图7 在Indian Pines数据集上, 各降维算法对应的全分类结果</a></li>
                                                <li><a href="#234" data-title="图8 在PaviaU数据集上, 各降维算法对应的全分类结果">图8 在PaviaU数据集上, 各降维算法对应的全分类结果</a></li>
                                                <li><a href="#235" data-title="&lt;b&gt;表3 不同算法在PaviaU数据集上的分类效果&lt;/b&gt;"><b>表3 不同算法在PaviaU数据集上的分类效果</b></a></li>
                                                <li><a href="#236" data-title="&lt;b&gt;表4 不同算法在PaviaU数据集每种地物上的分类精度&lt;/b&gt;"><b>表4 不同算法在PaviaU数据集每种地物上的分类精度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201709005&amp;v=MTA3NDhIOWJNcG85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2tXcjNPSmlYVGJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" 张良培, 武辰.多时相遥感影像变化检测的现状与展望[J].测绘学报, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340.ZHANG Liangpei, WU Chen.Advance and future development of change detection for multi-temporal remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201710028&amp;v=MTE0OTR6cXFCdEdGckNVUjdxZlp1ZHZGeTNrV3IzT0ppWFRiTEc0SDliTnI0OUhiSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张良培, 武辰.多时相遥感影像变化检测的现状与展望[J].测绘学报, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340.ZHANG Liangpei, WU Chen.Advance and future development of change detection for multi-temporal remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" MENEZES J, POOJARY N.Dimensionality reduction and classification of hyperspetral images using DWT and DCCF[C]//Proceedings of the 3rd MEC International Conference on Big Data and Smart City.Muscat:IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction and classification of hyperspetral images using DWT and DCCF">
                                        <b>[3]</b>
                                         MENEZES J, POOJARY N.Dimensionality reduction and classification of hyperspetral images using DWT and DCCF[C]//Proceedings of the 3rd MEC International Conference on Big Data and Smart City.Muscat:IEEE, 2016.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" CHEN Mulin, WANG Qi, LI Xuelong.Discriminant analysis with graph learning for hyperspectral image classification[J].Remote Sensing, 2018, 10 (6) :836." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminant analysis with graph learning for hyperspectral image classification">
                                        <b>[4]</b>
                                         CHEN Mulin, WANG Qi, LI Xuelong.Discriminant analysis with graph learning for hyperspectral image classification[J].Remote Sensing, 2018, 10 (6) :836.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" FENG Fubiao, LI Wei, DU Qian, et al.Dimensionality reduction of hyperspectral image with graph-based discriminant analysis considering spectral similarity[J].Remote Sensing, 2017, 9 (4) :323." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction of hyperspectral image with graph-based discriminant analysis considering spectral similarity">
                                        <b>[5]</b>
                                         FENG Fubiao, LI Wei, DU Qian, et al.Dimensionality reduction of hyperspectral image with graph-based discriminant analysis considering spectral similarity[J].Remote Sensing, 2017, 9 (4) :323.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201703019&amp;v=MzEzMDBGckNVUjdxZlp1ZHZGeTNrV3IzT0ppWFRiTEc0SDliTXJJOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" WANG Hao, FAN Yuanyuan, FANG Baofu, et al.Generalized linear discriminant analysis based on Euclidean norm for gait recognition[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (4) :569-576." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized linear discriminant analysis based on euclidean norm for gait recognition">
                                        <b>[7]</b>
                                         WANG Hao, FAN Yuanyuan, FANG Baofu, et al.Generalized linear discriminant analysis based on Euclidean norm for gait recognition[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (4) :569-576.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" FAN Mingyu, ZHANG Xianqin, QIAO Hong, et al.Efficient isometric multi-manifold learning based on the self-organizing method[J].Information Sciences, 2016 (345) :325-339." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES79402B4CA13F81C0D37DCA8897CA961B&amp;v=Mjg2ODJPR1FsZkJyTFUwNTlsaHdibTJ3cTQ9TmlmT2ZiU3hHdEhPM1lzMkZlb01lblE0dkJabjZUZ0pPdzdxcEJzeUNzT2RRN3Z0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         FAN Mingyu, ZHANG Xianqin, QIAO Hong, et al.Efficient isometric multi-manifold learning based on the self-organizing method[J].Information Sciences, 2016 (345) :325-339.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" 王东, 张强, 严亮.一种融合聚类的监督局部线性嵌入算法研究[J].半导体光学, 2017, 38 (3) :419-424.WANG Dong, ZHANG Qiang, YAN Liang.Study on supervised local linear embedding algorithm based on fusion clustering[J].Semiconductor Optoelectronics, 2017, 38 (3) :419-424." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BDTG201703024&amp;v=MDUyNTMzenFxQnRHRnJDVVI3cWZadWR2Rnkza1dyM09KeW5mYWJHNEg5Yk1ySTlIWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         王东, 张强, 严亮.一种融合聚类的监督局部线性嵌入算法研究[J].半导体光学, 2017, 38 (3) :419-424.WANG Dong, ZHANG Qiang, YAN Liang.Study on supervised local linear embedding algorithm based on fusion clustering[J].Semiconductor Optoelectronics, 2017, 38 (3) :419-424.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" WANG Qi, MENG Zhaotie, LI Xuelong.Locality adaptive discriminant analysis for spectral-spatial classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (11) :2077-2081." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locality adaptive discriminant analysis for spectral-spatial classification of hyperspectral images">
                                        <b>[10]</b>
                                         WANG Qi, MENG Zhaotie, LI Xuelong.Locality adaptive discriminant analysis for spectral-spatial classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (11) :2077-2081.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" JIANG Quansheng, ZHU Qixin, WANG Bangfu, et al.Nonlinear machine fault detection by semi-supervised Laplacian eigenmaps[J].Journal of Mechanical Science and Technology, 2017, 31 (8) :3697-3703." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD72DCFD62D7B35172FDBDBC583F6E37CF&amp;v=MzA1NThsSEVPeDlEM2s0eUJSbG5rMEpPZ3pucEJGRGY4ZVhRc25wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxod2JtMndxND1OajdCYXJTNmFxSzYyNA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         JIANG Quansheng, ZHU Qixin, WANG Bangfu, et al.Nonlinear machine fault detection by semi-supervised Laplacian eigenmaps[J].Journal of Mechanical Science and Technology, 2017, 31 (8) :3697-3703.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images">
                                        <b>[12]</b>
                                         DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" KUMAR S, BHUYAN M K, LOVELL B C, et al.Hierarchical uncorrelated multiview discriminant locality preserving projection for multiview facial expression recognition[J].Journal of Visual Communication and Image Representation, 2018 (54) :171-181." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFDF700E0F1443CB416062FEF3537F586&amp;v=MzA5NTBFd2VyWGlRTEtaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxod2JtMndxND1OaWZPZmNYTWFOYk1yL3BGRXVvTENIOUt2UklTN0Q5N1NnbVgyaA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         KUMAR S, BHUYAN M K, LOVELL B C, et al.Hierarchical uncorrelated multiview discriminant locality preserving projection for multiview facial expression recognition[J].Journal of Visual Communication and Image Representation, 2018 (54) :171-181.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" TAŞKIN G, KAYA H, BRUZZONE L.Feature selection based on high dimensional model representation for hyperspectral images[J].IEEE Transactions on Image Processing, 2017, 26 (6) :2918-2928." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature selection based on high dimensional model representation for hyperspectral images">
                                        <b>[14]</b>
                                         TAŞKIN G, KAYA H, BRUZZONE L.Feature selection based on high dimensional model representation for hyperspectral images[J].IEEE Transactions on Image Processing, 2017, 26 (6) :2918-2928.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" LUO Fulin, HUANG Hong, DUAN Yule, et al.Local geometric structure feature for dimensionality reduction of hyperspectral imagery[J].Remote Sensing, 2017, 9 (8) :790." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local geometric structure feature for dimensionality reduction of hyperspectral imagery">
                                        <b>[15]</b>
                                         LUO Fulin, HUANG Hong, DUAN Yule, et al.Local geometric structure feature for dimensionality reduction of hyperspectral imagery[J].Remote Sensing, 2017, 9 (8) :790.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimension Reduction Using Spatial and Spectral Regularized Local Discriminant Embedding for Hyperspectral Image Classification">
                                        <b>[16]</b>
                                         ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" YUAN Haoliang, TANG Yuanyan.Learning with hypergraph for hyperspectral image feature extraction[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (8) :1695-1699." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning with hypergraph for hyperspectral image feature extraction">
                                        <b>[17]</b>
                                         YUAN Haoliang, TANG Yuanyan.Learning with hypergraph for hyperspectral image feature extraction[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (8) :1695-1699.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" DU Weibao, QIANG Wenwen, L&#220; Meng, et al.Semi-supervised dimension reduction based on hypergraph embedding for hyperspectral images[J].International Journal of Remote Sensing, 2018, 39 (6) :1696-1712." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDDE52746DC12B6C72A02BAE408E10CF02&amp;v=MjU5MjZmQnJMVTA1OWxod2JtMndxND1Oam5CYXNmTkc5UExxNGt4RitvTmZucEt5QlJpNmowUE9Rcm1yQnBBZUxMbk03cWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         DU Weibao, QIANG Wenwen, L&#220; Meng, et al.Semi-supervised dimension reduction based on hypergraph embedding for hyperspectral images[J].International Journal of Remote Sensing, 2018, 39 (6) :1696-1712.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" HUANG Sheng, YANG Dan, GE Yongxin, et al.Discriminant hyper-Laplacian projections and its scalable extension for dimensionality reduction[J].Neurocomputing, 2016, 173 (2) :145-153." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFB56849B2429CACA685556250B751114&amp;v=MTYyOThZM1p1OE5CUTlJdkdjVjRqcDRUWG5ncVJKSGZyZVZSTHViQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxod2JtMndxND1OaWZPZmNYS0c5ZkVxNA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         HUANG Sheng, YANG Dan, GE Yongxin, et al.Discriminant hyper-Laplacian projections and its scalable extension for dimensionality reduction[J].Neurocomputing, 2016, 173 (2) :145-153.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" ZHANG Zhihong, BAI Lu, LIANG Yuanheng, et al.Joint hypergraph learning and sparse regression for feature selection[J].Pattern Recognition, 2017 (63) :291-309." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint hypergraph learning and sparse regression for feature selection">
                                        <b>[20]</b>
                                         ZHANG Zhihong, BAI Lu, LIANG Yuanheng, et al.Joint hypergraph learning and sparse regression for feature selection[J].Pattern Recognition, 2017 (63) :291-309.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" WU Zebin, SHI Linlin, LI Jun, et al.GPU parallel implementation of spatially adaptive hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2018, 11 (4) :1131-1143." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPU parallel implementation of spatially adaptive hyperspectral image classification">
                                        <b>[21]</b>
                                         WU Zebin, SHI Linlin, LI Jun, et al.GPU parallel implementation of spatially adaptive hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2018, 11 (4) :1131-1143.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" 黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201608012&amp;v=MTUwMTM0OUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrV3IzT0ppWFRiTEc0SDlmTXA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" SUN Yubao, WANG Sujuan, LIU Qingshan, et al.Hypergraph embedding for spatial-spectral joint feature extraction in hyperspectral images[J].Remote Sensing, 2017, 9 (5) :506." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hypergraph embedding for spatial-spectral joint feature extraction in hyperspectral images">
                                        <b>[23]</b>
                                         SUN Yubao, WANG Sujuan, LIU Qingshan, et al.Hypergraph embedding for spatial-spectral joint feature extraction in hyperspectral images[J].Remote Sensing, 2017, 9 (5) :506.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" SUN Tao, YIN Penghang, CHENG Lizhi, et al.Alternating direction method of multipliers with difference of convex functions[J].Advances in Computational Mathematics, 2018, 44 (3) :723-744." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Alternating direction method of multipliers with difference of convex functions">
                                        <b>[24]</b>
                                         SUN Tao, YIN Penghang, CHENG Lizhi, et al.Alternating direction method of multipliers with difference of convex functions[J].Advances in Computational Mathematics, 2018, 44 (3) :723-744.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" SUN Yanfeng, ZHAO Jiangang, HU Yongli.Supervised sparsity preserving projections for face recognition[C]//Proceedings of SPIE 8009, Third International Conference on Digital Image Processing.Chengdu, China:SPIE, 2011:357-366." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised sparsity preserving projections for face recognition">
                                        <b>[25]</b>
                                         SUN Yanfeng, ZHAO Jiangang, HU Yongli.Supervised sparsity preserving projections for face recognition[C]//Proceedings of SPIE 8009, Third International Conference on Digital Image Processing.Chengdu, China:SPIE, 2011:357-366.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(06),676-687 DOI:10.11947/j.AGCS.2019.20180469            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>空-谱协同正则化稀疏超图嵌入的高光谱图像分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E9%B8%BF&amp;code=10191717&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄鸿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E7%BE%8E%E5%88%A9&amp;code=38226342&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈美利</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%BD%E5%8D%8E&amp;code=25212776&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王丽华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%94%BF%E8%8B%B1&amp;code=39098262&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李政英</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E6%8A%80%E6%9C%AF%E4%B8%8E%E7%B3%BB%E7%BB%9F%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0109290&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆大学光电技术与系统教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统依据图嵌入的高光谱图像维数约简算法多数仅利用光谱信息表征像元间单一关系, 忽视了数据间的多元几何结构。本文提出了一种面向高光谱图像分类的空-谱协同正则化稀疏超图嵌入算法 (SSRSHE) 。该算法首先利用稀疏表示揭示像元之间的相关性, 自适应选择近邻, 并构建稀疏本征超图和惩罚超图, 以有效表征像元间的复杂多元关系, 并进行正则化处理。然后利用遥感图像空间一致性原则, 计算局部空间邻域散度来保持样本局部邻域结构, 并引入样本总体散度来保持高光谱数据的整体结构。在低维嵌入空间中, 尽可能使类内数据聚集、类间数据远离, 提取鉴别特征用于分类。在Indian Pines和PaviaU高光谱遥感数据集上试验结果表明, 本文算法总体分类精度分别达到86.7%和92.2%。相比传统光谱维数约简算法, 该算法可有效改善高光谱图像地物分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%B4%E6%95%B0%E7%BA%A6%E7%AE%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">维数约简;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A3%E5%88%99%E5%8C%96%E7%A8%80%E7%96%8F%E8%B6%85%E5%9B%BE%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">正则化稀疏超图模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA-%E8%B0%B1%E8%81%94%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空-谱联合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黄鸿 (1980—) , 男, 教授, 博士生导师, 研究方向为流形学习、模式识别、遥感影像智能化处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>重庆市基础研究与前沿探索项目 (cstc2018jcyjAX0093);</span>
                                <span>重庆市研究生科研创新项目 (CYB18048;CYS18035);</span>
                    </p>
            </div>
                    <h1>Using spatial-spectral regularized hypergraph embedding for hyperspectral image classification</h1>
                    <h2>
                    <span>HUANG Hong</span>
                    <span>CHEN Meili</span>
                    <span>WANG Lihua</span>
                    <span>LI Zhengying</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of Optoelectronic Technique System of the Ministry of Education, Chongqing University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In recent years, many graph embedding methods were developed for dimensionality reduction (DR) of hyperspectral image (HSI) , while these methods only use spectral information to reveal a simple intrinsic relation and ignore complex spatial-spectral structure in HSI. A new DR method termed spatial-spectral regularized sparse hypergraph embedding (SSRSHE) is proposed for the HSI classification. SSRSHE explores sparse coefficients to adaptively select neighbors for constructing the regularized sparse intrinsic hypergraph and the regularized sparse penalty hypergraph. Based on the spatial consistency property of HSI, a local spatial neighborhood scatter is computed to preserve local structure, and a total scatter is computed for global structure of HSI. Then, the optimal discriminant projection is obtained by possessing better intrinsic data compactness and penalty pixels separability, which is beneficial for classification. The experimental results on Indian Pines and PaviaU hyperspectral data sets show that the overall classification accuracies respectively reach 86.7% and 92.2%. The proposed SSRSHE method can effectively improve classification performance compared with the traditional spectral DR algorithms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dimensionality%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dimensionality reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=regularized%20sparse%20hypergraph&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">regularized sparse hypergraph;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial-spectral%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial-spectral features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HUANG Hong (1980—) , male, professor, PhD supervisor, majors in manifold learning, pattern recognition and intelligent processing of remote sensing images.E-mail: hhuang@cqu.edu.cn;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The Basic and Frontier Research Programmes of Chongqing (No.cstc2018jcyjAX0093);</span>
                                <span>The Chongqing University Postgraduates Innovation Project (Nos.CYB18048;CYS18035);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="52">高光谱遥感图像通过从可见光到短波红外区域的密集光谱采样, 可在数百个窄而连续的相邻光谱波段中提供空间场景, 包含了丰富的空间、辐射和光谱信息, 为地物精细分类提供了强有力的探测手段, 目前已广泛应用于矿物勘探、环境监测、精准农业和目标识别等领域<citation id="239" type="reference"><link href="2" rel="bibliography" /><link href="4" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。然而, 高光谱数据具有数据量大、波段数多、波段间相关性强等特点, 传统方法易导致“维数灾难”问题<citation id="240" type="reference"><link href="6" rel="bibliography" /><link href="8" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。因此, 如何减少波段数且尽量保留有用信息已成为高光谱遥感领域的研究热点问题。</p>
                </div>
                <div class="p1">
                    <p id="53">维数约简是克服数据冗余的有效方法, 可在降低数据维数的同时尽可能保留数据中的本征信息<citation id="241" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。目前学者们提出了一系列的维数约简方法, 如主成分分析 (principal component analysis, PCA) <citation id="242" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、线性判别分析 (linear discriminant analysis, LDA) <citation id="243" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、等距映射 (isometric feature mapping, ISOMAP) <citation id="244" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、局部线性嵌入 (local linear embedding, LLE) <citation id="245" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、邻域保持嵌入 (neighborhood preserving embedding, NPE) <citation id="246" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、拉普拉斯等距离映射 (Laplacian eigenmaps, LE) <citation id="247" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>及局部保持投影 (locality preserving projection, LPP) <citation id="248" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。上述方法可统一在图嵌入框架 (graph embedding, GE) <citation id="251" type="reference"><link href="26" rel="bibliography" /><link href="28" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>下, 其异于如何定义本征图和惩罚图, 但都为非监督方法, 其分类性能受限。针对此问题, 学者们通过将样本先验知识引入到图嵌入框架来改善分类性能, 提出了边缘Fisher分析 (marginal Fisher analysis, MFA) <citation id="249" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和正则化局部判别嵌入 (regularized local discriminant embedding, RLDE) <citation id="250" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>等监督学习方法, 以提升分类精度。</p>
                </div>
                <div class="p1">
                    <p id="54">然而, 直接图嵌入方法只考虑数据间一元关系, 在实际应用中高维数据通常具有复杂的多元几何结构<citation id="254" type="reference"><link href="34" rel="bibliography" /><link href="36" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>。为表征高维数据中的复杂结构, 学者们试图引入超图学习来表示高光谱数据间的高阶关系。文献<citation id="252" type="reference">[<a class="sup">19</a>]</citation>提出了一种判别超-拉普拉斯投影 (discriminant hyper-Laplacian projections, DHLP) 方法, 通过构造超图来获得超-拉普拉斯矩阵, 实现维数约简。文献<citation id="253" type="reference">[<a class="sup">20</a>]</citation>提出了一种超图拉普拉斯联合稀疏化处理方法来分析像元的内在关系, 以提取低维特征进行分类。</p>
                </div>
                <div class="p1">
                    <p id="55">上述方法仅利用了样本的光谱信息, 却忽略了像元之间的空间位置关系, 而研究表明空-谱联合维数约简方法可明显提高地物分类性能。文献<citation id="255" type="reference">[<a class="sup">21</a>]</citation>通过空间自适应方法提取影像的空间特征和光谱特征, 在分类精度和计算效率上均取得了较好效果。文献<citation id="256" type="reference">[<a class="sup">22</a>]</citation>提出了一种空-谱协同嵌入方法 (spatial-spectral coordination embedding, SSCE) , 利用样本空间块替代单个样本度量数据间相似性, 降低异类地物被选为近邻的概率, 从而改善地物分类效果。与此同时, 空间信息也被引入超图模型中, 文献<citation id="257" type="reference">[<a class="sup">17</a>]</citation>提出了一种融合空-谱信息的超图嵌入方法, 利用像元空间邻域构造超边, 能有效提取低维特征, 但忽视了像元的类别信息。在文献<citation id="258" type="reference">[<a class="sup">23</a>]</citation>中, 通过像元波段选取提取扩展形态学特征, 并与光谱信息融合来构建超图模型, 提取嵌入特征以提升地物分类性能。上述空-谱联合维数约简方法, 或是忽略了像元间多元几何结构关系, 或是在构造超图模型时没有充分利用样本标签信息, 限制了分类性能的进一步提升。</p>
                </div>
                <div class="p1">
                    <p id="56">针对上述问题, 本文提出了一种空-谱协同正则化稀疏超图嵌入方法 (spatial-spectral regularized sparse hypergraph embedding, SSRSHE) 。该方法运用稀疏系数自适应揭示数据间近邻关系, 并结合类别信息构建正则化稀疏超图, 从而有效表征高光谱数据的多元几何结构。同时, 融入图像的空间信息, 构造局部空间邻域散度来表征样本局部邻域结构, 同时定义样本总体散度矩阵来保证数据全局信息, 提取有效鉴别特征, 实现维数约简。在Indian Pines和PaviaU高光谱数据集上验证了本文算法的有效性。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">1 本文算法</h3>
                <div class="p1">
                    <p id="58">假设文中高光谱数据集<b><i>Z</i></b>=[<b><i>z</i></b><sub>1</sub>, <b><i>z</i></b><sub>2</sub>, …, <b><i>z</i></b><sub><i>i</i></sub>, …, <b><i>z</i></b><sub><i>n</i></sub>]∈<b><i>R</i></b><sup><i>d</i>×<i>n</i></sup>, 其中<i>d</i>为波段数, <i>n</i>为样本数, 类别标签集<b><i>L</i></b>=[<i>l</i><sub>1</sub>, <i>l</i><sub>2</sub>, …, <i>l</i><sub><i>i</i></sub>, …, <i>l</i><sub><i>n</i></sub>], <i>l</i><sub><i>i</i></sub>∈{1, 2, …, <i>u</i>}, 其中<i>u</i>为样本类别数。低维嵌入特征可表示为<b><i>Y</i></b>=<b><i>P</i></b><sup>T</sup><b><i>Z</i></b>, <b><i>Y</i></b>∈<b><i>R</i></b><sup><i>τ</i>×<i>n</i></sup>, <i>τ</i> (<i>τ</i>&lt;&lt;<i>d</i>) 为嵌入维数, <b><i>P</i></b>∈<b><i>R</i></b><sup><i>d</i>×<i>τ</i></sup>为映射矩阵。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">1.1 图嵌入学习</h4>
                <div class="p1">
                    <p id="60">为更好地理解维数约简算法, 学者们提出了一种图嵌入框架 (GE) 来表示数据几何结构, 并将PCA、LDA、ISOMAP、LLE、LE、NPE及LPP等算法统一到该框架中。在图嵌入框架下, 需构建本征图和惩罚图两个无向图。本征图<i>G</i><sup><i>I</i></sup> (<i>V</i>, <b><i>W</i></b><sup><i>I</i></sup>) 表征数据中需要保持的统计或几何性质, 惩罚图<i>G</i><sup><i>P</i></sup> (<i>V</i>, <b><i>W</i></b><sup><i>P</i></sup>) 描述数据中应避免的某种特性, 其中<i>V</i>为顶点集, <b><i>W</i></b><sup><i>I</i></sup>和<b><i>W</i></b><sup><i>P</i></sup>分别为图<i>G</i><sup><i>I</i></sup>和<i>G</i><sup><i>P</i></sup>的权重矩阵, 可通过简单法或热核函数来定义。</p>
                </div>
                <div class="p1">
                    <p id="61">图嵌入框架意在低维空间中保留数据集的某些统计或几何属性, 其低维嵌入特征可通过优化以下目标函数得到</p>
                </div>
                <div class="area_img" id="62">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="63">式中, <b><i>D</i></b><sup><i>I</i></sup>是对角矩阵, 且<i>D</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow><mi>Ι</mi></msubsup></mrow></math></mathml>=∑<sub><i>j</i></sub><i>w</i><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>Ι</mi></msubsup></mrow></math></mathml>;<b><i>L</i></b><sup><i>I</i></sup>=<b><i>D</i></b><sup><i>I</i></sup>-<b><i>W</i></b><sup><i>I</i></sup>为本征图<i>G</i><sup><i>I</i></sup>的拉普拉斯矩阵;<b><i>C</i></b>为一常量矩阵;<b><i>H</i></b>为约束矩阵, 可为单位阵以实现归一化处理, 或为惩罚图<i>G</i><sup><i>P</i></sup>的拉普拉斯矩阵, 即<b><i>H</i></b>=<b><i>L</i></b><sup><i>P</i></sup>=<b><i>D</i></b><sup><i>P</i></sup>-<b><i>W</i></b><sup><i>P</i></sup>, <i>D</i><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow><mi>Ρ</mi></msubsup></mrow></math></mathml>=∑<sub><i>j</i></sub><i>w</i><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>Ρ</mi></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">1.2 超图模型</h4>
                <div class="p1">
                    <p id="69">直接图嵌入模型仅考虑了两点间一阶关系, 而超图模型能有效表征数据间的多元特性<citation id="259" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。超图模型可表示为<i>G</i><sub><i>H</i></sub>= (<i>V</i><sub><i>H</i></sub>, <i>E</i><sub><i>H</i></sub>, <b><i>W</i></b><sub><i>H</i></sub>) , 其中<i>V</i><sub><i>H</i></sub>表示顶点集, <i>E</i><sub><i>H</i></sub>为超边集, 对应的相似权重矩阵是<b><i>W</i></b><sub><i>H</i></sub>, 以度量超边内各顶点间相关性。</p>
                </div>
                <div class="p1">
                    <p id="70">为表示<i>G</i><sub><i>H</i></sub>的内在关系, 假设每一超边<i>e</i><sub><i>i</i></sub>含有<i>N</i> (<i>e</i><sub><i>i</i></sub>) 个顶点, 其权重表示为<i>w</i> (<i>e</i><sub><i>i</i></sub>) ∈<i>E</i><sub><i>H</i></sub>, 则关联矩阵<b><i>H</i></b>=[<i>H</i><sub><i>mn</i></sub>:<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold-italic">R</mi><msup><mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>E</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow><mo>|</mo></mrow></mrow></msup><msup><mrow></mrow><mrow><mo>×</mo><mrow><mo>|</mo><mrow><mi>V</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>、超边<i>e</i><sub><i>m</i></sub>的度<i>d</i> (<i>e</i><sub><i>m</i></sub>) 和顶点<i>v</i><sub><i>n</i></sub>的度<i>d</i> (<i>v</i><sub><i>n</i></sub>) 可分别定义为</p>
                </div>
                <div class="area_img" id="72">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="74"><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>|</mo></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><msub><mrow></mrow><mi>n</mi></msub><mo>∈</mo><mi>V</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></munder><mi>Η</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub><mo>∈</mo><mi>E</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msub></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="78">式中, <image id="79" type="formula" href="images/CHXB201906003_07900.jpg" display="inline" placement="inline"><alt></alt></image>, 即值等于超边内目标像素与其近邻点权重之和;<i>h</i>为热核系数。</p>
                </div>
                <div class="p1">
                    <p id="80">综上, 超图内每一超边由某一像元与其近邻点构成, 揭示数据间内在多元关系。其对应的关联矩阵<b><i>H</i></b>, 每行中的非零元素, 描述每一超边内各点分布情况。超图通过多对顶点连通以表征邻域内顶点间多元结构, 因而可更好地描述数据中多元关系。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">1.3 SSRSHE算法</h4>
                <div class="p1">
                    <p id="82">为表征高光谱数据中的多元几何结构关系, 并联合像元的空间-光谱信息, 本文提出了一种空-谱协同正则化稀疏超图嵌入 (SSRSHE) 方法。首先利用样本的稀疏系数来自适应性选择其近邻, 构建稀疏本征超图和惩罚超图来揭示高光谱数据间的多元结构。同时, 依据空间一致性原理构造局部空间邻域散度以保持像元局部空间近邻关系, 并采用样本总体散度来表征高光谱数据整体特性。在低维鉴别空间中, 使类内数据尽可能聚集、类间数据尽可能发散, 提取鉴别特征, 提升地物分类性能。该算法的具体流程如图1所示。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SSRSHE算法流程" src="Detail/GetImg?filename=images/CHXB201906003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SSRSHE算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flowchart of the proposed SSRSHE method</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84">1.3.1 正则化稀疏超图模型构建</h4>
                <div class="p1">
                    <p id="85">在构建超图时, 首先需要选择合适的样本近邻点。目前的欧氏距离度量方法存在近邻点选取不准确及参数难以确定等问题, 而稀疏表示具有自然鉴别力能自适应地揭示出数据的内在关系。某个样本可以由一个足够大的样本空间来近似线性表示, 且表示系数大部分为零, 只有极少数与该样本同类别数据对应的系数为非零, 因此可反映数据的本征属性。</p>
                </div>
                <div class="p1">
                    <p id="86">基于此, 本文提出了一种正则化稀疏超图模型, 首先通过稀疏表示<citation id="260" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>得到数据的稀疏系数矩阵, 揭示数据内在关联特性, 以自适应获取像元近邻。稀疏系数可通过以下<i>l</i><sub>1</sub>范数求解</p>
                </div>
                <div class="area_img" id="87">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="89">式中, <i>ε</i>为稀疏误差;<b><i>E</i></b>是全为1的向量。在具体计算中, 可通过将式 (5) 问题进一步转化为Lasso问题求解<citation id="261" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>, 即可得到稀疏系数矩阵<b><i>S</i></b>=[<b><i>s</i></b><sub>1</sub>, <b><i>s</i></b><sub>2</sub>, …, <b><i>s</i></b><sub><i>n</i></sub>]<sup>T</sup>。</p>
                </div>
                <div class="p1">
                    <p id="90">图2为基于稀疏系数自适应选取近邻构造超边示意图。因稀疏系数可反映数据间相似性, 对应系数非零则表示像元间具有相关性, 其值越大则属于同类近邻点可能性越大。因此相比欧氏度量, 利用稀疏系数自适应选择近邻能更为有效反映数据内蕴信息。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于稀疏系数的自适应选取近邻构造超边" src="Detail/GetImg?filename=images/CHXB201906003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于稀疏系数的自适应选取近邻构造超边  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Construction of sparse hyperedge</p>

                </div>
                <div class="p1">
                    <p id="92">根据样本稀疏特性和类别信息, 构建稀疏本征超图<i>G</i><sup><i>w</i></sup>={<i>Z</i>, <i>E</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>w</mi></msubsup></mrow></math></mathml>, <b><i>W</i></b><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>w</mi></msubsup></mrow></math></mathml>}, 揭示类内数据的本征特性;同时, 构建稀疏惩罚超图<i>G</i><sup><i>b</i></sup>={<i>Z</i>, <i>E</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>b</mi></msubsup></mrow></math></mathml>, <b><i>W</i></b><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>b</mi></msubsup></mrow></math></mathml>}, 表征异类数据间几何结构;其中<b><i>Z</i></b>为顶点集, <i>E</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>w</mi></msubsup></mrow></math></mathml>、<i>E</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>b</mi></msubsup></mrow></math></mathml>分别是本征超边集和惩罚超边集, 对应权重矩阵为<b><i>W</i></b><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>w</mi></msubsup></mrow></math></mathml>、<b><i>W</i></b><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Η</mi><mi>b</mi></msubsup></mrow></math></mathml>。在稀疏本征超图<i>G</i><sup><i>w</i></sup>中, 根据稀疏系数矩阵具有的自适应表征能力, 本征超边<i>e</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>由样本<b><i>z</i></b><sub><i>i</i></sub>与其对应稀疏系数非零点连接而成。则其超边权值<i>w</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>w</mi></msubsup></mrow></math></mathml>可定义为</p>
                </div>
                <div class="area_img" id="103">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">式中, <i>s</i><sub><i>ij</i></sub>为稀疏系数矩阵<b><i>S</i></b>中第<i>i</i>行第<i>j</i>列元素, 以表征像元<b><i>z</i></b><sub><i>i</i></sub>和<b><i>z</i></b><sub><i>j</i></sub>互相关程度;系数<i>α</i> (<i>α</i>&gt;1) 用于调节同类像元权重, 强化同类样本贡献率, 进而提升分类性能。由此, 本征超边<i>e</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>的相似权重<i>w</i> (<i>e</i><sup><i>w</i></sup><sub><i>i</i></sub>) 为</p>
                </div>
                <div class="p1">
                    <p id="107"><i>w</i> (<i>e</i><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>) =∑<sub><i>z</i><sub><i>j</i></sub>∈<i>N</i> (<i>e</i><sup><i>w</i></sup><sub><i>i</i></sub>) </sub><i>w</i><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>w</mi></msubsup></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="110">式中, <i>N</i> (<i>e</i><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>) 表示本征超边<i>e</i><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>包含的顶点数目。</p>
                </div>
                <div class="p1">
                    <p id="113">同时, 稀疏本征超图的关联矩阵<b><i>H</i></b><sup><i>w</i></sup>=[<i>H</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>w</mi></msubsup></mrow></math></mathml>:<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>e</mi><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>E</mi><msup><mrow></mrow><mi>w</mi></msup></mrow><mo>|</mo></mrow></mrow></msup><msup><mrow></mrow><mrow><mo>×</mo><mrow><mo>|</mo><mi>Ζ</mi><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>计算如下</p>
                </div>
                <div class="area_img" id="116">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_11600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="118">式中, <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>j</mi></msub><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>i</mi></msub><mrow><msqrt><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></msqrt></mrow></mstyle></mrow></mstyle><mo>/</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>e</mi><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>。根据<b><i>H</i></b><sup><i>w</i></sup>和<i>w</i> (<i>e</i><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>) , 计算像元<b><i>z</i></b><sub><i>i</i></sub>与超边<b><i>e</i></b><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>的度</p>
                </div>
                <div class="p1">
                    <p id="122"><i>θ</i><mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>=<i>d</i> (<b><i>z</i></b><sub><i>i</i></sub>, <i>e</i><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup></mrow></math></mathml>) =∑<sub><i>j</i></sub><i>w</i> (<i>e</i><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup></mrow></math></mathml>) <i>h</i> (<i>e</i><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup></mrow></math></mathml>, <b><i>z</i></b><sub><i>i</i></sub>) =∑<sub><i>j</i></sub><i>w</i> (<i>e</i><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup></mrow></math></mathml>) <i>H</i><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>w</mi></msubsup></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="130"><mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϑ</mtext><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup><mo>=</mo><mi>d</mi><mrow><mo> (</mo><mrow><mi>e</mi><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>j</mi></msub><mi>h</mi></mstyle><mrow><mo> (</mo><mrow><mi>e</mi><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>j</mi></msub><mi>Η</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>w</mi></msubsup></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="132">同理, 在稀疏惩罚超图<i>G</i><sup><i>b</i></sup>中, 惩罚超边<i>e</i><mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>由样本<b><i>z</i></b><sub><i>i</i></sub>与其对应稀疏系数非零且类别不同的点连接而成, 其边权值可定义为</p>
                </div>
                <div class="area_img" id="134">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="136">由式 (11) 可获取惩罚超边<i>e</i><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>的权重<i>w</i> (<i>e</i><mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>) , 表述了<b><i>z</i></b><sub><i>i</i></sub>与其不同类近邻样本间的相似特性</p>
                </div>
                <div class="p1">
                    <p id="139"><i>w</i> (<i>e</i><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>) =∑<sub><b><i>z</i></b><sub><i>j</i></sub>∈<i>N</i> (<i>e</i><sup><i>b</i></sup><sub><i>i</i></sub>) </sub><i>w</i><mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>b</mi></msubsup></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="142">式中, <i>N</i> (<i>e</i><mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>) 表示惩罚超边<i>e</i><mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>含有的顶点数。</p>
                </div>
                <div class="p1">
                    <p id="145">其对应的关联矩阵<b><i>H</i></b><sup><i>b</i></sup>=[<i>H</i><mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>b</mi></msubsup></mrow></math></mathml>:<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>e</mi><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>E</mi><msup><mrow></mrow><mi>b</mi></msup></mrow><mo>|</mo></mrow></mrow></msup><msup><mrow></mrow><mrow><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Ζ</mi><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>可表示为</p>
                </div>
                <div class="area_img" id="148">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="150">由式 (13) 求解顶点<b><i>z</i></b><sub><i>i</i></sub>和惩罚超边<i>e</i><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>的度分别是</p>
                </div>
                <div class="p1">
                    <p id="152"><i>θ</i><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>=<i>d</i> (<b><i>z</i></b><sub><i>i</i></sub>, <i>e</i><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup></mrow></math></mathml>) =∑<sub><i>j</i></sub><i>w</i> (<i>e</i><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup></mrow></math></mathml>) <i>h</i> (<i>e</i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup></mrow></math></mathml>, <b><i>z</i></b><sub><i>i</i></sub>) =∑<sub><i>j</i></sub><i>w</i> (<i>e</i><mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>b</mi></msubsup></mrow></math></mathml>) <i>H</i><mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>b</mi></msubsup></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="160">ϑ<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>=<i>d</i> (<i>e</i><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>) =∑<sub><i>j</i></sub><i>h</i> (<i>e</i><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>b</mi></msubsup></mrow></math></mathml>, <b><i>z</i></b><sub><i>j</i></sub>) =∑<sub><i>j</i></sub><i>H</i><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>b</mi></msubsup></mrow></math></mathml>      (15) </p>
                </div>
                <div class="p1">
                    <p id="165">在低维映射空间中, 为提取鉴别特征, 应使同类数据尽可能聚集、不同类数据尽可能远离, 因此目标函数可表示为</p>
                </div>
                <div class="area_img" id="166">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_16600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="168">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="170">式中, <mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>w</mi></msup><mo>=</mo><mi mathvariant="bold-italic">D</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">z</mi><mi>w</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mi>w</mi></msup><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>w</mi></msup><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">D</mi><msubsup><mrow></mrow><mi>e</mi><mi>w</mi></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mi>w</mi></msup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>和<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>b</mi></msup><mo>=</mo><mi mathvariant="bold-italic">D</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">z</mi><mi>b</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mi>b</mi></msup><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>b</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">D</mi><msubsup><mrow></mrow><mi>e</mi><mi>b</mi></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mi>b</mi></msup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>分别是G<sup>w</sup>和G<sup>b</sup>对应的拉普拉斯矩阵;<b><i>D</i></b><sup><i>w</i></sup><sub><b><i>z</i></b></sub>、<b><i>D</i></b><sup><i>b</i></sup><sub><b><i>z</i></b></sub>分别为<i>θ</i><sup><i>w</i></sup>和<i>θ</i><sup><i>b</i></sup>对角阵;<b><i>D</i></b><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>e</mi><mi>w</mi></msubsup></mrow></math></mathml>表示本征超边度对角矩阵, <b><i>D</i></b><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>e</mi><mi>b</mi></msubsup></mrow></math></mathml>代表惩罚超边度对角矩阵。稀疏本征超图保持了同类样本的聚集性, 而稀疏惩罚超图避免了非同类样本在低维嵌入空间内过于接近。</p>
                </div>
                <div class="p1">
                    <p id="175">由式 (16) 、式 (17) 中的目标函数, 可进一步转化为以下最优化问题</p>
                </div>
                <div class="area_img" id="262">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201906003_26200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="178">在训练样本较少的情况下, 式 (18) 易受奇异点影响。故在此引入正则化项, 则式 (18) 中的优化问题可拓展为</p>
                </div>
                <div class="p1">
                    <p id="179"><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></mstyle><mi mathvariant="bold-italic">Ρ</mi></munder><mfrac><mrow><mtext>t</mtext><mtext>r</mtext><mrow><mo>{</mo><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>b</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ρ</mi><mo>+</mo><mi>η</mi><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ρ</mi></mrow><mo>}</mo></mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mrow><mo>{</mo><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>η</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>w</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ρ</mi><mo>+</mo><mi>η</mi><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>w</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi mathvariant="bold-italic">Ρ</mi></mrow><mo>}</mo></mrow></mrow></mfrac></mrow></math></mathml>      (19) </p>
                </div>
                <div class="p1">
                    <p id="181">式中, <i>η</i> (0&lt;<i>η</i>&lt;1) 表示正则化参数。正则项<b><i>ZZ</i></b><sup>T</sup>用于保持样本的多样性。将<b><i>ZL</i></b><sup><i>w</i></sup><b><i>Z</i></b><sup>T</sup>对角化, 以改善式 (19) 问题求解的稳定性, 即其对应的特征值在较大时可自适应减小, 在极小或是零时增大。因此, 式中分母项矩阵满足非奇异性。假如<i>η</i>=0, 式 (19) 即为式 (18) ;若<i>η</i>=1, 以单位矩阵替代对角矩阵, 式 (19) 则等效为PCA。</p>
                </div>
                <h4 class="anchor-tag" id="182" name="182">1.3.2 局部空间邻域散度和总体散度计算</h4>
                <div class="p1">
                    <p id="183">鉴于高光谱图像空间一致性特点, 即在空间局部邻域内近邻属于同类概率较大。以像元<b><i>z</i></b><sub><i>i</i></sub>: (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) 为中心作方形窗口<i>δ</i> (<b><i>z</i></b><sub><i>i</i></sub>) , (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) 为<b><i>z</i></b><sub><i>i</i></sub>在图像中的空间坐标位置, 则窗口为<i>γ</i>×<i>γ</i> (<i>γ</i>是正奇数) 的空间邻域像元集可记作</p>
                </div>
                <div class="p1">
                    <p id="184"><i>δ</i> (<b><i>z</i></b><sub><i>i</i></sub>) ={<b><i>z</i></b><sub><i>im</i></sub>: (<i>x</i><sub><i>m</i></sub>, <i>y</i><sub><i>m</i></sub>) |<i>x</i><sub><i>i</i></sub>-<i>c</i>&lt;<i>x</i><sub><i>m</i></sub>&lt;<i>x</i><sub><i>i</i></sub>+<i>c</i>, <i>y</i><sub><i>i</i></sub>-<i>c</i>&lt;<i>y</i><sub><i>m</i></sub>&lt;<i>y</i><sub><i>i</i></sub>+<i>c</i>}      (20) </p>
                </div>
                <div class="p1">
                    <p id="186">式中, <i>c</i>= (<i>γ</i>-1) /2, <b><i>z</i></b><sub><i>im</i></sub>: (<i>x</i><sub><i>m</i></sub>, <i>y</i><sub><i>m</i></sub>) 对应空间邻域里第<i>m</i>个像元点。<i>δ</i> (<b><i>z</i></b><sub><i>i</i></sub>) 共有<i>γ</i>×<i>γ</i>个像元。则空间邻域距离可定义为</p>
                </div>
                <div class="p1">
                    <p id="187"><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∂</mo><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>γ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>      (21) </p>
                </div>
                <div class="p1">
                    <p id="189">式中, <image id="190" type="formula" href="images/CHXB201906003_19000.jpg" display="inline" placement="inline"><alt></alt></image>, 度量像元<b><i>z</i></b><sub><i>i</i></sub>与邻域内像元间相似权重, 且<mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>γ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></munderover><mi mathvariant="bold-italic">z</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo>/</mo><mi>γ</mi><mo>×</mo><mi>γ</mi></mrow></math></mathml>。对于所有训练样本局部空间邻域散度矩阵</p>
                </div>
                <div class="p1">
                    <p id="192"><mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>n</mi></munderover><mo>∂</mo></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>m</mi><mrow><mi>γ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></munderover><mi>u</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>      (22) </p>
                </div>
                <div class="p1">
                    <p id="194">此外, 为揭示影像数据多样性, 保持数据的整体结构, 定义总体散度矩阵</p>
                </div>
                <div class="p1">
                    <p id="195"><mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">z</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">z</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>      (23) </p>
                </div>
                <div class="p1">
                    <p id="197">式中, <mathml id="198"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">z</mi><mo>¯</mo></mover></math></mathml>是训练样本均值。</p>
                </div>
                <h4 class="anchor-tag" id="199" name="199">1.3.3 空-谱协同低维嵌入</h4>
                <div class="p1">
                    <p id="200">为在嵌入空间中提取低维空-谱鉴别特征, 不仅要保持高光谱数据局部空间近邻结构, 还需使超图中的类内数据聚集、类间数据远离。因此, 式 (19) 、式 (22) 和式 (23) 可进一步转化为以下优化问题</p>
                </div>
                <div class="p1">
                    <p id="201"><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></mstyle><mi mathvariant="bold-italic">Ρ</mi></munder><mfrac><mrow><mtext>t</mtext><mtext>r</mtext><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo>[</mo><mrow><mi>ξ</mi><mrow><mo> (</mo><mrow><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>η</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>b</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi>η</mi><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow><mo>) </mo></mrow><mo>+</mo><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>ξ</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">B</mi></mrow><mo>]</mo></mrow><mi mathvariant="bold-italic">Ρ</mi></mrow><mo>}</mo></mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo>[</mo><mrow><mi>ξ</mi><mrow><mo> (</mo><mrow><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>η</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>w</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi>η</mi><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mrow><mo> (</mo><mrow><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ζ</mi><mi mathvariant="bold-italic">L</mi><msup><mrow></mrow><mi>w</mi></msup><mi mathvariant="bold-italic">Ζ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow><mo>) </mo></mrow></mrow><mo>) </mo></mrow></mrow><mo>) </mo></mrow><mo>+</mo><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>ξ</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">A</mi></mrow><mo>]</mo></mrow><mi mathvariant="bold-italic">Ρ</mi></mrow><mo>}</mo></mrow></mrow></mfrac></mrow></math></mathml>      (24) </p>
                </div>
                <div class="p1">
                    <p id="203">式中, 参数<i>η</i>, <i>ξ</i>∈[0, 1];<b><i>M</i></b><sup><i>w</i></sup>=<i>ξ</i>[ (1-<i>η</i>) <i>N</i><sup><i>w</i></sup>+<i>η</i>diag (diag (<b><i>N</i></b><sup><i>w</i></sup>) ) ]+ (1-<i>ξ</i>) <b><i>A</i></b>, 用于表征类内与局部数据紧致性, <b><i>N</i></b><sup><i>w</i></sup>=<b><i>ZL</i></b><sup><i>w</i></sup><b><i>Z</i></b><sup>T</sup>;<b><i>M</i></b><sup><i>b</i></sup>=<i>ξ</i>[ (1-<i>η</i>) <b><i>N</i></b><sup><i>b</i></sup>+<i>η</i><b><i>ZZ</i></b><sup>T</sup>]+ (1-<i>ξ</i>) <b><i>B</i></b>, 用于表示类间与全局数据发散度, <b><i>N</i></b><sup><i>b</i></sup>=<b><i>ZL</i></b><sup><i>b</i></sup><b><i>Z</i></b><sup>T</sup>。</p>
                </div>
                <div class="p1">
                    <p id="204">依据拉格朗日乘子法, 式 (24) 可转换为以下广义特征值求解</p>
                </div>
                <div class="p1">
                    <p id="205"><b><i>M</i></b><sup><i>b</i></sup><b><i>P</i></b>=<i>λ</i><b><i>M</i></b><sup><i>w</i></sup><b><i>P</i></b>      (25) </p>
                </div>
                <div class="p1">
                    <p id="206">将式 (25) 特征值降序排列, 选取前<i>τ</i>个特征值对应的特征向量构成最优映射矩阵<b><i>P</i></b>=[<b><i>p</i></b><sub>1</sub>, <b><i>p</i></b><sub>2</sub>, …, <b><i>p</i></b><sub><i>τ</i>-1</sub>, <b><i>p</i></b><sub><i>τ</i></sub>]。在低维空间里, 测试样本<b><i>z</i></b><sub>test</sub>的空-谱协同特征是<b><i>y</i></b><sub>test</sub>=<b><i>P</i></b><sup>T</sup><b><i>z</i></b><sub>test</sub>。</p>
                </div>
                <h3 id="207" name="207" class="anchor-tag">2 试验结果与分析</h3>
                <div class="p1">
                    <p id="208">为验证本文算法的有效性, 在公开的Indian Pines和PaviaU高光谱数据集上进行分类试验, 并与相关的维数约简算法进行了对比。</p>
                </div>
                <h4 class="anchor-tag" id="209" name="209">2.1 数据集</h4>
                <div class="p1">
                    <p id="210"> (1) Indian Pines数据集为美国宇航局在1992年利用AVIRIS传感器拍摄位于美国Indian州西北100 km<sup>2</sup>范围的高光谱遥感影像, 其尺寸为145×145像素, 共220个波段, 空间分辨率为20 m, 剔除受水气 (噪声) 影响的波段后, 余下200个波段用于试验。该数据集主要包含16类地物, 其假彩色图和真实地物图如图3所示。</p>
                </div>
                <div class="area_img" id="211">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_211.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Indian Pines高光谱图像" src="Detail/GetImg?filename=images/CHXB201906003_211.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Indian Pines高光谱图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_211.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Indian Pines hyperspectral image</p>

                </div>
                <div class="p1">
                    <p id="212"> (2) PaviaU数据集为2002年采用ROSIS传感器拍摄的意大利北部的帕维亚大学周围的高光谱影像, 其尺寸为610×340像素, 空间分辨率为1.3 m, 共有115个波段, 去除受噪声影响严重的12个波段后, 剩余103个波段用于对比试验。该数据集包括道路、砖块、屋顶和裸土等9类地物, 图4为其假彩色图和真实地物图。</p>
                </div>
                <div class="area_img" id="213">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 PaviaU 高光谱图像" src="Detail/GetImg?filename=images/CHXB201906003_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 PaviaU 高光谱图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 University of Pavia hyperspectral image</p>

                </div>
                <h4 class="anchor-tag" id="214" name="214">2.2 试验设置</h4>
                <div class="p1">
                    <p id="215">在试验中, 每次试验随机选取一定数目的样本用于训练, 其余进行测试。鉴于在实际应用中, 高光谱图像中存在部分地物类别样本数量非常少, 例如在Indian Pines数据集中, Alfalfa (46) 、Oats (20) 、Stone-steel towers (93) , 括号中为对应的样本数。为避免出现某些类别选取训练样本所占比例过高或数量过少, 在试验中设置如下:假设每类地物随机选取样本量为<i>n</i><sub><i>i</i></sub>, <i>N</i><sub><i>i</i></sub>表示某类地物的总样本数, 若<i>n</i><sub><i>i</i></sub>≥<i>N</i><sub><i>i</i></sub>/2, 则<i>n</i><sub><i>i</i></sub>=<i>N</i><sub><i>i</i></sub>/2;若<i>n</i><sub><i>i</i></sub>≤10, 则定<i>n</i><sub><i>i</i></sub>=10。通过采用各维数约简算法得到投影矩阵后, 将所有样本投影到低维空间得到嵌入特征, 并通过利用最近邻分类器 (1-NN) 进行分类。在每种试验条件下均进行10次重复试验, 将总体分类精度 (the overall accuracies, OAs) 、平均分类精度 (the average accuracies, AAs) 及Kappa系数作为分类结果的评价指标。</p>
                </div>
                <div class="p1">
                    <p id="216">试验中, 将本文方法与PCA、LDA、MFA、LPP、RLDE、DHLP、SSCE、LPSNPE等维数约简算法进行比较, 采用交叉验证方法获得各算法的最佳参数。SSCE在两个数据集中空间窗口均设置为5, SSCE和LPP的最近邻取5, DHLP中近邻数为9;RLDE和MFA的类内和类间近邻数分别为3、5, 8、60。LDA的嵌入维数为<i>u</i>-1, <i>u</i>为类别数, 其他算法的嵌入维数均设置为30。</p>
                </div>
                <div class="p1">
                    <p id="217">为探索本文方法中参数<i>η</i>、<i>ξ</i>, 空间窗口<i>γ</i>对分类精度的影响, 从数据集中每类地物中随机选取5个样本进行训练, 其余样本作为测试样本。令<i>α</i>=10, <i>ε</i>=0.006, <i>η</i>与<i>ξ</i>的取值范围均设置为{0, 0.01, 0.05, 0.1, 0.2, …, 0.9, 1}, <i>γ</i>={3, 5, …, 39}。图5为本文SSRSHE算法在不同<i>η</i>和<i>ξ</i>值下的分类结果, 图6是本文SSRSHE算法在不同<i>γ</i>下的分类结果。</p>
                </div>
                <div class="p1">
                    <p id="218">由图5可知, 随着<i>ξ</i>的增加, 其分类精度随之增加而后达到平稳, 但是<i>ξ</i>值过大时, 分类精度有所下降。这是因为在SSRSHE中, <i>ξ</i>用于平衡光谱信息和空间结构在特征提取中作用, <i>ξ</i>过小时未能有效利用超图所表征的像元间的复杂多元结构关系, 过大时则忽略了空间结构, 也不利于鉴别特征提取。与此同时, 尽管试验中每类样本数量仅有5个, 但是在同一<i>η</i>值下, 分类结果比较稳定, 有利于实际场景应用。为平衡光谱信息与空间信息对分类性能的影响, 依据试验结果, 本文在Indian Pines数据集设置<i>ξ</i>为0.3, <i>η</i>为0.7;对于PaviaU数据集, 设置<i>η</i>=0.5及<i>ξ</i>=0.2。</p>
                </div>
                <div class="area_img" id="219">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 SSRSHE在不同η和ξ参数值下的总体分类精度" src="Detail/GetImg?filename=images/CHXB201906003_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 SSRSHE在不同η和ξ参数值下的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 OAs of SSRSHE with different values of parameters <i>η</i> and <i>ξ</i> on Indian Pines and PaviaU data sets</p>

                </div>
                <div class="area_img" id="220">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 SSRSHE在不同空间窗口γ下的总体分类精度" src="Detail/GetImg?filename=images/CHXB201906003_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 SSRSHE在不同空间窗口<i>γ</i>下的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 OAs of SSRSHE with different size <i>γ</i> on different data sets</p>

                </div>
                <div class="p1">
                    <p id="221">由图6知, 随着空间窗口<i>γ</i>变大, 能利用的空间信息愈发丰富, 分类精度随之增加;但<i>γ</i>过大时, 空间窗口内包含来自于不同类数据的可能性增大, 导致分类性能下降, 且窗口过大, 会导致计算复杂度增加。因此, 综合考虑算法性能及计算效率, 在Indian Pines数据集上设置<i>γ</i>=7, 在PaviaU数据集上<i>γ</i>=15。</p>
                </div>
                <h4 class="anchor-tag" id="222" name="222">2.3 Indian Pines试验结果与分析</h4>
                <div class="p1">
                    <p id="223">试验中, 从Indian Pines数据集的每类地物里分别按照5、20、50、100、200样本数随机选取数据用于训练, 剩余样本用于测试。采用各维数约简算法训练得到嵌入特征后, 采用1-NN进行分类。表1为在不同样本数量下不同算法的总体分类精度和Kappa系数值。</p>
                </div>
                <div class="area_img" id="224">
                                            <p class="img_tit">
                                                <b>表1 不同降维算法在Indian Pines数据集上的分类效果</b>
                                                    <br />
                                                <b>Tab.1 Classification with different numbers of training data via different DR methods on Indian Pines data set</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/CHXB201906003_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 不同降维算法在Indian Pines数据集上的分类效果" src="Detail/GetImg?filename=images/CHXB201906003_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="225">从表1可得知, 各种维数约简算法的分类性能都随着训练样本数目的增大而不断提高, 这是由于随着训练数据量的增加, 蕴含的信息就越丰富, 有利于特征提取。DHLP、RSHE等超图方法的分类精度大多数情况下均优于传统图嵌入方法, 表明利用数据间的多元几何结构特性可有效提高分类精度。与此同时, SSCE、LPSNPE等空-谱类方法, 通过融合样本数据的空间信息, 其分类性能要优于PCA、LDA、LPP、MFA、RLDE等仅利用了光谱信息的图嵌入方法。在各种训练条件下SSRSHE方法的分类性能均优于其他算法, 因为它利用了超图框架来表示各样本邻域内顶点间的多元几何关系, 因而可更好描述数据中复杂邻域结构。同时SSRSHE将样本类别信息融入超图框架, 分别构建了稀疏本征超图和惩罚超图, 能充分揭示数据间的复杂判别多元关系, 提取出更有效的低维鉴别特征, 进一步提升分类精度。</p>
                </div>
                <div class="p1">
                    <p id="226">为进一步探索SSRSHE对每种地物的分类性能, 从Indian Pines数据集每一类里随机选择3%的像元为训练样本, 余下数据用于测试。表2为不同维数约简算法对于每一种地物的总体分类精度、平均分类精度、Kappa系数及降维运行时间, 其对应在整个数据集上的分类结果如图7所示。</p>
                </div>
                <div class="area_img" id="227">
                    <p class="img_tit"><b>表2 不同算法在Indian Pines数据集每类地物上的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 Classification accuracy of different types of features on Indian Pines data set by different algorithms</b></p>
                    <p class="img_note"> (%) </p>
                    <table id="227" border="1"><tr><td><br />class</td><td>train</td><td>test</td><td>RAW</td><td>PCA</td><td>LDA</td><td>LPP</td><td>MFA</td><td>RLDE</td><td>RSHE</td><td>DHLP</td><td>SSCE</td><td>LPSNPE</td><td>SSRSHE</td></tr><tr><td><br />1</td><td>10</td><td>36</td><td>41.67</td><td>41.67</td><td>77.78</td><td>36.11</td><td>50.00</td><td>61.11</td><td>47.22</td><td>63.89</td><td>55.56</td><td>77.78</td><td><b>94.44</b></td></tr><tr><td><br />2</td><td>143</td><td>1285</td><td>53.39</td><td>52.45</td><td>64.12</td><td>51.05</td><td>56.03</td><td>72.14</td><td>66.15</td><td>66.69</td><td>60.31</td><td>80.78</td><td><b>88.17</b></td></tr><tr><td><br />3</td><td>83</td><td>747</td><td>57.30</td><td>55.29</td><td>57.70</td><td>47.12</td><td>50.07</td><td>61.58</td><td>63.32</td><td>61.58</td><td>63.45</td><td>74.30</td><td><b>80.46</b></td></tr><tr><td><br />4</td><td>24</td><td>213</td><td>41.78</td><td>44.60</td><td>52.58</td><td>43.19</td><td>21.60</td><td>58.69</td><td>59.62</td><td>59.15</td><td>51.17</td><td>77.00</td><td><b>84.04</b></td></tr><tr><td><br />5</td><td>48</td><td>435</td><td>78.85</td><td>78.62</td><td>89.43</td><td>77.93</td><td>78.85</td><td>86.90</td><td>82.99</td><td>87.82</td><td>80.46</td><td>91.72</td><td><b>96.55</b></td></tr><tr><td><br />6</td><td>73</td><td>657</td><td>90.26</td><td>89.50</td><td>95.74</td><td>91.02</td><td>94.67</td><td>95.28</td><td><b>97.41</b></td><td>95.89</td><td>94.52</td><td>96.04</td><td>97.02</td></tr><tr><td><br />7</td><td>10</td><td>18</td><td>77.78</td><td>88.89</td><td><b>100</b></td><td>88.89</td><td>77.78</td><td>94.44</td><td><b>100</b></td><td>94.44</td><td><b>100</b></td><td>94.44</td><td><b>100</b></td></tr><tr><td><br />8</td><td>48</td><td>430</td><td>95.58</td><td>95.58</td><td>99.53</td><td>93.95</td><td>93.26</td><td>99.30</td><td>93.49</td><td><b>99.77</b></td><td>92.56</td><td>99.53</td><td>98.60</td></tr><tr><td><br />9</td><td>10</td><td>10</td><td>70.00</td><td>70.00</td><td>60.00</td><td>50.00</td><td>70.00</td><td>80.00</td><td>80.00</td><td>90.00</td><td>90.00</td><td><b>100</b></td><td>80.00</td></tr><tr><td><br />10</td><td>97</td><td>875</td><td>61.03</td><td>60.46</td><td>60.91</td><td>57.49</td><td>42.06</td><td>68.91</td><td>73.83</td><td>63.20</td><td>72.11</td><td>82.74</td><td><b>83.89</b></td></tr><tr><td><br />11</td><td>246</td><td>2209</td><td>69.76</td><td>69.85</td><td>71.89</td><td>69.62</td><td>58.85</td><td>79.36</td><td>82.66</td><td>79.22</td><td>74.02</td><td>85.92</td><td><b>89.50</b></td></tr><tr><td><br />12</td><td>59</td><td>534</td><td>39.33</td><td>37.45</td><td>65.36</td><td>32.02</td><td>47.38</td><td>67.42</td><td>60.30</td><td>62.73</td><td>50.56</td><td><b>87.83</b></td><td>83.71</td></tr><tr><td><br />13</td><td>21</td><td>184</td><td>88.04</td><td>88.04</td><td>97.83</td><td>88.04</td><td>94.57</td><td>97.28</td><td>95.65</td><td>98.37</td><td>94.57</td><td>98.91</td><td><b>100</b></td></tr><tr><td><br />14</td><td>127</td><td>1138</td><td>94.02</td><td>93.94</td><td>94.11</td><td>92.88</td><td>90.69</td><td><b>96.66</b></td><td>93.15</td><td>95.61</td><td>93.94</td><td>96.10</td><td>95.52</td></tr><tr><td><br />15</td><td>39</td><td>347</td><td>31.12</td><td>30.55</td><td>54.18</td><td>25.07</td><td>42.65</td><td>40.92</td><td>56.48</td><td>48.41</td><td>55.04</td><td>71.47</td><td><b>83.57</b></td></tr><tr><td><br />16</td><td>10</td><td>83</td><td>91.57</td><td>91.57</td><td>90.36</td><td>85.54</td><td>85.54</td><td>90.36</td><td>84.34</td><td>92.77</td><td>84.34</td><td>92.77</td><td><b>97.59</b></td></tr><tr><td><br />OA</td><td></td><td></td><td>68.33</td><td>67.88</td><td>74.44</td><td>65.91</td><td>64.03</td><td>78.27</td><td>78.17</td><td>77.00</td><td>74.06</td><td>87.65</td><td><b>89.78</b></td></tr><tr><td><br />AA</td><td></td><td></td><td>67.59</td><td>68.03</td><td>76.97</td><td>64.37</td><td>65.87</td><td>78.15</td><td>77.29</td><td>78.72</td><td>75.79</td><td>88.02</td><td><b>90.88</b></td></tr><tr><td><br />Kappa</td><td></td><td></td><td>0.638</td><td>0.633</td><td>0.707</td><td>0.609</td><td>0.589</td><td>0.751</td><td>0.750</td><td>0.736</td><td>0.704</td><td>0.858</td><td><b>0.884</b></td></tr><tr><td><br />DR time</td><td></td><td></td><td>0</td><td>0.01</td><td>0.01</td><td>0.15</td><td>0.20</td><td>3.28</td><td>11.87</td><td>5.86</td><td>432.8</td><td>15.15</td><td>27.87</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="228">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 在Indian Pines数据集上, 各降维算法对应的全分类结果" src="Detail/GetImg?filename=images/CHXB201906003_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 在Indian Pines数据集上, 各降维算法对应的全分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Classification map of different DR methods on Indian Pines data set</p>

                </div>
                <div class="p1">
                    <p id="229">从表2可发现, SSRSHE的分类性能表现最佳, 在每类上的总体分类精度、平均分类精度、Kappa值均优于其他方法, 且对比SSCE算法, 其运行效率快, 优势明显。这是因为SSRSHE算超图学习, 充分揭示了数据间高阶关系, 以及像元空间特征的有效利用, 有效表征了影像内蕴特性, 提取的嵌入特征更具鉴别力, 更有助于地物分类。同时, 从图7可以看到, 本文算法相比其他算法, 在其分类结果图更趋于平滑, 尤其在“Alfalfa”、“Soybeans-min”、“Stone-steel towers”等区域更明显。由此可见, 本文算法基于空-谱信息与超图模型协同学习, 实现有效鉴别特征提取, 改善影像分类精度, 确实具有一定实践意义。</p>
                </div>
                <h4 class="anchor-tag" id="230" name="230">2.4 PaviaU试验结果与分析</h4>
                <div class="p1">
                    <p id="231">在试验中, 从每种地物中随机选取5、20、50、100、200个样本用于训练, 其余数据用来测试, 采用最近邻分类器进行分类。表3为在不同的训练样本数目下各维数约简算法对应的总体分类精度及Kappa值。</p>
                </div>
                <div class="p1">
                    <p id="232">依据表3, 在大多数训练条件下, DHLP、RSHE等超图方法和SSCE、LPSNPE等空-谱联合方法的分类结果要优于直接图嵌入方法, 这表明超图学习和空-谱融合信息均有利于高光谱数据鉴别特征提取, 有效改善地物分类性能。本文提出的SSRSHE方法在各种试验条件下, 均具有最佳分类性能, 这是因为其不仅通过超图学习发现高光谱数据中复杂结构, 且有效融入了空间信息, 在低维空间中使同类信息聚集、非同类信息远离, 提高了数据可分性, 进而有效提高地物分类效果。</p>
                </div>
                <div class="p1">
                    <p id="233">为进一步分析SSRSHE方法在每种地物上的分类性能, 从每类地物里随机选择5%的像元组成训练样本集, 其他部分为测试样本集。表4反映了不同维数约简方法在每类地物的分类效果, 图8则为各方法对整个PaviaU遥感图像分类的结果图。由表4可以看到, SSRSHE在大多数地物类别中的分类性能要优于其他方法, 表明在影像地物分类过程中, SSRSHE算法可使同类数据的关联性, 异物数据间奇异性增强, 鉴别特征尤为突出, 分类性能更佳。同时, 在图8中, 本文方法在“Asphalt”, “Meadows”, “Gravel”等地物区域的分类结果较为光滑, 误分点较少, 且运行时间并没大幅度增加, 表明联合空-谱特性与超图学习的SSRSHE算法的地物分类性能有明显提升, 更适合实际应用场景。</p>
                </div>
                <div class="area_img" id="234">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_234.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 在PaviaU数据集上, 各降维算法对应的全分类结果" src="Detail/GetImg?filename=images/CHXB201906003_234.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 在PaviaU数据集上, 各降维算法对应的全分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_234.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Classification map of different DR methods on PaviaU data set</p>

                </div>
                <div class="area_img" id="235">
                                            <p class="img_tit">
                                                <b>表3 不同算法在PaviaU数据集上的分类效果</b>
                                                    <br />
                                                <b>Tab.3 Classification with different numbers of training data via different DR methods on PaviaU data set</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201906003_23500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/CHXB201906003_23500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201906003_23500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 不同算法在PaviaU数据集上的分类效果" src="Detail/GetImg?filename=images/CHXB201906003_23500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="236">
                    <p class="img_tit"><b>表4 不同算法在PaviaU数据集每种地物上的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.4 Classification accuracy of different types of features on PaviaU data set by different algorithms</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="236" border="1"><tr><td><br />class</td><td>train</td><td>test</td><td>RAW</td><td>PCA</td><td>LDA</td><td>LPP</td><td>MFA</td><td>RLDE</td><td>RSHE</td><td>DHLP</td><td>SSCE</td><td>LPSNPE</td><td>SSRSHE</td></tr><tr><td><br />1</td><td>332</td><td>6299</td><td>85.62</td><td>85.62</td><td>87.68</td><td>87.82</td><td>82.76</td><td>90.19</td><td>87.46</td><td>63.89</td><td>89.73</td><td>90.20</td><td><b>91.19</b></td></tr><tr><td><br />2</td><td>933</td><td>17716</td><td>94.65</td><td>94.57</td><td>94.88</td><td>94.76</td><td>93.90</td><td>97.73</td><td>95.80</td><td>66.69</td><td>96.70</td><td>97.53</td><td><b>98.12</b></td></tr><tr><td><br />3</td><td>105</td><td>1994</td><td>65.15</td><td>64.64</td><td>63.34</td><td>67.00</td><td>61.84</td><td>74.77</td><td>69.71</td><td>61.58</td><td>72.37</td><td>77.28</td><td><b>78.69</b></td></tr><tr><td><br />4</td><td>154</td><td>2910</td><td>77.22</td><td>77.36</td><td>81.79</td><td>79.01</td><td>77.02</td><td>84.13</td><td>79.59</td><td>59.15</td><td>84.78</td><td>87.83</td><td><b>89.26</b></td></tr><tr><td><br />5</td><td>68</td><td>1277</td><td>98.83</td><td>98.83</td><td>98.84</td><td>99.30</td><td><b>99.77</b></td><td>99.53</td><td>98.98</td><td>87.82</td><td>99.37</td><td><b>99.77</b></td><td><b>99.77</b></td></tr><tr><td><br />6</td><td>252</td><td>4777</td><td>60.26</td><td>60.32</td><td>65.17</td><td>65.47</td><td>69.72</td><td>70.36</td><td>65.24</td><td><b>95.89</b></td><td>73.86</td><td>89.68</td><td>85.22</td></tr><tr><td><br />7</td><td>67</td><td>1263</td><td>75.30</td><td>75.30</td><td>66.67</td><td>75.69</td><td>71.26</td><td>80.36</td><td>82.58</td><td><b>94.44</b></td><td>88.60</td><td>86.06</td><td>90.18</td></tr><tr><td><br />8</td><td>185</td><td>3497</td><td>80.27</td><td>80.27</td><td>74.39</td><td>81.42</td><td>77.36</td><td>84.79</td><td>75.24</td><td>79.77</td><td>82.85</td><td><b>84.68</b></td><td>79.33</td></tr><tr><td><br />9</td><td>48</td><td>899</td><td><b>100</b></td><td><b>100</b></td><td>99.44</td><td><b>100</b></td><td>99.67</td><td><b>100</b></td><td>98.44</td><td>90.00</td><td>99.78</td><td>99.89</td><td><b>100</b></td></tr><tr><td><br />OA</td><td></td><td></td><td>84.92</td><td>84.88</td><td>85.40</td><td>86.27</td><td>84.73</td><td>89.70</td><td>87.31</td><td>78.00</td><td>89.60</td><td>91.30</td><td><b>92.59</b></td></tr><tr><td><br />AA</td><td></td><td></td><td>81.92</td><td>81.88</td><td>81.47</td><td>83.38</td><td>81.48</td><td>86.87</td><td>85.51</td><td>77.72</td><td>87.56</td><td>89.53</td><td><b>90.55</b></td></tr><tr><td><br />Kappa</td><td></td><td></td><td>0.797</td><td>0.796</td><td>0.804</td><td>0.815</td><td>0.796</td><td>0.861</td><td>0.825</td><td>0.736</td><td>0.861</td><td>0.883</td><td><b>0.902</b></td></tr><tr><td><br />DR time</td><td></td><td></td><td>0</td><td>0.08</td><td>0.03</td><td>0.81</td><td>1.67</td><td>6.80</td><td>8.21</td><td>5.86</td><td>896.2</td><td>7.29</td><td>15.19</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="237" name="237" class="anchor-tag">3 总 结</h3>
                <div class="p1">
                    <p id="238">针对传统图嵌入降维方法存在不能表征高光谱数据中的多元关系且未有效利用空间信息等问题, 本文提出了一种空-谱协同正则化稀疏超图嵌入算法。本文算法利用稀疏系数实现自适应近邻选取, 构建正则化稀疏超图模型来揭示高光谱数据间的多元几何结构。此外, 考虑到保持样本的全局特性和局部邻域结构分别定义样本总体散度与局部空间邻域散度, 实现空-谱鉴别特征提取。在Indian Pines和PaviaU高光谱数据集上试验结果表明, 相比其他算法, 在训练样本数较少时, SSRSHE地物分类性能仍有明显提升。但本文方法仅运用光谱信息构建超图, 在下一步工作将考虑空-谱联合超图模型构建, 以进一步提升地物分类效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201709005&amp;v=MTI1ODZxZlp1ZHZGeTNrV3IzT0ppWFRiTEc0SDliTXBvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201710028&amp;v=MTc3NzBiTnI0OUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrV3IzT0ppWFRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张良培, 武辰.多时相遥感影像变化检测的现状与展望[J].测绘学报, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340.ZHANG Liangpei, WU Chen.Advance and future development of change detection for multi-temporal remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (10) :1447-1459.DOI:10.11947/j.AGCS.2017.20170340.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction and classification of hyperspetral images using DWT and DCCF">

                                <b>[3]</b> MENEZES J, POOJARY N.Dimensionality reduction and classification of hyperspetral images using DWT and DCCF[C]//Proceedings of the 3rd MEC International Conference on Big Data and Smart City.Muscat:IEEE, 2016.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminant analysis with graph learning for hyperspectral image classification">

                                <b>[4]</b> CHEN Mulin, WANG Qi, LI Xuelong.Discriminant analysis with graph learning for hyperspectral image classification[J].Remote Sensing, 2018, 10 (6) :836.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction of hyperspectral image with graph-based discriminant analysis considering spectral similarity">

                                <b>[5]</b> FENG Fubiao, LI Wei, DU Qian, et al.Dimensionality reduction of hyperspectral image with graph-based discriminant analysis considering spectral similarity[J].Remote Sensing, 2017, 9 (4) :323.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201703019&amp;v=MjIxOTJGeTNrV3IzT0ppWFRiTEc0SDliTXJJOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized linear discriminant analysis based on euclidean norm for gait recognition">

                                <b>[7]</b> WANG Hao, FAN Yuanyuan, FANG Baofu, et al.Generalized linear discriminant analysis based on Euclidean norm for gait recognition[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (4) :569-576.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES79402B4CA13F81C0D37DCA8897CA961B&amp;v=MjI2NThabjZUZ0pPdzdxcEJzeUNzT2RRN3Z0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxod2JtMndxND1OaWZPZmJTeEd0SE8zWXMyRmVvTWVuUTR2Qg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> FAN Mingyu, ZHANG Xianqin, QIAO Hong, et al.Efficient isometric multi-manifold learning based on the self-organizing method[J].Information Sciences, 2016 (345) :325-339.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BDTG201703024&amp;v=MDQ4ODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2tXcjNPSnluZmFiRzRIOWJNckk5SFlJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 王东, 张强, 严亮.一种融合聚类的监督局部线性嵌入算法研究[J].半导体光学, 2017, 38 (3) :419-424.WANG Dong, ZHANG Qiang, YAN Liang.Study on supervised local linear embedding algorithm based on fusion clustering[J].Semiconductor Optoelectronics, 2017, 38 (3) :419-424.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locality adaptive discriminant analysis for spectral-spatial classification of hyperspectral images">

                                <b>[10]</b> WANG Qi, MENG Zhaotie, LI Xuelong.Locality adaptive discriminant analysis for spectral-spatial classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (11) :2077-2081.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD72DCFD62D7B35172FDBDBC583F6E37CF&amp;v=MTY1MTZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDU5bGh3Ym0yd3E0PU5qN0JhclM2YXFLNjI0bEhFT3g5RDNrNHlCUmxuazBKT2d6bnBCRkRmOGVYUXNucA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> JIANG Quansheng, ZHU Qixin, WANG Bangfu, et al.Nonlinear machine fault detection by semi-supervised Laplacian eigenmaps[J].Journal of Mechanical Science and Technology, 2017, 31 (8) :3697-3703.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images">

                                <b>[12]</b> DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFDF700E0F1443CB416062FEF3537F586&amp;v=MDIzNjRhQnVIWWZPR1FsZkJyTFUwNTlsaHdibTJ3cTQ9TmlmT2ZjWE1hTmJNci9wRkV1b0xDSDlLdlJJUzdEOTdTZ21YMmhFd2VyWGlRTEtaQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> KUMAR S, BHUYAN M K, LOVELL B C, et al.Hierarchical uncorrelated multiview discriminant locality preserving projection for multiview facial expression recognition[J].Journal of Visual Communication and Image Representation, 2018 (54) :171-181.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature selection based on high dimensional model representation for hyperspectral images">

                                <b>[14]</b> TAŞKIN G, KAYA H, BRUZZONE L.Feature selection based on high dimensional model representation for hyperspectral images[J].IEEE Transactions on Image Processing, 2017, 26 (6) :2918-2928.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local geometric structure feature for dimensionality reduction of hyperspectral imagery">

                                <b>[15]</b> LUO Fulin, HUANG Hong, DUAN Yule, et al.Local geometric structure feature for dimensionality reduction of hyperspectral imagery[J].Remote Sensing, 2017, 9 (8) :790.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimension Reduction Using Spatial and Spectral Regularized Local Discriminant Embedding for Hyperspectral Image Classification">

                                <b>[16]</b> ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning with hypergraph for hyperspectral image feature extraction">

                                <b>[17]</b> YUAN Haoliang, TANG Yuanyan.Learning with hypergraph for hyperspectral image feature extraction[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (8) :1695-1699.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDDE52746DC12B6C72A02BAE408E10CF02&amp;v=MTcwMzlOZm5wS3lCUmk2ajBQT1FybXJCcEFlTExuTTdxZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNTlsaHdibTJ3cTQ9TmpuQmFzZk5HOVBMcTRreEYrbw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> DU Weibao, QIANG Wenwen, LÜ Meng, et al.Semi-supervised dimension reduction based on hypergraph embedding for hyperspectral images[J].International Journal of Remote Sensing, 2018, 39 (6) :1696-1712.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFB56849B2429CACA685556250B751114&amp;v=MDIwNzFiQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxod2JtMndxND1OaWZPZmNYS0c5ZkVxNFkzWnU4TkJROUl2R2NWNGpwNFRYbmdxUkpIZnJlVlJMdQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> HUANG Sheng, YANG Dan, GE Yongxin, et al.Discriminant hyper-Laplacian projections and its scalable extension for dimensionality reduction[J].Neurocomputing, 2016, 173 (2) :145-153.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint hypergraph learning and sparse regression for feature selection">

                                <b>[20]</b> ZHANG Zhihong, BAI Lu, LIANG Yuanheng, et al.Joint hypergraph learning and sparse regression for feature selection[J].Pattern Recognition, 2017 (63) :291-309.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPU parallel implementation of spatially adaptive hyperspectral image classification">

                                <b>[21]</b> WU Zebin, SHI Linlin, LI Jun, et al.GPU parallel implementation of spatially adaptive hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2018, 11 (4) :1131-1143.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201608012&amp;v=MDc5NzgzT0ppWFRiTEc0SDlmTXA0OUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hypergraph embedding for spatial-spectral joint feature extraction in hyperspectral images">

                                <b>[23]</b> SUN Yubao, WANG Sujuan, LIU Qingshan, et al.Hypergraph embedding for spatial-spectral joint feature extraction in hyperspectral images[J].Remote Sensing, 2017, 9 (5) :506.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Alternating direction method of multipliers with difference of convex functions">

                                <b>[24]</b> SUN Tao, YIN Penghang, CHENG Lizhi, et al.Alternating direction method of multipliers with difference of convex functions[J].Advances in Computational Mathematics, 2018, 44 (3) :723-744.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised sparsity preserving projections for face recognition">

                                <b>[25]</b> SUN Yanfeng, ZHAO Jiangang, HU Yongli.Supervised sparsity preserving projections for face recognition[C]//Proceedings of SPIE 8009, Third International Conference on Digital Image Processing.Chengdu, China:SPIE, 2011:357-366.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201906003" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201906003&amp;v=MjcxMDFyQ1VSN3FmWnVkdkZ5M2tXcjNPSmlYVGJMRzRIOWpNcVk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
