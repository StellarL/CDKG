<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142606234482500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201910008%26RESULT%3d1%26SIGN%3dkb%252bzpKXgLnWGG%252f80zMETEtCBdzg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910008&amp;v=MjI4OTE0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVWJyS0ppWFRiTEc0SDlqTnI0OUZiSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="1.1 多尺度目标检测">1.1 多尺度目标检测</a></li>
                                                <li><a href="#60" data-title="1.2 特征融合算法">1.2 特征融合算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="2 MultDet飞机检测框架 ">2 MultDet飞机检测框架</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="2.1 MultDet检测框架">2.1 MultDet检测框架</a></li>
                                                <li><a href="#67" data-title="2.2 融合模块设计">2.2 融合模块设计</a></li>
                                                <li><a href="#70" data-title="2.3 候选框设计">2.3 候选框设计</a></li>
                                                <li><a href="#74" data-title="2.4 网络模型训练">2.4 网络模型训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="3 试验与结果分析 ">3 试验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="3.1 数据集与训练参数">3.1 数据集与训练参数</a></li>
                                                <li><a href="#88" data-title="3.2 评价指标">3.2 评价指标</a></li>
                                                <li><a href="#91" data-title="3.3 试验结果与分析">3.3 试验结果与分析</a></li>
                                                <li><a href="#98" data-title="3.4 消融试验">3.4 消融试验</a></li>
                                                <li><a href="#107" data-title="3.5 检测速度">3.5 检测速度</a></li>
                                                <li><a href="#110" data-title="3.6 迁移试验分析">3.6 迁移试验分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#114" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="图1 飞机数据分布信息统计">图1 飞机数据分布信息统计</a></li>
                                                <li><a href="#66" data-title="图2 MultDet飞机目标检测框架">图2 MultDet飞机目标检测框架</a></li>
                                                <li><a href="#69" data-title="图3 反卷积融合模块">图3 反卷积融合模块</a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;表1 数据集信息统计&lt;/b&gt;"><b>表1 数据集信息统计</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;表2 不同飞机目标检测方法结果对比&lt;/b&gt;"><b>表2 不同飞机目标检测方法结果对比</b></a></li>
                                                <li><a href="#95" data-title="图4 不同检测算法在UCAS-AOD数据集上的PR曲线">图4 不同检测算法在UCAS-AOD数据集上的PR曲线</a></li>
                                                <li><a href="#96" data-title="图5 不同框架的检测结果对比图">图5 不同框架的检测结果对比图</a></li>
                                                <li><a href="#97" data-title="图6 MultDet512飞机检测结果示例">图6 MultDet512飞机检测结果示例</a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;表3 融合策略对飞机检测性能的影响&lt;/b&gt;"><b>表3 融合策略对飞机检测性能的影响</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表4 融合模块对飞机检测的影响分析&lt;/b&gt;"><b>表4 融合模块对飞机检测的影响分析</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表5 候选框纵横比设计分析&lt;/b&gt;"><b>表5 候选框纵横比设计分析</b></a></li>
                                                <li><a href="#113" data-title="图7 迁移试验检测结果">图7 迁移试验检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     CHENG Gong,ZHOU Peicheng,HAN Junwei.Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(12):7405-7415.</a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     HAN Junwei,ZHANG Dingwen,CHENG Gong,et al.Object detection in optical remote sensing images based on weakly supervised learning and high-level feature learning[J].IEEE Transactions on Geoscience and Remote Sensing,2015,53(6):3325-3337.</a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" CHENG Gong,HAN Junwei,ZHOU Peicheng,et al.Multi-class geospatial object detection and geographic image classification based on collection of part detectors[J].ISPRS Journal of Photogrammetry and Remote Sensing,2014,98(12):119-132." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700308532&amp;v=MDU5OTE4SDlETXFJOUZaK3NIQ1g4N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1dieEE9TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         CHENG Gong,HAN Junwei,ZHOU Peicheng,et al.Multi-class geospatial object detection and geographic image classification based on collection of part detectors[J].ISPRS Journal of Photogrammetry and Remote Sensing,2014,98(12):119-132.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" HE Chu,TU Mingxia,XIONG Dehui,et al.Adaptive component selection-based discriminative model for object detection in high-resolution SAR imagery[J].ISPRS International Journal of Geo-Information,2018,7(2):72." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive component selection-based discriminative model for object detection in high-resolution SAR imagery">
                                        <b>[4]</b>
                                         HE Chu,TU Mingxia,XIONG Dehui,et al.Adaptive component selection-based discriminative model for object detection in high-resolution SAR imagery[J].ISPRS International Journal of Geo-Information,2018,7(2):72.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" DIAO Wenhui,SUN Xian,ZHENG Xinwei,et al.Efficient saliency-based object detection in remote sensing images using deep belief networks[J].IEEE Geoscience and Remote Sensing Letters,2016,13(2):137-141." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient saliency-based object detection in remote sensing images using deep belief networks">
                                        <b>[5]</b>
                                         DIAO Wenhui,SUN Xian,ZHENG Xinwei,et al.Efficient saliency-based object detection in remote sensing images using deep belief networks[J].IEEE Geoscience and Remote Sensing Letters,2016,13(2):137-141.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" DU Bo,ZHANG Yuxiang,ZHANG Liangpei,et al.Beyond the sparsity-based target detector:a hybrid sparsity and statistics-based detector for hyperspectral images[J].IEEE Transactions on Image Processing,2016,25(11):5345-5357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond the sparsity-based target detector:a hybrid sparsity and statistics based detector for hyperspectral images">
                                        <b>[6]</b>
                                         DU Bo,ZHANG Yuxiang,ZHANG Liangpei,et al.Beyond the sparsity-based target detector:a hybrid sparsity and statistics-based detector for hyperspectral images[J].IEEE Transactions on Image Processing,2016,25(11):5345-5357.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" LI Xuelong,MOU Lichao,LU Xiaoqiang.Scene parsing from an MAP perspective[J].IEEE Transactions on Cybernetics,2015,45(9):1876-1886." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scene Parsing From an MAP Perspective">
                                        <b>[7]</b>
                                         LI Xuelong,MOU Lichao,LU Xiaoqiang.Scene parsing from an MAP perspective[J].IEEE Transactions on Cybernetics,2015,45(9):1876-1886.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" ZHANG Libao,ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2017,10(4):1511-1524." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images">
                                        <b>[8]</b>
                                         ZHANG Libao,ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2017,10(4):1511-1524.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" REN Shaoqing,HE Kaiming,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Montreal,Canada:ACM,2015:91-99." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Faster RCNN:Towards Real Time Object Detection with Region Proposal Networks">
                                        <b>[9]</b>
                                         REN Shaoqing,HE Kaiming,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Montreal,Canada:ACM,2015:91-99.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" DAI Jifeng,LI Yi,HE Kaiming,et al.R-FCN:object detection via region-based fully convolutional networks[C]//Proceedings of the 30th International Conference on Neural Information Processing Systems.Barcelona,Spain:ACM,2016:379-387." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=R-FCN:Object Detection via Region-based Fully Convolutional Networks">
                                        <b>[10]</b>
                                         DAI Jifeng,LI Yi,HE Kaiming,et al.R-FCN:object detection via region-based fully convolutional networks[C]//Proceedings of the 30th International Conference on Neural Information Processing Systems.Barcelona,Spain:ACM,2016:379-387.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" REDMON J,FARHADI A.YOLO9000:better,faster,stronger[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:6517-6525." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=YOLO9000:Better,Faster,Stronger">
                                        <b>[11]</b>
                                         REDMON J,FARHADI A.YOLO9000:better,faster,stronger[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:6517-6525.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" LIU Wei,ANGUELOV D,ERHAN D,et al.SSD:single shot MultiBox detector[C]//Proceedings of the 14th European Conference On Computer Vision.Amsterdam,The Netherlands:Springer,2016:21-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SSD:Single shot MultiBox detector">
                                        <b>[12]</b>
                                         LIU Wei,ANGUELOV D,ERHAN D,et al.SSD:single shot MultiBox detector[C]//Proceedings of the 14th European Conference On Computer Vision.Amsterdam,The Netherlands:Springer,2016:21-37.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     LIN T Y,DOLL&#193;R P,GIRSHICK R,et al.Feature pyramid networks for object detection[C]//Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:936-944.</a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" HAN Xiaobing,ZHONG Yanfei,ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing,2017,9(7):666." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Efficient and Robust Integrated Geospatial Object Detection Framework for High Spatial Resolution Remote Sensing Imagery">
                                        <b>[14]</b>
                                         HAN Xiaobing,ZHONG Yanfei,ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing,2017,9(7):666.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" CAI Bowen,JIANG Zhiguo,ZHANG Haopeng,et al.Airport detection using end-to-end convolutional neural network with hard example mining[J].Remote Sensing,2017,9(11):1198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Airport detection using end-to-end convolutional neural network with hard example mining">
                                        <b>[15]</b>
                                         CAI Bowen,JIANG Zhiguo,ZHANG Haopeng,et al.Airport detection using end-to-end convolutional neural network with hard example mining[J].Remote Sensing,2017,9(11):1198.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     GUO Wei,YANG Wen,ZHANG Haijian,et al.Geospatial object detection in high resolution satellite images based on multi-scale convolutional neural network[J].Remote Sensing,2018,10(1):131.</a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" 邓志鹏,孙浩,雷琳,等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng,SUN Hao,LEI Lin,et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201809008&amp;v=MTc1MTBkdkZ5cmdVYnJLSmlYVGJMRzRIOW5NcG85RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         邓志鹏,孙浩,雷琳,等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng,SUN Hao,LEI Lin,et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     CHEN Zhong,ZHANG Ting,OUYANG Chao.End-to-end airplane detection using transfer learning in remote sensing images[J].Remote Sensing,2018,10(1):139.</a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     SHEN Zhiqiang,LIU Zhuang,LI Jianguo,et al.DSOD:learning deeply supervised object detectors from scratch[C]//Proceedings of 2017 IEEE International Conference on Computer Vision.Venice,Italy:IEEE,2017:1937-1945.</a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" BELL S,ZITNICK C L,BALA K,et al.Inside-outside net:detecting objects in context with skip pooling and recurrent neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas:IEEE,2016:2874-2883." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Inside-outside net:detecting objects in context with skip pooling and recurrent neural networks">
                                        <b>[20]</b>
                                         BELL S,ZITNICK C L,BALA K,et al.Inside-outside net:detecting objects in context with skip pooling and recurrent neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas:IEEE,2016:2874-2883.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" KONG Tao,SUN Fuchun,YAO Anbang,et al.RON:reverse connection with objectness prior networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:5244-5252." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RON:Reverse Connection with Objectness Prior Networks for Object Detection">
                                        <b>[21]</b>
                                         KONG Tao,SUN Fuchun,YAO Anbang,et al.RON:reverse connection with objectness prior networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:5244-5252.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" ZHU Haigang,CHEN Xiaogang,DAI Weiqun,et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City:IEEE,2015:3735-3739." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Orientation Robust Object Detection in Aerial Images Using Deep Con- volutional Neural Network">
                                        <b>[22]</b>
                                         ZHU Haigang,CHEN Xiaogang,DAI Weiqun,et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City:IEEE,2015:3735-3739.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                     LONG J,SHELHAMER E,DARRELL T.Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Boston:IEEE,2015:3431-3440.</a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" 梁华,宋玉龙,钱锋等.基于深度学习的航空对地小目标检测[J].液晶与显示,2018,33(9):793-800.LIANG Hua,SONG Yulong,QIAN Feng,et al.Detection of small target in aerial photography based on deep learning[J].Chinese Journal of Liquid Crystals and Displays,2018,33(9):793-800." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YJYS201809011&amp;v=MjI2NTdCdEdGckNVUjdxZlp1ZHZGeXJnVWJyS1BDZlNmYkc0SDluTXBvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         梁华,宋玉龙,钱锋等.基于深度学习的航空对地小目标检测[J].液晶与显示,2018,33(9):793-800.LIANG Hua,SONG Yulong,QIAN Feng,et al.Detection of small target in aerial photography based on deep learning[J].Chinese Journal of Liquid Crystals and Displays,2018,33(9):793-800.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" XIA Guisong,BAI Xiang,DING Jian,et al.DOTA:a large-scale dataset for object detection in aerial images[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City:IEEE,2018:3974-3983." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DOTA:a large-scale dataset for object detection in aerial images">
                                        <b>[25]</b>
                                         XIA Guisong,BAI Xiang,DING Jian,et al.DOTA:a large-scale dataset for object detection in aerial images[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City:IEEE,2018:3974-3983.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(10),1266-1274 DOI:10.11947/j.AGCS.2019.20180398            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多尺度融合特征卷积神经网络的遥感图像飞机目标检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9A%E7%BE%A4%E5%8A%9B&amp;code=39904532&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姚群力</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E6%98%BE&amp;code=39904534&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡显</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9B%B7%E5%AE%8F&amp;code=09542040&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">雷宏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E7%94%B5%E5%AD%90%E5%AD%A6%E7%A0%94%E7%A9%B6%E6%89%80%E8%88%AA%E5%A4%A9%E5%BE%AE%E6%B3%A2%E9%81%A5%E6%84%9F%E7%B3%BB%E7%BB%9F%E9%83%A8&amp;code=0227399&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院电子学研究所航天微波遥感系统部</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E7%94%B5%E6%B0%94%E4%B8%8E%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学电子电气与通信工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>飞机检测在遥感图像解译中具有重要的研究意义。针对现有目标检测算法对于复杂场景区域或飞机密集区域的小尺度飞机目标检测精度较低的问题,本文提出了一种端到端的多尺度特征融合飞机目标检测框架MultDet。该方法基于SSD多尺度检测框架,采用轻量级基础网络提取多尺度特征信息;然后设计反卷积特征融合模块,通过跳跃连接将高层语义特征与低层细节特征进行特征融合,得到结构层次丰富的多尺度融合特征;最后设计了一系列不同纵横比的候选框以适应多尺度飞机目标检测。本文在光学遥感图像数据集UCAS-AOD上进行数据分析试验,结果表明,MultDet512在飞机数据集上取得了94.8%的平均检测精度(average precision,AP),在Titan Xp GPU上达到0.050 0 s/img的检测速度。本文所提飞机目标检测算法在包含多种复杂场景的遥感图像中,能够实现多尺度飞机目标的高精度稳健检测。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A3%9E%E6%9C%BA%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">飞机检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多尺度特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    姚群力(1993—),男,硕士,研究方向为机器学习,E-mail: yaoqunli15@mails.ucas.ac.cn。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金青年基金(61422113; 61601437);</span>
                                <span>国家重点研发计划(2017YFB0502700);</span>
                    </p>
            </div>
                    <h1>Aircraft detection in remote sensing imagery with multi-scale feature fusion convolutional neural networks</h1>
                    <h2>
                    <span>YAO Qunli</span>
                    <span>HU Xian</span>
                    <span>Lei Hong</span>
            </h2>
                    <h2>
                    <span>Department of Space Microwave Remote Sensing Systems, Institute of Electronics, Chinese Academy of Sciences</span>
                    <span>School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aircraft detection in remote sensing images(RSIs) is a meaningful task. There are many problems in current detection methods, such as low accuracy in complex background and dense aircraft area, especially for small-scale aircraft. To solve these problems, an end-to-end aircraft detection method named MultDet is proposed in this paper. Based on single shot multibox detector(SSD), a lightweight baseline Network is used to extract multi-scale features for its powerful ability in feature extraction. To obtain the feature maps with enriched representation power, then the multi-scale deconvolution feature fusion block is designed. We add the high-level features with rich semantic information to the low-level features via deconvolution fusion block. In order to locate aircraft of various scales more accurately, a series of aspect ratios of default boxes are set to better match aircraft shapes and combine predictions deduced from feature maps of different layers. The quantitative comparison analysis are carried out on the challenging UCAS-AOD data set. The experimental results demonstrate that the proposed method is accurate and robust for multi-scale aircraft detection, and achieves 94.8% AP(average precision) at the speed of 0.050 0 s/img with the input size 512×512 using a single Nvidia Titan Xp GPU.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing%20images&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing images;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=aircraft%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">aircraft detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-scale%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-scale features;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YAO Qunli(1993—), male, master, majors in machine learning,E-mail: yaoqunli15@mails.ucas.ac.cn;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-26</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China(Nos.61422113; 61601437);</span>
                                <span>The National Key Research and Development Program of China(No.2017YFB0502700);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="52">飞机目标自动检测技术是遥感图像智能解译领域的重要研究方向之一,飞机作为一类重要的军事和民用地物目标,在目标判读、交通安全和应急救援等方面具有重要的应用价值。目前,飞机目标检测算法通常可以划分为传统的多阶段检测算法和基于卷积神经网络的端到端检测算法两类。传统多阶段飞机检测算法<citation id="143" type="reference"><link href="2" rel="bibliography" /><link href="4" rel="bibliography" /><link href="6" rel="bibliography" /><link href="8" rel="bibliography" /><link href="10" rel="bibliography" /><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>首先通过滑窗获得目标候选区域,然后提取特征训练分类器,最后通过分类器对候选框中的目标进行判决。事实上,多阶段飞机检测算法实现流程复杂,并且候选框的提取存在较大冗余性,在目标检测的精度和效率方面,均难以满足大范围自动化检测的需求。</p>
                </div>
                <div class="p1">
                    <p id="53">近年来,基于端到端的目标检测研究取得了快速进展,研究人员提出了大量兼顾检测精度与速度的深度卷积神经网络(deep convolutional neural networks,DNNs)目标检测框架<citation id="151" type="reference"><link href="18" rel="bibliography" /><link href="20" rel="bibliography" /><link href="22" rel="bibliography" /><link href="24" rel="bibliography" /><link href="26" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation><sup>,</sup><citation id="174" type="note"><link href="162" rel="footnote" /><sup>注1</sup></citation><sup>,</sup><citation id="173" type="reference"><link href="4" rel="bibliography" /><sup>注2</sup></citation>。为提高遥感目标检测精度,文献<citation id="144" type="reference">[<a class="sup">14</a>]</citation>提出了R-P-Faster R-CNN,该方法将RPN添加到Faster R-CNN体系结构中,从而获得了比其他基于DNNs模型更高的检测精度。文献<citation id="145" type="reference">[<a class="sup">15</a>]</citation>基于难样本挖掘和权重平衡策略构造了HEM-CNN框架,提高了复杂环境下的飞机目标检测精度。文献<citation id="146" type="reference">[<a class="sup">16</a>]</citation>提出一种多尺度共享基础网络来增强多尺度目标的检测性能。然而,由于预测特征的感受野尺度相对固定,该类方法制约了小尺度目标的检测性能。文献<citation id="147" type="reference">[<a class="sup">17</a>]</citation>提出了一种基于多尺度形变特征卷积网络的目标检测方法,利用可形变卷积网络对具有尺度和方向变化的遥感图像目标进行特征提取。文献<citation id="148" type="reference">[<a class="sup">18</a>]</citation>则在SSD网络的基础上提出了一种输入图像尺度可变的方法,该方法对输入图像进行分块,提高了飞机检测精度。然而,由于来自低层的卷积特征的语义信息较弱,该方法对多尺度目标的检测能力仍待提高。FPN<citation id="149" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>和TDM<citation id="175" type="note"><link href="166" rel="footnote" /><sup>注3</sup></citation>则利用top-down结构<citation id="150" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>解决多尺度目标检测的问题。然而,由于特征金字塔的逐级特征融合方式极大地增加了计算成本,限制了目标检测的速度,给实时检测应用造成了困难。</p>
                </div>
                <div class="p1">
                    <p id="54">受上述研究启发,并针对复杂场景区域或飞机密集区域内的小尺度目标检测精度较低的问题,本文提出了一种基于多尺度融合特征的轻量级飞机检测框架MultDet。全文主要工作内容如下:</p>
                </div>
                <div class="p1">
                    <p id="55">(1) 设计了一种反卷积特征融合模块,通过跳跃连接将高层语义特征融合到细节信息丰富低层特征中,得到具有丰富结构信息的融合预测特征,并研究特征融合模块对飞机检测的影响。</p>
                </div>
                <div class="p1">
                    <p id="56">(2) 以SSD目标检测框架为基础,提出一种轻量级多尺度飞机目标检测框架MultDet。设计一系列不同纵横比的候选框以适应多尺度飞机目标检测,利用新的融合特征进行多尺度遥感图像飞机目标检测,MultDet显著提升复杂背景下小尺度飞机目标的检测精度。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="58" name="58">1.1 多尺度目标检测</h4>
                <div class="p1">
                    <p id="59">对于多尺度目标检测,特别是小尺度目标的检测更加依赖低层特征信息,然而低层特征缺乏足够的语义信息,从而导致网络对小尺度目标特征的表征能力不足。因此,仅采用卷积神经网络固有的多尺度特征进行目标检测是不够的。文献<citation id="156" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</citation>提出基于多尺度特征融合的目标检测方法,为小尺度目标检测提供更多必要的语义特征,提升了多尺度目标的检测精度。RON<citation id="152" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>通过反向连接增强了前向特征的语义信息;ION<citation id="153" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>使用跳跃连接提取多尺度特征,以及使用空间递归网络集成感兴趣区域外部的语义信息;DSOD<citation id="154" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>则引入密集层次连接的方式构造多尺度融合特征来强化多尺度目标的检测能力。此外,本文采用UCAS-AOD<citation id="155" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>多尺度数据集,以分析检测框架对于多尺度目标的检测性能。该数据集中目标实例的尺度和纵横比统计信息如图1所示,从图1中可以看出,数据集中目标实例的尺度分布于20～220像素,纵横比分布于0.7～1.6。数据统计表明,目标实例呈现出尺度差异明显、形态变化多样的统计特性,能够满足多尺度目标检测试验分析。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60">1.2 特征融合算法</h4>
                <div class="p1">
                    <p id="61">为了丰富特征的结构信息,文献<citation id="159" type="reference">[<a class="sup">13</a>,<a class="sup">23</a>]</citation>考虑到特征间的关系,利用多尺度特征提高网络的检测性能<citation id="176" type="note"><link href="162" rel="footnote" /><sup>注1,</sup></citation><citation id="177" type="note"><link href="164" rel="footnote" /><sup>注2</sup></citation>。DSSD<citation id="178" type="note"><link href="162" rel="footnote" /><sup>注1</sup></citation>采用了SSD+ResNet-101的方式,使用反卷积融合模块引入了上下文信息,提升了小尺度目标的检测精度。FSSD<citation id="179" type="note"><link href="164" rel="footnote" /><sup>注2</sup></citation>将浅层的细节特征和高层的语义特征结合起来,重构了一组金字塔特征,使网络的检测精度得到提升。FPN<citation id="157" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>则采用top-down结构进行充分的信息融合,增强了网络的特征表达能力。FCN<citation id="158" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>则使用对称结构和跳越连接来关联低层特征和高层特征。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 飞机数据分布信息统计" src="Detail/GetImg?filename=images/CHXB201910008_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 飞机数据分布信息统计  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 The distribution of aircraft regions on training data</p>

                </div>
                <h3 id="63" name="63" class="anchor-tag">2 MultDet飞机检测框架</h3>
                <h4 class="anchor-tag" id="64" name="64">2.1 MultDet检测框架</h4>
                <div class="p1">
                    <p id="65">所提检测框架MultDet的网络整体结构如图2所示。所提算法采用轻量级的VGG16作为基础网络提取多尺度特征信息。为充分利用低层特征信息的细节表达能力以提高网络对小尺度目标的检测精度,设定融合运算保持conv4_3和conv7层不变,将conv9_2和conv10_2分别反卷积添加到conv4_3和conv7层,新的融合特征层定义为M_1和M_2,并以此代替SSD的conv4_3和conv7进行目标检测。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 MultDet飞机目标检测框架" src="Detail/GetImg?filename=images/CHXB201910008_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 MultDet飞机目标检测框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 The architecture of aircraft detection MultDet</p>

                </div>
                <h4 class="anchor-tag" id="67" name="67">2.2 融合模块设计</h4>
                <div class="p1">
                    <p id="68">MultDet通过特征融合构成了2层新的特征M_1和M_2。以MultDet300为例,M_1对应的特征融合模块结构如图3所示,对于M_2模块同理。对于conv9_2,首先以步长为2进行3次反卷积运算,卷积核设定为2×2×256和3×3×256维张量;反卷积层后紧邻卷积层,采用L2规范化以及ReLU激活函数;conv4_3经3×3×256的卷积后,进行L2规范化,然后将两路特征进行逐元素求和,直至得到新的融合特征;最后添加3×3×256的卷积层以增强融合特征的分辨力,再经过ReLU激活函数后,即得到了M_1特征融合模块。2个特征融合模块的维度分别为512和1024。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 反卷积融合模块" src="Detail/GetImg?filename=images/CHXB201910008_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 反卷积融合模块  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Deconvolution fusion block</p>

                </div>
                <h4 class="anchor-tag" id="70" name="70">2.3 候选框设计</h4>
                <div class="p1">
                    <p id="71">假设取<i>m</i>个特征层用于目标检测,则第<i>k</i>层特征的候选框尺度系数设定为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>s</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mtd><mtd columnalign="left"><mi>k</mi><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>2</mn><mi>s</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo>+</mo><mfrac><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mn>2</mn><mi>s</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow><mrow><mi>m</mi><mo>-</mo><mn>2</mn></mrow></mfrac><mo>⋅</mo><mo stretchy="false">(</mo><mi>k</mi><mo>-</mo><mn>2</mn><mo stretchy="false">)</mo></mtd><mtd columnalign="left"><mi>k</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mn>2</mn><mo>,</mo><mi>m</mi></mrow><mo>]</mo></mrow></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式中,<i>s</i><sub>min</sub>和<i>s</i><sub>max</sub>分别表示尺度系数的最值,根据图1飞机尺度信息统计特性,尺度系数范围设定为<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mn>0</mn><mo>.</mo><mn>0</mn><mn>5</mn><mo>,</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>,对于不同的预测层根据<i>s</i><sub><i>k</i></sub>的定义均可计算出相应候选框的尺度系数。通过图1的飞机数据集尺度统计信息可知,飞机目标的纵横比通常处于0.5～1.5之间。为此,本文设计相应尺度与纵横比的候选框,对于特征融合模块M_1,M_2,候选框的纵横比设置为<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo>,</mo><mi>r</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>,</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>,</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mo>,</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mo>,</mo><mn>2</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>。每个候选框对应到原图像所占宽度设定为<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>σ</mi><mo>⋅</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>⋅</mo><msqrt><mi>r</mi></msqrt></mrow></math></mathml>,高度为<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mi>σ</mi><mo>⋅</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>/</mo><msqrt><mi>r</mi></msqrt></mrow></math></mathml>,当纵横比为1时增加一个长宽均为<mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><mo>⋅</mo><msqrt><mrow><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>⋅</mo><mi>s</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></msqrt></mrow></math></mathml>的候选框,其中<i>σ</i>代表输入图像的边长。候选框中心点坐标为<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>i</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow><mrow><mrow><mo>|</mo><mrow><mi>f</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo>,</mo><mfrac><mrow><mi>j</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow><mrow><mrow><mo>|</mo><mrow><mi>f</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow><mo>)</mo></mrow><mo>,</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mrow><mo>|</mo><mrow><mi>f</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow><mo>)</mo></mrow></mrow></math></mathml>,其中<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>f</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>表示第<i>k</i>个特征的边长。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">2.4 网络模型训练</h4>
                <div class="p1">
                    <p id="75">本文设计了多任务联合损失函数,用于对目标分类和边框回归两个任务进行联合训练。该损失函数如式(2)所示</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>g</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mo stretchy="false">(</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>f</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>c</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>g</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">式中,<i>N</i>是匹配的候选框数目;<i>α</i>是平衡回归损失和分类损失的超参数,<i>α</i>通常可设置为1;损失函数的第1项<i>L</i><sub>conf</sub>(<i>x</i>,<i>c</i>)是分类损失,通常采用Softmax函数,该损失函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>f</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>Ρ</mtext><mtext>o</mtext><mtext>s</mtext></mrow><mi>Ν</mi></munderover><mi>x</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>Ν</mtext><mtext>e</mtext><mtext>g</mtext></mrow></munder><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false">(</mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">式中,<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>c</mi><mo>^</mo></mover><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo stretchy="false">)</mo><mo>/</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>p</mi></munder><mrow><mi>exp</mi></mrow></mstyle><mo stretchy="false">(</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo stretchy="false">)</mo><mo>,</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup></mrow></math></mathml>代表第<i>i</i>个候选框属于类别<i>p</i>的置信度;<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mo>=</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>,</mo><mn>0</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>判别第<i>i</i>个候选框和第<i>j</i>个真值框关于类<i>p</i>的匹配度,本文约定<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo>=</mo><mrow><mo>{</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>,当<i>p</i>=1时,意味着检测到飞机目标,反之则为背景。此外,式(2)的第2项代表回归损失,通常采用smooth<sub><i>L</i></sub><sub>1</sub>函数,该损失函数可表示为</p>
                </div>
                <div class="area_img" id="80">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201910008_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="82">式中,(<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>g</mi><mo>^</mo></mover></math></mathml><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mi>c</mi><mi>x</mi></mrow></msubsup></mrow></math></mathml>,<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>g</mi><mo>^</mo></mover></math></mathml><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mi>c</mi><mi>y</mi></mrow></msubsup></mrow></math></mathml>,<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>g</mi><mo>^</mo></mover></math></mathml><mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>w</mi></msubsup></mrow></math></mathml>,<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>g</mi><mo>^</mo></mover></math></mathml><mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>h</mi></msubsup></mrow></math></mathml>)代表真值框信息;(<i>d</i><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>c</mi><mi>x</mi></mrow></msubsup></mrow></math></mathml>,<i>d</i><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>c</mi><mi>y</mi></mrow></msubsup></mrow></math></mathml>,<i>d</i><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>,<i>d</i><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>h</mi></msubsup></mrow></math></mathml>)代表候选框信息;(<i>l</i><mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>c</mi><mi>x</mi></mrow></msubsup></mrow></math></mathml>,<i>l</i><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>c</mi><mi>y</mi></mrow></msubsup></mrow></math></mathml>,<i>l</i><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>w</mi></msubsup></mrow></math></mathml>,<i>l</i><mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>h</mi></msubsup></mrow></math></mathml>)则代表预测框的相对偏移量。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">3 试验与结果分析</h3>
                <h4 class="anchor-tag" id="84" name="84">3.1 数据集与训练参数</h4>
                <div class="p1">
                    <p id="85">本文在UCAS-AOD<citation id="160" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>公开数据集上评估了所有试验。该数据集包含飞机图像1000景,共标注了7482个飞机目标,本文采用1000景飞机数据作为试验数据。训练过程中,随机分配其中的60%为训练集,余下的40%为测试集,数据集的统计信息如表1所示。</p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit"><b>表1 数据集信息统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 The statistics of object in data set</b></p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td><br />数据信息</td><td>图像数量/幅</td><td>尺度信息/像素</td><td>飞机数量/个</td></tr><tr><td><br />训练集</td><td>600</td><td>1280×659</td><td>3591</td></tr><tr><td><br />测试集</td><td>400</td><td>1372×941</td><td>3891</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="87">本文采用翻转以及旋转等方式将训练集进行数据扩充。扩充后训练集样本总量为3600景。本文训练和测试采用硬件平台为NVIDIA Titan Xp GPUs,并采用Pytorch深度学习框架完成试验的构建。本文采用与SSD相同的端到端训练方式,初始学习率设置为0.001,优化方法为随机梯度下降,动量设置为0.9,正则化系数设置为0.000 5,批处理大小设置为1。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">3.2 评价指标</h4>
                <div class="p1">
                    <p id="89">本文采用平均检测精度(average precision,AP)和PR曲线(precision-recall curve,PRC)作为飞机目标检测结果的评价指标。其中,正确检测将定义为检测边框与真值边框的某一交并比(intersection over union,IoU)阈值,本文将在2种IoU阈值(0.5和0.75)下评估相应的多尺度目标检测精度。</p>
                </div>
                <div class="p1">
                    <p id="90">为了验证本文所提方法的有效性,本文将在UCAS-AOD数据集上训练好的飞机检测模型迁移到国产高分辨率光学影像数据的检测中。该部分试验采用的数据为4景分辨率为1 m,幅面为3000×3000像素的光学遥感图像。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">3.3 试验结果与分析</h4>
                <div class="p1">
                    <p id="92">本文在UCAS-AOD数据集上对不同的目标检测方法进行训练和测试,检测结果如表2所示。从表2的检测结果可以看出:①Faster R-CNN在IoU阈值为0.5时取得了86.3%的平均检测精度,然而,当IoU阈值为0.75时,平均检测精度仅为43.5%,其原因是Faster R-CNN仅利用固定尺度的末端特征图生成预测,使得网络难以准确回归多尺度目标的位置信息;②R-FCN相较于Faster R-CNN的检测性能有了明显改善,这是由于R-FCN采用了ResNet-101网络,提升了检测器对目标特征的学习能力;此外,R-FCN提出了位置敏感得分图,增强了对多尺度目标的定位能力;③SSD300在IoU阈值为0.75时取得了73.3%的平均检测精度,相较于Faster R-CNN以及文献<citation id="161" type="reference">[<a class="sup">24</a>]</citation>所提的方法有明显的提高,原因在于SSD网络引入了多尺度检测思想,提升了检测精度;④FSSD相较于SSD网络进一步引入了多尺度特征融合模块,提升了多尺度目标的检测精度;⑤DSSD方法采用了反卷积特征融合策略,提高了对多尺度目标特征的表达能力;⑥相较于其他典型的目标检测方法,本文所提方法MultDet512在不同的IoU阈值下均取得了最优的平均检测精度,所提方法表现出了对于多尺度目标检测的优越性。</p>
                </div>
                <div class="area_img" id="93">
                                            <p class="img_tit">
                                                <b>表2 不同飞机目标检测方法结果对比</b>
                                                    <br />
                                                <b>Tab.2 Comparison of different aircraft detection methods</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/CHXB201910008_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 不同飞机目标检测方法结果对比" src="Detail/GetImg?filename=images/CHXB201910008_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="94">不同检测方法对应的飞机目标检测结果的PR曲线如图4所示,本文所提MultDet检测框架在精度和召回率两个性能指标均优于其他方法。如图5所示,分别给出SSD512(如图5(a),图5(d))、FSSD512(如图5(b),图5(e))以及MultDet512(如图5(c),图5(f))的飞机目标检测结果示例,方框代表检测到的飞机目标。从图5中可以看出,相较于SSD512和FSSD512目标检测框架,基于VGG16的MultDet网络显著提升了小尺度密集飞机目标的检测能力。此外,在不同场景下,MultDet网络的部分检测结果示例如图6所示,在密集飞机停靠区域(图6(a)、(d))、复杂背景区域(图6(b)、(e))以及小尺度飞机目标区域(图6(c)、(f)),MultDet均可以精确检测出其中的飞机目标,试验结果证明了MultDet目标检测框架可以有效提高复杂场景区域及密集小尺度飞机目标的检测能力。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同检测算法在UCAS-AOD数据集上的PR曲线" src="Detail/GetImg?filename=images/CHXB201910008_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同检测算法在UCAS-AOD数据集上的PR曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Precision-recall curves of the diverse methods on the UCAS-AOD dataset</p>

                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同框架的检测结果对比图" src="Detail/GetImg?filename=images/CHXB201910008_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同框架的检测结果对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Aircraft detection results of different detection methods</p>

                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 MultDet512飞机检测结果示例" src="Detail/GetImg?filename=images/CHXB201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 MultDet512飞机检测结果示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Aircraft detection results of MultDet512</p>

                </div>
                <h4 class="anchor-tag" id="98" name="98">3.4 消融试验</h4>
                <h4 class="anchor-tag" id="99" name="99">3.4.1 融合构型分析</h4>
                <div class="p1">
                    <p id="100">如表3所示,本文设计了3组多尺度特征融合构型分析对比试验,同时评估了相应模型的检测精度。以第1组试验为例,如表3第3～5行所示,当输入尺度为300×300时,即设定(conv4_3、conv8_2)为基本融合层时,对比了在不同融合组(conv7、conv9_2)以及(conv7、conv10_2)下的检测性能,其平均检测精度分别为85.6%和84.7%。试验结果表明,MeticDet300按所设计的不同融合构型,其平均检测精度由85.9%递减到83.7%。</p>
                </div>
                <div class="area_img" id="101">
                                            <p class="img_tit">
                                                <b>表3 融合策略对飞机检测性能的影响</b>
                                                    <br />
                                                <b>Tab.3 The influence of fusion strategy on aircraft detection performance</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/CHXB201910008_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 融合策略对飞机检测性能的影响" src="Detail/GetImg?filename=images/CHXB201910008_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="102" name="102">3.4.2 融合组件分析</h4>
                <div class="p1">
                    <p id="103">表4的对比试验分析了融合模块对飞机目标检测结果的影响,从试验结果可以看出,MultDet300在含有M_1、M_2特征融合模块时,飞机目标检测结果较仅含M_1融合模块时提高了1.6%;MultDet512检测结果较仅含M_1融合模块时提高了1.3%。试验结果表明,多尺度特征融合组件可以合理挖掘多尺度特征信息,增强多尺度目标的特征学习能力,从而提高了多尺度飞机目标检测性能。</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表4 融合模块对飞机检测的影响分析</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.4 The impact of fusion module on aircraft detection framework</b></p>
                    <p class="img_note"></p>
                    <table id="104" border="1"><tr><td><br />项目</td><td colspan="3">MultDet-300</td><td colspan="3">MultDet-512</td></tr><tr><td><br />M_1</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td></td></tr><tr><td><br />M_2</td><td>✓</td><td></td><td></td><td>✓</td><td></td><td></td></tr><tr><td><br />AP/(%)</td><td>85.9</td><td>84.3</td><td>81.7</td><td>94.8</td><td>93.5</td><td>87.1</td></tr><tr><td><br />时间/(s/img)</td><td>0.047 7</td><td>0.035 6</td><td>0.024 7</td><td>0.050 0</td><td>0.038 7</td><td>0.036 2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="105" name="105">3.4.3 候选框设计</h4>
                <div class="p1">
                    <p id="106">通过表5设计的对比结果可以看出设计多种纵横比的候选框可以提高飞机检测精度,注意到增加纵横比为<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>,</mo><mn>3</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>的候选框时,对飞机目标检测精度并无提升,这是由于遥感图像数据中几乎不存在相应比例的飞机数据。检测结果表明MultDet所设计的候选框比例是相对合理的。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107">3.5 检测速度</h4>
                <div class="p1">
                    <p id="108">本文评估了MultDet300/512框架的飞机目标检测速度,并与几种代表性多尺度飞机检测框架进行了对比,结果如表2第5列所示,MultDet300在单张Titan Xp GPU上的检测速度为0.047 7 s/img;由于所提算法在SSD网络上附加了融合特征层,导致额外消耗了推断时间,但是相比于DSSD网络仍具明显的速度优势。本文所提方法相较于其他目标检测算法实现了具有竞争力的检测速度,同时实现了检测精度与检测速度的良好权衡。</p>
                </div>
                <div class="area_img" id="109">
                                            <p class="img_tit">
                                                <b>表5 候选框纵横比设计分析</b>
                                                    <br />
                                                <b>Tab.5 Aspect ratios design of default box</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/CHXB201910008_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 候选框纵横比设计分析" src="Detail/GetImg?filename=images/CHXB201910008_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="110" name="110">3.6 迁移试验分析</h4>
                <div class="p1">
                    <p id="111">为了验证本文所提方法的有效性,以及对于小而密集的飞机目标的检测效果,本文将在上述UCAS-AOD数据集上训练好的飞机检测模型,直接用于国产高分辨率光学遥感卫星影像数据的飞机目标检测。</p>
                </div>
                <div class="p1">
                    <p id="112">如图7所示,本文给出了4景国产高分辨率光学遥感影像的检测结果实例。从中可以看出,MultDet对于小尺度密集分布的飞机目标检测效果比较理想,证明了本文方法对于检测尺度密集分布飞机目标的有效性。此外,训练集所采用的主要是民航客机样本,而测试图像中飞机形态与训练集数据的差异性较大,本文所提方法仍然能对其进行有效检测,证明了本文方法所学习到的检测模型具有一定的迁移性和通用性。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910008_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 迁移试验检测结果" src="Detail/GetImg?filename=images/CHXB201910008_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 迁移试验检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910008_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 The migration test results</p>

                </div>
                <h3 id="114" name="114" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="115">本文提出一种基于深度卷积神经网络的端到端飞机目标检测框架MultDet。采用轻量级的特征提取网络作为基础网络,设计多尺度特征融合模块,通过跳跃连接将高层语义特征与低层细节特征进行信息融合,增强了特征的结构信息以提高模型对多尺度目标特征的表征能力。本文根据数据集尺度分布特征,设计了相应尺度与纵横比的候选框,使检测器更好地适应多尺度飞机目标检测。试验结果表明,本文所提方法在保持较小的运算速度损失前提下,有效地解决了深层特征维度过低,特别是对小尺度目标表征能力不足的问题,实现了对复杂场景多尺度飞机目标的最优检测性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 CHENG Gong,ZHOU Peicheng,HAN Junwei.Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(12):7405-7415.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 HAN Junwei,ZHANG Dingwen,CHENG Gong,et al.Object detection in optical remote sensing images based on weakly supervised learning and high-level feature learning[J].IEEE Transactions on Geoscience and Remote Sensing,2015,53(6):3325-3337.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700308532&amp;v=MDY5NDBmYks4SDlETXFJOUZaK3NIQ1g4N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1dieEE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> CHENG Gong,HAN Junwei,ZHOU Peicheng,et al.Multi-class geospatial object detection and geographic image classification based on collection of part detectors[J].ISPRS Journal of Photogrammetry and Remote Sensing,2014,98(12):119-132.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive component selection-based discriminative model for object detection in high-resolution SAR imagery">

                                <b>[4]</b> HE Chu,TU Mingxia,XIONG Dehui,et al.Adaptive component selection-based discriminative model for object detection in high-resolution SAR imagery[J].ISPRS International Journal of Geo-Information,2018,7(2):72.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient saliency-based object detection in remote sensing images using deep belief networks">

                                <b>[5]</b> DIAO Wenhui,SUN Xian,ZHENG Xinwei,et al.Efficient saliency-based object detection in remote sensing images using deep belief networks[J].IEEE Geoscience and Remote Sensing Letters,2016,13(2):137-141.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond the sparsity-based target detector:a hybrid sparsity and statistics based detector for hyperspectral images">

                                <b>[6]</b> DU Bo,ZHANG Yuxiang,ZHANG Liangpei,et al.Beyond the sparsity-based target detector:a hybrid sparsity and statistics-based detector for hyperspectral images[J].IEEE Transactions on Image Processing,2016,25(11):5345-5357.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scene Parsing From an MAP Perspective">

                                <b>[7]</b> LI Xuelong,MOU Lichao,LU Xiaoqiang.Scene parsing from an MAP perspective[J].IEEE Transactions on Cybernetics,2015,45(9):1876-1886.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images">

                                <b>[8]</b> ZHANG Libao,ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2017,10(4):1511-1524.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Faster RCNN:Towards Real Time Object Detection with Region Proposal Networks">

                                <b>[9]</b> REN Shaoqing,HE Kaiming,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Montreal,Canada:ACM,2015:91-99.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=R-FCN:Object Detection via Region-based Fully Convolutional Networks">

                                <b>[10]</b> DAI Jifeng,LI Yi,HE Kaiming,et al.R-FCN:object detection via region-based fully convolutional networks[C]//Proceedings of the 30th International Conference on Neural Information Processing Systems.Barcelona,Spain:ACM,2016:379-387.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=YOLO9000:Better,Faster,Stronger">

                                <b>[11]</b> REDMON J,FARHADI A.YOLO9000:better,faster,stronger[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:6517-6525.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SSD:Single shot MultiBox detector">

                                <b>[12]</b> LIU Wei,ANGUELOV D,ERHAN D,et al.SSD:single shot MultiBox detector[C]//Proceedings of the 14th European Conference On Computer Vision.Amsterdam,The Netherlands:Springer,2016:21-37.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 LIN T Y,DOLLÁR P,GIRSHICK R,et al.Feature pyramid networks for object detection[C]//Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:936-944.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Efficient and Robust Integrated Geospatial Object Detection Framework for High Spatial Resolution Remote Sensing Imagery">

                                <b>[14]</b> HAN Xiaobing,ZHONG Yanfei,ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing,2017,9(7):666.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Airport detection using end-to-end convolutional neural network with hard example mining">

                                <b>[15]</b> CAI Bowen,JIANG Zhiguo,ZHANG Haopeng,et al.Airport detection using end-to-end convolutional neural network with hard example mining[J].Remote Sensing,2017,9(11):1198.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 GUO Wei,YANG Wen,ZHANG Haijian,et al.Geospatial object detection in high resolution satellite images based on multi-scale convolutional neural network[J].Remote Sensing,2018,10(1):131.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201809008&amp;v=MDk3MTVnVWJyS0ppWFRiTEc0SDluTXBvOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 邓志鹏,孙浩,雷琳,等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng,SUN Hao,LEI Lin,et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica,2018,47(9):1216-1227.DOI:10.11947/j.AGCS.2018.20170595.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 CHEN Zhong,ZHANG Ting,OUYANG Chao.End-to-end airplane detection using transfer learning in remote sensing images[J].Remote Sensing,2018,10(1):139.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 SHEN Zhiqiang,LIU Zhuang,LI Jianguo,et al.DSOD:learning deeply supervised object detectors from scratch[C]//Proceedings of 2017 IEEE International Conference on Computer Vision.Venice,Italy:IEEE,2017:1937-1945.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Inside-outside net:detecting objects in context with skip pooling and recurrent neural networks">

                                <b>[20]</b> BELL S,ZITNICK C L,BALA K,et al.Inside-outside net:detecting objects in context with skip pooling and recurrent neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas:IEEE,2016:2874-2883.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RON:Reverse Connection with Objectness Prior Networks for Object Detection">

                                <b>[21]</b> KONG Tao,SUN Fuchun,YAO Anbang,et al.RON:reverse connection with objectness prior networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Honolulu:IEEE,2017:5244-5252.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Orientation Robust Object Detection in Aerial Images Using Deep Con- volutional Neural Network">

                                <b>[22]</b> ZHU Haigang,CHEN Xiaogang,DAI Weiqun,et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City:IEEE,2015:3735-3739.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                 LONG J,SHELHAMER E,DARRELL T.Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Boston:IEEE,2015:3431-3440.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YJYS201809011&amp;v=MjQzNTdicktQQ2ZTZmJHNEg5bk1wbzlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> 梁华,宋玉龙,钱锋等.基于深度学习的航空对地小目标检测[J].液晶与显示,2018,33(9):793-800.LIANG Hua,SONG Yulong,QIAN Feng,et al.Detection of small target in aerial photography based on deep learning[J].Chinese Journal of Liquid Crystals and Displays,2018,33(9):793-800.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DOTA:a large-scale dataset for object detection in aerial images">

                                <b>[25]</b> XIA Guisong,BAI Xiang,DING Jian,et al.DOTA:a large-scale dataset for object detection in aerial images[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City:IEEE,2018:3974-3983.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="162" href="javascript:void(0)">
                            <b>1</b>注1:https：∥arxiv.org/abs/1701.06659．
                        </span>
                    </p>
                    <p>
                        <span id="164" href="javascript:void(0)">
                            <b>2</b>注2:https：∥arxiv.org/abs/1712.00960v1．
                        </span>
                    </p>
                    <p>
                        <span id="166" href="javascript:void(0)">
                            <b>3</b>注3:https：∥arxiv.org/abs/1612.06851.
                        </span>
                    </p>
                    <p>
                        <span id="168" href="javascript:void(0)">
                            <b>4</b>注1:https：∥arxiv.org/abs/1701.06659．
                        </span>
                    </p>
                    <p>
                        <span id="170" href="javascript:void(0)">
                            <b>5</b>注2:https：∥arxiv.org/abs/1712.00960v1.
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201910008" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910008&amp;v=MjI4OTE0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVWJyS0ppWFRiTEc0SDlqTnI0OUZiSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
