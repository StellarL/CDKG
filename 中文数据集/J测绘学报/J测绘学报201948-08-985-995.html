<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142614876201250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201908006%26RESULT%3d1%26SIGN%3dNqoIsD9W1lBuZRHU3y8kZ3sM8u0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908006&amp;v=MjYyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T0ppWFRiTEc0SDlqTXA0OUZZb1E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#62" data-title="1 高光谱影像显著性特征提取与分类 ">1 高光谱影像显著性特征提取与分类</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="1.1 SLIC超像素分割">1.1 SLIC超像素分割</a></li>
                                                <li><a href="#72" data-title="1.2 对比度计算">1.2 对比度计算</a></li>
                                                <li><a href="#93" data-title="1.3 显著性分配">1.3 显著性分配</a></li>
                                                <li><a href="#101" data-title="1.4 高光谱影像显著性特征提取与分类">1.4 高光谱影像显著性特征提取与分类</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#104" data-title="2 试验结果与分析 ">2 试验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#105" data-title="2.1 试验数据">2.1 试验数据</a></li>
                                                <li><a href="#110" data-title="2.2 参数设置">2.2 参数设置</a></li>
                                                <li><a href="#122" data-title="2.3 试验结果与分析">2.3 试验结果与分析</a></li>
                                                <li><a href="#132" data-title="2.4 训练样本数量适宜性分析">2.4 训练样本数量适宜性分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="3 总结与展望 ">3 总结与展望</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="图1 3个波段显著性特征提取流程">图1 3个波段显著性特征提取流程</a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表1 Pavia大学数据集样本信息&lt;/b&gt;"><b>表1 Pavia大学数据集样本信息</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表2 Indian Pines数据集样本信息&lt;/b&gt;"><b>表2 Indian Pines数据集样本信息</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表3 Salinas数据集样本信息&lt;/b&gt;"><b>表3 Salinas数据集样本信息</b></a></li>
                                                <li><a href="#113" data-title="图2 Pavia大学数据集不同的&lt;i&gt;K&lt;/i&gt;值对应的总体分类精度和计算时间">图2 Pavia大学数据集不同的<i>K</i>值对应的总体分类精度和计算时间</a></li>
                                                <li><a href="#116" data-title="图3 Pavia大学数据集不同的&lt;i&gt;σ&lt;/i&gt;&lt;sub&gt;&lt;i&gt;c&lt;/i&gt;&lt;/sub&gt;和&lt;i&gt;σ&lt;/i&gt;&lt;sub&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sub&gt;值对应的总体分类精度">图3 Pavia大学数据集不同的<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>值对应的总体分类精度</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表4 Pavia大学数据集中采用不同的特征进行分类的总体分类精度&lt;/b&gt;"><b>表4 Pavia大学数据集中采用不同的特征进行分类的总体分类精度</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表5 Pavia大学数据集中采用不同的波段数进行特征提取的总体分类精度&lt;/b&gt;"><b>表5 Pavia大学数据集中采用不同的波段数进行特征提取的总体分类精度</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表6 不同算法在Pavia大学数据集的分类结果&lt;/b&gt;"><b>表6 不同算法在Pavia大学数据集的分类结果</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表7 不同算法在Indian Pines数据集的分类结果&lt;/b&gt;"><b>表7 不同算法在Indian Pines数据集的分类结果</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表8 不同算法在Salinas数据集的分类结果&lt;/b&gt;"><b>表8 不同算法在Salinas数据集的分类结果</b></a></li>
                                                <li><a href="#129" data-title="图4 各算法在Pavia大学数据集上的分类结果及其对应的总体分类精度">图4 各算法在Pavia大学数据集上的分类结果及其对应的总体分类精度</a></li>
                                                <li><a href="#130" data-title="图5 各算法在Indian Pines数据集上的分类结果及其对应的总体分类精度">图5 各算法在Indian Pines数据集上的分类结果及其对应的总体分类精度</a></li>
                                                <li><a href="#131" data-title="图6 各算法在Salinas数据集上的分类结果图及其对应的总体分类精度">图6 各算法在Salinas数据集上的分类结果图及其对应的总体分类精度</a></li>
                                                <li><a href="#134" data-title="图7 不同训练样本数目对应的总体分类精度">图7 不同训练样本数目对应的总体分类精度</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 杜培军, 夏俊士, 薛朝辉, 等.高光谱遥感影像分类研究进展[J].遥感学报, 2016, 20 (2) :236-256.DU Peijun, XIA Junshi, XUE Chaohui, et al.Review of hyperspectral remote sensing image classification[J].Journal of Remote Sensing, 2016, 20 (2) :236-256." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXB201602008&amp;v=MTcwMzVoV3I3T1BDclRiTEc0SDlmTXJZOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         杜培军, 夏俊士, 薛朝辉, 等.高光谱遥感影像分类研究进展[J].遥感学报, 2016, 20 (2) :236-256.DU Peijun, XIA Junshi, XUE Chaohui, et al.Review of hyperspectral remote sensing image classification[J].Journal of Remote Sensing, 2016, 20 (2) :236-256.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" 刘冰, 余旭初, 张鹏强, 等.面对高光谱影像分类的半监督阶梯网络[J].测绘科学技术学报, 2017, 34 (6) :576-581.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Semi-supervised ladder network for hyperspectral image classification[J].Journal of Geomatics Science and Technology, 2017, 34 (6) :576-581." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFJC201706006&amp;v=MDk4OTRyaFdyN09MeXZCYmJHNEg5Yk1xWTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刘冰, 余旭初, 张鹏强, 等.面对高光谱影像分类的半监督阶梯网络[J].测绘科学技术学报, 2017, 34 (6) :576-581.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Semi-supervised ladder network for hyperspectral image classification[J].Journal of Geomatics Science and Technology, 2017, 34 (6) :576-581.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" GHAMISI P, PLAZA J, CHEN Yushi, et al.Advanced spectral classifiers for hyperspectral images:a review[J].IEEE Geoscience and Remote Sensing Magazine, 2017, 5 (1) :8-32." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advanced Spectral Classifiers for Hyperspectral Images:A Review">
                                        <b>[3]</b>
                                         GHAMISI P, PLAZA J, CHEN Yushi, et al.Advanced spectral classifiers for hyperspectral images:a review[J].IEEE Geoscience and Remote Sensing Magazine, 2017, 5 (1) :8-32.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" GHAMISI P, MURA M D, BENEDIKTSSON J A.A survey on spectral-spatial classification techniques based on attribute profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2335-2353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Survey on Spectral-Spatial Classification Techniques Based on Attribute Profiles">
                                        <b>[4]</b>
                                         GHAMISI P, MURA M D, BENEDIKTSSON J A.A survey on spectral-spatial classification techniques based on attribute profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2335-2353.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" BENEDIKTSSON J A, PALMASON J A, SVEINSSON J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of hyperspectral data from urban areas based on extended morphological profiles">
                                        <b>[5]</b>
                                         BENEDIKTSSON J A, PALMASON J A, SVEINSSON J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 王雷光, 曹小汪, 郑雅兰, 等.高光谱影像的引导滤波多尺度特征提取[J].遥感学报, 2018, 22 (2) :293-303.WANG Leiguang, CAO Xiaowang, ZHENG Yalan, et al.Multi-scale feature extraction of hyperspectral image with guided filtering[J].Journal of Remote Sensing, 2018, 22 (2) :293-303." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXB201802009&amp;v=Mjg3MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmhXcjdPUENyVGJMRzRIOW5Nclk5RmJZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         王雷光, 曹小汪, 郑雅兰, 等.高光谱影像的引导滤波多尺度特征提取[J].遥感学报, 2018, 22 (2) :293-303.WANG Leiguang, CAO Xiaowang, ZHENG Yalan, et al.Multi-scale feature extraction of hyperspectral image with guided filtering[J].Journal of Remote Sensing, 2018, 22 (2) :293-303.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" SHEN Linlin, JIA Sen.Three-dimensional Gabor wavelets for pixel-based hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2011, 49 (12) :5039-5046." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Three-dimensional gabor wavelets for pixel-based hyperspectral imagery classification">
                                        <b>[7]</b>
                                         SHEN Linlin, JIA Sen.Three-dimensional Gabor wavelets for pixel-based hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2011, 49 (12) :5039-5046.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" LI Wei, CHEN Chen, SU Hongjun, et al.Local binary patterns and extreme learning machine for hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (7) :3681-3693." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local binary patterns and extreme learning machine for hyperspectral imagery classification">
                                        <b>[8]</b>
                                         LI Wei, CHEN Chen, SU Hongjun, et al.Local binary patterns and extreme learning machine for hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (7) :3681-3693.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" TARABALKA Y, BENEDIKTSSON J A, CHANUSSOT J.Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques[J].IEEE Transactions on Geoscience and Remote Sensing, 2009, 47 (8) :2973-2987." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques">
                                        <b>[9]</b>
                                         TARABALKA Y, BENEDIKTSSON J A, CHANUSSOT J.Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques[J].IEEE Transactions on Geoscience and Remote Sensing, 2009, 47 (8) :2973-2987.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" 贾森, 吴奎霖, 朱家松, 等.面向高光谱图像分类的超像素级Gabor特征融合方法研究[J].南京信息工程大学学报 (自然科学版) , 2018, 10 (1) :72-80.JIA Sen, WU Kuilin, ZHU Jiasong, et al.Superpixel-level Gabor feature fusion method for hyperspectral image classification[J].Journal of Nanjing University of Information Science and Technology (Natural Science Edition) , 2018, 10 (1) :72-80." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJXZ201801008&amp;v=MjM4MTF2RnlyaFdyN09LeWZUZExHNEg5bk1ybzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         贾森, 吴奎霖, 朱家松, 等.面向高光谱图像分类的超像素级Gabor特征融合方法研究[J].南京信息工程大学学报 (自然科学版) , 2018, 10 (1) :72-80.JIA Sen, WU Kuilin, ZHU Jiasong, et al.Superpixel-level Gabor feature fusion method for hyperspectral image classification[J].Journal of Nanjing University of Information Science and Technology (Natural Science Edition) , 2018, 10 (1) :72-80.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" KANG Xudong, LI Shutao, BENEDIKTSSON J A.Spectral-spatial hyperspectral image classification with edge-preserving filtering[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (5) :2666-2677." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial Hyperspectral Image Classification with Edge-Preserving Filtering">
                                        <b>[11]</b>
                                         KANG Xudong, LI Shutao, BENEDIKTSSON J A.Spectral-spatial hyperspectral image classification with edge-preserving filtering[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (5) :2666-2677.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" CHEN Yushi, LIN Zhouhan, ZHAO Xing, et al.Deep learning-based classification of hyperspectral data[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (6) :2094-2107." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning-based classification of hyperspectral data">
                                        <b>[12]</b>
                                         CHEN Yushi, LIN Zhouhan, ZHAO Xing, et al.Deep learning-based classification of hyperspectral data[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (6) :2094-2107.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.A semi-supervised convolutional neural network for hyperspectral image classification[J].Remote Sensing Letters, 2017, 8 (9) :839-848." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD1632C6163AF65870F6EAB1D14AA3AE0A&amp;v=MzEzMjJIbE1McnVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDU5bGh4cnkyd2E0PU5qbkJhcksrSGRPL3FZNURaNXA1Q25reHlCWmw3RW9NT242V3JSWkVDTA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.A semi-supervised convolutional neural network for hyperspectral image classification[J].Remote Sensing Letters, 2017, 8 (9) :839-848.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     YUE Jun, ZHAO Wenzhi, MAO Shanjun, et al.Spectral-spatial classification of hyperspectral images using deep convolutional neural networks[J].Remote Sensing Letters, 2015, 6 (6) :468-477.</a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Supervised deep feature extraction for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (4) :1909-1921." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised deep feature extraction for hyperspectral image classification">
                                        <b>[15]</b>
                                         LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Supervised deep feature extraction for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (4) :1909-1921.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" MEI Shaohui, JI Jingyu, HOU Junhui, et al.Learning sensor-specific spatial-spectral features of hyperspectral images via convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing, 2017, 55 (8) :4520-4533." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning sensor-specific spatial-spectral features of hyperspectral images via convolutional neural networks">
                                        <b>[16]</b>
                                         MEI Shaohui, JI Jingyu, HOU Junhui, et al.Learning sensor-specific spatial-spectral features of hyperspectral images via convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing, 2017, 55 (8) :4520-4533.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Spectral-spatial classification of hyperspectral image using three-dimensional convolution network[J].Journal of Applied Remote Sensing, 2018, 12 (1) :016005." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGE34AC7615B4CA75BB9430853AD20EC6C&amp;v=MzAzMzNCdUhZZk9HUWxmQnJMVTA1OWxoeHJ5MndhND1OaWZPYWNhN0dxQy9xSWxFWVprTGZ3MCt5bVJoNHp0K1NIZm5yMk5CZTdMaE5yenNDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Spectral-spatial classification of hyperspectral image using three-dimensional convolution network[J].Journal of Applied Remote Sensing, 2018, 12 (1) :016005.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" LIU Bing, YU Xuchu, YU Anzhu, et al.Spectral-spatial classification of hyperspectral imagery based on recurrent neural networks[J].Remote Sensing Letters, 2018, 9 (12) :1118-1127." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDB1A648C2C388FF8CCDC6B18B5C272317&amp;v=MTc2NzM5ZklwL3hIRitnSEJBcFB4MlZnbmt4N09uN3EzaGRHZTdXV1JydVlDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDU5bGh4cnkyd2E0PU5qbkJhc0c1Yg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         LIU Bing, YU Xuchu, YU Anzhu, et al.Spectral-spatial classification of hyperspectral imagery based on recurrent neural networks[J].Remote Sensing Letters, 2018, 9 (12) :1118-1127.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" 崔丽群, 赵越, 胡志毅, 等.复合域的显著性目标检测方法[J].中国图象图形学报, 2018, 23 (6) :846-856.CUI Liqun, ZHAO Yue, HU Zhiyi, et al.Saliency object detection method based on complex domains[J].Journal of Image and Graphics, 2018, 23 (6) :846-856." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201806007&amp;v=MDQ2NjRSN3FmWnVkdkZ5cmhXcjdPUHlyZmJMRzRIOW5NcVk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         崔丽群, 赵越, 胡志毅, 等.复合域的显著性目标检测方法[J].中国图象图形学报, 2018, 23 (6) :846-856.CUI Liqun, ZHAO Yue, HU Zhiyi, et al.Saliency object detection method based on complex domains[J].Journal of Image and Graphics, 2018, 23 (6) :846-856.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" 何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612.HE Xiaofei, ZOU Zhengrong, TAO Chao, et al.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201609011&amp;v=MTUxNDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyaFdyN09KaVhUYkxHNEg5Zk1wbzlFWllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612.HE Xiaofei, ZOU Zhengrong, TAO Chao, et al.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" SU Peifeng, LIU Daizhi, LI Xihai, et al.A saliency-based band selection approach for hyperspectral imagery inspired by scale selection[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (4) :572-576." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A saliency-based band selection approach for hyperspectral imagery inspired by scale selection">
                                        <b>[21]</b>
                                         SU Peifeng, LIU Daizhi, LI Xihai, et al.A saliency-based band selection approach for hyperspectral imagery inspired by scale selection[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (4) :572-576.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" PERAZZI F, KR&#196;HENB&#220;HL P, PRITCH Y, et al.Saliency filters:contrast based filtering for salient region detection[C]//2012 IEEE Conference on Computer Vision and Pattern Recognition.Providence, RI, USA:IEEE, 2012:733-740." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency filters:Contrast based filtering for salient region detection">
                                        <b>[22]</b>
                                         PERAZZI F, KR&#196;HENB&#220;HL P, PRITCH Y, et al.Saliency filters:contrast based filtering for salient region detection[C]//2012 IEEE Conference on Computer Vision and Pattern Recognition.Providence, RI, USA:IEEE, 2012:733-740.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" LIU Tie, YUAN Zejian, SUN Jian, et al.Learning to detect a salient object[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (2) :353-367." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning to Detect a Salient Object">
                                        <b>[23]</b>
                                         LIU Tie, YUAN Zejian, SUN Jian, et al.Learning to detect a salient object[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (2) :353-367.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SLIC Superpixels Compared to State-of-the-Art Superpixel Methods">
                                        <b>[24]</b>
                                         ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" 崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594.CUI Lingling, XU Jinlan, XU Gang, et al.Image saliency detection method based on a pair of feature maps[J].Journal of Image and Graphics, 2018, 23 (4) :583-594." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201804013&amp;v=MDc3MTE0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T1B5cmZiTEc0SDluTXE0OUVaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594.CUI Lingling, XU Jinlan, XU Gang, et al.Image saliency detection method based on a pair of feature maps[J].Journal of Image and Graphics, 2018, 23 (4) :583-594.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_26" title=" 刘冰, 余旭初, 张鹏强, 等.联合空-谱信息的高光谱影像深度三维卷积网络分类[J].测绘学报, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Deep 3D convolutional network combined with spatial-spectral features for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201901008&amp;v=MjgyNTN5cmhXcjdPSmlYVGJMRzRIOWpNcm85RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         刘冰, 余旭初, 张鹏强, 等.联合空-谱信息的高光谱影像深度三维卷积网络分类[J].测绘学报, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Deep 3D convolutional network combined with spatial-spectral features for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578.
                                    </a>
                                </li>
                                <li id="54">


                                    <a id="bibliography_27" title=" 余旭初, 谭熊, 付琼莹, 等.联合纹理和光谱特征的高光谱影像多核分类方法[J].测绘通报, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289.YU Xuchu, TAN Xiong, FU Qiongying, et al.Combined texture-spectral feature for multiple kernel classification of hyperspectral images[J].Bulletin of Surveying and Mapping, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB201409011&amp;v=MDY4Njg2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T0ppWGZiTEc0SDlYTXBvOUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                         余旭初, 谭熊, 付琼莹, 等.联合纹理和光谱特征的高光谱影像多核分类方法[J].测绘通报, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289.YU Xuchu, TAN Xiong, FU Qiongying, et al.Combined texture-spectral feature for multiple kernel classification of hyperspectral images[J].Bulletin of Surveying and Mapping, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289.
                                    </a>
                                </li>
                                <li id="56">


                                    <a id="bibliography_28" title=" LIU Bing, YU Xuchu, YU Anzhu, et al.Deep few-shot learning for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2019, 57 (4) :2290-2304." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep few-shot learning for hyperspectral image classification">
                                        <b>[28]</b>
                                         LIU Bing, YU Xuchu, YU Anzhu, et al.Deep few-shot learning for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2019, 57 (4) :2290-2304.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(08),985-995 DOI:10.11947/j.AGCS.2019.20180499            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向高光谱影像分类的显著性特征提取方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E5%B2%B8%E7%AB%B9&amp;code=26360843&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">余岸竹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%86%B0&amp;code=20454626&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘冰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%A2%E5%BF%97%E9%B9%8F&amp;code=30504208&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邢志鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E5%B8%86&amp;code=42620005&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨帆</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E5%85%B6%E6%B7%BC&amp;code=42620006&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨其淼</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6&amp;code=0199248&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息工程大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=32023%E9%83%A8%E9%98%9F&amp;code=1745695&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">32023部队</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对高光谱影像分类问题, 提出了一种显著性特征提取方法。首先, 利用超像素分割算法将高光谱影像3个相邻波段分割为若干个小区域。然后, 基于分割得到的小区域计算反映不同区域的显著性特征。最后, 沿着光谱方向采用大小为3、步长为1的滑窗法获得所有波段的显著性特征。进一步将提取的显著性特征与光谱特征进行结合, 并将结合后的特征输入到支持向量机中进行分类。利用Pavia大学、Indian Pines和Salinas 3组高光谱影像数据进行分类试验。试验结果表明, 与传统的空间特征提取方法和基于卷积神经网络的高光谱影像分类方法相比, 提取的显著性特征能够获得更高的高光谱影像分类精度, 且结合光谱特征能够进一步提高分类精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1%E5%BD%B1%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱影像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%98%BE%E8%91%97%E6%80%A7%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">显著性特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    余岸竹 (1989—) , 男, 博士, 研究方向为机器视觉与图像智能处理。;
                                </span>
                                <span>
                                    *刘冰, E-mail:liubing220524@126.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (41801388);</span>
                    </p>
            </div>
                    <h1>Salient feature extraction method for hyperspectral image classification</h1>
                    <h2>
                    <span>YU Anzhu</span>
                    <span>LIU Bing</span>
                    <span>XING Zhipeng</span>
                    <span>YANG Fan</span>
                    <span>YANG Qimiao</span>
            </h2>
                    <h2>
                    <span>Information Engineering University</span>
                    <span>32023 Troops</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of hyperspectral image classification, a salient feature extraction method is proposed. Firstly, the method uses a superpixel segmentation algorithm to divide three adjacent bands of hyperspectral image into several small regions. Then, the salient features of different regions are calculated based on the small regions. Finally, the sliding window method with a size of 3 steps is used along the spectral direction to obtain the salient features of all bands. The extracted saliency features are further combined with the spectral features, and the combined features are fed into a support vector machine for classification. The classification experiments were carried out on three hyperspectral image datasets including Pavia University, Indian Pines and Salinas. The experimental results show that compared with the traditional spatial feature extraction method and the convolutional neural network based methods, the extracted salient features can obtain higher classification accuracy. Combining salient features and spectral features can further improve classification accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral%20image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=salient%20feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">salient feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20vector%20machine%20(SVM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support vector machine (SVM) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YU Anzhu (1989—) , male, PhD, majors in machine vision and image intelligent processing.E-mail: anzhu_yu@126.com;
                                </span>
                                <span>
                                    LIU Bing, E-mail: liubing220524@126.com;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-08</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China (No.41801388);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="58">近年来, 随着遥感平台和传感器的不断进步, 人们获取高光谱遥感影像的能力不断提高。但在完成数据获取以后, 数据的处理与分析将真正决定地物探测的水平。高光谱影像分类能够为高光谱影像的进一步应用提供基础, 是高光谱遥感中的关键技术和研究热点之一<citation id="137" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。高光谱影像中可以获取每个像素近似连续的光谱曲线, 这些光谱曲线能够较好地反映地物的属性信息, 这就为地物的精细分类提供了可能。但近似连续的光谱曲线导致了高光谱影像具有高维的数据特点, 且在高光谱影像中获取标记数据较为困难, 可用于训练的标记样本数量较少。高维的数据结构和较少的训练样本数量给高光谱影像分类带来了极大的挑战<citation id="138" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">早期的高光谱影像分类方法通过提取光谱特征, 并结合支持向量机、决策树、逻辑回归等分类器进行分类<citation id="139" type="reference"><link href="6" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。但在高光谱影像中“同谱异物”和“同物异谱”的现象广泛存在, 这就导致仅仅利用光谱信息进行分类具有一定的局限性。高光谱影像具有“图谱合一”的特点, 在提供光谱特征的同时, 也提供了丰富的空间信息。而大量的研究表明, 在分类过程中引入空间信息能够降低地物分类的不确定性, 从而能够提高高光谱影像分类的精度<citation id="140" type="reference"><link href="8" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。拓展形态学属性剖面<citation id="141" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation> (extended morphological profile, EMP) 通过形态学操作提取高光谱影像的空间结构信息, 并与光谱特征结合进行分类, 有效地改善了高光谱影像的分类效果。除了EMP, 还可以应用滤波半径依次增加的引导滤波器来获得影像不同尺度的结构信息, 进而提高分类精度<citation id="142" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。纹理特征也是一种能够有效利用空间信息的方法, 常用于高光谱影像分类的纹理特征有Gabor特征<citation id="143" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、局部二值模式<citation id="144" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>纹理特征等。除了上述在特征提取过程中考虑空间邻域信息, 也可以利用聚类获得的空间信息来提高高光谱影像的分类精度。文献<citation id="145" type="reference">[<a class="sup">9</a>]</citation>利用聚类信息对支持向量机的分类结果进行后处理, 进一步提高了高光谱影像的分类精度。文献<citation id="146" type="reference">[<a class="sup">10</a>]</citation>在利用支持向量机对Gabor特征进行分类的基础上, 采用多数投票策略进一步融合超像素分割结果, 在训练样本数量较少的情况下取得了较为理想的分类精度。文献<citation id="147" type="reference">[<a class="sup">11</a>]</citation>提出利用边缘保持滤波对分类结果进行处理, 既能滤除分类结果中孤立的分类噪声, 又能较好地保持分类结果的边缘, 因此能够提高分类精度。</p>
                </div>
                <div class="p1">
                    <p id="60">近年来, 随着计算能力和数据获取能力的不断提高, 深度学习方法得到了快速发展, 已经被广泛应用于自然语言处理、图像分类识别、高分辨率遥感影像处理、高光谱影像分类等领域。最早用于高光谱影像分类的深度学习模型是堆栈式自编码器, 该方法先利用主成分分析对高光谱影像进行降维处理, 然后选取一定的邻域范围, 并展成一维特征向量输入到堆栈式自编码器中进行分类<citation id="148" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。随后, 利用光谱特征的一维卷积神经网络模型也被引入到了高光谱分类领域中<citation id="149" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。为了进一步提高高光谱影像的分类精度, 二维卷积神经网络被用于提取高光谱影像的空间特征, 并将空间特征与光谱特征结合进行分类, 取得了较为理想的分类结果<citation id="152" type="reference"><link href="28" rel="bibliography" /><link href="30" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>。此外, 研究人员还利用三维卷积神经网络<citation id="150" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和循环神经网络<citation id="151" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提取高光谱影像的空-谱特征进行分类。基于深度学习的高光谱影像分类方法能够自动从数据中学习如何提取特征, 简化了高光谱影像分类的处理流程, 但仍然面临小样本问题的挑战。</p>
                </div>
                <div class="p1">
                    <p id="61">视觉显著性是人类视觉系统的重要机制, 其能够快速准确地提取场景中最感兴趣的区域, 并忽略冗余的信息<citation id="153" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。视觉显著性估计已经被广泛应用于遥感图像处理和分析中, 例如文献<citation id="154" type="reference">[<a class="sup">20</a>]</citation>联合显著性和多层卷积神经网络进行高分辨率遥感影像场景分类;文献<citation id="155" type="reference">[<a class="sup">21</a>]</citation>对高光谱影像进行显著性波段选择, 从而提高高光谱影像的分类精度。为充分利用空间信息提高高光谱影像分类精度, 本文以显著性滤波器为基础, 提出了一种用于高光谱影像分类的显著性特征提取方法, 并进一步结合光谱特征进行分类。最后利用Pavia大学、Indian Pines和Salinas 3组高光谱数据集验证了本文算法的有效性。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">1 高光谱影像显著性特征提取与分类</h3>
                <div class="p1">
                    <p id="63">视觉显著性估计中通常以彩色图像为输入<citation id="156" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 因此, 本文以3个相邻波段的高光谱影像为输入, 进行显著性特征提取, 然后沿光谱维度利用滑窗法获取各个波段的显著性特征, 最后将各个波段的显著性特征进行堆叠形成最终用于分类的显著性特征。如图1所示, 3个相邻波段的高光谱影像显著性特征提取主要包括超像素分割、对比度计算和显著性分配3个步骤。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">1.1 SLIC超像素分割</h4>
                <div class="p1">
                    <p id="65">基于像素的视觉显著性估计方法对噪声较为敏感, 而超像素以相对简单的方式表示图像并能减少图像的冗余, 同时每个超像素块具有相同的性质<citation id="157" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。为了更加有效地提取显著性特征, 首先将输入的三波段高光谱影像根据颜色相似性分割为若干个超像素, 每个超像素由区域内的颜色均值表示, 进而以超像素为基础进行视觉显著性估计。本文采用SLIC<citation id="158" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation> (simple linear iterative cluster) 方法对输入的三波段高光谱影像进行超像素分割。</p>
                </div>
                <div class="p1">
                    <p id="66">SLIC算法是基于k-means聚类设计的超像素分割算法, 其根据CIE LAB颜色空间和二维坐标构成的5维特征向量进行局部聚类, 并将搜索空间限制在与超像素大小成比例的区域内来提高计算效率<citation id="159" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。SLIC算法接受一个参数<i>K</i> (<i>K</i>为超像素分割的个数) , 首先初始化<i>K</i>个种子点, 并在每个种子点的邻域空间内搜索距离该种子点最近的若干像素, 将它们与该种子点归为一类, 直到所有像素点都归类完毕;然后计算这<i>K</i>个超像素里所有像素点的平均向量值作为新的聚类中心;再根据更新后的<i>K</i>个聚类中心重复上述步骤, 迭代直到收敛。<i>K</i>个种子之间的初始距离定义为<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><msqrt><mrow><mi>Ν</mi><mo>/</mo><mi>Κ</mi></mrow></msqrt></mrow></math></mathml>, 其中<i>N</i>为图像的像素个数, 搜索邻域范围设置为2<i>S</i>×2<i>S</i>。其中, 距离度量包括颜色距离<i>d</i><sub><i>c</i></sub>和空间距离<i>d</i><sub><i>s</i></sub>, 两种距离的计算方式如下</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>b</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mtd></mtr><mtr><mtd><mi>D</mi><mo>=</mo><msqrt><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mi>c</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mi>s</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mtd></mtr></mtable><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中, <i>l</i>、<i>a</i>、<i>b</i>为CIE LAB颜色空间对应的3个通道变量;<i>i</i>和<i>j</i>为超像素的索引;<i>N</i><sub><i>c</i></sub>和<i>N</i><sub><i>s</i></sub>分别为最大的颜色距离和种子点之间最大的距离。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3个波段显著性特征提取流程" src="Detail/GetImg?filename=images/CHXB201908006_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 3个波段显著性特征提取流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Salient feature extraction of three adjacent bands</p>

                </div>
                <div class="p1">
                    <p id="71">SLIC算法能够有效地将图像分割为若干个超像素块, 每个超像素块内部像素属性趋于一致, 并由颜色均值表示。这样可以在特征提取的过程中充分考虑像素周围的局部空间信息, 同时能够降低噪声对特征提取的影响。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">1.2 对比度计算</h4>
                <div class="p1">
                    <p id="73">视觉显著性检测中通常通过计算对比度来进行显著性估计, 为了更加充分地利用全局空间信息, 以分割后的超像素为基础, 定义颜色独立性和空间颜色分布两种对比度。颜色独立性定义如下</p>
                </div>
                <div class="area_img" id="166">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908006_16600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="76">式中, <i>c</i><sub><i>j</i></sub>=[<i>l</i><sub><i>j</i></sub>, <i>a</i><sub><i>j</i></sub><i>b</i><sub><i>j</i></sub>]和<i>p</i><sub><i>j</i></sub>=[<i>x</i><sub><i>j</i></sub>, <i>y</i><sub><i>j</i></sub>]分别为第<i>j</i>个超像素的颜色和位置;<i>w</i><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>表示局部或全局对比的控制变量, 权重与超像素空间位置的距离有关;<i>Z</i><sub><i>i</i></sub>为归一化因子, 用于保证<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup><mo>=</mo><mn>1</mn></mrow></math></mathml>;<i>σ</i><sub><i>p</i></sub>为参数。由式 (2) 可知, 距离越远则权值越小, 对显著性影响越小;而某个超像素颜色越独特, 则<i>U</i><sub><i>i</i></sub>越大, 也表示该超像素越显著。</p>
                </div>
                <div class="p1">
                    <p id="79">进一步可将式 (2) 改写为</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>c</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></mstyle><mn>1</mn></munder><mo>-</mo><mn>2</mn><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>c</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></mstyle><mrow><mtext>b</mtext><mtext>l</mtext><mtext>u</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>c</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mo>+</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>c</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>p</mi></msubsup></mrow></mstyle><mrow><mtext>b</mtext><mtext>l</mtext><mtext>u</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>c</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></munder><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">式中, 第1项的结果是1;第2和第3项可以通过以<i>w</i>为核的滤波器, 分别对<i>c</i><sub><i>j</i></sub>和<i>c</i><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></math></mathml>进行滤波加以实现。</p>
                </div>
                <div class="p1">
                    <p id="83">空间颜色分布定义如下</p>
                </div>
                <div class="area_img" id="167">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908006_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="86">式中, <i>c</i><sub><i>j</i></sub>=[<i>l</i><sub><i>j</i></sub>, <i>a</i><sub><i>j</i></sub><i>b</i><sub><i>j</i></sub>]和<i>p</i><sub><i>j</i></sub>=[<i>x</i><sub><i>j</i></sub>, <i>y</i><sub><i>j</i></sub>]分别为第<i>j</i>个超像素的颜色和位置;<i>w</i><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>表示表示<i>i</i>和<i>j</i>个超像素的颜色相似度;<i>Z</i><sub><i>i</i></sub>为归一化因子;<i>σ</i><sub><i>c</i></sub>为参数;<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>为第<i>i</i>个超像素的加权平均位置。<i>D</i><sub><i>i</i></sub>可以表示某种颜色在空间分布的广度, 例如某种地物颜色分散在图像中, 但是面积都很小, 那么计算出来的颜色独立性就比较高, 但空间颜色分布较广, 说明该类地物并不显著。</p>
                </div>
                <div class="p1">
                    <p id="89">式 (4) 可以改写为</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup><mo>-</mo><mn>2</mn><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup></mrow></mstyle><mrow><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mo>+</mo><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup></mrow></mstyle><mn>1</mn></munder><mo>=</mo></mtd></mtr><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>c</mi></msubsup></mrow></mstyle><mrow><mtext>b</mtext><mtext>l</mtext><mtext>u</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>p</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></munder><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></mstyle><mrow><mtext>b</mtext><mtext>l</mtext><mtext>u</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">与式 (2) 类似, 式 (4) 可以通过对<i>p</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></math></mathml>和<i>p</i><sub><i>j</i></sub>进行滤波的方式加以实现。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">1.3 显著性分配</h4>
                <div class="p1">
                    <p id="94">根据颜色独立性和空间颜色分布计算每个超像素的显著性为</p>
                </div>
                <div class="p1">
                    <p id="95"><i>S</i><sub><i>i</i></sub>=<i>U</i><sub><i>i</i></sub>exp (-<i>kD</i><sub><i>i</i></sub>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="96">由式 (6) 可知空间颜色分布<i>D</i><sub><i>i</i></sub>越大即颜色分布越广, 对应显著性值越小;颜色独立性<i>U</i><sub><i>i</i></sub>越大, 则对应显著性值越大。最终定义每个像素的显著性如下</p>
                </div>
                <div class="area_img" id="168">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908006_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="99">式中, <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ζ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">∥</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow></mrow></math></mathml>, 每个像素的显著性是通过其所在超像素单元以及周围的超像素单元进行高斯线性加权, 权重取决于颜色和位置的距离, 同样可以通过滤波加以实现。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">1.4 高光谱影像显著性特征提取与分类</h4>
                <div class="p1">
                    <p id="102">由于高光谱影像具有众多波段, 因此需要沿光谱方向依次获取各个波段的显著性特征。最后将各个波段获得的显著性特征图进行堆叠, 形成维度为<i>B</i>-2的显著性特征向量, 其中<i>B</i>为波段数。为进一步提高分类精度, 将每个像素的显著性特征向量和光谱特征向量进行连接形成最终用于分类的特征。</p>
                </div>
                <div class="p1">
                    <p id="103">大量的研究已经表明支持向量机是一种快速可靠的分类器, 因此本文采用支持向量机作为最终的分类器。其中支持向量机的核函数采用高斯核函数, 核函数参数和惩罚系数在2<sup>-2</sup>, 2<sup>-1</sup>, …, 2<sup>7</sup>范围内通过5折交叉验证确定。</p>
                </div>
                <h3 id="104" name="104" class="anchor-tag">2 试验结果与分析</h3>
                <h4 class="anchor-tag" id="105" name="105">2.1 试验数据</h4>
                <div class="p1">
                    <p id="106">参照文献<citation id="160" type="reference">[<a class="sup">26</a>]</citation>, 采用Pavia大学、Indian Pines和Salinas 3组高光谱数据集进行分类试验来验证显著性特征提取方法的有效性。Pavia大学数据集由ROSIS传感器获得, Indian Pines和Salinas数据集由AVIRIS传感器获得。Pavia大学数据集的影像大小为610×340像素, 空间分辨率为1.3 m, 光谱覆盖范围为430～860 nm, 有103个有效波段可用于分类试验。Indian Pines数据集的影像大小为145×145像素, 空间分辨率为20 m, 光谱覆盖范围为400～2500 nm, 有200个有效波段可用于分类。Salinas数据集的影像大小为512×217像素, 空间分辨率为3.7 m, 光谱覆盖范围为430～860 nm, 有204个有效波段可用于分类。3组高光谱影像数据集的地物类别、选取的训练样本数量和测试样本数量分别如表1—表3所示。</p>
                </div>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表1 Pavia大学数据集样本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 The information of samples on the University of Pavia dataset</b></p>
                    <p class="img_note"></p>
                    <table id="107" border="1"><tr><td><br />序号</td><td>地物类别</td><td>训练样本</td><td>确认样本</td><td>测试样本</td></tr><tr><td><br />1</td><td>柏油路面</td><td>180</td><td>20</td><td>6631</td></tr><tr><td><br />2</td><td>草地</td><td>180</td><td>20</td><td>18 649</td></tr><tr><td><br />3</td><td>砖块砂砾</td><td>180</td><td>20</td><td>2099</td></tr><tr><td><br />4</td><td>树木</td><td>180</td><td>20</td><td>3064</td></tr><tr><td><br />5</td><td>金属板</td><td>180</td><td>20</td><td>1345</td></tr><tr><td><br />6</td><td>裸土</td><td>180</td><td>20</td><td>5029</td></tr><tr><td><br />7</td><td>沥青屋顶</td><td>180</td><td>20</td><td>1330</td></tr><tr><td><br />8</td><td>砖块</td><td>180</td><td>20</td><td>3682</td></tr><tr><td><br />9</td><td>阴影</td><td>180</td><td>20</td><td>947</td></tr><tr><td><br /></td><td>总数</td><td>1620</td><td>180</td><td>42 776</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表2 Indian Pines数据集样本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 The information of samples on the Indian Pines dataset</b></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td><br />序号</td><td>地物类别</td><td>训练样本</td><td>确认样本</td><td>测试样本</td></tr><tr><td><br />1</td><td>未耕玉米地</td><td>180</td><td>20</td><td>1428</td></tr><tr><td><br />2</td><td>玉米幼苗</td><td>180</td><td>20</td><td>830</td></tr><tr><td><br />3</td><td>草地/牧场</td><td>180</td><td>20</td><td>483</td></tr><tr><td><br />4</td><td>草地树木</td><td>180</td><td>20</td><td>730</td></tr><tr><td><br />5</td><td>干草/料堆</td><td>180</td><td>20</td><td>478</td></tr><tr><td><br />6</td><td>未耕大豆地</td><td>180</td><td>20</td><td>972</td></tr><tr><td><br />7</td><td>大豆幼苗</td><td>180</td><td>20</td><td>2455</td></tr><tr><td><br />8</td><td>整理过的大豆</td><td>180</td><td>20</td><td>593</td></tr><tr><td><br />9</td><td>木材</td><td>180</td><td>20</td><td>1265</td></tr><tr><td><br /></td><td>总数</td><td>1620</td><td>180</td><td>9234</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表3 Salinas数据集样本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.3 The information of samples on the Salinas dataset</b></p>
                    <p class="img_note"></p>
                    <table id="109" border="1"><tr><td><br />序号</td><td>地物类别</td><td>训练样本</td><td>确认样本</td><td>测试样本</td></tr><tr><td><br />1</td><td>椰菜_绿_野草1</td><td>180</td><td>20</td><td>2009</td></tr><tr><td><br />2</td><td>椰菜_绿_野草2</td><td>180</td><td>20</td><td>3726</td></tr><tr><td><br />3</td><td>休耕地</td><td>180</td><td>20</td><td>1976</td></tr><tr><td><br />4</td><td>粗糙的休耕地</td><td>180</td><td>20</td><td>1394</td></tr><tr><td><br />5</td><td>平滑的休耕地</td><td>180</td><td>20</td><td>2678</td></tr><tr><td><br />6</td><td>残株</td><td>180</td><td>20</td><td>3959</td></tr><tr><td><br />7</td><td>芹菜</td><td>180</td><td>20</td><td>3579</td></tr><tr><td><br />8</td><td>未结果实的葡萄</td><td>180</td><td>20</td><td>11 271</td></tr><tr><td><br />9</td><td>正在开发的葡萄园土壤</td><td>180</td><td>20</td><td>6203</td></tr><tr><td><br />10</td><td>开始衰老的玉米</td><td>180</td><td>20</td><td>3278</td></tr><tr><td><br />11</td><td>长叶莴苣4 wk</td><td>180</td><td>20</td><td>1068</td></tr><tr><td><br />12</td><td>长叶莴苣5 wk</td><td>180</td><td>20</td><td>1927</td></tr><tr><td><br />13</td><td>长叶莴苣6 wk</td><td>180</td><td>20</td><td>916</td></tr><tr><td><br />14</td><td>长叶莴苣7 wk</td><td>180</td><td>20</td><td>1070</td></tr><tr><td><br />15</td><td>未结果实的葡萄园</td><td>180</td><td>20</td><td>7268</td></tr><tr><td><br />16</td><td>葡萄园小路</td><td>180</td><td>20</td><td>1807</td></tr><tr><td><br /></td><td>总数</td><td>2880</td><td>320</td><td>54 129</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="110" name="110">2.2 参数设置</h4>
                <div class="p1">
                    <p id="111">本文提出的高光谱影像显著性特征提取涉及的参数主要包括:颜色独立性调节参数<i>σ</i><sub><i>p</i></sub>、空间颜色分布调节参数<i>σ</i><sub><i>c</i></sub>和分割超像素的个数<i>K</i>。本小节以Pavia大学数据集为例分析不同的参数设置对最终分类结果的影响。需要指出的是本小节的分类试验没有结合光谱特征, 仅采用了显著性特征。</p>
                </div>
                <div class="p1">
                    <p id="112">图2所示为在Pavia大学数据集中设置不同的<i>K</i>值对应的总体分类精度和特征提取所需时间。由图2可知, 当<i>K</i>值较少时 (例如100、200) , 分类精度较低;而当<i>K</i>值大于500时, 均能够取得较为理想的分类精度;但随着<i>K</i>值的增大, 特征提取所需时间也相应增加, 而分类精度提升却不明显。在实际应用过程中应该根据高光谱影像大小适当增大<i>K</i>。本文综合考虑分类精度和计算效率统一设置<i>K</i>=500。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Pavia大学数据集不同的K值对应的总体分类精度和计算时间" src="Detail/GetImg?filename=images/CHXB201908006_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Pavia大学数据集不同的<i>K</i>值对应的总体分类精度和计算时间  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Overall accuracy and computing time with different number of elements decomposed by SLIC on the University of Pavia dataset</p>

                </div>
                <div class="p1">
                    <p id="114">为了分析<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>对最终分类精度的影响, 分别设置<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>为0.25、1、5、10、20。图3所示为在Pavia大学数据集中设置不同的<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>值对应的总体分类精度。分析图3可知, 当<i>σ</i><sub><i>p</i></sub>值固定时, 总体分类精度随着<i>σ</i><sub><i>c</i></sub>的增加而增加, 而当<i>σ</i><sub><i>c</i></sub>固定时, 总体分类精度大体上随着<i>σ</i><sub><i>p</i></sub>的减小而增加。这说明为了获取更高的分类精度, 应该设置较大<i>σ</i><sub><i>c</i></sub>的值和较小<i>σ</i><sub><i>p</i></sub>的值。根据图3, 最终设置<i>σ</i><sub><i>c</i></sub>=20、<i>σ</i><sub><i>p</i></sub>=0.25。</p>
                </div>
                <div class="p1">
                    <p id="115">通过以上分析, 本文提出的高光谱影像显著性特征提取方法对于分割超像素的个数<i>K</i>、颜色独立性调节参数<i>σ</i><sub><i>p</i></sub>、空间颜色分布调节参数<i>σ</i><sub><i>c</i></sub> 3个参数较为敏感。实际应用中应该根据高光谱影像的大小适当调节<i>K</i>值的大小, 即影像越大, <i>K</i>的值也越大。需要指出的是, 过小的<i>K</i>值会导致精度下降, 根据本文结果建议设置<i>K</i>≥500较为合理。对于<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>, 应该设置较大的<i>σ</i><sub><i>c</i></sub>值和较小的<i>σ</i><sub><i>p</i></sub>值。根据本文试验结果设置<i>σ</i><sub><i>c</i></sub>=20、<i>σ</i><sub><i>p</i></sub>=0.25较为合理。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Pavia大学数据集不同的σc和σp值对应的总体分类精度" src="Detail/GetImg?filename=images/CHXB201908006_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Pavia大学数据集不同的<i>σ</i><sub><i>c</i></sub>和<i>σ</i><sub><i>p</i></sub>值对应的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Overall accuracy with different <i>σ</i><sub><i>c</i></sub> and <i>σ</i><sub><i>p</i></sub> on the University of Pavia dataset</p>

                </div>
                <div class="p1">
                    <p id="117">表4给出了分别利用颜色独立性和颜色空间分布特征以及综合利用颜色独立性和颜色空间分布特征进行分类的总体分类精度。由表4可知综合利用两种对比度有利于提高分类精度。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表4 Pavia大学数据集中采用不同的特征进行分类的总体分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.4 Overall accuracy with different features on the University of Pavia dataset</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br /></td><td>颜色<br />独立性</td><td>颜色空间<br />分布</td><td>颜色独立性+<br />颜色空间分布</td></tr><tr><td><br />总体分类精度</td><td>93.91</td><td>87.53</td><td>96.03</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="119">通常来说对高光谱影像进行特征提取前, 可以进行波段随机排序、PCA变换等预处理操作, 以期进一步提高分类精度。表5给出了采用不同的波段数量进行超像素分割和采用不同预处理操作, 进而提取显著性特征对应的总体分类精度。其中“PCA”表示对高光谱数据进行PCA变换后, 再选取相邻波段进行显著性特征提取;“随机排列”表示对高光谱影像不同波段进行随机排列后再选取相邻波段进行显著性特征提取。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表5 Pavia大学数据集中采用不同的波段数进行特征提取的总体分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.5 Overall accuracy of feature extraction using different band numbers in the University of Pavia dataset</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br /></td><td>PCA</td><td>随机排列</td><td>直接选择</td></tr><tr><td><br />1波段</td><td>89.71</td><td>93.38</td><td>95.24</td></tr><tr><td><br />3波段</td><td>92.22</td><td>95.86</td><td>96.03</td></tr><tr><td><br />5波段</td><td>92.13</td><td>96.07</td><td>96.11</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="121">观察表5可知采用单波段进行显著性特征提取的分类精度略低于采用3个连续波段进行显著性特征提取的分类精度。这是由于采用单波段进行显著性特征提取仅仅考虑了空间邻域信息, 而采用3个连续的波段进行显著性特征提取不仅在特征提取的过程中引入了邻域空间信息, 还能够充分考虑相邻波段的影响。进一步采用5个相邻波段进行显著性特征提取对于分类精度的提升效果不明显, 且会极大地增加特征提取的时间。此外, 事先对高光谱数据进行PCA变换, 使各波段相互独立, 再进行显著性特征提取, 会极大地降低分类精度。而波段随机排列操作对于分类精度的提升并没有帮助。为了简化特征提取过程, 本文不对高光谱影像进行随机排序或PCA变换等预处理操作。且最终采用3个连续的波段进行显著性特征提取, 即沿着光谱方向采用大小为3、步长为1的滑窗法获得所有波段的显著性特征。</p>
                </div>
                <h4 class="anchor-tag" id="122" name="122">2.3 试验结果与分析</h4>
                <div class="p1">
                    <p id="123">为了验证显著性特征 (SF+SVM) 的有效性, 分别与SVM、EMPs<citation id="161" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、Gabor<citation id="162" type="reference"><link href="54" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>、2D-CNN<citation id="163" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和3D-CNN<citation id="165" type="reference"><link href="52" rel="bibliography" /><link href="56" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">28</a>]</sup></citation>、Gabor+SVM+SLIC<citation id="164" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>算法进行对比分析, 并进一步将显著性特征和光谱特征结合输入到SVM中进行分类 (Spec-SF+SVM) 。SVM采用光谱特征进行分类;EMPs取前3个主成分波段进行特征提取, 每个波段分别利用4个开运算和4个闭运算构建形态学属性剖面特征, 开闭运算的半径分别为3、5、7、9;Gabor滤波器的带宽设置为1, 波长设置为1.4, 方向角分别取0°、30°、60°、90°, 偏移相位为0, 滤波窗口大小为11×11;2D-CNN采用3个卷积层和3个池化层, 3个卷积层的卷积核大小分别为5×5、6×6、4×4;3D-CNN采用7个三维卷积层、2个三维池化层和1个全连接层, 且引入了两个残差模块, 三维卷积层的卷积核大小设置为3×3×3;Gabor+SVM+SLIC中的SLIC分割数设置为500。SVM、EMPs、Gabor、Gabor+SVM+SLIC、SF+SVM和Spec-SF+SVM均采用支持向量机作为分类器, 支持向量机核函数采用高斯核函数, 核函数参数和惩罚系数通过5折交叉验证确定;2D-CNN和3D-CNN均从训练样本中随机选取10%的样本作为确认样本, 并选择在确认样本上分类精度最高的模型进行测试。</p>
                </div>
                <div class="p1">
                    <p id="124">表6—表8给出了不同算法在3组高光谱数据集上的分类结果。观察分类结果可知, 采用空间特征进行分类的EMPs、Gabor、2D-CNN、3D-CNN和SF+SVM的总体分类精度、平均分类精度、Kappa系数均优于仅利用光谱特征进行分类的SVM, 这说明在分类过程中引入空间信息有助于提高高光谱影像分类精度;2D-CNN和3D-CNN由于训练样本数量较少, 其分类精度较EMPs和Gabor并无明显优势;Gabor+SVM+SLIC除了使用SVM对Gabor特征进行分类, 还利用SLIC超像素分割结果采用多数投票的策略对分类结果进行修正, 因此能够获得较其他对比方法更高的分类精度。SF+SVM在Pavia大学数据集上的分类精度高于SVM、EMPs、Gabor和2D-CNN, 略低于3D-CNN和Gabor+SVM+SLIC, 且在Indian Pines和Salinas数据上均能获得较其他方法更高的分类精度。这说明了本文所提出的显著性特征是一种有效的特征提取方法, 能够提高高光谱影像的分类精度, 且将显著性特征与光谱特征结合 (Spec-SF+SVM) 能够进一步提高高光谱影像的分类精度。</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表6 不同算法在Pavia大学数据集的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.6 The classification results with different methods on the University of Pavia dataset</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br />序号</td><td>SVM</td><td>EMPs</td><td>Gabor</td><td>2D-CNN</td><td>3D-CNN</td><td>Gabor+SVM+SLIC</td><td>SF+SVM</td><td>Spec-SF+SVM</td></tr><tr><td><br />1</td><td>91.24</td><td>86.17</td><td>95.54</td><td>88.80</td><td>95.23</td><td>97.06</td><td>97.03</td><td>96.46</td></tr><tr><td><br />2</td><td>85.37</td><td>91.57</td><td>90.71</td><td>90.33</td><td>96.88</td><td>96.63</td><td>95.71</td><td>98.05</td></tr><tr><td><br />3</td><td>90.66</td><td>88.61</td><td>97.98</td><td>91.19</td><td>94.85</td><td>95.65</td><td>96.95</td><td>97.78</td></tr><tr><td><br />4</td><td>98.07</td><td>95.07</td><td>100.0</td><td>99.71</td><td>98.43</td><td>99.86</td><td>91.19</td><td>100.0</td></tr><tr><td><br />5</td><td>100.0</td><td>99.03</td><td>97.32</td><td>100.0</td><td>99.85</td><td>100.0</td><td>99.70</td><td>96.14</td></tr><tr><td><br />6</td><td>87.25</td><td>94.35</td><td>98.35</td><td>92.22</td><td>93.28</td><td>93.72</td><td>95.37</td><td>99.32</td></tr><tr><td><br />7</td><td>96.32</td><td>95.79</td><td>91.04</td><td>95.56</td><td>97.67</td><td>94.70</td><td>99.47</td><td>96.69</td></tr><tr><td><br />8</td><td>89.65</td><td>83.24</td><td>99.89</td><td>95.17</td><td>95.71</td><td>97.13</td><td>96.66</td><td>99.89</td></tr><tr><td><br />9</td><td>100.0</td><td>99.89</td><td>90.30</td><td>99.58</td><td>100.0</td><td>99.45</td><td>99.89</td><td>98.42</td></tr><tr><td><br /></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><br />OA</td><td>89.16</td><td>91.00</td><td>94.81</td><td>92.11</td><td>96.30</td><td>96.68</td><td>96.03</td><td><b>97.19</b></td></tr><tr><td><br />AA</td><td>93.17</td><td>92.64</td><td>95.68</td><td>94.73</td><td>96.88</td><td>97.13</td><td>96.89</td><td><b>98.08</b></td></tr><tr><td><br />Kappa</td><td>85.96</td><td>88.24</td><td>93.18</td><td>89.72</td><td>95.11</td><td>95.89</td><td>94.77</td><td><b>96.31</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表7 不同算法在Indian Pines数据集的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.7 The classification results with different methods on the Indian Pines dataset</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td><br />序号</td><td>SVM</td><td>EMPs</td><td>Gabor</td><td>2D-CNN</td><td>3D-CNN</td><td>Gabor+SVM+SLIC</td><td>SF+SVM</td><td>Spec-SF+SVM</td></tr><tr><td><br />1</td><td>82.49</td><td>69.75</td><td>94.10</td><td>83.75</td><td>86.55</td><td>90.24</td><td>94.96</td><td>99.75</td></tr><tr><td><br />2</td><td>85.54</td><td>87.71</td><td>99.79</td><td>96.14</td><td>94.58</td><td>97.25</td><td>94.34</td><td>99.38</td></tr><tr><td><br />3</td><td>96.89</td><td>97.93</td><td>99.59</td><td>98.96</td><td>98.96</td><td>97.42</td><td>97.52</td><td>99.86</td></tr><tr><td><br />4</td><td>99.59</td><td>98.77</td><td>100.0</td><td>98.77</td><td>99.86</td><td>89.55</td><td>99.73</td><td>99.79</td></tr><tr><td><br />5</td><td>100.0</td><td>99.79</td><td>95.99</td><td>98.74</td><td>100.0</td><td>99.70</td><td>99.79</td><td>97.74</td></tr><tr><td><br />6</td><td>82.82</td><td>91.87</td><td>87.05</td><td>93.93</td><td>94.75</td><td>99.22</td><td>95.78</td><td>98.45</td></tr><tr><td><br />7</td><td>73.93</td><td>82.57</td><td>93.93</td><td>77.72</td><td>86.97</td><td>99.32</td><td>96.74</td><td>98.31</td></tr><tr><td><br />8</td><td>91.74</td><td>90.56</td><td>99.84</td><td>98.65</td><td>96.46</td><td>97.55</td><td>98.31</td><td>99.76</td></tr><tr><td><br />9</td><td>98.66</td><td>95.10</td><td>88.38</td><td>98.02</td><td>99.84</td><td>99.68</td><td>99.84</td><td>95.66</td></tr><tr><td><br /></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><br />OA</td><td>86.34</td><td>87.23</td><td>93.35</td><td>90.00</td><td>93.10</td><td>95.92</td><td>97.11</td><td><b>98.30</b></td></tr><tr><td><br />AA</td><td>90.18</td><td>90.45</td><td>95.41</td><td>93.86</td><td>95.33</td><td>96.66</td><td>97.45</td><td><b>98.55</b></td></tr><tr><td><br />Kappa</td><td>84.12</td><td>85.11</td><td>92.24</td><td>88.39</td><td>91.94</td><td>94.71</td><td>96.61</td><td><b>98.00</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表8 不同算法在Salinas数据集的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.8 The classification results with different methods on the Salinas dataset</b> (%) </p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br />序号</td><td>SVM</td><td>EMPs</td><td>Gabor</td><td>2D-CNN</td><td>3D-CNN</td><td>Gabor+SVM+SLIC</td><td>SF+SVM</td><td>Spec-SF+SVM</td></tr><tr><td><br />1</td><td>99.40</td><td>99.85</td><td>99.85</td><td>98.11</td><td>99.70</td><td>98.16</td><td>99.95</td><td>99.57</td></tr><tr><td><br />2</td><td>99.54</td><td>99.49</td><td>99.81</td><td>99.54</td><td>100.0</td><td>99.25</td><td>99.62</td><td>100.0</td></tr><tr><td><br />3</td><td>99.90</td><td>100.00</td><td>99.75</td><td>98.03</td><td>98.73</td><td>99.69</td><td>100.0</td><td>99.64</td></tr><tr><td><br />4</td><td>99.71</td><td>99.78</td><td>99.50</td><td>100.0</td><td>99.78</td><td>99.57</td><td>98.64</td><td>98.81</td></tr><tr><td><br />5</td><td>97.80</td><td>97.46</td><td>98.36</td><td>98.21</td><td>99.22</td><td>95.37</td><td>95.97</td><td>99.47</td></tr><tr><td><br />6</td><td>99.60</td><td>99.70</td><td>98.84</td><td>100.0</td><td>100.0</td><td>100.0</td><td>99.32</td><td>99.83</td></tr><tr><td><br />7</td><td>99.44</td><td>98.91</td><td>99.78</td><td>97.85</td><td>99.89</td><td>97.51</td><td>99.75</td><td>97.52</td></tr><tr><td><br />8</td><td>79.24</td><td>81.60</td><td>86.36</td><td>87.82</td><td>89.51</td><td>92.32</td><td>98.38</td><td>99.87</td></tr><tr><td><br />9</td><td>99.69</td><td>98.03</td><td>99.77</td><td>96.70</td><td>99.81</td><td>99.77</td><td>99.69</td><td>99.15</td></tr><tr><td><br />10</td><td>94.02</td><td>97.04</td><td>96.67</td><td>96.28</td><td>97.04</td><td>96.37</td><td>98.99</td><td>99.34</td></tr><tr><td><br />11</td><td>99.91</td><td>98.78</td><td>97.85</td><td>98.03</td><td>98.03</td><td>100.0</td><td>99.72</td><td>100.0</td></tr><tr><td><br />12</td><td>99.64</td><td>100.0</td><td>100.0</td><td>99.90</td><td>100.0</td><td>99.95</td><td>95.49</td><td>99.24</td></tr><tr><td><br />13</td><td>98.14</td><td>99.02</td><td>99.89</td><td>100.0</td><td>99.78</td><td>100.0</td><td>98.69</td><td>98.79</td></tr><tr><td><br />14</td><td>99.07</td><td>99.72</td><td>98.76</td><td>99.72</td><td>99.91</td><td>99.25</td><td>98.50</td><td>99.71</td></tr><tr><td><br />15</td><td>75.15</td><td>85.90</td><td>86.13</td><td>79.43</td><td>85.13</td><td>98.25</td><td>99.97</td><td>99.23</td></tr><tr><td><br />16</td><td>98.95</td><td>99.39</td><td>99.17</td><td>94.80</td><td>99.94</td><td>98.78</td><td>100.0</td><td>99.95</td></tr><tr><td><br /></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><br />OA</td><td>91.60</td><td>93.54</td><td>94.76</td><td>93.47</td><td>95.46</td><td>97.33</td><td>99.02</td><td><b>99.15</b></td></tr><tr><td><br />AA</td><td>96.20</td><td>97.17</td><td>97.54</td><td>96.53</td><td>97.90</td><td>98.39</td><td>98.92</td><td><b>99.38</b></td></tr><tr><td><br />Kappa</td><td>90.67</td><td>92.82</td><td>94.17</td><td>92.73</td><td>94.95</td><td>96.79</td><td>98.90</td><td><b>99.06</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="128">为了更好地观察分类结果, 图4—图6给出了3组高光谱影像数据采用不同的算法获得的分类图。观察图4—图6可知, SF+SVM和Spec-SF+SVM获得的分类图噪声明显少于其他对比算法, 具有更好的视觉效果。这也进一步说明了本文算法的有效性。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 各算法在Pavia大学数据集上的分类结果及其对应的总体分类精度" src="Detail/GetImg?filename=images/CHXB201908006_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 各算法在Pavia大学数据集上的分类结果及其对应的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Classification maps and overall accuracy with different methods on the University of Pavia dataset</p>

                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 各算法在Indian Pines数据集上的分类结果及其对应的总体分类精度" src="Detail/GetImg?filename=images/CHXB201908006_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 各算法在Indian Pines数据集上的分类结果及其对应的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Classification maps and overall accuracy with different methods on the Indian Pines dataset</p>

                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 各算法在Salinas数据集上的分类结果图及其对应的总体分类精度" src="Detail/GetImg?filename=images/CHXB201908006_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 各算法在Salinas数据集上的分类结果图及其对应的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Classification maps and overall accuracy with different methods on the Salinas dataset</p>

                </div>
                <h4 class="anchor-tag" id="132" name="132">2.4 训练样本数量适宜性分析</h4>
                <div class="p1">
                    <p id="133">高光谱影像中可用于分类的标记样本数量通常较少, 因此小样本问题是高光谱影像分类面临的主要挑战之一。本小节进一步减少训练样本数量进行试验分析, 以验证所提出算法在小样本情况下的有效性。如图7所示为3组高光谱数据集中选取不同数量的训练样本对应的分类结果。观察图7可知, 不同算法的分类精度均随着训练样本数量的减少而降低, 但SF+SVM和Spec-SF+SVM均能取得较SVM、EMPs、Gabor、2D-CNN和3D-CNN更高的分类精度, 尤其是当每类地物选取20个训练样本时, SF+SVM和Spec-SF+SVM的分类精度依然高于其他对比算法, 这证明了所提出方法在小样本情况下的有效性。</p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908006_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同训练样本数目对应的总体分类精度" src="Detail/GetImg?filename=images/CHXB201908006_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同训练样本数目对应的总体分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908006_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Overall accuracy with different number of training samples</p>

                </div>
                <h3 id="135" name="135" class="anchor-tag">3 总结与展望</h3>
                <div class="p1">
                    <p id="136">本文提出了一种高光谱影像显著性特征提取方法, 能够充分地利用局部和全局的空间信息来提高高光谱影像分类的精度。采用Pavia大学、Indian Pines和Salinas 3组高光谱影像数据集进行试验验证。试验结果表明:①与EMPs、Gabor、2D-CNN、3D-CNN等空间特征提取方法相比, 采用显著性特征进行分类能够获取更高的分类精度, 且将显著性特征与光谱特征结合能够进一步提高分类精度;②本文提出的显著性特征提取方法对小样本有较好的适应性, 在训练样本较少的情况下, 采用显著性特征进行分类仍然能够取得较为理想的分类结果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXB201602008&amp;v=MjU1NDdmWnVkdkZ5cmhXcjdPUENyVGJMRzRIOWZNclk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 杜培军, 夏俊士, 薛朝辉, 等.高光谱遥感影像分类研究进展[J].遥感学报, 2016, 20 (2) :236-256.DU Peijun, XIA Junshi, XUE Chaohui, et al.Review of hyperspectral remote sensing image classification[J].Journal of Remote Sensing, 2016, 20 (2) :236-256.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFJC201706006&amp;v=Mjc2NDRSN3FmWnVkdkZ5cmhXcjdPTHl2QmJiRzRIOWJNcVk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刘冰, 余旭初, 张鹏强, 等.面对高光谱影像分类的半监督阶梯网络[J].测绘科学技术学报, 2017, 34 (6) :576-581.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Semi-supervised ladder network for hyperspectral image classification[J].Journal of Geomatics Science and Technology, 2017, 34 (6) :576-581.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advanced Spectral Classifiers for Hyperspectral Images:A Review">

                                <b>[3]</b> GHAMISI P, PLAZA J, CHEN Yushi, et al.Advanced spectral classifiers for hyperspectral images:a review[J].IEEE Geoscience and Remote Sensing Magazine, 2017, 5 (1) :8-32.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Survey on Spectral-Spatial Classification Techniques Based on Attribute Profiles">

                                <b>[4]</b> GHAMISI P, MURA M D, BENEDIKTSSON J A.A survey on spectral-spatial classification techniques based on attribute profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2335-2353.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of hyperspectral data from urban areas based on extended morphological profiles">

                                <b>[5]</b> BENEDIKTSSON J A, PALMASON J A, SVEINSSON J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXB201802009&amp;v=MzI2NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T1BDclRiTEc0SDluTXJZOUZiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 王雷光, 曹小汪, 郑雅兰, 等.高光谱影像的引导滤波多尺度特征提取[J].遥感学报, 2018, 22 (2) :293-303.WANG Leiguang, CAO Xiaowang, ZHENG Yalan, et al.Multi-scale feature extraction of hyperspectral image with guided filtering[J].Journal of Remote Sensing, 2018, 22 (2) :293-303.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Three-dimensional gabor wavelets for pixel-based hyperspectral imagery classification">

                                <b>[7]</b> SHEN Linlin, JIA Sen.Three-dimensional Gabor wavelets for pixel-based hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2011, 49 (12) :5039-5046.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local binary patterns and extreme learning machine for hyperspectral imagery classification">

                                <b>[8]</b> LI Wei, CHEN Chen, SU Hongjun, et al.Local binary patterns and extreme learning machine for hyperspectral imagery classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (7) :3681-3693.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques">

                                <b>[9]</b> TARABALKA Y, BENEDIKTSSON J A, CHANUSSOT J.Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques[J].IEEE Transactions on Geoscience and Remote Sensing, 2009, 47 (8) :2973-2987.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJXZ201801008&amp;v=MzI3NTdyN09LeWZUZExHNEg5bk1ybzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyaFc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 贾森, 吴奎霖, 朱家松, 等.面向高光谱图像分类的超像素级Gabor特征融合方法研究[J].南京信息工程大学学报 (自然科学版) , 2018, 10 (1) :72-80.JIA Sen, WU Kuilin, ZHU Jiasong, et al.Superpixel-level Gabor feature fusion method for hyperspectral image classification[J].Journal of Nanjing University of Information Science and Technology (Natural Science Edition) , 2018, 10 (1) :72-80.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial Hyperspectral Image Classification with Edge-Preserving Filtering">

                                <b>[11]</b> KANG Xudong, LI Shutao, BENEDIKTSSON J A.Spectral-spatial hyperspectral image classification with edge-preserving filtering[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (5) :2666-2677.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning-based classification of hyperspectral data">

                                <b>[12]</b> CHEN Yushi, LIN Zhouhan, ZHAO Xing, et al.Deep learning-based classification of hyperspectral data[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (6) :2094-2107.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD1632C6163AF65870F6EAB1D14AA3AE0A&amp;v=MjAwMzdsZkJyTFUwNTlsaHhyeTJ3YTQ9TmpuQmFySytIZE8vcVk1RFo1cDVDbmt4eUJabDdFb01PbjZXclJaRUNMSGxNTHJ1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.A semi-supervised convolutional neural network for hyperspectral image classification[J].Remote Sensing Letters, 2017, 8 (9) :839-848.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 YUE Jun, ZHAO Wenzhi, MAO Shanjun, et al.Spectral-spatial classification of hyperspectral images using deep convolutional neural networks[J].Remote Sensing Letters, 2015, 6 (6) :468-477.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised deep feature extraction for hyperspectral image classification">

                                <b>[15]</b> LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Supervised deep feature extraction for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (4) :1909-1921.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning sensor-specific spatial-spectral features of hyperspectral images via convolutional neural networks">

                                <b>[16]</b> MEI Shaohui, JI Jingyu, HOU Junhui, et al.Learning sensor-specific spatial-spectral features of hyperspectral images via convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing, 2017, 55 (8) :4520-4533.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGE34AC7615B4CA75BB9430853AD20EC6C&amp;v=MTI4NTlHUWxmQnJMVTA1OWxoeHJ5MndhND1OaWZPYWNhN0dxQy9xSWxFWVprTGZ3MCt5bVJoNHp0K1NIZm5yMk5CZTdMaE5yenNDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Spectral-spatial classification of hyperspectral image using three-dimensional convolution network[J].Journal of Applied Remote Sensing, 2018, 12 (1) :016005.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDB1A648C2C388FF8CCDC6B18B5C272317&amp;v=MDg3MjNCckxVMDU5bGh4cnkyd2E0PU5qbkJhc0c1YjlmSXAveEhGK2dIQkFwUHgyVmdua3g3T243cTNoZEdlN1dXUnJ1WUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> LIU Bing, YU Xuchu, YU Anzhu, et al.Spectral-spatial classification of hyperspectral imagery based on recurrent neural networks[J].Remote Sensing Letters, 2018, 9 (12) :1118-1127.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201806007&amp;v=MDk3NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyaFdyN09QeXJmYkxHNEg5bk1xWTlGWTRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 崔丽群, 赵越, 胡志毅, 等.复合域的显著性目标检测方法[J].中国图象图形学报, 2018, 23 (6) :846-856.CUI Liqun, ZHAO Yue, HU Zhiyi, et al.Saliency object detection method based on complex domains[J].Journal of Image and Graphics, 2018, 23 (6) :846-856.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201609011&amp;v=Mjc1Mjl1ZHZGeXJoV3I3T0ppWFRiTEc0SDlmTXBvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612.HE Xiaofei, ZOU Zhengrong, TAO Chao, et al.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.DOI:10.11947/j.AGCS.2016.20150612.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A saliency-based band selection approach for hyperspectral imagery inspired by scale selection">

                                <b>[21]</b> SU Peifeng, LIU Daizhi, LI Xihai, et al.A saliency-based band selection approach for hyperspectral imagery inspired by scale selection[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (4) :572-576.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency filters:Contrast based filtering for salient region detection">

                                <b>[22]</b> PERAZZI F, KRÄHENBÜHL P, PRITCH Y, et al.Saliency filters:contrast based filtering for salient region detection[C]//2012 IEEE Conference on Computer Vision and Pattern Recognition.Providence, RI, USA:IEEE, 2012:733-740.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning to Detect a Salient Object">

                                <b>[23]</b> LIU Tie, YUAN Zejian, SUN Jian, et al.Learning to detect a salient object[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (2) :353-367.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SLIC Superpixels Compared to State-of-the-Art Superpixel Methods">

                                <b>[24]</b> ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201804013&amp;v=MDA3Nzg3T1B5cmZiTEc0SDluTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594.CUI Lingling, XU Jinlan, XU Gang, et al.Image saliency detection method based on a pair of feature maps[J].Journal of Image and Graphics, 2018, 23 (4) :583-594.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201901008&amp;v=MTIzMTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T0ppWFRiTEc0SDlqTXJvOUY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> 刘冰, 余旭初, 张鹏强, 等.联合空-谱信息的高光谱影像深度三维卷积网络分类[J].测绘学报, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578.LIU Bing, YU Xuchu, ZHANG Pengqiang, et al.Deep 3D convolutional network combined with spatial-spectral features for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2019, 48 (1) :53-63.DOI:10.11947/j.AGCS.2019.20170578.
                            </a>
                        </p>
                        <p id="54">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB201409011&amp;v=MDMwMzVxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmhXcjdPSmlYZmJMRzRIOVhNcG85RVpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b> 余旭初, 谭熊, 付琼莹, 等.联合纹理和光谱特征的高光谱影像多核分类方法[J].测绘通报, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289.YU Xuchu, TAN Xiong, FU Qiongying, et al.Combined texture-spectral feature for multiple kernel classification of hyperspectral images[J].Bulletin of Surveying and Mapping, 2014 (9) :38-42.DOI:10.13474/j.cnki.11-2246.2014.0289.
                            </a>
                        </p>
                        <p id="56">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep few-shot learning for hyperspectral image classification">

                                <b>[28]</b> LIU Bing, YU Xuchu, YU Anzhu, et al.Deep few-shot learning for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2019, 57 (4) :2290-2304.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201908006" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908006&amp;v=MjYyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoV3I3T0ppWFRiTEc0SDlqTXA0OUZZb1E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
