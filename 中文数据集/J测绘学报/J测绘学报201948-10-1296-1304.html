<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142607155576250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201910011%26RESULT%3d1%26SIGN%3dNoV243JsLw8g3W6HNndEvHZZ4oM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910011&amp;v=MjA3OTh0R0ZyQ1VSN3FmWnVkdkZ5cmdWNy9NSmlYVGJMRzRIOWpOcjQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="1 目标函数 ">1 目标函数</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="1.1 相关工作">1.1 相关工作</a></li>
                                                <li><a href="#76" data-title="1.2 目标函数设置">1.2 目标函数设置</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="2 粒子群优化 ">2 粒子群优化</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="2.1 粒子群算法">2.1 粒子群算法</a></li>
                                                <li><a href="#98" data-title="2.2 编码方式及种群初始化">2.2 编码方式及种群初始化</a></li>
                                                <li><a href="#101" data-title="2.3 技术流程">2.3 技术流程</a></li>
                                                <li><a href="#104" data-title="2.4 PAIHS算法">2.4 PAIHS算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="3 试验及对比分析 ">3 试验及对比分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#122" data-title="3.1 视觉对比及分析">3.1 视觉对比及分析</a></li>
                                                <li><a href="#129" data-title="3.2 定量对比及分析">3.2 定量对比及分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#100" data-title="图1 染色体编码方式">图1 染色体编码方式</a></li>
                                                <li><a href="#103" data-title="图2 技术流程">图2 技术流程</a></li>
                                                <li><a href="#131" data-title="图3 Pan-sharpened结果比较">图3 Pan-sharpened结果比较</a></li>
                                                <li><a href="#132" data-title="图4 Pan-sharpened结果比较">图4 Pan-sharpened结果比较</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表1 图3的Pan-sharpening的定量指标结果&lt;/b&gt;"><b>表1 图3的Pan-sharpening的定量指标结果</b></a></li>
                                                <li><a href="#134" data-title="图5 Pan-sharpened结果比较">图5 Pan-sharpened结果比较</a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表2 图4的Pan-sharpening的定量指标结果&lt;/b&gt;"><b>表2 图4的Pan-sharpening的定量指标结果</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;表3 图5的Pan-sharpening的定量指标结果&lt;/b&gt;"><b>表3 图5的Pan-sharpening的定量指标结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" EL-MEZOUAR M C,TALEB N,KPALMA K,et al.An IHS-based fusion for color distortion reduction and vegetation enhancement in IKONOS imagery[J].IEEE Transactions on Geoscience and Remote Sensing,2011,49(5):1590-1602." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An IHS-based fusion for color distortion reduction and vegetation enhancement in IKONOS imagery">
                                        <b>[1]</b>
                                         EL-MEZOUAR M C,TALEB N,KPALMA K,et al.An IHS-based fusion for color distortion reduction and vegetation enhancement in IKONOS imagery[J].IEEE Transactions on Geoscience and Remote Sensing,2011,49(5):1590-1602.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" RAHMANI S,STRAIT M,MERKURJEV D,et al.An adaptive IHS Pan-sharpening method[J].IEEE Geoscience and Remote Sensing Letters,2010,7(4):746-750." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An adaptive IHS pan-sharpening method">
                                        <b>[2]</b>
                                         RAHMANI S,STRAIT M,MERKURJEV D,et al.An adaptive IHS Pan-sharpening method[J].IEEE Geoscience and Remote Sensing Letters,2010,7(4):746-750.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" LABEN C A,BROWER B V.Process for enhancing the spatial resolution of multispectral imagery using Pan-sharpening:USA,6011875 [P].2000-01-04." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening">
                                        <b>[3]</b>
                                         LABEN C A,BROWER B V.Process for enhancing the spatial resolution of multispectral imagery using Pan-sharpening:USA,6011875 [P].2000-01-04.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" LU Xiaochen,ZHANG Junping.Panchromatic and multispectral images fusion based on modified GS-SWT[C]//Proceedings of 2014 IEEE Geoscience and Remote Sensing Symposium.Quebec,Canada:IEEE,2014:2530-2533." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Panchromatic and multispectral images fusion based on modified GSSWT.&amp;quot;">
                                        <b>[4]</b>
                                         LU Xiaochen,ZHANG Junping.Panchromatic and multispectral images fusion based on modified GS-SWT[C]//Proceedings of 2014 IEEE Geoscience and Remote Sensing Symposium.Quebec,Canada:IEEE,2014:2530-2533.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" ZHANG Hankui,ROY D P.Computationally inexpensive Landsat 8 operational land imager (OLI) Pan-sharpening[J].Remote Sensing,2016,8(3):180." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computationally inexpensive Landsat 8 operational land imager (OLI) Pan-sharpening">
                                        <b>[5]</b>
                                         ZHANG Hankui,ROY D P.Computationally inexpensive Landsat 8 operational land imager (OLI) Pan-sharpening[J].Remote Sensing,2016,8(3):180.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" PARK J H,KIM K O,YANG Y K.Image fusion using multiresolution analysis[C]//Proceedings of 2001 IEEE International Geoscience and Remote Sensing Symposium.Sydney,Australia:IEEE,2001:864-866." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image fusion using multireso-lution analysis">
                                        <b>[6]</b>
                                         PARK J H,KIM K O,YANG Y K.Image fusion using multiresolution analysis[C]//Proceedings of 2001 IEEE International Geoscience and Remote Sensing Symposium.Sydney,Australia:IEEE,2001:864-866.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" ZHOU J,CIVCO D L,SILANDER J A.A wavelet transform method to merge Landsat TM and SPOT panchromatic data[J].International Journal of Remote Sensing,1998,19(4):743-757." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD713859550&amp;v=MjgwMDl1ZHZGeXJnVjcvTU5qbkJhclM1SGRuSnBvcEFaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         ZHOU J,CIVCO D L,SILANDER J A.A wavelet transform method to merge Landsat TM and SPOT panchromatic data[J].International Journal of Remote Sensing,1998,19(4):743-757.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" METEALLI M R,NASR A H,FARAGALLAH O S,et al.Efficient Pan-sharpening of satellite images with the contourlet transform[J].International Journal of Remote Sensing,2014,35(5):1979-2002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD14022800000399&amp;v=MjcxNTdCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1FhaFk9TmpuQmFySzhIdFBPcDQ5RlpPc1BEM1V3bw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         METEALLI M R,NASR A H,FARAGALLAH O S,et al.Efficient Pan-sharpening of satellite images with the contourlet transform[J].International Journal of Remote Sensing,2014,35(5):1979-2002.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" AIAZZI B,ALPARONE L,BARONTI S,et al.Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis[J].IEEE Transactions on Geoscience and Remote Sensing,2002,40(10):2300-2312." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis">
                                        <b>[9]</b>
                                         AIAZZI B,ALPARONE L,BARONTI S,et al.Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis[J].IEEE Transactions on Geoscience and Remote Sensing,2002,40(10):2300-2312.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" M&#214;LLER M,WITTMAN T,BERTOZZI A L,et al.A variational approach for sharpening high dimensional images[J].SIAM Journal on Imaging Sciences,2012,5(1):150-178." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Variational Approach for Sharpening High Dimensional Images">
                                        <b>[10]</b>
                                         M&#214;LLER M,WITTMAN T,BERTOZZI A L,et al.A variational approach for sharpening high dimensional images[J].SIAM Journal on Imaging Sciences,2012,5(1):150-178.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" BALLESTER C,CASELLES V,IGUAL L,et al.A variational model for P+XS image fusion[J].International Journal of Computer Vision,2006,69(1):43-58." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002831035&amp;v=MjA0NzJVYnJNSUZvPU5qN0Jhck80SHRIT3A0eEVaT2dLWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGeW5s&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         BALLESTER C,CASELLES V,IGUAL L,et al.A variational model for P+XS image fusion[J].International Journal of Computer Vision,2006,69(1):43-58.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" MOELLER M,WITTMAN T,BERTOZZI A L.Variational wavelet Pan-sharpening[J].IEEE Transactions on Geoscience and Remote Sensing,2008:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Variational wavelet Pan-sharpening">
                                        <b>[12]</b>
                                         MOELLER M,WITTMAN T,BERTOZZI A L.Variational wavelet Pan-sharpening[J].IEEE Transactions on Geoscience and Remote Sensing,2008:1-9.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" ALY H A,SHARMA G.A regularized model-based optimization framework for Pan-sharpening[J].IEEE Transactions on Image Processing,2014,23(6):2596-2608." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A regularized model-based optimization framework for Pan-sharpening">
                                        <b>[13]</b>
                                         ALY H A,SHARMA G.A regularized model-based optimization framework for Pan-sharpening[J].IEEE Transactions on Image Processing,2014,23(6):2596-2608.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" FANG Faming,LI Fang,SHEN Chaomin,et al.A variational approach for Pan-sharpening[J].IEEE Transactions on Image Processing,2013,22(7):2822-2834." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A variational approach for pan-sharpening">
                                        <b>[14]</b>
                                         FANG Faming,LI Fang,SHEN Chaomin,et al.A variational approach for Pan-sharpening[J].IEEE Transactions on Image Processing,2013,22(7):2822-2834.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" MUMTAZ A,MAJID A,MUMTAZ A.Genetic algorithms and its application to image fusion[C]//Proceedings of the 4th International Conference on Emerging Technologies.Rawalpindi,Pakistan:IEEE,2008:6-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Genetic Algorithms and its application to Image Fusion.2008">
                                        <b>[15]</b>
                                         MUMTAZ A,MAJID A,MUMTAZ A.Genetic algorithms and its application to image fusion[C]//Proceedings of the 4th International Conference on Emerging Technologies.Rawalpindi,Pakistan:IEEE,2008:6-10.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" CHEN Yingxia,ZHANG Guixu.A Pan-sharpening method based on evolutionary optimization and IHS transformation[J].Mathematical Problems in Engineering,2017(4):1-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHDBFBBC3C0781E187C238FFDF22A10B2EE&amp;v=MjM2MjJPR1FsZkJyTFUwNTlsaHhyMjd3S3c9TmlmRGFzSE9iS08vclB4RlkrTU9lWDB4eUdVUjZUY0xQZ3VVcmhCRWVMTG1SOC9xQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         CHEN Yingxia,ZHANG Guixu.A Pan-sharpening method based on evolutionary optimization and IHS transformation[J].Mathematical Problems in Engineering,2017(4):1-8.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" ZHOU Zeming,YANG Pinglv,LI Yuanxiang,et al.Joint IHS and variational methods for Pan-sharpening of very high resolution imagery[C]//Proceedings of 2013 IEEE International Geoscience and Remote Sensing Symposium.Melbourne,VIC,Australia:IEEE,2014:2597-2600." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint IHS and variational methods for Pan-sharpening of very high resolution imagery">
                                        <b>[17]</b>
                                         ZHOU Zeming,YANG Pinglv,LI Yuanxiang,et al.Joint IHS and variational methods for Pan-sharpening of very high resolution imagery[C]//Proceedings of 2013 IEEE International Geoscience and Remote Sensing Symposium.Melbourne,VIC,Australia:IEEE,2014:2597-2600.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" 许宁,肖新耀,尤红建,等.HCT变换与联合稀疏模型相结合的遥感影像融合[J].测绘学报,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372.XU Ning,XIAO Xinyao,YOU Hongjian,et al.A Pansharpening method based on HCT and joint sparse model[J].Acta Geodaetica et Cartographica Sinica,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201604009&amp;v=MTg1MzgvTUppWFRiTEc0SDlmTXE0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         许宁,肖新耀,尤红建,等.HCT变换与联合稀疏模型相结合的遥感影像融合[J].测绘学报,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372.XU Ning,XIAO Xinyao,YOU Hongjian,et al.A Pansharpening method based on HCT and joint sparse model[J].Acta Geodaetica et Cartographica Sinica,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     KENNEDY J,EBERHART R C.Particle swarm optimization[C]//Proceedings of ICNN&#39;95 - International Conference on Neural Networks.Perth,Australia:IEEE,1995:1942-1948.</a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" VENTER G,SOBIESZCZANSKI-SOBIESKI J.Particle swarm optimization[J].AIAA Journal,2003,41(8):1583-1589." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Particle swarm optimization">
                                        <b>[20]</b>
                                         VENTER G,SOBIESZCZANSKI-SOBIESKI J.Particle swarm optimization[J].AIAA Journal,2003,41(8):1583-1589.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" PUSHPARAJ J,HEGDE A V.Evaluation of Pan-sharpening methods for spatial and spectral quality[J].Applied Geomatics,2017,9(1):1-12." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDB3D20B2B2E19643141952BA2D9764B81&amp;v=MTIyOTJXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxoeHIyN3dLdz1OajdCYXNHN2F0UE0zWTAzWnA0T0JYbzl6QmNYNnpaNFNnMlRybVk4ZnJTUU43S2VDT052RlNpVw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         PUSHPARAJ J,HEGDE A V.Evaluation of Pan-sharpening methods for spatial and spectral quality[J].Applied Geomatics,2017,9(1):1-12.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" ALPARONE L,WALD L,CHANUSSOT J,et al.Comparison of Pansharpening algorithms:outcome of the 2006 GRS-S data-fusion contest[J].IEEE Transactions on Geoscience and Remote Sensing,2007,45(10):3012-3021." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparison of pansharpening algorithms: Outcome of the 2006 GRS-S data-fusion contest">
                                        <b>[22]</b>
                                         ALPARONE L,WALD L,CHANUSSOT J,et al.Comparison of Pansharpening algorithms:outcome of the 2006 GRS-S data-fusion contest[J].IEEE Transactions on Geoscience and Remote Sensing,2007,45(10):3012-3021.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" WANG Z,BOVIK A C.A universal image quality index[J].IEEE Signal Processing Letters,2002,9(3):81-84." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A universal image quality index">
                                        <b>[23]</b>
                                         WANG Z,BOVIK A C.A universal image quality index[J].IEEE Signal Processing Letters,2002,9(3):81-84.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" TOET A,HOGERVORST M A.Performance comparison of different gray-level image fusion schemes through a universal image quality index[C]//Proceedings Volume 5096,Signal Processing,Sensor Fusion,and Target Recognition XII.Orlando,Florida,United States:SPIE,2003:552-561." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Performance comparison of different graylevel image fusion schemes through a universal image quality index">
                                        <b>[24]</b>
                                         TOET A,HOGERVORST M A.Performance comparison of different gray-level image fusion schemes through a universal image quality index[C]//Proceedings Volume 5096,Signal Processing,Sensor Fusion,and Target Recognition XII.Orlando,Florida,United States:SPIE,2003:552-561.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" CHOI M.A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter[J].IEEE Transactions on Geoscience and Remote Sensing,2006,44(6):1672-1682." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter">
                                        <b>[25]</b>
                                         CHOI M.A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter[J].IEEE Transactions on Geoscience and Remote Sensing,2006,44(6):1672-1682.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_26" title=" FANG Faming,ZHANG Guixu,LI Fang,et al.Framelet based Pan-sharpening via a variational method[J].Neurocomputing,2014(10):362-377." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600370076&amp;v=MDYwMzhubFU3N0lJbHNRYWhZPU5pZk9mYks4SHRETXFZOUZaK3dQREhzL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         FANG Faming,ZHANG Guixu,LI Fang,et al.Framelet based Pan-sharpening via a variational method[J].Neurocomputing,2014(10):362-377.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(10),1296-1304 DOI:10.11947/j.AGCS.2019.20180509            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>遥感影像融合AIHS转换与粒子群优化算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%BA%94%E9%9C%9E&amp;code=42897692&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈应霞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E8%89%B3&amp;code=11179867&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈艳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E4%B8%9B&amp;code=24287252&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘丛</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东师范大学计算机科学与软件工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B1%9F%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0112354&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长江大学计算机科学学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0256814&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学光电信息与计算机工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>Pan-sharpening是通过将低分辨率多光谱图像(LMS)与高分辨率全色图像(PAN)进行合成而获得高光谱高空间分辨率的多光谱图像(HMS)的过程。本文提出一种Pan-sharpening方法,称为PAIHS。该方法基于自适应亮度-色度-饱和度(AIHS)转换和变分Pan-sharpening框架以及两个假设(①Pan-sharpening图像和原始多光谱图像(MS)具有相同的光谱信息;②Pan-sharpening图像与全色图像(PAN)包含的几何信息保持一致),同时确定目标函数,然后用粒子群算法(PSO)进行优化,目的是得到最佳控制参数并求得目标函数最小值,此时对应着最好的Pan-sharpening质量。试验结果表明,本文提出的方法具有高效性和可靠性,获得的性能指标也优于目前一些主流的融合方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Pan-sharpening&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Pan-sharpening;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多光谱图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A8%E8%89%B2%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">全色图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%AE%E5%BA%A6-%E8%89%B2%E5%BA%A6-%E9%A5%B1%E5%92%8C%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">亮度-色度-饱和度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒子群算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标函数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈应霞(1978—),男,博士,讲师,研究方向为遥感图像处理,E-mail: 672057422@qq.com。;
                                </span>
                                <span>
                                    *陈艳,E-mail: 345854199@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-05</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61703278);</span>
                    </p>
            </div>
                    <h1>Joint AIHS and particle swarm optimization for Pan-sharpening</h1>
                    <h2>
                    <span>CHEN Yingxia</span>
                    <span>CHEN Yan</span>
                    <span>LIU Cong</span>
            </h2>
                    <h2>
                    <span>Department of Computer Science, East China Normal University</span>
                    <span>School of Computer Science, Yangtze University</span>
                    <span>School of Computer Science, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Pan-sharpening is a process of obtaining a high spatial and spectral multispectral image(HMS) by combining a low resolution multispectral image(LMS) with a high resolution panchromatic image(PAN). In this paper, a Pan-sharpening method called PAIHS is proposed. It is based on adaptive intensity-hue-saturation(AIHS) transformation, variational Pan-sharpening framework and two assumptions: ①pan-sharpened image and original multispectral image(MS) have the same spectral information; ②pan-sharpened image and PAN image contain the same geometric information. The suitable objective function was established, and optimized by particle swarm optimization(PSO) to obtain the optimal control parameters and minimum value, which corresponds to the best Pan-sharpening quality. The experimental results show that the proposed method has high efficiency and reliability, and the obtained performance index is also better than some of the current mainstream fusion methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Pan-sharpening&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Pan-sharpening;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multispectral%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multispectral image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=panchromatic%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">panchromatic image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AIHS%20transformation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AIHS transformation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=particle%20swarm%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">particle swarm optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=objective%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">objective function;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHEN Yingxia (1978— ), male, PhD, lecturer, majors in remote sensing processing,E-mail: 672057422@qq.com;;
                                </span>
                                <span>
                                    CHEN Yan,E-mail: 345854199@qq.com;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-05</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China(No.61703278);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="54">Pan-sharpening是遥感影像融合技术中的一个重要分支,它是将不同来源同一对象的影像数据采用某种算法将影像中所包含的信息互补的数据进行有机结合产生新影像的技术,该技术在目标识别、计算机视觉、遥感、军事及智慧城市等领域有着广泛的应用,是当前遥感图像处理研究的热点。它可以分为3个层级:像素级、特征级和决策级,其中像素级是特征级和决策级的基础,也是目前主流的Pan-sharpening方法。本文研究的是基于像素级的Pan-sharpening方法。</p>
                </div>
                <div class="p1">
                    <p id="55">目前,像素级Pan-sharpening方法大致分为3类。第1类是CS方法,也称之为组件替代法,如亮度-色度-饱和度(IHS)<citation id="159" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、自适应亮度-色度-饱和度(AIHS)<citation id="160" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、GramSchmidt<citation id="171" type="reference"><link href="6" rel="bibliography" /><link href="8" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、Brovey<citation id="161" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等。此类方法能获得较好的空间信息,但它们通常会产生光谱失真。第2类是多分辨率分析(MRA)方法<citation id="162" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,如Wavelet<citation id="163" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和Contourlet<citation id="164" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等。与第1类方法不同,它是将全色图像(PAN)的高频细节加入到低空间分辨率的多光谱图像(LMS)中,同时对全色图像(PAN)进行采样,然后将采样图像与相应波段的多光谱图像(MS)进行Pan-sharpening。虽然MRA方法能在一定程度上减少光谱失真,但它却产生了空间退化现象,如混叠效应等<citation id="165" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。第3类是近年来出现的基于变分的Pan-sharpening方法。该类方法首先建立一个总的能量泛函,然后对其进行优化,其最优化结果即对应着最佳的Pan-sharpening质量<citation id="166" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,如P+XS<citation id="167" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、VWP和AVWP<citation id="168" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、SRIF<citation id="169" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、文献<citation id="170" type="reference">[<a class="sup">14</a>]</citation>中的变分法等。它是Pan-sharpening领域的一个重大创新,但也存在一些缺陷,如在总能量函数优化过程中,其控制系数无法自动寻优,以至容易陷入局部最优,从而可能无法保证得到全局最优解。</p>
                </div>
                <div class="p1">
                    <p id="56">为了解决以上问题,研究人员将上述Pan-sharpening方法与目前热门的群体智能优化方法相结合。如文献<citation id="172" type="reference">[<a class="sup">15</a>]</citation>提出了基于遗传算法(GA)的像素级加权平均法,他们将遗传算法和小波变换进行结合,试验结果表明与不使用遗传算法的方法相比,使用遗传算法的融合方法能得到更好的融合质量。文献<citation id="173" type="reference">[<a class="sup">16</a>]</citation>将亮度-色度-饱和度(IHS)与组合差分进化算法(CODE)进行结合,通过设置合理的进化算子和适应度函数,并对控制参数进行全局自动寻优,从而获得了最佳的Pan-sharpening效果。从现有的研究成果来看,目前基于智能优化的Pan-sharpening方法大多集中在空间域方面,而基于变换域的研究则相对较少。基于传统亮度-色度-饱和度(GIHS)的改进方法<citation id="174" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和文献<citation id="175" type="reference">[<a class="sup">14</a>]</citation>中的变分Pan-sharpening以及文献<citation id="176" type="reference">[<a class="sup">16</a>]</citation>中的两个假设:①Pan-sharpening图像和原始MS图像具有相同的光谱信息;②Pan-sharpening图像与PAN图像包含的几何信息保持一致。本文提出了一种基于变换域的自适应亮度-色度-饱和度(AIHS)转换和粒子群算法(PSO)相结合的Pan-sharpening方法,称之为PAIHS。试验结果表明,该方法可以获得优化的自动控制参数,并在优化控制参数的约束下,利用AIHS转换可以获得优良质量的Pan-sharpening图像。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">1 目标函数</h3>
                <div class="p1">
                    <p id="58">传统亮度-色度-饱和度(GIHS)转换方法虽是一种计算高效且能获得高空间信息的融合方法,但它并不能很好地获得高光谱信息且会出现光谱失真现象,因此在提出方法之前需要做一些相关的工作以提高融合图像的保真度。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">1.1 相关工作</h4>
                <h4 class="anchor-tag" id="60" name="60">1.1.1 改进自适应系数</h4>
                <div class="p1">
                    <p id="61"><i>M</i>=(<i>M</i><sub>1</sub>,<i>M</i><sub>2</sub>,…,<i>M</i><sub><i>c</i></sub>,…,<i>M</i><sub><i>C</i></sub>)(<i>c</i>=1,2,…,<i>C</i>),表示多光谱图像<i>M</i>有<i>C</i>个波段,<i>M</i><sub><i>c</i></sub>是第<i>c</i>个波段的多光谱图像,<i>M</i><sub><i>c</i></sub>(<i>x</i>,<i>y</i>)是<i>M</i><sub><i>c</i></sub>中位置为(<i>x</i>,<i>y</i>)的一个像素;<i>P</i>表示为全色图像(PAN);<i>F</i>=(<i>F</i><sub>1</sub>,<i>F</i><sub>2</sub>,…,<i>F</i><sub><i>c</i></sub>,…,<i>F</i><sub><i>C</i></sub>)由多个未知的Pan-sharpening图像组成。</p>
                </div>
                <div class="p1">
                    <p id="62">MS图像<i>M</i>的亮度分量<i><b>I</b></i>可以与MS图像之间建立一个线性关系<citation id="177" type="reference"><link href="4" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">16</a>]</sup></citation>,这个关系描述为</p>
                </div>
                <div class="p1">
                    <p id="63"><i><b>I</b></i>=∑<sub><i>c</i></sub><i>α</i><sub><i>c</i></sub><i>M</i><sub><i>c</i></sub>      (1)</p>
                </div>
                <div class="p1">
                    <p id="64">式中,当多光谱图像为红、绿、蓝(RGB)三色时,<i>α</i><sub><i>c</i></sub>的值为1/3。而事实上,大多数多光谱图像是由RGB和一个红外共4个波段组成,因此可以用<i>α</i><sub><i>c</i></sub>=1/<i>C</i>表示4个及以上的多光谱图像的系数<citation id="178" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="65">由于亮度-色度-饱和度转换到红、绿、蓝(IHS-RGB)是用PAN图像的分量替换MS图像中<i><b>I</b></i>分量,因此,除去在替换过程中产生的误差以及由于图像本身存在的噪音和冗余信息外,MS图像的<i><b>I</b></i>波段的所有信息可以被全色图像所代替<citation id="179" type="reference"><link href="4" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">16</a>]</sup></citation>,并结合式(1),于是有</p>
                </div>
                <div class="p1">
                    <p id="66"><i><b>P</b></i>≈∑<sub><i>c</i></sub><i>α</i><sub><i>c</i></sub><i>M</i><sub><i>c</i></sub>      (2)</p>
                </div>
                <div class="p1">
                    <p id="67">式中,<i>α</i><sub><i>c</i></sub>为未知系数。为了计算系数<i>a</i>,可以对函数<i>G</i>(<i>a</i>)进行最小化</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>α</mi></munder><mi>G</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>x</mi></msub><mo stretchy="false">(</mo></mstyle><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mi>α</mi></mstyle><msub><mrow></mrow><mi>c</mi></msub><mi>Μ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mi>λ</mi><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mo stretchy="false">(</mo></mstyle><mrow><mi>max</mi></mrow><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中,<i>P</i>(<i>x</i>)表示PAN图像处理函数;另外由于系数<i>a</i>非负,因此采用拉格朗日乘子<i>λ</i>来增加<i>a</i>的非负约束,目的是保证能获得较为理想的解<citation id="180" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">1.1.2 增强边缘保真度</h4>
                <div class="p1">
                    <p id="71">由于IHS方法只对<i>R</i>、<i>G</i>、<i>B</i> 3个分量进行转换和融合,导致4个及4个以上波段的图像在融合处理过程中会丢失很多的空间信息和光谱信息,尤其图像边缘的空间信息易丢失。解决这一问题,可以从PAN图像中提取边缘信息,然后与MS图像进行相应的Pan-sharpening,从而获得融合图像<i>F</i><sub><i>c</i></sub><citation id="181" type="reference"><link href="4" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">16</a>]</sup></citation>,描述如式(4)</p>
                </div>
                <div class="p1">
                    <p id="72"><i>F</i><sub><i>c</i></sub>(<i>x</i>,<i>y</i>)=<i>M</i><sub><i>c</i></sub>(<i>x</i>,<i>y</i>)+<i>h</i>(<i>x</i>,<i>y</i>)(<i>P</i>(<i>x</i>,<i>y</i>)-<i>I</i>(<i>x</i>,<i>y</i>))      (4)</p>
                </div>
                <div class="p1">
                    <p id="73">式中,<i>h</i>(<i>x</i>,<i>y</i>)是边缘检测函数,其定义为</p>
                </div>
                <div class="p1">
                    <p id="74"><mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>exp</mi></mrow><mrow><mo>(</mo><mrow><mo>-</mo><mfrac><mi>η</mi><mrow><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mn>4</mn></msup><mo>+</mo><mi>ε</mi></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="75">式中,<i>ε</i>是一个很小的非零值;∇<i>P</i>(<i>x</i>,<i>y</i>)是PAN图像在(<i>x</i>,<i>y</i>)处的梯度;<i>η</i>是表示梯度大小的一个参数,其目的是形成边缘并控制图像的平滑度<citation id="182" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">1.2 目标函数设置</h4>
                <div class="p1">
                    <p id="77">结合改进后的IHS方法<citation id="183" type="reference"><link href="32" rel="bibliography" /><link href="34" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>和文献<citation id="184" type="reference">[<a class="sup">10</a>,<a class="sup">14</a>]</citation>提出的Pan-sharpening变分模型,可以确立目标函数,然后优化这个目标函数来找重构最佳融合图像。</p>
                </div>
                <div class="p1">
                    <p id="78">由于多光谱图像融合旨在结合全色图像PAN的空间细节和多光谱图像MS的光谱信息,得到空间分辨率和光谱分辨率兼优的高质量多光谱Pan-sharpening影像<i>F</i><citation id="185" type="reference"><link href="32" rel="bibliography" /><link href="36" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">18</a>]</sup></citation>,故<i>F</i>空间域中的细节信息主要来自于PAN图像,而其光谱维的波段信息主要来自MS图像<citation id="186" type="reference"><link href="20" rel="bibliography" /><link href="28" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">14</a>,<a class="sup">16</a>]</sup></citation>,因此可以作以下2个假设:</p>
                </div>
                <div class="p1">
                    <p id="79">(1) 保持空间信息策略。在式(2)中,描述的是MS图像与PAN图像之间的线性关系,这种组合约束对于提高融合图像的质量作用并不大,因此需要对其作进一步改进,建立PAN图像与Pan-sharpening图像<i>F</i>之间的关系,目的是尽可能地保留PAN图像的空间信息,从而提高融合图像的空间质量。文献<citation id="187" type="reference">[<a class="sup">16</a>]</citation>设计了PAN图像可以近似为Pan-sharpening图像<i>F</i>中每个波段图像的线性组合,即通过组合Pan-sharpening得到的图像<i>F</i>的全部波段的空间结构信息可以恢复成高分辨率PAN图像的细节信息,这种关联约束能很好地提高图像<i>F</i>的空间分辨率,但忽略了IHS转换过程中可能存在的光谱信息丢失,于是有</p>
                </div>
                <div class="p1">
                    <p id="80"><i><b>P</b></i>≈∑<sub><i>c</i></sub><i>θ</i><sub><i>c</i></sub><i>F</i><sub><i>c</i></sub>+<i>δ</i>      (6)</p>
                </div>
                <div class="p1">
                    <p id="81">式中,<i>δ</i>表示光谱信息丢失量;<i>θ</i><sub><i>c</i></sub>为未知系数且0≤<i>θ</i><sub><i>c</i></sub>≤1,其目的是约束空间分辨率的保真度。</p>
                </div>
                <div class="p1">
                    <p id="82">(2) 保持光谱信息策略。式(6)是为了丰富Pan-sharpening图像<i>F</i>的边缘几何信息,在一定程度上能提高融合图像的空间分辨率,但由于在第1个假设中,已经对空间质量进行了很好地约束,足以保证了Pan-sharpening图像<i>F</i>的空间分辨率,因此,还需要对图像<i>F</i>的光谱质量进行约束,从而避免出现光谱失真现象。文献<citation id="188" type="reference">[<a class="sup">16</a>]</citation>设计了MS图像可以近似看作Pan-sharpening图像<i>F</i>中的每个波段图像经过空间卷积操作后得到的采样图像的组合,即利用空间滤波滤除融合影像中的PAN结构信息后保留了多光谱图像的主要成分,但它忽略了采样过程中可能存在的空间信息丢失,于是有</p>
                </div>
                <div class="p1">
                    <p id="83"><i>M</i><sub><i>c</i></sub>(<i>x</i>,<i>y</i>)≈∑<sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub><i>K</i>(<i>i</i>,<i>j</i>)<i>F</i><sub><i>c</i></sub>(<i>x</i>-<i>i</i>,<i>y</i>-<i>j</i>)+<i>φ</i>      (7)</p>
                </div>
                <div class="p1">
                    <p id="84">式中,<i>φ</i>表示空间信息丢失量;<i>K</i>为3×3的未知卷积模型。</p>
                </div>
                <div class="p1">
                    <p id="85">这两个假设是基于遥感图像Pan-sharpening的基本原理,是在文献<citation id="190" type="reference">[<a class="sup">10</a>,<a class="sup">14</a>]</citation>等基础上演化而来,并在文献<citation id="189" type="reference">[<a class="sup">16</a>]</citation>中已得到了相关验证,其目的依旧是分别建立Pan-sharpening图像<i>F</i>与全色图像PAN以及与多光谱图像MS之间的关联约束。因此,根据这2个假设并结合式(3)可以确立需要优化的目标函数为</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtable columnalign="left"><mtr><mtd><mi>min</mi><mi>Η</mi><mo stretchy="false">(</mo><mi>α</mi><mo>,</mo><mi>θ</mi><mo>,</mo><mi>Κ</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub><mo stretchy="false">{</mo></mstyle><mrow><mo>|</mo><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mi>θ</mi></mstyle><msub><mrow></mrow><mi>c</mi></msub><mi>F</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mi>δ</mi></mrow><mo>|</mo></mrow><msup><mrow></mrow><mi>p</mi></msup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mfrac><mn>1</mn><mi>C</mi></mfrac><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mrow><mrow><mo>|</mo><mrow><mi>Μ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mi>Κ</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mstyle><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mrow><mrow><mrow><mi>F</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mi>i</mi><mo>,</mo><mi>y</mi><mo>-</mo><mi>j</mi><mo stretchy="false">)</mo><mo>+</mo><mi>φ</mi></mrow><mo>|</mo></mrow><msup><mrow></mrow><mi>p</mi></msup></mrow><mo>}</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mn>0</mn><mo>≤</mo><mi>α</mi><msub><mrow></mrow><mi>c</mi></msub><mo>≤</mo><mn>1</mn><mo>,</mo><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>C</mi></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mn>0</mn><mo>≤</mo><mi>θ</mi><msub><mrow></mrow><mi>c</mi></msub><mo>≤</mo><mn>1</mn><mo>,</mo><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>C</mi></mtd></mtr><mtr><mtd><mtext> </mtext><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mi>Κ</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>≤</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>≤</mo><mn>1</mn><mo>,</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mi>i</mi><mo>,</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn></mtd></mtr></mtable><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">式中,第1部分即对应的是上述第1个假设,目的是保证Pan-sharpening图像<i>F</i>的空间质量;第2部分对应的是上述第2个假设,目的是保证Pan-sharpening图像<i>F</i>的光谱质量<citation id="191" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。其中,1/<i>C</i>具有平衡作用,协同参数(<i>α</i>,<i>θ</i>,<i>k</i>)促使目标函数(8)向着最优解的方向快速收敛,从而确保获得最佳的Pan-sharpening结果。另外,图像<i>F</i>的最优值依据AIHS转换通过式(4)求得。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">2 粒子群优化</h3>
                <h4 class="anchor-tag" id="89" name="89">2.1 粒子群算法</h4>
                <div class="p1">
                    <p id="90">粒子群算法(PSO)采用群体智能优化策略,通过种群内粒子间的合作与竞争机制进行全局寻优从而获得全局最优解。该算法是由文献<citation id="192" type="reference">[<a class="sup">19</a>]</citation>首次提出来的。</p>
                </div>
                <div class="p1">
                    <p id="91">在<i>D</i>维空间中,设定种群规模为<i>NP</i>,粒子<i>i</i>的位置表示为<i>x</i><sub><i>i</i></sub>=(<i>x</i><sub><i>i</i></sub><sub>1</sub>,<i>x</i><sub><i>i</i></sub><sub>2</sub>,…,<i>x</i><sub><i>iD</i></sub>),粒子<i>i</i>的速度表示为<i>v</i><sub><i>i</i></sub>=(<i>v</i><sub><i>i</i></sub><sub>1,</sub><i>v</i><sub><i>i</i></sub><sub>2,</sub>…,<i>v</i><sub><i>iD</i></sub>),<i>f</i>(<i>x</i><sub><i>i</i></sub>)为适应度函数,pbest<sub><i>i</i></sub>=(<i>p</i><sub><i>i</i></sub><sub>1,</sub><i>p</i><sub><i>i</i></sub><sub>2,</sub>…,<i>p</i><sub><i>iD</i></sub>)表示第<i>i</i>个粒子经历过的最佳位置,gbest<sub><i>i</i></sub>=(<i>g</i><sub>1,</sub><i>g</i><sub>2,</sub>…,<i>g</i><sub><i>D</i></sub>)表示所有粒子的全局最佳位置,并设定在第<i>d</i>(1≤<i>d</i>≪<i>D</i>)维的粒子位置变化范围限定在<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>min</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>,</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>,粒子速度变化范围限定在<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mrow><mo>-</mo><mi>V</mi></mrow><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>,</mo><mi>V</mi><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">(1) 粒子<i>i</i>的第<i>d</i>维速度更新公式</h4>
                <div class="p1">
                    <p id="93"><i><b>V</b></i><mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>=<i>w</i><i><b>V</b></i><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>+<i>c</i><sub>1</sub><i>r</i><sub>1</sub>(pbest<sub><i>id</i></sub>-<i><b>x</b></i><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>)+</p>
                </div>
                <div class="p1">
                    <p id="94"><i>c</i><sub>2</sub><i>r</i><sub>2</sub>(gbest<sub><i>d</i></sub>-<i><b>x</b></i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>)      (9)</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">(2) 粒子<i>i</i>的第<i>d</i>维位置更新公式</h4>
                <div class="p1">
                    <p id="96"><i><b>X</b></i><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>=<i><b>X</b></i><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>+<i><b>V</b></i><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>      (10)</p>
                </div>
                <div class="p1">
                    <p id="97">式中,<i><b>V</b></i><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>表示粒子<i>i</i>在第<i>k</i>次迭代的第<i>d</i>维分量的飞行速度矢量;<i><b>X</b></i><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>表示粒子<i>i</i>在第<i>k</i>次迭代的第<i>d</i>维分量的位置矢量;<i>c</i><sub>1</sub>、<i>c</i><sub>2</sub>为加速度系数,调节学习最大步长;<i>r</i><sub>1</sub>、<i>r</i><sub>2</sub>表示2个随机变量,其取值范围[0,1],以增加搜索随机性;<i>w</i>表示惯性权重,非负数,调节对解空间的搜索范围<citation id="193" type="reference"><link href="38" rel="bibliography" /><link href="40" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98">2.2 编码方式及种群初始化</h4>
                <div class="p1">
                    <p id="99">编码的主要工作是将Pan-sharpening模型中的未知数映射成粒子的表达形式,常用的编码方式有二进制编码和实数编码。根据式(8)可知,需要求解的参数为<mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>{</mo><mi>a</mi></mrow></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>,</mo><mi>a</mi></mrow><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo><mo>,</mo><mrow><mrow><mo>{</mo><mi>θ</mi></mrow></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>θ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>θ</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow></math></mathml>以及{<i>K</i>(1,1),<i>K</i>(1,2),<i>K</i>(1,3),<i>K</i>(2,1),<i>K</i>(2,2),<i>K</i>(2,3),<i>K</i>(3,1),<i>K</i>(3,2),<i>K</i>(3,3)},因此本文采用实数编码的方式更为合理且算法的运行效率更高,其编码方式如图1所示。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 染色体编码方式" src="Detail/GetImg?filename=images/CHXB201910011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 染色体编码方式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910011_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 The chromosome coding mode</p>
                                <p class="img_note">注:种群中的每个染色体(粒子)是随机生成的。</p>

                </div>
                <h4 class="anchor-tag" id="101" name="101">2.3 技术流程</h4>
                <div class="p1">
                    <p id="102">经过编码和初始化后,通过设定合理的算法收敛条件,并采用粒子群算法来优化式(8),不断地迭代求解,从而可以获得全局最优解,即获得最佳控制参数和最优的Pan-sharpening图像。本文所采取的技术路线如图2所示。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910011_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 技术流程" src="Detail/GetImg?filename=images/CHXB201910011_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 技术流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910011_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 The technology</p>

                </div>
                <h4 class="anchor-tag" id="104" name="104">2.4 PAIHS算法</h4>
                <div class="p1">
                    <p id="105">这里主要介绍图2中的PAIHS部分,其基本算法流程如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="106">算法1 PAIHS基本算法流程</p>
                </div>
                <div class="p1">
                    <p id="107">输入:LMS <i>M</i>,PAN <i>P</i>,<i>c</i><sub>1</sub>,<i>c</i><sub>2</sub>,<i>r</i><sub>1</sub>,<i>r</i><sub>2</sub>,<i>w</i>;</p>
                </div>
                <div class="p1">
                    <p id="108">步骤1:根据AIHS和2个假设条件确定优化目标函数<i>f</i>(<i>x</i>)。</p>
                </div>
                <div class="p1">
                    <p id="109">步骤2:设定粒子种群规模<i>NP</i>,粒子的维数<i>D</i>,算法的终止条件<i>FES</i>;设定<mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mrow><mo>[</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>min</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>,</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub></mrow><mo>]</mo></mrow><mo>,</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mrow><mo>[</mo><mrow><mrow><mo>-</mo><mi>V</mi></mrow><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>,</mo><mi>V</mi><msub><mrow></mrow><mrow><mi>max</mi><mo>,</mo><mi>d</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>;确定粒子编码方式,随机初始化种群,产生一组包含(<i>α</i>,<i>θ</i>,<i>k</i>)的解集合。</p>
                </div>
                <div class="p1">
                    <p id="110">步骤3:根据<i>F</i>=AdaptiveIHS(<i>M</i>,<i>P</i>,<i>α</i>)计算融合图像<i>F</i>。</p>
                </div>
                <div class="p1">
                    <p id="111">步骤4:对初始种群中的个体<i>x</i><sub><i>i</i></sub>进行评估<i>f</i>(<i>x</i><sub><i>i</i></sub>)min</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Η</mi><mo stretchy="false">(</mo><mi>α</mi><mo>,</mo><mi>θ</mi><mo>,</mo><mi>Κ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub><mo stretchy="false">{</mo></mstyle><mrow><mrow><mo>|</mo><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mi>θ</mi></mstyle><msub><mrow></mrow><mi>c</mi></msub><mi>F</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mi>δ</mi></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mi>p</mi></msup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mi>C</mi></mfrac><mstyle displaystyle="true"><msub><mo>∑</mo><mi>c</mi></msub><mrow><mrow><mrow><mrow><mrow><mo>|</mo><mrow><mi>Μ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mi>Κ</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mi>F</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mi>i</mi><mo>,</mo><mi>y</mi><mo>-</mo><mi>j</mi><mo stretchy="false">)</mo><mo>+</mo><mi>φ</mi></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mi>p</mi></msup></mrow><mo>}</mo></mrow></mrow></mstyle></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">并记录个体最佳位置信息pbest<sub><i>i</i></sub>,全局最佳位置信息gbest<sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="114">步骤5:根据式(9)和式(10)对粒子的速度<i><b>V</b></i><mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>和位置<i><b>X</b></i><mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>d</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>进行更新,并判断速度和位置是否出界,若出界则修正。</p>
                </div>
                <div class="p1">
                    <p id="115">步骤6:比较每个粒子的适应度值<i>f</i>(<i>x</i><sub><i>i</i></sub>)和它的个体最优值pbest<sub><i>i</i></sub>,若当前值particle(<i>i</i>).Posit优于个体最优值pbest<sub><i>i</i></sub>,则设particle(<i>i</i>).Posit为新的个体最优值。</p>
                </div>
                <div class="p1">
                    <p id="116">步骤7:比较每个粒子的最佳适应度值和全局最优粒子的位置gbest<sub><i>i</i></sub>,若当前值particle(<i>i</i>).Best.Position优于全局最优粒子,则当设前值particle(<i>i</i>).Best.Position为新的全局最优粒子。</p>
                </div>
                <div class="p1">
                    <p id="117">步骤8:计算评价指标<i>R</i>=imagemetrics(<i>M</i>,<i>P</i>,<i>F</i>)。</p>
                </div>
                <div class="p1">
                    <p id="118">步骤9:判断代数<i>FES</i>是否已到达最大代数,如果已经到达,结束算法。否则转向步骤(3)。</p>
                </div>
                <div class="p1">
                    <p id="119">输出:Pan-sharpening图像<i>F</i>;定量评价指标值<i>R</i>。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">3 试验及对比分析</h3>
                <div class="p1">
                    <p id="121">目前Pan-sharpening质量的评估方法有两种:主观评价方法和客观评价方法。主观评价法即根据人的视觉感知、大脑分析等机能特征对图像色彩、亮度、形状等作出一系列判断,并作出相应的分析和决策,也称之为视觉分析法。它是一种直观、简单灵活的判断方法,但该方法具有一定的片面性,因为观察者对色彩、亮度、模糊度、重影等现象的感知程度、理解能力、分析能力的不同,作出的判断结论可能存在一定的差异,这并不利于得到准确的评价结果。因此,除了进行主观评价外,还需要选取比较可靠的客观评价指标来进行定量计算,该方法也称之为定量分析方法。本文除了进行主观的视觉对比和分析外,还选取了CC<citation id="194" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、ERGAS<citation id="198" type="reference"><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><sup>[<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>、QAVE<citation id="199" type="reference"><link href="46" rel="bibliography" /><link href="48" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>、RASE<citation id="195" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>、RMSE<citation id="196" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、SAM<citation id="197" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、SID<citation id="200" type="reference"><link href="32" rel="bibliography" /><link href="52" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">26</a>]</sup></citation>这7个参数指标来进行客观评价。</p>
                </div>
                <h4 class="anchor-tag" id="122" name="122">3.1 视觉对比及分析</h4>
                <div class="p1">
                    <p id="123">从整体视觉效果来看,图3—图5中的所有Pan-sharpening方法都能很好地将PAN图像的空间信息与MS图像的光谱信息集成到一起。相对于PAN图像而言,所获得Pan-sharpening图像F的解译能力都有了很大程度的提高,能够比较容易地分辨出图像<i>F</i>中的地物颜色和亮度等特征;相对于原MS图像,图像<i>F</i>中增添了大量的空间细节纹理信息,使得地物信息更为丰富。</p>
                </div>
                <div class="p1">
                    <p id="124">图3采用了分辨率较高的MS图像,试验结果发现Pan-sharpening后的图像在视觉分析上辨别度不高,除PCA方法所得的图像颜色变红而失真明显外,其他3种方法所产生的图像在肉眼上难以分辨差异。于是在图4和图5中,采用了分辨率较低的MS图像进行试验,其视觉效果就产生了明显差异,对比及分析如下:</p>
                </div>
                <div class="p1">
                    <p id="125">(1) 虽然Wavelet和AIHS方法所获得的图像在细节上表现最为丰富,但树木等地物存在明显颗粒感,出现了重影现象。</p>
                </div>
                <div class="p1">
                    <p id="126">(2) 通过对比,不难发现Brovey方法所获得的图像是这5种方法中视觉效果最差的,如图4和图5中的树、道路和建筑物等都成团状、很模糊,基本看不清地物轮廓和纹理特征。</p>
                </div>
                <div class="p1">
                    <p id="127">(3) 与PAN图像仔细对比,发现PCA方法获得的图像中间区域有较小程度的细节信息丢失,另外图像中的树木也有轻微模糊现象,而且整个图像偏亮,对比度也存在失真,因此存在光谱失真现象。</p>
                </div>
                <div class="p1">
                    <p id="128">通过对图3—图5的视觉对比和分析,能直观地发现PAIHS方法得到的融合图像整体平滑、清晰、无明显重影和模糊现象。因此,在视觉上该方法是这5种方法中Pan-sharpening质量最好的。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">3.2 定量对比及分析</h4>
                <div class="p1">
                    <p id="130">表1—表3是基于AIHS、Wavelet、PCA、Brovey及PAIHS的Pan-sharpening 5种方法的试验结果,其中的参考值和最好的评价指标值用粗体表示,其定量分析和比较如下。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Pan-sharpened结果比较" src="Detail/GetImg?filename=images/CHXB201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Pan-sharpened结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Comparison of Pan-sharpened results</p>

                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910011_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Pan-sharpened结果比较" src="Detail/GetImg?filename=images/CHXB201910011_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Pan-sharpened结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910011_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Comparison of Pan-sharpened results</p>

                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表1 图3的Pan-sharpening的定量指标结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 Performance comparison on images in Fig.3</b></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />定量指标</td><td>CC</td><td>ERGAS</td><td>QAVE</td><td>RASE</td><td>RMSE</td><td>SAM</td><td>SID</td></tr><tr><td><br />参考值</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr><tr><td><br />AIHS</td><td>0.000 6</td><td>1.004 5</td><td>0.998 4</td><td>4.041 8</td><td>4.276 7</td><td>0.049 9</td><td>0.001 8</td></tr><tr><td><br />Wavelet</td><td>0.003 6</td><td>0.772 6</td><td>0.993 4</td><td>3.088 0</td><td>3.267 4</td><td>0.544 3</td><td>0.002 1</td></tr><tr><td><br />PCA</td><td>0.111 5</td><td>2.575 9</td><td>0.985 9</td><td>10.381 9</td><td>10.985 1</td><td>0.469 1</td><td>0.007 4</td></tr><tr><td><br />Brovey</td><td>0.006 4</td><td>12.461 0</td><td>0.854 7</td><td>33.673 7</td><td>35.630 3</td><td>2.286 7</td><td>0.003 3</td></tr><tr><td><br />PAIHS</td><td><b>0.000</b><b>2</b></td><td><b>0.114</b><b>9</b></td><td><b>0.999</b><b>9</b></td><td><b>0.462</b><b>3</b></td><td><b>0.489</b><b>2</b></td><td><b>0.006</b><b>1</b></td><td><b>0.000</b><b>2</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910011_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 Pan-sharpened结果比较" src="Detail/GetImg?filename=images/CHXB201910011_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 Pan-sharpened结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910011_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Comparison of Pan-sharpened results</p>

                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表2 图4的Pan-sharpening的定量指标结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 Performance comparison on images in Fig.4</b></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />定量指标</td><td>CC</td><td>ERGAS</td><td>QAVE</td><td>RASE</td><td>RMSE</td><td>SAM</td><td>SID</td></tr><tr><td><br />参考值</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr><tr><td><br />AIHS</td><td>0.054 5</td><td>7.311 6</td><td>0.947 6</td><td>28.803 8</td><td>31.195 6</td><td>4.193 8</td><td>0.201 7</td></tr><tr><td><br />Wavelet</td><td>0.170 1</td><td>7.430 9</td><td>0.873 0</td><td>29.262 3</td><td>31.692 2</td><td>6.805 1</td><td>0.217 2</td></tr><tr><td><br />PCA</td><td>0.425 1</td><td>9.009 1</td><td>0.755 5</td><td>36.530 7</td><td>39.564 1</td><td>6.745 1</td><td>0.047 2</td></tr><tr><td><br />Brovey</td><td>0.293 3</td><td>10.848 4</td><td>0.804 2</td><td>50.074 2</td><td>54.232 2</td><td>1.340 3</td><td>0.047 4</td></tr><tr><td><br />PAIHS</td><td><b>0.026</b><b>9</b></td><td><b>2.030</b><b>5</b></td><td><b>0.995</b><b>6</b></td><td><b>7.990</b><b>0</b></td><td><b>8.653</b><b>4</b></td><td><b>1.037</b><b>7</b></td><td><b>0.046</b><b>5</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="136">
                    <p class="img_tit"><b>表3 图5的Pan-sharpening的定量指标结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.3 Performance comparison on images in Fig.5</b></p>
                    <p class="img_note"></p>
                    <table id="136" border="1"><tr><td><br />定量指标</td><td>CC</td><td>ERGAS</td><td>QAVE</td><td>RASE</td><td>RMSE</td><td>SAM</td><td>SID</td></tr><tr><td><br />参考值</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr><tr><td><br />AIHS</td><td>0.044 1</td><td>5.548 0</td><td>0.967 7</td><td>21.679 0</td><td>27.145 7</td><td>2.602 1</td><td>0.082 6</td></tr><tr><td><br />Wavelet</td><td>0.145 5</td><td>5.542 3</td><td>0.836 4</td><td>21.671 0</td><td>27.135 2</td><td>5.206 0</td><td>0.107 2</td></tr><tr><td><br />PCA</td><td>0.140 6</td><td>5.750 3</td><td>0.882 4</td><td>23.753 8</td><td>29.743 3</td><td>3.429 9</td><td>0.037 2</td></tr><tr><td><br />Brovey</td><td>0.170 1</td><td>7.840 9</td><td>0.879 5</td><td>35.371 1</td><td>44.289 8</td><td>0.070 0</td><td>0.002 0</td></tr><tr><td><br />PAIHS</td><td><b>0.019</b><b>6</b></td><td><b>1.455</b><b>1</b></td><td><b>0.997</b><b>6</b></td><td><b>5.682</b><b>4</b></td><td><b>7.115</b><b>2</b></td><td><b>0.634</b><b>6</b></td><td><b>0.017</b><b>2</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="137">(1) 表1、表2中,PAIHS方法的各项指标值是5种方法中最好的。表3中,PAIHS方法的SAM值、SID值略差于Brovey方法,但是优于AIHS方法、Wavelet方法、PCA方法相应的指标值;除SAM值和SID值外,PAIHS方法的其他几种指标值仍是所有方法中最好的。因此,再一次印证了PAIHS方法的效果是最好的。</p>
                </div>
                <div class="p1">
                    <p id="138">(2) 表1中,Brovey方法除CC值和SID值不是最差的外,其他5个指标值均是所有方法中最差的。表2中,Brovey方法的CC值优于Wavelet方法,但不及PCA方法;其SAM值略好外,QAVE值和SID值也比较居中,Brovey方法的ERGAS值、RASE值和RMSE值仍是所有方法中最差的。表3中的数值分布与表2类似。因此Brovey方法是所有方法中最差的,这与视觉分析得到Brovey方法是最差这一结论是一致的。</p>
                </div>
                <div class="p1">
                    <p id="139">(3) 通过比较表1—表3发现,AIHS、Wavelet、PCA 3种方法的指标值时好时坏,比较中庸。3个表中,PCA方法的ERGAS值比另外两种方法的ERGAS值差,PCA方法的QAVE值除在表1和表2中也是3种方法中最差的,而ERGAS值和QAVE值是光谱失真的评价指标,这与视觉上得到的对比度失真、图像整体亮度偏亮的结论是相吻合的。</p>
                </div>
                <div class="p1">
                    <p id="140">通过主观分析和客观评价参数的对比,可以发现PAIHS方法比其他4种融合方法好。另外,在试验中也得出一个结论:种群规模设置越大,迭代次数越Pan-sharpening质量越好。</p>
                </div>
                <h3 id="141" name="141" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="142">本文提出了一种Pan-sharpening方法,称之为PAIHS。该方法基于自适应亮度-色度-饱和度(AIHS)转换和变分Pan-sharpening框架及2个假设,同时确定了优化目标函数,然后采用粒子群优化算法进行优化,目的是寻找全局最优控制系数,确保能较好地保持原MS图像的光谱信息和PAN图像的空间细节信息,从而获得最佳质量的Pan-sharpening图像。另外,文中将提出的方法与目前主流的Pan-sharpening方法通过3幅遥感图像进行试验对比。试验结果表明,本文方法所得的融合图像在光谱特性的保持能力和空间细节信息的表现方面都有更好的效果,是一种有效且可行的Pan-sharpening方法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An IHS-based fusion for color distortion reduction and vegetation enhancement in IKONOS imagery">

                                <b>[1]</b> EL-MEZOUAR M C,TALEB N,KPALMA K,et al.An IHS-based fusion for color distortion reduction and vegetation enhancement in IKONOS imagery[J].IEEE Transactions on Geoscience and Remote Sensing,2011,49(5):1590-1602.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An adaptive IHS pan-sharpening method">

                                <b>[2]</b> RAHMANI S,STRAIT M,MERKURJEV D,et al.An adaptive IHS Pan-sharpening method[J].IEEE Geoscience and Remote Sensing Letters,2010,7(4):746-750.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening">

                                <b>[3]</b> LABEN C A,BROWER B V.Process for enhancing the spatial resolution of multispectral imagery using Pan-sharpening:USA,6011875 [P].2000-01-04.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Panchromatic and multispectral images fusion based on modified GSSWT.&amp;quot;">

                                <b>[4]</b> LU Xiaochen,ZHANG Junping.Panchromatic and multispectral images fusion based on modified GS-SWT[C]//Proceedings of 2014 IEEE Geoscience and Remote Sensing Symposium.Quebec,Canada:IEEE,2014:2530-2533.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computationally inexpensive Landsat 8 operational land imager (OLI) Pan-sharpening">

                                <b>[5]</b> ZHANG Hankui,ROY D P.Computationally inexpensive Landsat 8 operational land imager (OLI) Pan-sharpening[J].Remote Sensing,2016,8(3):180.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image fusion using multireso-lution analysis">

                                <b>[6]</b> PARK J H,KIM K O,YANG Y K.Image fusion using multiresolution analysis[C]//Proceedings of 2001 IEEE International Geoscience and Remote Sensing Symposium.Sydney,Australia:IEEE,2001:864-866.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD713859550&amp;v=MjQxNzlNTmpuQmFyUzVIZG5KcG9wQVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWNy8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> ZHOU J,CIVCO D L,SILANDER J A.A wavelet transform method to merge Landsat TM and SPOT panchromatic data[J].International Journal of Remote Sensing,1998,19(4):743-757.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD14022800000399&amp;v=MTgxOTAvaXJSZEdlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1FhaFk9TmpuQmFySzhIdFBPcDQ5RlpPc1BEM1V3b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> METEALLI M R,NASR A H,FARAGALLAH O S,et al.Efficient Pan-sharpening of satellite images with the contourlet transform[J].International Journal of Remote Sensing,2014,35(5):1979-2002.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis">

                                <b>[9]</b> AIAZZI B,ALPARONE L,BARONTI S,et al.Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis[J].IEEE Transactions on Geoscience and Remote Sensing,2002,40(10):2300-2312.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Variational Approach for Sharpening High Dimensional Images">

                                <b>[10]</b> MÖLLER M,WITTMAN T,BERTOZZI A L,et al.A variational approach for sharpening high dimensional images[J].SIAM Journal on Imaging Sciences,2012,5(1):150-178.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002831035&amp;v=Mjk2NTdCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGeW5sVWJyTUlGbz1OajdCYXJPNEh0SE9wNHhFWk9nS1kzazV6&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> BALLESTER C,CASELLES V,IGUAL L,et al.A variational model for P+XS image fusion[J].International Journal of Computer Vision,2006,69(1):43-58.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Variational wavelet Pan-sharpening">

                                <b>[12]</b> MOELLER M,WITTMAN T,BERTOZZI A L.Variational wavelet Pan-sharpening[J].IEEE Transactions on Geoscience and Remote Sensing,2008:1-9.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A regularized model-based optimization framework for Pan-sharpening">

                                <b>[13]</b> ALY H A,SHARMA G.A regularized model-based optimization framework for Pan-sharpening[J].IEEE Transactions on Image Processing,2014,23(6):2596-2608.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A variational approach for pan-sharpening">

                                <b>[14]</b> FANG Faming,LI Fang,SHEN Chaomin,et al.A variational approach for Pan-sharpening[J].IEEE Transactions on Image Processing,2013,22(7):2822-2834.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Genetic Algorithms and its application to Image Fusion.2008">

                                <b>[15]</b> MUMTAZ A,MAJID A,MUMTAZ A.Genetic algorithms and its application to image fusion[C]//Proceedings of the 4th International Conference on Emerging Technologies.Rawalpindi,Pakistan:IEEE,2008:6-10.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHDBFBBC3C0781E187C238FFDF22A10B2EE&amp;v=MDc5NTgvcUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNTlsaHhyMjd3S3c9TmlmRGFzSE9iS08vclB4RlkrTU9lWDB4eUdVUjZUY0xQZ3VVcmhCRWVMTG1SOA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> CHEN Yingxia,ZHANG Guixu.A Pan-sharpening method based on evolutionary optimization and IHS transformation[J].Mathematical Problems in Engineering,2017(4):1-8.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint IHS and variational methods for Pan-sharpening of very high resolution imagery">

                                <b>[17]</b> ZHOU Zeming,YANG Pinglv,LI Yuanxiang,et al.Joint IHS and variational methods for Pan-sharpening of very high resolution imagery[C]//Proceedings of 2013 IEEE International Geoscience and Remote Sensing Symposium.Melbourne,VIC,Australia:IEEE,2014:2597-2600.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201604009&amp;v=MDYxOTFNcTQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWNy9NSmlYVGJMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 许宁,肖新耀,尤红建,等.HCT变换与联合稀疏模型相结合的遥感影像融合[J].测绘学报,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372.XU Ning,XIAO Xinyao,YOU Hongjian,et al.A Pansharpening method based on HCT and joint sparse model[J].Acta Geodaetica et Cartographica Sinica,2016,45(4):434-441.DOI:10.11947/j.AGCS.2016.20150372.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 KENNEDY J,EBERHART R C.Particle swarm optimization[C]//Proceedings of ICNN'95 - International Conference on Neural Networks.Perth,Australia:IEEE,1995:1942-1948.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Particle swarm optimization">

                                <b>[20]</b> VENTER G,SOBIESZCZANSKI-SOBIESKI J.Particle swarm optimization[J].AIAA Journal,2003,41(8):1583-1589.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDB3D20B2B2E19643141952BA2D9764B81&amp;v=MTk4MTVUcm1ZOGZyU1FON0tlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxoeHIyN3dLdz1OajdCYXNHN2F0UE0zWTAzWnA0T0JYbzl6QmNYNnpaNFNnMg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> PUSHPARAJ J,HEGDE A V.Evaluation of Pan-sharpening methods for spatial and spectral quality[J].Applied Geomatics,2017,9(1):1-12.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparison of pansharpening algorithms: Outcome of the 2006 GRS-S data-fusion contest">

                                <b>[22]</b> ALPARONE L,WALD L,CHANUSSOT J,et al.Comparison of Pansharpening algorithms:outcome of the 2006 GRS-S data-fusion contest[J].IEEE Transactions on Geoscience and Remote Sensing,2007,45(10):3012-3021.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A universal image quality index">

                                <b>[23]</b> WANG Z,BOVIK A C.A universal image quality index[J].IEEE Signal Processing Letters,2002,9(3):81-84.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Performance comparison of different graylevel image fusion schemes through a universal image quality index">

                                <b>[24]</b> TOET A,HOGERVORST M A.Performance comparison of different gray-level image fusion schemes through a universal image quality index[C]//Proceedings Volume 5096,Signal Processing,Sensor Fusion,and Target Recognition XII.Orlando,Florida,United States:SPIE,2003:552-561.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter">

                                <b>[25]</b> CHOI M.A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter[J].IEEE Transactions on Geoscience and Remote Sensing,2006,44(6):1672-1682.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600370076&amp;v=MjI4ODhlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1FhaFk9TmlmT2ZiSzhIdERNcVk5Rlord1BESHMvb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> FANG Faming,ZHANG Guixu,LI Fang,et al.Framelet based Pan-sharpening via a variational method[J].Neurocomputing,2014(10):362-377.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201910011" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910011&amp;v=MjA3OTh0R0ZyQ1VSN3FmWnVkdkZ5cmdWNy9NSmlYVGJMRzRIOWpOcjQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
