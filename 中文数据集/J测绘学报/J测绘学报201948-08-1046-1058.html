<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142616472295000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201908012%26RESULT%3d1%26SIGN%3d4ZJXREEtuqLHNHSu5e6PWlluJIo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908012&amp;v=MTg3MDNVUjdxZlp1ZHZGeTNrVXJyUEppWFRiTEc0SDlqTXA0OUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#80" data-title="1 理论背景与方法 ">1 理论背景与方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="1.1 级联卷积神经网络">1.1 级联卷积神经网络</a></li>
                                                <li><a href="#101" data-title="1.2 训练样本选取">1.2 训练样本选取</a></li>
                                                <li><a href="#108" data-title="1.3 训练与检测">1.3 训练与检测</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="2 试验与分析 ">2 试验与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#114" data-title="2.1 试验数据与环境">2.1 试验数据与环境</a></li>
                                                <li><a href="#124" data-title="2.2 结果与分析">2.2 结果与分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#139" data-title="3 结 论 ">3 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="图1 MTCNN模型结构">图1 MTCNN模型结构</a></li>
                                                <li><a href="#87" data-title="图2 改进的卷积层结构">图2 改进的卷积层结构</a></li>
                                                <li><a href="#106" data-title="图3 改进的级联卷积神经网络结构">图3 改进的级联卷积神经网络结构</a></li>
                                                <li><a href="#107" data-title="图4 训练样本的选取">图4 训练样本的选取</a></li>
                                                <li><a href="#111" data-title="图5 训练过程">图5 训练过程</a></li>
                                                <li><a href="#112" data-title="图6 检测流程">图6 检测流程</a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表1 不同数据集的基本信息&lt;/b&gt;"><b>表1 不同数据集的基本信息</b></a></li>
                                                <li><a href="#117" data-title="图7 不同数据集下的影像示例">图7 不同数据集下的影像示例</a></li>
                                                <li><a href="#128" data-title="图8 不同方法在4种数据集下的PR曲线">图8 不同方法在4种数据集下的PR曲线</a></li>
                                                <li><a href="#132" data-title="图9 数据集A和B下的检测结果">图9 数据集A和B下的检测结果</a></li>
                                                <li><a href="#133" data-title="图10 本文方法在大幅影像上的飞机目标检测结果">图10 本文方法在大幅影像上的飞机目标检测结果</a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表2 模型大小对比&lt;/b&gt;"><b>表2 模型大小对比</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;表3 检测时间对比&lt;/b&gt;"><b>表3 检测时间对比</b></a></li>
                                                <li><a href="#141" data-title="图11 不同种类的飞机示例">图11 不同种类的飞机示例</a></li>
                                                <li><a href="#142" data-title="图12 军用飞机检测结果">图12 军用飞机检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 邓志鹏, 孙浩, 雷琳, 等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng, SUN Hao, LEI Lin, et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201809008&amp;v=MDU5MzVrVXJyT0ppWFRiTEc0SDluTXBvOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         邓志鹏, 孙浩, 雷琳, 等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng, SUN Hao, LEI Lin, et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" 曾接贤, 付俊, 符祥.特征点和不变矩结合的遥感图像飞机目标识别[J].中国图象图形学报, 2014, 19 (4) :592-602.ZENG Jiexian, FU Jun, FU Xiang.Aircraft target recognition in remote sensing images based on distribution of the feature points and invariant moments[J].Journal of Image and Graphics, 2014, 19 (4) :592-602." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201404014&amp;v=MTcxNThyT1B5cmZiTEc0SDlYTXE0OUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         曾接贤, 付俊, 符祥.特征点和不变矩结合的遥感图像飞机目标识别[J].中国图象图形学报, 2014, 19 (4) :592-602.ZENG Jiexian, FU Jun, FU Xiang.Aircraft target recognition in remote sensing images based on distribution of the feature points and invariant moments[J].Journal of Image and Graphics, 2014, 19 (4) :592-602.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" HSIEH J W, CHEN J M, CHUANG C H, et al.Aircraft type recognition in satellite images[J].IEE Proceedings-Vision, Image and Signal Processing, 2005, 152 (3) :307-315." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aircraft type recognition in satellite images">
                                        <b>[3]</b>
                                         HSIEH J W, CHEN J M, CHUANG C H, et al.Aircraft type recognition in satellite images[J].IEE Proceedings-Vision, Image and Signal Processing, 2005, 152 (3) :307-315.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" ZHAO An, FU Kun, SUN Hao, et al.An effective method based on ACF for aircraft detection in remote sensing images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :744-748." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An effective method based on acf for aircraft detection in remote sensing images">
                                        <b>[4]</b>
                                         ZHAO An, FU Kun, SUN Hao, et al.An effective method based on ACF for aircraft detection in remote sensing images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :744-748.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" LEI Zhen, FANG Tao, HUO Hong, et al.Rotation-invariant object detection of remotely sensed images based on texton forest and Hough voting[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (4) :1206-1217.DOI:10.1109/TGRS.2011.2166966." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rotation-invariant object detection of remotely sensed images based on texton forest and hough voting">
                                        <b>[5]</b>
                                         LEI Zhen, FANG Tao, HUO Hong, et al.Rotation-invariant object detection of remotely sensed images based on texton forest and Hough voting[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (4) :1206-1217.DOI:10.1109/TGRS.2011.2166966.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 王树国, 黄勇杰, 张生.可见光图像中飞机目标的特征选择及提取[J].哈尔滨工业大学学报, 2010, 42 (7) :1056-1059.WANG Shuguo, HUANG Yongjie, ZHANG Sheng.Selection and extraction of features of aircraft in optical image[J].Journal of Harbin Institute of Technology, 2010, 42 (7) :1056-1059." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201007012&amp;v=MjU3NDNKZHJHNEg5SE1xSTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck9MU2o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         王树国, 黄勇杰, 张生.可见光图像中飞机目标的特征选择及提取[J].哈尔滨工业大学学报, 2010, 42 (7) :1056-1059.WANG Shuguo, HUANG Yongjie, ZHANG Sheng.Selection and extraction of features of aircraft in optical image[J].Journal of Harbin Institute of Technology, 2010, 42 (7) :1056-1059.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" 王文胜.宽幅光学遥感图像舰船飞机目标检测识别技术研究[D].长春:中国科学院大学 (中国科学院长春光学精密机械与物理研究所) , 2018.WANG Wensheng.Research on technology of ship and aircraft targets recognition from large-field optical remote sensing image[D].Changchun:Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018189095.nh&amp;v=MDY1ODU3cWZadWR2Rnkza1Vyck9WRjI2RnJLd0Y5SEZxcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         王文胜.宽幅光学遥感图像舰船飞机目标检测识别技术研究[D].长春:中国科学院大学 (中国科学院长春光学精密机械与物理研究所) , 2018.WANG Wensheng.Research on technology of ship and aircraft targets recognition from large-field optical remote sensing image[D].Changchun:Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, 2018.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" WANG Wensheng, NIE Ting, FU Tianjiao, et al.A novel method of aircraft detection based on high-resolution panchromatic optical remote sensing images[J].Sensors, 2017, 17 (5) :1047.DOI:10.3390/s17051047." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Novel Method of Aircraft Detection Based on HighResolution Panchromatic Optical Remote Sensing Images">
                                        <b>[8]</b>
                                         WANG Wensheng, NIE Ting, FU Tianjiao, et al.A novel method of aircraft detection based on high-resolution panchromatic optical remote sensing images[J].Sensors, 2017, 17 (5) :1047.DOI:10.3390/s17051047.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" LI Yu, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using a contour-based spatial model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (5) :886-890.DOI:10.1109/LGRS.2012.2183337." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Target Detection in High-Resolution Remote Sensing Images Using a Contour-Based Spatial Model">
                                        <b>[9]</b>
                                         LI Yu, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using a contour-based spatial model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (5) :886-890.DOI:10.1109/LGRS.2012.2183337.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" SUN Hao, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using spatial sparse coding bag-of-words model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (1) :109-113." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic target detection in high-resolution remote sensing images using spatial sparse coding bag-of-words model">
                                        <b>[10]</b>
                                         SUN Hao, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using spatial sparse coding bag-of-words model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (1) :109-113.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" BAI Xiao, ZHANG Huigang, ZHOU Jun.VHR object detection based on structural feature extraction and query expansion[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (10) :6508-6520.DOI:10.1109/TGRS.2013.2296782." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VHR object detection based on structural feature extraction and query expansion">
                                        <b>[11]</b>
                                         BAI Xiao, ZHANG Huigang, ZHOU Jun.VHR object detection based on structural feature extraction and query expansion[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (10) :6508-6520.DOI:10.1109/TGRS.2013.2296782.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" 岳伍军.基于光学遥感图像的飞机目标检测算法研究[D].成都:西南交通大学, 2014.YUE Wujun.Research on airplane and target detection algorithms in optical remote sensing imagery[D].Chengdu:Southwest Jiaotong University, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014252526.nh&amp;v=MjEwMTNaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXJyT1ZGMjZHckc5SE5UT3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         岳伍军.基于光学遥感图像的飞机目标检测算法研究[D].成都:西南交通大学, 2014.YUE Wujun.Research on airplane and target detection algorithms in optical remote sensing imagery[D].Chengdu:Southwest Jiaotong University, 2014.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" 吴喆, 曾接贤, 高琪琪.显著图和多特征结合的遥感图像飞机目标识别[J].中国图象图形学报, 2017, 22 (4) :532-541.WU Zhe, ZENG Jiexian, GAO Qiqi.Aircraft target recognition in remote sensing images based on saliency images and multi-feature combination[J].Journal of Image and Graphics, 2017, 22 (4) :532-541." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201704013&amp;v=MjkxNTlPUHlyZmJMRzRIOWJNcTQ5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2tVcnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         吴喆, 曾接贤, 高琪琪.显著图和多特征结合的遥感图像飞机目标识别[J].中国图象图形学报, 2017, 22 (4) :532-541.WU Zhe, ZENG Jiexian, GAO Qiqi.Aircraft target recognition in remote sensing images based on saliency images and multi-feature combination[J].Journal of Image and Graphics, 2017, 22 (4) :532-541.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" ZHANG Libao, ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017, 10 (4) :1511-1524.DOI:10.1109/JSTARS.2016.2620900." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images">
                                        <b>[14]</b>
                                         ZHANG Libao, ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017, 10 (4) :1511-1524.DOI:10.1109/JSTARS.2016.2620900.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     LONG Yang, GONG Yiping, XIAO Zhifeng, et al.Accurate object localization in remote sensing images based on convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing, 2017, 55 (5) :2486-2498.DOI:10.1109/TGRS.2016.2645610.</a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" 姚相坤, 万里红, 霍宏, 等.基于多结构卷积神经网络的高分遥感影像飞机目标检测[J].计算机工程, 2017, 43 (1) :259-267.YAO Xiangkun, WAN Lihong, HUO Hong, et al.Airplane object detection in high resolution remote sensing imagery based on multi-structure convolutional neural network[J].Computer Engineering, 2017, 43 (1) :259-267." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201701045&amp;v=MDE2NTJPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2tVcnJPTHo3QmJiRzRIOWJNcm85QllZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         姚相坤, 万里红, 霍宏, 等.基于多结构卷积神经网络的高分遥感影像飞机目标检测[J].计算机工程, 2017, 43 (1) :259-267.YAO Xiangkun, WAN Lihong, HUO Hong, et al.Airplane object detection in high resolution remote sensing imagery based on multi-structure convolutional neural network[J].Computer Engineering, 2017, 43 (1) :259-267.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" 刘欢.基于高分辨率光学遥感影像的特定目标检测算法研究[D].哈尔滨:哈尔滨工业大学, 2017.LIU Huan.Research on detection algorithm for specific objects in high-resolution optical remote sensing images[D].Harbin:Harbin Institute of Technology, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017738880.nh&amp;v=MTY1NjBWRjI2R2JTN0Z0bkVyNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         刘欢.基于高分辨率光学遥感影像的特定目标检测算法研究[D].哈尔滨:哈尔滨工业大学, 2017.LIU Huan.Research on detection algorithm for specific objects in high-resolution optical remote sensing images[D].Harbin:Harbin Institute of Technology, 2017.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" REN Shaoqing, HE Kaiming, GIRSHICK R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:91-99." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN:towards real-time object detection with region proposal networks">
                                        <b>[18]</b>
                                         REN Shaoqing, HE Kaiming, GIRSHICK R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:91-99.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:779-788." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">
                                        <b>[19]</b>
                                         REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:779-788.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" 洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018.HONG Tao.Specific object detection and recognition in optical remote sensing image[D].Chengdu:University of Electronic Science and Technology of China, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991422.nh&amp;v=MjgyOTE0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXJyT1ZGMjZGcnF4SDlYT3JaRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018.HONG Tao.Specific object detection and recognition in optical remote sensing image[D].Chengdu:University of Electronic Science and Technology of China, 2018.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" 辛鹏, 许悦雷, 唐红, 等.全卷积网络多层特征融合的飞机快速检测[J].光学学报, 2018, 38 (3) :0315003.XIN Peng, XU Yuelei, TANG Hong, et al.Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J].Acta Optica Sinica, 2018, 38 (3) :0315003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MTcxMjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXJyT0lqWFRiTEc0SDluTXJJOUdZb1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         辛鹏, 许悦雷, 唐红, 等.全卷积网络多层特征融合的飞机快速检测[J].光学学报, 2018, 38 (3) :0315003.XIN Peng, XU Yuelei, TANG Hong, et al.Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J].Acta Optica Sinica, 2018, 38 (3) :0315003.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" HAN Xiaobing, ZHONG Yanfei, ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing, 2017, 9 (7) :666.DOI:10.3390/rs9070666." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Efficient and Robust Integrated Geospatial Object Detection Framework for High Spatial Resolution Remote Sensing Imagery">
                                        <b>[22]</b>
                                         HAN Xiaobing, ZHONG Yanfei, ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing, 2017, 9 (7) :666.DOI:10.3390/rs9070666.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" RADOVIC M, ADARKWA O, WANG Qiaosong.Object recognition in aerial images using convolutional neural networks[J].Journal of Imaging, 2017, 3 (2) :21.DOI:10.3390/jimaging3020021." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Recognition in Aerial Images Using Convolutional Neural Networks">
                                        <b>[23]</b>
                                         RADOVIC M, ADARKWA O, WANG Qiaosong.Object recognition in aerial images using convolutional neural networks[J].Journal of Imaging, 2017, 3 (2) :21.DOI:10.3390/jimaging3020021.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].arXiv:1409.1556, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[24]</b>
                                         SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].arXiv:1409.1556, 2014.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" HE Kaiming, ZHANG Xiangyu, REN Shaoqing, et al.Deep residual learning for image recognition[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[25]</b>
                                         HE Kaiming, ZHANG Xiangyu, REN Shaoqing, et al.Deep residual learning for image recognition[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:770-778.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_26" title=" LIU Wei, ANGUELOV D, ERHAN D, et al.SSD:single shot multibox detector[C]//Proceedings of the 14th European Conference on Computer Vision.Amsterdam:Springer International Publishing, 2016:21-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SSD:Single shot multibox detector">
                                        <b>[26]</b>
                                         LIU Wei, ANGUELOV D, ERHAN D, et al.SSD:single shot multibox detector[C]//Proceedings of the 14th European Conference on Computer Vision.Amsterdam:Springer International Publishing, 2016:21-37.
                                    </a>
                                </li>
                                <li id="54">


                                    <a id="bibliography_27" title=" VIOLA P, JONES M.Rapid object detection using a boosted cascade of simple features[C]//Proceedings of 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Kauai, HI:IEEE, 2001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rapid object detection using a boosted cascade of simple features">
                                        <b>[27]</b>
                                         VIOLA P, JONES M.Rapid object detection using a boosted cascade of simple features[C]//Proceedings of 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Kauai, HI:IEEE, 2001.
                                    </a>
                                </li>
                                <li id="56">


                                    <a id="bibliography_28" title=" LI Haoxiang, LIN Zhe, SHEN Xiaohui, et al.A convolutional neural network cascade for face detection[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Boston, MA:IEEE, 2015:5325-5334." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network cascade for face detection">
                                        <b>[28]</b>
                                         LI Haoxiang, LIN Zhe, SHEN Xiaohui, et al.A convolutional neural network cascade for face detection[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Boston, MA:IEEE, 2015:5325-5334.
                                    </a>
                                </li>
                                <li id="58">


                                    <a id="bibliography_29" title=" ZHANG Kaipeng, ZHANG Zhanpeng, LI Zhifeng, et al.Joint face detection and alignment using multitask cascaded convolutional networks[J].IEEE Signal Processing Letters, 2016, 23 (10) :1499-1503.DOI:10.1109/LSP.2016.2603342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint face detection and alignment using multi-task cascaded convolutional networks">
                                        <b>[29]</b>
                                         ZHANG Kaipeng, ZHANG Zhanpeng, LI Zhifeng, et al.Joint face detection and alignment using multitask cascaded convolutional networks[J].IEEE Signal Processing Letters, 2016, 23 (10) :1499-1503.DOI:10.1109/LSP.2016.2603342.
                                    </a>
                                </li>
                                <li id="60">


                                    <a id="bibliography_30" title=" LIN Ming, CHEN Qiang, YAN Shuicheng.Network in network[J].arXiv:1312.4400, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network in network">
                                        <b>[30]</b>
                                         LIN Ming, CHEN Qiang, YAN Shuicheng.Network in network[J].arXiv:1312.4400, 2013.
                                    </a>
                                </li>
                                <li id="62">


                                    <a id="bibliography_31" title=" SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:761-769." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Training region-based object detectors with online hard example mining">
                                        <b>[31]</b>
                                         SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:761-769.
                                    </a>
                                </li>
                                <li id="64">


                                    <a id="bibliography_32" title=" ZHU Haigang, CHEN Xiaogang, DAI Weiqun, et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City, QC:IEEE, 2015:3735-3739.DOI:10.1109/ICIP.2015.7351502." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Orientation robust object detection in aerial images using deep convolutional neural network">
                                        <b>[32]</b>
                                         ZHU Haigang, CHEN Xiaogang, DAI Weiqun, et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City, QC:IEEE, 2015:3735-3739.DOI:10.1109/ICIP.2015.7351502.
                                    </a>
                                </li>
                                <li id="66">


                                    <a id="bibliography_33" >
                                        <b>[33]</b>
                                     XIA Guisong, BAI Xiang, DING Jian, et al.DOTA:a large-scale dataset for object detection in aerial images[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City, UT:IEEE, 2018:3974-3983.</a>
                                </li>
                                <li id="68">


                                    <a id="bibliography_34" >
                                        <b>[34]</b>
                                     REDMON J, FARHADI A.YOLO9000:better, faster, stronger[C]//Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition.Honolulu, HI:IEEE, 2017:6517-6525.</a>
                                </li>
                                <li id="70">


                                    <a id="bibliography_35" >
                                        <b>[35]</b>
                                     LIN T Y, GOYAL P, GIRSHICK R, et al.Focal loss for dense object detection[C]//Proceedings of 2017 IEEE International Conference on Computer Vision.Venice:IEEE, 2017:2999-3007.</a>
                                </li>
                                <li id="72">


                                    <a id="bibliography_36" title=" HOWARD A G, ZHU Menglong, CHEN Bo, et al.MobileNets:efficient convolutional neural networks for mobile vision applications[J].arXiv:1704.04861, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MobileNets:efficient convolutional neural networks for mobile vision applications">
                                        <b>[36]</b>
                                         HOWARD A G, ZHU Menglong, CHEN Bo, et al.MobileNets:efficient convolutional neural networks for mobile vision applications[J].arXiv:1704.04861, 2017.
                                    </a>
                                </li>
                                <li id="74">


                                    <a id="bibliography_37" title=" ZHANG Xiangyu, ZHOU Xinyu, LIN Mengxiao, et al.Shufflenet:an extremely efficient convolutional neural network for mobile devices[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City, UT:IEEE, 2018:6848-6856." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shuffle Net an extremely efficient convolutional neural network for mobile devices">
                                        <b>[37]</b>
                                         ZHANG Xiangyu, ZHOU Xinyu, LIN Mengxiao, et al.Shufflenet:an extremely efficient convolutional neural network for mobile devices[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City, UT:IEEE, 2018:6848-6856.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(08),1046-1058 DOI:10.11947/j.AGCS.2019.20180471            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>级联卷积神经网络的遥感影像飞机目标检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E4%B8%9C%E8%A1%8C&amp;code=40648239&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">余东行</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%B5%B7%E6%B6%9B&amp;code=20057225&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭海涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%BF%9D%E6%98%8E&amp;code=21141378&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张保明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E4%BC%A0&amp;code=34922942&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵传</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E4%BF%8A&amp;code=20149717&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢俊</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6&amp;code=0199248&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息工程大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统遥感影像飞机目标检测算法依赖于人工设计特征, 对大范围复杂场景和多尺度的飞机目标稳健性较差, 基于深层卷积神经网络的目标检测算法通常难以有效应对大幅影像的目标搜索和弱小目标检测问题, 针对上述问题, 本文提出了一种基于级联卷积神经网络的遥感影像飞机目标检测算法。首先根据全卷积神经网络能够支持输入任意大小图像的特点, 采用小尺度浅层全卷积神经网络对整幅影像进行遍历和搜索, 快速获取疑似飞机目标作为兴趣区域, 然后利用较深层的卷积神经网络对兴趣区域进行更精确的目标分类与定位。为提高卷积神经网络对地物目标的辨识能力, 在卷积层中引入多层感知器, 并在训练过程中采取多任务学习与离线难分样本挖掘的策略;在测试阶段, 建立影像金字塔进行多级搜索, 并结合非极大值抑制消除冗余窗口, 从而实现由粗到精的飞机目标检测与识别。对多个数据集下多种复杂场景的遥感影像进行测试, 结果表明, 本文方法具有较高的准确性和较强的稳健性, 可为大幅遥感影像的飞机目标检测问题提供一个快速高效的解决方案。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A3%9E%E6%9C%BA%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">飞机检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感影像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%A7%E8%81%94%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">级联卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%BE%E5%88%86%E6%A0%B7%E6%9C%AC%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">难分样本挖掘;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    余东行 (1993—) , 男, 硕士生, 研究方向为遥感影像目标识别, 深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (41601507);</span>
                    </p>
            </div>
                    <h1>Aircraft detection in remote sensing images using cascade convolutional neural networks</h1>
                    <h2>
                    <span>YU Donghang</span>
                    <span>GUO Haitao</span>
                    <span>ZHANG Baoming</span>
                    <span>ZHAO Chuan</span>
                    <span>LU Jun</span>
            </h2>
                    <h2>
                    <span>Information Engineering University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional aircraft detection algorithms which adopt handcraft features have poor performance in complex scene images and recognizing multi-scale objects. Methods using deep convolutional neural networks still face difficulty in dim small target search and recognition in large images with complex background. Aiming at these problems, a coarse-to-fine algorithm for aircraft detection in remote sensing images using cascade convolutional neural networks is proposed. To quickly and effectively acquire suspicious regions of interest (ROI) , the whole image is searched by a small and shallow fully convolutional neural network which could deal with images of any size. Then deeper convolutional neural networks are used to refine the classification and location of the ROIs. A multilayer perceptron is introduced to the convolutional layer to improve identification capability of the convolutional neural networks and the strategies of multi-task learning and offline hard example mining are adopted in the process of training. At the detecting stage, the image pyramid is constructed and the redundant windows could be eliminated by the non-maximal suppression. Multiple datasets are tested and the results show that the proposed method has higher accuracy and stronger robustness and provides a fast and efficient solution for object detection in large remote sensing images.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=aircraft%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">aircraft detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=cascade%20convolutional%20neural%20networks&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">cascade convolutional neural networks;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hard%20example%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hard example mining;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YU Donghang (1993—) , male, postgraduate, majors in remote sensing image interpretation, deep learning.E-mail: dong_hang@aliyun.com;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China (No.41601507);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="76">遥感影像重点目标的检测和识别是遥感影像智能解译的重要研究方向, 具有重要的应用价值<citation id="144" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在诸多地物目标中, 飞机作为一种重要的运输载体和武器装备, 其在遥感影像上的快速检测和识别具有重要的现实意义。由于遥感影像背景复杂, 大范围遥感影像的飞机目标自动化检测和识别还没有得到很好的解决。</p>
                </div>
                <div class="p1">
                    <p id="77">传统的飞机目标识别算法多是利用目标在影像上的不变矩特征<citation id="145" type="reference"><link href="4" rel="bibliography" /><link href="6" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、颜色和纹理特征<citation id="146" type="reference"><link href="8" rel="bibliography" /><link href="10" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、轮廓和结构特征<citation id="147" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><link href="18" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>、词袋特征<citation id="148" type="reference"><link href="20" rel="bibliography" /><link href="22" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>等, 这些特征稳健性较差, 并且特征的提取通常在较为准确的影像分割或轮廓提取的前提下进行, 极易受影像质量和人工建筑等地物的影响:当影像质量较差或飞机周围背景复杂时, 会直接导致影像欠分割或过分割, 从而难以提取有效的特征, 影响后续目标检测与识别的精度。此外, 这些方法通常采用滑动窗口<citation id="149" type="reference"><link href="8" rel="bibliography" /><link href="20" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">10</a>]</sup></citation>、图像分割<citation id="150" type="reference"><link href="4" rel="bibliography" /><link href="14" rel="bibliography" /><link href="18" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">7</a>,<a class="sup">9</a>]</sup></citation>或者视觉显著性检测<citation id="151" type="reference"><link href="24" rel="bibliography" /><link href="26" rel="bibliography" /><link href="28" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>来搜索目标, 滑动窗口法存在大量冗余窗口, 针对性差、耗时长, 而图像分割法和视觉显著性检测易受到其他地物干扰, 难以适用于大范围场景下的飞机目标搜索。</p>
                </div>
                <div class="p1">
                    <p id="78">近年来, 深度学习特别是卷积神经网络 (convolutional neural network, CNN) 在计算机视觉领域取得了巨大进展, 并广泛应用于人脸识别和自动驾驶等领域, 将卷积神经网络应用于遥感影像目标检测和识别任务中, 能够显著提高地物目标检测的实效性。目前基于卷积神经网络的遥感影像目标检测方法主要有两种思路, 一种是采取滑动窗口或显著性检测先对影像进行无监督搜索, 然后利用卷积神经网络对候选窗口提取特征并分类, 最终实现目标的识别<citation id="156" type="reference"><link href="30" rel="bibliography" /><link href="32" rel="bibliography" /><link href="34" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>。相比采用传统特征的方法, 这种方法可以提高目标检测和识别的精度, 但在候选目标选取过程中, 同样避免不了检测耗时和泛化性差的问题。另一种是对Faster RCNN (以下均简写为FRCNN) <citation id="152" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、YOLO<citation id="153" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>等自然场景下较为成熟的目标检测算法加以改进, 应用于遥感影像目标识别<citation id="157" type="reference"><link href="2" rel="bibliography" /><link href="40" rel="bibliography" /><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><link href="46" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>, 这种方法速度快, 精度也得到大幅提升, 但要实现大范围、多尺度和复杂背景下飞机目标的高精度检测仍有一定难度。直接将自然场景下的目标检测算法应用于遥感影像目标检测任务中, 必须考虑以下问题:①相对于自然场景影像, 遥感影像具有一定的特殊性<citation id="154" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 如影像质量受成像条件影响较大、背景复杂、空间范围广、分辨率低、目标小且分散、目标呈多方向性等特点;②高精度卷积神经网络普遍具有数十层甚至上百层<citation id="158" type="reference"><link href="48" rel="bibliography" /><link href="50" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>, 巨大的存储和计算开销依赖于高性能的硬件设备, 不仅难以有效处理大幅遥感影像, 还严重限制了在可移动设备 (如无人机等) 上的应用;③深层卷积神经网络模型含有大量参数, 训练需要大量的标注数据, 训练过程复杂且耗时, 在数据较少情况下难以达到理想的检测效果;④基于深度学习的目标检测算法针对常规自然场景影像而设计, 算法的泛化性依赖于训练数据集, 并且受限硬件设备的计算能力, 这些算法通常是针对固定大小的图像进行训练和检测<citation id="159" type="reference"><link href="40" rel="bibliography" /><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><link href="46" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>, 如FRCNN等算法只能处理大小约为1000像素的图像, YOLO算法需要将待检测图像统一缩放至448×448像素, SSD300<citation id="155" type="reference"><link href="52" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>需要将图像缩放至300×300像素, 当输入图像较大时, 必须更改网络结构或对大幅影像进行切分, 这显然不能满足遥感影像目标检测的通用性以及尺度自适应性。</p>
                </div>
                <div class="p1">
                    <p id="79">针对上述问题, 本文提出了一种基于多尺度级联卷积神经网络的遥感影像飞机目标检测方法, 利用小尺度浅层全卷积神经网络实现大幅影像的快速遍历和目标搜索, 利用较深层卷积神经网络对候选目标进行级联分类和精确定位。浅层全卷积神经网络能够支持任意大小的图像输入, 并且具有极强的速度优势, 多个卷积神经网络的级联判断机制可以弥补单个神经网络在精度上的缺点, 使得本文方法速度更快、精度更高, 并且更利于在可移动设备上的移植和应用。</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag">1 理论背景与方法</h3>
                <div class="p1">
                    <p id="81">遥感影像目标检测的难点在于, 大幅影像上目标搜索带来的巨大计算量和多尺度目标特别是小目标难以准确检测, 虽然FRCNN、SSD等算法针对多尺度目标检测问题采用了融合不同尺度的特征以及预设先验框等方式, 但这远远不能有效应对大范围多尺度的遥感影像。深层卷积神经网络在大幅影像上的计算量较大, 并且小目标经过多层卷积与池化, 难以提取到有效特征, 漏检率较高, 这种漏检在后处理很难得到弥补。采取级联分类思想在一定程度上可以提高大幅影像目标搜索的效率和目标检测的精度:先利用小型卷积神经网络在影像上进行初步目标检测, 快速获取所有可能的区域作为候选目标, 再将候选区域映射到高分辨率影像上, 利用更高精度的卷积神经网络进行目标类别和位置级联确定, 从而最大程度降低虚警率, 保留真正目标。级联分类的思想最早应用于人脸检测和识别<citation id="160" type="reference"><link href="54" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>。文献<citation id="161" type="reference">[<a class="sup">28</a>]</citation>设计了级联卷积神经网络用于人脸识别, 文献<citation id="162" type="reference">[<a class="sup">29</a>]</citation>设计多任务级联卷积神经网络模型 (multi-task cascaded convolutional neural networks, MTCNN) 用于人脸检测和关键点定位。MTCNN模型摒弃了常规依靠增加卷积神经网络深度来提高人脸检测精度的做法, 而采用多个小尺度卷积神经网络以级联的方式实现人脸检测, 模型具有稳健性强、轻量化、可实时等特点。此外, MTCNN采用浅层全卷积神经网络对影像进行目标搜索, 能够支持输入任意大小的图像, 这为大幅遥感影像的目标搜索和检测问题提供了一个快速高效的解决方案。由于遥感影像上的飞机目标具有多方向性且背景复杂多样等特点, 本文以MTCNN模型为基础, 通过对其网络结构进行优化, 并设计了相应的样本选取和模型训练方法, 可有效降低模型的虚警率, 提升检测效果。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">1.1 级联卷积神经网络</h4>
                <div class="p1">
                    <p id="83">MTCNN模型由3个不同尺度的小型卷积神经网络组成, 如图1所示, 分别为PNet、RNet和ONet。PNet为区域建议网络, 用来生成候选目标。PNet是一个浅层的全卷积网络, 包含3个卷积层和1个池化层, 输入图像大小为12×12像素。由于全卷积神经网络不含全连接层, 可以满足任意大小的图像输入, 因此可以实现大范围遥感影像的目标搜索。PNet本质上是一种利用GPU加速的滑动窗口法, 在选取候选窗口的同时对每个候选窗口进行分类判断。相对于传统滑动窗口法, 可以极大减少耗时。与PNet结构相似, RNet和ONet输入图像大小分别为24×24像素、48×48像素, 网络结构更深, 用于对PNet输出的候选目标进行级联判断, 能够实现更为精确的目标分类和定位。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 MTCNN模型结构" src="Detail/GetImg?filename=images/CHXB201908012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 MTCNN模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 The structure of MTCNN</p>

                </div>
                <div class="p1">
                    <p id="85">通过试验发现, 直接利用MTCNN模型检测飞机目标, 存在的大量误检目标。误检目标主要为长条形车辆、人工建筑物等, 笔者将这类与飞机目标在形状、纹理、颜色等方面具有极大相似性、易被误识别的地物称难分负样本 (hard negative example) 。检测过程中出现误检测的主要原因有:①地物种类复杂多样, 而训练样本不均衡, 负样本种类和数量远远大于正样本, 但大多数的负样本为易分样本, 如空地、草地等。大量易分样本的存在将会在训练过程中稀释反向传播的梯度, 导致模型无法有效排除建筑物、车辆等更复杂的人工地物。②小型化卷积神经网络结构在较少参数和不均衡训练数据的情况下必然导致难以有效区分难分负样本。③不同于自然场景下的人脸, 遥感影像为俯视图, 飞机呈多方向旋转, 其表观特征变化较大, 浅层网络难以准确识别。</p>
                </div>
                <div class="p1">
                    <p id="86">原始的MTCNN模型采用小型、浅层的常规卷积神经网络结构, 虽然计算速度较快, 但其网络结构简单, 卷积层所提取的特征信息表达能力不够。此外, RNet和ONet在卷积层之后用于分类的全连接层参数多, 模型易过拟合, 导致泛化能力降低。加深网络虽然可以在一定程度上提高其性能, 但其参数将大大增加, 同时其模型检测速度也将显著降低, 而对网络结构上的优化将有助于提升模型的整体性能。传统卷积操作是对数据的广义线性变换, 对数据特征的抽象化水平较低。文献<citation id="163" type="reference">[<a class="sup">30</a>]</citation>提出了一种更高效的卷积方式, 即在卷积神经网络结构中大量使用大小为1×1的卷积, 如图2所示, 不仅能够得到抽象性更高、泛化能力更强的特征, 还能起到数据降维的作用, 这种卷积方式已广泛应用于各种主流的卷积神经网络结构之中。此外, 采用全局池化替代传统CNN中的全连接层, 可以减少网络参数并降低过拟合的可能。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 改进的卷积层结构" src="Detail/GetImg?filename=images/CHXB201908012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 改进的卷积层结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Improved convolutional layer</p>

                </div>
                <div class="p1">
                    <p id="88">因此, 本文在原始MTCNN模型的部分卷积层之后加入非线性多层感知器, 并去除全连接层, 以提高模型的性能, 改进后的级联卷积神经网络模型如图3所示。由于PNet是用于兴趣区域的生成, 网络输入的图像较小 (12×12像素) , 即使增加网络的复杂度也难以提高精度, 反而会降低整个模型的速度和效率, 因此保留原始PNet结构, 而在对RNet和ONet的每个卷积层之后加入一个1×1卷积层, 并除去最后的全连接层。</p>
                </div>
                <div class="p1">
                    <p id="89">每个子网络同时包含目标分类和边界回归两个任务, 其多任务损失函数为</p>
                </div>
                <div class="p1">
                    <p id="90"><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>L</mtext><mtext>o</mtext><mtext>s</mtext><mtext>s</mtext><mo>=</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>a</mtext><mtext>s</mtext><mtext>s</mtext></mrow></msub><mrow><mo> (</mo><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>, </mo><mi>p</mi></mrow><mo>) </mo></mrow><mo>+</mo><mi>λ</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>x</mtext></mrow></msub><mrow><mo> (</mo><mrow><mover accent="true"><mi>t</mi><mo>^</mo></mover><mo>, </mo><mi>t</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="92">式中, <i>λ</i>取值5;<i>p</i><sub><i>i</i></sub>∈{0, 1}表示样本<i>i</i>的真实类别, <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>∈ (0, 1) 表示样本<i>i</i>的预测概率;<i>L</i><sub>class</sub> (<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>^</mo></mover></math></mathml>, <i>p</i>) 为用于二分类任务的交叉熵损失, 描述目标预测类别与实际类别的偏差;<i>L</i><sub>box</sub> (<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>t</mi><mo>^</mo></mover></math></mathml>, <i>t</i>) 为目标精确定位的边界回归损失函数, 采用欧氏距离来描述目标预测位置与真实位置之间的偏差, 即</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>a</mtext><mtext>s</mtext><mtext>s</mtext></mrow></msub><mrow><mo> (</mo><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>, </mo><mi>p</mi></mrow><mo>) </mo></mrow><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mi>log</mi></mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>x</mtext></mrow></msub><mrow><mo> (</mo><mrow><mover accent="true"><mi>t</mi><mo>^</mo></mover><mo>, </mo><mi>t</mi></mrow><mo>) </mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>t</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="99">式中, <i>t</i><sub><i>i</i></sub>= (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>, <i>w</i><sub><i>i</i></sub>, <i>h</i><sub><i>i</i></sub>) 用来描述目标在图像中的真实位置 (边界框的左上角点坐标、宽度和高度) ;<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>t</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>w</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>h</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>用来描述目标在图像中的预测位置。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">1.2 训练样本选取</h4>
                <div class="p1">
                    <p id="102">为了增加训练数据的数量和多样性, 将训练样本划分为4种类别:正样本、负样本、部分正样本及难分负样本。正样本和负样本用于优化模型的分类损失函数, 正样本和部分正样本用于优化模型的边界回归损失函数。正样本、负样本和部分正样本的划分根据交并比 (intersection-over-union, IOU) 的大小来确定。IOU是目标检测任务中用来衡量定位精度的概念, 采用所预测的候选框与真实标注框面积的交集与并集的比值, 计算公式为</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ι</mtext><mtext>Ο</mtext><mtext>U</mtext><mo>=</mo><mfrac><mrow><mtext>a</mtext><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mo stretchy="false"> (</mo><mi>g</mi><mi>t</mi><mstyle displaystyle="true"><mo>∩</mo><mi>d</mi></mstyle><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mtext>a</mtext><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mo stretchy="false"> (</mo><mi>g</mi><mi>t</mi><mstyle displaystyle="true"><mo>∪</mo><mi>d</mi></mstyle><mi>t</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="105">式中, <i>gt</i>、<i>dt</i>分别为目标真实的边界框和预测边界框。训练样本的选取采取滑动窗口法, 即对训练影像建立金字塔, 采用一定大小的滑动窗口选取影像上的区域, 如图4所示, 并计算选择的区域与标注边界框的IOU, IOU大于0.7的区域标记为正样本, 小于0.3的区域标记为负样本, 介于0.5和0.7之间的区域作为部分正样本。由于卷积神经网络提取的特征具有抽象性, 难分负样本的判断和选取难以采用人工选取的方式, 而由MTCNN模型检测结果中的误检目标组成, 见1.3节。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 改进的级联卷积神经网络结构" src="Detail/GetImg?filename=images/CHXB201908012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 改进的级联卷积神经网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Improve MTCNN</p>

                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 训练样本的选取" src="Detail/GetImg?filename=images/CHXB201908012_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 训练样本的选取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Samples for training</p>

                </div>
                <h4 class="anchor-tag" id="108" name="108">1.3 训练与检测</h4>
                <div class="p1">
                    <p id="109">为了尽可能利用有限的标注数据提高模型的泛化性能, 将训练过程分为预训练和离线难分样本训练两个步骤, 如图5所示。在预训练阶段, 采用在线难分样本挖掘<citation id="164" type="reference"><link href="62" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation> (online hard example mining, OHEM) 的策略, 即在训练过程中, 对每一个批量的数据计算得到的前向传播损失排序, 将损失最大的一定比例的样本作为难分样本;在反向传播的过程中, 只利用难分样本的损失对神经网络模型的权重进行更新。由于遥感影像背景范围广、种类多样, 选取的样本中真正的难分负样本数量较少, 因此在预训练阶段, 将在线难分样本的比例设置为40%。利用预训练好的MTCNN模型对不同尺度的训练影像进行检测, 此时模型能够有效区分简单背景与飞机目标, 将获得的检测结果结合标注信息, 除去真正的飞机目标, 即可获得大量的误检目标, 这些误检的目标即为难分负样本。OHEM策略的依据是训练样本包含了数量充足、种类丰富的负样本和正样本, 在卷积神经网络的反向传播过程中忽略部分易分样本的梯度。在没有人工干预的情况下, 选取的样本绝大多数为简单易分样本, 大量易分样本的存在导致模型在检测过程中不能有效区分难分负样本, 这是导致虚警和误检的主要原因, 将难分负样本加入到训练数据中可以降低检测的虚警率和误检率。因此, 在离线难分样本训练阶段, 针对不同尺度的网络模型, 对选取的正样本、负样本和部分正样本均分别缩放至12×12像素和24×24像素, 分别训练PNet和改进的RNet;将获得的难分负样本与正样本、部分正样本缩放至48×48像素重新训练改进的ONet。</p>
                </div>
                <div class="p1">
                    <p id="110">检测过程采取级联检测, 如图6所示, 对影像建立金字塔, 利用PNet对每一级影像检测来获取候选窗口。PNet本质上是一种GPU加速的滑动窗口法, PNet在每一级影像上滑动的同时, 并判断该窗口属于飞机目标的概率, 从而形成该级影像的概率图;以概率大于0.5的像素为中心, 选取大小为12×12像素的区域作为候选窗口。将每一级影像获取的候选窗口映射到原始影像上, 获得目标切片, 并利用RNet进行分类和边界回归;此后, 再将满足一定阈值的窗口再次利用ONet进行分类和边界回归, 从而得到最终的检测结果。候选窗口选取过程中将产生大量重叠窗口, 因此检测过程中采取非极大值抑制 (non-maximum suppression, NMS) 的策略减少窗口冗余。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 训练过程" src="Detail/GetImg?filename=images/CHXB201908012_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 训练过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Flowchart of training</p>

                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 检测流程" src="Detail/GetImg?filename=images/CHXB201908012_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 检测流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Flowchart of detection on test image</p>

                </div>
                <h3 id="113" name="113" class="anchor-tag">2 试验与分析</h3>
                <h4 class="anchor-tag" id="114" name="114">2.1 试验数据与环境</h4>
                <div class="p1">
                    <p id="115">本文采用4个不同数据集中的影像进行试验:UCAS-AOD<citation id="165" type="reference"><link href="64" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>、RSOD<citation id="166" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、DOTA<citation id="167" type="reference"><link href="66" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>和自建数据集, 分别记为数据集A-D, 不同数据集的基本信息和示例分别如表1和图7所示。UCAS-AOD和RSOD数据集的影像均为小范围机场区域切片, 其中UCAS-AOD数据集中影像重复率较大, 飞机目标尺寸较大, 背景及其他人工地物干扰较小;RSOD数据集影像具有一定倾角, 成像质量较差, 且存在大量的密集小目标;DOTA和自建数据集均选取能够覆盖整个机场的大范围遥感影像。利用数据集A中70%的影像训练, 共选取正样本30 000个, 部分正样本30 000个, 负样本90 000个;其余影像作为测试数据, 以检验模型对不同分辨率、大小、质量影像的泛化性和实用性。计算机配置i7-6900K, 3.2 GHz, 64 GB内存, NVIDIA GTX1080TI, 11 GB显存, 试验环境为Ubuntu16.04和 TensorFlow。</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表1 不同数据集的基本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 Brief information of datasets used</b></p>
                    <p class="img_note"></p>
                    <table id="116" border="1"><tr><td>数据集</td><td>数据来源</td><td>影像分辨率</td><td>影像大小/像素</td><td>影像数量</td><td>飞机数量</td><td>用途</td></tr><tr><td><br />A</td><td>UCAS-AOD</td><td>不详</td><td>1280×659-1372×940</td><td>1000</td><td>7482</td><td>70%训练, 30%测试</td></tr><tr><td><br />B</td><td>RSOD</td><td>0.5—2.0 m</td><td>1024×768-1044×915</td><td>446</td><td>5374</td><td>测试</td></tr><tr><td><br />C</td><td>DOTA</td><td>0.2—0.6 m</td><td>2000×2000-8000×8000</td><td>18</td><td>1605</td><td>测试</td></tr><tr><td><br />D</td><td>自建数据集</td><td>1.2—2.4 m</td><td>1500×1500-4000×4000</td><td>10</td><td>643</td><td>测试</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同数据集下的影像示例" src="Detail/GetImg?filename=images/CHXB201908012_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同数据集下的影像示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Samples of four datasets</p>

                </div>
                <div class="p1">
                    <p id="118">采用精确率 (precision) 和召回率 (recall) 作为评价指标, 计算公式为</p>
                </div>
                <div class="p1">
                    <p id="119"><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="121"><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="123">式中, <i>TP</i>为正确识别飞机目标数量;<i>FP</i>为影像中误检目标数量;<i>FN</i>为漏检目标数量。</p>
                </div>
                <h4 class="anchor-tag" id="124" name="124">2.2 结果与分析</h4>
                <div class="p1">
                    <p id="125">为验证本文所设计的级联卷积神经网络模型与训练方式的有效性, 利用相同的训练和测试数据, 对比了5种基于卷积神经网络的目标检测方法:SSD300、YOLOv2<citation id="168" type="reference"><link href="68" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>、FRCNN、RetinaNet<citation id="169" type="reference"><link href="70" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>和未作改进的MTCNN方法。SSD300采用VGG16<citation id="170" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>作为骨干网络, YOLOv2、FRCNN和RetinaNet采用ResNet50<citation id="171" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>作为骨干网络。MTCNN和本文方法均能检测任意大小的影像, 而FRCNN等算法不能直接检测很大的图像, 因此利用FRCNN等算法检测数据集C和D时, 分别采取512×512像素和1024×1024像素两种切分方式。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126">2.2.1 检测效果分析</h4>
                <div class="p1">
                    <p id="127">利用5种算法对4个数据中的影像进行检测, 并根据检测结果中的精确率和召回率绘制PR (precision-recall) 曲线, 如图8所示。综合4种数据集的检测结果来看, SSD300性能最差, 其原因主要有:①训练数据来自数据集A, 数据集A的影像大小为1280×659—1372×940像素, 训练SSD300时, 图像缩放过于剧烈, 严重影响模型训练和检测效果;②本文采取数据集A中的部分影像作为训练集, 去测试其余3个数据集, 不同数据集的影像在大小、分辨率差异较大, 导致检测结果下降;③SSD300采用的是VGG16模型作为骨干网络, VGG16本身模型泛化性较差。YOLOv2输入图像大小为448×448像素, 对分辨率较低的数据集A和数据集B同样难以有较大的精度提升;对于数据集C和数据集D中的影像, 切分为512×512像素大小时, 能够取得80%以上的检测精度, 当切分方式为1024×1024像素大小时, 检测精度剧烈下降。SSD300和YOLOv2检测精度均弱于FRCNN和RetinaNet, 这是其模型设计所决定的, 端对端的检测方式提高了检测速度, 但牺牲了精度, 特别是弱化了对小目标的检测能力。在不同数据集下, FRCNN和RetinaNet算法能够取得相对不错的检测效果, 且RetinaNet优于FRCNN。FRCNN和RetinaNet精度较高主要是由于采用区域建议的思想, 并且采取训练图像大小为1200×600像素, 当被检测影像和训练影像的分辨率相接近时 (数据集C和数据集D中1024×1024像素的切分方式) , 可以取得不错的检测结果, 当被检测影像的分辨率提高时 (数据集C和数据集D中512×512像素的切分方式) , 精度还能进一步提升。原始的MTCNN方法在不做任何改进的情况下, 在4种数据集中均能够取得高于FRCNN的精度, 表明级联卷积神经网络得益于能够对整幅影像进行多尺度遍历和搜索, 具有天然的精度优势。本文方法进一步提升了MTCNN方法的精度, 特别是提高了对数据集B中质量较差的影像和密集小目标的检测精度, 除在数据集A中精度稍弱于RetinaNet, 在其余数据集上明显优于RetinaNet。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同方法在4种数据集下的PR曲线" src="Detail/GetImg?filename=images/CHXB201908012_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同方法在4种数据集下的PR曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Precision-Recall of different methods on four datasets</p>
                                <p class="img_note">注:map表示平均精度。</p>

                </div>
                <div class="p1">
                    <p id="129">为对比本文方法的改进效果, 选取了4幅包含大量飞机目标的测试影像, 测试影像中的目标具有小而密集分布、目标与背景的区分度较差等特点, 检测效果如图9所示, 其中绿色、红色、黄色方框分别代表正确检测、漏检和误检的飞机。原始的MTCNN存在较多的虚警和误检, 过多的误检目标造成视觉上的干扰, 几乎无法用于实际应用, 而本文方法采用了更高效的卷积神经网络结构和训练方式, 提高了模型对目标的特征表达和识别能力, 在不同背景和影像质量下均能取得较好的检测效果。但同时也发现, 不管采取哪种方法, 对于小于16×16像素的目标, 仍然还难以有效检测, 这是所有方法在数据集B上精度较低的主要原因。图10为大幅遥感影像的检测结果, 可以看出, 飞机目标相对整个影像较小, 同一幅影像上的目标具有尺度、方向上的多样性, 地物类型更加多样和复杂, 本文方法在大幅影像上具有优异的检测性能, 对目标的尺度变化、旋转等情况下具有较强的稳健性。</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130">2.2.2 模型轻量化分析</h4>
                <div class="p1">
                    <p id="131">目前, 高精度的目标检测和识别算法通常依赖于深层卷积神经网络, 当网络加深时, 模型参数和计算量将显著增加, 对硬件设备的依赖程度也随之增加。虽然对卷积神经网络模型小型化和轻量化的探索已有巨大的进展, 如MobileNet<citation id="172" type="reference"><link href="72" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>、ShuffleNet<citation id="173" type="reference"><link href="74" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>等, 但轻量化模型通常难以达到深层卷积神经网络模型的精度。由不同卷积神经网络目标检测算法的模型参数大小 (如表2所示) 可以看出, 深层卷积神经网络模型动辄数百兆 (MB) , 级联小型卷积神经网络有着天然的轻量化优势, 这意味着更加快速高效地处理影像以及在可移动平台上的应用。由于卷积神经网络的层数极大地影响其运行速度, 在不增加网络层数的情况下, 单纯靠增加卷积层参数数量的方式不仅难以实现精度上的显著提升, 还大大增加了模型整体的参数量。本文方法对RNet和ONet采取了更高效的卷积结构和训练方式, 大大提升模型的性能, 在能够提高模型精度的同时, 也减小了模型的参数, 从而在一定程度上大大降低了对硬件设备的依赖程度。</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 数据集A和B下的检测结果" src="Detail/GetImg?filename=images/CHXB201908012_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 数据集A和B下的检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Aircraft detection results on dataset A and B</p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 本文方法在大幅影像上的飞机目标检测结果" src="Detail/GetImg?filename=images/CHXB201908012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 本文方法在大幅影像上的飞机目标检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Aircraft detection results on large images</p>

                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表2 模型大小对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 Model size of different methods</b> MB</p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td><br />模型</td><td>模型大小</td></tr><tr><td><br />FRCNN (ResNet50) </td><td>208</td></tr><tr><td><br />SSD300 (VGG16) </td><td>267</td></tr><tr><td><br />RetinaNet (ResNet50) </td><td>257</td></tr><tr><td><br />YOLOv2 (ResNet50) </td><td>379</td></tr><tr><td><br />MTCNN</td><td><u>3.9</u></td></tr><tr><td><br />本文方法</td><td><b>2.7</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:模型大小为模型参数所保存的字节数, 加粗数字表示本列最优值, 加横线数字表示本列次优值。</p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">为比较不同方法检测单张影像的用时, 采取了1280×900像素和10 000×4000像素两种大小的影像进行测试, 不同方法用时统计如表3所示。RetinaNet和YOLOv2分别是目前公认的高精度和快速的目标检测方法, 在相同硬件设备的情况下, 检测速度依然慢于采用级联卷积神经网络的方法。为了能够检测到未知分辨率影像上不同大小的目标, 本文方法在检测过程中, 采取建立影像金字塔, 对不同尺度上的影像进行检测, 这实际上是一种耗时的检测方式, 但依然可以在1280×900像素大小的影像上实现接近实时的检测速度。对于大场景影像 (10 000×4000像素) 的目标检测来说, 本文方法的速度优势更加明显:MTCNN每一子模型存在较多的误判, 且子模型的复杂度依次增加, 检测同一切片的用时也是依次递增, 这大大增加了目标在级联判断的数量和用时;本文方法模型性能更加高效, 虚警目标更少, 大大节省了目标识别的用时, 将单张大幅影像的检测时间降低了27.05% (从2.625 s降低至1.915 s) 。此外, 如若在获知影像分辨率的情况下, 有针对性地减少影像金字塔的冗余层级, 检测速度将进一步提升。</p>
                </div>
                <div class="area_img" id="136">
                    <p class="img_tit"><b>表3 检测时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.3 Time used on per image</b></p>
                    <p class="img_note">s</p>
                    <table id="136" border="1"><tr><td rowspan="2"><br />模型</td><td colspan="2"><br />用时</td></tr><tr><td><br />1280×900</td><td>10000×4000</td></tr><tr><td><br />FRCNN (ResNet50) </td><td>1.873</td><td>N/A</td></tr><tr><td><br />RetinaNet (ResNet50) </td><td>0.131</td><td>N/A</td></tr><tr><td><br />YOLOv2 (ResNet50) </td><td>0.062</td><td>N/A</td></tr><tr><td><br />MTCNN</td><td><b>0.041</b></td><td>2.625</td></tr><tr><td><br />本文方法</td><td><u>0.045</u></td><td><b>1.915</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note">注:N/A表示不能直接检测大幅影像, 加粗数字表示本列最优值, 加横线数字表示本列次优值。</p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">2.2.3 模型迁移检测结果</h4>
                <div class="p1">
                    <p id="138">为了测试本文方法对不同类型飞机目标检测的效果, 选取戴蒙斯空军基地两个区域的影像进行测试, 测试区域共包含1389架密集分布、形状完整的军用飞机 (战斗机、轰炸机、运输机等) 。由图11可知, 军用飞机形状各异, 人工设计的特征往往不具有较强稳健性。本文训练数据 (UCAS-AOD) 均为民用客机影像, 而军用飞机与客机在形状上具有一定的相似性, 卷积神经网络模型具有优异的特征提取能力, 因此将客机样本训练好的模型, 直接用于军用飞机的检测。部分检测结果如图12所示, 其中绿色、红色、黄色方框分别代表正确检测、漏检和误检的飞机。本文方法正确检测1309个, 误检14个, 漏检80个, 精确率为98.94%, 召回率为94.24%, 而其中漏检的目标大多数因为目标排列过于密集, 在非极大值抑制过程中两个飞机目标被认为是同一个目标。对军用飞机的检测结果验证了本文方法具有较强的泛化性和实用性, 不仅可以用于民用飞机目标检测, 还可以在军用飞机类型识别任务中, 用于候选目标的选取。</p>
                </div>
                <h3 id="139" name="139" class="anchor-tag">3 结 论</h3>
                <div class="p1">
                    <p id="140">针对大范围区域、复杂背景下遥感影像飞机目标检测的准确性和实时性较低的问题, 本文根据常规卷积神经网络目标检测算法的局限性和遥感影像目标检测任务的特殊性, 提出了一种基于级联卷积神经网络的飞机目标检测方法, 显著提高了模型对复杂地物的辨识能力。通过在不同的数据集上对比分析了目前部分主流目标检测算法, 可以得出以下结论:①深层卷积神经网络的目标检测能力依赖于测试影像与训练影像的一致性程度, 测试数据与训练数据在影像质量、大小及分辨率等方面差异较大时, 模型泛化性将显著降低;②深层卷积神经网络目标检测算法对遥感影像上密集小目标检测精度较低, 处理大幅影像也必须进行切分, 这种切分必然破坏目标与影像的相对大小关系, 也将影响检测的精度, 同时增加了后处理的复杂度;③本文采用的多尺度级联卷积神经网络不仅具有更高的精度, 而且可以支持大幅影像的目标检测, 检测过程中采用金字塔多级检测的方式, 在一定程度上解决了大幅遥感影像、多尺度飞机目标检测的问题。需要说明的是, 深层卷积神经网络是致力于解决多类目标 (数十类甚至数百类) 的检测问题, 尽管仅从单类目标的检测精度、参数量多少和运行速度来对比深层卷积神经网络与级联浅层卷积神经网络模型有失偏颇, 但仍能从一个侧面反映出针对特定任务或领域的目标识别问题, 级联浅层卷积神经网络模型更简单、参数更少、速度更快, 在移动平台的可移植性更强, 具有不可忽视的优势。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 不同种类的飞机示例" src="Detail/GetImg?filename=images/CHXB201908012_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 不同种类的飞机示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Different types of aircraft</p>

                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908012_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 军用飞机检测结果" src="Detail/GetImg?filename=images/CHXB201908012_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 军用飞机检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908012_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.12 Military aircraft detection results</p>

                </div>
                <div class="p1">
                    <p id="143">目前, 卷积神经网络模型在自动驾驶和人脸识别等领域应用虽然已经较为成熟, 但由于深层卷积神经的自身局限性和遥感影像的特殊性, 探索能够兼顾速度与精度、适用于遥感影像多类地物目标, 特别是密集小目标的检测方法仍然任重而道远。在后续工作中, 将研究更为高效的卷积神经网络结构和目标检测的新方法, 提高检测器对地物目标的泛化能力, 以期实现大幅遥感影像上更多类别目标的自动化检测和识别。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201809008&amp;v=MDQ1NThyT0ppWFRiTEc0SDluTXBvOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 邓志鹏, 孙浩, 雷琳, 等.基于多尺度形变特征卷积网络的高分辨率遥感影像目标检测[J].测绘学报, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595.DENG Zhipeng, SUN Hao, LEI Lin, et al.Object detection in remote sensing imagery with multi-scale deformable convolutional networks[J].Acta Geodaetica et Cartographica Sinica, 2018, 47 (9) :1216-1227.DOI:10.11947/j.AGCS.2018.20170595.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201404014&amp;v=MjA0MjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck9QeXJmYkxHNEg5WE1xNDlFWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 曾接贤, 付俊, 符祥.特征点和不变矩结合的遥感图像飞机目标识别[J].中国图象图形学报, 2014, 19 (4) :592-602.ZENG Jiexian, FU Jun, FU Xiang.Aircraft target recognition in remote sensing images based on distribution of the feature points and invariant moments[J].Journal of Image and Graphics, 2014, 19 (4) :592-602.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aircraft type recognition in satellite images">

                                <b>[3]</b> HSIEH J W, CHEN J M, CHUANG C H, et al.Aircraft type recognition in satellite images[J].IEE Proceedings-Vision, Image and Signal Processing, 2005, 152 (3) :307-315.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An effective method based on acf for aircraft detection in remote sensing images">

                                <b>[4]</b> ZHAO An, FU Kun, SUN Hao, et al.An effective method based on ACF for aircraft detection in remote sensing images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :744-748.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rotation-invariant object detection of remotely sensed images based on texton forest and hough voting">

                                <b>[5]</b> LEI Zhen, FANG Tao, HUO Hong, et al.Rotation-invariant object detection of remotely sensed images based on texton forest and Hough voting[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (4) :1206-1217.DOI:10.1109/TGRS.2011.2166966.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201007012&amp;v=MTA1MDVyRzRIOUhNcUk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2tVcnJPTFNqSmQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 王树国, 黄勇杰, 张生.可见光图像中飞机目标的特征选择及提取[J].哈尔滨工业大学学报, 2010, 42 (7) :1056-1059.WANG Shuguo, HUANG Yongjie, ZHANG Sheng.Selection and extraction of features of aircraft in optical image[J].Journal of Harbin Institute of Technology, 2010, 42 (7) :1056-1059.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018189095.nh&amp;v=MjcxNzdyck9WRjI2RnJLd0Y5SEZxcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 王文胜.宽幅光学遥感图像舰船飞机目标检测识别技术研究[D].长春:中国科学院大学 (中国科学院长春光学精密机械与物理研究所) , 2018.WANG Wensheng.Research on technology of ship and aircraft targets recognition from large-field optical remote sensing image[D].Changchun:Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, 2018.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Novel Method of Aircraft Detection Based on HighResolution Panchromatic Optical Remote Sensing Images">

                                <b>[8]</b> WANG Wensheng, NIE Ting, FU Tianjiao, et al.A novel method of aircraft detection based on high-resolution panchromatic optical remote sensing images[J].Sensors, 2017, 17 (5) :1047.DOI:10.3390/s17051047.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Target Detection in High-Resolution Remote Sensing Images Using a Contour-Based Spatial Model">

                                <b>[9]</b> LI Yu, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using a contour-based spatial model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (5) :886-890.DOI:10.1109/LGRS.2012.2183337.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic target detection in high-resolution remote sensing images using spatial sparse coding bag-of-words model">

                                <b>[10]</b> SUN Hao, SUN Xian, WANG Hongqi, et al.Automatic target detection in high-resolution remote sensing images using spatial sparse coding bag-of-words model[J].IEEE Geoscience and Remote Sensing Letters, 2012, 9 (1) :109-113.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VHR object detection based on structural feature extraction and query expansion">

                                <b>[11]</b> BAI Xiao, ZHANG Huigang, ZHOU Jun.VHR object detection based on structural feature extraction and query expansion[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (10) :6508-6520.DOI:10.1109/TGRS.2013.2296782.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014252526.nh&amp;v=Mjc4NTViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck9WRjI2R3JHOUhOVE9xWkU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 岳伍军.基于光学遥感图像的飞机目标检测算法研究[D].成都:西南交通大学, 2014.YUE Wujun.Research on airplane and target detection algorithms in optical remote sensing imagery[D].Chengdu:Southwest Jiaotong University, 2014.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201704013&amp;v=MTk2NDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck9QeXJmYkxHNEg5Yk1xNDlFWjRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 吴喆, 曾接贤, 高琪琪.显著图和多特征结合的遥感图像飞机目标识别[J].中国图象图形学报, 2017, 22 (4) :532-541.WU Zhe, ZENG Jiexian, GAO Qiqi.Aircraft target recognition in remote sensing images based on saliency images and multi-feature combination[J].Journal of Image and Graphics, 2017, 22 (4) :532-541.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images">

                                <b>[14]</b> ZHANG Libao, ZHANG Yingying.Airport detection and aircraft recognition based on two-layer saliency model in high spatial resolution remote-sensing images[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017, 10 (4) :1511-1524.DOI:10.1109/JSTARS.2016.2620900.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 LONG Yang, GONG Yiping, XIAO Zhifeng, et al.Accurate object localization in remote sensing images based on convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing, 2017, 55 (5) :2486-2498.DOI:10.1109/TGRS.2016.2645610.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201701045&amp;v=MDE5Mjk5Yk1ybzlCWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2Rnkza1Vyck9MejdCYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 姚相坤, 万里红, 霍宏, 等.基于多结构卷积神经网络的高分遥感影像飞机目标检测[J].计算机工程, 2017, 43 (1) :259-267.YAO Xiangkun, WAN Lihong, HUO Hong, et al.Airplane object detection in high resolution remote sensing imagery based on multi-structure convolutional neural network[J].Computer Engineering, 2017, 43 (1) :259-267.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017738880.nh&amp;v=MjA2OTZVcnJPVkYyNkdiUzdGdG5FcjVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5M2s=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 刘欢.基于高分辨率光学遥感影像的特定目标检测算法研究[D].哈尔滨:哈尔滨工业大学, 2017.LIU Huan.Research on detection algorithm for specific objects in high-resolution optical remote sensing images[D].Harbin:Harbin Institute of Technology, 2017.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN:towards real-time object detection with region proposal networks">

                                <b>[18]</b> REN Shaoqing, HE Kaiming, GIRSHICK R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]//Proceedings of the 28th International Conference on Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:91-99.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">

                                <b>[19]</b> REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:779-788.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991422.nh&amp;v=MTExMzE0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeTNrVXJyT1ZGMjZGcnF4SDlYT3JaRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018.HONG Tao.Specific object detection and recognition in optical remote sensing image[D].Chengdu:University of Electronic Science and Technology of China, 2018.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MTk2NjRSN3FmWnVkdkZ5M2tVcnJPSWpYVGJMRzRIOW5Nckk5R1lvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 辛鹏, 许悦雷, 唐红, 等.全卷积网络多层特征融合的飞机快速检测[J].光学学报, 2018, 38 (3) :0315003.XIN Peng, XU Yuelei, TANG Hong, et al.Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J].Acta Optica Sinica, 2018, 38 (3) :0315003.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Efficient and Robust Integrated Geospatial Object Detection Framework for High Spatial Resolution Remote Sensing Imagery">

                                <b>[22]</b> HAN Xiaobing, ZHONG Yanfei, ZHANG Liangpei.An efficient and robust integrated geospatial object detection framework for high spatial resolution remote sensing imagery[J].Remote Sensing, 2017, 9 (7) :666.DOI:10.3390/rs9070666.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Recognition in Aerial Images Using Convolutional Neural Networks">

                                <b>[23]</b> RADOVIC M, ADARKWA O, WANG Qiaosong.Object recognition in aerial images using convolutional neural networks[J].Journal of Imaging, 2017, 3 (2) :21.DOI:10.3390/jimaging3020021.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[24]</b> SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].arXiv:1409.1556, 2014.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[25]</b> HE Kaiming, ZHANG Xiangyu, REN Shaoqing, et al.Deep residual learning for image recognition[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:770-778.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SSD:Single shot multibox detector">

                                <b>[26]</b> LIU Wei, ANGUELOV D, ERHAN D, et al.SSD:single shot multibox detector[C]//Proceedings of the 14th European Conference on Computer Vision.Amsterdam:Springer International Publishing, 2016:21-37.
                            </a>
                        </p>
                        <p id="54">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rapid object detection using a boosted cascade of simple features">

                                <b>[27]</b> VIOLA P, JONES M.Rapid object detection using a boosted cascade of simple features[C]//Proceedings of 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Kauai, HI:IEEE, 2001.
                            </a>
                        </p>
                        <p id="56">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network cascade for face detection">

                                <b>[28]</b> LI Haoxiang, LIN Zhe, SHEN Xiaohui, et al.A convolutional neural network cascade for face detection[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Boston, MA:IEEE, 2015:5325-5334.
                            </a>
                        </p>
                        <p id="58">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint face detection and alignment using multi-task cascaded convolutional networks">

                                <b>[29]</b> ZHANG Kaipeng, ZHANG Zhanpeng, LI Zhifeng, et al.Joint face detection and alignment using multitask cascaded convolutional networks[J].IEEE Signal Processing Letters, 2016, 23 (10) :1499-1503.DOI:10.1109/LSP.2016.2603342.
                            </a>
                        </p>
                        <p id="60">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network in network">

                                <b>[30]</b> LIN Ming, CHEN Qiang, YAN Shuicheng.Network in network[J].arXiv:1312.4400, 2013.
                            </a>
                        </p>
                        <p id="62">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Training region-based object detectors with online hard example mining">

                                <b>[31]</b> SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Las Vegas, NV:IEEE, 2016:761-769.
                            </a>
                        </p>
                        <p id="64">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Orientation robust object detection in aerial images using deep convolutional neural network">

                                <b>[32]</b> ZHU Haigang, CHEN Xiaogang, DAI Weiqun, et al.Orientation robust object detection in aerial images using deep convolutional neural network[C]//Proceedings of 2015 IEEE International Conference on Image Processing.Quebec City, QC:IEEE, 2015:3735-3739.DOI:10.1109/ICIP.2015.7351502.
                            </a>
                        </p>
                        <p id="66">
                            <a id="bibliography_33" >
                                    <b>[33]</b>
                                 XIA Guisong, BAI Xiang, DING Jian, et al.DOTA:a large-scale dataset for object detection in aerial images[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City, UT:IEEE, 2018:3974-3983.
                            </a>
                        </p>
                        <p id="68">
                            <a id="bibliography_34" >
                                    <b>[34]</b>
                                 REDMON J, FARHADI A.YOLO9000:better, faster, stronger[C]//Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition.Honolulu, HI:IEEE, 2017:6517-6525.
                            </a>
                        </p>
                        <p id="70">
                            <a id="bibliography_35" >
                                    <b>[35]</b>
                                 LIN T Y, GOYAL P, GIRSHICK R, et al.Focal loss for dense object detection[C]//Proceedings of 2017 IEEE International Conference on Computer Vision.Venice:IEEE, 2017:2999-3007.
                            </a>
                        </p>
                        <p id="72">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MobileNets:efficient convolutional neural networks for mobile vision applications">

                                <b>[36]</b> HOWARD A G, ZHU Menglong, CHEN Bo, et al.MobileNets:efficient convolutional neural networks for mobile vision applications[J].arXiv:1704.04861, 2017.
                            </a>
                        </p>
                        <p id="74">
                            <a id="bibliography_37" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shuffle Net an extremely efficient convolutional neural network for mobile devices">

                                <b>[37]</b> ZHANG Xiangyu, ZHOU Xinyu, LIN Mengxiao, et al.Shufflenet:an extremely efficient convolutional neural network for mobile devices[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.Salt Lake City, UT:IEEE, 2018:6848-6856.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201908012" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908012&amp;v=MTg3MDNVUjdxZlp1ZHZGeTNrVXJyUEppWFRiTEc0SDlqTXA0OUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
