<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142606869482500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201910010%26RESULT%3d1%26SIGN%3dzM%252b6vvM9RQzvSUcxdbajz5ZC0mg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201910010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910010&amp;v=MjQ0MDBGckNVUjdxZlp1ZHZGeXJnVnJyUEppWFRiTEc0SDlqTnI0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="1 本文方法概述 ">1 本文方法概述</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="1.1 目标感兴趣区域尺度范围">1.1 目标感兴趣区域尺度范围</a></li>
                                                <li><a href="#66" data-title="1.2 目标检测与识别卷积神经网络架构">1.2 目标检测与识别卷积神经网络架构</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="2 试验结果与分析 ">2 试验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#91" data-title="2.1 训练损失值(loss)对比">2.1 训练损失值(loss)对比</a></li>
                                                <li><a href="#95" data-title="2.2 目标检测与识别定量评价">2.2 目标检测与识别定量评价</a></li>
                                                <li><a href="#103" data-title="2.3 目标检测与识别目视判别">2.3 目标检测与识别目视判别</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#117" data-title="3 结 论 ">3 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="&lt;b&gt;表1 WHU-RSone数据集目标类别与数目&lt;/b&gt;"><b>表1 WHU-RSone数据集目标类别与数目</b></a></li>
                                                <li><a href="#61" data-title="图1 WHU-RSone目标样例数据">图1 WHU-RSone目标样例数据</a></li>
                                                <li><a href="#62" data-title="图2 目标感兴趣区域提取网络">图2 目标感兴趣区域提取网络</a></li>
                                                <li><a href="#64" data-title="图3 目标感兴趣区域覆盖范围">图3 目标感兴趣区域覆盖范围</a></li>
                                                <li><a href="#65" data-title="图4 目标尺度分布范围">图4 目标尺度分布范围</a></li>
                                                <li><a href="#68" data-title="图5 本文卷积神经网路架构">图5 本文卷积神经网路架构</a></li>
                                                <li><a href="#93" data-title="图6 Faster-RCNN架构与本文架构训练loss对比图">图6 Faster-RCNN架构与本文架构训练loss对比图</a></li>
                                                <li><a href="#99" data-title="图7 P-R曲线">图7 P-R曲线</a></li>
                                                <li><a href="#101" data-title="图8 Faster-RCNN架构与本文架构测试mAP对比图">图8 Faster-RCNN架构与本文架构测试mAP对比图</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表2 目标检测与识别定量评价结果&lt;/b&gt;"><b>表2 目标检测与识别定量评价结果</b></a></li>
                                                <li><a href="#110" data-title="图9 测试样例检测与识别结果">图9 测试样例检测与识别结果</a></li>
                                                <li><a href="#110" data-title="图9 测试样例检测与识别结果">图9 测试样例检测与识别结果</a></li>
                                                <li><a href="#115" data-title="图10 高分二号影像目标检测与识别试验结果">图10 高分二号影像目标检测与识别试验结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 李德仁,王密,沈欣,等.从对地观测卫星到对地观测脑[J].武汉大学学报(信息科学版),2017,42(2):143-149.LI Deren,WANG Mi,SHEN Xin,et al.From earth observation satellite to earth observation brain[J].Geomatics and Information Science of Wuhan University,2017,42(2):143-149." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201702001&amp;v=Mjg5MzJyWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBNaVhJWnJHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李德仁,王密,沈欣,等.从对地观测卫星到对地观测脑[J].武汉大学学报(信息科学版),2017,42(2):143-149.LI Deren,WANG Mi,SHEN Xin,et al.From earth observation satellite to earth observation brain[J].Geomatics and Information Science of Wuhan University,2017,42(2):143-149.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" 董志鹏,王密,李德仁.一种融合超像素与最小生成树的高分辨率遥感影像分割方法[J].测绘学报,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514.DONG Zhipeng,WANG Mi,LI Deren.A high resolution remote sensing image segmentation method by combining superpixels with minimum spanning tree[J].Acta Geodaetica et Cartographica Sinica,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201706010&amp;v=MjM2NTFNcVk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWcnJQSmlYVGJMRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         董志鹏,王密,李德仁.一种融合超像素与最小生成树的高分辨率遥感影像分割方法[J].测绘学报,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514.DONG Zhipeng,WANG Mi,LI Deren.A high resolution remote sensing image segmentation method by combining superpixels with minimum spanning tree[J].Acta Geodaetica et Cartographica Sinica,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" 刘婧,李培军.结合结构和光谱特征的高分辨率影像分割方法[J].测绘学报,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087.LIU Jing,LI Peijun.A high resolution image segmentation method by combined structural and spectral characteristics[J].Acta Geodaetica et Cartographica Sinica,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201405006&amp;v=MTE3NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg5WE1xbzlGWW8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘婧,李培军.结合结构和光谱特征的高分辨率影像分割方法[J].测绘学报,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087.LIU Jing,LI Peijun.A high resolution image segmentation method by combined structural and spectral characteristics[J].Acta Geodaetica et Cartographica Sinica,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" 高常鑫,桑农.基于深度学习的高分辨率遥感影像目标检测[J].测绘通报,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625.GAO Changxin,SANG Nong.Deep learning for object detection in remote sensing image[J].Bulletin of Surveying and Mapping,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB2014S1025&amp;v=MjQxNTlHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhmYkxHNEg5V3ZybzlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         高常鑫,桑农.基于深度学习的高分辨率遥感影像目标检测[J].测绘通报,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625.GAO Changxin,SANG Nong.Deep learning for object detection in remote sensing image[J].Bulletin of Surveying and Mapping,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" CHENG Gong,HAN Junwei,GUO Lei,et al.Object detection in remote sensing imagery using a discriminatively trained mixture model[J].ISPRS Journal of Photogrammetry and Remote Sensing,2013,85(11):32-43." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600364403&amp;v=MzE4MjM9TmlmT2ZiSzhIdERNcVk5RlorMExDSHc2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVNzdJSWxzUmJ4VQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         CHENG Gong,HAN Junwei,GUO Lei,et al.Object detection in remote sensing imagery using a discriminatively trained mixture model[J].ISPRS Journal of Photogrammetry and Remote Sensing,2013,85(11):32-43.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 张剑清,佘琼,潘励.基于LBP/C纹理的遥感影像居民地变化检测[J].武汉大学学报(信息科学版),2008,33(1):7-11.ZHANG Jianqing,SHE Qiong,PAN Li.Change detection of residential area by remote sensing image based on LBP/C texture[J].Geomatics and Information Science of Wuhan University,2008,33(1):7-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH200801002&amp;v=MzEwNjJDVVI3cWZadWR2RnlyZ1ZyclBNaVhJWnJHNEh0bk1ybzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         张剑清,佘琼,潘励.基于LBP/C纹理的遥感影像居民地变化检测[J].武汉大学学报(信息科学版),2008,33(1):7-11.ZHANG Jianqing,SHE Qiong,PAN Li.Change detection of residential area by remote sensing image based on LBP/C texture[J].Geomatics and Information Science of Wuhan University,2008,33(1):7-11.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" MORANDUZZO T,MELGANI F,DAAMOUCHE A.An object detection technique for very high resolution remote sensing images[C]//Proceedings of the 8th IEEE International Workshop on Systems,Signal Processing and Their Applications.Algiers,Algeria:IEEE,2013:79-83." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An object detection technique for very high resolution remote sensing images">
                                        <b>[7]</b>
                                         MORANDUZZO T,MELGANI F,DAAMOUCHE A.An object detection technique for very high resolution remote sensing images[C]//Proceedings of the 8th IEEE International Workshop on Systems,Signal Processing and Their Applications.Algiers,Algeria:IEEE,2013:79-83.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" BRENNING A,LONG Shilei,FIEGUTH P.Detecting rock glacier flow structures using Gabor filters and IKONOS imagery[J].Remote Sensing of Environment,2012,125(10):227-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600661948&amp;v=MDQ1ODlIL2lyUmRHZXJxUVRNbndaZVp0RmlubFU3N0lJbHNSYnhVPU5pZk9mYks3SHRETnFZOUZZdTBPQlhneG9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         BRENNING A,LONG Shilei,FIEGUTH P.Detecting rock glacier flow structures using Gabor filters and IKONOS imagery[J].Remote Sensing of Environment,2012,125(10):227-237.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" DOU Peng,CHEN Yangbo,YUE Haiyun.Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost[J].International Journal of Remote Sensing,2018,39(3):619-639." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost">
                                        <b>[9]</b>
                                         DOU Peng,CHEN Yangbo,YUE Haiyun.Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost[J].International Journal of Remote Sensing,2018,39(3):619-639.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" YANG Guang,FANG Shenghui.Improving remote sensing image classification by exploiting adaptive features and hierarchical hybrid decision trees[J].Remote Sensing Letters,2017,8(2):156-164." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDD91802D7446C4257773FC187D2BEA6C3&amp;v=MDczMjFTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxoeHIyNnhhOD1Oam5CYXNleEg5bk1yZnRDWU84SmYzZzd5aEVVN1R3TE8zN3FxMlkzQzhmbFE4bWNDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         YANG Guang,FANG Shenghui.Improving remote sensing image classification by exploiting adaptive features and hierarchical hybrid decision trees[J].Remote Sensing Letters,2017,8(2):156-164.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" 曲景影,孙显,高鑫.基于CNN模型的高分辨率遥感图像目标识别[J].国外电子测量技术,2016,35(8):45-50.QU Jingying,SUN Xian,GAO Xin.Remote sensing image target recognition based on CNN[J].Foreign Electronic Measurement Technology,2016,35(8):45-50." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201608011&amp;v=MTM1NTJGeXJnVnJyUElqcklZckc0SDlmTXA0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         曲景影,孙显,高鑫.基于CNN模型的高分辨率遥感图像目标识别[J].国外电子测量技术,2016,35(8):45-50.QU Jingying,SUN Xian,GAO Xin.Remote sensing image target recognition based on CNN[J].Foreign Electronic Measurement Technology,2016,35(8):45-50.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" 卢艺帆,张松海.基于卷积神经网络的光学遥感图像目标检测[J].中国科技论文,2017,12(14):1583-1589,1633.LU Yifan,ZHANG Songhai.Object detection in optical remote sensing images with convolutional neural networks[J].China Sciencepaper,2017,12(14):1583-1589,1633." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKZX201714004&amp;v=MjUwMzQ5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWcnJQUHliUmRyRzRIOWJOcTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         卢艺帆,张松海.基于卷积神经网络的光学遥感图像目标检测[J].中国科技论文,2017,12(14):1583-1589,1633.LU Yifan,ZHANG Songhai.Object detection in optical remote sensing images with convolutional neural networks[J].China Sciencepaper,2017,12(14):1583-1589,1633.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" 何海威,钱海忠,谢丽敏,等.立交桥识别的CNN卷积神经网络法[J].测绘学报,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265.HE Haiwei,QIAN Haizhong,XIE Limin,et al.Interchange recognition method based on CNN[J].Acta Geodaetica et Cartographica Sinica,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201803012&amp;v=MjM3NThyUEppWFRiTEc0SDluTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         何海威,钱海忠,谢丽敏,等.立交桥识别的CNN卷积神经网络法[J].测绘学报,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265.HE Haiwei,QIAN Haizhong,XIE Limin,et al.Interchange recognition method based on CNN[J].Acta Geodaetica et Cartographica Sinica,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" 郑卓,方芳,刘袁缘,等.高分辨率遥感影像场景的多尺度神经网络分类法[J].测绘学报,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191.ZHENG Zhuo,FANG Fang,LIU Yuanyuan,et al.Joint multi-scale convolution neural network for scene classification of high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201805009&amp;v=MzIxMjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg5bk1xbzlGYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         郑卓,方芳,刘袁缘,等.高分辨率遥感影像场景的多尺度神经网络分类法[J].测绘学报,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191.ZHENG Zhuo,FANG Fang,LIU Yuanyuan,et al.Joint multi-scale convolution neural network for scene classification of high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" 伍广明,陈奇,SHIBASAKI R,等.基于U型卷积神经网络的航空影像建筑物检测[J].测绘学报,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651.WU Guangming,CHEN Qi,SHIBASAKI R,et al.High precision building detection from aerial imagery using a U-Net like convolutional architecture[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201806020&amp;v=MjUzNDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg5bk1xWTlIWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         伍广明,陈奇,SHIBASAKI R,等.基于U型卷积神经网络的航空影像建筑物检测[J].测绘学报,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651.WU Guangming,CHEN Qi,SHIBASAKI R,et al.High precision building detection from aerial imagery using a U-Net like convolutional architecture[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" 戴玉超,张静,PORIKLI F,等.深度残差网络的多光谱遥感图像显著目标检测[J].测绘学报,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633.DAI Yuchao,ZHANG Jing,PORIKLI F,et al.Salient object detection from multi-spectral remote sensing images with deep residual network[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201806021&amp;v=MDk2NTVnVnJyUEppWFRiTEc0SDluTXFZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         戴玉超,张静,PORIKLI F,等.深度残差网络的多光谱遥感图像显著目标检测[J].测绘学报,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633.DAI Yuchao,ZHANG Jing,PORIKLI F,et al.Salient object detection from multi-spectral remote sensing images with deep residual network[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" GIRSHICK R,DONAHUE J,DARRELL T,et al.Region-based convolutional networks for accurate object detection and segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2016,38(1):142-158." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Region-based convolutional networks for accurate object detection and segmentation">
                                        <b>[17]</b>
                                         GIRSHICK R,DONAHUE J,DARRELL T,et al.Region-based convolutional networks for accurate object detection and segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2016,38(1):142-158.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" HE Kaiming,ZHANG Xiangyu,REN Shaoqing,et al.Spatial pyramid pooling in deep convolutional networks for visual recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(9):1904-1916." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial pyramid pooling in deep convolutional networks for visual recognition">
                                        <b>[18]</b>
                                         HE Kaiming,ZHANG Xiangyu,REN Shaoqing,et al.Spatial pyramid pooling in deep convolutional networks for visual recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(9):1904-1916.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" GIRSHICK R.Fast R-CNN[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Santiago,Chile:IEEE,2015:1440-1448." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">
                                        <b>[19]</b>
                                         GIRSHICK R.Fast R-CNN[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Santiago,Chile:IEEE,2015:1440-1448.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     REN Shaoqing,HE Kaiming,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(6):1137-1149.</a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" 温奇,李苓苓,刘庆杰,等.基于视觉显著性和图分割的高分辨率遥感影像中人工目标区域提取[J].测绘学报,2013,42(6):831-837.WEN Qi,LI Lingling,LIU Qingjie,et al.A man-made object area extraction method based on visual saliency detection and graph-cut segmentation for high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2013,42(6):831-837." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201306009&amp;v=MjYwNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWcnJQSmlYVGJMRzRIOUxNcVk5RmJZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         温奇,李苓苓,刘庆杰,等.基于视觉显著性和图分割的高分辨率遥感影像中人工目标区域提取[J].测绘学报,2013,42(6):831-837.WEN Qi,LI Lingling,LIU Qingjie,et al.A man-made object area extraction method based on visual saliency detection and graph-cut segmentation for high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2013,42(6):831-837.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" 沈佳洁,潘励,胡翔云.可变形部件模型在高分辨率遥感影像建筑物检测中的应用[J].武汉大学学报(信息科学版),2017,42(9):1285-1291.SHEN Jiajie,PAN Li,HU Xiangyun.Building detection from high resolution remote sensing imagery based on a deformable part model[J].Geomatics and Information Science of Wuhan University,2017,42(9):1285-1291." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201709015&amp;v=MDk4MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBNaVhJWnJHNEg5Yk1wbzlFWVlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         沈佳洁,潘励,胡翔云.可变形部件模型在高分辨率遥感影像建筑物检测中的应用[J].武汉大学学报(信息科学版),2017,42(9):1285-1291.SHEN Jiajie,PAN Li,HU Xiangyun.Building detection from high resolution remote sensing imagery based on a deformable part model[J].Geomatics and Information Science of Wuhan University,2017,42(9):1285-1291.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C]//Proceedings of the 13th European Conference on Computer Vision.Zurich,Switzerland:Springer,2014:818-833." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">
                                        <b>[23]</b>
                                         ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C]//Proceedings of the 13th European Conference on Computer Vision.Zurich,Switzerland:Springer,2014:818-833.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[C]//Proceedings of the 3rd International Conference on Learning Representations.San Diego,California:[s.n.],2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[24]</b>
                                         SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[C]//Proceedings of the 3rd International Conference on Learning Representations.San Diego,California:[s.n.],2015.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" EVERINGHAM M,ESLAMI S M A,VAN GOOL L,et al.The Pascal visual object classes challenge:a retrospective[J].International Journal of Computer Vision,2015,111(1):98-136." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15011900002694&amp;v=MjIwNzNycVFUTW53WmVadEZpbmxVNzdJSWxzUmJ4VT1OajdCYXJLOUh0RE5wbzlGWk9zTkNuVTlvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         EVERINGHAM M,ESLAMI S M A,VAN GOOL L,et al.The Pascal visual object classes challenge:a retrospective[J].International Journal of Computer Vision,2015,111(1):98-136.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(10),1285-1295 DOI:10.11947/j.AGCS.2019.20180393            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>遥感影像目标的尺度特征卷积神经网络识别法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%A3%E5%BF%97%E9%B9%8F&amp;code=36379720&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">董志鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%AF%86&amp;code=08989108&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王密</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%BE%B7%E4%BB%81&amp;code=09015827&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李德仁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%89%B3%E4%B8%BD&amp;code=10138194&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王艳丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%87%B4%E9%BD%90&amp;code=32983239&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张致齐</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6%E6%B5%8B%E7%BB%98%E9%81%A5%E6%84%9F%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0009404&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉大学测绘遥感信息工程国家重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9C%B0%E7%90%83%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">地球空间信息协同创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>高分辨率遥感影像的目标检测与识别,是高分对地观测系统中影像信息自动提取及分析理解的重要内容。针对传统影像目标检测与识别算法中人工设计特征稳健性与普适性差的问题,本文提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别方法。首先通过统计遥感影像目标的尺度范围,获得卷积神经网络训练与测试过程中目标感兴趣区域合适的尺度大小。然后根据目标感兴趣区域合适的尺度,提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别架构。通过WHU-RSone数据集对本文卷积神经网络架构与Faster-RCNN架构对比测试验证。试验结果表明,本文架构ZF模型和本文架构VGG-16模型的mean average precision(mAP)分别比Faster-RCNN ZF模型和Faster-RCNN VGG-16模型提高8.17%和8.31%,本文卷积神经网络架构可获得良好的影像目标检测与识别效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高分辨率遥感影像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标检测与识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E5%B0%BA%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标尺度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    董志鹏(1991—),男,博士,研究方向为高分辨遥感影像处理及信息提取,E-mail: zhipengdong@foxmail.com。;
                                </span>
                                <span>
                                    *王密,E-mail: wangmi@whu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61825103;91638301);</span>
                    </p>
            </div>
                    <h1>Object detection in remote sensing imagery based on convolutional neural networks with suitable scale features</h1>
                    <h2>
                    <span>DONG Zhipeng</span>
                    <span>WANG Mi</span>
                    <span>LI Deren</span>
                    <span>WANG Yanli</span>
                    <span>ZHANG Zhiqi</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University</span>
                    <span>Collaborative Innovation Center of Geospatial Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Object detection and recognition in high spatial resolution remote sensing images(HSRI) is an important part of image information automatic extraction, analysis and understanding in high resolution earth observation system. The robustness and universality of traditional object detection and recognition algorithms using artificial design object feature are poor. To solve these problems, object detection and recognition in HSRI based on convolutional neural networks(CNN) with suitable scale features is proposed. Firstly, the suitable scale of the region of interest(ROI) of object is obtained by statistic the scale range of object in HSRI in the process of training and testing of CNN. Then, a CNN framework for object detection and recognition in HSRI is designed according to the suitable object ROI scale. The mean average precision(mAP) of the proposed CNN framework and Faster-RCNN is tested using the WHU-RSone data set. The experimental results show that the mAP of ZF model and VGG-16 model of the proposed CNN framework are 8.17% and 8.31% higher than that of Faster R-CNN ZF model and Faster R-CNN VGG-16 model, respectively. The proposed CNN framework can obtain good object detection and recognition results.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=high%20resolution%20remote%20sensing%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">high resolution remote sensing image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20detection%20and%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object detection and recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20scale&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object scale;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    DONG Zhipeng (1991—), male, PhD, majors in high resolution remote sensing image processing and information extraction,E-mail: zhipengdong@foxmail.com;;
                                </span>
                                <span>
                                    WANG Mi,E-mail: wangmi@whu.edu.cn;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-20</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China(Nos.61825103;91638301);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="52">随着地对地观测技术的发展,高分辨率遥感影像的数据获取量越来越大,且已被广泛用于城市规划、灾害监测、农业管理和军事侦察等方面<citation id="131" type="reference"><link href="2" rel="bibliography" /><link href="4" rel="bibliography" /><link href="6" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。在大数据条件下,如何自动化、智能化地实现高分辨率遥感影像目标检测与识别,对高分辨率遥感影像应用价值的发挥具有重要影响<citation id="124" type="reference"><link href="8" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。为此,国内外学者开展了大量的研究,其中许多研究方法主要使用人工设计的影像目标特征进行目标检测与识别,如梯度直方图(histogram of oriented gradient,HOG)<citation id="125" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、局部二值模式(local binary patterns,LBP)<citation id="126" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、尺度不变特征变换(scale-invariant feature transform,SIFT)<citation id="127" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和Gabor<citation id="128" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等特征,然后将这些特征以特征量的形式输入到传统的分类器,如支持向量机(support vector machine,SVM)<citation id="132" type="reference"><link href="10" rel="bibliography" /><link href="14" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">7</a>]</sup></citation>、AdaBoost<citation id="129" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、决策树<citation id="130" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等进行分类,在特定的目标识别任务中取得了较好的效果。但由于遥感卫星复杂多变的拍摄条件,传统的目标检测与识别算法难以适应不同情况下的遥感影像,算法的稳健性、普适性较差<citation id="133" type="reference"><link href="22" rel="bibliography" /><link href="24" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="53">近年来,卷积神经网络(convolutional neural networks,CNN)作为最热门的深度学习模型算法,其不需要人为设计目标特征,且会根据海量数据和标注自行进行有效特征提取和学习<citation id="139" type="reference"><link href="26" rel="bibliography" /><link href="28" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。在训练数据充足的情况下,模型具有良好的泛化能力,能够在复杂多变的条件下依然保持良好的稳健性<citation id="140" type="reference"><link href="30" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>。因此,卷积神经网络模型已被广泛应用于图像目标检测与识别领域。如文献<citation id="134" type="reference">[<a class="sup">17</a>]</citation>提出regional CNN(RCNN)算法,该算法将候选区域提取算法与CNN相结合,首先使用selective search算法提取图像的候选区域,然后通过CNN对候选区域进行特征提取,最后根据特征使用SVM进行区域分类,实现图像的目标检测与识别。文献<citation id="135" type="reference">[<a class="sup">18</a>]</citation>为了减少文献<citation id="136" type="reference">[<a class="sup">17</a>]</citation>中CNN对重叠候选区域的重复计算,提出spatial pyramid pooling net(SPPNet)算法。该算法只对CNN最后一层卷积层特定区域进行一次池化操作,输出候选区域的特征用于分类实现目标检测与识别,极大提高了模型的训练和测试速度。文献<citation id="137" type="reference">[<a class="sup">19</a>]</citation>提出Fast-RCNN算法,采用region of interest pooling(ROI pooling)层对CNN卷积层的特定区域进行池化,并引入多任务训练函数,使模型的训练和测试变得更加方便,且具有较高的目标检测与识别精度。文献<citation id="138" type="reference">[<a class="sup">20</a>]</citation>对Fast-RCNN算法进行进一步加速,提出Faster-RCNN算法,用region proposal network(RPN)网络代替selective search候选区域提取算法;RPN负责提取数量更少准确率更高的候选区域,并与Fast-RCNN提取特征的网络共享卷积层,进一步减少计算量,检测速度更快,且目标检测与识别精度优于RCNN、Fast-RCNN算法。但上述卷积神经网络算法均是针对自然图像设计的模型算法,相对于自然图像,高分辨率遥感影像存在背景更加复杂、目标区域范围更小和同类目标尺度变化更大等特点<citation id="141" type="reference"><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><sup>[<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>。因此,上述卷积神经网络算法难以良好地学习与耦合高分辨率遥感影像目标特征信息,对遥感影像目标检测与识别精度不高。</p>
                </div>
                <div class="p1">
                    <p id="54">针对上述问题,本文提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别方法。首先通过统计遥感影像目标的尺度范围,获得卷积神经网络训练与测试过程中目标感兴趣区域合适的尺度大小。然后根据目标感兴趣区域合适的尺度,提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别架构。最后通过定性对比试验和定量评价验证本文卷积神经网络架构的有效性。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">1 本文方法概述</h3>
                <div class="p1">
                    <p id="56">本文方法主要分为两个步骤:①统计高分辨率遥感影像目标的尺度范围,获得遥感影像目标感兴趣区域尺度大小;②根据目标感兴趣区域尺度,设计高分辨率遥感影像目标检测与识别卷积神经网络架构。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">1.1 目标感兴趣区域尺度范围</h4>
                <div class="p1">
                    <p id="58">高分辨率遥感卫星通常在近地轨道对地球表面进行成像,且成像过程中受光照、气象条件等影响,生成的遥感影像存在影像内容复杂、目标尺度范围较小,且不同时间段生成的遥感影像辐射差异较大等特点。在遥感卫星特殊的成像条件下,为了充分统计影像典型目标感兴趣区域的尺度范围,本文建立了一个包含飞机、储存罐和船只的遥感影像目标检测与识别数据集WHU-RSone。该数据集中包含2460幅高分辨率遥感影像,影像大小为600×600像素～1372×1024像素。2460幅遥感影像中包含22 191个目标,其中7732个飞机(plane)目标、10 572个储存罐(storage-tank)目标和3887个船只(ship)目标,具体信息如表1所示。</p>
                </div>
                <div class="area_img" id="59">
                    <p class="img_tit"><b>表1 WHU-RSone数据集目标类别与数目</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 The category and number of objects in WHU-RSone data set</b></p>
                    <p class="img_note"></p>
                    <table id="59" border="1"><tr><td><br />目标类型</td><td>目标个数</td></tr><tr><td><br />飞机</td><td>7732</td></tr><tr><td><br />存储罐</td><td>10 572</td></tr><tr><td><br />船只</td><td>3887</td></tr><tr><td><br />总计</td><td>22 191</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="60">WHU-RSone数据集中包含不同辐射亮度、不同尺度大小的目标影像数据,可以用于充分统计不同成像条件下遥感影像典型目标感兴趣区域的尺度范围,图1为WHU-RSone数据集中部分样例目标数据。在Faster-RCNN架构中RPN网络使用3种尺度(128、256和512)和3种比例(1∶2、1∶1和2∶1)生成9种目标感兴趣区域。9种目标感兴趣区域大小如图2左侧矩形框内所示,9种目标感兴趣区域能覆盖的区域范围如图3面积较大多边形区域所示。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 WHU-RSone目标样例数据" src="Detail/GetImg?filename=images/CHXB201910010_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 WHU-RSone目标样例数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Object sample data in WHU-RSone data set</p>

                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 目标感兴趣区域提取网络" src="Detail/GetImg?filename=images/CHXB201910010_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 目标感兴趣区域提取网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Object region of interest extraction network</p>

                </div>
                <div class="p1">
                    <p id="63">对WHU-RSone数据集中22 191个目标尺寸进行统计,统计信息如图4所示。在图4中,WHU-RSone数据集中仅有6.95%的目标尺寸处于中RPN网络生成的9种目标感兴趣区域覆盖的区域范围内,RPN网络生成的9种目标感兴趣区域难以有效耦合遥感影像典型目标的尺寸大小。由于高分辨率遥感影像中典型目标的尺度通常较小,需要对RPN网络生成的感兴趣区域尺度进行改进,设置4种尺度(16、32、64和128)与3种比例(1∶2、1∶1和2∶1)获得12种目标感兴趣区域。12种目标感兴趣区域大小如图2右侧矩形框内所示,12种目标感兴趣区域能覆盖的区域范围大小如图3面积较小多边形区域所示。在图4中,WHU-RSone数据集中有95.65%的目标尺寸处于改进后RPN网络生成的12种目标感兴趣区域覆盖的区域范围内,几乎所有的目标尺寸均处于改进后RPN网络生成的12种目标感兴趣区域覆盖的范围内。统计结果表明,设置的4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成的目标感兴趣区域能有效耦合遥感影像中典型目标的尺度范围。据此,在本文卷积神经网络架构设计中,RPN网络利用4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成卷积神经网络架构训练与测试过程中目标感兴趣区域大小。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 目标感兴趣区域覆盖范围" src="Detail/GetImg?filename=images/CHXB201910010_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 目标感兴趣区域覆盖范围  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Coverage area of object region of interest</p>

                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 目标尺度分布范围" src="Detail/GetImg?filename=images/CHXB201910010_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 目标尺度分布范围  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Object scale distribution range</p>

                </div>
                <h4 class="anchor-tag" id="66" name="66">1.2 目标检测与识别卷积神经网络架构</h4>
                <div class="p1">
                    <p id="67">借鉴Faster-RCNN架构设计,本文卷积神经网络架构包括RPN网络和目标识别网络。其中RPN网络用于生成影像中的目标感兴趣区域,目标识别网络用于对RPN网络中生成的目标感兴趣区域进行识别分类及目标区域坐标回归。卷积神经网络架构示意图如图5所示。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文卷积神经网路架构" src="Detail/GetImg?filename=images/CHXB201910010_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文卷积神经网路架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 The proposed convolution neural network framework</p>

                </div>
                <h4 class="anchor-tag" id="69" name="69">1.2.1 RPN网络</h4>
                <div class="p1">
                    <p id="70">本文中RPN网络用于提取目标感兴趣区域,生成的目标感兴趣区域用于架构的目标检测与识别的训练与测试。本文架构的RPN网络采用4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成12种锚点用于得到卷积神经网络架构的目标感兴趣区域,锚点示意图如图5矩形框内所示。RPN网络在最后一层特征图上根据锚点生成目标感兴趣区域,对目标感兴趣区域进行前景与背景的二分类及目标感兴趣区域坐标回归训练,使RPN网络中的权重学习到预测目标区域的能力。二分类与目标区域坐标回归训练的损失函数<i>L</i>(<i><b>p</b></i><b>,</b><i><b>t</b></i>)的计算如下所示</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><mo>,</mo><mi mathvariant="bold-italic">t</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>L</mi></mstyle><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub><mo stretchy="false">(</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>λ</mi><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>g</mtext></mrow></msub></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mi>L</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72"><i>L</i><sub>cls</sub>(<i>p</i><sub><i>i</i></sub>,<i>p</i><sup>*</sup><sub><i>i</i></sub>)=-<i>p</i><sup>*</sup><sub><i>i</i></sub>ln(<i>p</i><sub><i>i</i></sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>w</mi><mo>,</mo><mi>h</mi><mo stretchy="false">}</mo></mrow></munder><mtext>s</mtext></mstyle><mtext>m</mtext><mtext>o</mtext><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><msub><mrow></mrow><mrow><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="74">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201910010_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="78">式中,<i><b>p</b></i>为目标区域二分类的概率;<i>p</i><sub><i>i</i></sub>为标签<i>i</i>锚点二分类的概率;<i>p</i><sup>*</sup><sub><i>i</i></sub>为标签<i>i</i>锚点二分类的概率真值,当标签<i>i</i>锚点为目标时,<i>p</i><sup>*</sup><sub><i>i</i></sub>=1,否则<i>p</i><sup>*</sup><sub><i>i</i></sub>=0;<i><b>t</b></i>为网络预测目标区域坐标向量;<i><b>t</b></i><sub><i>i</i></sub>为网络对锚点<i>i</i>预测的坐标向量,<i><b>t</b></i><sub><i>i</i></sub>=[<i>x</i><sub><i>i</i></sub><i>y</i><sub><i>i</i></sub><i>w</i><sub><i>i</i></sub><i>h</i><sub><i>i</i></sub>];<i><b>t</b></i><sup>*</sup><sub><i>i</i></sub>为目标区域坐标向量真值,<i><b>t</b></i><sup>*</sup><sub><i>i</i></sub>=[<i>x</i><sup>*</sup><sub><i>i</i></sub><i>y</i><sup>*</sup><sub><i>i</i></sub><i>w</i><sup>*</sup><sub><i>i</i></sub><i>h</i><sup>*</sup><sub><i>i</i></sub>];[<i>x</i><sub><i>a</i></sub><i>y</i><sub><i>a</i></sub><i>w</i><sub><i>a</i></sub><i>h</i><sub><i>a</i></sub>]为锚点区域的坐标向量;<i>L</i><sub>cls</sub>(<i>p</i><sub><i>i</i></sub>,<i>p</i><sup>*</sup><sub><i>i</i></sub>)为二分类损失函数,采用标准交叉熵损失函数<citation id="142" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>;<i>L</i><sub>reg</sub>(<i>t</i><sub><i>i</i></sub>,<i>t</i><sup>*</sup><sub><i>i</i></sub>)为目标区域坐标损失函数,采用smooth<sub><i>L</i></sub><sub>1</sub>函数<citation id="143" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>;<i>N</i><sub>cls</sub>、<i>N</i><sub>reg</sub>和<i>λ</i>为两类损失函数间的平衡系数,文献<citation id="144" type="reference">[<a class="sup">20</a>]</citation>中设置<i>N</i><sub>cls</sub>为256、<i>N</i><sub>reg</sub>为2400、<i>λ</i>为10。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">1.2.2 目标识别网络</h4>
                <div class="p1">
                    <p id="80">目标识别网络使用卷积层(convolution layer)、激活层(relu layer)和池化层(pooling layer)获得影像特征图(feature map)。本文分别使用Zeiler and Fergus(ZF)模型<citation id="145" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>和visual geometry group(VGG)模型<citation id="146" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>两种经典网络模型获得卷积神经网络架构的特征图,通过两种不同的模型验证卷积神经网络架构的有效性。RPN网络将生成的目标区域信息传递给目标识别网络,目标识别网络结合目标区域信息和网络中最后一层特征图,获得目标区域在特征图上特征向量信息,将特征向量信息传递至ROI pooling层,获得指定大小的特征向量信息。特征向量被传递至全连接层(fully-connected layer,FC)用于目标识别分类和区域坐标回归训练和测试。目标识别分类和区域坐标回归训练的损失函数<i>L</i>(<i><b>p</b></i>,<i>k</i><sup>*</sup>,<i><b>t</b></i><b>,</b><i><b>t</b></i><sup>*</sup>)计算如下所示</p>
                </div>
                <div class="p1">
                    <p id="81"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><mo>,</mo><mi>k</mi><msup><mrow></mrow><mo>*</mo></msup><mo>,</mo><mi mathvariant="bold-italic">t</mi><mo>,</mo><mi mathvariant="bold-italic">t</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo><mo>=</mo><msup><mi>L</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">)</mo><mo>+</mo><mrow><mo>[</mo><mrow><mi>k</mi><msup><mrow></mrow><mo>*</mo></msup><mo>≥</mo><mn>1</mn></mrow><mo>]</mo></mrow><msup><mi>L</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><mo>,</mo><mi mathvariant="bold-italic">t</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>L</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mo>-</mo></mstyle><mrow><mi>ln</mi></mrow><mo stretchy="false">(</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>k</mi><msup><mrow></mrow><mo>*</mo></msup></mrow></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>L</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><mo>,</mo><mi mathvariant="bold-italic">t</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>w</mi><mo>,</mo><mi>h</mi></mrow><mo>}</mo></mrow></mrow></munder><mtext>s</mtext></mstyle><mtext>m</mtext><mtext>o</mtext><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><msub><mrow></mrow><mrow><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi mathvariant="bold-italic">t</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">式中,<i><b>p</b></i>=(<i>p</i><sub>0</sub>,<i>p</i><sub>1</sub>,<i>p</i><sub>2</sub>,…,<i>p</i><sub><i>k</i></sub>),为<i>k</i>+1维目标识别分类的概率向量,<i>k</i>为目标区域识别分类的类别数;<i>k</i><sup>*</sup>为生成的目标区域对应的类别真值标签,当对应的类别真值为背景时,<i>k</i><sup>*</sup>=0,否则<i>k</i><sup>*</sup>≥1;当生成的目标区域对应的类别标签真值为背景时,<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>k</mi><msup><mrow></mrow><mo>*</mo></msup><mo>≥</mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math></mathml>为0,否则<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>k</mi><msup><mrow></mrow><mo>*</mo></msup><mo>≥</mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math></mathml>为1;<i><b>t</b></i>为目标识别网络预测目标区域坐标向量,<i><b>t</b></i>=(<i>x</i>,<i>y</i>,<i>w</i>,<i>h</i>);<i><b>t</b></i><sup>*</sup>为目标区域坐标向量真值,<i><b>t</b></i><sup>*</sup>=(<i>x</i><sup>*</sup>,<i>y</i><sup>*</sup>,<i>w</i><sup>*</sup>,<i>h</i><sup>*</sup>);<i>L</i>′<sub>cls</sub>(<i><b>p</b></i>)为目标识别分类损失函数,为标准交叉熵损失函数;<i>L</i>′<sub>reg</sub>为目标区域坐标损失函数,为smooth<sub><i>L</i></sub><sub>1</sub>函数。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">1.2.3 架构训练与测试</h4>
                <div class="p1">
                    <p id="86">本文卷积神经网络架构利用Caffe框架实现,采用端到端的训练方式对RPN网络和目标识别网络进行训练。将RPN网络损失和目标识别网络损失相加,利用随机梯度下降法进行反向传播。训练过程中,使用ImageNet上训练好的模型初始化本文网络模型参数。本文RPN网络的batch大小为256,目标识别网络的batch大小为2000,网络训练的动量为0.9,衰减因子为0.000 5,基础学习速率为0.001,学习速率变化比率为0.1,每迭代50 000次变化学习速率,最大训练迭代次数为75 000。</p>
                </div>
                <div class="p1">
                    <p id="87">在卷积神经网络架构测试阶段,将一幅遥感影像输入卷积神经网络架构,利用RPN网络生成6000个目标区域,对目标区域进行非极大值抑制,非极大值抑制的intersection over union(IoU)阈值为0.7。然后选取置信度排名前300的目标区域传递至目标识别网络,目标识别网络对300个目标区域进行分类识别及区域坐标回归,输出目标类别和区域坐标。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">2 试验结果与分析</h3>
                <div class="p1">
                    <p id="89">大规模的学习样本是支撑深度学习发挥高性能的基础。为此,本文建立了一个包含2460幅遥感影像的目标检测与识别数据集WHU-RSone。数据集中包含22 191个目标,其中7732个飞机目标、10 572个存储罐目标和3887个船只目标,数据集具体信息如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="90">为了充分验证本文卷积神经网络架构的有效性,将本文卷积神经网络架构与Faster-RCNN架构进行定性与定量对比评价。在试验中使用ZF和VGG两种网络模型获得本文架构与Faster-RCNN架构的特征图,通过两种不同的模型充分对比验证两种架构的性能。在2460幅遥感影像中随机选出1476幅影像作为训练数据,492幅影像作为验证数据,492幅影像作为测试数据。通过训练和验证数据对本文架构与Faster-RCNN架构进行训练,利用测试数据对训练后的两种架构进行对比测试。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2.1 训练损失值(loss)对比</h4>
                <div class="p1">
                    <p id="92">图6为两种架构基于ZF模型和VGG-16模型训练loss走势图。图6(a)中蓝色曲线和红色曲线分别为Faster-RCNN ZF和本文架构ZF模型训练loss曲线。相对于Faster-RCNN ZF模型loss曲线,本文架构ZF模型的loss更易趋于收敛,且收敛后的loss值小于Faster-RCNN ZF模型。图6(b)中的蓝色曲线和红色曲线分别为Faster-RCNN VGG-16和本文架构VGG-16模型训练loss曲线。同样,相对于Faster-RCNN VGG-16模型loss曲线,本文架构VGG-16模型的loss更易趋于收敛,且收敛后的loss值小于Faster-RCNN VGG-16模型。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Faster-RCNN架构与本文架构训练loss对比图" src="Detail/GetImg?filename=images/CHXB201910010_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 Faster-RCNN架构与本文架构训练loss对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Comparison of Faster-RCNN and the proposed CNN framework training loss</p>

                </div>
                <div class="p1">
                    <p id="94">Faster-RCNN架构通过设置3种尺度(128、256和512)和3种比例(1∶2、1∶1和2∶1)生成9种目标感兴趣区域对架构进行训练。本文架构通过设置4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成12种目标感兴趣区域对架构进行训练。两种架构在其他结构相似的情况下,试验结果表明本文架构设置的4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成12种目标感兴趣区域更有利于高分辨率遥感影像目标检测与识别训练,可以获得更好的模型训练结果。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">2.2 目标检测与识别定量评价</h4>
                <div class="p1">
                    <p id="96">本文使用492幅遥感影像对训练后的Faster-RCNN架构和本文架构进行对比评价。通过mAP(mean average precision)<citation id="147" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>对两种架构的目标检测与识别精度进行定量评价。mAP值越大说明网络架构的目标检测与识别精度越高,反之亦然。在计算mAP时,当检测结果的坐标与目标真值坐标的IoU大于等于0.5时,认为检测结果正确,反之为错误检测结果。mAP的计算如式(9)所示</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>m</mtext><mtext>A</mtext><mtext>Ρ</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>n</mi></munderover><mi>A</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="98">式中,<i>n</i>为目标类别数;<i>i</i>为类别标签;AP<sub><i>i</i></sub>为标签<i>i</i>类别的平均精度,AP<sub><i>i</i></sub>的大小为标签<i>i</i>类别的P-R曲线下包含的面积,如图7所示。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 P-R曲线" src="Detail/GetImg?filename=images/CHXB201910010_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 P-R曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 P-R curve diagram</p>

                </div>
                <div class="p1">
                    <p id="100">图8为两种架构基于ZF模型和VGG-16模型的mAP走势图,图8(a)中实线和虚线分别为本文架构ZF模型和Faster-RCNN ZF模型的mAP曲线,图8(b)中实线和虚线分别为本文架构VGG-16模型和Faster-RCNN VGG-16模型的mAP曲线。图8(a)、(b)中,本文架构的mAP曲线均高于Faster-RCNN架构的mAP曲线,表明本文架构的目标检测与识别精度优于Faster-RCNN架构。</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 Faster-RCNN架构与本文架构测试mAP对比图" src="Detail/GetImg?filename=images/CHXB201910010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 Faster-RCNN架构与本文架构测试mAP对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 The mAP comparison of Faster-RCNN and the proposed CNN framework test</p>

                </div>
                <div class="p1">
                    <p id="102">表2中为图8中Faster-RCNN架构和本文架构的mAP曲线平稳时,各类目标的AP值,及所有目标类别的mAP值。表2中,本文架构ZF模型的飞机、存储罐和船只的AP值均高于Faster-RCNN ZF模型,说明本文架构ZF模型对各类目标的检测与识别精度均优于Faster-RCNN ZF模型;本文架构ZF模型和Faster-RCNN ZF模型的mAP值分别为0.772 7和0.691 0,本文架构ZF模型的mAP值比Faster-RCNN ZF模型提高了8.17%。表2中本文架构VGG-16模型的飞机、存储罐和船只的AP值均高于Faster-RCNN VGG-16模型,表明本文架构VGG-16模型对各类目标的检测与识别精度均优于Faster-RCNN VGG-16模型;本文架构VGG-16模型和Faster-RCNN VGG-16模型的mAP值分别为0.779 0和0.695 9,本文架构VGG-16模型的mAP值比Faster-RCNN VGG-16模型提高了8.31%。试验结果表明本文架构的mAP值比Faster-RCNN架构有了较大的提升,本文架构的目标检测与识别精度优于Faster-RCNN架构。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">2.3 目标检测与识别目视判别</h4>
                <div class="p1">
                    <p id="104">表2中Faster-RCNN架构与本文架构基于VGG-16模型的mAP值分别高于两种架构基于ZF模型的mAP值,则对mAP值更高的Faster-RCNN VGG-16模型与本文架构VGG-16模型的检测与识别结果进行目视对比评价。两种架构目标检测与识别的置信度阈值设为0.8,图9(a1)、(b1)、(c1)、(d1)和(e1)为Faster-RCNN VGG-16模型的测试样例结果,图9(a2)、(b2)、(c2)、(d2)和(e2)为本文架构VGG-16模型的测试样例结果。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表2 目标检测与识别定量评价结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 Quantitative evaluation results of object detection and recognition</b></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />模型</td><td>飞机</td><td>存储罐</td><td>船只</td><td>mAP</td></tr><tr><td><br />Faster-RCNN ZF</td><td>0.928 0</td><td>0.547 8</td><td>0.597 4</td><td>0.691 0</td></tr><tr><td><br />Faster-RCNN <br />VGG-16</td><td>0.931 9</td><td>0.540 7</td><td>0.615 0</td><td>0.695 9</td></tr><tr><td><br />本文架构ZF</td><td>0.937 9</td><td>0.735 2</td><td>0.644 9</td><td>0.772 7</td></tr><tr><td><br />本文架构VGG-16</td><td>0.938 0</td><td>0.740 0</td><td>0.658 9</td><td>0.779 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="106">在图9(a1)、(a2)中黄色箭头所指的区域,Faster-RCNN VGG-16模型难以检测与识别出尺度较小的飞机目标,而本文架构VGG-16模型可以准确检测与识别出尺度较小的飞机目标。</p>
                </div>
                <div class="p1">
                    <p id="107">在图9(b1)、(b2)中黄色箭头所指的区域,Faster-RCNN VGG-16模型难以检测与识别出尺度较小的飞机目标,而本文架构VGG-16模型可以准确检测与识别出尺度较小的飞机目标。</p>
                </div>
                <div class="p1">
                    <p id="108">在图9(c1)、(c2)中黄色箭头所指的区域,Faster-RCNN VGG-16模型难以检测与识别出尺度较小的存储罐目标,而本文架构VGG-16模型可以准确检测与识别出尺度较小的存储罐目标。</p>
                </div>
                <div class="p1">
                    <p id="109">在图9(d1)、(d2)中黄色箭头所指的区域,Faster-RCNN VGG-16模型难以检测与识别出尺度较小的存储罐目标,而本文架构VGG-16模型可以准确检测与识别出尺度较小的存储罐目标。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 测试样例检测与识别结果" src="Detail/GetImg?filename=images/CHXB201910010_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 测试样例检测与识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Test sample detection and recognition results</p>

                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 测试样例检测与识别结果" src="Detail/GetImg?filename=images/CHXB201910010_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 测试样例检测与识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Test sample detection and recognition results</p>

                </div>
                <div class="p1">
                    <p id="112">在图9(e1)、(e2)中黄色箭头所指的区域,Faster-RCNN VGG-16模型将长条形状的码头区域识别为船只,而本文架构VGG-16模型可正确识别长条形状的码头区域。</p>
                </div>
                <div class="p1">
                    <p id="113">试验结果表明,对于遥感影像中尺度较小的目标,本文架构VGG-16模型的检测与识别结果优于Faster-RCNN VGG-16模型,本文架构VGG-16模型可获得良好的影像检测与识别结果。</p>
                </div>
                <div class="p1">
                    <p id="114">为了进一步验证本文框架的适用性与稳健性,将本文框架VGG16模型用于6幅高分二号全色影像目标检测与识别。目标检测与识别的置信度阈值设为0.8,试验结果如图10所示。</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201910010_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 高分二号影像目标检测与识别试验结果" src="Detail/GetImg?filename=images/CHXB201910010_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 高分二号影像目标检测与识别试验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201910010_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Experimental results of object detection and recognition on GF-2 images</p>

                </div>
                <div class="p1">
                    <p id="116">通过目视判读试验结果,本文框架VGG-16模型可有效检测与识别出影像中的飞机、存储罐和船只等典型地物。试验结果表明本文卷积神经网络架构可有效应用于高分二号影像的目标检测与识别,本文卷积神经网路架构具有良好的普适性与稳健性。</p>
                </div>
                <h3 id="117" name="117" class="anchor-tag">3 结 论</h3>
                <div class="p1">
                    <p id="118">针对传统影像目标检测与识别算法中人工设计特征稳健性、普适性差的问题,本文提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别。由于高分辨率遥感影像存在背景复杂、目标区域范围较小和同类目标尺度变化较大的特点,对此本文通过统计遥感影像目标的尺度范围,获得卷积神经网络训练与检测过程中目标感兴趣区域合适的尺度大小。试验统计分析得出设置4种尺度(16、32、64和128)和3种比例(1∶2、1∶1和2∶1)生成的12种目标感兴趣区域能有效耦合遥感影像中飞机、存储罐和船只等典型目标的尺度范围。根据合适的目标感兴趣区域尺度,提出基于高分辨率遥感影像目标尺度特征的卷积神经网络检测与识别架构。通过WHU-RSone数据集测试验证,结果表明本文架构ZF模型和本文架构VGG-16模型的mAP值分别比Faster-RCNN ZF模型和Faster-RCNN VGG-16模型提高了8.17%和8.31%,本文架构可以更好地检测出影像中尺度较小的目标,获得良好的目标检测与识别效果。下一步将在遥感影像目标检测与识别的基础上,对目标方向预测进行研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201702001&amp;v=MjIzNjU3cWZadWR2RnlyZ1ZyclBNaVhJWnJHNEg5Yk1yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李德仁,王密,沈欣,等.从对地观测卫星到对地观测脑[J].武汉大学学报(信息科学版),2017,42(2):143-149.LI Deren,WANG Mi,SHEN Xin,et al.From earth observation satellite to earth observation brain[J].Geomatics and Information Science of Wuhan University,2017,42(2):143-149.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201706010&amp;v=MTI4NzR6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVnJyUEppWFRiTEc0SDliTXFZOUVaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 董志鹏,王密,李德仁.一种融合超像素与最小生成树的高分辨率遥感影像分割方法[J].测绘学报,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514.DONG Zhipeng,WANG Mi,LI Deren.A high resolution remote sensing image segmentation method by combining superpixels with minimum spanning tree[J].Acta Geodaetica et Cartographica Sinica,2017,46(6):734-742.DOI:10.11947/j.AGCS.2017.20160514.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201405006&amp;v=MDQ4NDFyQ1VSN3FmWnVkdkZ5cmdWcnJQSmlYVGJMRzRIOVhNcW85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘婧,李培军.结合结构和光谱特征的高分辨率影像分割方法[J].测绘学报,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087.LIU Jing,LI Peijun.A high resolution image segmentation method by combined structural and spectral characteristics[J].Acta Geodaetica et Cartographica Sinica,2014,43(5):466-473.DOI:10.13485/j.cnki.11-2089.2014.0087.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHTB2014S1025&amp;v=MTQyMTZWcnJQSmlYZmJMRzRIOVd2cm85SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 高常鑫,桑农.基于深度学习的高分辨率遥感影像目标检测[J].测绘通报,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625.GAO Changxin,SANG Nong.Deep learning for object detection in remote sensing image[J].Bulletin of Surveying and Mapping,2014(S1):108-111.DOI:10.13474/j.cnki.11-2246.2014.0625.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600364403&amp;v=MjYxNTJlcnFRVE1ud1plWnRGaW5sVTc3SUlsc1JieFU9TmlmT2ZiSzhIdERNcVk5RlorMExDSHc2b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> CHENG Gong,HAN Junwei,GUO Lei,et al.Object detection in remote sensing imagery using a discriminatively trained mixture model[J].ISPRS Journal of Photogrammetry and Remote Sensing,2013,85(11):32-43.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH200801002&amp;v=Mjk5NTBuTXJvOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVnJyUE1pWElackc0SHQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 张剑清,佘琼,潘励.基于LBP/C纹理的遥感影像居民地变化检测[J].武汉大学学报(信息科学版),2008,33(1):7-11.ZHANG Jianqing,SHE Qiong,PAN Li.Change detection of residential area by remote sensing image based on LBP/C texture[J].Geomatics and Information Science of Wuhan University,2008,33(1):7-11.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An object detection technique for very high resolution remote sensing images">

                                <b>[7]</b> MORANDUZZO T,MELGANI F,DAAMOUCHE A.An object detection technique for very high resolution remote sensing images[C]//Proceedings of the 8th IEEE International Workshop on Systems,Signal Processing and Their Applications.Algiers,Algeria:IEEE,2013:79-83.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600661948&amp;v=MjY1NzJGaW5sVTc3SUlsc1JieFU9TmlmT2ZiSzdIdEROcVk5Rll1ME9CWGd4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> BRENNING A,LONG Shilei,FIEGUTH P.Detecting rock glacier flow structures using Gabor filters and IKONOS imagery[J].Remote Sensing of Environment,2012,125(10):227-237.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost">

                                <b>[9]</b> DOU Peng,CHEN Yangbo,YUE Haiyun.Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost[J].International Journal of Remote Sensing,2018,39(3):619-639.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDD91802D7446C4257773FC187D2BEA6C3&amp;v=MDg5OTNmT0dRbGZCckxVMDU5bGh4cjI2eGE4PU5qbkJhc2V4SDluTXJmdENZTzhKZjNnN3loRVU3VHdMTzM3cXEyWTNDOGZsUThtY0NPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> YANG Guang,FANG Shenghui.Improving remote sensing image classification by exploiting adaptive features and hierarchical hybrid decision trees[J].Remote Sensing Letters,2017,8(2):156-164.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201608011&amp;v=MDg0MDc0SDlmTXA0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVnJyUElqcklZckc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 曲景影,孙显,高鑫.基于CNN模型的高分辨率遥感图像目标识别[J].国外电子测量技术,2016,35(8):45-50.QU Jingying,SUN Xian,GAO Xin.Remote sensing image target recognition based on CNN[J].Foreign Electronic Measurement Technology,2016,35(8):45-50.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKZX201714004&amp;v=MDYwODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBQeWJSZHJHNEg5Yk5xNDlGWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 卢艺帆,张松海.基于卷积神经网络的光学遥感图像目标检测[J].中国科技论文,2017,12(14):1583-1589,1633.LU Yifan,ZHANG Songhai.Object detection in optical remote sensing images with convolutional neural networks[J].China Sciencepaper,2017,12(14):1583-1589,1633.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201803012&amp;v=MDk1MzlQSmlYVGJMRzRIOW5Nckk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmdWcnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 何海威,钱海忠,谢丽敏,等.立交桥识别的CNN卷积神经网络法[J].测绘学报,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265.HE Haiwei,QIAN Haizhong,XIE Limin,et al.Interchange recognition method based on CNN[J].Acta Geodaetica et Cartographica Sinica,2018,47(3):385-395.DOI:10.11947/j.AGCS.2018.20170265.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201805009&amp;v=MDc4NDNVUjdxZlp1ZHZGeXJnVnJyUEppWFRiTEc0SDluTXFvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 郑卓,方芳,刘袁缘,等.高分辨率遥感影像场景的多尺度神经网络分类法[J].测绘学报,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191.ZHENG Zhuo,FANG Fang,LIU Yuanyuan,et al.Joint multi-scale convolution neural network for scene classification of high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2018,47(5):620-630.DOI:10.11947/j.AGCS.2018.20170191.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201806020&amp;v=MDg5MjU3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg5bk1xWTlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 伍广明,陈奇,SHIBASAKI R,等.基于U型卷积神经网络的航空影像建筑物检测[J].测绘学报,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651.WU Guangming,CHEN Qi,SHIBASAKI R,et al.High precision building detection from aerial imagery using a U-Net like convolutional architecture[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):864-872.DOI:10.11947/j.AGCS.2018.20170651.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201806021&amp;v=MDA4NDk5bk1xWTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 戴玉超,张静,PORIKLI F,等.深度残差网络的多光谱遥感图像显著目标检测[J].测绘学报,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633.DAI Yuchao,ZHANG Jing,PORIKLI F,et al.Salient object detection from multi-spectral remote sensing images with deep residual network[J].Acta Geodaetica et Cartographica Sinica,2018,47(6):873-881.DOI:10.11947/j.AGCS.2018.20170633.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Region-based convolutional networks for accurate object detection and segmentation">

                                <b>[17]</b> GIRSHICK R,DONAHUE J,DARRELL T,et al.Region-based convolutional networks for accurate object detection and segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2016,38(1):142-158.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial pyramid pooling in deep convolutional networks for visual recognition">

                                <b>[18]</b> HE Kaiming,ZHANG Xiangyu,REN Shaoqing,et al.Spatial pyramid pooling in deep convolutional networks for visual recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(9):1904-1916.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">

                                <b>[19]</b> GIRSHICK R.Fast R-CNN[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Santiago,Chile:IEEE,2015:1440-1448.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 REN Shaoqing,HE Kaiming,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(6):1137-1149.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201306009&amp;v=MDgxOTA1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyZ1ZyclBKaVhUYkxHNEg5TE1xWTlGYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 温奇,李苓苓,刘庆杰,等.基于视觉显著性和图分割的高分辨率遥感影像中人工目标区域提取[J].测绘学报,2013,42(6):831-837.WEN Qi,LI Lingling,LIU Qingjie,et al.A man-made object area extraction method based on visual saliency detection and graph-cut segmentation for high resolution remote sensing imagery[J].Acta Geodaetica et Cartographica Sinica,2013,42(6):831-837.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201709015&amp;v=MTYyNzBiTXBvOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJnVnJyUE1pWElackc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 沈佳洁,潘励,胡翔云.可变形部件模型在高分辨率遥感影像建筑物检测中的应用[J].武汉大学学报(信息科学版),2017,42(9):1285-1291.SHEN Jiajie,PAN Li,HU Xiangyun.Building detection from high resolution remote sensing imagery based on a deformable part model[J].Geomatics and Information Science of Wuhan University,2017,42(9):1285-1291.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">

                                <b>[23]</b> ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C]//Proceedings of the 13th European Conference on Computer Vision.Zurich,Switzerland:Springer,2014:818-833.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[24]</b> SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[C]//Proceedings of the 3rd International Conference on Learning Representations.San Diego,California:[s.n.],2015.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15011900002694&amp;v=MTI1NTFHZXJxUVRNbndaZVp0RmlubFU3N0lJbHNSYnhVPU5qN0Jhcks5SHRETnBvOUZaT3NOQ25VOW9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> EVERINGHAM M,ESLAMI S M A,VAN GOOL L,et al.The Pascal visual object classes challenge:a retrospective[J].International Journal of Computer Vision,2015,111(1):98-136.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201910010" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201910010&amp;v=MjQ0MDBGckNVUjdxZlp1ZHZGeXJnVnJyUEppWFRiTEc0SDlqTnI0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
