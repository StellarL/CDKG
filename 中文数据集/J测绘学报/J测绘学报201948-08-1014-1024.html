<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637142615681357500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCHXB201908009%26RESULT%3d1%26SIGN%3dV4mYHCd3DxUsn9hm9KyVHshUGJk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CHXB201908009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908009&amp;v=MjkyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoVzd6T0ppWFRiTEc0SDlqTXA0OUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#58" data-title="1 NPE算法 ">1 NPE算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="2 本文算法 ">2 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="2.1 &lt;i&gt;WMF&lt;/i&gt;方法">2.1 <i>WMF</i>方法</a></li>
                                                <li><a href="#84" data-title="2.2 WSCPE算法">2.2 WSCPE算法</a></li>
                                                <li><a href="#123" data-title="2.3 &lt;i&gt;WSCPE&lt;/i&gt;算法步骤">2.3 <i>WSCPE</i>算法步骤</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#131" data-title="3 试验结果与分析 ">3 试验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#132" data-title="3.1 试验数据集">3.1 试验数据集</a></li>
                                                <li><a href="#139" data-title="3.2 试验设置">3.2 试验设置</a></li>
                                                <li><a href="#143" data-title="3.3 PaviaU试验结果">3.3 PaviaU试验结果</a></li>
                                                <li><a href="#154" data-title="3.4 Indian Pines试验结果">3.4 Indian Pines试验结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#160" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="图1 加权空谱联合距离 (WSCD) 的流程">图1 加权空谱联合距离 (WSCD) 的流程</a></li>
                                                <li><a href="#92" data-title="图2 3种不同近邻点的选取">图2 3种不同近邻点的选取</a></li>
                                                <li><a href="#138" data-title="图3 高光谱图像">图3 高光谱图像</a></li>
                                                <li><a href="#142" data-title="图4 WSCPE在不同&lt;i&gt;k&lt;/i&gt;下的分类结果">图4 WSCPE在不同<i>k</i>下的分类结果</a></li>
                                                <li><a href="#145" data-title="图5 PaviaU数据集中WSCPE 在不同&lt;i&gt;w&lt;/i&gt;和&lt;i&gt;t&lt;/i&gt;下的分类结果">图5 PaviaU数据集中WSCPE 在不同<i>w</i>和<i>t</i>下的分类结果</a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;表1 PaviaU数据集上不同算法的分类结果 (总体分类精度&lt;/b&gt;&#177;&lt;b&gt;标准差&lt;/b&gt;) "><b>表1 PaviaU数据集上不同算法的分类结果 (总体分类精度</b>±<b>标准差</b>) </a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;表2 PaviaU数据集中各类地物在不同算法下的分类结果&lt;/b&gt;"><b>表2 PaviaU数据集中各类地物在不同算法下的分类结果</b></a></li>
                                                <li><a href="#152" data-title="图6 各算法在PaviaU数据集上的分类结果">图6 各算法在PaviaU数据集上的分类结果</a></li>
                                                <li><a href="#156" data-title="图7 Indian Pines数据集中WSCPE在不同&lt;i&gt;w&lt;/i&gt;和&lt;i&gt;t&lt;/i&gt;下的分类结果">图7 Indian Pines数据集中WSCPE在不同<i>w</i>和<i>t</i>下的分类结果</a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表3 Indian Pines数据集上不同算法的分类结果 (总体分类精度&lt;/b&gt;&#177;&lt;b&gt;标准差&lt;/b&gt;) "><b>表3 Indian Pines数据集上不同算法的分类结果 (总体分类精度</b>±<b>标准差</b>) </a></li>
                                                <li><a href="#162" data-title="&lt;b&gt;表4 Indian Pines数据集中各类地物在不同算法下的分类结果&lt;/b&gt;"><b>表4 Indian Pines数据集中各类地物在不同算法下的分类结果</b></a></li>
                                                <li><a href="#163" data-title="图8 各算法在Indian Pines数据集上的分类结果">图8 各算法在Indian Pines数据集上的分类结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201608012&amp;v=MjkxMzMzenFxQnRHRnJDVVI3cWZadWR2RnlyaFc3ek9KaVhUYkxHNEg5Zk1wNDlFWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" LI Chang, MA Yong, MEI Xiaoguang, et al.Hyperspectral image classification with robust sparse representation[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (5) :641-645." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hyperspectral image classification with robust sparse representation">
                                        <b>[2]</b>
                                         LI Chang, MA Yong, MEI Xiaoguang, et al.Hyperspectral image classification with robust sparse representation[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (5) :641-645.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" LI Li, SUN Chao, LIN Lianlei, et al.A dual-layer supervised Mahalanobis kernel for the classification of hyperspectral images[J].Neurocomputing, 2016, 214:430-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A dual-layer supervised Mahalanobis kernel for the classification of hyperspectral images">
                                        <b>[3]</b>
                                         LI Li, SUN Chao, LIN Lianlei, et al.A dual-layer supervised Mahalanobis kernel for the classification of hyperspectral images[J].Neurocomputing, 2016, 214:430-444.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" HU Wei, HUANG Yangyu, WEI Li, et al.Deep convolutional neural networks for hyperspectral image classification[J].Journal of Sensors, 2015 (2) :1-12." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD15081800000389&amp;v=MjU1ODBwNDlGWk9zUEQzUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFU3N0lJbG9jYVJRPU5pZkRhcks5SHRuTg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         HU Wei, HUANG Yangyu, WEI Li, et al.Deep convolutional neural networks for hyperspectral image classification[J].Journal of Sensors, 2015 (2) :1-12.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" 罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201703019&amp;v=MjA1NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVkdkZ5cmhXN3pPSmlYVGJMRzRIOWJNckk5RWJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201709005&amp;v=MTg4NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoVzd6T0ppWFRiTEc0SDliTXBvOUZZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" HUANG Hong, LUO Fulin, LIU Jiamin, et al.Dimensionality reduction of hyperspectral images based on sparse discriminant manifold embedding[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 106 (3) :42-54." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8395EAF1B37D9747B0530A12EB87CA3F&amp;v=MjAxODRybWRIY2JYbk5MbnBDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDU5bGh4cnkzdzY0PU5pZk9mYnU3RjlTNTN2bEVGdWdJZUhVK3l4Rmg2anArU0E3ag==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         HUANG Hong, LUO Fulin, LIU Jiamin, et al.Dimensionality reduction of hyperspectral images based on sparse discriminant manifold embedding[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 106 (3) :42-54.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" BONIFAZI G, CAPOBIANCO G, SERRANTI S.Asbestos containing materials detection and classification by the use of hyperspectral imaging[J].Journal of Hazardous Materials, 2018, 344 (4) :981-993." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA5E38BE2F4925032F62A0263D85018AB&amp;v=MDk0MDlCUmw3RDBNU0gza3IyWTlmTEtWVGN2dENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNTlsaHhyeTN3NjQ9TmlmT2ZjSzlhOUxFM2ZwSEV1OEdEbms1eg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         BONIFAZI G, CAPOBIANCO G, SERRANTI S.Asbestos containing materials detection and classification by the use of hyperspectral imaging[J].Journal of Hazardous Materials, 2018, 344 (4) :981-993.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" LIAO Wenzhi, PIZURICA A, SCHEUNDERS P, et al.Semisupervised local discriminant analysis for feature extraction in hyperspectral images[J].IEEE Transactions on Geoscience and Remote Sensing, 2013, 51 (1) :184-198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semisupervised Local Discriminant Analysis for Feature Extraction in Hyperspectral Images">
                                        <b>[9]</b>
                                         LIAO Wenzhi, PIZURICA A, SCHEUNDERS P, et al.Semisupervised local discriminant analysis for feature extraction in hyperspectral images[J].IEEE Transactions on Geoscience and Remote Sensing, 2013, 51 (1) :184-198.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" HUANG Hong, YANG Mei.Dimensionality reduction of hyperspectral images with sparse discriminant embedding[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (9) :5160-5169." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction of hyperspectral images with sparse discriminant embedding">
                                        <b>[10]</b>
                                         HUANG Hong, YANG Mei.Dimensionality reduction of hyperspectral images with sparse discriminant embedding[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (9) :5160-5169.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" ZHANG Lili, ZHAO Chunhui.Sparsity divergence index based on locally linear embedding for hyperspectral anomaly detection[J].Journal of Applied Remote Sensing, 2016, 10 (2) :025026." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparsity divergence index based on locally linear embedding for hyperspectral anomaly detection">
                                        <b>[11]</b>
                                         ZHANG Lili, ZHAO Chunhui.Sparsity divergence index based on locally linear embedding for hyperspectral anomaly detection[J].Journal of Applied Remote Sensing, 2016, 10 (2) :025026.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" LI Wan, ZHANG Liangpei, ZHANG Lefei, et al.GPU parallel implementation of isometric mapping for hyperspectral classification[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (9) :1532-1539." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPU parallel implementation of isometric mapping for hyperspectral classification">
                                        <b>[12]</b>
                                         LI Wan, ZHANG Liangpei, ZHANG Lefei, et al.GPU parallel implementation of isometric mapping for hyperspectral classification[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (9) :1532-1539.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" DORADO-MUNOZ L P, MESSINGER D W.Initial study of Schroedinger eigenmaps for spectral target detection[J].Optical Engineering, 2016, 55 (8) :083101." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGB3285380E97CABB23DEB810CA1AB734A&amp;v=MDEzMDZJSWZ3MUx2UlFRbmtvUFFIN2kzMk0wQ01DVFJyN3VDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDU5bGh4cnkzdzY0PU5pZk9hY0c3SE5uSnJJZEZFZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         DORADO-MUNOZ L P, MESSINGER D W.Initial study of Schroedinger eigenmaps for spectral target detection[J].Optical Engineering, 2016, 55 (8) :083101.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" L&#220; Meng, ZHAO Xinbin, LIU Liming, et al.Discriminant collaborative neighborhood preserving embedding for hyperspectral imagery[J].Journal of Applied Remote Sensing, 2017, 11 (4) :046004." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminant collaborative neighborhood preserving embedding for hyperspectral imagery">
                                        <b>[14]</b>
                                         L&#220; Meng, ZHAO Xinbin, LIU Liming, et al.Discriminant collaborative neighborhood preserving embedding for hyperspectral imagery[J].Journal of Applied Remote Sensing, 2017, 11 (4) :046004.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images">
                                        <b>[15]</b>
                                         DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" LUO Renbo, LIAO Wenzhi, HUANG Xin, et al.Feature extraction of hyperspectral images with semisupervised graph learning[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2016, 9 (9) :4389-4399." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature Extraction of Hyperspectral Images with Semisupervised Graph Learning">
                                        <b>[16]</b>
                                         LUO Renbo, LIAO Wenzhi, HUANG Xin, et al.Feature extraction of hyperspectral images with semisupervised graph learning[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2016, 9 (9) :4389-4399.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" TAN Kun, HU Jun, LI Jun, et al.A novel semi-supervised hyperspectral image classification approach based on spatial neighborhood information and classifier combination[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 105 (5) :19-29." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF4A3A86F18BCCB099D0CCAAD78F90CB6&amp;v=MTgyNDRuajhPT3c2VDJCVTlEN3VVTnNpWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNTlsaHhyeTN3NjQ9TmlmT2ZjVzhiOUs5cDRrelplTjlmdzlMeng4YQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         TAN Kun, HU Jun, LI Jun, et al.A novel semi-supervised hyperspectral image classification approach based on spatial neighborhood information and classifier combination[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 105 (5) :19-29.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" WEN Jinhua, FOWLER J E, HE Mingyi, et al.Orthogonal nonnegative matrix factorization combining multiple features for spectral-spatial dimensionality reduction of hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (7) :4272-4286." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Orthogonal Nonnegative Matrix Factorization Combining Multiple Features for Spectral-Spatial Dimensionality Reduction of Hyperspectral Imagery">
                                        <b>[18]</b>
                                         WEN Jinhua, FOWLER J E, HE Mingyi, et al.Orthogonal nonnegative matrix factorization combining multiple features for spectral-spatial dimensionality reduction of hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (7) :4272-4286.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" XIA Junshi, BOMBRUN L, ADALI T, et al.Spectral-spatial classification of hyperspectral images using ICA and edge-preserving filter via an ensemble strategy[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (8) :4971-4982." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial classification of hyperspectral images using ICA and edgepreserving filter via an ensemble strategy">
                                        <b>[19]</b>
                                         XIA Junshi, BOMBRUN L, ADALI T, et al.Spectral-spatial classification of hyperspectral images using ICA and edge-preserving filter via an ensemble strategy[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (8) :4971-4982.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_20" title=" XIA Junshi, CHANUSSOT J, DU Peijun, et al.Spectral-spatial classification for hyperspectral data using rotation forests with local feature extraction and Markov random fields[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2532-2546." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial Classification for Hyperspectral Data Using Rotation Forests with Local Feature Extraction and Markov Random Fields">
                                        <b>[20]</b>
                                         XIA Junshi, CHANUSSOT J, DU Peijun, et al.Spectral-spatial classification for hyperspectral data using rotation forests with local feature extraction and Markov random fields[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2532-2546.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_21" title=" DE SOUZA F D M, SARKAR S, SRIVASTAVA A, et al.Spatially coherent interpretations of videos using pattern theory[J].International Journal of Computer Vision, 2017, 121 (1) :5-25." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatially coherent interpretations of videos using pattern theory">
                                        <b>[21]</b>
                                         DE SOUZA F D M, SARKAR S, SRIVASTAVA A, et al.Spatially coherent interpretations of videos using pattern theory[J].International Journal of Computer Vision, 2017, 121 (1) :5-25.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_22" title=" YUE Jun, ZHAO Wenzhi, MAO Shanjun, et al.Spectral-spatial classification of hyperspectral images using deep convolutional neural networks[J].Remote Sensing Letters, 2015, 6 (6) :468-477." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial classification of hyperspectral images using deep convolutional neural networks">
                                        <b>[22]</b>
                                         YUE Jun, ZHAO Wenzhi, MAO Shanjun, et al.Spectral-spatial classification of hyperspectral images using deep convolutional neural networks[J].Remote Sensing Letters, 2015, 6 (6) :468-477.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_23" title=" JIA Sen, ZHANG Xiujun, LI Qingquan.Spectral-spatial hyperspectral image classification using ℓ&lt;sub&gt;1/2&lt;/sub&gt; regularized low-rank representation and sparse representation-based graph cuts[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2015, 8 (6) :2473-2484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial hyperspectral image classification using,regularized low-rank representation and sparse representation-based graph cuts">
                                        <b>[23]</b>
                                         JIA Sen, ZHANG Xiujun, LI Qingquan.Spectral-spatial hyperspectral image classification using ℓ&lt;sub&gt;1/2&lt;/sub&gt; regularized low-rank representation and sparse representation-based graph cuts[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2015, 8 (6) :2473-2484.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_24" title=" 魏峰, 何明一, 梅少辉.空间一致性邻域保留嵌入的高光谱数据特征提取[J].红外与激光工程, 2012, 41 (5) :1249-1254.WEI Feng, HE Mingyi, MEI Shaohui.Hyperspectral data feature extraction using spatial coherence based neighborhood preserving embedding[J].Infrared and Laser Engineering, 2012, 41 (5) :1249-1254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201205025&amp;v=MzE0NDc0SDlQTXFvOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoVzd6T0xUclNaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         魏峰, 何明一, 梅少辉.空间一致性邻域保留嵌入的高光谱数据特征提取[J].红外与激光工程, 2012, 41 (5) :1249-1254.WEI Feng, HE Mingyi, MEI Shaohui.Hyperspectral data feature extraction using spatial coherence based neighborhood preserving embedding[J].Infrared and Laser Engineering, 2012, 41 (5) :1249-1254.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_25" title=" ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimension Reduction Using Spatial and Spectral Regularized Local Discriminant Embedding for Hyperspectral Image Classification">
                                        <b>[25]</b>
                                         ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_26" title=" FENG Zhixi, YANG Shuyuan, WANG Shigang, et al.Discriminative spectral-spatial margin-based semisupervised dimensionality reduction of hyperspectral data[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (2) :224-228." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative spectral-spatial margin-based semi-supervised dimensionality reduction of hyperspectral data">
                                        <b>[26]</b>
                                         FENG Zhixi, YANG Shuyuan, WANG Shigang, et al.Discriminative spectral-spatial margin-based semisupervised dimensionality reduction of hyperspectral data[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (2) :224-228.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CHXB" target="_blank">测绘学报</a>
                2019,48(08),1014-1024 DOI:10.11947/j.AGCS.2019.20180229            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>加权空-谱联合保持嵌入的高光谱遥感影像降维方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E9%B8%BF&amp;code=10191717&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄鸿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%9F%B3%E5%85%89%E8%80%80&amp;code=35772897&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">石光耀</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AE%B5%E5%AE%87%E4%B9%90&amp;code=37482830&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">段宇乐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%B8%BD%E6%A2%85&amp;code=38226343&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张丽梅</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%87%8D%E5%BA%86%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E6%8A%80%E6%9C%AF%E4%B8%8E%E7%B3%BB%E7%BB%9F%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0109290&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重庆大学光电技术与系统教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>高光谱遥感影像数据量大、波段数多, 容易导致“维数灾难”。传统流形学习方法一般仅考虑其光谱特征, 忽略了空间信息。为此提出一种非监督的基于加权空-谱联合保持嵌入 (WSCPE) 的维数约简算法。首先采用加权均值滤波 (WMF) 方法对高光谱影像进行滤波, 以消除噪点和背景点的干扰。然后根据遥感影像地物分布的空间一致性, 通过采用加权空-谱联合距离 (WSCD) 来融合像素点的光谱信息和空间信息, 有效选取各像素点的空-谱近邻, 并根据像素点与其空-谱近邻点之间的坐标距离来有区别的利用其近邻点进行流形重构, 提取低维鉴别特征进行地物分类。在PaviaU和Indian Pines数据集上的分类结果表明, 总体分类精度分别达到了98.89%和95.47%。该方法在反映影像内部流形结构的同时, 有效融合了影像的空间-光谱信息, 故能提高影像特征的鉴别性, 并提升分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱遥感影像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流形学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%B4%E6%95%B0%E7%BA%A6%E7%AE%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">维数约简;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA-%E8%B0%B1%E8%BF%91%E9%82%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空-谱近邻;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%89%B4%E5%88%AB%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鉴别特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黄鸿 (1980—) , 男, 博士, 教授, 研究方向为遥感影像智能化处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (41371338);</span>
                                <span>重庆市基础研究与前沿探索项目 (cstc2018jcyjAX0093);</span>
                                <span>重庆市研究生科研创新项目 (CYB18048);</span>
                    </p>
            </div>
                    <h1>Dimensionality reduction method for hyperspectral images based on weighted spatial-spectral combined preserving embedding</h1>
                    <h2>
                    <span>HUANG Hong</span>
                    <span>SHI Guangyao</span>
                    <span>DUAN Yule</span>
                    <span>ZHANG Limei</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of Optoelectronic Technique and System of Ministry of Education, Chongqing University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Hyperspectral image (HSI) contains a large number of spectral bands, which easily leads to the curse of dimensionality. However, the traditional manifold learning methods generally only consider the spectral features, while the spatial information of HSI is ignored. To overcome this shortcoming, it is proposed that an unsupervised dimensionality reduction algorithm called weighted spatial-spectral combined preserving embedding (WSCPE) for HSI classification. Firstly, the proposed algorithm uses a weighted mean filter (WMF) to filter the image, which can reduce the influence of background noise. Then, according to the spatial consistency property of HSI, it adopts the weighted spatial-spectral combined distance (WSCD) to fuse the spectral and spatial information of pixels to effectively select the spatial-spectral neighbors of each pixel. Finally, the proposed method explores the coordinate distances between pixels and their spatial-spectral neighbors to perform manifold reconstruction, and the low-dimensional discriminative features are extracted for HSI classification. The experimental results on PaviaU and Indian Pines datasets indicate that the overall classification accuracies of the proposed method reached 98.89% and 95.47%, respectively. The WSCPE method not only discovers the intrinsic manifold structure of HSI data, but also effectively integrates the spatial-spectral combined information, which enhances the classification performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral%20remote%20sensing%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral remote sensing image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=manifold%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">manifold learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dimensionality%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dimensionality reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial-spectral%20neighbors&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial-spectral neighbors;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=discriminant%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">discriminant features;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HUANG Hong (1980—) , male, PhD, professor, majors in remote sensing with intelligent processing.E-mail: hhuang@cqu.edu.cn;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-05-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The National Natural Science Foundation of China (No.41371338);</span>
                                <span>The Basic and Advanced Research Program of Chongqing (No.cstc2018jcyjAX0093);</span>
                                <span>The Postgraduate Research and Innovation Program of Chongqing (No.CYB18048);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="54">高光谱遥感影像具有图谱合一、光谱波段范围广、分辨率高等特点, 增强了遥感对地观测能力和地物鉴别能力, 给地物分类带来了机遇<citation id="164" type="reference"><link href="2" rel="bibliography" /><link href="4" rel="bibliography" /><link href="6" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。但是, 高光谱遥感影像同时存在数据量大、波段数多、信息冗余多<citation id="165" type="reference"><link href="8" rel="bibliography" /><link href="10" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 直接对其进行地物分类易导致“维数灾难”问题。因此, 如何去除高光谱数据中的冗余信息, 挖掘高维数据的潜在本质特征, 提取低维鉴别表征, 已成为高光谱影像处理中的研究热点<citation id="166" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="55">维数约简 (dimensionality reduction, DR) 是解决这一问题的有效方法, 其目的是降低数据维数, 得到高维数据有意义的低维表示。近年来, 国内外学者提出了一系列维数约简方法, 并在许多领域取得了较好的效果。主成分分析 (principal component analysis, PCA) <citation id="167" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、线性判别分析 (linear discriminant analysis, LDA) <citation id="168" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>是基于线性子空间的常用方法, 但研究表明高光谱影像中存在着非线性的流形结构<citation id="169" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。流形学习方法能有效发现嵌入高维观测数据中的低维流形结构, 代表性方法主要有局部线性嵌入 (local linear embedding, LLE) <citation id="170" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、等距离映射 (isometric feature mapping, ISOMAP) <citation id="171" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和拉普拉斯特征映射 (Laplacian eigenmaps, LE) <citation id="172" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等。然而, 这些方法存在“样本外学习”的问题, 不能直接得到新样本的低维嵌入特征。为解决此问题, 学者对LLE和LE方法进行了线性近似, 提出了邻域保持嵌入 (neighborhood preserving embedding, NPE) <citation id="173" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和局部保持投影 (locality preserving projection, LPP) <citation id="174" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>等线性方法, 取得了不错的分类效果。</p>
                </div>
                <div class="p1">
                    <p id="56">上述维数约简方法仅通过利用高光谱数据的光谱信息来实现降维<citation id="175" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 但是高光谱遥感影像具有“图谱合一”的特点, 其空间相关性强, 即相邻像素点一般具有比较明显的区域一致性<citation id="179" type="reference"><link href="34" rel="bibliography" /><link href="36" rel="bibliography" /><link href="38" rel="bibliography" /><link href="40" rel="bibliography" /><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>。因此, 学者们开始融合高光谱数据的光谱信息和空间信息来提高地物分类性能<citation id="180" type="reference"><link href="44" rel="bibliography" /><link href="46" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>。文献<citation id="176" type="reference">[<a class="sup">24</a>]</citation>提出了一种基于空间一致性的邻域保持嵌入 (spatial coherence-neighborhood preserving embedding, SC-NPE) 算法。该算法通过比较每个像素点周围一定大小环块之间的距离来进行近邻选取, 然后通过一个优化的线性嵌入将原始数据映射到低维子空间。文献<citation id="177" type="reference">[<a class="sup">25</a>]</citation>提出了一种空间域的局部像素近邻保持嵌入 (local pixel neighborhood preserving embedding, LPNPE) 算法。其目标是寻找一个线性的映射矩阵, 使得投影之后局部像素的近邻保持散度矩阵最小化、总体散度矩阵最大化, 进而提升分类性能。文献<citation id="178" type="reference">[<a class="sup">26</a>]</citation>提出了一种鉴别空谱边界 (discriminate spectral-spatial margins, DSSM) 算法。该算法在每个像素点周围定义一定大小的局部空间区域, 通过比较该区域中同类地物与不同地物近邻点之间的差异来挖掘高光谱数据中的空间信息。上述空-谱联合方法在高光谱影像分类中都取得了较好的效果, 但仅局限于利用局部空间区域内中心像素与其周围像素之间的空间信息, 而忽略了流形重构过程中各像素点与其近邻点之间的空间信息, 这些空间信息对于地物分类依然有着重要的作用, 尤其在训练样本较少时更为明显。</p>
                </div>
                <div class="p1">
                    <p id="57">基于此, 本文提出了一种加权空-谱联合保持嵌入 (weighted spatial-spectral combined preserving embedding, WSCPE) 方法, 通过有效利用高光谱影像中的空间-光谱特征信息来提升分类效果。其主要思想是首先采用加权均值滤波 (weighted mean filter, WMF) 方法对高光谱影像进行空间滤波, 以消除噪点和背景点的干扰, 然后利用加权空-谱联合距离 (weighted spatial-spectral combined distance, WSCD) 得到各像素点的空-谱近邻点, 并根据各像素点与近邻点空间位置的远近给予不同的权重以进行流形重构, 提取出更为有效的鉴别特征, 实现高光谱数据降维。在PaviaU和Indian Pines高光谱数据集上的试验结果表明, 本文方法能够有效提取出高光谱遥感影像中各类地物的鉴别特征, 改善了地物分类性能。</p>
                </div>
                <h3 id="58" name="58" class="anchor-tag">1 NPE算法</h3>
                <div class="p1">
                    <p id="59">NPE算法是LLE算法的线性逼近, 通过投影矩阵将高维数据投影到低维空间后, 保持其局部近邻结构不变。遇有新样本时, 可利用得到的投影矩阵计算其嵌入特征。其具体算法步骤包括:</p>
                </div>
                <div class="p1">
                    <p id="60"> (1) 构建近邻图<b><i>G</i></b>。构建图<b><i>G</i></b>时可采用<i>K</i>近邻法或<i>ε</i>近邻法得到近邻, 若样本点<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>为近邻, 则在图<b><i>G</i></b>中用边连接;否则无边连接。</p>
                </div>
                <div class="p1">
                    <p id="61"> (2) 计算权重矩阵<b><i>W</i></b>。在高维空间中, <b><i>x</i></b><sub><i>i</i></sub>可由它的<i>k</i>个近邻点进行近似线性表示, 可通过最小化重构误差进行计算权重, 则</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>min</mi></mrow><mi>J</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>min</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mtd></mtr></mtable></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">式中, <b><i>w</i></b><sub><i>ij</i></sub>为<b><i>x</i></b><sub><i>i</i></sub>与<b><i>x</i></b><sub><i>j</i></sub>之间的权值, 若<b><i>x</i></b><sub><i>j</i></sub>为<b><i>x</i></b><sub><i>i</i></sub>的近邻点, 有<b><i>w</i></b><sub><i>ij</i></sub>≠0, 否则<b><i>w</i></b><sub><i>ij</i></sub>=0。</p>
                </div>
                <div class="p1">
                    <p id="64"> (3) 求解投影矩阵<b><i>A</i></b>。在高维空间中样本<b><i>x</i></b><sub><i>i</i></sub>能够由其近邻点及权重矩阵<b><i>W</i></b>进行线性重构, 那么其低维映射<b><i>y</i></b><sub><i>i</i></sub>也可以通过<b><i>W</i></b>进行重构。因此, 投影矩阵<b><i>A</i></b>可通过优化以下目标函数而得到</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtable columnalign="left"><mtr><mtd><mi>min</mi><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi mathvariant="bold-italic">w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mspace width="0.25em" /><mtext> </mtext><mtext>t</mtext><mtext>r</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">Μ</mi><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><mo>=</mo><mi mathvariant="bold-italic">Ι</mi></mtd></mtr></mtable><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式中, <b><i>M</i></b>= (<b><i>I</i></b>-<b><i>W</i></b>) (<b><i>I</i></b>-<b><i>W</i></b>) <sup>T</sup>;<b><i>I</i></b>=diag (1, …, 1) 为单位矩阵。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag">2 本文算法</h3>
                <div class="p1">
                    <p id="68">假设一个高光谱立方体可表示为<b><i>Z</i></b>∈<i>R</i><sup><i>D</i>×<i>l</i>×<i>w</i></sup>, 其中<i>l</i>、<i>w</i>分别为高光谱影像的长和宽, <i>D</i>为高光谱数据集的波段数。若高光谱数据集为<b><i>X</i></b>=[<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>N</i></sub>]∈<i>R</i><sup><i>D</i>×<i>N</i></sup>, <i>N</i>为高光谱影像中训练样本的个数, 对应的低维嵌入特征可表示为<b><i>Y</i></b>=<b><i>A</i></b><sup>T</sup><b><i>X</i></b>, <b><i>Y</i></b>∈<i>R</i><sup><i>N</i>×<i>d</i></sup>, <i>d</i>&lt;&lt;<i>D</i>, 其中<b><i>A</i></b>∈<i>R</i><sup><i>D</i>×<i>d</i></sup>为投影矩阵。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.1 <i>WMF</i>方法</h4>
                <div class="p1">
                    <p id="70">假设数据点<b><i>x</i></b><sub><i>i</i></sub>在原始高光谱影像中的位置坐标为 (<i>p</i><sub><i>i</i></sub>, <i>q</i><sub><i>i</i></sub>) , 那么以<b><i>x</i></b><sub><i>i</i></sub>为中心, 以<i>w</i> (<i>w</i>为正奇数) 为长和宽的近邻空间<i>Ω</i> (<b><i>x</i></b><sub><i>i</i></sub>) 可定义为</p>
                </div>
                <div class="area_img" id="181">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908009_18100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="73">由式 (3) 可得知, 近邻空间<i>Ω</i> (<b><i>x</i></b><sub><i>i</i></sub>) 中共包含<i>w</i>×<i>w</i>个像素, 定义除<b><i>x</i></b><sub><i>i</i></sub>之外的其余<i>w</i><sup>2</sup>-1个像素分别为<b><i>x</i></b><sub><i>i</i>1</sub>、<b><i>x</i></b><sub><i>i</i>2</sub>、…、<b><i>x</i></b><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo stretchy="false"> (</mo><mi>w</mi><msub><mrow></mrow><mo>-</mo></msub><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></msubsup></mrow></math></mathml>, 那么可利用这<i>w</i>×<i>w</i>个像素通过加权求和的方式对<b><i>x</i></b><sub><i>i</i></sub>进行重构, 得到重构像素<b><i>x</i></b>′<sub><i>i</i></sub>, 那么<b><i>x</i></b>′<sub><i>i</i></sub>可以表示为</p>
                </div>
                <div class="p1">
                    <p id="75"><mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>Ω</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>Ω</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mn>1</mn></mrow></munderover><mi>v</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mrow><mrow><mn>1</mn><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mn>1</mn></mrow></munderover><mi>v</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="77">式中, <i>v</i><sub><i>k</i></sub>为像素<b><i>x</i></b><sub><i>ik</i></sub>在重构过程中的权重, 可通过热核函数进行计算</p>
                </div>
                <div class="p1">
                    <p id="78"><i>v</i><sub><i>k</i></sub>=exp{-‖<b><i>x</i></b><sub><i>i</i></sub>-<b><i>x</i></b><sub><i>ik</i></sub>‖<sup>2</sup>/<i>d</i><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></math></mathml>}      (5) </p>
                </div>
                <div class="p1">
                    <p id="80">式中, <i>d</i><sub><i>i</i></sub>为近邻空间<i>Ω</i> (<b><i>x</i></b><sub><i>i</i></sub>) 中所有像素与中心像素<b><i>x</i></b><sub><i>i</i></sub>之间欧氏距离的平均值, 可表示为</p>
                </div>
                <div class="p1">
                    <p id="81"><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>w</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi></mrow></msub><mo stretchy="false">∥</mo></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="83">WMF方法通过控制参数<i>w</i>的大小来调节滤波窗口的大小, 其本质是通过衡量近邻空间中近邻像素与中心像素的光谱相似性来对中心像素进行重构。光谱越相似, 所计算出来的权重就越大;相反, 若光谱之间的差异越大, 其相应的权重就越小。因此, 该滤波方法能够有效地消除噪点和背景点的干扰, 使得滤波后的图像变得更加平滑。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">2.2 WSCPE算法</h4>
                <div class="p1">
                    <p id="85">传统NPE算法仅通过像素点之间的光谱相似性来进行近邻点选取, 忽略了空间信息。随后提出的SC-NPE算法虽然考虑了一定大小环块之内像素间的空间信息, 通过比较各像素点周围环块之间的差异来进行近邻选取, 但没有在流形重构过程中利用各像素点与其近邻点之间的空间信息。针对上述问题, 本文提出的加权空-谱联合保持嵌入方法 (WSCPE) 首先采用一种新的加权空-谱联合距离 (weighted spatial-spectral combined distance, WSCD) 来进行空谱近邻点的选取, 然后通过利用各像素点与其空谱近邻点之间的空间关系赋予各空谱近邻点更为合适的重构权重, 使得空间位置上越近的像素占据更大的权重, 反之权重较小, 进而得到空-谱鉴别特征, 提高分类性能。</p>
                </div>
                <div class="p1">
                    <p id="86">WSCD方法通过对WMF滤波前后的高光谱数据分别计算距离, 并对这两种距离进行加权求和以融合像素点的光谱信息和空间信息, 可有效度量像素点之间的近邻关系。该方法的具体实现过程如图1所示。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 加权空谱联合距离 (WSCD) 的流程" src="Detail/GetImg?filename=images/CHXB201908009_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 加权空谱联合距离 (WSCD) 的流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flow chart of weighted spatial-spectral combined distance (WSCD) </p>

                </div>
                <div class="p1">
                    <p id="88">对于任意两个像素点<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>, 采用WMF方法构造近邻空间对其进行线性重构, 得到融合空间近邻信息的重构像素<b><i>x</i></b>′<sub><i>i</i></sub>和<b><i>x</i></b>′<sub><i>j</i></sub>。在此, 定义<i>d</i> (<b><i>x</i></b>′<sub><i>i</i></sub>, <b><i>x</i></b>′<sub><i>j</i></sub>) 为重构像素<b><i>x</i></b>′<sub><i>i</i></sub>和<b><i>x</i></b>′<sub><i>j</i></sub>之间的欧氏距离、<i>d</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) 为原始像素<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>之间的欧氏距离, 则加权空-谱联合距离如式 (7) 所示</p>
                </div>
                <div class="p1">
                    <p id="89"><i>d</i><sub>WSCD</sub> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) =<i>td</i> (<b><i>x</i></b>′<sub><i>i</i></sub>, <b><i>x</i></b>′<sub><i>j</i></sub>) + (1-<i>t</i>) <i>d</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="90">式中, 0≤<i>t</i>≤1用于调节<i>d</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) 和<i>d</i> (<b><i>x</i></b>′<sub><i>i</i></sub>, <b><i>x</i></b>′<sub><i>j</i></sub>) 两种距离对于加权距离的贡献。</p>
                </div>
                <div class="p1">
                    <p id="91">此处用图2进一步说明不同近邻方法选择的区别。图2为光谱、空间、空-谱联合近邻选取方式示意图, 其中灰色圆圈代表中心像素, 黑实线连接的圆圈代表其选取的近邻点。图2 (a) 为光谱近邻选取, 仅考虑了光谱曲线的相似程度, 没有考虑地物一致性原则, 因此得到的近邻点来自于影像中较远的位置;图2 (b) 表示的是空间近邻选取, 由于只考虑了像素在空间位置上的远近关系, 因此得到的近邻点可能来自于不同的地物类别, 进而影响流形重构效果;图2 (c) 表示的是选择空-谱近邻选择, 通过利用加权空-谱联合距离, 综合考虑了像素间的光谱相似性以及空间远近关系, 因此能有效选择真实的近邻点进行流形重构。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 3种不同近邻点的选取" src="Detail/GetImg?filename=images/CHXB201908009_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 3种不同近邻点的选取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Distribution of three different neighbors</p>

                </div>
                <div class="p1">
                    <p id="93">获得空-谱近邻点后, 即可构建空-谱近邻图<b><i>G</i></b><sub>ss</sub> (<b><i>X</i></b>, <b><i>W</i></b><sub>ss</sub>) , <b><i>X</i></b>为图的顶点, <b><i>W</i></b><sub>ss</sub>为其权重矩阵。在图<b><i>G</i></b><sub>ss</sub>中, 若两点为近邻, 则需连接一条边, 否则不连接。根据真实地物成块分布的原则, 像素点的近邻点在高光谱图像中空间距离越近, 则它们属于同一类的可能性就越大, 其重构权重也应该越大;反之, 属于同一类的可能性就越小, 其重构权重也应该越小。因此, 为体现近邻样本的差异性, 本文通过引入像素坐标距离<i>d</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>来表征。在此定义<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>在原始图像中坐标分别为 (<i>p</i><sub><i>i</i></sub>, <i>q</i><sub><i>i</i></sub>) 和 (<i>p</i><sub><i>j</i></sub>, <i>q</i><sub><i>j</i></sub>) , 则其像素坐标距离<i>d</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>可以表示为</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup><mo>=</mo><mi>d</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="98">通过引入<i>d</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>, 式 (1) 中的目标函数可重新定义为</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><mi>J</mi><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo> (</mo><mrow><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn><mtext> </mtext><mo>∀</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∉</mo><mi>k</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><mi>J</mi><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><mfrac><mrow><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></mfrac></mrow></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn><mtext> </mtext><mo>∀</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∉</mo><mi>k</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">式中, (<b><i>x</i></b><sub><i>i</i></sub>-<b><i>x</i></b><sub><i>j</i></sub>) 与<i>d</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>分别为<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>之间的光谱距离和像素坐标距离, 则 (<b><i>x</i></b><sub><i>i</i></sub>-<b><i>x</i></b><sub><i>j</i></sub>) /<i>d</i><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>就成了<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>之间空间距离和光谱距离的综合性度量。与NPE算法相比, <b><i>x</i></b><sub><i>i</i></sub>的<i>k</i>个近邻点权重<i>w</i>′<sub><i>i</i>1</sub>、<i>w</i>′<sub><i>i</i>2</sub>、…、<i>w</i>′<sub><i>ik</i></sub>因<i>d</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></math></mathml>的引入得到不同程度的减小, 在空间位置上离<b><i>x</i></b><sub><i>i</i></sub>越近的近邻点, 其权重减小的幅度越小, 反之则减小的幅度越大, 实现对其权重的有效调节。</p>
                </div>
                <div class="p1">
                    <p id="105">通过化简, 式 (9) 中目标函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>min</mi></mrow><mi>J</mi><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo> (</mo><mrow><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">式中, <b><i>w</i></b>′<sub><i>i</i></sub>=[<b><i>w</i></b>′<sub><i>i</i>1</sub><b><i>w</i></b>′<sub><i>i</i>2</sub> … <b><i>w</i></b>′<sub><i>ik</i></sub>];</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mn>1</mn></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msubsup></mrow></mfrac></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msubsup></mrow></mfrac><mspace width="0.25em" /><mo>⋯</mo><mspace width="0.25em" /><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msubsup></mrow></mfrac></mrow><mo>]</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mn>1</mn></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msubsup></mrow></mfrac><mo>, </mo><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msubsup></mrow></mfrac><mo>, </mo><mo>⋯</mo><mo>, </mo></mrow></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109"><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>d</mi><msubsup><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>C</mtext><mtext>D</mtext></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msubsup></mrow></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup></mrow></math></mathml>表示<b><i>x</i></b><sub><i>i</i></sub>的第<i>k</i>个近邻点, <i>k</i>为<b><i>x</i></b><sub><i>i</i></sub>近邻点的总个数。</p>
                </div>
                <div class="p1">
                    <p id="111">为消除尺度因子的影响, 增加样本近邻点权重之和为1的约束条件, 目标函数进一步表示为</p>
                </div>
                <div class="area_img" id="182">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908009_18200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="114">然后, 利用拉格朗日乘子法对式 (11) 进行求解, 可得到</p>
                </div>
                <div class="p1">
                    <p id="115"><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi mathvariant="bold-italic">w</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>j</mi><mi>m</mi></mrow></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>p</mi><mi>q</mi></mrow></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mfrac></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="117">在得到空-谱近邻点的权重矩阵<b><i>W</i></b>′之后, 投影矩阵<b><i>A</i></b>可通过求解以下最优化问题得到</p>
                </div>
                <div class="area_img" id="183">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/CHXB201908009_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="120">式中, <b><i>M</i></b>′= (<b><i>I</i></b>-<b><i>W</i></b>′) (<b><i>I</i></b>-<b><i>W</i></b>′) <sup>T</sup>。利用拉格朗日乘子法对式 (13) 进行求解, 可得到</p>
                </div>
                <div class="p1">
                    <p id="121"><b><i>XM</i></b>′<b><i>X</i></b><sup>T</sup><b><i>A</i></b>=<i>λ</i><b><i>XX</i></b><sup>T</sup><b><i>A</i></b>⇒ (<b><i>XX</i></b><sup>T</sup>) <sup>-1</sup><b><i>XM</i></b>′<b><i>X</i></b><sup>T</sup><b><i>A</i></b>=<i>λ</i><b><i>A</i></b>      (14) </p>
                </div>
                <div class="p1">
                    <p id="122">通过式 (14) 求取广义特征值, 并对特征值进行升序排序, 则前<i>d</i>个特征值所对应的特征向量<b><i>a</i></b><sub>1</sub>、<b><i>a</i></b><sub>2</sub>、…、<b><i>a</i></b><sub><i>d</i></sub>就构成了投影矩阵<b><i>A</i></b>, 则高维数据的低维嵌入特征可表示为<b><i>Y</i></b>=<b><i>A</i></b><sup>T</sup><b><i>X</i></b>。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">2.3 <i>WSCPE</i>算法步骤</h4>
                <div class="p1">
                    <p id="124">输入:高光谱影像数据集<b><i>X</i></b>, 低维空间中的近邻个数<i>k</i>, 空间窗口<i>w</i>, 加权系数<i>t</i>。</p>
                </div>
                <div class="p1">
                    <p id="125">输出:映射向量<b><i>A</i></b>, 高光谱数据的低维嵌入特征<b><i>Y</i></b>=[<b><i>y</i></b><sub>1</sub><b><i>y</i></b><sub>2</sub><b><i>y</i></b><sub>3</sub> … <b><i>y</i></b><sub><i>N</i></sub>]∈<i>R</i><sup><i>N</i>×<i>d</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="126">步骤1:利用WMF算法对高光谱影像进行滤波。</p>
                </div>
                <div class="p1">
                    <p id="127">步骤2:在滤波后的样本集<b><i>X</i></b>中根据样本比例随机抽取得到训练样本集, 其余作为测试样本。</p>
                </div>
                <div class="p1">
                    <p id="128">步骤3:根据WSCD算法计算每个训练样本之间的欧氏距离, 并按照从小到大的顺序进行排列, 然后选取前<i>k</i>个距离对应的样本点作为其近邻点。</p>
                </div>
                <div class="p1">
                    <p id="129">步骤4:根据式 (10) 计算训练样本的权重矩阵<b><i>W</i></b>′。</p>
                </div>
                <div class="p1">
                    <p id="130">步骤5:保持权重矩阵<b><i>W</i></b>′不变, 根据式 (13) 求出映射向量<b><i>A</i></b>以及高维数据的低维表示<b><i>Y</i>=<i>A</i></b><sup>T</sup><b><i>X</i></b>。</p>
                </div>
                <h3 id="131" name="131" class="anchor-tag">3 试验结果与分析</h3>
                <h4 class="anchor-tag" id="132" name="132">3.1 试验数据集</h4>
                <div class="p1">
                    <p id="133">本文算法主要通过PaviaU和Indian Pines高光谱数据集进行试验论证, 下面对其进行简单介绍。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"> (1) PaviaU数据集:</h4>
                <div class="p1">
                    <p id="135">该数据集由西班牙巴斯克大学提供, 主要采集于意大利北部的帕维亚大学区域, 并且已经对草地、泥土和沥青等9类地物的样本类别进行了事先标注。影像大小为610×340 pixels, 空间分辨率为1.3 m, 共包含115个波段。由于其中包含的12个波段受水汽的影响较为严重, 一般只用其余的103个波段进行研究。图3 (a) 、图3 (b) 分别为PaviaU数据集的假彩色图和真实地物分布图, 其中括号中的数值表示每类地物的样本总数。</p>
                </div>
                <h4 class="anchor-tag" id="136" name="136"> (2) Indian Pines数据集:</h4>
                <div class="p1">
                    <p id="137">该数据集由美国国家宇航局提供, 主要采集于美国西北部印第安纳松林, 并且事先已经对森林、植被和房屋等16类地物的样本类别进行了事先标注。影像大小为145×145 pixels, 空间分辨率为20 m, 共包含220个波段。由于其中包含的20个波段受水汽的影响较为严重, 一般只用其余的200个波段进行研究。图3 (c) 、图3 (d) 分别为Indian Pines数据集的假彩色图、真实地物分布图, 其中括号中的数值表示每类地物的样本总数。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 高光谱图像" src="Detail/GetImg?filename=images/CHXB201908009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 高光谱图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Hyperspectral image</p>

                </div>
                <h4 class="anchor-tag" id="139" name="139">3.2 试验设置</h4>
                <div class="p1">
                    <p id="140">由于高光谱遥感数据中不同波段的数据范围不一致, 为了降低不同数据范围对降维的影响, 首先对其按波段分别进行归一化处理。在每次试验中, 高光谱数据集被随机划分为训练样本和测试样本, 利用训练数据得到投影矩阵后, 可将样本投影到嵌入空间得到低维特征, 利用最近邻分类器 (1-nearest neighbor, 1-NN) 进行分类, 并采用总体分类精度 (overall accuracy, OA) 、平均分类精度 (average accuracy, AA) 、Kappa系数3个参数对分类结果进行评价。为了保证试验结果的可靠性, 每种条件下的试验均重复进行10次, 并取10次结果的平均值作为最终试验结果。</p>
                </div>
                <div class="p1">
                    <p id="141">为了论证本文方法在提取高光谱数据集鉴别特征的有效性, 试验中选取RAW (表示直接利用原始光谱数据) 、PCA、LDA、LPP、NPE、LFDA、DSSM、SC-NPE和LPNPE与本文算法进行对比, 其中PCA、LDA、LPP、NPE、LFDA方法仅利用了高光谱数据的光谱信息, 而DSSM、SC-NPE、LPNPE等空-谱联合方法则融合了影像的光谱-空间信息。另外, 为使LPP、NPE、SC-NPE、LPNPE等方法达到较好的效果, 将其参数调整为最佳, 低维嵌入特征维数为40维。LDA算法特征维数为<i>c</i>-1维, 其中<i>c</i>为类别数。为使WSCPE算法取得最优的近邻数, 本文分别从PaviaU和Indian Pines数据集中的从每类地物中随机选取30个样本用于训练, 其余样本用于测试, 图4为对应的试验结果。由图4可知, 在PaviaU数据集上可选择<i>k</i>=10, 在Indian Pines数据集上可选择<i>k</i>=20。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 WSCPE在不同k下的分类结果" src="Detail/GetImg?filename=images/CHXB201908009_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 WSCPE在不同<i>k</i>下的分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Classification result of WSCPE with different <i>k</i></p>

                </div>
                <h4 class="anchor-tag" id="143" name="143">3.3 PaviaU试验结果</h4>
                <div class="p1">
                    <p id="144">为研究窗口大小<i>w</i>和权重因子<i>t</i>对WSCPE算法性能的影响, 首先选用PaviaU数据集进行试验。试验中, 从每类地物中随机选取30个样本用于训练, 其余样本用于测试, 窗口大小<i>w</i>的变化范围为1、3、5、…、31, 权重因子<i>t</i>的变化范围为0、0.1、0.2、…、1。图5为WSCPE算法在不同窗口大小和权重因子下的分类精度。</p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 PaviaU数据集中WSCPE 在不同w和t下的分类结果" src="Detail/GetImg?filename=images/CHXB201908009_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 PaviaU数据集中WSCPE 在不同<i>w</i>和<i>t</i>下的分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Classification result of WSCPE with different <i>w</i> and <i>t</i> on PaviaU dataset</p>

                </div>
                <div class="p1">
                    <p id="146">由图5可知, 随着窗口<i>w</i>的增大, 本文算法的分类精度随之增加;当<i>w</i>增大到5×5时, 增幅开始逐渐减小;当<i>w</i>增大到11×11左右时出现分类精度的峰值;当<i>w</i>继续增大时, 分类精度略有下降。这是由于当空间窗口包含了更多的空间近邻时, 可利用的空间信息更加丰富, 因而能够更好地区分不同地物, 提高分类精度。然而, 如果选用的窗口太大, 得到的近邻点中就会包含来自于其他地物类别的像素点, 因此会影响分类性能。综合考虑到算法分类精度以及运行效率, 本文选取<i>w</i>=11, <i>t</i>=0.3。</p>
                </div>
                <div class="p1">
                    <p id="147">为评估不同算法在不同数目训练样本下的分类性能, 从PaviaU数据集中的每类地物中分别随机选取30、40、50、60个样本用于训练, 其余样本用于测试。表1为不同数目训练样本下的分类结果。</p>
                </div>
                <div class="area_img" id="148">
                    <p class="img_tit"><b>表1 PaviaU数据集上不同算法的分类结果 (总体分类精度</b>±<b>标准差</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.1 Classification results of different algorithms on PaviaU dataset (overall accuracy</b>±<b>STD</b>) </p>
                    <p class="img_note">（%）</p>
                    <table id="148" border="1"><tr><td rowspan="2"><br />algorithm</td><td colspan="4"><br />样本数量</td></tr><tr><td><br />30</td><td>40</td><td>50</td><td>60</td></tr><tr><td><br />RAW</td><td>81.02±1.24</td><td>83.06±0.75</td><td>85.29±0.86</td><td>87.35±0.42</td></tr><tr><td><br />PCA</td><td>81.02±1.25</td><td>83.06±0.75</td><td>85.27±0.83</td><td>87.32±0.41</td></tr><tr><td><br />NPE</td><td>84.95±1.42</td><td>86.07±0.85</td><td>87.95±1.34</td><td>89.53±1.11</td></tr><tr><td><br />LPP</td><td>85.35±1.44</td><td>87.11±1.59</td><td>89.57±1.61</td><td>91.17±0.75</td></tr><tr><td><br />LDA</td><td>90.80±1.14</td><td>92.44±1.20</td><td>94.36±1.00</td><td>95.20±0.30</td></tr><tr><td><br />LFDA</td><td>90.54±1.17</td><td>92.53±1.28</td><td>93.38±1.58</td><td>94.57±0.85</td></tr><tr><td><br />DSSM</td><td>82.16±1.31</td><td>84.23±1.36</td><td>86.56±1.28</td><td>88.51±1.32</td></tr><tr><td><br />SC-NPE</td><td>85.13±1.45</td><td>86.96±1.23</td><td>88.63±1.15</td><td>90.66±1.27</td></tr><tr><td><br />LPNPE</td><td>91.81±1.27</td><td>93.26±1.25</td><td>94.29±1.32</td><td>95.30±1.25</td></tr><tr><td><br />WSCPE</td><td><b>92.35</b>±1.22</td><td><b>94.36</b>±1.29</td><td><b>96.48</b>±0.92</td><td><b>97.06</b>±1.33</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="149">由表1可知, 随着训练样本数量的增加, 各种算法的分类精度随之提升, 这是由于更多的训练样本包含了更丰富的先验信息, 更有利于特征提取。在基于光谱特征的维数约简方法中, LDA、LFDA这两种监督算法通过利用训练样本的类别标记信息, 其分类精度要明显优于PCA、NPE、LPP等非监督算法。同时, 在空-谱联合维数约简方法中, WSCPE算法的分类精度要高于DSSM、SC-NPE、LPNPE方法, 并且在各种试验条件下均取得了最好的分类效果。这是因为WSCPE算法分别在近邻点选取和流形重构过程进行了空间信息的挖掘, 使得得到的鉴别特征更为丰富和有效, 进而提升了分类精度。</p>
                </div>
                <div class="p1">
                    <p id="150">为分析各算法在每类地物上的分类性能, 试验中随机选取2%的样本用于训练, 其余样本用于测试, 得到PaviaU数据集中每类地物的分类精度、总体分类精度 (OA) 、平均分类精度 (AA) 和Kappa系数如表2所示。图6为其相对应的分类结果图。</p>
                </div>
                <div class="area_img" id="151">
                    <p class="img_tit"><b>表2 PaviaU数据集中各类地物在不同算法下的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.2 Classification results of various ground objects in PaviaU dataset under different algorithms</b></p>
                    <p class="img_note">（%）</p>
                    <table id="151" border="1"><tr><td><br />class</td><td>train</td><td>test</td><td>RAW</td><td>PCA</td><td>NPE</td><td>LPP</td><td>LDA</td><td>LFDA</td><td>DSSM</td><td>SCNPE</td><td>LPNPE</td><td>WSCPE</td></tr><tr><td><br />1</td><td>133</td><td>6498</td><td>93.72</td><td>93.72</td><td>94.70</td><td>97.16</td><td>95.93</td><td><b>97.47</b></td><td>93.75</td><td>93.93</td><td>96.83</td><td>97.19</td></tr><tr><td><br />2</td><td>373</td><td>18 276</td><td>97.03</td><td>97.03</td><td>97.29</td><td>99.33</td><td>99.57</td><td>99.21</td><td>97.03</td><td>98.01</td><td><b>99.93</b></td><td><b>99.93</b></td></tr><tr><td><br />3</td><td>42</td><td>2057</td><td>80.55</td><td>80.51</td><td>85.66</td><td>94.89</td><td>87.46</td><td>88.52</td><td>80.55</td><td>84.83</td><td>89.16</td><td><b>95.65</b></td></tr><tr><td><br />4</td><td>61</td><td>3003</td><td>84.38</td><td>84.38</td><td>85.21</td><td>81.61</td><td><b>96.43</b></td><td>94.70</td><td>85.72</td><td>88.75</td><td>88.54</td><td>92.70</td></tr><tr><td><br />5</td><td>27</td><td>1318</td><td>99.46</td><td>99.46</td><td>95.47</td><td>99.62</td><td>99.46</td><td>99.62</td><td>99.54</td><td>99.54</td><td><b>99.73</b></td><td>99.17</td></tr><tr><td><br />6</td><td>101</td><td>4928</td><td>88.51</td><td>88.48</td><td>88.02</td><td>97.56</td><td>96.75</td><td>97.28</td><td>89.12</td><td>91.29</td><td>99.42</td><td><b>99.83</b></td></tr><tr><td><br />7</td><td>27</td><td>1303</td><td>84.11</td><td>84.03</td><td>88.03</td><td>99.53</td><td><b>100.00</b></td><td>98.69</td><td>84.17</td><td>91.17</td><td>93.78</td><td><b>100.00</b></td></tr><tr><td><br />8</td><td>74</td><td>3608</td><td>93.93</td><td>93.93</td><td>83.74</td><td>95.67</td><td>93.51</td><td>93.54</td><td>94.15</td><td>94.01</td><td>91.71</td><td><b>95.99</b></td></tr><tr><td><br />9</td><td>19</td><td>928</td><td>99.89</td><td>99.89</td><td>99.89</td><td>99.89</td><td>99.89</td><td><b>100.00</b></td><td>99.89</td><td>99.89</td><td>79.96</td><td><b>100.00</b></td></tr><tr><td><br />OA</td><td>—</td><td>—</td><td>92.15</td><td>92.14</td><td>92.41</td><td>95.75</td><td>97.12</td><td>97.75</td><td>93.12</td><td>94.81</td><td>96.74</td><td><b>98.89</b></td></tr><tr><td><br />AA</td><td>—</td><td>—</td><td>91.29</td><td>91.28</td><td>92.44</td><td>94.30</td><td>96.58</td><td>96.56</td><td>91.35</td><td>93.49</td><td>95.50</td><td><b>97.36</b></td></tr><tr><td><br />Kappa</td><td>—</td><td>—</td><td>91.05</td><td>91.04</td><td>91.87</td><td>96.38</td><td>96.51</td><td>96.54</td><td>91.48</td><td>93.10</td><td>96.59</td><td><b>98.21</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 各算法在PaviaU数据集上的分类结果" src="Detail/GetImg?filename=images/CHXB201908009_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 各算法在PaviaU数据集上的分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Classification results of different algorithms on PaviaU data set</p>

                </div>
                <div class="p1">
                    <p id="153">由表2知, WSCPE算法在大多数类别上都取得了较好的分类结果, 尤其是在“gravel”“soil”“bitumen”等区域更为明显, 这是因为WSCPE算法在近邻点选取和权重矩阵计算两个过程均引入了像素的空间信息, 可有效避免来自不同地物类别中具有相似光谱特征的像素点的影响, 因此空间信息的引入可以更好地表征数据本身的内在属性, 使得到的鉴别特征更有效地反映出不同地物类别间的本质差异。另外, 从图6可以看出, 与其他方法相比, WSCPE的分类结果图更为平滑, 错分点更少。</p>
                </div>
                <h4 class="anchor-tag" id="154" name="154">3.4 Indian Pines试验结果</h4>
                <div class="p1">
                    <p id="155">试验中, 分别从Indian pines数据集每类地物中随机选取30个样本用于训练, 剩余样本用于测试。首先对窗口大小<i>w</i>和权重因子<i>t</i>这两个参数进行试验, 其中<i>w</i>的变化范围为1、3、5、…、35, <i>t</i>的变化范围为0、0.1、0.2、…、1。图7为WSCPE算法的分类精度在不同<i>w</i>和<i>t</i>下的试验结果。由于窗口增大到11×11时, 算法分类精度已基本稳定, 因此在综合考虑到算法分类精度以及算法运行效率的情况下, 这里选取<i>w</i>=11, <i>t</i>=0.5。</p>
                </div>
                <div class="area_img" id="156">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 Indian Pines数据集中WSCPE在不同w和t下的分类结果" src="Detail/GetImg?filename=images/CHXB201908009_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 Indian Pines数据集中WSCPE在不同<i>w</i>和<i>t</i>下的分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Classification result of WSCPE with different <i>w</i> and <i>t</i> on Indian Pines dataset</p>

                </div>
                <div class="p1">
                    <p id="157">表3为Indian Pines数据集中各算法在不同数目训练样本下的分类结果。可以看出各种算法的分类精度随着训练样本个数的增加而递增, 同时WSCPE算法始终取得了最好的分类效果。这是因为WSCPE充分利用高光谱影像的空间一致性原则, 将光谱信息和空间信息进行有效的结合, 发现高光谱数据内部的鉴别子流形结构, 有效提取表征不同地物差异的鉴别特征, 从而提升了地物分类效果。</p>
                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表3 Indian Pines数据集上不同算法的分类结果 (总体分类精度</b>±<b>标准差</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.3 Classification results of different algorithms on Indian Pines dataset (overall accuracy</b>±<b>STD</b>) </p>
                    <p class="img_note">（%）</p>
                    <table id="158" border="1"><tr><td rowspan="2"><br />algorithm</td><td colspan="4"><br />样本数量</td></tr><tr><td><br />30</td><td>40</td><td>50</td><td>60</td></tr><tr><td><br />RAW</td><td>78.30±1.04</td><td>81.12±1.62</td><td>83.60±0.74</td><td>84.92±0.36</td></tr><tr><td><br />PCA</td><td>78.23±1.06</td><td>81.01±1.66</td><td>83.52±0.77</td><td>84.79±0.36</td></tr><tr><td><br />NPE</td><td>79.48±1.20</td><td>82.41±1.90</td><td>84.18±1.33</td><td>85.43±0.71</td></tr><tr><td><br />LPP</td><td>80.02±0.46</td><td>82.95±1.72</td><td>86.35±1.06</td><td>88.23±0.63</td></tr><tr><td><br />LDA</td><td>93.06±0.81</td><td>94.67±1.16</td><td>96.30±1.30</td><td>96.93±0.70</td></tr><tr><td><br />LFDA</td><td>90.82±0.71</td><td>93.29±1.37</td><td>94.94±0.91</td><td>95.71±0.42</td></tr><tr><td><br />DSSM</td><td>80.19±0.65</td><td>84.13±0.81</td><td>85.42±0.94</td><td>86.49±0.41</td></tr><tr><td><br />SC-NPE</td><td>80.25±0.51</td><td>83.98±0.74</td><td>85.64±0.93</td><td>87.56±0.39</td></tr><tr><td><br />LPNPE</td><td>91.91±0.64</td><td>93.94±0.69</td><td>94.83±0.92</td><td>96.01±0.81</td></tr><tr><td><br />WSCPE</td><td><b>93.54</b>±1.03</td><td><b>95.62</b>±1.15</td><td><b>97.37</b>±0.56</td><td><b>98.19</b>±0.73</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="159">表4为随机选取3%的训练样本, 其余作为测试样本的情况下, 在Indian Pines数据集中的不同地物在不同算法下的分类精度, 图8为其相对应的分类结果图。可得知, WSCPE算法的总体分类精度、平均分类精度以及Kappa系数均高于其他算法。同时从图8中的分类结果图也可看出, WSCPE算法的分类结果图较为平滑, 分类效果较好, 尤其在“hay-windowed”“soybeans-notill”“wheat”区域更为明显, 更加证明了本文算法的有效性。</p>
                </div>
                <h3 id="160" name="160" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="161">针对传统降维算法单一利用光谱信息, 未考虑高光谱影像内部空间结构, 提取得到的鉴别特征不够充分有效的问题, 本文基于流形学习方法和空间一致性原则, 提出一种加权空-谱联合保持嵌入 (WSCPE) 方法。该方法有效融合影像中的空间-光谱信息, 通过加权空-谱距离选择得到各像素点的空-谱近邻, 并在流形重构过程中根据各像素点与近邻点空间位置的远近给予不同的权重, 提取出更为有效的鉴别特征, 进而实现维数约简。在PaviaU和Indian Pines高光谱数据集上的试验结果表明, 本文算法可有效提取高光谱遥感影像中各类地物的鉴别特征, 改善了地物分类性能, 在较少训练样本的情况下其总体分类精度分别达到了98.89%和95.47%。与传统基于光谱以及空-谱联合的降维算法相比, 本文提出的WSCPE算法的分类精度有了明显地提升。</p>
                </div>
                <div class="area_img" id="162">
                    <p class="img_tit"><b>表4 Indian Pines数据集中各类地物在不同算法下的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Tab.4 Classification results of various ground objects in Indian Pines dataset under different algorithms</b></p>
                    <p class="img_note"> (%) </p>
                    <table id="162" border="1"><tr><td><br />class</td><td>train</td><td>test</td><td>RAW</td><td>PCA</td><td>NPE</td><td>LPP</td><td>LDA</td><td>LFDA</td><td>DSSM</td><td>SCNPE</td><td>LPNPE</td><td>WSCPE</td></tr><tr><td><br />1</td><td>10</td><td>36</td><td>94.44</td><td>94.44</td><td>99.89</td><td>99.89</td><td><b>100.00</b></td><td>99.89</td><td>97.22</td><td>99.89</td><td><b>100.00</b></td><td><b>100.00</b></td></tr><tr><td><br />2</td><td>43</td><td>1385</td><td>66.57</td><td>66.57</td><td>77.40</td><td>71.84</td><td>92.71</td><td>91.41</td><td>76.75</td><td>71.19</td><td><b>94.44</b></td><td>94.30</td></tr><tr><td><br />3</td><td>25</td><td>805</td><td>73.29</td><td>72.79</td><td>75.65</td><td>66.96</td><td>82.61</td><td>79.63</td><td>78.21</td><td>76.65</td><td>80.87</td><td><b>94.78</b></td></tr><tr><td><br />4</td><td>10</td><td>227</td><td>72.69</td><td>72.68</td><td>67.40</td><td>70.48</td><td>95.15</td><td>92.07</td><td>71.75</td><td>74.89</td><td>94.71</td><td><b>99.12</b></td></tr><tr><td><br />5</td><td>14</td><td>469</td><td>78.89</td><td>78.89</td><td><b>89.77</b></td><td>85.71</td><td>87.21</td><td>87.42</td><td>84.36</td><td>82.73</td><td>84.43</td><td>85.71</td></tr><tr><td><br />6</td><td>22</td><td>708</td><td>95.33</td><td>95.34</td><td>98.16</td><td>94.63</td><td>98.16</td><td>95.34</td><td>95.19</td><td>93.50</td><td><b>98.73</b></td><td>92.51</td></tr><tr><td><br />7</td><td>10</td><td>18</td><td>99.96</td><td>99.96</td><td>99.12</td><td>99.96</td><td><b>100.00</b></td><td><b>100.00</b></td><td>99.96</td><td>99.05</td><td>99.96</td><td><b>100.00</b></td></tr><tr><td><br />8</td><td>14</td><td>464</td><td>97.63</td><td>97.84</td><td>91.38</td><td>85.34</td><td>99.57</td><td>98.71</td><td>98.89</td><td>99.57</td><td>93.53</td><td><b>100.00</b></td></tr><tr><td><br />9</td><td>10</td><td>10</td><td>99.89</td><td>99.89</td><td>99.89</td><td><b>100.00</b></td><td>99.89</td><td>99.89</td><td>80.00</td><td><b>100.00</b></td><td>99.89</td><td><b>100.00</b></td></tr><tr><td><br />10</td><td>29</td><td>943</td><td>78.68</td><td>78.58</td><td>86.43</td><td>82.08</td><td>88.76</td><td>80.81</td><td>86.43</td><td>75.19</td><td>84.94</td><td><b>90.56</b></td></tr><tr><td><br />11</td><td>74</td><td>2381</td><td>86.09</td><td>85.93</td><td>89.67</td><td>83.45</td><td>97.35</td><td>95.72</td><td>88.60</td><td>89.71</td><td>95.55</td><td>96.72</td></tr><tr><td><br />12</td><td>18</td><td>575</td><td>62.43</td><td>62.09</td><td>71.83</td><td>55.13</td><td>86.78</td><td>78.78</td><td>62.30</td><td>61.39</td><td>88.35</td><td>89.74</td></tr><tr><td><br />13</td><td>10</td><td>195</td><td>93.33</td><td>93.33</td><td>96.92</td><td>97.95</td><td><b>100.00</b></td><td><b>100.00</b></td><td>98.96</td><td>93.33</td><td>99.49</td><td><b>100.00</b></td></tr><tr><td><br />14</td><td>38</td><td>1227</td><td>96.41</td><td>96.33</td><td>96.82</td><td>94.78</td><td>98.53</td><td>96.98</td><td>97.98</td><td><b>99.67</b></td><td>91.52</td><td>98.86</td></tr><tr><td><br />15</td><td>12</td><td>374</td><td>69.79</td><td>69.79</td><td>82.09</td><td>71.93</td><td>95.19</td><td>89.57</td><td>73.40</td><td>86.36</td><td>98.40</td><td><b>98.93</b></td></tr><tr><td><br />16</td><td>10</td><td>83</td><td>96.39</td><td>96.39</td><td>96.39</td><td>97.59</td><td><b>100.00</b></td><td>98.80</td><td>93.98</td><td>96.39</td><td>92.77</td><td>98.80</td></tr><tr><td><br />OA</td><td></td><td></td><td>81.76</td><td>81.65</td><td>86.51</td><td>80.89</td><td>93.86</td><td>91.12</td><td>85.60</td><td>84.39</td><td>92.15</td><td><b>95.47</b></td></tr><tr><td><br />AA</td><td></td><td></td><td>85.12</td><td>85.06</td><td>88.74</td><td>84.87</td><td>93.42</td><td>92.83</td><td>86.48</td><td>87.54</td><td>93.61</td><td><b>96.25</b></td></tr><tr><td><br />Kappa</td><td></td><td></td><td>79.18</td><td>79.05</td><td>84.61</td><td>78.21</td><td>92.97</td><td>89.82</td><td>83.58</td><td>82.10</td><td>90.93</td><td><b>94.38</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="163">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CHXB201908009_163.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 各算法在Indian Pines数据集上的分类结果" src="Detail/GetImg?filename=images/CHXB201908009_163.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 各算法在Indian Pines数据集上的分类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CHXB201908009_163.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Classification results of different algorithms on Indian Pines data set</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201608012&amp;v=MTgxNDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyaFc3ek9KaVhUYkxHNEg5Zk1wNDlFWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 黄鸿, 郑新磊.高光谱影像空-谱协同嵌入的地物分类算法[J].测绘学报, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.HUANG Hong, ZHENG Xinlei.Hyperspectral image land cover classification algorithm based on spatial-spectral coordination embedding[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (8) :964-972.DOI:10.11947/j.AGCS.2016.20150654.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hyperspectral image classification with robust sparse representation">

                                <b>[2]</b> LI Chang, MA Yong, MEI Xiaoguang, et al.Hyperspectral image classification with robust sparse representation[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (5) :641-645.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A dual-layer supervised Mahalanobis kernel for the classification of hyperspectral images">

                                <b>[3]</b> LI Li, SUN Chao, LIN Lianlei, et al.A dual-layer supervised Mahalanobis kernel for the classification of hyperspectral images[J].Neurocomputing, 2016, 214:430-444.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD15081800000389&amp;v=Mjg2MDZud1plWnRGaW5sVTc3SUlsb2NhUlE9TmlmRGFySzlIdG5OcDQ5RlpPc1BEM1F3b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> HU Wei, HUANG Yangyu, WEI Li, et al.Deep convolutional neural networks for hyperspectral image classification[J].Journal of Sensors, 2015 (2) :1-12.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201703019&amp;v=MTkxMTlHRnJDVVI3cWZadWR2RnlyaFc3ek9KaVhUYkxHNEg5Yk1ySTlFYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 罗甫林.高光谱图像稀疏流形学习方法研究[J].测绘学报, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.LUO Fulin.Sparse manifold learning for hyperspectral imagery[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (3) :400.DOI:10.11947/j.AGCS.2017.20160621.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201709005&amp;v=MDA5NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadWR2RnlyaFc3ek9KaVhUYkxHNEg5Yk1wbzlGWVk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 侯榜焕, 王锟, 姚敏立, 等.面向高光谱图像分类的半监督空谱判别分析[J].测绘学报, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.HOU Banghuan, WANG Kun, YAO Minli, et al.Semi-supervised spatial-spectral discriminant analysis for hyperspectral image classification[J].Acta Geodaetica et Cartographica Sinica, 2017, 46 (9) :1098-1106.DOI:10.11947/j.AGCS.2017.20170121.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8395EAF1B37D9747B0530A12EB87CA3F&amp;v=MjMxNTRwbWFCdUhZZk9HUWxmQnJMVTA1OWxoeHJ5M3c2ND1OaWZPZmJ1N0Y5UzUzdmxFRnVnSWVIVSt5eEZoNmpwK1NBN2pybWRIY2JYbk5MbnBDT052RlNpV1dyN0pJRg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> HUANG Hong, LUO Fulin, LIU Jiamin, et al.Dimensionality reduction of hyperspectral images based on sparse discriminant manifold embedding[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 106 (3) :42-54.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA5E38BE2F4925032F62A0263D85018AB&amp;v=Mjg4MzZmTEtWVGN2dENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNTlsaHhyeTN3NjQ9TmlmT2ZjSzlhOUxFM2ZwSEV1OEdEbms1ekJSbDdEME1TSDNrcjJZOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> BONIFAZI G, CAPOBIANCO G, SERRANTI S.Asbestos containing materials detection and classification by the use of hyperspectral imaging[J].Journal of Hazardous Materials, 2018, 344 (4) :981-993.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semisupervised Local Discriminant Analysis for Feature Extraction in Hyperspectral Images">

                                <b>[9]</b> LIAO Wenzhi, PIZURICA A, SCHEUNDERS P, et al.Semisupervised local discriminant analysis for feature extraction in hyperspectral images[J].IEEE Transactions on Geoscience and Remote Sensing, 2013, 51 (1) :184-198.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction of hyperspectral images with sparse discriminant embedding">

                                <b>[10]</b> HUANG Hong, YANG Mei.Dimensionality reduction of hyperspectral images with sparse discriminant embedding[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (9) :5160-5169.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparsity divergence index based on locally linear embedding for hyperspectral anomaly detection">

                                <b>[11]</b> ZHANG Lili, ZHAO Chunhui.Sparsity divergence index based on locally linear embedding for hyperspectral anomaly detection[J].Journal of Applied Remote Sensing, 2016, 10 (2) :025026.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPU parallel implementation of isometric mapping for hyperspectral classification">

                                <b>[12]</b> LI Wan, ZHANG Liangpei, ZHANG Lefei, et al.GPU parallel implementation of isometric mapping for hyperspectral classification[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (9) :1532-1539.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGB3285380E97CABB23DEB810CA1AB734A&amp;v=MTYyMDNKcklkRkVlSUlmdzFMdlJRUW5rb1BRSDdpMzJNMENNQ1RScjd1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1OWxoeHJ5M3c2ND1OaWZPYWNHN0hObg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> DORADO-MUNOZ L P, MESSINGER D W.Initial study of Schroedinger eigenmaps for spectral target detection[J].Optical Engineering, 2016, 55 (8) :083101.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminant collaborative neighborhood preserving embedding for hyperspectral imagery">

                                <b>[14]</b> LÜ Meng, ZHAO Xinbin, LIU Liming, et al.Discriminant collaborative neighborhood preserving embedding for hyperspectral imagery[J].Journal of Applied Remote Sensing, 2017, 11 (4) :046004.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images">

                                <b>[15]</b> DENG Yangjun, LI Hengchao, PAN Lei, et al.Modified tensor locality preserving projection for dimensionality reduction of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2018, 15 (2) :277-281.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature Extraction of Hyperspectral Images with Semisupervised Graph Learning">

                                <b>[16]</b> LUO Renbo, LIAO Wenzhi, HUANG Xin, et al.Feature extraction of hyperspectral images with semisupervised graph learning[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2016, 9 (9) :4389-4399.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF4A3A86F18BCCB099D0CCAAD78F90CB6&amp;v=MTY3MjBZZk9HUWxmQnJMVTA1OWxoeHJ5M3c2ND1OaWZPZmNXOGI5SzlwNGt6WmVOOWZ3OUx6eDhhbmo4T093NlQyQlU5RDd1VU5zaVpDT052RlNpV1dyN0pJRnBtYUJ1SA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> TAN Kun, HU Jun, LI Jun, et al.A novel semi-supervised hyperspectral image classification approach based on spatial neighborhood information and classifier combination[J].ISPRS Journal of Photogrammetry and Remote Sensing, 2015, 105 (5) :19-29.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Orthogonal Nonnegative Matrix Factorization Combining Multiple Features for Spectral-Spatial Dimensionality Reduction of Hyperspectral Imagery">

                                <b>[18]</b> WEN Jinhua, FOWLER J E, HE Mingyi, et al.Orthogonal nonnegative matrix factorization combining multiple features for spectral-spatial dimensionality reduction of hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (7) :4272-4286.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial classification of hyperspectral images using ICA and edgepreserving filter via an ensemble strategy">

                                <b>[19]</b> XIA Junshi, BOMBRUN L, ADALI T, et al.Spectral-spatial classification of hyperspectral images using ICA and edge-preserving filter via an ensemble strategy[J].IEEE Transactions on Geoscience and Remote Sensing, 2016, 54 (8) :4971-4982.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial Classification for Hyperspectral Data Using Rotation Forests with Local Feature Extraction and Markov Random Fields">

                                <b>[20]</b> XIA Junshi, CHANUSSOT J, DU Peijun, et al.Spectral-spatial classification for hyperspectral data using rotation forests with local feature extraction and Markov random fields[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (5) :2532-2546.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatially coherent interpretations of videos using pattern theory">

                                <b>[21]</b> DE SOUZA F D M, SARKAR S, SRIVASTAVA A, et al.Spatially coherent interpretations of videos using pattern theory[J].International Journal of Computer Vision, 2017, 121 (1) :5-25.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-Spatial classification of hyperspectral images using deep convolutional neural networks">

                                <b>[22]</b> YUE Jun, ZHAO Wenzhi, MAO Shanjun, et al.Spectral-spatial classification of hyperspectral images using deep convolutional neural networks[J].Remote Sensing Letters, 2015, 6 (6) :468-477.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial hyperspectral image classification using,regularized low-rank representation and sparse representation-based graph cuts">

                                <b>[23]</b> JIA Sen, ZHANG Xiujun, LI Qingquan.Spectral-spatial hyperspectral image classification using ℓ<sub>1/2</sub> regularized low-rank representation and sparse representation-based graph cuts[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2015, 8 (6) :2473-2484.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201205025&amp;v=MTk1MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoVzd6T0xUclNaTEc0SDlQTXFvOUhZWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> 魏峰, 何明一, 梅少辉.空间一致性邻域保留嵌入的高光谱数据特征提取[J].红外与激光工程, 2012, 41 (5) :1249-1254.WEI Feng, HE Mingyi, MEI Shaohui.Hyperspectral data feature extraction using spatial coherence based neighborhood preserving embedding[J].Infrared and Laser Engineering, 2012, 41 (5) :1249-1254.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimension Reduction Using Spatial and Spectral Regularized Local Discriminant Embedding for Hyperspectral Image Classification">

                                <b>[25]</b> ZHOU Yicong, PENG Jiangtao, CHEN C L P.Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2015, 53 (2) :1082-1095.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative spectral-spatial margin-based semi-supervised dimensionality reduction of hyperspectral data">

                                <b>[26]</b> FENG Zhixi, YANG Shuyuan, WANG Shigang, et al.Discriminative spectral-spatial margin-based semisupervised dimensionality reduction of hyperspectral data[J].IEEE Geoscience and Remote Sensing Letters, 2015, 12 (2) :224-228.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CHXB201908009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201908009&amp;v=MjkyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1ZHZGeXJoVzd6T0ppWFRiTEc0SDlqTXA0OUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM28vVUR0R2xyamVab0dVVnFzS1A1UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
