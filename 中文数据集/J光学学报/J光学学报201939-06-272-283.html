

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133924264502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201906033%26RESULT%3d1%26SIGN%3d3Yx%252f3irh%252bljBMHPjInA0Ja1H1qE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201906033&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201906033&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201906033&amp;v=MjM4Mjk5ak1xWTlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick5JalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#82" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="2 理论方法 ">2 理论方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;2.1 FMT前向模型&lt;/b&gt;"><b>2.1 FMT前向模型</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;2.2 FMT逆向问题&lt;/b&gt;"><b>2.2 FMT逆向问题</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;2.3 基于自编码器的FMT快速重建框架&lt;/b&gt;"><b>2.3 基于自编码器的FMT快速重建框架</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="3 实验与结果 ">3 实验与结果</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="&lt;b&gt;3.1 实验设置&lt;/b&gt;"><b>3.1 实验设置</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;3.2 单光源重建实验&lt;/b&gt;"><b>3.2 单光源重建实验</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;3.3 双光源重建实验&lt;/b&gt;"><b>3.3 双光源重建实验</b></a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;3.4 数字鼠单光源重建实验&lt;/b&gt;"><b>3.4 数字鼠单光源重建实验</b></a></li>
                                                <li><a href="#162" data-title="&lt;b&gt;3.5 数字鼠双光源重建实验&lt;/b&gt;"><b>3.5 数字鼠双光源重建实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="4 结  论 ">4 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#107" data-title="图1 基于自编码器的FMT快速重建框架">图1 基于自编码器的FMT快速重建框架</a></li>
                                                <li><a href="#123" data-title="图2 非匀质圆柱仿体示意图">图2 非匀质圆柱仿体示意图</a></li>
                                                <li><a href="#126" data-title="表1 各器官的光学参数">表1 各器官的光学参数</a></li>
                                                <li><a href="#139" data-title="表2 采用自编码器方法得到的单光源非匀质圆柱仿真实验的重建结果">表2 采用自编码器方法得到的单光源非匀质圆柱仿真实验的重建结果</a></li>
                                                <li><a href="#141" data-title="图3 单光源重建图">图3 单光源重建图</a></li>
                                                <li><a href="#143" data-title="表3 采用自编码器方法得到的单光源非匀质仿体在不同激发光源个数下的定量仿真实验结果">表3 采用自编码器方法得到的单光源非匀质仿体在不同激发光源个数下的定量仿真实验结果</a></li>
                                                <li><a href="#145" data-title="表4 采用自编码器方法得到的单光源非匀质仿体在不同噪声水平下的定量仿真实验结果">表4 采用自编码器方法得到的单光源非匀质仿体在不同噪声水平下的定量仿真实验结果</a></li>
                                                <li><a href="#152" data-title="图4 采用自编码器方法时, 双光源T1和T2在不同维度下的重建结果">图4 采用自编码器方法时, 双光源T1和T2在不同维度下的重建结果</a></li>
                                                <li><a href="#153" data-title="表5 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果">表5 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果</a></li>
                                                <li><a href="#154" data-title="图5 双光源重建图">图5 双光源重建图</a></li>
                                                <li><a href="#158" data-title="图6 采用自编码器方法得到的单光源小鼠实验在不同维度下的重建结果">图6 采用自编码器方法得到的单光源小鼠实验在不同维度下的重建结果</a></li>
                                                <li><a href="#159" data-title="表6 采用自编码器方法得到的单光源小鼠的定量仿真实验结果">表6 采用自编码器方法得到的单光源小鼠的定量仿真实验结果</a></li>
                                                <li><a href="#160" data-title="图7 单光源数字鼠的仿真实验结果">图7 单光源数字鼠的仿真实验结果</a></li>
                                                <li><a href="#165" data-title="图8 使用自编码器压缩至不同维度时双光源T1和T2的重建结果">图8 使用自编码器压缩至不同维度时双光源T1和T2的重建结果</a></li>
                                                <li><a href="#166" data-title="表7 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果">表7 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果</a></li>
                                                <li><a href="#170" data-title="图9 双光源小鼠的仿真实验结果">图9 双光源小鼠的仿真实验结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="12">


                                    <a id="bibliography_1" title=" Hwang J Y, Wachsmann-Hogiu S, Ramanujan V K, &lt;i&gt;et al&lt;/i&gt;.A multimode optical imaging system for preclinical applications &lt;i&gt;in vivo&lt;/i&gt;:technology development, multiscale imaging, and chemotherapy assessment[J].Molecular Imaging and Biology, 2012, 14 (4) :431-442." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120724001379&amp;v=MDczNjI3QmFySzZIdGJPcTQ5RlplZ0lCUk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDcmxVN3pLSWxzUU5q&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Hwang J Y, Wachsmann-Hogiu S, Ramanujan V K, &lt;i&gt;et al&lt;/i&gt;.A multimode optical imaging system for preclinical applications &lt;i&gt;in vivo&lt;/i&gt;:technology development, multiscale imaging, and chemotherapy assessment[J].Molecular Imaging and Biology, 2012, 14 (4) :431-442.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_2" title=" Roy R, Thompson A B, Godavarty A, &lt;i&gt;et al&lt;/i&gt;.Tomographic fluorescence imaging in tissue phantoms:a novel reconstruction algorithm and imaging geometry[J].IEEE Transactions on Medical Imaging, 2005, 24 (2) :137-154." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tomographic fluorescence imaging in tissue phantoms: a novel reconstruction algorithm and imaging geometry">
                                        <b>[2]</b>
                                         Roy R, Thompson A B, Godavarty A, &lt;i&gt;et al&lt;/i&gt;.Tomographic fluorescence imaging in tissue phantoms:a novel reconstruction algorithm and imaging geometry[J].IEEE Transactions on Medical Imaging, 2005, 24 (2) :137-154.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_3" title=" Yi H J.Regularization based reconstruction algorithms for fluorescence molecular tomography[D].Xi′an:Xidian University, 2013.易黄建.基于正则化的荧光分子断层成像重建方法研究[D].西安:西安电子科技大学, 2013." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1014324903.nh&amp;v=MDI3MDBWRjI2R3JDNkd0ak1ySkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Yi H J.Regularization based reconstruction algorithms for fluorescence molecular tomography[D].Xi′an:Xidian University, 2013.易黄建.基于正则化的荧光分子断层成像重建方法研究[D].西安:西安电子科技大学, 2013.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_4" title=" Shang W T, Tian J.Progress of nanoprobes for cancer diagnosis and treatment[J].Chinese Journal of Nuclear Medicine and Molecular Imaging, 2017, 37 (11) :726-729.尚文婷, 田捷.纳米探针在肿瘤诊疗中的研究进展[J].中华核医学与分子影像杂志, 2017, 37 (11) :726-729." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHHY201711018&amp;v=MjgwNzhyTVB5WERkN0c0SDliTnJvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXZuVWI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Shang W T, Tian J.Progress of nanoprobes for cancer diagnosis and treatment[J].Chinese Journal of Nuclear Medicine and Molecular Imaging, 2017, 37 (11) :726-729.尚文婷, 田捷.纳米探针在肿瘤诊疗中的研究进展[J].中华核医学与分子影像杂志, 2017, 37 (11) :726-729.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_5" title=" Leblond F, Davis S C, Vald&#233;s P A, &lt;i&gt;et al&lt;/i&gt;.Pre-clinical whole-body fluorescence imaging:review of instruments, methods and applications[J].Journal of Photochemistry and Photobiology B:Biology, 2010, 98 (1) :77-94." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501329969&amp;v=MjYxMDUxd1dieFk9TmlmT2ZiSzdIdEROcW85RVora0dCWG93b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Leblond F, Davis S C, Vald&#233;s P A, &lt;i&gt;et al&lt;/i&gt;.Pre-clinical whole-body fluorescence imaging:review of instruments, methods and applications[J].Journal of Photochemistry and Photobiology B:Biology, 2010, 98 (1) :77-94.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_6" title=" Hou Y Q, Jin M Y, He X W, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomography using a stochastic variant of alternating direction method of multipliers[J].Acta Optica Sinica, 2017, 37 (7) :0717001.侯榆青, 金明阳, 贺小伟, 等.基于随机变量交替方向乘子法的荧光分子断层成像[J].光学学报, 2017, 37 (7) :0717001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201707024&amp;v=MjUyMDhIOWJNcUk5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNSWpYVGJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Hou Y Q, Jin M Y, He X W, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomography using a stochastic variant of alternating direction method of multipliers[J].Acta Optica Sinica, 2017, 37 (7) :0717001.侯榆青, 金明阳, 贺小伟, 等.基于随机变量交替方向乘子法的荧光分子断层成像[J].光学学报, 2017, 37 (7) :0717001.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_7" title=" Dong F, Hou Y Q, Yu J J, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomography via greedy method combined with region-shrinking strategy[J].Laser &amp;amp; Optoelectronics Progress, 2016, 53 (1) :011701.董芳, 侯榆青, 余景景, 等.结合区域收缩和贪婪策略的荧光分子断层成像[J].激光与光电子学进展, 2016, 53 (1) :011701." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201601023&amp;v=MDc1NjJyUFpMRzRIOWZNcm85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Dong F, Hou Y Q, Yu J J, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomography via greedy method combined with region-shrinking strategy[J].Laser &amp;amp; Optoelectronics Progress, 2016, 53 (1) :011701.董芳, 侯榆青, 余景景, 等.结合区域收缩和贪婪策略的荧光分子断层成像[J].激光与光电子学进展, 2016, 53 (1) :011701.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_8" title=" Wang Z M, Panasyuk G Y, Markel V A, &lt;i&gt;et al&lt;/i&gt;.Experimental demonstration of an analytic method for image reconstruction in optical diffusion tomography with large data sets[J].Optics Letters, 2005, 30 (24) :3338-3340." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Experimental demonstration of an analytic method for image reconstruction in optical diffusion tomography with large data sets">
                                        <b>[8]</b>
                                         Wang Z M, Panasyuk G Y, Markel V A, &lt;i&gt;et al&lt;/i&gt;.Experimental demonstration of an analytic method for image reconstruction in optical diffusion tomography with large data sets[J].Optics Letters, 2005, 30 (24) :3338-3340.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_9" title=" Zou W, Wang J J, Feng D D, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomographic image reconstruction based on reduced measurement data[J].Optical Engineering, 2015, 54 (7) :073114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG71DF4E77DF659E6A0A8B225296A66ABA&amp;v=MzA4NzJGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHg3cTl4YXc9TmlmT2FiUzVhcWZJMm9oQ0VKMEpDWFZNeVdjVG16Y1BTbjNucmhzekNMU1NOTWp1Q09Odg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Zou W, Wang J J, Feng D D, &lt;i&gt;et al&lt;/i&gt;.Fluorescence molecular tomographic image reconstruction based on reduced measurement data[J].Optical Engineering, 2015, 54 (7) :073114.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_10" title=" Partridge M, Jabri M.Robust principal component analysis[C]//Neural Networks for Signal Processing X.Proceedings of the 2000 IEEE Signal Processing Society Workshop (Cat.No.00TH8501) , December 11-13, 2000, Sydney, NSW, Australia.New York:IEEE, 2000:289-298." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust principal component analysis">
                                        <b>[10]</b>
                                         Partridge M, Jabri M.Robust principal component analysis[C]//Neural Networks for Signal Processing X.Proceedings of the 2000 IEEE Signal Processing Society Workshop (Cat.No.00TH8501) , December 11-13, 2000, Sydney, NSW, Australia.New York:IEEE, 2000:289-298.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_11" title=" Li M, Yuan B Z.2D-LDA:a statistical linear discriminant analysis for image matrix[J].Pattern Recognition Letters, 2005, 26 (5) :527-532." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300415176&amp;v=MTA0NDlNbndaZVp1SHlqbVViL0lJMXdXYnhZPU5pZk9mYks3SHRET3JJOUZZT29LRFhzL29CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Li M, Yuan B Z.2D-LDA:a statistical linear discriminant analysis for image matrix[J].Pattern Recognition Letters, 2005, 26 (5) :527-532.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_12" title=" Lai P L, Fyfe C.Kernel and nonlinear canonical correlation analysis[J].International Journal of Neural Systems, 2000, 10 (5) :365-377." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kernel and Nonlinear Canonical Correlation Analysis">
                                        <b>[12]</b>
                                         Lai P L, Fyfe C.Kernel and nonlinear canonical correlation analysis[J].International Journal of Neural Systems, 2000, 10 (5) :365-377.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_13" title=" Zhang X, Yi H J, Hou Y Q, &lt;i&gt;et al&lt;/i&gt;.Fast reconstruction in fluorescence molecular tomography based on locality preserving projections[J].Acta Optica Sinica, 2016, 36 (7) :0717001.张旭, 易黄建, 侯榆青, 等.基于局部保留投影的荧光分子断层成像快速重建[J].光学学报, 2016, 36 (7) :0717001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201607028&amp;v=MjQ5MzZxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick1JalhUYkxHNEg5Zk1xSTlIYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Zhang X, Yi H J, Hou Y Q, &lt;i&gt;et al&lt;/i&gt;.Fast reconstruction in fluorescence molecular tomography based on locality preserving projections[J].Acta Optica Sinica, 2016, 36 (7) :0717001.张旭, 易黄建, 侯榆青, 等.基于局部保留投影的荧光分子断层成像快速重建[J].光学学报, 2016, 36 (7) :0717001.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     Hinton G E, Salakhutdinov R R.Reducing the dimensionality of data with neural networks[J].Science, 2006, 313 (5786) :504-507.</a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     LeCun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436-444.</a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_16" title=" Tang J, Sun J, Wang C, &lt;i&gt;et al&lt;/i&gt;.Social influence analysis in large-scale networks[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, June 28-July 1, 2009, Paris, France.New York:ACM, 2009:807-816." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Social influence analysis in large-scale networks">
                                        <b>[16]</b>
                                         Tang J, Sun J, Wang C, &lt;i&gt;et al&lt;/i&gt;.Social influence analysis in large-scale networks[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, June 28-July 1, 2009, Paris, France.New York:ACM, 2009:807-816.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_17" title=" Chu C T, Sang K K, Lin Y A, &lt;i&gt;et al&lt;/i&gt;.Map-reduce for machine learning on multicore[M]∥Sch&#246;lkopf B, Platt J, Hofmann T.Advances in Neural Information Processing Systems 19:Proceedings of the 2006 Conference.Cambridge:MIT Press, 2007:281-288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Map-reduce for machine learning on multicore">
                                        <b>[17]</b>
                                         Chu C T, Sang K K, Lin Y A, &lt;i&gt;et al&lt;/i&gt;.Map-reduce for machine learning on multicore[M]∥Sch&#246;lkopf B, Platt J, Hofmann T.Advances in Neural Information Processing Systems 19:Proceedings of the 2006 Conference.Cambridge:MIT Press, 2007:281-288.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_18" title=" Alham N K, Li M Z, Liu Y, &lt;i&gt;et al&lt;/i&gt;.A MapReduce-based distributed SVM algorithm for automatic image annotation[J].Computers &amp;amp; Mathematics with Applications, 2011, 62 (7) :2801-2811." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300010547&amp;v=Mjk1ODJmT2ZiSzdIdERPckk5RlpPb1BDWGcrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSTF3V2J4WT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Alham N K, Li M Z, Liu Y, &lt;i&gt;et al&lt;/i&gt;.A MapReduce-based distributed SVM algorithm for automatic image annotation[J].Computers &amp;amp; Mathematics with Applications, 2011, 62 (7) :2801-2811.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_19" title=" Shi Z G, Yang Z Y.Research on the measurement of information loss in the dimension reduction of deep learning[J].Journal of Chinese Computer Systems, 2017, 38 (7) :1590-1594.石志国, 杨志勇.深度学习降维过程中的信息损失度量研究[J].小型微型计算机系统, 2017, 38 (7) :1590-1594." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201707031&amp;v=MDA1OTJGeXZuVWJyTVBUWGNkckc0SDliTXFJOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Shi Z G, Yang Z Y.Research on the measurement of information loss in the dimension reduction of deep learning[J].Journal of Chinese Computer Systems, 2017, 38 (7) :1590-1594.石志国, 杨志勇.深度学习降维过程中的信息损失度量研究[J].小型微型计算机系统, 2017, 38 (7) :1590-1594.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_20" title=" Wang Y S, Yao H X, Zhao S C.Auto-encoder based dimensionality reduction[J].Neurocomputing, 2016, 184:232-242." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES34B6C33CFCC0D5CF1AB56694E03EB35E&amp;v=MjM0NTRxOXhhdz1OaWZPZmJDOGJOZS9ySXcyRXBoOERBZzh2R0FTbTAxNFRubnJxR2MxZXNmbVJyL3FDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4Nw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         Wang Y S, Yao H X, Zhao S C.Auto-encoder based dimensionality reduction[J].Neurocomputing, 2016, 184:232-242.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_21" title=" Wang Y, Yao H, Zhao S, &lt;i&gt;et al&lt;/i&gt;.Dimensionality reduction strategy based on auto-encoder[C]∥Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, August 19-21, 2015, Zhangjiajie, Hunan, China.New York:ACM, 2015:63." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction strategy based on auto-encoder">
                                        <b>[21]</b>
                                         Wang Y, Yao H, Zhao S, &lt;i&gt;et al&lt;/i&gt;.Dimensionality reduction strategy based on auto-encoder[C]∥Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, August 19-21, 2015, Zhangjiajie, Hunan, China.New York:ACM, 2015:63.
                                    </a>
                                </li>
                                <li id="54">


                                    <a id="bibliography_22" title=" Masci J, Meier U, Cireşan D, &lt;i&gt;et al&lt;/i&gt;.Stacked convolutional auto-encoders for hierarchical feature extraction[M]∥Honkela T, Duch W, Girolami M, &lt;i&gt;et al&lt;/i&gt;.Lecture Notes in Computer Science.Berlin, Heidelberg:Springer, 2011, 6791:52-59." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked convolutional auto-encoders for hierarchical feature extraction">
                                        <b>[22]</b>
                                         Masci J, Meier U, Cireşan D, &lt;i&gt;et al&lt;/i&gt;.Stacked convolutional auto-encoders for hierarchical feature extraction[M]∥Honkela T, Duch W, Girolami M, &lt;i&gt;et al&lt;/i&gt;.Lecture Notes in Computer Science.Berlin, Heidelberg:Springer, 2011, 6791:52-59.
                                    </a>
                                </li>
                                <li id="56">


                                    <a id="bibliography_23" title=" Wang Y S, Yao H X, Sun X S, &lt;i&gt;et al&lt;/i&gt;.Representation ability research of auto-encoders in deep learning[J].Computer Science, 2015, 42 (9) :56-60, 65.王雅思, 姚鸿勋, 孙晓帅, 等.深度学习中的自编码器的表达能力研究[J].计算机科学, 2015, 42 (9) :56-60, 65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201509013&amp;v=MzI2MTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeXZuVWJyTUx6N0JiN0c0SDlUTXBvOUVaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         Wang Y S, Yao H X, Sun X S, &lt;i&gt;et al&lt;/i&gt;.Representation ability research of auto-encoders in deep learning[J].Computer Science, 2015, 42 (9) :56-60, 65.王雅思, 姚鸿勋, 孙晓帅, 等.深度学习中的自编码器的表达能力研究[J].计算机科学, 2015, 42 (9) :56-60, 65.
                                    </a>
                                </li>
                                <li id="58">


                                    <a id="bibliography_24" title=" He X W, Liang J M, Wang X R, &lt;i&gt;et al&lt;/i&gt;.Sparse reconstruction for quantitative bioluminescence tomography based on the incomplete variables truncated conjugate gradient method[J].Optics Express, 2010, 18 (24) :24825-24841." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse reconstruction for quantitative bioluminescence tomography based on the incomplete variables truncated conjugate gradient method">
                                        <b>[24]</b>
                                         He X W, Liang J M, Wang X R, &lt;i&gt;et al&lt;/i&gt;.Sparse reconstruction for quantitative bioluminescence tomography based on the incomplete variables truncated conjugate gradient method[J].Optics Express, 2010, 18 (24) :24825-24841.
                                    </a>
                                </li>
                                <li id="60">


                                    <a id="bibliography_25" title=" Cong A X, Wang G.A finite-element-based reconstruction method for 3D fluorescence tomography[J].Optics Express, 2005, 13 (24) :9847-9854." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A finite-element-based reconstruction method for 3D fluorescence tomography">
                                        <b>[25]</b>
                                         Cong A X, Wang G.A finite-element-based reconstruction method for 3D fluorescence tomography[J].Optics Express, 2005, 13 (24) :9847-9854.
                                    </a>
                                </li>
                                <li id="62">


                                    <a id="bibliography_26" title=" Fan S F, Li J, Zhao Y Q.Principle, technique, and biomedical applications of spectral imaging[J].Life Science Instruments, 2004, 2 (4) :24-27.范世福, 李昀, 赵友全.光谱成像的原理、技术和生物医学应用[J].生命科学仪器, 2004, 2 (4) :24-27." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SBKY200404003&amp;v=MDA5NDllVnVGeXZuVWJyTU5pL0FkN0c0SHRYTXE0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         Fan S F, Li J, Zhao Y Q.Principle, technique, and biomedical applications of spectral imaging[J].Life Science Instruments, 2004, 2 (4) :24-27.范世福, 李昀, 赵友全.光谱成像的原理、技术和生物医学应用[J].生命科学仪器, 2004, 2 (4) :24-27.
                                    </a>
                                </li>
                                <li id="64">


                                    <a id="bibliography_27" title=" Yao J J, Hu G, Yue S H, &lt;i&gt;et al&lt;/i&gt;.A 3D-surface torso reconstruction method used in fluorescence molecular tomography of small animals[J].Chinese Journal of Biomedical Engineering, 2008, 27 (3) :360-365.姚俊杰, 胡刚, 岳蜀华, 等.用于荧光分子断层成像的小动物躯干部分三维表面轮廓重建研究[J].中国生物医学工程学报, 2008, 27 (3) :360-365." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSWY200803009&amp;v=Mjc1OTdick1QejdjZDdHNEh0bk1ySTlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                         Yao J J, Hu G, Yue S H, &lt;i&gt;et al&lt;/i&gt;.A 3D-surface torso reconstruction method used in fluorescence molecular tomography of small animals[J].Chinese Journal of Biomedical Engineering, 2008, 27 (3) :360-365.姚俊杰, 胡刚, 岳蜀华, 等.用于荧光分子断层成像的小动物躯干部分三维表面轮廓重建研究[J].中国生物医学工程学报, 2008, 27 (3) :360-365.
                                    </a>
                                </li>
                                <li id="66">


                                    <a id="bibliography_28" title=" Song X L, Wang D F, Chen N G, &lt;i&gt;et al&lt;/i&gt;.Reconstruction for free-space fluorescence tomography using a novel hybrid adaptive finite element algorithm[J].Optics Express, 2007, 15 (26) :18300-18317." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reconstruction for free-space fluorescence tomography using a novel hybrid adaptive finite element algorithm">
                                        <b>[28]</b>
                                         Song X L, Wang D F, Chen N G, &lt;i&gt;et al&lt;/i&gt;.Reconstruction for free-space fluorescence tomography using a novel hybrid adaptive finite element algorithm[J].Optics Express, 2007, 15 (26) :18300-18317.
                                    </a>
                                </li>
                                <li id="68">


                                    <a id="bibliography_29" title=" Schweiger M, Arridge S R, Hiraoka M, &lt;i&gt;et al&lt;/i&gt;.The finite element method for the propagation of light in scattering media:boundary and source conditions[J].Medical Physics, 1995, 22 (11) :1779-1792." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The finite element method for the propagation of light in scattering media: boundary and source conditions">
                                        <b>[29]</b>
                                         Schweiger M, Arridge S R, Hiraoka M, &lt;i&gt;et al&lt;/i&gt;.The finite element method for the propagation of light in scattering media:boundary and source conditions[J].Medical Physics, 1995, 22 (11) :1779-1792.
                                    </a>
                                </li>
                                <li id="70">


                                    <a id="bibliography_30" title=" Chartrand R.Exact reconstruction of sparse signals via nonconvex minimization[J].IEEE Signal Processing Letters, 2007, 14 (10) :707-710." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exact reconstruction of sparse signals via nonconvex minimization">
                                        <b>[30]</b>
                                         Chartrand R.Exact reconstruction of sparse signals via nonconvex minimization[J].IEEE Signal Processing Letters, 2007, 14 (10) :707-710.
                                    </a>
                                </li>
                                <li id="72">


                                    <a id="bibliography_31" title=" Vincent P, Larocheh H, Lajoie I, &lt;i&gt;et al&lt;/i&gt;.Stacked denoising autoencoders:learning useful representations in a deep network with a local denoising criterion[J].Journal of Machine Learning Research, 2010, 11 (Dec) :3371-3408." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked denoising autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion">
                                        <b>[31]</b>
                                         Vincent P, Larocheh H, Lajoie I, &lt;i&gt;et al&lt;/i&gt;.Stacked denoising autoencoders:learning useful representations in a deep network with a local denoising criterion[J].Journal of Machine Learning Research, 2010, 11 (Dec) :3371-3408.
                                    </a>
                                </li>
                                <li id="74">


                                    <a id="bibliography_32" title=" Baldi P.Autoencoders, unsupervised learning and deep architectures[C]∥Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop, June 28-July 2, 2011, Bellevue, Washington, USA.Washington:JMLR.org, 2011, 27:37-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Autoencoders,unsupervised learning and deep architectures">
                                        <b>[32]</b>
                                         Baldi P.Autoencoders, unsupervised learning and deep architectures[C]∥Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop, June 28-July 2, 2011, Bellevue, Washington, USA.Washington:JMLR.org, 2011, 27:37-50.
                                    </a>
                                </li>
                                <li id="76">


                                    <a id="bibliography_33" title=" Deng J F, Zhang X L.Deep learning algorithm optimization based on combination of auto-encoders[J].Journal of Computer Applications, 2016, 36 (3) :697-702.邓俊锋, 张晓龙.基于自动编码器组合的深度学习优化方法[J].计算机应用, 2016, 36 (3) :697-702." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201603023&amp;v=MTg1Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXZuVWJyTUx6N0JkN0c0SDlmTXJJOUhaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[33]</b>
                                         Deng J F, Zhang X L.Deep learning algorithm optimization based on combination of auto-encoders[J].Journal of Computer Applications, 2016, 36 (3) :697-702.邓俊锋, 张晓龙.基于自动编码器组合的深度学习优化方法[J].计算机应用, 2016, 36 (3) :697-702.
                                    </a>
                                </li>
                                <li id="78">


                                    <a id="bibliography_34" title=" Qu J L, Du C F, Di Y Z, &lt;i&gt;et al&lt;/i&gt;.Research and prospect of deep auto-encoders[J].Computer and Modernization, 2014 (8) :128-134.曲建岭, 杜辰飞, 邸亚洲, 等.深度自动编码器的研究与展望[J].计算机与现代化, 2014 (8) :128-134." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201408028&amp;v=MjIyMDk5WE1wNDlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick1MelRUWnJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[34]</b>
                                         Qu J L, Du C F, Di Y Z, &lt;i&gt;et al&lt;/i&gt;.Research and prospect of deep auto-encoders[J].Computer and Modernization, 2014 (8) :128-134.曲建岭, 杜辰飞, 邸亚洲, 等.深度自动编码器的研究与展望[J].计算机与现代化, 2014 (8) :128-134.
                                    </a>
                                </li>
                                <li id="80">


                                    <a id="bibliography_35" title=" Sun Z J, Xue L, Xu Y M, &lt;i&gt;et al&lt;/i&gt;.Overview of deep learning[J].Application Research of Computers, 2012, 29 (8) :2806-2810.孙志军, 薛磊, 许阳明, 等.深度学习研究综述[J].计算机应用研究, 2012, 29 (8) :2806-2810." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201208003&amp;v=MjE2NDFyQ1VSTE9lWmVWdUZ5dm5VYnJNTHo3U1pMRzRIOVBNcDQ5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[35]</b>
                                         Sun Z J, Xue L, Xu Y M, &lt;i&gt;et al&lt;/i&gt;.Overview of deep learning[J].Application Research of Computers, 2012, 29 (8) :2806-2810.孙志军, 薛磊, 许阳明, 等.深度学习研究综述[J].计算机应用研究, 2012, 29 (8) :2806-2810.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-09 18:02</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(06),272-283 DOI:10.3788/AOS201939.0617001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于自编码器的荧光分子断层成像快速重建</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E7%AC%9B&amp;code=40399101&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢笛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%AB%E6%BD%87&amp;code=36905181&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卫潇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B9%E6%AC%A3&amp;code=28800158&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曹欣</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E5%B0%8F%E4%BC%9F&amp;code=11292711&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺小伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BE%AF%E6%A6%86%E9%9D%92&amp;code=10197079&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">侯榆青</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0125326&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北大学信息科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%A4%A7%E5%AD%A6%E8%A5%BF%E5%AE%89%E5%B8%82%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6%E4%B8%8E%E6%99%BA%E8%83%BD%E6%84%9F%E7%9F%A5%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0125326&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北大学西安市影像组学与智能感知重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>多激发点荧光分子断层成像 (FMT) 重建过程中生成的系统矩阵规模较大, 导致计算复杂度高, 重建时间长。为了加快重建速度并保证其准确性, 基于人工神经网络理论, 通过降低系统矩阵规模, 提出了一种快速FMT重建方法。具体来说, 采用的降维方法是自编码器, 即一种典型的人工神经网络, 训练数据为由系统矩阵和表面荧光测量值组成的矩阵, 然后使用自编码器网络的编码部分得到原始矩阵在低维空间上的表示。为了测试所提方法的性能, 设计了一系列数值模拟实验, 包括非匀质圆柱体实验和数字鼠实验。实验结果表明, 该方法能有效缩短重建时间, 得到较高的重建精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BB%E7%94%A8%E5%85%89%E5%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">医用光学;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%8D%A7%E5%85%89%E5%88%86%E5%AD%90%E6%96%AD%E5%B1%82%E6%88%90%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">荧光分子断层成像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据降维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自编码器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像重建;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    贺小伟 E-mail:hexw@nwu.edu.cn;
                                </span>
                                <span>
                                    曹欣 E-mail:xin_cao@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (11571012, 61701403);</span>
                                <span>西安市科技计划 (201805060ZD11CG44);</span>
                                <span>陕西省自然科学基金 (2016JM6025);</span>
                                <span>陕西省教育厅产业化项目 (16JF026) ;陕西省教育厅专项科学研究计划 (18JK0767);</span>
                                <span>中国博士后科学基金 (2018M643719);</span>
                                <span>陕西省自然科学基础研究计划 (2017JQ6006);</span>
                                <span>陕西省科技计划 (2013K12-20-12, 2015KW-002);</span>
                    </p>
            </div>
                    <h1><b>Fast Reconstruction Method for Fluorescence Molecular Tomography Based on Autoencoder</b></h1>
                    <h2>
                    <span>Lu Di</span>
                    <span>Wei Xiao</span>
                    <span>Cao Xin</span>
                    <span>He Xiaowei</span>
                    <span>Hou Yuqing</span>
            </h2>
                    <h2>
                    <span>School of Information Sciences & Technology, Northwest University</span>
                    <span>Key Laboratory for Radiomics and Intelligent Sense of Xi'an, Northwest University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The large-scale system matrix generated during the reconstruction procedure of multiple excitation points based on fluorescence molecular tomography (FMT) leads to the high computational complexity and long reconstruction time. In order to shorten the reconstruction time and ensure its accuracy, based on the theory of artificial neural network (ANN) , we propose a fast reconstruction method for FMT by reducing the dimension of system matrix in this paper. Specifically, the dimension reduction tool is the autoencoder (AE) , which is a famous ANN architecture, and during the training of AE, the input matrix data consists of system matrix and surface fluorescence measurement data, then the representation of the previous matrix in the lower dimensional space is obtained by utilizing encoder part of AE. To test the performance of our method, a series numerical simulation experiments are devised, including non-heterogeneous cylinder and digital mouse experiments. Experimental results demonstrate that our method can effectively shorten the time of FMT reconstruction as well as obtain a good reconstruction accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=medical%20optics&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">medical optics;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fluorescence%20molecular%20tomography&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fluorescence molecular tomography;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20dimensionality%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data dimensionality reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=autoencoder&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">autoencoder;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image reconstruction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-17</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="82" name="82" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="83">荧光分子断层成像 (FMT) 作为一种重要的分子成像技术, 在深层组织的成像、精准量化以及多模态成像<citation id="172" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>等方面具有明显优势。FMT利用激光底透扫描以及超声探头深度定位的方式<citation id="173" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 获取10万级数量的深层荧光信息, 结合重建算法和分析软件实现三维断层信号的扫描及重建, 进而得到目标的三维分布、形态、荧光强度等信息, 具有高灵敏度、高时间分辨率、无电离、无放射性, 以及成本低、成像快捷等诸多优点<citation id="174" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。近十年来, 荧光探针的靶向性技术<citation id="175" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、临床的无创定量分析、在体特异性分子活动可视化、多模态成像技术成为了研究重点。</p>
                </div>
                <div class="p1">
                    <p id="84">FMT主要应用于肿瘤的早期检测和药物分子监测等生物医学方面<citation id="176" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。将FMT应用于目标重建时, 考虑到目标本身对光的吸收和散射作用, 根据检测的光分布, 如何准确而快速地重建出荧光标志物, 一直都是FMT中的关键问题。近年来, 在重建算法的研究中, 侯榆青等<citation id="177" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>结合对偶坐标下降法 (DCA) 和交替方向乘子法 (ADMM) 提出了一种改进的随机变量的交替方向乘子法重建优化方法, 该方法可以降低FMT重建的病态性, 提升大规模数据集下的重建效率。受压缩感知理论启发, 董芳等<citation id="178" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了一种结合自适应可行区域迭代收缩策略和分段正交匹配追踪算法的重建方法, 该方法可显著提高荧光目标的定位精度和荧光产额的定量分布, 降低了算法对参数选取的依赖。由于FMT成像过程采用单个投影角度, 产生的投影数据信息含量较少, 导致重建图像质量差, 重建精度较低。为了提高重建的准确性, 研究者常常把多个投影角度获得的荧光数据及系统矩阵分别整合成大规模的表面荧光向量和系统矩阵, 再将其用于重建算法<citation id="179" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 但系统矩阵规模的增大必然会导致重建速度的下降<citation id="180" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 因此, 在保证重建准确度的前提下, 缩小系统矩阵的规模, 提高重建速度成为本文研究的重点。</p>
                </div>
                <div class="p1">
                    <p id="85">早期的数据降维方法主要有主成分分析 (PCA) <citation id="181" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、线性判决 (LDA) <citation id="182" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、典型关联分析 (CCA) <citation id="183" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、局部保留投影 (LPP) <citation id="184" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等, 属于流形学习的范畴, 主要用于处理数据量较小的高维数据, 在数据可视化、数据分析、数据去噪等方面表现相对良好。自2006年Hinton等<citation id="185" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>在Science杂志上发表了名为“Reducing the Dimensionality of Data with Neural Networks”的文章至今, 深度学习 (DL) 已被广泛应用于自然语言处理、图像识别、推荐系统和数据降维等领域<citation id="186" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 常用的方法和模型有自编码器 (AE) 、稀疏编码 (SC) 、受限波兹曼机 (RBM) 、深度信念网络 (DBN) 等<citation id="188" type="reference"><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><link href="46" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>。其中自编码器是一种无监督学习神经网络, 采用梯度下降法配合反向传播算法进行训练, 目的在于使神经网络的输出值尽可能地等于输入值<citation id="187" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。当自编码器中设置的隐藏层节点数量小于原始输入节点数量时, 即可实现期望的降维功能<citation id="189" type="reference"><link href="50" rel="bibliography" /><link href="52" rel="bibliography" /><link href="54" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>, 属于非线性降维方法。</p>
                </div>
                <div class="p1">
                    <p id="86">本文提出了一种基于自编码器的FMT快速重建方法, 该方法通过降低系统矩阵的规模来达到提高重建速度的目的。本文所用到的自编码器为单隐藏层网络结构, 节点个数为100。具体来说, 首先使用系统矩阵及表面测量值构成的矩阵训练自编码器, 然后利用自编码器的编码部分得到系统矩阵和表面测量值的低维空间表达<citation id="190" type="reference"><link href="56" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 最后将降维后的上述数据用于不完全变量截断共轭梯度算法 (IVTCG) <citation id="191" type="reference"><link href="58" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>进行验证。结果表明, 通过自编码器不仅能够有效降低系统矩阵的规模, 还能在提高重建速度的同时兼顾重建精度。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag">2 理论方法</h3>
                <h4 class="anchor-tag" id="88" name="88"><b>2.1 FMT前向模型</b></h4>
                <div class="p1">
                    <p id="89">光在生物组织中的传播可以用辐射传输方程 (RTE) 来描述<citation id="192" type="reference"><link href="60" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mi>c</mi></mfrac><mfrac><mrow><mo>∂</mo><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mo>=</mo></mtd></mtr><mtr><mtd><mo>-</mo><mi mathvariant="bold-italic">s</mi><mo>⋅</mo><mo>∇</mo><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mtext>t</mtext></msub><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mi>μ</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo>×</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mrow><mn>4</mn><mtext>π</mtext></mrow></munder><mi>L</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo>, </mo><msup><mi mathvariant="bold-italic">s</mi><mo>′</mo></msup><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">s</mi><mo>′</mo></msup><mo>⋅</mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><mtext>d</mtext><msup><mi>Ω</mi><mo>′</mo></msup><mo>+</mo><mi>S</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><msqrt><mn>2</mn></msqrt><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">式中:<i>Ω</i>′为在<b><i>s</i></b>方向上的立体角;<i>c</i>为光在生物组织中的传输速度;<i>L</i> (<b><i>r</i></b>, <b><i>s</i></b>, <i>t</i>) 为辐射度, 表征<i>t</i>时刻介质中<b><i>s</i></b>方向<b><i>r</i></b>点处单位面原单位立体角上的光子流能量;<i>μ</i><sub>t</sub>为消光系数;<i>μ</i><sub>s</sub>为生物组织的散射系数;<i>p</i> (<b><i>s</i></b>′, <b><i>s</i></b>) 为散射相位函数, 表示单次散射时光子由入射方向<b><i>s</i></b>′散射到方向<b><i>s</i></b>的概率;<i>S</i> (<b><i>r</i></b>, <b><i>s</i></b>, <i>t</i>) 为生物体发光光源的空间和角度分布。由于近红外谱段 (700～900 nm) 光在非匀质介质中的传播具有高散射、低吸收的特性<citation id="193" type="reference"><link href="62" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>, 因此, 辐射度传输方程可以用耦合的扩散方程 (DE) 来近似表示<citation id="194" type="reference"><link href="64" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>, 激发光和发射光可以分别表示为</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mo>-</mo><mo>∇</mo><mo>⋅</mo><mo stretchy="false">[</mo><mi>D</mi><msub><mrow></mrow><mtext>x</mtext></msub><mo>∇</mo><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mtext>x</mtext></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>x</mtext></mrow></msub><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd columnalign="left"><mo>-</mo><mo>∇</mo><mo>⋅</mo><mo stretchy="false">[</mo><mi>D</mi><msub><mrow></mrow><mtext>m</mtext></msub><mo>∇</mo><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mtext>m</mtext></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>m</mtext></mrow></msub><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mtext>x</mtext></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">c</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">r</mi><mo>∈</mo><mi mathvariant="bold-italic">Ω</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">式中:<i>Ω</i>为成像物体占据的三维空间;<b><i>S</i></b> (<b><i>r</i></b>) 为激发光的空间和角度分布;<i>D</i><sub>x</sub>为激发光的扩散系数;<i>D</i><sub>m</sub>为发射光的扩散系数;<i>μ</i><sub>ax</sub>为荧光团对激发光的吸收系数;<i>μ</i><sub>am</sub>为荧光团对发射光的吸收系数;<i>Φ</i><sub>x</sub>为激发光的光强分布向量;<i>Φ</i><sub>m</sub>为发射光的光强分布向量;<b><i>c</i></b> (<b><i>r</i></b>) 为所要求解的荧光探针分布。结合Robin边界和有限元方法<citation id="195" type="reference"><link href="66" rel="bibliography" /><link href="68" rel="bibliography" /><sup>[<a class="sup">28</a>,<a class="sup">29</a>]</sup></citation>可以得到矩阵方程组</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mtext>x</mtext></msub><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mtext>x</mtext></msub><mo>=</mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mtext>x</mtext></msub></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mtext>m</mtext></msub><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mtext>m</mtext></msub><mo>=</mo><mi mathvariant="bold-italic">F</mi><mi mathvariant="bold-italic">C</mi></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">式中:<b><i>K</i></b><sub>x</sub>和<b><i>K</i></b><sub>m</sub>为系统矩阵;<b><i>S</i></b><sub>x</sub>为激发光源向量;<b><i>F</i></b>为对未知荧光光源分布进行离散化后得到的矩阵;<b><i>C</i></b>为待重建的未知光源分布向量。去掉方程两边的非测量值可以建立如下线性关系:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Φ</mi><msubsup><mrow></mrow><mtext>m</mtext><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msubsup><mo>=</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msup><mi mathvariant="bold-italic">C</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">式中:<i>Φ</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>m</mtext><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msubsup></mrow></math></mathml>为由<i>Φ</i><sub>m</sub>去掉内部元素后得到的<i>M</i>维列向量, 代表获得的表面荧光测量信息;<b><i>A</i></b><sup>meas</sup>为由系统矩阵<b><i>A</i></b>去掉内部元素后生成的<i>M</i>维系统矩阵。本课题组采用了36个投影角度, (4) 式可以视为由所有投影角度对应的子系统方程组合而成的。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>2.2 FMT逆向问题</b></h4>
                <div class="p1">
                    <p id="100">FMT重建是一个典型的逆问题, 得到的解往往是通过优化的数学方法求出的近似解。为了解决逆问题的不适定性, 可以将FMT重建问题归结为寻找 (4) 式的稀疏解的问题, 借助压缩感知的思想, 引入正则项<citation id="196" type="reference"><link href="70" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>, 得到如下重建模型</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>min</mi><mrow><mo>{</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msup><mi mathvariant="bold-italic">C</mi><mo>-</mo><mi mathvariant="bold-italic">Φ</mi><msup><mrow></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msup></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mi mathvariant="bold-italic">C</mi><mo>|</mo></mrow><msub><mrow></mrow><mi>p</mi></msub></mrow><mo>}</mo></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">式中:<i>λ</i>为正则化参数;<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">C</mi><mo>|</mo></mrow><msub><mrow></mrow><mi>p</mi></msub></mrow></math></mathml>为对应p范数的惩罚项;<i>Φ</i><sup>meas</sup>为表面荧光测量值。 (5) 式中的目标函数是凸函数且不可微, 直接求解比较困难, 而不完全变量截断共轭梯度算法 (IVTCG) 算法可以有效解决此问题。因此, 解决多角度投影造成的系统矩阵规模较大、重建计算复杂度等问题成为实现快速FMT重建的关键。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>2.3 基于自编码器的FMT快速重建框架</b></h4>
                <div class="p1">
                    <p id="105">基于2.2节提到的大规模系统矩阵会降低重建速度这一问题, 本课题组提出了一种基于自编码器的FMT快速重建框架。如图1所示, 自编码器是一种三层神经网络, 分为编码、解码两个过程, 主要应用在数据去噪、数据降维、特征提取<citation id="197" type="reference"><link href="70" rel="bibliography" /><link href="72" rel="bibliography" /><link href="74" rel="bibliography" /><link href="76" rel="bibliography" /><sup>[<a class="sup">30</a>,<a class="sup">31</a>,<a class="sup">32</a>,<a class="sup">33</a>]</sup></citation>等方面。</p>
                </div>
                <div class="p1">
                    <p id="106">图1 (a) 中展示了本课题组使用的自编码器网络, 最左边layer 1称之为输入层 (input) , 即原始的高维数据;中间一层是隐藏层 (hidden layer) ;右边一层layer 3是输出层 (output) , 即从低维空间重构得到的数据。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于自编码器的FMT快速重建框架" src="Detail/GetImg?filename=images/GXXB201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于自编码器的FMT快速重建框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Framework of FMT rapid reconstruction based on autoencoder</p>

                </div>
                <div class="p1">
                    <p id="108">假设输入数据是<i>M</i>维的高维数据, 隐藏层节点数为<i>R</i> (手动设置) ——即低维空间上的维数。通过反向传播算法进行训练, 使layer 3的输出值 (由低维空间重构得到) 尽可能地等于layer 1的输入值, 这样就认定隐藏层的低维空间中<i>R</i>维数据包含着输入数据的某些特征, 进而实现降维处理。</p>
                </div>
                <div class="p1">
                    <p id="109">具体操作如下:图1 (a) 中, 前向计算完成后, 得到<i>M</i>维的系统矩阵<b><i>A</i></b><sup>meas</sup>和<i>M</i>维的表面荧光测量值<i>Φ</i><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>m</mtext><mrow><mtext>m</mtext><mtext>e</mtext><mtext>a</mtext><mtext>s</mtext></mrow></msubsup></mrow></math></mathml>, 将二者组成矩阵<b><i>X</i></b><sub><i>M</i>×<i>N</i></sub>, 输入到自编码器中进行训练。为了实现高维数据的非线性降维, 加快收敛速度, 在反向传播算法中选取tanh作为激活函数, 如 (6) 式所示</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo></mrow><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">式中:<b><i>y</i></b>为训练过程中每次计算得到的输出值。采用均方误差作为损失函数, 通过最小化损失函数来优化网络, 损失函数如 (7) 式所示:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi mathvariant="bold-italic">Y</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mo>, </mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">式中:<b><i>Y</i></b>为优化网络过程中得到的输出矩阵;<b><i>x</i></b>为输入层的每一个样本, 即<b><i>X</i></b><sub><i>M</i>×<i>N</i></sub>中的每一列;<b><i>Y</i></b>′为训练过程中每次迭代生成的矩阵;<b><i>W</i></b>为权值矩阵。采用梯度下降法配合反向传播过程, 反复进行权值矩阵<b><i>W</i></b>及偏置向量<b><i>b</i></b>的更新, 直至收敛或达到预设迭代次数, 训练结束。</p>
                </div>
                <div class="p1">
                    <p id="115">继而进行图1 (b) 的操作, 使用训练好的自编码器的编码部分, 此时的权重及偏置已确定, 通过 (8) 式计算得到矩阵<b><i>X</i></b><sub><i>M</i>×<i>N</i></sub>在低维空间上的特征表示<b><i>Y</i></b><sub><i>R</i>×<i>N</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">y</mi><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">x</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">从而得到逆问题的低维度表示, 如 (9) 式所示, 结合IVTCG重建算法得出结果:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mrow><mi>R</mi><mo>×</mo><mi>Ν</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mrow><mi>R</mi><mo>×</mo><mi>Ν</mi></mrow></msub><mi mathvariant="bold-italic">C</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">式中:<i>Φ</i><sub><i>R</i>×<i>N</i></sub>为表面荧光测量值的低维空间表示;<b><i>A</i></b><sub><i>R</i>×<i>N</i></sub>为系统矩阵的低维空间表示, 相比于原始<i>M</i>维数据, 其维度变为<i>R</i>维, 矩阵规模大大减小。由于自编码器可以有效减小数据的冗余, 很好地重现数据特征<citation id="198" type="reference"><link href="78" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>, 因此应用降维后的数据进行FMT重建仍可以获得较好的重建结果。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">3 实验与结果</h3>
                <h4 class="anchor-tag" id="121" name="121"><b>3.1 实验设置</b></h4>
                <div class="p1">
                    <p id="122">为了验证基于自编码器的FMT快速重建方法的有效性与准确性, 设计了单光源非匀质圆柱仿真实验、双光源非匀质圆柱仿真实验和数字鼠仿真实验, 圆柱仿真实验采用如图2 (a) 所示的非匀质圆柱体作为研究对象。圆柱体的半径为10 mm, 高为30 mm, 主要包含肌肉、肝脏、肺、心脏、骨骼5个器官, 各器官的光学参数如表1<citation id="199" type="reference"><link href="80" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>所示。荧光目标用圆柱体模拟, 放置在肺部, 荧光产额设定为0.05 mm<sup>-1</sup>, 36个激发点均匀地分布在<i>z</i>=15 mm的平面上, 并且距表面一个光子自由程, 如图2 (b) 所示。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 非匀质圆柱仿体示意图" src="Detail/GetImg?filename=images/GXXB201906033_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 非匀质圆柱仿体示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Diagram of the non-homogeneous cylinder phantom</p>
                                <p class="img_note"> (a) 非匀质圆柱仿体模型; (b) 激发点在z=15mm处的平面分布示意图</p>
                                <p class="img_note"> (a) Model of non-homogeneous cylinder phantom; (b) distribution of shot points at plane of z=15mm</p>

                </div>
                <div class="p1">
                    <p id="125">本课题组根据不同模型的复杂程度, 尝试将神经网络的隐藏层节点数分别设置为不同的数值, 实验结果证明, 当隐藏层节点数为100时, 可以达到较好的降维效果。所有计算均在配置为Intel Core i5-3330 CPU, 4 GB内存的个人计算机上完成。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit">表1 各器官的光学参数 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Optical parameters for non-homogeneous cylinder phantom</p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td><br />Organ</td><td><i>μ</i><sub>ax</sub> /mm<sup>-1</sup></td><td><i>μ</i><sub>sx</sub> /mm<sup>-1</sup></td><td><i>μ</i><sub>am</sub> /mm<sup>-1</sup></td><td><i>μ</i><sub>sm</sub> /mm<sup>-1</sup></td></tr><tr><td><br />Muscle</td><td>0.0052</td><td>10.80</td><td>0.0068</td><td>10.30</td></tr><tr><td><br />Heart</td><td>0.0083</td><td>6.73</td><td>0.0104</td><td>6.60</td></tr><tr><td><br />Lungs</td><td>0.0133</td><td>19.70</td><td>0.0203</td><td>19.50</td></tr><tr><td><br />Liver</td><td>0.0329</td><td>7.00</td><td>0.0176</td><td>6.60</td></tr><tr><td><br />Bone</td><td>0.0060</td><td>60.09</td><td>0.0030</td><td>30.74</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="127">为定量评估本课题组所提方法的性能, 引入定位误差 (LE) 、加权中心误差 (WCLE) 、Dice系数和归一化均方根误差 (NRMSE) 等指标。其中, 定位误差定义为重建中心 (<i>x</i>, <i>y</i>, <i>z</i>) 和真实目标 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 之间的欧几里得距离:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>L</mtext><mtext>E</mtext></mrow></msub><mo>=</mo><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>y</mi><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>z</mi><mo>-</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">加权中心误差定义为加权中心 (<i>x</i><sub>W</sub>, <i>y</i><sub>W</sub>, <i>z</i><sub>W</sub>) 与真实目标 (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>, <i>z</i><sub>0</sub>) 之间的欧几里得距离:</p>
                </div>
                <div class="p1">
                    <p id="130" class="code-formula">
                        <mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>W</mtext><mtext>C</mtext><mtext>L</mtext><mtext>E</mtext></mrow></msub><mo>=</mo><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mtext>W</mtext></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mtext>W</mtext></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mtext>W</mtext></msub><mo>-</mo><mi>z</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="131">Dice系数可以验证重建区域与真正荧光区域的相似性。Dice系数越大, 说明重建结果与真实结果越接近。Dice系数的表达式为</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>i</mtext><mtext>c</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mrow><mo>|</mo><mrow><mi>S</mi><msub><mrow></mrow><mtext>r</mtext></msub><mstyle displaystyle="true"><mo>∩</mo><mi>S</mi></mstyle><msub><mrow></mrow><mtext>o</mtext></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>S</mi><msub><mrow></mrow><mtext>r</mtext></msub></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>S</mi><msub><mrow></mrow><mtext>o</mtext></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">式中:<i>S</i><sub>r</sub>和<i>S</i><sub>o</sub>分别为重建区域和真实光源区域所含的点集。</p>
                </div>
                <div class="p1">
                    <p id="134">归一化均方根误差定义式为</p>
                </div>
                <div class="p1">
                    <p id="135" class="code-formula">
                        <mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>Ν</mtext><mtext>R</mtext><mtext>Μ</mtext><mtext>S</mtext><mtext>E</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext></mrow></msub><mo>-</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>r</mtext><mtext>g</mtext></mrow></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>r</mtext><mtext>g</mtext></mrow></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="136">式中:<i>C</i><sub>rec</sub>为重建得到的荧光产值;<i>C</i><sub>org</sub>为原始荧光产值。<i>f</i><sub>NRMSE</sub>越接近于0说明重建准确率越高。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>3.2 单光源重建实验</b></h4>
                <div class="p1">
                    <p id="138">在单光源重建实验中, 将半径为0.5 mm、高为2 mm的圆柱体置于肺部模拟真实目标, 中心位置是 (0 mm, 6 mm, 15 mm) 。在前向问题中, 将仿体离散化成包含68396个四面体单元和12019个网格节点的有限元网格。在逆向问题中, 仿体被离散化成包含29602个四面体单元和5285个网格节点的有限元网格, 原始系统矩阵的规模是4785×5285。由于在构建自编码器网络过程中, 隐藏层节点数的设置将会直接影响降维的效果<citation id="200" type="reference"><link href="74" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>, 因此, 本课题组设计了5组实验, 分别将隐藏层的节点数设置为50、100、150、200、300, 使用自编码器方法后的重建结果如表2所示。</p>
                </div>
                <div class="area_img" id="139">
                    <p class="img_tit">表2 采用自编码器方法得到的单光源非匀质圆柱仿真实验的重建结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Reconstruction results of single source non-homogeneous cylinder phantom simulation experiments using AE method</p>
                    <p class="img_note"></p>
                    <table id="139" border="1"><tr><td>Method (dimensionality) </td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td><br />IVTCG</td><td>0.73</td><td>0.2546</td><td>3.3640</td><td>7.68</td><td>0.5200</td></tr><tr><td><br />AE+IVTCG (50) </td><td>0.73</td><td>0.2438</td><td>0.0239</td><td>4.22</td><td>0.6667</td></tr><tr><td><br />AE+IVTCG (100) </td><td>0.73</td><td>0.1789</td><td>0.0186</td><td>3.98</td><td>0.6667</td></tr><tr><td><br />AE+IVTCG (150) </td><td>0.79</td><td>0.2621</td><td>0.0204</td><td>4.37</td><td>0.6000</td></tr><tr><td><br />AE+IVTCG (200) </td><td>0.79</td><td>0.4100</td><td>0.0280</td><td>4.48</td><td>0.5200</td></tr><tr><td><br />AE+IVTCG (300) </td><td>1.26</td><td>0.6047</td><td>0.0318</td><td>4.76</td><td>0.4444</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="140">由表2可知, 当隐藏层节点数设置为100时, 重建LE、WCLE、重建时间、Dice系数均达到较高水平, 因此本课题组的仿体实验均将隐藏层节点数预设为100个。降维后, 系统矩阵规模变成100×5285, 分别采用IVTCG算法对原始数据和降维后的数据进行重建, 使用Tecplot软件展示重建立体图, 并采集<i>x</i>=0 mm和<i>z</i>=15 mm平面处的二维截面图, 如图3所示。结果显示, 使用自编码器方法降维至100维后, 仍可以得到分辨率较高的可视化视图, 且光源位置清晰, 重建结果的中心误差、归一化均方根误差明显减小, 重建时间明显缩短, Dice系数增大。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 单光源重建图" src="Detail/GetImg?filename=images/GXXB201906033_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 单光源重建图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Result diagram of single-source reconstruction</p>
                                <p class="img_note"> (a) ～ (c) 采用原始数据得到的重建立体图及在x=0mm、z=15mm处的二维截面图; (d) ～ (f) 采用自编码器方法得到的重建立体图及在x=0mm、z=15mm处的二维截面图</p>
                                <p class="img_note"> (a) - (c) Stereogram of reconstruction results, the 2Dcross-section views at planes of x=0mm and z=15mm with original data; (d) - (f) stereogram of reconstruction results, the 2Dcross-section views at planes of x=0mm and z=15mm with AE method</p>

                </div>
                <div class="p1">
                    <p id="142">在FMT成像过程中, 重建质量往往会受激发光源个数的影响。为了验证该方法的稳定性, 本课题组设计了激发光源个数分别为36、18、9、6、3的仿真实验。重建结果如表3所示, 可见:当激发光源个数在3个以上时, 可以达到较好的重建效果, 且各个指标在小范围内上下浮动;激发光源个数为3时, 各指标有所下降, 但仍在误差允许的范围内, 重建时间明显少于使用原始数据重建的时间。可见, 采用自编码器方法降维的FMT快速重建具有良好的稳定性。</p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit">表3 采用自编码器方法得到的单光源非匀质仿体在不同激发光源个数下的定量仿真实验结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Quantitative simulation results of single source non-homogeneous cylinder using AE method under different number of excitation sources</p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td>Number of excitation source</td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td><br />36</td><td>0.73</td><td>0.1789</td><td>0.0186</td><td>3.98</td><td>0.6667</td></tr><tr><td><br />18</td><td>0.73</td><td>0.2094</td><td>0.0334</td><td>4.21</td><td>0.6667</td></tr><tr><td><br />9</td><td>0.73</td><td>0.5235</td><td>0.0236</td><td>4.85</td><td>0.6667</td></tr><tr><td><br />6</td><td>1.17</td><td>0.4118</td><td>0.0474</td><td>4.02</td><td>0.4700</td></tr><tr><td><br />3</td><td>1.26</td><td>1.2600</td><td>0.0534</td><td>4.17</td><td>0.4000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="144">在FMT重建过程中, 噪声干扰是不可避免的, 为了验证该方法的抗噪声性能, 设计了5组不同比例噪声下的对比仿真实验, 结果如表4所示。可见, 加入不同比例的噪声后, 重建效果依然良好, 重建时间仅有微小的扰动, 表明自编码器方法具有良好的稳定性。</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit">表4 采用自编码器方法得到的单光源非匀质仿体在不同噪声水平下的定量仿真实验结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Quantitative simulation results of single source non-homogeneous cylinder using AE method under different noise levels</p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td>Noise level /%</td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td><br />5</td><td>0.73</td><td>0.6723</td><td>0.0152</td><td>4.09</td><td>0.6667</td></tr><tr><td><br />10</td><td>0.73</td><td>0.6879</td><td>0.0159</td><td>4.20</td><td>0.6667</td></tr><tr><td><br />15</td><td>0.73</td><td>0.1461</td><td>0.0192</td><td>4.33</td><td>0.6667</td></tr><tr><td><br />20</td><td>0.79</td><td>0.2033</td><td>0.0179</td><td>4.01</td><td>0.6000</td></tr><tr><td><br />25</td><td>1.26</td><td>0.7213</td><td>0.0164</td><td>4.80</td><td>0.4000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="146" name="146"><b>3.3 双光源重建实验</b></h4>
                <div class="p1">
                    <p id="147">为了进一步评估基于自编码器的FMT快速重建方法应对多目标复杂情况的处理能力, 本课题组设计了双光源非匀质仿体实验, 在 (0 mm, 6 mm, 15 mm) 和 (0 mm, -6 mm, 15 mm) 处分别放置半径为0.5 mm、高为1.5 mm的圆柱体模拟真实的荧光目标T1和T2。在前向问题中, 仿体被离散化成包含119561个四面体单元和21146个节点的有限元网格;在逆向问题中, 仿体被离散成包含19083个四面体单元和3479个节点的有限元网格。</p>
                </div>
                <div class="p1">
                    <p id="148">由于在构建自编码器网络过程中, 隐藏层节点数的设置将直接影响降维的效果<citation id="201" type="reference"><link href="74" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>, 因此, 本课题组设计了5组实验, 分别将隐藏层节点数设置为50、100、150、200、300, 进行仿真重建实验, 分析T1、T2的重建结果。图4展示了定位误差及重建时间, 可见, 当隐藏层节点数设置为100时, 各指标稳定, T1、T2均可达到较好的重建结果。</p>
                </div>
                <div class="p1">
                    <p id="149">因此, 使用自编码器方法进行双光源重建时设定隐藏层节点数为100, 即降维前原始系统矩阵的规模为4788×3479, 降维后系统矩阵的规模为100×3479, 将两组数据分别输入IVTCG算法进行重建, 结果如表5所示。使用Tecplot软件展示重建立体图并采集<i>x</i>=0 mm和<i>z</i>=15 mm平面处的二维截面图, 如图5所示。结果表明, 采用自编码器方法的多目标重建同样可以得到分辨率较高的重建立体图, 重建精确度高, 相似系数、归一化均方误差等指标明显优化, 重建时间约减少了1/2。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150"><b>3.4 数字鼠单光源重建实验</b></h4>
                <div class="p1">
                    <p id="151">为了进一步评估自编码器方法在FMT系统中的性能, 进行了数字鼠单光源重建实验。真实光源中心为 (11.9 mm, 6.4 mm, 16.4 mm) 。在前向问题中, 将仿体离散化成包含108396个四面体单元和19019个网格节点的有限元网格;在逆向问题中, 仿体被离散化成包含18602个四面体单元和2604个网格节点的有限元网格。</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 采用自编码器方法时, 双光源T1和T2在不同维度下的重建结果" src="Detail/GetImg?filename=images/GXXB201906033_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 采用自编码器方法时, 双光源T1和T2在不同维度下的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 T1 and T2 reconstruction results using AE method under different dimensionality</p>
                                <p class="img_note"> (a) T1重建结果; (b) T2重建结果</p>
                                <p class="img_note"> (a) Reconstruction results of T1; (b) reconstruction results of T2</p>

                </div>
                <div class="area_img" id="153">
                    <p class="img_tit">表5 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Quantitative simulation results of double sources non-homogeneous cylinder phantom simulation experiments using AE method</p>
                    <p class="img_note"></p>
                    <table id="153" border="1"><tr><td>Method</td><td>Target</td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td rowspan="2">IVTCG</td><td><br />T1</td><td>0.6169</td><td>0.4915</td><td rowspan="2">0.3291</td><td rowspan="2">24.3438</td><td rowspan="2">0.2361</td></tr><tr><td><br />T2</td><td>1.3971</td><td>0.9369</td></tr><tr><td rowspan="2"><br />AE+IVTCG</td><td><br />T1</td><td>0.6169</td><td>0.4826</td><td rowspan="2">0.0491</td><td rowspan="2">10.5170</td><td rowspan="2">0.4444</td></tr><tr><td><br />T2</td><td>1.3286</td><td>0.4598</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 双光源重建图" src="Detail/GetImg?filename=images/GXXB201906033_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 双光源重建图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Result diagram of double-sources reconstruction</p>
                                <p class="img_note"> (a) ～ (c) 采用原始数据得到的重建立体图及在x=0mm、z=15mm处的二维截面图; (d) ～ (f) 采用自编码方法得到的重建立体图及在x=0mm、z=15mm处的二维截面图</p>
                                <p class="img_note"> (a) - (c) Stereogram of reconstruction results, the 2Dcross-section views at planes of x=0mm and z=15mm with original data; (d) - (f) stereogram of reconstruction results, the 2Dcross-section views at planes of x=0mm and z=15mm with AE method</p>

                </div>
                <div class="p1">
                    <p id="156">重建结果表明, 单光源小鼠重建数据降维至100时各个指标稳定且相对更优, 如图6所示, 位置误差LE及重建时间在隐藏层节点数设置为100时达到最优, 因此将隐藏层节点数设置为100, 降维前系统矩阵的规模为7552×2604, 降维后矩阵的规模为100×2604。</p>
                </div>
                <div class="p1">
                    <p id="157">分别使用原始数据和经自编码器降维后的数据用于IVTCG重建, 结果如表6所示, 使用Tecplot软件展示重建立体图并采集<i>x</i>=11.9 mm和<i>z</i>=16.4 mm平面处的二维截面图, 结果如图7所示。结果表明, 相对于原始数据的重建, 使用自编码器方法得到的重建立体图同样具有较高的分辨率和精确度, 且相似系数、归一化均方根误差等指标明显优化, 重建时间大大缩短, 进一步验证了基于自编码器的快速重建方法的可行性。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 采用自编码器方法得到的单光源小鼠实验在不同维度下的重建结果" src="Detail/GetImg?filename=images/GXXB201906033_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 采用自编码器方法得到的单光源小鼠实验在不同维度下的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Single source reconstruction results in digital mouse experiments using AE method under different dimensionality</p>

                </div>
                <div class="area_img" id="159">
                    <p class="img_tit">表6 采用自编码器方法得到的单光源小鼠的定量仿真实验结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 6 Quantitative simulation results of single source in digital mouse experiments using AE method</p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td>Method</td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td><br />IVTCG</td><td>0.40425</td><td>0.4268</td><td>0.2509</td><td>5.8112</td><td>0.4000</td></tr><tr><td><br />AE+IVTCG</td><td>0.40425</td><td>0.5635</td><td>0.0343</td><td>1.7308</td><td>0.5700</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="160">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 单光源数字鼠的仿真实验结果" src="Detail/GetImg?filename=images/GXXB201906033_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 单光源数字鼠的仿真实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Results of single source in digital mouse experiments</p>
                                <p class="img_note"> (a) ～ (c) 采用原始数据得到的重建立体图及在x=11.9mm、z=16.4mm处的二维截面图; (d) ～ (f) 采用自编码器降维方法得到的重建立体图及在x=11.9mm、z=16.4mm处的二维截面图</p>
                                <p class="img_note"> (a) - (c) Stereogram of reconstruction results, the 2Dcross-section views at planes of x=11.9mm and z=16.4mm with original data; (d) - (f) stereogram of reconstruction results, the 2Dcross-section views at planes of x=11.9mm and z=16.4mm with AE method</p>

                </div>
                <h4 class="anchor-tag" id="162" name="162"><b>3.5 数字鼠双光源重建实验</b></h4>
                <div class="p1">
                    <p id="163">为了进一步评估基于自编码器的FMT快速重建方法应对多目标复杂情况的处理能力, 设计了近距离双光源数字鼠仿体实验, 在 (11.9 mm, 6.4 mm, 16.4 mm) 和 (11.9 mm, 10.9 mm, 16.4 mm) 处分别放置半径为0.5 mm、高为1 mm的圆柱体, 模拟真实荧光目标T1和T2。在前向问题中, 仿体被离散化成包含119313个四面体单元和20117个节点的有限元网格。在逆向问题中, 仿体被离散化成包含18602个四面体单元和2604个网格节点的有限元网格。</p>
                </div>
                <div class="p1">
                    <p id="164">如图8所示, 当隐藏层节点数设置为100时, 各指标稳定, T1、T2均可达到较好的重建结果。因此将隐藏层节点数设置为100个, 降维前系统矩阵的规模为6996×2604, 降维后矩阵的规模为100×2604。分别采用IVTCG方法和AE+IVTCG方法进行重建, 通过表7的定量分析可知, AE+IVTCG方法在重建时间上明显优于IVTCG方法, 且相似系数、归一化均方根误差等指标也有不同程度的改善。</p>
                </div>
                <div class="area_img" id="165">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 使用自编码器压缩至不同维度时双光源T1和T2的重建结果" src="Detail/GetImg?filename=images/GXXB201906033_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 使用自编码器压缩至不同维度时双光源T1和T2的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Reconstruction results of T1 and T2 when compressed to different dimensions using AE</p>
                                <p class="img_note"> (a) T1的重建结果; (b) T2的重建结果</p>
                                <p class="img_note"> (a) Reconstruction results of T1; (b) reconstruction results of T2</p>

                </div>
                <div class="area_img" id="166">
                    <p class="img_tit">表7 采用自编码器方法得到的双光源非匀质圆柱的定量仿真实验结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 7 Quantitative simulation results of double sources in digital mouse experiments using AE method</p>
                    <p class="img_note"></p>
                    <table id="166" border="1"><tr><td>Method</td><td>Target</td><td>LE /mm</td><td>WCLE /mm</td><td>NRMSE /mm<sup>-1</sup></td><td>Time /s</td><td>Dice</td></tr><tr><td rowspan="2">IVTCG</td><td><br />T1</td><td>0.6169</td><td>1.2876</td><td rowspan="2">0.2617</td><td rowspan="2">47.776</td><td rowspan="2">0.3333</td></tr><tr><td><br />T2</td><td>0.6833</td><td>0.9369</td></tr><tr><td rowspan="2"><br />AE+IVTCG</td><td><br />T1</td><td>0.6169</td><td>1.2876</td><td rowspan="2">0.0220</td><td rowspan="2">20.171</td><td rowspan="2">0.4000</td></tr><tr><td><br />T2</td><td>0.5169</td><td>0.4579</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="167">使用Tecplot软件展示重建立体图并采集<i>x</i>=11.9 mm和<i>z</i>=16.4 mm平面处的二维截面图, 结果如图9所示。结果表明, 使用自编码器方法得到的重建可视化图像光源区分度良好, 可以处理距离较近的双光源数字鼠结构, 进一步证实了基于自编码器的快速重建方法应对复杂光源仿体的稳定性。</p>
                </div>
                <h3 id="168" name="168" class="anchor-tag">4 结  论</h3>
                <div class="p1">
                    <p id="169">之前的研究往往采用多角度投影的方法来提高FMT成像系统的重建准确度, 而大规模的系统矩阵会导致计算复杂度增大, 重建速度减慢。为了解决此问题, 本课题组提出了基于人工神经网络中无监督学习算法——自编码器的FMT快速重建方法。具体来说就是, 构建具有较少隐藏层节点数的自编码器网络, 采用tanh作为激活函数, 均方误差作为损失函数, 使用自编码器对系统矩阵和表面荧光测量值组成的矩阵进行训练, 同时利用自编码器的编码部分得到矩阵的低维空间表达, 实现降维处理, 最后采用IVTCG进行重建的方法。为了评估自编码器方法的性能, 进行了单光源和双光源非匀质圆柱体数值模拟, 以及单光源数字鼠模拟实验。引入定位误差、加权中心误差、Dice系数、归一化均方根误差和图像重建时间等参数以及多光源检验和噪声干扰测试, IVTCG和AE+IVTCG两种处理方法的对比结果表明, 本课题组提出的方法在自编码器降维后, 仍可得到分辨率较高的视图, 光源位置清晰, 且重建的定位误差和归一化均方根误差明显减小, 重建时间大幅缩短。但目前的仿真实验还需要人为设定隐藏层节点数, 因此, 结合数据特征, 选择最优的自编码器模型, 是本课题组下一步研究的方向和重点。</p>
                </div>
                <div class="area_img" id="170">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201906033_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 双光源小鼠的仿真实验结果" src="Detail/GetImg?filename=images/GXXB201906033_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 双光源小鼠的仿真实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201906033_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Results of double-sources in digital mouse experiments</p>
                                <p class="img_note"> (a) ～ (c) 采用原始数据得到的重建立体图及在x=11.9mm、z=16.4mm处的二维截面图; (d) ～ (f) 采用自编码器降维方法得到的重建立体图及在x=11.9mm、z=16.4mm处的二维截面图</p>
                                <p class="img_note"> (a) - (c) Stereogram of reconstruction results, the 2Dcross-section views at planes of x=11.9mm and z=16.4mm with original data; (d) - (f) stereogram of reconstruction results, the 2Dcross-section views at planes of x=11.9mm and z=16.4mm with AE method</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="12">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120724001379&amp;v=MjQ3Nzd0Yk9xNDlGWmVnSUJSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkNybFU3ektJbHNRTmo3QmFySzZI&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Hwang J Y, Wachsmann-Hogiu S, Ramanujan V K, <i>et al</i>.A multimode optical imaging system for preclinical applications <i>in vivo</i>:technology development, multiscale imaging, and chemotherapy assessment[J].Molecular Imaging and Biology, 2012, 14 (4) :431-442.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tomographic fluorescence imaging in tissue phantoms: a novel reconstruction algorithm and imaging geometry">

                                <b>[2]</b> Roy R, Thompson A B, Godavarty A, <i>et al</i>.Tomographic fluorescence imaging in tissue phantoms:a novel reconstruction algorithm and imaging geometry[J].IEEE Transactions on Medical Imaging, 2005, 24 (2) :137-154.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1014324903.nh&amp;v=MjgyNzRFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNVkYyNkdyQzZHdGpNcko=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Yi H J.Regularization based reconstruction algorithms for fluorescence molecular tomography[D].Xi′an:Xidian University, 2013.易黄建.基于正则化的荧光分子断层成像重建方法研究[D].西安:西安电子科技大学, 2013.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHHY201711018&amp;v=MDkzODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXZuVWJyTVB5WERkN0c0SDliTnJvOUViSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Shang W T, Tian J.Progress of nanoprobes for cancer diagnosis and treatment[J].Chinese Journal of Nuclear Medicine and Molecular Imaging, 2017, 37 (11) :726-729.尚文婷, 田捷.纳米探针在肿瘤诊疗中的研究进展[J].中华核医学与分子影像杂志, 2017, 37 (11) :726-729.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501329969&amp;v=MTY2ODVCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUkxd1dieFk9TmlmT2ZiSzdIdEROcW85RVora0dCWG93bw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Leblond F, Davis S C, Valdés P A, <i>et al</i>.Pre-clinical whole-body fluorescence imaging:review of instruments, methods and applications[J].Journal of Photochemistry and Photobiology B:Biology, 2010, 98 (1) :77-94.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201707024&amp;v=MjI1NjJYVGJMRzRIOWJNcUk5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNSWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Hou Y Q, Jin M Y, He X W, <i>et al</i>.Fluorescence molecular tomography using a stochastic variant of alternating direction method of multipliers[J].Acta Optica Sinica, 2017, 37 (7) :0717001.侯榆青, 金明阳, 贺小伟, 等.基于随机变量交替方向乘子法的荧光分子断层成像[J].光学学报, 2017, 37 (7) :0717001.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201601023&amp;v=MDQwNTA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick1MeXJQWkxHNEg5Zk1ybzlIWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Dong F, Hou Y Q, Yu J J, <i>et al</i>.Fluorescence molecular tomography via greedy method combined with region-shrinking strategy[J].Laser &amp; Optoelectronics Progress, 2016, 53 (1) :011701.董芳, 侯榆青, 余景景, 等.结合区域收缩和贪婪策略的荧光分子断层成像[J].激光与光电子学进展, 2016, 53 (1) :011701.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Experimental demonstration of an analytic method for image reconstruction in optical diffusion tomography with large data sets">

                                <b>[8]</b> Wang Z M, Panasyuk G Y, Markel V A, <i>et al</i>.Experimental demonstration of an analytic method for image reconstruction in optical diffusion tomography with large data sets[J].Optics Letters, 2005, 30 (24) :3338-3340.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG71DF4E77DF659E6A0A8B225296A66ABA&amp;v=Mjc3ODB4YXc9TmlmT2FiUzVhcWZJMm9oQ0VKMEpDWFZNeVdjVG16Y1BTbjNucmhzekNMU1NOTWp1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeDdxOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Zou W, Wang J J, Feng D D, <i>et al</i>.Fluorescence molecular tomographic image reconstruction based on reduced measurement data[J].Optical Engineering, 2015, 54 (7) :073114.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust principal component analysis">

                                <b>[10]</b> Partridge M, Jabri M.Robust principal component analysis[C]//Neural Networks for Signal Processing X.Proceedings of the 2000 IEEE Signal Processing Society Workshop (Cat.No.00TH8501) , December 11-13, 2000, Sydney, NSW, Australia.New York:IEEE, 2000:289-298.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300415176&amp;v=MDc4OTlPckk5RllPb0tEWHMvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSTF3V2J4WT1OaWZPZmJLN0h0RA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Li M, Yuan B Z.2D-LDA:a statistical linear discriminant analysis for image matrix[J].Pattern Recognition Letters, 2005, 26 (5) :527-532.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kernel and Nonlinear Canonical Correlation Analysis">

                                <b>[12]</b> Lai P L, Fyfe C.Kernel and nonlinear canonical correlation analysis[J].International Journal of Neural Systems, 2000, 10 (5) :365-377.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201607028&amp;v=Mjk1NjllVnVGeXZuVWJyTUlqWFRiTEc0SDlmTXFJOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Zhang X, Yi H J, Hou Y Q, <i>et al</i>.Fast reconstruction in fluorescence molecular tomography based on locality preserving projections[J].Acta Optica Sinica, 2016, 36 (7) :0717001.张旭, 易黄建, 侯榆青, 等.基于局部保留投影的荧光分子断层成像快速重建[J].光学学报, 2016, 36 (7) :0717001.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 Hinton G E, Salakhutdinov R R.Reducing the dimensionality of data with neural networks[J].Science, 2006, 313 (5786) :504-507.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 LeCun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436-444.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Social influence analysis in large-scale networks">

                                <b>[16]</b> Tang J, Sun J, Wang C, <i>et al</i>.Social influence analysis in large-scale networks[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, June 28-July 1, 2009, Paris, France.New York:ACM, 2009:807-816.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Map-reduce for machine learning on multicore">

                                <b>[17]</b> Chu C T, Sang K K, Lin Y A, <i>et al</i>.Map-reduce for machine learning on multicore[M]∥Schölkopf B, Platt J, Hofmann T.Advances in Neural Information Processing Systems 19:Proceedings of the 2006 Conference.Cambridge:MIT Press, 2007:281-288.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300010547&amp;v=MDkxNTJlcnFRVE1ud1plWnVIeWptVWIvSUkxd1dieFk9TmlmT2ZiSzdIdERPckk5RlpPb1BDWGcrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Alham N K, Li M Z, Liu Y, <i>et al</i>.A MapReduce-based distributed SVM algorithm for automatic image annotation[J].Computers &amp; Mathematics with Applications, 2011, 62 (7) :2801-2811.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201707031&amp;v=Mjk5MjFyQ1VSTE9lWmVWdUZ5dm5VYnJNUFRYY2RyRzRIOWJNcUk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Shi Z G, Yang Z Y.Research on the measurement of information loss in the dimension reduction of deep learning[J].Journal of Chinese Computer Systems, 2017, 38 (7) :1590-1594.石志国, 杨志勇.深度学习降维过程中的信息损失度量研究[J].小型微型计算机系统, 2017, 38 (7) :1590-1594.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES34B6C33CFCC0D5CF1AB56694E03EB35E&amp;v=MjIxNjFkaGh4N3E5eGF3PU5pZk9mYkM4Yk5lL3JJdzJFcGg4REFnOHZHQVNtMDE0VG5ucnFHYzFlc2ZtUnIvcUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> Wang Y S, Yao H X, Zhao S C.Auto-encoder based dimensionality reduction[J].Neurocomputing, 2016, 184:232-242.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensionality reduction strategy based on auto-encoder">

                                <b>[21]</b> Wang Y, Yao H, Zhao S, <i>et al</i>.Dimensionality reduction strategy based on auto-encoder[C]∥Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, August 19-21, 2015, Zhangjiajie, Hunan, China.New York:ACM, 2015:63.
                            </a>
                        </p>
                        <p id="54">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked convolutional auto-encoders for hierarchical feature extraction">

                                <b>[22]</b> Masci J, Meier U, Cireşan D, <i>et al</i>.Stacked convolutional auto-encoders for hierarchical feature extraction[M]∥Honkela T, Duch W, Girolami M, <i>et al</i>.Lecture Notes in Computer Science.Berlin, Heidelberg:Springer, 2011, 6791:52-59.
                            </a>
                        </p>
                        <p id="56">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201509013&amp;v=MDA1NjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNTHo3QmI3RzRIOVRNcG85RVo0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> Wang Y S, Yao H X, Sun X S, <i>et al</i>.Representation ability research of auto-encoders in deep learning[J].Computer Science, 2015, 42 (9) :56-60, 65.王雅思, 姚鸿勋, 孙晓帅, 等.深度学习中的自编码器的表达能力研究[J].计算机科学, 2015, 42 (9) :56-60, 65.
                            </a>
                        </p>
                        <p id="58">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse reconstruction for quantitative bioluminescence tomography based on the incomplete variables truncated conjugate gradient method">

                                <b>[24]</b> He X W, Liang J M, Wang X R, <i>et al</i>.Sparse reconstruction for quantitative bioluminescence tomography based on the incomplete variables truncated conjugate gradient method[J].Optics Express, 2010, 18 (24) :24825-24841.
                            </a>
                        </p>
                        <p id="60">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A finite-element-based reconstruction method for 3D fluorescence tomography">

                                <b>[25]</b> Cong A X, Wang G.A finite-element-based reconstruction method for 3D fluorescence tomography[J].Optics Express, 2005, 13 (24) :9847-9854.
                            </a>
                        </p>
                        <p id="62">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SBKY200404003&amp;v=MjM4ODU3RzRIdFhNcTQ5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNTmkvQWQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> Fan S F, Li J, Zhao Y Q.Principle, technique, and biomedical applications of spectral imaging[J].Life Science Instruments, 2004, 2 (4) :24-27.范世福, 李昀, 赵友全.光谱成像的原理、技术和生物医学应用[J].生命科学仪器, 2004, 2 (4) :24-27.
                            </a>
                        </p>
                        <p id="64">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZSWY200803009&amp;v=MDAzNDdlWmVWdUZ5dm5VYnJNUHo3Y2Q3RzRIdG5Nckk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b> Yao J J, Hu G, Yue S H, <i>et al</i>.A 3D-surface torso reconstruction method used in fluorescence molecular tomography of small animals[J].Chinese Journal of Biomedical Engineering, 2008, 27 (3) :360-365.姚俊杰, 胡刚, 岳蜀华, 等.用于荧光分子断层成像的小动物躯干部分三维表面轮廓重建研究[J].中国生物医学工程学报, 2008, 27 (3) :360-365.
                            </a>
                        </p>
                        <p id="66">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reconstruction for free-space fluorescence tomography using a novel hybrid adaptive finite element algorithm">

                                <b>[28]</b> Song X L, Wang D F, Chen N G, <i>et al</i>.Reconstruction for free-space fluorescence tomography using a novel hybrid adaptive finite element algorithm[J].Optics Express, 2007, 15 (26) :18300-18317.
                            </a>
                        </p>
                        <p id="68">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The finite element method for the propagation of light in scattering media: boundary and source conditions">

                                <b>[29]</b> Schweiger M, Arridge S R, Hiraoka M, <i>et al</i>.The finite element method for the propagation of light in scattering media:boundary and source conditions[J].Medical Physics, 1995, 22 (11) :1779-1792.
                            </a>
                        </p>
                        <p id="70">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exact reconstruction of sparse signals via nonconvex minimization">

                                <b>[30]</b> Chartrand R.Exact reconstruction of sparse signals via nonconvex minimization[J].IEEE Signal Processing Letters, 2007, 14 (10) :707-710.
                            </a>
                        </p>
                        <p id="72">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked denoising autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion">

                                <b>[31]</b> Vincent P, Larocheh H, Lajoie I, <i>et al</i>.Stacked denoising autoencoders:learning useful representations in a deep network with a local denoising criterion[J].Journal of Machine Learning Research, 2010, 11 (Dec) :3371-3408.
                            </a>
                        </p>
                        <p id="74">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Autoencoders,unsupervised learning and deep architectures">

                                <b>[32]</b> Baldi P.Autoencoders, unsupervised learning and deep architectures[C]∥Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop, June 28-July 2, 2011, Bellevue, Washington, USA.Washington:JMLR.org, 2011, 27:37-50.
                            </a>
                        </p>
                        <p id="76">
                            <a id="bibliography_33" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201603023&amp;v=MTgxODI3QmQ3RzRIOWZNckk5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5dm5VYnJNTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[33]</b> Deng J F, Zhang X L.Deep learning algorithm optimization based on combination of auto-encoders[J].Journal of Computer Applications, 2016, 36 (3) :697-702.邓俊锋, 张晓龙.基于自动编码器组合的深度学习优化方法[J].计算机应用, 2016, 36 (3) :697-702.
                            </a>
                        </p>
                        <p id="78">
                            <a id="bibliography_34" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201408028&amp;v=MTExMjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXZuVWJyTUx6VFRackc0SDlYTXA0OUhiSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[34]</b> Qu J L, Du C F, Di Y Z, <i>et al</i>.Research and prospect of deep auto-encoders[J].Computer and Modernization, 2014 (8) :128-134.曲建岭, 杜辰飞, 邸亚洲, 等.深度自动编码器的研究与展望[J].计算机与现代化, 2014 (8) :128-134.
                            </a>
                        </p>
                        <p id="80">
                            <a id="bibliography_35" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201208003&amp;v=MTU2MzdCdEdGckNVUkxPZVplVnVGeXZuVWJyTUx6N1NaTEc0SDlQTXA0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[35]</b> Sun Z J, Xue L, Xu Y M, <i>et al</i>.Overview of deep learning[J].Application Research of Computers, 2012, 29 (8) :2806-2810.孙志军, 薛磊, 许阳明, 等.深度学习研究综述[J].计算机应用研究, 2012, 29 (8) :2806-2810.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201906033" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201906033&amp;v=MjM4Mjk5ak1xWTlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl2blVick5JalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralV4ZEdibEtXKzVXTDBsc0dtdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

