

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133134740283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201909016%26RESULT%3d1%26SIGN%3dWchkl7c2MljKgfw8YQ%252fiVkd6rN8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201909016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201909016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201909016&amp;v=MjQwMjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5M25WYnZLSWpYVGJMRzRIOWpNcG85RVlvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#50" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="2 所提算法 ">2 所提算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="&lt;b&gt;2.1 图像块分解&lt;/b&gt;"><b>2.1 图像块分解</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;2.2 参考图像分区&lt;/b&gt;"><b>2.2 参考图像分区</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.3 鬼影的检测及去除&lt;/b&gt;"><b>2.3 鬼影的检测及去除</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;2.4 图像块的融合过程&lt;/b&gt;"><b>2.4 图像块的融合过程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="3 实验结果分析 ">3 实验结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="&lt;b&gt;3.1 主观评价&lt;/b&gt;"><b>3.1 主观评价</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;3.2 客观评价&lt;/b&gt;"><b>3.2 客观评价</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;3.3 算法执行时间&lt;/b&gt;"><b>3.3 算法执行时间</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="4 结  论 ">4 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="图1 所提算法框架">图1 所提算法框架</a></li>
                                                <li><a href="#78" data-title="图2 鬼影的检测及去除框架">图2 鬼影的检测及去除框架</a></li>
                                                <li><a href="#99" data-title="图3 输入多曝光Puppet序列的鬼影检测图。">图3 输入多曝光Puppet序列的鬼影检测图。</a></li>
                                                <li><a href="#117" data-title="图4 Sculpture garden序列去鬼影对比实验结果。">图4 Sculpture garden序列去鬼影对比实验结果。</a></li>
                                                <li><a href="#122" data-title="图5 puppets序列去鬼影对比实验结果。">图5 puppets序列去鬼影对比实验结果。</a></li>
                                                <li><a href="#123" data-title="图6 BabyOnGrass序列去鬼影对比实验结果。">图6 BabyOnGrass序列去鬼影对比实验结果。</a></li>
                                                <li><a href="#124" data-title="表1 采用HDR-VDP2模型评估五种算法的结果">表1 采用HDR-VDP2模型评估五种算法的结果</a></li>
                                                <li><a href="#128" data-title="表2 不同高动态范围图像去鬼影算法的计算效率对比">表2 不同高动态范围图像去鬼影算法的计算效率对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" Du L,Sun H Y,Wang S,&lt;i&gt;et al&lt;/i&gt;.High dynamic range image fusion algorithm for moving targets[J].Acta Optica Sinica,2017,37(4):0410001.都琳,孙华燕,王帅,等.针对动态目标的高动态范围图像融合算法研究[J].光学学报,2017,37(4):0410001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201704013&amp;v=MDgyNjJDVVJMT2VaZVZ2RnkzblZidktJalhUYkxHNEg5Yk1xNDlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Du L,Sun H Y,Wang S,&lt;i&gt;et al&lt;/i&gt;.High dynamic range image fusion algorithm for moving targets[J].Acta Optica Sinica,2017,37(4):0410001.都琳,孙华燕,王帅,等.针对动态目标的高动态范围图像融合算法研究[J].光学学报,2017,37(4):0410001.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" Kang S B,Uyttendaele M,Winder S,&lt;i&gt;et al&lt;/i&gt;.High dynamic range video[J].ACM Transactions on Graphics,2003,22(3):319-325." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098000&amp;v=MTk0NzJvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKVndTYmhBPU5pZklZN0s3SHRqTnI0OUZaT0lIREh3NQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Kang S B,Uyttendaele M,Winder S,&lt;i&gt;et al&lt;/i&gt;.High dynamic range video[J].ACM Transactions on Graphics,2003,22(3):319-325.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" Mangiat S,Gibson J.High dynamic range video with ghost removal[J].Proceedings of SPIE,2010,7798:779812." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High dynamic range video with ghost removal">
                                        <b>[3]</b>
                                         Mangiat S,Gibson J.High dynamic range video with ghost removal[J].Proceedings of SPIE,2010,7798:779812.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" Zimmer H,Bruhn A,Weickert J.Freehand HDR imaging of moving scenes with simultaneous resolution enhancement[J].Computer Graphics Forum,2011,30(2):405-414." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Freehand HDR Imaging of Moving Scenes with Simultaneous Resolution Enhancement">
                                        <b>[4]</b>
                                         Zimmer H,Bruhn A,Weickert J.Freehand HDR imaging of moving scenes with simultaneous resolution enhancement[J].Computer Graphics Forum,2011,30(2):405-414.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" Park S C,Oh H H,Kwon J H,&lt;i&gt;et al&lt;/i&gt;.Motion artifact-free HDR imaging under dynamic environments[C]∥2011 18th IEEE International Conference on Image Processing,September 11-14,2011,Brussels,Belgium.New York:IEEE,2011:11-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Motion artifact-free HDR imaging under dynamic environments">
                                        <b>[5]</b>
                                         Park S C,Oh H H,Kwon J H,&lt;i&gt;et al&lt;/i&gt;.Motion artifact-free HDR imaging under dynamic environments[C]∥2011 18th IEEE International Conference on Image Processing,September 11-14,2011,Brussels,Belgium.New York:IEEE,2011:11-14.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" title=" Zhang W,Cham W K.Gradient-directed multiexposure composition[J].IEEE Transactions on Image Processing,2012,21(4):2318-2323." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient-Directed Multiexposure Composition">
                                        <b>[6]</b>
                                         Zhang W,Cham W K.Gradient-directed multiexposure composition[J].IEEE Transactions on Image Processing,2012,21(4):2318-2323.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" Sen P,Kalantari N K,Yaesoubi M,&lt;i&gt;et al&lt;/i&gt;.Robust patch-based HDR reconstruction of dynamic scenes[J].ACM Transactions on Graphics,2012,31(6):203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007839&amp;v=MTEyODVoQT1OaWZJWTdLN0h0ak5yNDlGWk9zSUJIOHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKVndTYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Sen P,Kalantari N K,Yaesoubi M,&lt;i&gt;et al&lt;/i&gt;.Robust patch-based HDR reconstruction of dynamic scenes[J].ACM Transactions on Graphics,2012,31(6):203.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" HaCohen Y,Shechtman E,Goldman D B,&lt;i&gt;et al&lt;/i&gt;.Non-rigid dense correspondence with applications for image enhancement[J].ACM Transactions on Graphics,2011,30(4):70." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000002939&amp;v=Mjc3ODhUTW53WmVadUh5am1VYjdJSlZ3U2JoQT1OaWZJWTdLN0h0ak5yNDlGWk9zTkJYOHdvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         HaCohen Y,Shechtman E,Goldman D B,&lt;i&gt;et al&lt;/i&gt;.Non-rigid dense correspondence with applications for image enhancement[J].ACM Transactions on Graphics,2011,30(4):70.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" Boykov Y,Veksler O,Zabih R.Fast approximate energy minimization via graph cuts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2001,23(11):1222-1239." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast approximate energy minimization via graph cuts">
                                        <b>[9]</b>
                                         Boykov Y,Veksler O,Zabih R.Fast approximate energy minimization via graph cuts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2001,23(11):1222-1239.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" Hu J,Gallo O,Pulli K.Exposure stacks of live scenes with hand-held cameras[M]∥Fitzgibbon A,Lazebnik S,Perona P,&lt;i&gt;et al&lt;/i&gt;.Computer vision-ECCV 2012.Lecture notes in computer science.Berlin,Heidelberg:Springer,2012,7572:499-512." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exposure stacks of live scenes with hand-held cameras">
                                        <b>[10]</b>
                                         Hu J,Gallo O,Pulli K.Exposure stacks of live scenes with hand-held cameras[M]∥Fitzgibbon A,Lazebnik S,Perona P,&lt;i&gt;et al&lt;/i&gt;.Computer vision-ECCV 2012.Lecture notes in computer science.Berlin,Heidelberg:Springer,2012,7572:499-512.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" Lee C,Li Y,Monga V.Ghost-free high dynamic range imaging via rank minimization[J].IEEE Signal Processing Letters,2014,21(9):1045-1049." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ghost-Free High Dynamic Range Imaging via Rank Minimization">
                                        <b>[11]</b>
                                         Lee C,Li Y,Monga V.Ghost-free high dynamic range imaging via rank minimization[J].IEEE Signal Processing Letters,2014,21(9):1045-1049.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" Oh T H,Lee J Y,Tai Y W,&lt;i&gt;et al&lt;/i&gt;.Robust high dynamic range imaging by rank minimization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(6):1219-1232." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust high dynamic range imaging by rank minimization">
                                        <b>[12]</b>
                                         Oh T H,Lee J Y,Tai Y W,&lt;i&gt;et al&lt;/i&gt;.Robust high dynamic range imaging by rank minimization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(6):1219-1232.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" Grossberg M D,Nayar S K.Determining the camera response from images:What is knowable?[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(11):1455-1467." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Determining the camera response from images: What is knowable?">
                                        <b>[13]</b>
                                         Grossberg M D,Nayar S K.Determining the camera response from images:What is knowable?[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(11):1455-1467.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" Ward G.Fast,robust image registration for compositing high dynamic range photographs from hand-held exposures[J].Journal of Graphics Tools,2003,8(2):17-30." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD14082200000688&amp;v=MTA2MjdQQ25ReG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpWd1NiaEE9TmpuQmFySzhIdG5Pclk5RlpPcw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Ward G.Fast,robust image registration for compositing high dynamic range photographs from hand-held exposures[J].Journal of Graphics Tools,2003,8(2):17-30.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjI0NjJ3PU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVnIzT0pG&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" Zhang W,Cham W K.Reference-guided exposure fusion in dynamic scenes[J].Journal of Visual Communication and Image Representation,2012,23(3):467-475." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263297&amp;v=MTU2NDFpZk9mYks3SHRETnFvOUVadTBNRG5VK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpWd1NiaEE9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Zhang W,Cham W K.Reference-guided exposure fusion in dynamic scenes[J].Journal of Visual Communication and Image Representation,2012,23(3):467-475.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_17" title=" Gallo O,Gelfandz N,Chen W C,&lt;i&gt;et al&lt;/i&gt;.Artifact-free high dynamic range imaging[C]∥2009 IEEE International Conference on Computational Photography (ICCP),April 16-17,2009,San Francisco,CA,USA.New York:IEEE,2009:5559003." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Artifact-free High Dynamic Range Imaging">
                                        <b>[17]</b>
                                         Gallo O,Gelfandz N,Chen W C,&lt;i&gt;et al&lt;/i&gt;.Artifact-free high dynamic range imaging[C]∥2009 IEEE International Conference on Computational Photography (ICCP),April 16-17,2009,San Francisco,CA,USA.New York:IEEE,2009:5559003.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_18" title=" Commercially-available HDR processing software[OL].[2019-03-10].http://www.hdrsoft.com/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Commercially-available HDR processing software[OL]">
                                        <b>[18]</b>
                                         Commercially-available HDR processing software[OL].[2019-03-10].http://www.hdrsoft.com/.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_19" title=" Ma K D,Li H,Yong H W,&lt;i&gt;et al&lt;/i&gt;.Robust multi-exposure image fusion:a structural patch decomposition approach[J].IEEE Transactions on Image Processing,2017,26(5):2519-2532." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust multi-exposure image fusion:a structural patch decomposition approach">
                                        <b>[19]</b>
                                         Ma K D,Li H,Yong H W,&lt;i&gt;et al&lt;/i&gt;.Robust multi-exposure image fusion:a structural patch decomposition approach[J].IEEE Transactions on Image Processing,2017,26(5):2519-2532.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_20" title=" Mantiuk R,Kim K J,Rempel A G,&lt;i&gt;et al&lt;/i&gt;.HDR-VDP-2:a calibrated visual metric for visibility and quality predictions in all luminance conditions[J].ACM Transactions on Graphics,2011,30(4):40." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000002909&amp;v=MDc4Mjc3SHRqTnI0OUZaT3NOQlh3d29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpWd1NiaEE9TmlmSVk3Sw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         Mantiuk R,Kim K J,Rempel A G,&lt;i&gt;et al&lt;/i&gt;.HDR-VDP-2:a calibrated visual metric for visibility and quality predictions in all luminance conditions[J].ACM Transactions on Graphics,2011,30(4):40.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-06-04 11:49</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(09),132-140 DOI:10.3788/AOS201939.0910001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于图像块分解的多曝光图像融合去鬼影算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E5%A4%8F%E4%B8%80&amp;code=42914562&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马夏一</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8C%83%E6%96%B9%E6%99%B4&amp;code=42914563&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">范方晴</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E9%99%B6%E7%84%B6&amp;code=42914564&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢陶然</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%AD%90%E8%B1%AA&amp;code=42914565&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王子豪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E5%BD%AC&amp;code=15142826&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙彬</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%AD%A6%E9%99%A2&amp;code=0178313&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子科技大学航空航天学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在传统的多曝光图像融合方法中,一旦目标发生移动则会在最终融合图像中出现“鬼影”现象。现有的去“鬼影”算法大部分都继承了参考图像中的大量信息,倘若参考图像中出现曝光不足/曝光过度现象,便会影响到最终的融合结果。基于此,提出了一种基于图像块分解的多曝光图像融合去鬼影算法。首先将参考图像划分为曝光正常及曝光不足/过度两大区域,并有针对性地对这两部分区域进行处理。为了更加精准地检测出鬼影区域,将多曝光图像块分解成信号结构、信号强度和平均强度3个概念相独立的部分,采用图像块结构一致性检测的方式来进行鬼影检测。最后,去除结构不一致的图像块并对这3个部分分开融合,重构所需图像块并将其聚合至最终融合图像。实验结果表明,与现有的去“鬼影”算法相比,所提算法取得了更好的视觉效果,且计算效率得到了较大提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%9B%9D%E5%85%89%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多曝光图像融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E9%AC%BC%E5%BD%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去鬼影;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%9D%97%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像块分解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%82%E8%80%83%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">参考图像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孙彬,E-mail:sunbinhust@uestc.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>四川省科学技术厅项目(KKY2017001);</span>
                    </p>
            </div>
                    <h1><b>Multi-Exposure Image Fusion De-Ghosting Algorithm Based on Image Block Decomposition</b></h1>
                    <h2>
                    <span>Ma Xiayi</span>
                    <span>Fan Fangqing</span>
                    <span>Lu Taoran</span>
                    <span>Wang Zihao</span>
                    <span>Sun Bin</span>
            </h2>
                    <h2>
                    <span>School of Aeronautics and Astronautics, University of Electronic Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In traditional multi-exposure image fusion methods, once the target moves, the phenomenon of “ghosting” occurs in the final fused image. Most existing de-ghosting algorithms inherit substantial data from the reference image. Once the underexposure/overexposure occurs in the reference image, the final fusion result is affected. To remedy this, herein, a multi-exposure image fusion de-ghosting algorithm based on image block decomposition is proposed. First, the reference image is divided into two areas, i.e., normal exposure and underexposed/overexposed areas, both of which are individually processed. To detect the ghost area more accurately, the proposed algorithm decomposes the multi-exposure image block into three independent parts, i.e., signal structure, signal intensity, and average intensity. Ghost detection is then performed by detecting structurally consistent image parts, following which inconsistent parts are removed, the three image parts are fused, and the required image parts are reconstructed and added to the final fused image. Experimental results of this algorithm′s validation show that compared to existing de-ghosting algorithms, the proposed algorithm achieves better visual effects and improves computational efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-exposure%20image%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-exposure image fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=de-ghosting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">de-ghosting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20block%20decomposition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image block decomposition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reference%20images&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reference images;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="50" name="50" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="51">真实世界的场景往往包含极其丰富的亮度、色彩、强度等诸多图像信息,但传统的数字图像获取技术的表现能力有限,数字图像无法准确呈现出真实场景的全部信息,由此产生了高动态范围(HDR)图像合成技术。</p>
                </div>
                <div class="p1">
                    <p id="52">其中多曝光图像融合技术是获取HDR图像的最主要途径,通过调节相机光圈及曝光时间,可在不改变硬件的情况下对同一场景执行多次曝光,之后适当地对其进行融合,最终获得的HDR图像能够重现目标场景的动态范围<citation id="144" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。然而,现实生活中的场景往往是动态的,一旦场景在拍摄过程中发生任何改变,如运动物体的闯入,那么在最终的合成图像中就会呈现模糊或重影现象,一般称之为“鬼影”。由于室外拍摄的场景大多为动态场景,运动物体不可避免,因此研究如何消除合成图像中的鬼影至关重要。近年来,研究者针对运动目标造成的“鬼影”现象提出了不少解决方法。文献<citation id="145" type="reference">[<a class="sup">2</a>]</citation>采用基于梯度域的光流(optical flow)方法计算运动区域的运动向量,根据向量对相邻帧的图像作一致性处理,但该方法只适用于运动幅度较小的场景。基于此,文献<citation id="146" type="reference">[<a class="sup">3</a>]</citation>提出了基于块的运动估计方法以提升相邻曝光之间的一致性,并根据颜色相似度优化饱和区域的运动向量,但其缺点是获得的HDR图像可能会存在块效应。文献<citation id="147" type="reference">[<a class="sup">4</a>]</citation>提出了基于能量的光流方法,该方法可同时进行图像对齐与鬼影去除,但该方法在运动目标运动幅度较大及运动目标被遮挡的情况下HDR成像效果不好。文献<citation id="148" type="reference">[<a class="sup">5</a>]</citation>提出了基于零均值归一化互相关(ZNCC)的鬼影检测方法,但只适用于造成鬼影的移动物体出现在大多数图像中的情况。基于此,文献<citation id="149" type="reference">[<a class="sup">6</a>]</citation>中挑选出一幅曝光良好的图像作为参考图像,并计算其他输入图像与参考图像之间梯度方向的改变量,以此来检测出图像中的鬼影区域。文献<citation id="150" type="reference">[<a class="sup">7</a>]</citation>提出了一种基于图像块的优化算法,将曝光等级处于中间的一帧图像视为参考图像,在合成HDR图像的同时进行图像对齐并去除鬼影。文献<citation id="151" type="reference">[<a class="sup">8</a>]</citation>是通过提取参考图像与其他图像之间的密集匹配,并采用图像块拼接<citation id="152" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>的方式对匹配较差的区域进行修复,进而达到去除鬼影的效果。然而,当参考图像存在较大范围的曝光过度/不足区域时,该算法的合成效果较差。文献<citation id="153" type="reference">[<a class="sup">10</a>]</citation>利用参考图像与其他图像之间的匹配关系构建出一组中间图像,同时将参考图像中的饱和区域以序列中其他图像的内容进行修补,以应对参考图像中存在大片饱和区域及相机严重抖动的问题。文献<citation id="154" type="reference">[<a class="sup">11</a>]</citation>通过对鬼影区域添加相关的物理约束条件,将鬼影检测视为低秩矩阵填充问题来处理,但该算法不适用于图像中包含大片重叠区域的运动物体。文献<citation id="155" type="reference">[<a class="sup">12</a>]</citation>则是将上述低秩问题近似为核范数最小化问题,采用人工选取运动区域、奇异值部分,基于最小化算法对矩阵填充算法进行优化,并同时进行图像对齐与鬼影去除。但该方法对于场景中分布较为离散或内容较复杂的运动区域,手动选取的难度会显著增加。</p>
                </div>
                <div class="p1">
                    <p id="53">针对上述问题,本文在图像块分解思想的基础上,对于最终融合图像保留了参考图像大量信息以致部分区域出现细节丢失这一现象,提出了一种基于图像块分解的多曝光图像融合去鬼影算法,最终获得了细节信息更准确的HDR图像。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">2 所提算法</h3>
                <div class="p1">
                    <p id="55">所提算法的总体框架如图1所示,其主要计算过程如下:将图像块分解成信号强度、信号结构、平均强度三个概念相独立的部分。从输入多曝光图像序列中挑选出一幅曝光良好的图像作为参考图像。通过强度映射函数(IMF)<citation id="156" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>将参考图像的强度值映射到其余输入多曝光图像序列中,得到相应的输入多曝光潜像序列,其目标位置与参考图像一致,曝光等级不发生改变。为了更好地呈现出参考图像中曝光不足/过度区域的细节信息,将掩模添加至参考图像的方式划分为曝光正常及曝光不正常(曝光不足/过度)两个区域。并对这两部分区域作分开处理,进行后续的图像块结构一致性检测与图像块平均强度差异检测(以便更好地填充参考图像中曝光不正常区域),从而去掉结构不一致的图像块,并用相应位置的图像块所替代。分别融合图像块的三个分量,重构所需的图像块,并将其添加至最终的融合图像中。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 所提算法框架" src="Detail/GetImg?filename=images/GXXB201909016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 所提算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Framework of proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>2.1 图像块分解</b></h4>
                <div class="p1">
                    <p id="59">假设输入的多曝光序列图像有<i>N</i>张,用<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mrow><mo>|</mo><mrow><mn>1</mn><mo>≤</mo><mi>n</mi><mo>≤</mo><mi>Ν</mi></mrow></mrow><mo stretchy="false">}</mo></mrow></math></mathml>表示从<i>N</i>张多曝光序列图像的相同空间位置处提取出的一组彩色图像块。给定一个图像块,将其分解成信号强度、信号结构和平均强度三个组成部分。</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>⋅</mo><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub></mrow><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo>+</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></mstyle><mo>∼</mo></mover></mrow><mo>|</mo></mrow><mo>⋅</mo><mfrac><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub></mrow><mrow><mrow><mo>|</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></mstyle><mo>∼</mo></mover></mrow><mo>|</mo></mrow></mrow></mfrac><mo>+</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>n</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>n</mi></msub><mo>+</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow></mrow></math></mathml>为向量的模;<i>μ</i><sub><i><b>x</b></i></sub><sub><i>n</i></sub>为图像块的平均值<i>μ</i><sub><i><b>x</b></i></sub><sub><i>n</i></sub>组成的列向量;<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub></mrow></math></mathml>为去掉平均值的图像块;<i><b>c</b></i><sub><i>n</i></sub>、<i><b>s</b></i><sub><i>n</i></sub>和<i><b>l</b></i><sub><i>n</i></sub>分别为图像块<i><b>x</b></i><sub><i>n</i></sub>的信号强度<i>c</i><sub><i>n</i></sub>、信号结构<i>s</i><sub><i>n</i></sub>和平均强度分量<i>l</i><sub><i>n</i></sub>组成的列向量。这里,所有的<i><b>x</b></i><sub><i>n</i></sub>都是维度为<i>CS</i><sup>2</sup>的列向量,其中<i>C</i>为输入图像颜色通道的数量,<i>S</i>为图像块的空间尺寸。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>2.2 参考图像分区</b></h4>
                <div class="p1">
                    <p id="63">假设输入多曝光图像序列预先通过图像配准算法<citation id="157" type="reference"><link href="36" rel="bibliography" /><link href="38" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>对齐,从输入图像序列中挑选曝光质量表现最好的一幅图像作为参考图像,类似于文献<citation id="158" type="reference">[<a class="sup">16</a>,<a class="sup">17</a>]</citation>中典型的基于参考图像的方法。若所有图像在内容上都与最终的融合目标区别较大,则可选取其中含运动目标最清晰的图像作为参考图像。若所有图像在内容上都与最终的融合目标一致,则可选取其中含饱和像素最少的图像作为参考图像。即便如此,参考图像中的某些区域依然会存在曝光不足及曝光过度的现象。为了减轻参考图像中曝光不正常区域对最终融合图像的影响,采用添加掩模的方式,将参考图像划分为曝光正常及曝光不正常两个区域。</p>
                </div>
                <div class="p1">
                    <p id="64">通过变换这个区间的阈值发现,当设定强度值区间为[40,220]时,掩模能够较好地包含参考图像中曝光正常位置的像素点。因此,将参考图像中像素点强度值位于[40,220]区间内表示为曝光正常,相应地,像素点强度值小于40及大于220的部分分别表示为曝光不足及曝光过度。若参考图像块中超过80%的像素点强度值位于[40,220]区间内,将视该图像块为曝光正常,反之,则视该图像块为曝光不足或曝光过度,其对应关系如下</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mtext>r</mtext><mtext>L</mtext></msubsup><mo>,</mo></mtd><mtd><mi>m</mi><msup><mrow></mrow><mtext>L</mtext></msup><mo>&gt;</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>Ν</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mtext>r</mtext><mtext>Μ</mtext></msubsup><mo>,</mo></mtd><mtd><mi>m</mi><msup><mrow></mrow><mtext>Μ</mtext></msup><mo>&gt;</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>Ν</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mtext>r</mtext><mtext>Η</mtext></msubsup><mo>,</mo></mtd><mtd><mi>m</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mo>&gt;</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>Ν</mi></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式中:<i>N</i>为参考图像块<i><b>x</b></i><sub>r</sub>中的像素点个数;<i>m</i><sup>L</sup>,<i>m</i><sup>M</sup>,<i>m</i><sup>H</sup>分别为参考图像块中位于曝光不足、曝光正常及曝光过度区域的像素点个数;相应地,<i><b>x</b></i><sup>L</sup><sub>r</sub>,<i><b>x</b></i><sup>M</sup><sub>r</sub>及<i><b>x</b></i><sup>H</sup><sub>r</sub>则分别为参考图像曝光不足、曝光正常及曝光过度的图像块。为方便起见,将曝光不足/过度图像块归为一类,用<i><b>x</b></i><sup>A</sup><sub>r</sub>表示,即<i><b>x</b></i><sup>L</sup><sub>r</sub>∪<i><b>x</b></i><sup>H</sup><sub>r</sub>=<i><b>x</b></i><sup>A</sup><sub>r</sub>。最终的图像被划分成曝光正常及曝光不正常两个区域。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.3 鬼影的检测及去除</b></h4>
                <div class="p1">
                    <p id="68">为了使得参考图像中曝光不足/过度区域的细节信息得到更好的展现,对参考图像曝光正常/不正常区域对应的输入多曝光序列图像块,分别进行图像块的结构一致性检测和图像块的平均强度差异检测,得到输入多曝光序列图像的最终结构一致性二值图,其大致过程如图2所示。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.3.1 图像块的结构一致性检测</h4>
                <div class="p1">
                    <p id="70">通过计算参考图像块的信号结构分量<i><b>s</b></i><sub>r</sub>与对应位置输入多曝光序列图像块的信号结构分量<i><b>s</b></i><sub><i>n</i></sub>之间的内积,进行图像块的结构一致性检测,即</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mtext>r</mtext><mtext>Τ</mtext></msubsup><mo>⋅</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo>-</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo>-</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mtext>r</mtext></msub></mrow><mo>|</mo></mrow><mrow><mo>|</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>+</mo><mi>ε</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">式中:<i>θ</i><sub><i>n</i></sub>位于[-1,1]中,值越大表示<i><b>s</b></i><sub>r</sub>和<i><b>s</b></i><sub><i>n</i></sub>之间的一致性越高;<i><b>l</b></i><sub>r</sub>为参考图像块的平均强度分量<i>l</i><sub>r</sub>组成的列向量;为避免分母趋近于零,<i>ε</i><sub>0</sub>取值为一个很小的常数。</p>
                </div>
                <div class="p1">
                    <p id="73">通过定义阈值<i>K</i><sub>s</sub>将<i>θ</i><sub><i>n</i></sub>二值化,来去掉结构不一致的图像块,即</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>,</mo></mtd><mtd><mtext>i</mtext><mtext>f</mtext><mtext> </mtext><mi>θ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>≥</mo><mi>Κ</mi><msub><mrow></mrow><mtext>s</mtext></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mtext>i</mtext><mtext>f</mtext><mtext> </mtext><mi>θ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>≤</mo><mi>Κ</mi><msub><mrow></mrow><mtext>s</mtext></msub></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">式中:<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub></mrow></math></mathml>为相应的结构一致性二值图。对于参考图像曝光正常区域对应的输入多曝光序列图像,结构一致性二值图表示为<mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msubsup><mrow></mrow><mi>n</mi><mtext>Ν</mtext></msubsup></mrow></math></mathml>。相应地,对于参考图像曝光不正常区域对应的输入多曝光序列图像的结构一致性二值图表示为<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msubsup><mrow></mrow><mi>n</mi><mtext>A</mtext></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">2.3.2 图像块的平均强度差异检测</h4>
                <div class="p1">
                    <p id="77">为了更好地填充参考图像中曝光不足及曝光过度的区域,在结构一致性检测的基础上添加另一个约束以检查这些结构是否适合于融合。利用<i>IMF</i>将参考图像强度值映射到输入多曝光序列图像中,得到相应的输入多曝光潜像序列。由于其强度值与输入多曝光序列图像强度值保持一致,且保留了参考图像的内容,故可通过计算参考图像块与对应位置潜像序列图像块之间的平均强度分量间的差异,来去掉那些与参考图像块平均强度差异过大的图像块,即去掉在输入多曝光图像序列中的曝光不足/过度图像块。此处,只检测参考图像曝光正常区域图像块与对应位置潜像序列图像块之间平均强度的差异,即</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 鬼影的检测及去除框架" src="Detail/GetImg?filename=images/GXXB201909016_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 鬼影的检测及去除框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Framework of ghost detection and removal</p>

                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Μ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>,</mo></mtd><mtd><mtext>i</mtext><mtext>f</mtext><mtext> </mtext><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo>-</mo><msup><mi mathvariant="bold-italic">l</mi><mo>′</mo></msup><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>|</mo></mrow><mo>&lt;</mo><mi>Κ</mi><msub><mrow></mrow><mtext>m</mtext></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mtext>i</mtext><mtext>f</mtext><mtext> </mtext><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mtext>r</mtext></msub><mo>-</mo><msup><mi mathvariant="bold-italic">l</mi><mo>′</mo></msup><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>|</mo></mrow><mo>≥</mo><mi>Κ</mi><msub><mrow></mrow><mtext>m</mtext></msub></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">式中:<i>K</i><sub>m</sub>为预先定义的阈值;<i><b>l</b></i>′<sub><i>n</i></sub>为对应位置多曝光潜像序列图像块的平均强度分量<i>l</i>′<sub><i>n</i></sub>组成的列向量。</p>
                </div>
                <div class="p1">
                    <p id="82">因此,对于参考图像中曝光正常区域对应的输入多曝光序列图像,最终的结构一致性检测二值图为</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Μ</mi><msubsup><mrow></mrow><mi>n</mi><mtext>Ν</mtext></msubsup><mo>=</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msubsup><mrow></mrow><mi>n</mi><mtext>Ν</mtext></msubsup><mo>⋅</mo><mover accent="true"><mi mathvariant="bold-italic">Μ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">对于参考图像中曝光不正常区域对应的输入多曝光序列图像,最终的结构一致性检测二值图为</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Μ</mi><msubsup><mrow></mrow><mi>n</mi><mtext>A</mtext></msubsup><mo>=</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Μ</mi></mstyle><mo>∼</mo></mover></mrow><msubsup><mrow></mrow><mi>n</mi><mtext>A</mtext></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">将上述两部分相加,得到最终的结构一致性二值图为</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi mathvariant="bold-italic">Μ</mi><msubsup><mrow></mrow><mi>n</mi><mtext>A</mtext></msubsup><mo>+</mo><mi mathvariant="bold-italic">Μ</mi><msubsup><mrow></mrow><mi>n</mi><mtext>Ν</mtext></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">图3展示了由输入多曝光Puppet序列得到的最终结构一致性二值图。图中选择第3幅图像作为参考图像,图3(b)中的黑色区域表示与参考图像结构不一致的部分,即其余4幅图像基于参考图像得到的鬼影区域。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>2.4 图像块的融合过程</b></h4>
                <div class="p1">
                    <p id="90">通过结构一致性检测,去掉与参考图像结构不一致的图像块,之后对图像块进行融合,分别融合其信号强度、信号结构、平均强度三个分量,并根据图像块强度、曝光度和结构的一致性措施对每个部分进行处理,重构所需图像块并将其添加至最终融合图像中。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2.4.1 图像块信号强度分量的融合</h4>
                <div class="p1">
                    <p id="92">由于局部图像块结构的可见性很大程度上取决于局部对比度,其与信号强度直接相关。输入源图像序列中具有最高对比度的图像块将对应于真实性约束条件下具有最佳可见性的图像块。因此,融合图像块的信号强度由所有源图像块中最高的信号强度确定,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>c</mi><mo>^</mo></mover><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>n</mi><mo>≤</mo><mi>Ν</mi></mrow></munder><mspace width="0.25em" /><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>n</mi><mo>≤</mo><mi>Ν</mi></mrow></munder><mrow><mo>|</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>|</mo></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式中<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>c</mi><mo>^</mo></mover></math></mathml>表示融合图像块的信号强度,c<sub>n</sub>表示图像块x<sub>n</sub>的信号强度。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">2.4.2 图像块信号结构分量的融合</h4>
                <div class="p1">
                    <p id="96">与信号强度分量不同,局部图像块的结构用单位长度向量<i><b>s</b></i><sub><i>n</i></sub>表示,其中1≤<i>n</i>≤<i>N</i>,每个向量指向向量空间中的特定方向。融合图像块的结构对应于相同向量空间中的另一个方向,该方向能最佳地反映所有源图像块的结构,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">s</mi><mo>^</mo></mover><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>S</mi></mstyle><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>S</mi></mstyle><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>/</mo><mrow><mo>|</mo><mrow><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>S</mi></mstyle><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>S</mi></mstyle><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>|</mo></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">式中:<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">s</mi><mo>^</mo></mover></math></mathml>表示融合图像块的信号结构<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">s</mi><mo>^</mo></mover></math></mathml>组成的列向量,<i>S</i>(·)为加权函数,用于确定融合图像块结构中每个源图像块的贡献。直观地说,贡献应随图像块强度的增加而增加。由此可得</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 输入多曝光Puppet序列的鬼影检测图。" src="Detail/GetImg?filename=images/GXXB201909016_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 输入多曝光Puppet序列的鬼影检测图。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Input ghost detection images of multi-exposure Puppet sequence.</p>
                                <p class="img_note">(a）输入多曝光Puppet序列；（b）对应的结构一致性二值图</p>
                                <p class="img_note">(a)Input multi-exposure Puppet sequence;(b)corresponding structural consistency binary images</p>

                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mrow><mo>|</mo><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mi>ρ</mi></msup><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">式中<i>ρ</i>≥0,为一个指数参数,<i>ρ</i>越大,则表示强度越强的图像块的贡献就越大。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">2.4.3 图像块平均强度分量的融合</h4>
                <div class="p1">
                    <p id="104">对于图像块的平均强度,采取类似(10)式的方式,则有</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>l</mi><mo>^</mo></mover><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>L</mi></mstyle><mo stretchy="false">(</mo><mi>μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>L</mi></mstyle><mo stretchy="false">(</mo><mi>μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">式中:<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>l</mi><mo>^</mo></mover></math></mathml>表示融合图像块的平均强度;L(·)为将彩色图像<i><b>X</b></i><sub><i>n</i></sub>的全局平均值<i>μ</i><sub><i>n</i></sub>和当前图像块<i><b>x</b></i><sub><i>n</i></sub>的局部平均值<i>l</i><sub><i>n</i></sub>作为输入的加权函数。其量化<i><b>x</b></i><sub><i>k</i></sub>在<i><b>X</b></i><sub><i>k</i></sub>中的曝光程度,当<i><b>X</b></i><sub><i>k</i></sub>或<i><b>x</b></i><sub><i>k</i></sub>曝光不足/过度时,给出较大的惩罚。本研究采用二维高斯轮廓来进行度量,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mrow><mo>[</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false">(</mo><mi>μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mtext>a</mtext><mn>2</mn></msubsup></mrow></mfrac><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false">(</mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mtext>b</mtext><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>]</mo></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">式中:<i>σ</i><sub>a</sub>和<i>σ</i><sub>b</sub>分别控制剖面沿<i>μ</i><sub><i>n</i></sub>和<i>l</i><sub><i>n</i></sub>维度的扩展;<i>μ</i><sub>c</sub>和<i>l</i><sub>c</sub>为中等强度值常数,值为0.5。</p>
                </div>
                <div class="p1">
                    <p id="109">由(13)式计算出融合图像块的信号强度、信号结构,以及平均强度分量。从而可得到融合图像块为</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mo>⋅</mo><mover accent="true"><mi mathvariant="bold-italic">s</mi><mo>^</mo></mover><mo>+</mo><mover accent="true"><mi mathvariant="bold-italic">l</mi><mo>^</mo></mover><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">式中<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml>为融合图像块;<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mo>,</mo><mover accent="true"><mi mathvariant="bold-italic">l</mi><mo>^</mo></mover></mrow></math></mathml>分别为融合图像块<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml>的信号强度和平均强度分量组成的向量。通过聚合这些图像块,就可获得无鬼影的HDR融合图像。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">3 实验结果分析</h3>
                <div class="p1">
                    <p id="113">所有的实验都是在Intel i5处理器(3.4 GHz,64位),8G内存的计算机平台上利用Matlab 2017b编程实现。选择当前具有代表性的Oh<citation id="159" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、Sen<citation id="160" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、photomatix<citation id="161" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,以及Ma<citation id="162" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>这4种去鬼影算法与本文算法作对比,并比较在三种场景下的去鬼影实验结果。</p>
                </div>
                <div class="p1">
                    <p id="114">对实验中算法的相关参数进行设置。算法中阈值<i>K</i><sub>s</sub>和<i>K</i><sub>m</sub>对于存在相机和物体运动情况下的动态场景的鬼影检测至关重要,且<i>K</i><sub>s</sub>和<i>K</i><sub>m</sub>都具有相同的范围[0,1]。理想情况下,最终结构一致性图应该能够精确地检测出输入多曝光图像基于参考图像中的运动区域,以充分利用有效的信息进行后续地融合过程。对于<i>K</i><sub>s</sub>而言,当<i>K</i><sub>s</sub>相对较小时,结构一致性检查不能完全检测出移动物体,特别是离参考图像的曝光值较远的输入曝光图像。反之,当<i>K</i><sub>s</sub>太大时,结构一致性检查错误地将曝光中的一些一致运动视为不一致并且拒绝他们。根据经验发现,当<i>K</i><sub>s</sub>=0.8时,能够可靠地识别出多曝光图像中基于参考图像的不一致运动区域,并充分利用一致的区域进行融合。对于<i>K</i><sub>m</sub>而言,当设置的值相对较大时,算法不能很好地填充一些曝光不足/过度的区域。而当<i>K</i><sub>m</sub>太小时,算法开始拒绝曝光图像中的一致运动。根据经验发现,当<i>K</i><sub>m</sub>=0.1时,可达到细化结构一致性图而非拒绝一致运动区域的效果。此外,对于图像块尺寸<i>S</i>而言,其值越大,信号结构矢量在结构一致性方面就越稳健,但其计算复杂度也会增加。而<i>S</i>太小,则会导致一些鬼影产生。根据经验发现,当<i>S</i>=24时,可在性能与复杂度之间取得良好的平衡。最终,本文将实验参数固定为<i>S</i>=24、<i>ρ</i>=4、<i>σ</i><sub>a</sub>=0.2、<i>σ</i><sub>b</sub>=0.5、<i>K</i><sub>s</sub>=0.8及<i>K</i><sub>m</sub>=0.1。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>3.1 主观评价</b></h4>
                <div class="p1">
                    <p id="116">多曝光图像序列sculpture garden<citation id="163" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、puppets<citation id="164" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,以及BabyOnGrass<citation id="165" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>的实验结果如图4～6所示。图4为sculpture garden序列的实验结果,第一行为5张不同曝光度的输入图像序列,下面两行分别展示了本文与其他4种去鬼影算法的实验结果及结果图中相同区域的局部放大图像,其中选取第3幅图像作为参考图像。由结果图可知,photomatix算法的整体饱和度不高,Sen算法在天空区域出现了颜色失真。由局部放大图可知,Oh算法产生了明显的鬼影现象,Sen及photomatix算法在楼梯处呈现出白色伪影,Ma算法在门的位置稍显模糊。相较而言,本文算法能在有效去除鬼影的同时保留参考图像中曝光不正常区域的细节信息。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Sculpture garden序列去鬼影对比实验结果。" src="Detail/GetImg?filename=images/GXXB201909016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Sculpture garden序列去鬼影对比实验结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Comparing results of de-ghosting experiment of Sculpture garden sequence.</p>
                                <p class="img_note">(a)Sculpture garden图像序列；（b)(g)Oh算法；（c)(h)Sen算法；(d)(i)photomatix算法；（e)(j)Ma算法；（f)(k）所提算法</p>
                                <p class="img_note">(a)Sculpture garden image sequence;(b)(g)Oh′s algorithm;(c)(h)Sen′s algorithm;(d)(i)photomatix′s algorithm;(e)(j)Ma′s algorithm；（f)(k)proposed algorithm</p>

                </div>
                <div class="p1">
                    <p id="118">图5为puppets序列的实验结果,其中选择第3幅图像作为参考图像。由结果图可知,Oh算法在玩偶耳朵的影子边界存在鬼影现象,photomatix算法在玩偶耳朵及橄榄球的阴影处丢失了一些图像信息,Sen算法尽管在一定程度上减少了鬼影,但在橄榄球下方区域出现了比较明显的伪影,Ma算法基本去除了鬼影,但在球及玩偶耳朵的影子处出现了斑驳现象。相较而言,本文算法的伪影较少,且图像细节比较清晰。</p>
                </div>
                <div class="p1">
                    <p id="119">图6为BabyOnGrass序列的实验结果,选定第3幅图像作为参考图像。对比结果图的局部放大区域可知,Oh、Sen、photomatix,以及Ma等的算法都在树枝中间较明亮的地方产生了鬼影现象。且从结果图中也可以看出,本文的视觉效果相对较好,图像细节信息也较为丰富。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>3.2 客观评价</b></h4>
                <div class="p1">
                    <p id="121">当前,普遍采用HDR-VDP-2客观评价模型<citation id="166" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>对HDR图像的品质进行预测。该视觉模型能够在输入测试图像与参考图像之间预测出视觉与质量区别,<i>Q</i><sub>mos</sub>(mean opinion score)可对测试图像与参考图像之间的失真度进行直观地评判,进而体现出最终获得的图像质量的好坏程度,若数值越大则表示图像的品质越高,反之,则表示图像的品质越差。表1为经HDR-VDP-2评判出的5种算法在三组多曝光序列上所得结果的<i>Q</i><sub>mos</sub>值。对于每一组图像,其最大数值采用加粗字体标明。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 puppets序列去鬼影对比实验结果。" src="Detail/GetImg?filename=images/GXXB201909016_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 puppets序列去鬼影对比实验结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Comparing results of de-ghosting experiments of puppets sequence.</p>
                                <p class="img_note">(a)puppets图像序列；（b)(g)Oh算法；（c)(h)Sen算法；(d)(i)photomatix算法；（e)(j)Ma算法；（f)(k）所提算法</p>
                                <p class="img_note">(a)puppets image sequence;(b)(g)Oh′s algorithm;(c)(h)Sen′s algorithm;(d)(i)photomatix′s algorithm;(e)(j)Ma′s algorithm;(f)(k)proposed algorithm</p>

                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201909016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 BabyOnGrass序列去鬼影对比实验结果。" src="Detail/GetImg?filename=images/GXXB201909016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 BabyOnGrass序列去鬼影对比实验结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201909016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Comparing results of de-ghosting experiments of BabyOnGrass sequence.</p>
                                <p class="img_note">(a)BabyOnGrass图像序列；（b)(g)Oh算法；（c)(h)Sen算法；(d)(i)photomatix算法；（e)(j)Ma算法；（f)(k）所提算法</p>
                                <p class="img_note">(a)BabyOnGrass image sequence;(b)(g)Oh′s algorithm;(c)(h)Sen′s algorithm;(d)(i)photomatix′s algorithm;(e)(j)Ma′s algorithm;(f)(k)proposed algorithm</p>

                </div>
                <div class="area_img" id="124">
                    <p class="img_tit">表1 采用HDR-VDP2模型评估五种算法的结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Evaluation results of five algorithms using HDR-VDP2 model</p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td rowspan="2"><br />Image sequence</td><td colspan="5"><br /><i>Q</i><sub>mos</sub></td></tr><tr><td>Oh′s <br />algorithm</td><td>Sen′s <br />algorithm</td><td>photomatix′s<br />algorithm</td><td>Ma′s <br />algorithm</td><td>Proposed<br />algorithm</td></tr><tr><td>Sculpture garden image sequence</td><td>39.5632</td><td>44.8876</td><td><b>48.6635</b></td><td>46.1691</td><td>45.3746</td></tr><tr><td><br />puppets image sequence</td><td>50.5574</td><td>51.6934</td><td>47.7747</td><td>52.4349</td><td><b>52.4408</b></td></tr><tr><td><br />BabyOnGrass image sequence</td><td>44.4329</td><td>50.7220</td><td>42.2317</td><td>44.5276</td><td><b>57.9048</b></td></tr><tr><td><br />Average value</td><td>44.8512</td><td>49.1010</td><td>46.2232</td><td>47.7081</td><td><b>51.9067</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="125">从表1可知,本文方法所得的<i>Q</i><sub>mos</sub>在两组测试序列中取得了最高值,且平均值在4种对比算法中也达到了最高,即表明本文算法不仅可以有效地去除鬼影,还能保证较高的图像质量。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>3.3 算法执行时间</b></h4>
                <div class="p1">
                    <p id="127">所提算法与其他4种算法在三组多曝光序列上的执行时间如表2所示。对应的图像尺寸分别为1024 pixel×754 pixel、812 pixel×1024 pixel,以及900 pixel×1350 pixel。由表2的对比结果可知,本文算法的计算效率显著优于Oh及Sen的算法,且稍优于Ma算法,其计算效率最高。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit">表2 不同高动态范围图像去鬼影算法的计算效率对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Comparison of computational efficiencies of different high-dynamic-range image de-ghosting algorithms</p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td rowspan="2"><br />Image sequence</td><td rowspan="2">Image size /(pixel×pixel)</td><td colspan="4"><br />Time</td></tr><tr><td>Oh′s<br />algorithm</td><td>Sen′s <br />algorithm</td><td>Ma′s <br />algorithm</td><td>Proposed<br />algorithm</td></tr><tr><td>Sculpture garden image sequence</td><td>1024×754</td><td>91.06</td><td>297.03</td><td>22.20</td><td><b>12.18</b></td></tr><tr><td><br />puppets image sequence</td><td>812×1024</td><td>77.94</td><td>230.85</td><td>24.89</td><td><b>13.16</b></td></tr><tr><td><br />BabyOnGrass image sequence</td><td>900×1350</td><td>127.15</td><td>145.36</td><td>18.14</td><td><b>17.67</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="129" name="129" class="anchor-tag">4 结  论</h3>
                <div class="p1">
                    <p id="130">提出了一种基于图像块分解的多曝光图像融合去鬼影算法,首先将图像块分解成信号结构、信号强度、平均强度3个相独立的部分,对参考图像进行预先分区,避免了因最终融合图像继承参考图像的大量信息而导致的融合图像在参考图像曝光不正常区域出现细节丢失现象。此外,使用结构向量的方向信息进行结构一致性检测,可靠地去除了鬼影。之后分别对每个部分进行融合,以重构图像块并将其添加至最终融合图像中。实验结果表明,本文算法得到的融合图像不仅具有清晰的细节、良好的视觉效果和极少的伪影,且计算效率较高。但在不同控制参数(如图像块尺寸大小、步长、结构一致性阈值,以及平均强度差异阈值等)的自适应性方面仍然存在不足,今后将进一步研究参数自适应的调控,提高算法的实用性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201704013&amp;v=MjQ2OTR6cXFCdEdGckNVUkxPZVplVnZGeTNuVmJ2S0lqWFRiTEc0SDliTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Du L,Sun H Y,Wang S,<i>et al</i>.High dynamic range image fusion algorithm for moving targets[J].Acta Optica Sinica,2017,37(4):0410001.都琳,孙华燕,王帅,等.针对动态目标的高动态范围图像融合算法研究[J].光学学报,2017,37(4):0410001.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098000&amp;v=MjIyODBUTW53WmVadUh5am1VYjdJSlZ3U2JoQT1OaWZJWTdLN0h0ak5yNDlGWk9JSERIdzVvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Kang S B,Uyttendaele M,Winder S,<i>et al</i>.High dynamic range video[J].ACM Transactions on Graphics,2003,22(3):319-325.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High dynamic range video with ghost removal">

                                <b>[3]</b> Mangiat S,Gibson J.High dynamic range video with ghost removal[J].Proceedings of SPIE,2010,7798:779812.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Freehand HDR Imaging of Moving Scenes with Simultaneous Resolution Enhancement">

                                <b>[4]</b> Zimmer H,Bruhn A,Weickert J.Freehand HDR imaging of moving scenes with simultaneous resolution enhancement[J].Computer Graphics Forum,2011,30(2):405-414.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Motion artifact-free HDR imaging under dynamic environments">

                                <b>[5]</b> Park S C,Oh H H,Kwon J H,<i>et al</i>.Motion artifact-free HDR imaging under dynamic environments[C]∥2011 18th IEEE International Conference on Image Processing,September 11-14,2011,Brussels,Belgium.New York:IEEE,2011:11-14.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient-Directed Multiexposure Composition">

                                <b>[6]</b> Zhang W,Cham W K.Gradient-directed multiexposure composition[J].IEEE Transactions on Image Processing,2012,21(4):2318-2323.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007839&amp;v=MTI1NjV5am1VYjdJSlZ3U2JoQT1OaWZJWTdLN0h0ak5yNDlGWk9zSUJIOHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Sen P,Kalantari N K,Yaesoubi M,<i>et al</i>.Robust patch-based HDR reconstruction of dynamic scenes[J].ACM Transactions on Graphics,2012,31(6):203.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000002939&amp;v=MjEwNzk9TmlmSVk3SzdIdGpOcjQ5RlpPc05CWDh3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSlZ3U2JoQQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> HaCohen Y,Shechtman E,Goldman D B,<i>et al</i>.Non-rigid dense correspondence with applications for image enhancement[J].ACM Transactions on Graphics,2011,30(4):70.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast approximate energy minimization via graph cuts">

                                <b>[9]</b> Boykov Y,Veksler O,Zabih R.Fast approximate energy minimization via graph cuts[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2001,23(11):1222-1239.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exposure stacks of live scenes with hand-held cameras">

                                <b>[10]</b> Hu J,Gallo O,Pulli K.Exposure stacks of live scenes with hand-held cameras[M]∥Fitzgibbon A,Lazebnik S,Perona P,<i>et al</i>.Computer vision-ECCV 2012.Lecture notes in computer science.Berlin,Heidelberg:Springer,2012,7572:499-512.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ghost-Free High Dynamic Range Imaging via Rank Minimization">

                                <b>[11]</b> Lee C,Li Y,Monga V.Ghost-free high dynamic range imaging via rank minimization[J].IEEE Signal Processing Letters,2014,21(9):1045-1049.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust high dynamic range imaging by rank minimization">

                                <b>[12]</b> Oh T H,Lee J Y,Tai Y W,<i>et al</i>.Robust high dynamic range imaging by rank minimization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2015,37(6):1219-1232.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Determining the camera response from images: What is knowable?">

                                <b>[13]</b> Grossberg M D,Nayar S K.Determining the camera response from images:What is knowable?[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(11):1455-1467.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD14082200000688&amp;v=MjYxODJuQmFySzhIdG5Pclk5RlpPc1BDblF4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSlZ3U2JoQT1Oag==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Ward G.Fast,robust image registration for compositing high dynamic range photographs from hand-held exposures[J].Journal of Graphics Tools,2003,8(2):17-30.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjkwNjFyTzRIdEhPcDR4RmJlc09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTbmxWcjNPSkZ3PU5qN0Jh&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263297&amp;v=MTIzMDFWd1NiaEE9TmlmT2ZiSzdIdEROcW85RVp1ME1EblUrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Zhang W,Cham W K.Reference-guided exposure fusion in dynamic scenes[J].Journal of Visual Communication and Image Representation,2012,23(3):467-475.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Artifact-free High Dynamic Range Imaging">

                                <b>[17]</b> Gallo O,Gelfandz N,Chen W C,<i>et al</i>.Artifact-free high dynamic range imaging[C]∥2009 IEEE International Conference on Computational Photography (ICCP),April 16-17,2009,San Francisco,CA,USA.New York:IEEE,2009:5559003.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Commercially-available HDR processing software[OL]">

                                <b>[18]</b> Commercially-available HDR processing software[OL].[2019-03-10].http://www.hdrsoft.com/.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust multi-exposure image fusion:a structural patch decomposition approach">

                                <b>[19]</b> Ma K D,Li H,Yong H W,<i>et al</i>.Robust multi-exposure image fusion:a structural patch decomposition approach[J].IEEE Transactions on Image Processing,2017,26(5):2519-2532.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000002909&amp;v=Mjk1MzFOQlh3d29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpWd1NiaEE9TmlmSVk3SzdIdGpOcjQ5RlpPcw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> Mantiuk R,Kim K J,Rempel A G,<i>et al</i>.HDR-VDP-2:a calibrated visual metric for visibility and quality predictions in all luminance conditions[J].ACM Transactions on Graphics,2011,30(4):40.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201909016" />
        <input id="dpi" type="hidden" value="200" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201909016&amp;v=MjQwMjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5M25WYnZLSWpYVGJMRzRIOWpNcG85RVlvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

