

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134013098565000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905031%26RESULT%3d1%26SIGN%3dq8BOtCw0TcDa79rDtXdob2lNq%252bE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905031&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905031&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905031&amp;v=MTMwMzBqTXFvOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVTdyQklqWFRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#6" data-title="2 算法描述 ">2 算法描述</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#8" data-title="2.1 背景感知相关滤波器">2.1 背景感知相关滤波器</a></li>
                                                <li><a href="#29" data-title="2.2 多通道背景感知相关滤波器多通道相关滤波器表达形式为">2.2 多通道背景感知相关滤波器多通道相关滤波器表达形式为</a></li>
                                                <li><a href="#51" data-title="2.3 通道可靠性系数">2.3 通道可靠性系数</a></li>
                                                <li><a href="#74" data-title="2.4 尺度估计">2.4 尺度估计</a></li>
                                                <li><a href="#80" data-title="2.5 模型更新">2.5 模型更新</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#84" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="3.1 实验环境与参数设置">3.1 实验环境与参数设置</a></li>
                                                <li><a href="#90" data-title="3.2 性能评估">3.2 性能评估</a></li>
                                                <li><a href="#97" data-title="3.3 定量分析">3.3 定量分析</a></li>
                                                <li><a href="#104" data-title="3.4 定性分析">3.4 定性分析</a></li>
                                                <li><a href="#113" data-title="3.5 算法跟踪速率">3.5 算法跟踪速率</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="4 结论 ">4 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#21" data-title="图1 所提算法的框架图">图1 所提算法的框架图</a></li>
                                                <li><a href="#65" data-title="图2 通道可靠性系数示意图。 (a) 第6帧响应图; (b) 第6帧; (c) 第108帧; (d) 第108帧响应图">图2 通道可靠性系数示意图。 (a) 第6帧响应图; (b) 第6帧; (c) 第108帧; (d)......</a></li>
                                                <li><a href="#86" data-title="表1 测试跟踪算法特征">表1 测试跟踪算法特征</a></li>
                                                <li><a href="#87" data-title="表2 实验图像序列特征">表2 实验图像序列特征</a></li>
                                                <li><a href="#95" data-title="图3 8种算法的距离精度曲线和成功率曲线。 (a) 整体距离精度曲线; (b) 整体成功率曲线">图3 8种算法的距离精度曲线和成功率曲线。 (a) 整体距离精度曲线; (b) 整体成功率曲线</a></li>
                                                <li><a href="#100" data-title="图4 不同属性场景的距离精度和成功率曲线。 (a) 光照变化; (b) 尺度变化; (c) 遮挡; (d) 旋转变化">图4 不同属性场景的距离精度和成功率曲线。 (a) 光照变化; (b) 尺度变化; (c) 遮挡; ......</a></li>
                                                <li><a href="#106" data-title="图5 不同方法的跟踪结果。 (a) Lemming; (b) Liquor; (c) Shaking; (d) Singer2; (e) Soccer; (f) Terris">图5 不同方法的跟踪结果。 (a) Lemming; (b) Liquor; (c) Shaking......</a></li>
                                                <li><a href="#107" data-title="表3 平均CLE对比">表3 平均CLE对比</a></li>
                                                <li><a href="#108" data-title="表4 各个算法的OP">表4 各个算法的OP</a></li>
                                                <li><a href="#115" data-title="表5 各个算法的跟踪速度">表5 各个算法的跟踪速度</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="118">


                                    <a id="bibliography_1" title="Yilmaz A, Javed O, Shah M.Object tracking:a survey[J].ACM Computing Surveys, 2006, 38 (2) :1-45." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017656&amp;v=MTY0MTNCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpGOFVieHM9TmlmSVk3SzdIdGpOcjQ5RlpPb0lDbmsvbw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Yilmaz A, Javed O, Shah M.Object tracking:a survey[J].ACM Computing Surveys, 2006, 38 (2) :1-45.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_2" title="Smeulders A W M, Chu D M, Cucchiara R, et al.Visual tracking:an experimental survey[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2014, 36 (7) :1442-1468." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual tracking:an experimental survey">
                                        <b>[2]</b>
                                        Smeulders A W M, Chu D M, Cucchiara R, et al.Visual tracking:an experimental survey[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2014, 36 (7) :1442-1468.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_3" title="Wu Y, Lim J, Yang M H.Object tracking benchmark[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Tracking Benchmark">
                                        <b>[3]</b>
                                        Wu Y, Lim J, Yang M H.Object tracking benchmark[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_4" title="Zhang W, Kang B S.Recent advances in correlation filter-based object tracking:a review[J].Journal of Image and Graphics, 2017, 22 (8) :1017-1033.张微, 康宝生.相关滤波目标跟踪进展综述[J].中国图象图形学报, 2017, 22 (8) :1017-1033." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201708001&amp;v=MjkxNjhIOWJNcDQ5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVN3JCUHlyZmJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Zhang W, Kang B S.Recent advances in correlation filter-based object tracking:a review[J].Journal of Image and Graphics, 2017, 22 (8) :1017-1033.张微, 康宝生.相关滤波目标跟踪进展综述[J].中国图象图形学报, 2017, 22 (8) :1017-1033.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_5" title="Bolme D S, Beveridge J R, Draper B A, et al.Visual object tracking using adaptive correlation filters[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition, 13-18 June 2010, San Francisco, CA, USA, 2010:2544-2550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">
                                        <b>[5]</b>
                                        Bolme D S, Beveridge J R, Draper B A, et al.Visual object tracking using adaptive correlation filters[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition, 13-18 June 2010, San Francisco, CA, USA, 2010:2544-2550.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_6" title="Henriques J F, Caseiro R, Martins P, et al.Exploiting the circulant structure of tracking-bydetection with kernels[C]//Proceedings of European Conference on Computer Vision, 7-13 October, Florence, Italy.2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of trackingby-detection with kernels">
                                        <b>[6]</b>
                                        Henriques J F, Caseiro R, Martins P, et al.Exploiting the circulant structure of tracking-bydetection with kernels[C]//Proceedings of European Conference on Computer Vision, 7-13 October, Florence, Italy.2012:702-715.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_7" title="Danelljan M, Khan F S, Felsberg M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 23-28 June 2014, Columbus, OH, USA.2014:1090-1097." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive color attributes for real-time visual tracking">
                                        <b>[7]</b>
                                        Danelljan M, Khan F S, Felsberg M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 23-28 June 2014, Columbus, OH, USA.2014:1090-1097.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_8" title="Henriques J F, Caseiro R, Martins P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">
                                        <b>[8]</b>
                                        Henriques J F, Caseiro R, Martins P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_9" title="Galoogahi H K, Fagg A, Lucey S.Learning background-aware correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 22-29 Oct.2017, Venice, Italy.2017:1135-1143." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Background-Aware Correlation Filters for Visual Tracking">
                                        <b>[9]</b>
                                        Galoogahi H K, Fagg A, Lucey S.Learning background-aware correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 22-29 Oct.2017, Venice, Italy.2017:1135-1143.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_10" title="Luke6ic A, Voj&#237;r T, Zajc L C, et al.Discriminative correlation filter with channel and spatial reliability[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:4847-4856." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative correlation filter with channel and spatial reliability">
                                        <b>[10]</b>
                                        Luke6ic A, Voj&#237;r T, Zajc L C, et al.Discriminative correlation filter with channel and spatial reliability[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:4847-4856.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_11" title="Li C, Lu C Y, Zhao X, et al.Scale adaptive correlation filter tracking algorithm based on feature fusion[J].Acta Optica Sinica, 2018, 38 (5) :0515001.李聪, 鹿存跃, 赵珣, 等.特征融合的尺度自适应相关滤波跟踪算法[J].光学学报, 2018, 38 (5) :0515001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201805026&amp;v=MDA5MDBJalhUYkxHNEg5bk1xbzlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3ckI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Li C, Lu C Y, Zhao X, et al.Scale adaptive correlation filter tracking algorithm based on feature fusion[J].Acta Optica Sinica, 2018, 38 (5) :0515001.李聪, 鹿存跃, 赵珣, 等.特征融合的尺度自适应相关滤波跟踪算法[J].光学学报, 2018, 38 (5) :0515001.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_12" title="Wang Y C, Huang H, Li S M, et al.Correlation filter tracking based on online detection and scaleadaption[J].Acta Optica Sinica, 2018, 38 (2) :0215002.王艳川, 黄海, 李邵梅, 等.基于在线检测和尺度自适应的相关滤波跟踪[J].光学学报, 2018, 38 (2) :0215002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201802028&amp;v=MzI1OTFNclk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVN3JCSWpYVGJMRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Wang Y C, Huang H, Li S M, et al.Correlation filter tracking based on online detection and scaleadaption[J].Acta Optica Sinica, 2018, 38 (2) :0215002.王艳川, 黄海, 李邵梅, 等.基于在线检测和尺度自适应的相关滤波跟踪[J].光学学报, 2018, 38 (2) :0215002.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_13" title="Liao X F, Hou Z Q, Yu W S, et al.A scale adapted tracking algorithm based on kernelized correlation[J].Acta Optica Sinica, 2018, 38 (7) :0715002.廖秀峰, 侯志强, 余旺盛, 等.基于核相关的尺度自适应视觉跟踪[J].光学学报, 2018, 38 (7) :0715002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807026&amp;v=MTg3NjJDVVJMT2VaZVZ1Rnl6a1U3ckJJalhUYkxHNEg5bk1xSTlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Liao X F, Hou Z Q, Yu W S, et al.A scale adapted tracking algorithm based on kernelized correlation[J].Acta Optica Sinica, 2018, 38 (7) :0715002.廖秀峰, 侯志强, 余旺盛, 等.基于核相关的尺度自适应视觉跟踪[J].光学学报, 2018, 38 (7) :0715002.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_14" title="Ma C, Huang J B, Yang X K, et al.Hierarchical convolutional features for visual tracking[C]//2015IEEE International Conference on Computer Vision, 7-13Dec.2015, Santiago, Chile.2015:3074-3082." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical Convolutional Features for Visual Tracking">
                                        <b>[14]</b>
                                        Ma C, Huang J B, Yang X K, et al.Hierarchical convolutional features for visual tracking[C]//2015IEEE International Conference on Computer Vision, 7-13Dec.2015, Santiago, Chile.2015:3074-3082.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_15" title="Li Y, Zhu J K.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision, 6-12Sep.2014, Zurich, Switzerland.2014:254-265." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">
                                        <b>[15]</b>
                                        Li Y, Zhu J K.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision, 6-12Sep.2014, Zurich, Switzerland.2014:254-265.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_16" title="Bertinetto L, Valmadre J, Golodetz S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 27-30 June 2016, Las Vegas, NV, USA.2016:1 401-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Staple:Complementary learners for real-time tracking">
                                        <b>[16]</b>
                                        Bertinetto L, Valmadre J, Golodetz S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 27-30 June 2016, Las Vegas, NV, USA.2016:1 401-1409.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_17" title="Galoogahi H K, Sim T, Lucey S.Correlation filters with limited boundaries[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 7-12June 2015, Boston, MA, USA.2015:4630-4638." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Correlation Filters with Limited Boundaries">
                                        <b>[17]</b>
                                        Galoogahi H K, Sim T, Lucey S.Correlation filters with limited boundaries[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 7-12June 2015, Boston, MA, USA.2015:4630-4638.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_18" title="Danelljan M, Hger G, Khan F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 7-13 Dec.2015, Santiago, Chile.2015:4310-4318." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning spatially regularized correlation filters for visual tracking">
                                        <b>[18]</b>
                                        Danelljan M, Hger G, Khan F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 7-13 Dec.2015, Santiago, Chile.2015:4310-4318.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_19" title="Mueller M, Smith N, Ghanem B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:1387-1395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">
                                        <b>[19]</b>
                                        Mueller M, Smith N, Ghanem B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:1387-1395.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_20" title="Lukeˇziˇc A, Voj&#237;ˇr T, Cehovin Zajc L, et al.Discriminative correlation filter tracker with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative Correlation Filter Tracker with Channel and Spatial Reliability">
                                        <b>[20]</b>
                                        Lukeˇziˇc A, Voj&#237;ˇr T, Cehovin Zajc L, et al.Discriminative correlation filter tracker with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_21" title="Bibi A, Ghanem B.Multi-templatescale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision Workshop, 7-13Dec.2015, Santiago, Chile.2015:613-620." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-template Scale-Adaptive Kernelized Correlation Filters">
                                        <b>[21]</b>
                                        Bibi A, Ghanem B.Multi-templatescale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision Workshop, 7-13Dec.2015, Santiago, Chile.2015:613-620.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_22" title="Li Y, Zhu J K, Hoi S C H.Reliable Patch Trackers:Robust visual tracking by exploiting reliable patches[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 7-12 June 2015, Boston, MA, USA.2015:353-361." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reliable patch trackers:robust visual tracking by exploiting reliable patches">
                                        <b>[22]</b>
                                        Li Y, Zhu J K, Hoi S C H.Reliable Patch Trackers:Robust visual tracking by exploiting reliable patches[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 7-12 June 2015, Boston, MA, USA.2015:353-361.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-02-02 20:34</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),247-257 DOI:10.3788/AOS201939.0515002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于通道可靠性的多尺度背景感知相关滤波跟踪算法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%B9%E6%98%8E%E9%94%8B&amp;code=27144145&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尹明锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%84%E7%85%9C%E6%98%8E&amp;code=08091562&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薄煜明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%BB%BA%E8%89%AF&amp;code=08097362&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱建良</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E7%9B%98%E9%BE%99&amp;code=10650391&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴盘龙</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0077991&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京理工大学自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对现实场景中跟踪目标的光照变化、尺度变化、遮挡等问题, 提出了一种基于通道可靠性的多尺度背景感知相关滤波跟踪算法。通过提取方向梯度直方图特征、灰度特征和颜色属性特征作为目标表观模型, 提高了目标跟踪方法在复杂场景中的稳健性;独立训练每个通道的背景感知相关滤波器, 采用通道可靠性系数衡量每个通道响应图的置信度;根据所有通道的响应图和可靠性系数, 合成多通道背景感知相关滤波跟踪器的最终响应图, 对目标进行精确定位;运用尺度池方法估计目标的最优位置和尺度。实验结果表明:与现有跟踪算法相比, 所提算法可以有效地处理光照变化、尺度变化、遮挡等复杂因素的干扰, 取得较高的跟踪精度和成功率, 其整体性能优于其他算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相关滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E6%99%AF%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背景感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%80%9A%E9%81%93%E5%8F%AF%E9%9D%A0%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">通道可靠性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%BA%E5%BA%A6%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尺度估计;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    尹明锋, E-mail:yinmingfengnjust@gmail.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-05</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61473153);</span>
                                <span>航空科学基金 (2016ZC59006);</span>
                                <span>江苏省产学研联合创新资金-前瞻性联合研究项目 (BY2016004-04);</span>
                    </p>
            </div>
                    <h1>Multi-Scale Context-Aware Correlation Filter Tracking Algorithm Based on Channel Reliability</h1>
                    <h2>
                    <span>Yin Mingfeng</span>
                    <span>Bo Yuming</span>
                    <span>Zhu Jianliang</span>
                    <span>Wu Panlong</span>
            </h2>
                    <h2>
                    <span>School of Automation, Nanjing University of Science &Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the problems of illumination variation, occlusion, and scale variation during object tracking, we propose a multi-scale context-aware correlation filter tracking algorithm based on channel reliability.First, we extract the histogram of the oriented gradient (HOG) , gray features, and color name (CN) features as the appearance model of the object, which can enhance the robustness of the tracking algorithm in a complex scene.Second, the single-channel context-aware correlation tracker is independently trained by applying the related channel feature samples.The channel reliability factor is applied to evaluate the confidence of each channel.Then, the final response map of the multi-channel context-aware correlation tracker comprises the response maps and the channel reliability values of all the channels, and it is used to accurately locate the object.Finally, the scale pool method is applied to estimate the optimal position and scale of the object. When compared with the results obtained using the state-of-art trackers, the experimental results show that the proposed algorithm can effectively tackle the illumination variation, occlusion, scale variation, and other complicated factors, and achieve relatively high tracking accuracy and success rate.The overall performance of the proposed algorithm is superior to those of other algorithms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=correlation%20filter&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">correlation filter;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=context-aware&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">context-aware;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=channel%20reliability&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">channel reliability;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=scale%20estimation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">scale estimation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-05</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">目标跟踪<citation id="162" type="reference"><link href="118" rel="bibliography" /><link href="120" rel="bibliography" /><link href="122" rel="bibliography" /><link href="124" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>是计算机视觉领域中的研究热点之一, 在视频监控、行为识别、无人驾驶、人机交互等领域有着广泛的应用。目前目标跟踪技术已取得相当大的进展, 但是解决目标跟踪中的尺度变化、外观变化、快速运动和遮挡等问题, 仍是具有挑战性的任务。</p>
                </div>
                <div class="p1">
                    <p id="3">近年来, 由于具有较强的稳健性和超高的跟踪速度, 相关滤波方法 (CF) <citation id="170" type="reference"><link href="126" rel="bibliography" /><link href="128" rel="bibliography" /><link href="130" rel="bibliography" /><link href="132" rel="bibliography" /><link href="134" rel="bibliography" /><link href="136" rel="bibliography" /><link href="138" rel="bibliography" /><link href="140" rel="bibliography" /><link href="142" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>得到了国内外学者广泛地研究。Bolme等<citation id="163" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出采用相关滤波器进行目标跟踪, 利用灰度图像信息学习输出误差平方和 (MOSSE) 相关滤波跟踪器;为解决训练样本不足的问题, Henriques等<citation id="164" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在相关滤波的基础上结合循环矩阵理论和快速傅里叶变换提出了核循环结构 (CSK) 跟踪器;之后又提出核相关滤波器 (KCF) , 对多通道方向梯度直方图 (HOG) 特征进行融合, 增强了训练所得分类器对目标的解释能力<citation id="165" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>;Danelljan等<citation id="166" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>使用颜色属性 (CN) 作为训练样本特征, 提高了跟踪器对光照变化等干扰因素的影响;Ma等<citation id="167" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用卷积特征建立目标外观模型, 对每一层卷积层分别训练相关滤波器, 实现了由粗到精的多层相关响应图的目标位置定位。然而, 这些方法仅利用单一特征对目标进行描述, 当目标外观变化时, 模型误差容易积累, 进而影响跟踪的稳健性。因此, 多特征方法被引入到相关滤波器中, 尺度自适应多特征跟踪器 (SAMF) <citation id="168" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>采用灰度、CN和HOG特征串联, 结合模板和像素特征的分类器 (STAPLE) <citation id="169" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>分别训练颜色直方图和HOG特征分类器, 并在决策层进行融合。</p>
                </div>
                <div class="p1">
                    <p id="4">由于引入循环转移采样和余弦窗, 大多数相关滤波器会产生边界效应。循环转移采样的使用导致真实样本的数量远小于训练样本。余弦窗的引进增加了真实样本的占比, 同时滤掉了分类器中需要学习的背景信息, 大大降低分类器的判别力, 导致跟踪失败。为解决边界效应, Galoogahi等<citation id="171" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出了边界约束相关滤波 (CFLB) 方法, 该方法采用较大尺寸检测图像块和较小尺寸滤波器提高真实样本比例, 虽然速度较快, 但是跟踪性能不佳;空间正则化相关滤波器 (SRDCF) <citation id="172" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>采用更大的检测区域, 通过加入空间正则化项来限制边界附近的滤波器系数, 由于没有闭合解, 采用Gauss-Seidel方法进行迭代优化求解, 算法实时性能较差;Mueller等<citation id="173" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出了背景感知相关滤波器 (CACF) , 该方法解决了边界效应, 同时增强了相关滤波器对背景信息的学习。此外, CACF不需要进行迭代求解, 有较好的算法实时性。</p>
                </div>
                <div class="p1">
                    <p id="5">为有效应对相关滤波器的边界效应和场景的复杂变化, 在背景感知相关滤波框架的基础上, 提出了一种基于通道可靠性的多尺度背景感知相关滤波跟踪算法, 该算法主要包含以下4个方面的功能:1) 针对单一特征分辨率不足的问题, 同时提取HOG特征、灰度特征和CN特征描述目标外观模型, 增强目标外观模型的抗干扰能力;2) 针对多通道相关滤波器通道之间相互影响的问题, 提出每个通道单独训练的机制;3) 采用通道可靠性系数衡量相关滤波器响应图的置信度并将其应用于多通道响应图的融合, 实现目标的精确定位;4) 采用尺度池方法进行目标尺度估计, 增强算法对尺度变化的稳健性。同时, 选用目标跟踪精准度 (OTB) <citation id="174" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>数据库中的视频序列对所提算法进行验证, 并将其与近年来具有代表性的相关滤波算法进行对比。结果表明, 所提算法的性能优于其他算法的性能。</p>
                </div>
                <h3 id="6" name="6" class="anchor-tag">2 算法描述</h3>
                <div class="p1">
                    <p id="7">所提算法主要分为5个阶段:1) 多特征通道提取;2) 独立训练所有单通道背景感知滤波器;3) 计算出可靠性系数, 并得出多通道背景感知滤波器响应图;4) 目标尺度估计;5) 更新各模型参数。算法框架如图1所示。</p>
                </div>
                <h4 class="anchor-tag" id="8" name="8">2.1 背景感知相关滤波器</h4>
                <div class="p1">
                    <p id="9">传统的相关滤波跟踪器通过目标特征与模板矩阵来构造目标函数, 使目标函数最小化, 从而训练目标跟踪相关滤波器, 目标函数可表示为</p>
                </div>
                <div class="area_img" id="10">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="11">式中:h∈R<sup>T</sup>为相关滤波器模板;T为滤波器模板维数;f∈R<sup>T</sup>为目标特征;g∈R<sup>T</sup>为目标期望响应, 一般设定为以目标位置为中心的二维高斯分布;符号*为f和h之间的循环相关操作;λ<sub>1</sub>为正则化参数, 防止过拟合。 (1) 式为线性最小方差问题, 其解为</p>
                </div>
                <div class="area_img" id="12">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="13">式中:H=F (h) , G=F (g) , F=F (f) , F为傅里叶变换符号;G<sup>*</sup>为G的共轭转置;F<sup>*</sup>为F的共轭转置。</p>
                </div>
                <div class="p1">
                    <p id="14">目标跟踪过程中, 目标区域附近的背景信息对跟踪性能的影响较大, 在相关滤波器训练过程中, CACF算法引进背景信息, 增强了滤波器对背景信息的学习, 其表达式为</p>
                </div>
                <div class="area_img" id="15">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_01500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="16">式中:f<sub>i</sub> (i=1, 2, 3, 4) 为设定4块背景区域的特征表示;f<sub>0</sub>为目标区域的特征表示;λ<sub>2</sub>为回归参数。<image id="185" type="formula" href="images/GXXB201905031_18500.jpg" display="inline" placement="inline"><alt></alt></image>为背景信息约束项, 可加强对背景信息的限制, 该项越小, 则背景信息对跟踪器的影响越小。</p>
                </div>
                <div class="p1">
                    <p id="19">为方便求解, 将 (3) 式转化为与 (1) 式类似的结构形式:</p>
                </div>
                <div class="area_img" id="20">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_02000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="21">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_02100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 所提算法的框架图" src="Detail/GetImg?filename=images/GXXB201905031_02100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 所提算法的框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_02100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Framework of proposed algorithm</p>

                </div>
                <div class="p1">
                    <p id="22">其中</p>
                </div>
                <div class="area_img" id="186">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_18600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="26"> (4) 式对应的解为</p>
                </div>
                <div class="area_img" id="27">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="28">式中:<image id="188" type="formula" href="images/GXXB201905031_18800.jpg" display="inline" placement="inline"><alt></alt></image>分别为<image id="189" type="formula" href="images/GXXB201905031_18900.jpg" display="inline" placement="inline"><alt></alt></image>的共轭转置。</p>
                </div>
                <h4 class="anchor-tag" id="29" name="29">2.2 多通道背景感知相关滤波器多通道相关滤波器表达形式为</h4>
                <div class="area_img" id="30">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_03000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="31">式中:<image id="190" type="formula" href="images/GXXB201905031_19000.jpg" display="inline" placement="inline"><alt></alt></image>为所有通道的特征表示集合;<image id="191" type="formula" href="images/GXXB201905031_19100.jpg" display="inline" placement="inline"><alt></alt></image>为对应的滤波器参数。对应的多通道背景感知滤波器的表达式为</p>
                </div>
                <div class="area_img" id="32">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_03200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="33">其中</p>
                </div>
                <div class="area_img" id="192">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_19200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="36"> (8) 式中滤波器参数<image id="193" type="formula" href="images/GXXB201905031_19300.jpg" display="inline" placement="inline"><alt></alt></image>的解为</p>
                </div>
                <div class="area_img" id="37">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="38">式中:<image id="194" type="formula" href="images/GXXB201905031_19400.jpg" display="inline" placement="inline"><alt></alt></image><image id="194" type="formula" href="images/GXXB201905031_19401.jpg" display="inline" placement="inline"><alt></alt></image>的共轭转置, <image id="195" type="formula" href="images/GXXB201905031_19500.jpg" display="inline" placement="inline"><alt></alt></image><image id="195" type="formula" href="images/GXXB201905031_19501.jpg" display="inline" placement="inline"><alt></alt></image>对角线上的元素组成的向量;⊙<sup>-1</sup>为点除符号。根据 (10) 式, 第d通道的滤波器系数h<sup> (d) </sup>是由对应通道的响应值除以所有通道特征响应和得到的, 并不能真实地反映出每个通道特征的分辨能力。</p>
                </div>
                <div class="p1">
                    <p id="39">为避免上述问题对多通道滤波器分辨能力的影响, 现将滤波器表达式改为</p>
                </div>
                <div class="area_img" id="40">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="41">式中:l∈π, π为除d通道之外的所有通道的集合。消除这些通道的影响后, 滤波器表达式变为</p>
                </div>
                <div class="area_img" id="42">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_04200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="43"> (12) 式对应的解为</p>
                </div>
                <div class="area_img" id="44">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_04400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="45">由 (13) 式可得, 每个通道的滤波器h<sup> (d) </sup>只受自身通道特征信息的影响, 与其他通道的信息无关, 这体现出每个通道的独立性。t+1时刻第d个通道滤波器响应图R<sub>t+1</sub><sup> (d) </sup>的表达式为</p>
                </div>
                <div class="area_img" id="46">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_04600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="47">式中:H<sub>t</sub><sup> (d) </sup>为t时刻滤波器系数;<image id="196" type="formula" href="images/GXXB201905031_19600.jpg" display="inline" placement="inline"><alt></alt></image>为t+1时刻第d个通道预测样本的特征表示。</p>
                </div>
                <div class="p1">
                    <p id="48">融合各通道的响应图, 得到最终的响应图为</p>
                </div>
                <div class="area_img" id="49">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="50">式中:<image id="197" type="formula" href="images/GXXB201905031_19700.jpg" display="inline" placement="inline"><alt></alt></image>为衡量每个通道置信程度的可靠性系数。下面将讨论每个通道的可靠性系数。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51">2.3 通道可靠性系数</h4>
                <div class="p1">
                    <p id="52">采用响应图分布指标衡量每个通道的可靠性, 现定义如下。</p>
                </div>
                <div class="p1">
                    <p id="53">1) 响应图峰值, 其表达式为</p>
                </div>
                <div class="area_img" id="54">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_05400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="55">式中:r<sub>max</sub> (R) 为响应图R中的最大值, 如图2 (a) 所示。</p>
                </div>
                <div class="p1">
                    <p id="56">2) 峰值旁瓣比 (PSR) , 其表达式为</p>
                </div>
                <div class="area_img" id="57">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="58">式中:μ (R) 为响应图R的均值;σ (R) 为响应图的标准差。PSR指标在MOSSE算法<citation id="175" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>中已经得到验证, 可反映跟踪过程中通道特征的可靠性。</p>
                </div>
                <div class="p1">
                    <p id="59">3) 平均峰值相关能量 (APCE) , 其表达式为</p>
                </div>
                <div class="area_img" id="60">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="61">式中:R (i, j) 为响应图中坐标位置为 (i, j) 的响应值;min (R) 为响应图中的最小值, 该指标可以较真实地反映响应图的波动程度和检测目标的置信水平。</p>
                </div>
                <div class="p1">
                    <p id="62">4) 次主峰和主峰比 (RSFMP) , 其表达式为</p>
                </div>
                <div class="area_img" id="63">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="64">式中:r<sub>peak1</sub>为响应图中第一主峰的峰值, 该值等同于r<sub>max</sub> (R) ;r<sub>peak2</sub>为响应图中的第二主峰的峰值, 且这两大主峰是不相毗连的[图2 (d) ], 该指标同样在CSR-DCF<citation id="176" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>算法中得到验证, 这体现了每个通道响应图中主模式的突出性。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 通道可靠性系数示意图。 (a) 第6帧响应图; (b) 第6帧; (c) 第108帧; (d) 第108帧响应图" src="Detail/GetImg?filename=images/GXXB201905031_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 通道可靠性系数示意图。 (a) 第6帧响应图; (b) 第6帧; (c) 第108帧; (d) 第108帧响应图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Illustration of channel reliability. (a) Response map of 6<sup>th </sup>frame; (b) 6<sup>th </sup>frame; (c) 108<sup>th </sup>frame; (d) response map of 108<sup>th </sup>frame</p>

                </div>
                <div class="p1">
                    <p id="66">将上述指标融合在一起, 定义t+1时刻第d个通道的可靠性系数为</p>
                </div>
                <div class="area_img" id="67">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="68">由于每个指标的数量级不同, 故 (20) 式利用乘性方法进行融合, 该方法可使可靠性系数更好地综合衡量响应图的整体表现。同时, 跟踪过程中, t+1帧的可靠性系数<image id="198" type="formula" href="images/GXXB201905031_19800.jpg" display="inline" placement="inline"><alt></alt></image>取决于前一帧的响应图R<sub>t</sub><sup> (d) </sup>。对可靠性系数进行归一化, 得到</p>
                </div>
                <div class="area_img" id="69">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_06900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="199">根据 (21) 式, <image id="200" type="formula" href="images/GXXB201905031_20000.jpg" display="inline" placement="inline"><alt></alt></image>成立, 同时平缓更新可靠性系数, 则有</p>
                </div>
                <div class="area_img" id="71">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="72">式中:α为通道可靠性系数学习率。</p>
                </div>
                <div class="p1">
                    <p id="73">图2为通道可靠性系数示意图, 图中w (R) 为可靠性系数。选用了OTB数据库中的“tiger2”序列, 图2 (b) 、 (c) 分别为图像序列中的第6帧和第108帧, 响应图是由多通道背景感知相关滤波器得到。第6帧中目标“tiger”不受任何影响, 其跟踪情况良好, 所得响应图峰值较大且主峰较突出, 响应图分布形态较好, 利于目标精确定位。第108帧目标遭遇了遮挡, 受遮挡物体的影响, 其跟踪效果较差, 响应图峰值较小且主峰不突出, 响应图分布形态较差。图2中所呈现的可靠性指标真实地反映了跟踪情况, 体现出通道特征的置信程度。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">2.4 尺度估计</h4>
                <div class="p1">
                    <p id="75">选用尺度池方法对目标尺度进行估计, 当前目标大小为c<sub>t</sub>= (c<sub>x</sub>, c<sub>y</sub>) , c<sub>x</sub>和c<sub>y</sub>分别为目标的宽和高, 设定尺度池为S={s<sub>1</sub>, s<sub>2</sub>, …, s<sub>k</sub>}, 即跟踪过程中会对这些尺度{s<sub>k</sub>c<sub>t</sub>|s<sub>k</sub>∈S}分别进行估算, 选出可靠性系数最大的值作为当前帧尺寸, 即</p>
                </div>
                <div class="area_img" id="76">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_07600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="77">式中:W<sub>t+</sub><sup> (s</sup>k<sub>1</sub><sup>c</sup>t<sup>) </sup>是尺度为s<sub>k</sub>c<sub>t</sub>融合后的响应图可靠性指标。采用多通道特征对目标进行表征, 跟踪算法稳健性能较强且目标尺寸不会突变, 设定尺度池为S={0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15, 1.20}。此外, 为保证目标尺寸平稳, 更新t+1时刻的目标尺寸c<sub>t+1</sub>:</p>
                </div>
                <div class="area_img" id="78">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_07800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="79">式中:γ为目标尺寸学习率。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">2.5 模型更新</h4>
                <div class="p1">
                    <p id="81">跟踪过程中, 滤波器的训练会受到目标形变、尺度变化、遮挡等因素的影响, 同时出现漂移现象, 因此有必要对跟踪模型进行更新, 即</p>
                </div>
                <div class="area_img" id="82">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="83">式中:β为相关滤波器模型学习率。</p>
                </div>
                <h3 id="84" name="84" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="85">选用OTB-100<citation id="177" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>数据集中的42段彩色视频序列, 包含光照变化 (IV) 、尺度变化 (SV) 、快速运动 (FM) 、遮挡 (OCC) 、非刚性形变 (DEF) 、运动模糊 (MB) 、背景混乱 (BC) 、低分辨率 (LR) 、平面内旋转 (IPR) 、平面外旋转 (OPR) 及超出视野 (OV) 等干扰。为验证算法的有效性, 将所提方法与目前具有代表性的相关滤波算法[CSK<citation id="178" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、多模板尺度自适应判别相关滤波器 (KCF＿MTSA) <citation id="179" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、SAMF<citation id="180" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、MOSSE＿CA<citation id="182" type="reference"><link href="126" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">19</a>]</sup></citation>、背景感知判别相关滤波器 (DCF＿CA) <citation id="183" type="reference"><link href="128" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">19</a>]</sup></citation>、SAMF＿CA<citation id="184" type="reference"><link href="146" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">19</a>]</sup></citation>和可信块跟踪器 (RPT) <citation id="181" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>]进行对比, 结果如表1所示。针对序列Lemming、Liquor、Shaking、Singer2、Soccer、Terris进行定量和定性分析, 结果如表2所示。</p>
                </div>
                <div class="area_img" id="86">
                                            <p class="img_tit">
                                                表1 测试跟踪算法特征
                                                    <br />
                                                Table 1 Characteristics of testing tracking algorithms
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905031_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 测试跟踪算法特征" src="Detail/GetImg?filename=images/GXXB201905031_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">Note:√means yes, ○means no.</p>

                </div>
                <div class="area_img" id="87">
                                            <p class="img_tit">
                                                表2 实验图像序列特征
                                                    <br />
                                                Table 2 Characteristics of image sequences in the experiment
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905031_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 实验图像序列特征" src="Detail/GetImg?filename=images/GXXB201905031_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="88" name="88">3.1 实验环境与参数设置</h4>
                <div class="p1">
                    <p id="89">实验环境为:CPU型号为2.80GHz Intel (R) Core (TM) i5-8400, 内存为8 GB, 操作系统为Windows 10 64bit, 实验软件平台为Matlab2014a。目标所提取特征为:31维的HOG特征, 4pixel×4pixel的元胞, 10维的CN颜色特征, 1维的灰度特征, 总数N<sub>c</sub>为42的特征通道。算法参数设定如下:学习率参数分别为α=0.2、β=0.01、γ=0.2, 正则化系数为λ<sub>1</sub>=10<sup>-4</sup>和λ<sub>2</sub>=0.4。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">3.2 性能评估</h4>
                <div class="p1">
                    <p id="91">选用最常用的3种指标评价跟踪算法性能:中心位置误差 (CLE) 、距离精度 (DP) 和重叠精度 (OP) 。其中, CLE评价指标定义为目标中心 (x<sub>T</sub>, y<sub>T</sub>) 和目标真实中心 (x<sub>G</sub>, y<sub>G</sub>) 之间的平均欧式距离值, 即</p>
                </div>
                <div class="area_img" id="92">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">DP指标指CLE小于某一阈值的百分比, 默认选择阈值为20pixel。OP指标指设定R<sub>T</sub>为t时刻跟踪结果所表示的目标区域, R<sub>G</sub>为目标标注区域, 定义每一帧的综合得分为S<sub>t</sub>, 则</p>
                </div>
                <div class="area_img" id="201">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905031_20100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_09500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 8种算法的距离精度曲线和成功率曲线。 (a) 整体距离精度曲线; (b) 整体成功率曲线" src="Detail/GetImg?filename=images/GXXB201905031_09500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 8种算法的距离精度曲线和成功率曲线。 (a) 整体距离精度曲线; (b) 整体成功率曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_09500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Curves of distance precision and success rate of eight algorithms. (a) Distance precision curves of overall; (b) Success rate curves of overall</p>

                </div>
                <div class="p1">
                    <p id="96">式中:∪为取两者的覆盖总区域;∩为取两者的重叠区域。一般设定重叠率的阈值为0.5, OP指标的数值即为跟踪得分S<sub>t</sub>大于0.5的帧数与序列总帧数的百分比。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">3.3 定量分析</h4>
                <div class="p1">
                    <p id="98">根据OTB数据集提供的评估方法, 对所提算法和上述7种算法进行一次性通过评估 (OPE) , 图3为不同算法的整体精度曲线和成功率曲线, 图4为不同场景属性的精度曲线和成功率曲线, 表3和表4分别展示了平均CLE和平均OP。</p>
                </div>
                <div class="p1">
                    <p id="99">精确度反映跟踪得到的目标中心位置与目标的实际中心位置的距离小于给定阈值 (本文设定为20pixel) 的视频帧数占视频总帧数的比例。因此, 随着阈值的增大, 精确度曲线不断上升。成功率反映了跟踪得到的目标框和实际目标框的重叠程度大于某个阈值 (本文设定为0.5) 的视频帧数与总视频帧数的比例, 因此, 对重叠程度的要求越高, 即阈值越大, 成功率曲线越下降。由图3可以看出, 所提算法的整体精确度和成功率都是排名第1, 优于其他跟踪算法。由图4可以看出, 所提算法在不同场景属性下的精确度和成功率均排名第1, 说明所提算法对不同的场景变化有着较强的适应性。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同属性场景的距离精度和成功率曲线。 (a) 光照变化; (b) 尺度变化; (c) 遮挡; (d) 旋转变化" src="Detail/GetImg?filename=images/GXXB201905031_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同属性场景的距离精度和成功率曲线。 (a) 光照变化; (b) 尺度变化; (c) 遮挡; (d) 旋转变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Distance precision and success rate curves for different attribute scenes. (a) Illumination variation; (b) scale variation; (c) occlusion; (d) rotation variation</p>

                </div>
                <div class="p1">
                    <p id="101">根据表3和表4, 相比于其他跟踪算法, 在相同实验条件下所提算法在CLE、OP指标上均取得较好的结果, 除Soccer序列中与排名第1的算法有着微弱差距外, 其他序列中都排名第1。由图3、图4和表3、表4可以看出, 所提算法精度较高且对场景变化有较强的稳健性。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">3.4 定性分析</h4>
                <div class="p1">
                    <p id="105">图5为所选用的8种算法在6组不同视频序列的跟踪结果。现主要针对算法在光照变化、尺度变化、遮挡和旋转变化等情况下的表现进行定性分析。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同方法的跟踪结果。 (a) Lemming; (b) Liquor; (c) Shaking; (d) Singer2; (e) Soccer; (f) Terris" src="Detail/GetImg?filename=images/GXXB201905031_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同方法的跟踪结果。 (a) Lemming; (b) Liquor; (c) Shaking; (d) Singer2; (e) Soccer; (f) Terris  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Tracking results using different approaches. (a) Lemming; (b) Liquor; (c) Shaking; (d) Singer2; (e) Soccer; (f) Terris</p>

                </div>
                <div class="area_img" id="107">
                                            <p class="img_tit">
                                                表3 平均CLE对比
                                                    <br />
                                                Table 3 Comparison of average CLE
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905031_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note">pixel</p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 平均CLE对比" src="Detail/GetImg?filename=images/GXXB201905031_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="108">
                                            <p class="img_tit">
                                                表4 各个算法的OP
                                                    <br />
                                                Table 4 OP of different algorithms
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 各个算法的OP" src="Detail/GetImg?filename=images/GXXB201905031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="109">1) 光照变化。所选测试序列中的目标都遭遇了光照变化的干扰, 在序列Shaking、Singer2和Terris中较为明显。所提算法提取了HOG特征、灰度特征和CN特征对目标进行描述, 其中HOG特征对光照变化不敏感, 有效地提升了目标对光照变化的抵抗能力, 如Shaking序列中的第173帧和第203帧, Singer2序列中的第180帧和第300帧。而选用单一灰度特征的跟踪器 (如CSK、MOSSE＿CA) 在这些视频序列中的跟踪效果较差, 不能很好地应对光照变化。</p>
                </div>
                <div class="p1">
                    <p id="110">2) 尺度变化。所选用视频序列中除Singer2外都发生目标的尺度变化。所提算法采用尺度池方法对尺度进行最优估计, 实时准确地更新目标尺度。如Lemming序列中的第427帧和第710帧, Terris序列中的第402帧和第562帧, 目标都发生了明显的尺度变化, 相比于其他算法, 所提算法尺度估计精确度较高。因此所提算法对尺度变化的目标有很好的适应性。</p>
                </div>
                <div class="p1">
                    <p id="111">3) 遮挡。序列Lemming、Liquor、Soccer中存在着严重的遮挡问题, 在遮挡之后只有所提算法和RPT, DCF＿CA可以正常跟踪, 如Lemming序列中的第336帧和第545帧, Liquor序列中的第505帧、第894帧和第1228帧, Soccer序列中的第105帧和第174帧。所提算法和DCF＿CA算法采用了背景感知相关滤波器框架, 而RPT算法采用了可靠性分块对目标位置进行估计的方法, 遮挡效果较强。虽然所提算法没有遮挡检测机制, 但是背景感知模型的引进增强了相关滤波器对背景信息的学习, 且多通道特征增强了算法对部分遮挡的分辨能力, 对遮挡有较强的稳健性。</p>
                </div>
                <div class="p1">
                    <p id="112">4) 旋转变化。旋转变化给目标跟踪带来很大的挑战。Shaking序列、Singer2序列和Soccer序列中目标如果发生明显旋转, 较多的算法会出现漂移现象。所提算法利用多通道特征和背景感知模型有效地解决了旋转问题, 如Shaking序列中的第173帧和第268帧, Singer2序列中的第204帧, Soccer序列中的第224帧。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">3.5 算法跟踪速率</h4>
                <div class="p1">
                    <p id="114">表5为8种算法在不同视频序列的平均跟踪速率。所提算法在背景感知框架下独立训练多通道相关滤波器, 并增加了通道可靠性系数的计算和时间开销。所提算法与其他多特征相关滤波器相比, 虽然跟踪速度稍有下降, 但性能有明显的提升。</p>
                </div>
                <div class="area_img" id="115">
                                            <p class="img_tit">
                                                表5 各个算法的跟踪速度
                                                    <br />
                                                Table 5 Tracking speeds of different trackers
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905031_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905031_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note">frame·s-1</p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905031_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 各个算法的跟踪速度" src="Detail/GetImg?filename=images/GXXB201905031_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="116" name="116" class="anchor-tag">4 结论</h3>
                <div class="p1">
                    <p id="117">在背景感知相关滤波跟踪算法的基础上, 提出了一种基于通道可靠性的多尺度背景感知相关滤波跟踪算法。提取了HOG特征、灰度特征、CN特征作为跟踪目标的外观表征模型, 实现了特征之间的有效互补, 提高了目标表征的准确性。为解决每个通道相关滤波器之间的相互干扰, 单独训练每个通道的背景感知相关滤波器, 并采用通道可靠性系数衡量每个通道的置信度。利用通道可靠性系数融合所有单通道滤波器响应图, 实现了精确的目标定位。采用尺度技术对目标尺度进行估计, 提高了跟踪算法应对尺度变化的能力。实验结果表明, 所提算法对于跟踪场景中的复杂变化 (如光照变化、尺度变化、遮挡等) 都有着精确和稳健的跟踪效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="118">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017656&amp;v=MDE2NTUvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSkY4VWJ4cz1OaWZJWTdLN0h0ak5yNDlGWk9vSUNuaw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Yilmaz A, Javed O, Shah M.Object tracking:a survey[J].ACM Computing Surveys, 2006, 38 (2) :1-45.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual tracking:an experimental survey">

                                <b>[2]</b>Smeulders A W M, Chu D M, Cucchiara R, et al.Visual tracking:an experimental survey[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2014, 36 (7) :1442-1468.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Tracking Benchmark">

                                <b>[3]</b>Wu Y, Lim J, Yang M H.Object tracking benchmark[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (9) :1834-1848.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201708001&amp;v=MTc0MTBiTXA0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVTdyQlB5cmZiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Zhang W, Kang B S.Recent advances in correlation filter-based object tracking:a review[J].Journal of Image and Graphics, 2017, 22 (8) :1017-1033.张微, 康宝生.相关滤波目标跟踪进展综述[J].中国图象图形学报, 2017, 22 (8) :1017-1033.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">

                                <b>[5]</b>Bolme D S, Beveridge J R, Draper B A, et al.Visual object tracking using adaptive correlation filters[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition, 13-18 June 2010, San Francisco, CA, USA, 2010:2544-2550.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of trackingby-detection with kernels">

                                <b>[6]</b>Henriques J F, Caseiro R, Martins P, et al.Exploiting the circulant structure of tracking-bydetection with kernels[C]//Proceedings of European Conference on Computer Vision, 7-13 October, Florence, Italy.2012:702-715.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive color attributes for real-time visual tracking">

                                <b>[7]</b>Danelljan M, Khan F S, Felsberg M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 23-28 June 2014, Columbus, OH, USA.2014:1090-1097.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">

                                <b>[8]</b>Henriques J F, Caseiro R, Martins P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583-596.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Background-Aware Correlation Filters for Visual Tracking">

                                <b>[9]</b>Galoogahi H K, Fagg A, Lucey S.Learning background-aware correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 22-29 Oct.2017, Venice, Italy.2017:1135-1143.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative correlation filter with channel and spatial reliability">

                                <b>[10]</b>Luke6ic A, Vojír T, Zajc L C, et al.Discriminative correlation filter with channel and spatial reliability[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:4847-4856.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201805026&amp;v=MDYzNTlCSWpYVGJMRzRIOW5NcW85SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVN3I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Li C, Lu C Y, Zhao X, et al.Scale adaptive correlation filter tracking algorithm based on feature fusion[J].Acta Optica Sinica, 2018, 38 (5) :0515001.李聪, 鹿存跃, 赵珣, 等.特征融合的尺度自适应相关滤波跟踪算法[J].光学学报, 2018, 38 (5) :0515001.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201802028&amp;v=Mjc2MjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3ckJJalhUYkxHNEg5bk1yWTlIYklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Wang Y C, Huang H, Li S M, et al.Correlation filter tracking based on online detection and scaleadaption[J].Acta Optica Sinica, 2018, 38 (2) :0215002.王艳川, 黄海, 李邵梅, 等.基于在线检测和尺度自适应的相关滤波跟踪[J].光学学报, 2018, 38 (2) :0215002.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807026&amp;v=MjA1MzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVN3JCSWpYVGJMRzRIOW5NcUk5SFk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Liao X F, Hou Z Q, Yu W S, et al.A scale adapted tracking algorithm based on kernelized correlation[J].Acta Optica Sinica, 2018, 38 (7) :0715002.廖秀峰, 侯志强, 余旺盛, 等.基于核相关的尺度自适应视觉跟踪[J].光学学报, 2018, 38 (7) :0715002.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical Convolutional Features for Visual Tracking">

                                <b>[14]</b>Ma C, Huang J B, Yang X K, et al.Hierarchical convolutional features for visual tracking[C]//2015IEEE International Conference on Computer Vision, 7-13Dec.2015, Santiago, Chile.2015:3074-3082.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">

                                <b>[15]</b>Li Y, Zhu J K.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision, 6-12Sep.2014, Zurich, Switzerland.2014:254-265.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Staple:Complementary learners for real-time tracking">

                                <b>[16]</b>Bertinetto L, Valmadre J, Golodetz S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 27-30 June 2016, Las Vegas, NV, USA.2016:1 401-1409.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Correlation Filters with Limited Boundaries">

                                <b>[17]</b>Galoogahi H K, Sim T, Lucey S.Correlation filters with limited boundaries[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 7-12June 2015, Boston, MA, USA.2015:4630-4638.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning spatially regularized correlation filters for visual tracking">

                                <b>[18]</b>Danelljan M, Hger G, Khan F S, et al.Learning spatially regularized correlation filters for visual tracking[C]//Proceedings of IEEE International Conference on Computer Vision, 7-13 Dec.2015, Santiago, Chile.2015:4310-4318.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">

                                <b>[19]</b>Mueller M, Smith N, Ghanem B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition, 21-26July 2017, Honolulu, HI, USA.2017:1387-1395.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative Correlation Filter Tracker with Channel and Spatial Reliability">

                                <b>[20]</b>Lukeˇziˇc A, Vojíˇr T, Cehovin Zajc L, et al.Discriminative correlation filter tracker with channel and spatial reliability[J].International Journal of Computer Vision, 2018, 126 (7) :671-688.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-template Scale-Adaptive Kernelized Correlation Filters">

                                <b>[21]</b>Bibi A, Ghanem B.Multi-templatescale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision Workshop, 7-13Dec.2015, Santiago, Chile.2015:613-620.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reliable patch trackers:robust visual tracking by exploiting reliable patches">

                                <b>[22]</b>Li Y, Zhu J K, Hoi S C H.Reliable Patch Trackers:Robust visual tracking by exploiting reliable patches[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 7-12 June 2015, Boston, MA, USA.2015:353-361.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905031" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905031&amp;v=MTMwMzBqTXFvOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVTdyQklqWFRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

