

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135524562600000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201902009%26RESULT%3d1%26SIGN%3dhx8ff3EjUsv%252bAdFsM8yiaLkgq%252b8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201902009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201902009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201902009&amp;v=MTYwMzZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURrVXJ2QUlqWFRiTEc0SDlqTXJZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 更快的区域卷积神经网络 ">2 更快的区域卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="&lt;b&gt;2.1&lt;/b&gt;&lt;b&gt;区域建议网络&lt;/b&gt;"><b>2.1</b><b>区域建议网络</b></a></li>
                                                <li><a href="#53" data-title="&lt;b&gt;2.2&lt;/b&gt;&lt;b&gt;检测网络&lt;/b&gt;"><b>2.2</b><b>检测网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="3 多层特征融合与软判决 ">3 多层特征融合与软判决</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="&lt;b&gt;3.1&lt;/b&gt;&lt;b&gt;多层特征融合&lt;/b&gt;"><b>3.1</b><b>多层特征融合</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;3.2&lt;/b&gt;&lt;b&gt;软判决的非极大值抑制&lt;/b&gt;"><b>3.2</b><b>软判决的非极大值抑制</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#81" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="&lt;b&gt;4.1&lt;/b&gt;&lt;b&gt;实验数据&lt;/b&gt;"><b>4.1</b><b>实验数据</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;4.2&lt;/b&gt;&lt;b&gt;网络训练&lt;/b&gt;"><b>4.2</b><b>网络训练</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;4.3&lt;/b&gt;&lt;b&gt;结果分析&lt;/b&gt;"><b>4.3</b><b>结果分析</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;4.4&lt;/b&gt;&lt;b&gt;方法对比&lt;/b&gt;"><b>4.4</b><b>方法对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="图1 Faster R-CNN的结构">图1 Faster R-CNN的结构</a></li>
                                                <li><a href="#51" data-title="图2 区域建议网络的结构">图2 区域建议网络的结构</a></li>
                                                <li><a href="#59" data-title="图3 特征融合的结构">图3 特征融合的结构</a></li>
                                                <li><a href="#71" data-title="图4 非极大值抑制">图4 非极大值抑制</a></li>
                                                <li><a href="#73" data-title="图5 漏检结果">图5 漏检结果</a></li>
                                                <li><a href="#85" data-title="图6 数据示例。 (a) 训练数据; (b) 测试数据">图6 数据示例。 (a) 训练数据; (b) 测试数据</a></li>
                                                <li><a href="#88" data-title="图7 迁移学习">图7 迁移学习</a></li>
                                                <li><a href="#92" data-title="表1 特征融合的结果">表1 特征融合的结果</a></li>
                                                <li><a href="#94" data-title="图8 不同方法的网络检测结果。 (a) 第5层的结果; (b) 融合3, 4, 5层的结果">图8 不同方法的网络检测结果。 (a) 第5层的结果; (b) 融合3, 4, 5层的结果</a></li>
                                                <li><a href="#96" data-title="图9 NMS算法改进前后的飞机检测结果。 (a) 传统NMS算法; (b) 改进NMS算法">图9 NMS算法改进前后的飞机检测结果。 (a) 传统NMS算法; (b) 改进NMS算法</a></li>
                                                <li><a href="#99" data-title="表2 不同飞机检测方法的结果对比">表2 不同飞机检测方法的结果对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="9">


                                    <a id="bibliography_1" title=" Song M Z, Qu H S, Jin G. Weak ship target detection of noisy optical remote sensing image on sea surface[J]. Acta Optica Sinica, 2017, 37 (10) : 1011004. 宋明珠, 曲宏松, 金光. 含噪光学遥感图像海面弱小舰船目标检测[J]. 光学学报, 2017, 37 (10) : 1011004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201710021&amp;v=MTQ3MzZxQnRHRnJDVVI3cWZadVp0RmlEa1VydkFJalhUYkxHNEg5Yk5yNDlIWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Song M Z, Qu H S, Jin G. Weak ship target detection of noisy optical remote sensing image on sea surface[J]. Acta Optica Sinica, 2017, 37 (10) : 1011004. 宋明珠, 曲宏松, 金光. 含噪光学遥感图像海面弱小舰船目标检测[J]. 光学学报, 2017, 37 (10) : 1011004.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_2" title=" Li W, Xiang S M, Wang H B, &lt;i&gt;et al&lt;/i&gt;. Robust airplane detection in satellite images[C]. IEEE International Conference on Image Processing, 2011: 2821-2824." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust airplane detection in satellite images">
                                        <b>[2]</b>
                                         Li W, Xiang S M, Wang H B, &lt;i&gt;et al&lt;/i&gt;. Robust airplane detection in satellite images[C]. IEEE International Conference on Image Processing, 2011: 2821-2824.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_3" title=" Bo S K, Jing Y J. Region-based airplane detection in remotely sensed imagery[C]. International Congress on Image and Signal Processing, 2010: 1923-1926." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Region-based Airplane Detection in Remotely Sensed Imagery">
                                        <b>[3]</b>
                                         Bo S K, Jing Y J. Region-based airplane detection in remotely sensed imagery[C]. International Congress on Image and Signal Processing, 2010: 1923-1926.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_4" title=" Liu L, Shi Z W. Airplane detection based on rotation invariant and sparse coding in remote sensing images[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (18) : 5327-5333." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700100326&amp;v=MjkxNDFSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SktGOFZiaG89TmlmT2ZiSzhIOURNcUk5Rlplc1BEMzQvb0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Liu L, Shi Z W. Airplane detection based on rotation invariant and sparse coding in remote sensing images[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (18) : 5327-5333.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_5" title=" Chen X Y, Xiang S M, Liu C L, &lt;i&gt;et al&lt;/i&gt;. Aircraft detection by deep belief nets[C]. Asian Conference on Pattern Recognition, 2013: 54-58." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aircraft detection by deep belief nets">
                                        <b>[5]</b>
                                         Chen X Y, Xiang S M, Liu C L, &lt;i&gt;et al&lt;/i&gt;. Aircraft detection by deep belief nets[C]. Asian Conference on Pattern Recognition, 2013: 54-58.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_6" title=" Wu H, Zhang H, Zhang J F, &lt;i&gt;et al&lt;/i&gt;. Fast aircraft detection in satellite images based on convolutional neural networks[C]. IEEE International Conference on Image Processing, 2015: 4210-4214." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast aircraft detection in satellite images based on convolutional neural networks">
                                        <b>[6]</b>
                                         Wu H, Zhang H, Zhang J F, &lt;i&gt;et al&lt;/i&gt;. Fast aircraft detection in satellite images based on convolutional neural networks[C]. IEEE International Conference on Image Processing, 2015: 4210-4214.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_7" title=" Xin P, Xu Y L, Tan H, &lt;i&gt;et al&lt;/i&gt;. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MzA4MTR6cXFCdEdGckNVUjdxZlp1WnRGaURrVXJ2QUlqWFRiTEc0SDluTXJJOUdZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Xin P, Xu Y L, Tan H, &lt;i&gt;et al&lt;/i&gt;. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_8" title=" Li Y, Fu K, Sun H, &lt;i&gt;et al&lt;/i&gt;. An aircraft detection framework based on reinforcement learning and convolutional neural networks in remote sensing images[J]. Remote Sensing, 2018, 10 (2) : 243." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An aircraft detection framework based on reinforcement learning and convolutional neural networks in remote sensing images">
                                        <b>[8]</b>
                                         Li Y, Fu K, Sun H, &lt;i&gt;et al&lt;/i&gt;. An aircraft detection framework based on reinforcement learning and convolutional neural networks in remote sensing images[J]. Remote Sensing, 2018, 10 (2) : 243.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_9" title=" Zhang W C, Sun X, Fu K, &lt;i&gt;et al&lt;/i&gt;. Object detection in high-resolution remote sensing images using rotation invariant parts based model[J]. IEEE Geoscience and Remote Sensing Letters, 2014, 11 (1) : 74-78." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object detection in high-resolution remote sensing images using rotation invariant parts based model">
                                        <b>[9]</b>
                                         Zhang W C, Sun X, Fu K, &lt;i&gt;et al&lt;/i&gt;. Object detection in high-resolution remote sensing images using rotation invariant parts based model[J]. IEEE Geoscience and Remote Sensing Letters, 2014, 11 (1) : 74-78.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_10" title=" Wang G L, Wang X C, Fan B, &lt;i&gt;et al&lt;/i&gt;. Feature extraction by rotation-invariant matrix representation for object detection in aerial image[J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (6) : 851-855." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Feature extraction by rotationinvariant matrix representation for object detection in aerial image,&amp;quot;">
                                        <b>[10]</b>
                                         Wang G L, Wang X C, Fan B, &lt;i&gt;et al&lt;/i&gt;. Feature extraction by rotation-invariant matrix representation for object detection in aerial image[J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (6) : 851-855.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_11" title=" Pan S J, Yang Q. A survey on transfer learning[J]. IEEE Transactions on Knowledge and Data Engineering, 2010, 22 (10) : 1345-1359." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Survey on Transfer Learning">
                                        <b>[11]</b>
                                         Pan S J, Yang Q. A survey on transfer learning[J]. IEEE Transactions on Knowledge and Data Engineering, 2010, 22 (10) : 1345-1359.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_12" title=" Ren S Q, He K M, Girshick R, &lt;i&gt;et al&lt;/i&gt;. Faster R-CNN: towards real-time object detection with region proposal networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) : 1137-1149." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN:towards real-time object detection with region proposal networks">
                                        <b>[12]</b>
                                         Ren S Q, He K M, Girshick R, &lt;i&gt;et al&lt;/i&gt;. Faster R-CNN: towards real-time object detection with region proposal networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) : 1137-1149.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_13" title=" Girshick R B. Fast R-CNN[C]. International Conference on Computer Vision, 2015: 1440-1448." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">
                                        <b>[13]</b>
                                         Girshick R B. Fast R-CNN[C]. International Conference on Computer Vision, 2015: 1440-1448.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_14" title=" Kong T, Yao A, Chen Y, &lt;i&gt;et al&lt;/i&gt;. HyperNet: towards accurate region proposal generation and joint object detection[C]. IEEE Conference on Computer Vision and Pattern Recognition, 2016: 845-853." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=HyperNet:Towards Accurate Region Proposal Generation and Joint Object Detection">
                                        <b>[14]</b>
                                         Kong T, Yao A, Chen Y, &lt;i&gt;et al&lt;/i&gt;. HyperNet: towards accurate region proposal generation and joint object detection[C]. IEEE Conference on Computer Vision and Pattern Recognition, 2016: 845-853.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_15" title=" Liu W, Rabinovich A, Berg A C, &lt;i&gt;et al&lt;/i&gt;. ParseNet: looking wider to see better[EB/OL]. (2015-11-23) [2018-01-15]. https://arxiv.org/abs/1506.04579" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ParseNet: looking wider to see better">
                                        <b>[15]</b>
                                         Liu W, Rabinovich A, Berg A C, &lt;i&gt;et al&lt;/i&gt;. ParseNet: looking wider to see better[EB/OL]. (2015-11-23) [2018-01-15]. https://arxiv.org/abs/1506.04579
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_16" title=" Rothe R, Guillaumin M, Van Gool L, &lt;i&gt;et al&lt;/i&gt;. Non-maximum suppression for object detection by passing messages between windows[C]. Asian Conference on Computer Vision, 2014: 290-306." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-maximum suppression for object detection by passing messages between windows">
                                        <b>[16]</b>
                                         Rothe R, Guillaumin M, Van Gool L, &lt;i&gt;et al&lt;/i&gt;. Non-maximum suppression for object detection by passing messages between windows[C]. Asian Conference on Computer Vision, 2014: 290-306.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-09-14 09:18</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(02),71-77 DOI:10.3788/AOS201939.0210001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于特征融合与软判决的遥感图像飞机检测</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%98%8E%E6%98%8E&amp;code=38559959&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱明明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%AE%B8%E6%82%A6%E9%9B%B7&amp;code=23261238&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">许悦雷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E6%97%B6%E5%B9%B3&amp;code=20940682&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马时平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%B8%85&amp;code=31457843&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李帅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E7%BA%A2%E5%BC%BA&amp;code=38613075&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马红强</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A9%BA%E5%86%9B%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%94%9F%E9%99%A2&amp;code=0274788&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空军工程大学研究生院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=0085569&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学无人系统技术研究院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出了一种特征融合结合软判决的飞机检测方法。以区域卷积神经网络为基本框架, 依次采用L2范数归一化、特征连接、尺度缩放和特征降维来融合多层特征。为了降低网络在目标高度重叠时的漏检率, 引入软判决来改进传统的非极大值抑制方法。实验结果表明, 所提方法能够准确快速地检测到飞机, 得到检测率为94.25%、虚警率为5.5%、平均运行时间为0.16 s的实验结果。与现有的其他检测方法相比, 所提方法的各项指标均得到显著提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A3%9E%E6%9C%BA%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">飞机检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%AF%E5%88%A4%E5%86%B3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">软判决;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *朱明明, E-mail:ming_paper@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>航空科学基金 (20175896022);</span>
                    </p>
            </div>
                    <h1>Airplane Detection Based on Feature Fusion and Soft Decision in Remote Sensing Images</h1>
                    <h2>
                    <span>Zhu Mingming</span>
                    <span>Xu Yuelei</span>
                    <span>Ma Shiping</span>
                    <span>Li Shuai</span>
                    <span>Ma Hongqiang</span>
            </h2>
                    <h2>
                    <span>Graduate School, Air Force Engineering University</span>
                    <span>Unmanned System Research Institute, Northwestern Polytechnical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>An airplane detection method is proposed based on feature fusion and soft decision, in which the region-based convolutional neural network is used as the basic framework and the L2 normalization, feature connection, scaling, and dimensionality reduction are in turn used to fuse the multi-layer features. The soft decision, which can improve the traditional non-maximum suppression method, is introduced in order to reduce the detection-omission-rate of grids in the case of significant overlap of targets. The experimental results show that the proposed method can be used to detect airplanes accurately and quickly with a detection rate of 94.25%, a false alarm rate of 5.5%, and the average running time of 0.16 s. Compared with those of the other existing detection methods, each index of the proposed method is significantly improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=airplane%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">airplane detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=soft%20decision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">soft decision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=region-based%20convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">region-based convolutional neural network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-04</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="42">随着高分辨率卫星遥感技术的快速发展, 遥感图像的分辨率变得越来越高, 获取方式也更加方便、多样, 这推动了遥感图像中目标检测的发展<citation id="103" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。飞机作为典型的军事和民用目标, 在战场监视、航空管制和交通运输等领域发挥着重要作用。然而, 由于飞机类型、姿态、尺寸和复杂背景的不确定性, 在遥感图像中检测飞机目标一直是一个具有挑战性的研究课题。</p>
                </div>
                <div class="p1">
                    <p id="43">为了解决这个难题, 前人不断提出了各种方法。Li等<citation id="104" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出了将视觉显著性和对称性相结合的方法, 利用形状匹配进行飞机分类。Bo等<citation id="105" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出了一种基于区域分割的飞机检测方法。Liu等<citation id="106" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>基于稀疏编码提出了一种飞机特征表达的方法。上述方法均采用人工设计特征结合分类器训练的传统固定模式, 存在着滑动窗口冗余、特征表征不足等局限性, 导致了飞机检测的准确率不高。近年来, 深度学习被广泛用于自动学习目标特征, 这是因为卷积神经网络 (CNN) 在图像目标分类和检测领域中的性能遥遥领先于传统方法。Chen等<citation id="107" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>将深度置信网络 (DBN) 用于飞机检测, 但也只是将DBN作为目标分类器, 其检测性能不高且时间成本过高。Wu等<citation id="108" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种二值化梯度 (BING) 结合CNN的检测方法, 但BING产生2000～3000个候选区域, 导致计算成本很高, 严重影响了算法的速度。辛鹏等<citation id="109" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>融合了CNN中的多层特征来进行飞机检测, 但存在易漏检相邻目标的缺陷。Li等<citation id="110" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种基于强化学习和CNN的飞机检测架构, 但是与前沿的算法相比, 这种方法的检测时间过长。</p>
                </div>
                <div class="p1">
                    <p id="44">由于飞机的姿态具有多方向性, 学习旋转不变性对于分类器是至关重要的。针对飞机的这种特点, Zhang等<citation id="111" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>使用扩展直方图的梯度来获得具有旋转不变性的特征;Wang等<citation id="112" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用一个旋转不变矩阵来获得旋转不变性;Liu等<citation id="113" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了一种基于稀疏编码的特征提取方法, 虽然能在一定程度上提取旋转不变性, 但对其他目标的适用性不强。本文利用数据增强的旋转、翻转技术来实现飞机姿态的多方向性, 正如CNN学习图像的其他特征一样, 直接学习这个特性。</p>
                </div>
                <div class="p1">
                    <p id="45">由于大数据的出现和软硬件平台性能的不断提升, 在自然图像中, 基于深度学习的目标检测技术的性能也不断提升, 并持续处于领先水平。然而, 遥感图像的数据采集相对困难且人工标注的数据集较少, 因此遥感图像中的目标检测技术水平一直滞后于自然图像。而迁移学习技术<citation id="114" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>的出现, 为将深度学习中的目标检测模型应用到遥感图像上提供了可能。因此, 本文以更快的区域卷积神经网络<citation id="115" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation> (Faster R-CNN) 为基本架构, 针对飞机目标的特点对网络模型进行改进和优化, 提出了一种特征融合结合软判决的飞机检测方法。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 更快的区域卷积神经网络</h3>
                <div class="p1">
                    <p id="47">Faster R-CNN结构主要由两部分组成, 分别为区域建议网络<citation id="116" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation> (RPN) 和检测网络, 这两个网络共享卷积层, 如图1所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Faster R-CNN的结构" src="Detail/GetImg?filename=images/GXXB201902009_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Faster R-CNN的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Architecture of Faster R-CNN</p>

                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>2.1</b><b>区域建议网络</b></h4>
                <div class="p1">
                    <p id="50">RPN利用CNN来生成候选框, 并与后续的检测网络共享卷积层, 这大大缩短了候选区域的生成时间。共享卷积层输出的最后一层卷积特征图作为RPN的输入, RPN的具体结构如图2所示。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 区域建议网络的结构" src="Detail/GetImg?filename=images/GXXB201902009_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 区域建议网络的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Structure of RPN</p>

                </div>
                <div class="p1">
                    <p id="52">RPN使用一个3×3的滑动窗口在输入的特征图上进行卷积运算, 将每个位置的计算结果映射到一个低维向量。候选框的参数化表示称为anchor, 即每个anchor以滑动窗口的中心为中心对应一组尺寸和长宽比。对于卷积特征图上的每个位置, 考虑3种尺寸和3种长宽比的anchors, 以适应多尺度的目标。将低维向量同时输入到分类层和回归层, 以进行分类和位置回归。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53"><b>2.2</b><b>检测网络</b></h4>
                <div class="p1">
                    <p id="54">检测网络主要由感兴趣区域<citation id="117" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation> (ROI) 池化层、全连接层以及分类与回归层组成。对于来自同一幅图像的候选区域, 如果进行全部特征的提取, 将导致网络的计算成本很高。由于候选区域对应的特征图与完整特征图存在固定的映射关系, 可以先对整幅图像进行特征提取, 然后通过ROI池化层从完整特征图上直接得到不同候选区域对应的特征矢量, 实现候选区域的特征共享。由于全连接层需要固定尺寸的输入, 因此ROI池化层采用最大池化, 将特征矢量固定为同一尺寸 (512×7×7) 。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">3 多层特征融合与软判决</h3>
                <h4 class="anchor-tag" id="56" name="56"><b>3.1</b><b>多层特征融合</b></h4>
                <div class="p1">
                    <p id="57">在选取的实验图像中, 飞机目标的尺寸很小, 大致像素范围为32 pixel×32 pixel～64 pixel×64 pixel。经过一系列的卷积层处理后, 32 pixel×32 pixel大小的飞机在最后一层卷积特征图上大概只有2 pixel×2 pixel。这样的特征图是很粗糙的, 同时相邻区域可能会相互重叠, 不利于飞机的检测。高层特征包含丰富的语义信息, 更利于目标分类;低层特征空间分辨率较大, 更利于目标定位。目标检测可以理解为分类加定位, 因此一个好的目标检测系统应该同时利用低层和高层特征, 尤其针对小目标物体时。</p>
                </div>
                <div class="p1">
                    <p id="58">Kong等<citation id="118" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>从不同的卷积层提取了同一个位置的特征矢量, 其中较低层特征的激活响应明显高于较高层, 表明同一特征在不同层通常具有不同的响应尺度。因此融合多层特征, 不能简单直接地将多层特征进行相加或合并。融合多层特征首先是利用ROI池化层从不同卷积层 (“conv3”、“conv4”和“conv5”) 提取候选区域对应的固定特征向量, 然后依次进行L2范数归一化以及各层特征连接、尺度变换和特征降维, 最后将融合后的特征输入到全连接层, 如图3所示。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 特征融合的结构" src="Detail/GetImg?filename=images/GXXB201902009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 特征融合的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Structure of feature fusion</p>

                </div>
                <div class="p1">
                    <p id="60">首先使用L2范数对每层卷积层输出的第<i>d</i>个通道的特征<b><i>x</i></b>= (<i>x</i><sub>1</sub>…<i>x</i><sub><i>d</i></sub>) 进行归一化:</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mrow><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></msubsup><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">式中<i>i</i>表示特征的第<i>i</i>个通道。 (1) 式为归一化特征, (2) 式为L2范数的表达式。</p>
                </div>
                <div class="p1">
                    <p id="63">将不同层的归一化特征<b><i>x</i></b>′= (<i>x</i>′<sub>1</sub>…<i>x</i>′<sub><i>d</i>1</sub>) 和<b><i>y</i></b>′= (<i>y</i>′<sub>1</sub>…<i>y</i>′<sub><i>d</i>2</sub>) 按照</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><mo>=</mo><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">x</mi><mo>′</mo></msup><mo>, </mo><msup><mi mathvariant="bold-italic">y</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub><mo>⋯</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>d</mi><mn>1</mn></mrow></msub><mo>, </mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub><mo>⋯</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>d</mi><mn>2</mn></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">进行融合连接, 由于各层特征融合后的特征尺度很小, 不利于网络的训练<citation id="119" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 因此有必要对特征进行缩放处理:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>z</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>γ</mi><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">式中<i>γ</i>为缩放参数, 具体的数值为最后一层卷积特征的L2范数值。</p>
                </div>
                <div class="p1">
                    <p id="68">利用预训练模型VGG16网络在遥感数据上进行迁移学习, 融合后的特征大小需与原网络保持一致。使用1×1卷积核进行降维, 使输入到全连接层的特征大小为512×7×7。1×1卷积核已在GoogLeNet、ResNet等网络中得到广泛应用, 它不仅能在保持特征尺度不变的前提下实现降维, 而且能利用后续非线性激活函数来增加网络的非线性特性, 最终实现跨通道的特征信息融合。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>3.2</b><b>软判决的非极大值抑制</b></h4>
                <div class="p1">
                    <p id="70">由于没有强制要求检测网络只产生唯一检测框, 因此会出现多个检测框包围同一目标的情况。为了避免产生误检, 利用非极大值抑制<citation id="120" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation> (NMS) 来剔除多余的检测框, 从而留下最优的检测框, 如图4所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 非极大值抑制" src="Detail/GetImg?filename=images/GXXB201902009_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 非极大值抑制  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Non-maximum suppression</p>

                </div>
                <div class="p1">
                    <p id="72">NMS实现流程为:1) 将集合<i>A</i>中的检测框依据分类得分从高到低排序。2) 将得分最高的检测框<i>M</i>移到集合<i>B</i>, 同时计算检测框<i>M</i>与其他检测框的IoU (Intersection-over-Union) 值。若IoU值大于阈值<i>T</i>, 则剔除得分较低的检测框, 否则认为存在多个目标。3) 从集合<i>A</i>剩余的检测框中再选取得分最高的, 重复步骤2) 直到集合<i>A</i>中无检测框, 最后得到集合<i>B</i>中的检测框即为输出。如果两个目标的检测框重叠面积过大, 可能会导致其中一个目标的检测框被剔除, 从而造成目标漏检, 如图5所示。虽然这在一定程度上能够缓解阈值<i>T</i>的增大, 但大大增加了误检率。传统的NMS将邻近检测框的得分强制归零, 这是一种硬判决做法。信道译码算法可以分为硬判决译码算法和软判决译码算法, 其中软判决的纠错能力远优于硬判决。因此, 借鉴软判决的思想对传统NMS算法进行改进, 提出了一种软判决的NMS算法。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 漏检结果" src="Detail/GetImg?filename=images/GXXB201902009_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 漏检结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Results of omission detection</p>

                </div>
                <div class="p1">
                    <p id="74">传统的NMS算法对邻近检测框的判决函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo></mtd><mtd><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Τ</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo></mtd><mtd><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>≥</mo><mi>Τ</mi></mtd></mtr></mtable></mrow></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76"> (5) 式设置一个硬性阈值<i>T</i>来判断邻近检测框<i>a</i><sub><i>i</i></sub>的得分<i>s</i><sub><i>i</i></sub>是保持原值或归零, <i>I</i><sub>oU</sub> (<i>M</i>, <i>a</i><sub><i>i</i></sub>) 表示邻近检测框<i>a</i><sub><i>i</i></sub>与检测框<i>M</i>的IoU值。</p>
                </div>
                <div class="p1">
                    <p id="77">引入软判决对判决函数式进行改进, 改进后的判决函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo></mtd><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Τ</mi></mtd></mtr><mtr><mtd columnalign="left"><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo></mtd><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>≥</mo><mi>Τ</mi></mtd></mtr></mtable></mrow></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">当邻近检测框<i>a</i><sub><i>i</i></sub>与检测框<i>M</i>的IoU小于阈值<i>T</i>, 检测框得分保持不变;当邻近检测框<i>a</i><sub><i>i</i></sub>与检测框<i>M</i>的<i>I</i><sub>oU</sub>≥<i>T</i>时, 检测框得分呈线性衰减。 (6) 式表明<i>I</i><sub>oU</sub> (<i>M</i>, <i>a</i><sub><i>i</i></sub>) 越大 (即重叠面积越大) , 检测框得分衰减越严重;<i>I</i><sub>oU</sub> (<i>M</i>, <i>a</i><sub><i>i</i></sub>) 很小 (即重叠面积很小) , 检测框得分不受影响。</p>
                </div>
                <div class="p1">
                    <p id="80"> (6) 式减小了<i>I</i><sub>oU</sub> (<i>M</i>, <i>a</i><sub><i>i</i></sub>) 大于阈值的检测框得分而非完全归零剔除, 尽管该检测框的分数降低, 但有效避免了漏检, 同时设置检测框得分阈值为0.45, 以剔除得分较小的检测框, 避免造成多余的误检。这里仅通过修改判决函数来实现对传统NMS的改进, 所提算法实现简单且不会增加额外的计算成本。</p>
                </div>
                <h3 id="81" name="81" class="anchor-tag">4 实验与结果分析</h3>
                <div class="p1">
                    <p id="82">所提算法的实验环境为:处理器为i7-7700, 主频为3.6 GHz, 内存为16 G, 显卡为NVIDIA GTX1060, 操作系统为Ubuntu14.04, 网络框架为Caffe。实验中采用检测率 (DR) 、虚警率 (FAR) 和平均运行时间作为评价指标。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>4.1</b><b>实验数据</b></h4>
                <div class="p1">
                    <p id="84">所有的实验数据均来自Google Earth中的机场遥感影像, 比如北京首都国际机场、美国波士顿国际机场等共300个机场, 空间分辨率为1.19 m。选取150个机场中的飞机图像作为训练和验证集, 图像大小范围为375 pixel×375 pixel～400 pixel×400 pixel, 共1500张。将剩余150个机场中的飞机图像作为测试集, 图像大小范围为900 pixel×800 pixel～1000 pixel×900 pixel, 共150张。为了避免出现过拟合和学习飞机的旋转不变性特征, 在此采用数据增强来扩充训练验证集图片的数量。将1500张图片随机旋转90°、180°和270°, 同时以0.5的概率进行水平或垂直翻转, 最终使得训练验证集的图片数量为5000张, 其中训练集和验证集的图片各2500张。所有的图片标签均为手工标注, 图6为部分实验数据。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 数据示例。 (a) 训练数据; (b) 测试数据" src="Detail/GetImg?filename=images/GXXB201902009_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 数据示例。 (a) 训练数据; (b) 测试数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Examples of data. (a) Training data; (b) test data</p>

                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>4.2</b><b>网络训练</b></h4>
                <div class="p1">
                    <p id="87">虽然遥感图像相对于自然图像具有尺度多样、多方向、目标小、背景复杂等特点, 但其含有的边缘、颜色等低级语义特征和抽象的高级语义特征等目标特征是类似的。卷积神经网络同样可以从遥感图像中学习和提取低级或高级语义特征。对于尺度多样性、多方向性、背景复杂等特点, 卷积神经网络可以通过模型训练从实验数据中学习得到, 就如同学习边缘颜色等语义特征一样。深度学习模型的目标检测需要大规模的数据训练, 而目前的遥感数据样本有限, 且数据的标注也需要大量的人工成本, 这就是深度学习在遥感图像领域应用较少的主要原因, 因此从Google Earth搜集遥感图像并进行人工标注数据。使用飞机遥感数据重新训练一个新的CNN是低效的, 甚至可能会导致过拟合。低层卷积层学到的都是边缘纹理以及颜色等低级语义特征, 飞机遥感图像和普通自然图像上的这些特征是一致的, 如图7所示。因此, 可以在大型自然图像数据库上预先训练CNN, 再利用迁移学习将网络学到的特征迁移到新的飞机检测任务中, 事实证明这个过程十分高效。共享卷积层的权重用预先训练的网络VGG16进行初始化, 其余层的权重用均值为0、标准差为0.01的高斯分布随机进行初始化。网络的基本学习率为0.001, 动量为0.9, 权重衰减为0.0005。为了实现RPN和检测网络共享卷积层, 采用交替优化策略<citation id="121" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来训练整个网络。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 迁移学习" src="Detail/GetImg?filename=images/GXXB201902009_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 迁移学习  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Transfer learning</p>

                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>4.3</b><b>结果分析</b></h4>
                <div class="p1">
                    <p id="90">为了分析融合不同层的特征对实验结果的影响, 在其他条件不变的情况下, 采用控制变量法进行对比实验, 结果如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="91">由表1可知, 融合多层特征的DR均优于使用单层特征 (表1第1行) , 验证了融合多层特征的有效性。正如第3.1节所述, 经过多层的卷积和池化后, 在最后一层即第5层卷积特征图上飞机的特征尺度很小, 这样不利于飞机的定位。粗糙、高语义的高层特征有利于目标的分类, 而精细、高分辨率的低层特征有利于目标的定位, 因此融合多层特征能够结合不同层的优势, 从而提高针对飞机这样的小目标的网络检测能力。逐渐增加融合的层数能不断提高DR, 但融合层数增加到第2层时, DR并没有继续提高, 这表明融合3, 4, 5层特征的DR最优, 继续融合其他层的特征无法提供额外的有用信息, 即网络性能的提升已经饱和。以下实验中若无特殊说明, 默认融合3, 4, 5层特征。为了更直观地说明特征融合的重要性, 给出不同方法的检测结果对比图, 如图8所示。图8 (a) 是使用第5层特征的检测结果, 图8 (b) 是融合3, 4, 5层特征的检测结果。可以看出, 融合多层特征可以使网络能够检测到更多的较小目标, 从而提高了检测率。</p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit">表1 特征融合的结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Results of feature fusion</p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td><br />Layer 2</td><td>Layer 3</td><td>Layer 4</td><td>Layer 5</td><td>DR /%</td></tr><tr><td><br /></td><td></td><td></td><td>√</td><td>86.28</td></tr><tr><td><br /></td><td></td><td>√</td><td>√</td><td>90.30</td></tr><tr><td><br /></td><td>√</td><td>√</td><td>√</td><td>91.90</td></tr><tr><td><br />√</td><td>√</td><td>√</td><td>√</td><td>91.90</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同方法的网络检测结果。 (a) 第5层的结果; (b) 融合3, 4, 5层的结果" src="Detail/GetImg?filename=images/GXXB201902009_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同方法的网络检测结果。 (a) 第5层的结果; (b) 融合3, 4, 5层的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Network detection results by different methods. (a) Results of 5th layer; (b) results after fusion of 3, 4, 5 layers</p>

                </div>
                <div class="p1">
                    <p id="95">为了说明改进NMS算法的有效性, 在飞机测试集上进行对比实验。采用软判决NMS算法得到的DR为91.90%, 所提算法得到的DR为94.25%。采用软判决NMS算法测试集时DR提高了约2%。这是因为传统的NMS算法将与检测框<i>M</i>重叠面积大于阈值的所有检测框全部剔除, 可能会导致一些相邻目标的漏检。而改进的NMS算法是使用一个关于重叠面积的函数来减小相邻检测框的分类得分, 并不同于传统NMS算法将邻近检测框的分类得分归零, 这样能有效地降低漏检率。图9呈现的是NMS改进前后对不同飞机的检测结果, 可以看出NMS算法错误地将相邻检测框抑制掉, 而所提方法能够准确地检测到目标。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902009_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 NMS算法改进前后的飞机检测结果。 (a) 传统NMS算法; (b) 改进NMS算法" src="Detail/GetImg?filename=images/GXXB201902009_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 NMS算法改进前后的飞机检测结果。 (a) 传统NMS算法; (b) 改进NMS算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902009_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Airplane detection results before and after improvement of NMS algorithm. (a) Traditional NMS; (b) improved NMS</p>

                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>4.4</b><b>方法对比</b></h4>
                <div class="p1">
                    <p id="98">为了说明所提方法的优越性, 选取已有的飞机检测方法进行对比实验。在本文实验环境下使用网上公开的代码进行仿真, 记录每种方法在测试集上的检测率、虚警率和平均运行时间, 并进行比较, 结果如表2所示。文献<citation id="122" type="reference">[<a class="sup">5</a>]</citation>是基于深度置信网络的方法, 文献<citation id="123" type="reference">[<a class="sup">6</a>]</citation>是基于卷积神经网络的方法, Faster R-CNN是既不融合多层特征也不改进NMS算法的原始方法。</p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit">表2 不同飞机检测方法的结果对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Comparison among airplane detection results by different methods</p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td>Method</td><td>DR /%</td><td>FAR /%</td><td>Average running<br /> time /s</td></tr><tr><td><br />Ref. [5]</td><td>79.54</td><td>22.52</td><td>171.25</td></tr><tr><td><br />Ref. [6]</td><td>84.25</td><td>17.66</td><td>6.41</td></tr><tr><td><br />Faster R-CNN</td><td>86.28</td><td>8.15</td><td>0.15</td></tr><tr><td><br />Proposed</td><td>94.25</td><td>5.50</td><td>0.16</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">由表2结果可知, 所提方法的检测率、虚警率和平均运行时间均明显优于以往的飞机检测方法。文献<citation id="124" type="reference">[<a class="sup">5</a>]</citation>的方法依旧采用手工设计特征加分类器的方式, 只是用深度置信网络代替了以往的简单分类器时, 依旧存在手工特征表征能力不足和滑动窗口冗余的问题。文献<citation id="125" type="reference">[<a class="sup">6</a>]</citation>的方法先利用BING技术产生候选区域, 再使用卷积神经网络对飞机进行检测。然而, 与RPN相比, BING产生的候选区域质量差且时间成本较高。Faster R-CNN将候选区域生成、特征提取、目标分类和边界回归整合到一个深度卷积神经网络框架中, 充分利用CNN强大的特征表达能力实现端到端的飞机检测, 因此Faster R-CNN和所提方法的准确性和速度均优于前两种方法。正如第4.3节所述, 通过融合多层特征和软判决的NMS算法进一步提升了Faster R-CNN的飞机检测性能, 且改进方法的同时并没有造成过多的时间成本。因此, 所提方法的速度与Faster R-CNN相当, 且检测率和虚警率要优于Faster R-CNN。综上所述, 与以往的飞机检测方法相比, 所提方法的性能最优。</p>
                </div>
                <h3 id="101" name="101" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="102">以更快的区域卷积神经网络为基本框架, 提出了一种特征融合结合软判决的遥感图像飞机检测方法。依次采用L2范数归一化、特征连接、尺度缩放和特征降维来融合多层特征, 引入软判决来改进传统的非极大值抑制方法。实验结果表明, 所提方法能够提高小目标检测的性能, 同时降低了网络在目标高度重叠时的漏检率, 最终得到检测率为94.25%、虚警率为5.5%、平均运行时间为0.16 s的实验结果。所提方法优于现有的其他飞机检测方法, 对于飞机的实时、精确检测具有较好的理论指导和实际意义。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="9">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201710021&amp;v=MDU5OTREa1VydkFJalhUYkxHNEg5Yk5yNDlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rmk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Song M Z, Qu H S, Jin G. Weak ship target detection of noisy optical remote sensing image on sea surface[J]. Acta Optica Sinica, 2017, 37 (10) : 1011004. 宋明珠, 曲宏松, 金光. 含噪光学遥感图像海面弱小舰船目标检测[J]. 光学学报, 2017, 37 (10) : 1011004.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust airplane detection in satellite images">

                                <b>[2]</b> Li W, Xiang S M, Wang H B, <i>et al</i>. Robust airplane detection in satellite images[C]. IEEE International Conference on Image Processing, 2011: 2821-2824.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Region-based Airplane Detection in Remotely Sensed Imagery">

                                <b>[3]</b> Bo S K, Jing Y J. Region-based airplane detection in remotely sensed imagery[C]. International Congress on Image and Signal Processing, 2010: 1923-1926.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700100326&amp;v=MDgyNTY2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SktGOFZiaG89TmlmT2ZiSzhIOURNcUk5Rlplc1BEMzQvb0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Liu L, Shi Z W. Airplane detection based on rotation invariant and sparse coding in remote sensing images[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (18) : 5327-5333.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aircraft detection by deep belief nets">

                                <b>[5]</b> Chen X Y, Xiang S M, Liu C L, <i>et al</i>. Aircraft detection by deep belief nets[C]. Asian Conference on Pattern Recognition, 2013: 54-58.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast aircraft detection in satellite images based on convolutional neural networks">

                                <b>[6]</b> Wu H, Zhang H, Zhang J F, <i>et al</i>. Fast aircraft detection in satellite images based on convolutional neural networks[C]. IEEE International Conference on Image Processing, 2015: 4210-4214.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MDY2NTJGaURrVXJ2QUlqWFRiTEc0SDluTXJJOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Xin P, Xu Y L, Tan H, <i>et al</i>. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An aircraft detection framework based on reinforcement learning and convolutional neural networks in remote sensing images">

                                <b>[8]</b> Li Y, Fu K, Sun H, <i>et al</i>. An aircraft detection framework based on reinforcement learning and convolutional neural networks in remote sensing images[J]. Remote Sensing, 2018, 10 (2) : 243.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object detection in high-resolution remote sensing images using rotation invariant parts based model">

                                <b>[9]</b> Zhang W C, Sun X, Fu K, <i>et al</i>. Object detection in high-resolution remote sensing images using rotation invariant parts based model[J]. IEEE Geoscience and Remote Sensing Letters, 2014, 11 (1) : 74-78.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Feature extraction by rotationinvariant matrix representation for object detection in aerial image,&amp;quot;">

                                <b>[10]</b> Wang G L, Wang X C, Fan B, <i>et al</i>. Feature extraction by rotation-invariant matrix representation for object detection in aerial image[J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (6) : 851-855.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Survey on Transfer Learning">

                                <b>[11]</b> Pan S J, Yang Q. A survey on transfer learning[J]. IEEE Transactions on Knowledge and Data Engineering, 2010, 22 (10) : 1345-1359.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN:towards real-time object detection with region proposal networks">

                                <b>[12]</b> Ren S Q, He K M, Girshick R, <i>et al</i>. Faster R-CNN: towards real-time object detection with region proposal networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) : 1137-1149.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">

                                <b>[13]</b> Girshick R B. Fast R-CNN[C]. International Conference on Computer Vision, 2015: 1440-1448.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=HyperNet:Towards Accurate Region Proposal Generation and Joint Object Detection">

                                <b>[14]</b> Kong T, Yao A, Chen Y, <i>et al</i>. HyperNet: towards accurate region proposal generation and joint object detection[C]. IEEE Conference on Computer Vision and Pattern Recognition, 2016: 845-853.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ParseNet: looking wider to see better">

                                <b>[15]</b> Liu W, Rabinovich A, Berg A C, <i>et al</i>. ParseNet: looking wider to see better[EB/OL]. (2015-11-23) [2018-01-15]. https://arxiv.org/abs/1506.04579
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-maximum suppression for object detection by passing messages between windows">

                                <b>[16]</b> Rothe R, Guillaumin M, Van Gool L, <i>et al</i>. Non-maximum suppression for object detection by passing messages between windows[C]. Asian Conference on Computer Vision, 2014: 290-306.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201902009" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201902009&amp;v=MTYwMzZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURrVXJ2QUlqWFRiTEc0SDlqTXJZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

