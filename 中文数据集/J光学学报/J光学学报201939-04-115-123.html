

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134113769033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201904014%26RESULT%3d1%26SIGN%3d4wm35I3K7pGL6kAb7nGPIDgoKIQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904014&amp;v=MTA2NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdnVzczTUlqWFRiTEc0SDlqTXE0OUVZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 SC非监督预训练 ">2 SC非监督预训练</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="3 基于SC和CNN的模型 ">3 基于SC和CNN的模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="&lt;b&gt;3.1 模型的建立&lt;/b&gt;"><b>3.1 模型的建立</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;3.2 模型的算法流程&lt;/b&gt;"><b>3.2 模型的算法流程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#81" data-title="4 仿真实验 ">4 仿真实验</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="&lt;b&gt;4.1 实验数据&lt;/b&gt;"><b>4.1 实验数据</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;4.2 SC非监督学习&lt;/b&gt;"><b>4.2 SC非监督学习</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;4.3 训练收敛性能分析&lt;/b&gt;"><b>4.3 训练收敛性能分析</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;4.4 分类性能的比较&lt;/b&gt;"><b>4.4 分类性能的比较</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;4.5 自然地貌图像的无人机着陆场景分类&lt;/b&gt;"><b>4.5 自然地貌图像的无人机着陆场景分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="图1 字典可视化表达。 (a) 示例1; (b) 示例2">图1 字典可视化表达。 (a) 示例1; (b) 示例2</a></li>
                                                <li><a href="#70" data-title="图2 基于SC和CNN的模型">图2 基于SC和CNN的模型</a></li>
                                                <li><a href="#73" data-title="表1 基于SC和CNN的模型的网络结构">表1 基于SC和CNN的模型的网络结构</a></li>
                                                <li><a href="#84" data-title="图3 基于SC和CNN的地貌场景分类算法流程图">图3 基于SC和CNN的地貌场景分类算法流程图</a></li>
                                                <li><a href="#92" data-title="图4 采用SC在两个数据库中对大小为14&#215;14的图像块进行特征学习得到的特征可视化表示。 (a) 无人机地貌数据库3, 特征排序前; (b) 无人机地貌数据库3, 特征排序后; (c) UC Merced LU数据库, 特征排序前; (d) UC Merced LU数据 库, 特征排序后">图4 采用SC在两个数据库中对大小为14×14的图像块进行特征学习得到的特征可视化表示。 (a) 无......</a></li>
                                                <li><a href="#97" data-title="图5 UC Merced LU数据库的训练收敛曲线。 (a) 4种方法得到的训练收敛曲线; (b) SC-CNN算法得到的训练收敛曲线">图5 UC Merced LU数据库的训练收敛曲线。 (a) 4种方法得到的训练收敛曲线; (b) ......</a></li>
                                                <li><a href="#101" data-title="表2 不同算法在UC Merced LU数据库中的分类准确率">表2 不同算法在UC Merced LU数据库中的分类准确率</a></li>
                                                <li><a href="#102" data-title="表3 不同算法在无人机地貌数据库3中的分类准确率">表3 不同算法在无人机地貌数据库3中的分类准确率</a></li>
                                                <li><a href="#105" data-title="图6 采用SC-CNN算法对地貌进行分类得到的混淆矩阵">图6 采用SC-CNN算法对地貌进行分类得到的混淆矩阵</a></li>
                                                <li><a href="#110" data-title="图7 复杂地貌图像的分类效果图。 (a) 地貌图像; (b) 人工地貌划分; (c) 分块后的图像; (d) 地貌分类效果图">图7 复杂地貌图像的分类效果图。 (a) 地貌图像; (b) 人工地貌划分; (c) 分块后的图像;......</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="12">


                                    <a id="bibliography_1" title=" Hinton G E, Osindero S, Teh Y W.A fast learning algorithm for deep belief nets[J].Neural Computation, 2006, 18 (7) :1527-1554." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012538&amp;v=MDg0NDVvOUZaT29OQ1g4eG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpsc2NhQlk9TmlmSlpiSzlIdGpNcQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Hinton G E, Osindero S, Teh Y W.A fast learning algorithm for deep belief nets[J].Neural Computation, 2006, 18 (7) :1527-1554.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_2" title=" Szegedy C, Liu W, Jia Y Q, &lt;i&gt;et al&lt;/i&gt;.Going deeper with convolutions[EB/OL]. (2014-09-17) [2018-09-18].https://arxiv.org/abs/1409.4842." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going Deeper with Convolutions">
                                        <b>[2]</b>
                                         Szegedy C, Liu W, Jia Y Q, &lt;i&gt;et al&lt;/i&gt;.Going deeper with convolutions[EB/OL]. (2014-09-17) [2018-09-18].https://arxiv.org/abs/1409.4842.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_3" title=" Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[EB/OL]. (2015-04-10) [2018-09-18].https://arxiv.org/abs/1409.1556v1." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">
                                        <b>[3]</b>
                                         Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[EB/OL]. (2015-04-10) [2018-09-18].https://arxiv.org/abs/1409.1556v1.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_4" title=" Sun Y F, Qi G L, Hu Y L, &lt;i&gt;et al&lt;/i&gt;.Deep convolution neural network recognition algorithm based on improved Fisher criterion[J].Journal of Beijing University of Technology, 2015, 41 (6) :835-841.孙艳丰, 齐光磊, 胡永利, 等.基于改进Fisher准则的深度卷积神经网络识别算法[J].北京工业大学学报, 2015, 41 (6) :835-841." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJGD201506007&amp;v=MTA5MzQ5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2dXNzNNSnlmTWFyRzRIOVRNcVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Sun Y F, Qi G L, Hu Y L, &lt;i&gt;et al&lt;/i&gt;.Deep convolution neural network recognition algorithm based on improved Fisher criterion[J].Journal of Beijing University of Technology, 2015, 41 (6) :835-841.孙艳丰, 齐光磊, 胡永利, 等.基于改进Fisher准则的深度卷积神经网络识别算法[J].北京工业大学学报, 2015, 41 (6) :835-841.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_5" title=" Zhu M M, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;.Airport detection method with improved region-based convolutional neural network[J].Acta Optica Sinica, 2018, 38 (7) :0728001.朱明明, 许悦雷, 马时平, 等.改进区域卷积神经网络的机场检测方法[J].光学学报, 2018, 38 (7) :0728001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807042&amp;v=MDIyNTZxQnRHRnJDVVJMT2VaZVZ1Rnk3Z1c3M01JalhUYkxHNEg5bk1xSTlCWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Zhu M M, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;.Airport detection method with improved region-based convolutional neural network[J].Acta Optica Sinica, 2018, 38 (7) :0728001.朱明明, 许悦雷, 马时平, 等.改进区域卷积神经网络的机场检测方法[J].光学学报, 2018, 38 (7) :0728001.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_6" title=" Kavukcuoglu K, Sermanet P, Boureau Y L, &lt;i&gt;et al&lt;/i&gt;.Learning convolutional feature hierarchies for visual recognition[C]//Proceedings of 23rd International Conference on Neural Information Processing Systems, December 6-9, 2010, Vancouver, British Columbia, Canada.New York:Curran Associates Inc., 2010:1090-1098." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning convolutional feature hierarchies for visual recognition">
                                        <b>[6]</b>
                                         Kavukcuoglu K, Sermanet P, Boureau Y L, &lt;i&gt;et al&lt;/i&gt;.Learning convolutional feature hierarchies for visual recognition[C]//Proceedings of 23rd International Conference on Neural Information Processing Systems, December 6-9, 2010, Vancouver, British Columbia, Canada.New York:Curran Associates Inc., 2010:1090-1098.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_7" title=" Zhang W D, Xu Y L, Ni J C, &lt;i&gt;et al&lt;/i&gt;.Image target recognition method based on multi-scale block convolutional neural network[J].Journal of Computer Applications, 2016, 36 (4) :1033-1038.张文达, 许悦雷, 倪嘉成, 等.基于多尺度分块卷积神经网络的图像目标识别算法[J].计算机应用, 2016, 36 (4) :1033-1038." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201604030&amp;v=MjMzMzF1Rnk3Z1c3M01MejdCZDdHNEg5Zk1xNDlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Zhang W D, Xu Y L, Ni J C, &lt;i&gt;et al&lt;/i&gt;.Image target recognition method based on multi-scale block convolutional neural network[J].Journal of Computer Applications, 2016, 36 (4) :1033-1038.张文达, 许悦雷, 倪嘉成, 等.基于多尺度分块卷积神经网络的图像目标识别算法[J].计算机应用, 2016, 36 (4) :1033-1038.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_8" title=" Shi H H, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;.Convolutional neural networks recognition algorithm based on PCA[J].Journal of Xidian University (Natural Science) , 2016, 43 (3) :161-166.史鹤欢, 许悦雷, 马时平, 等.PCA预训练的卷积神经网络目标识别算法[J].西安电子科技大学学报 (自然科学版) , 2016, 43 (3) :161-166." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201603028&amp;v=MTcxNDFyQ1VSTE9lWmVWdUZ5N2dXNzNNUFNuQWFyRzRIOWZNckk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Shi H H, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;.Convolutional neural networks recognition algorithm based on PCA[J].Journal of Xidian University (Natural Science) , 2016, 43 (3) :161-166.史鹤欢, 许悦雷, 马时平, 等.PCA预训练的卷积神经网络目标识别算法[J].西安电子科技大学学报 (自然科学版) , 2016, 43 (3) :161-166.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_9" title=" Chen Y, Fan R S, Wang J X, &lt;i&gt;et al&lt;/i&gt;.High resolution image classification method combining with minimum noise fraction rotation and convolution neural network[J].Laser &amp;amp; Optoelectronics Progress, 2017, 54 (10) :102801.陈洋, 范荣双, 王竞雪, 等.结合最小噪声分离变换和卷积神经网络的高分辨影像分类方法[J].激光与光电子学进展, 2017, 54 (10) :102801." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201710056&amp;v=MTY2NTMzenFxQnRHRnJDVVJMT2VaZVZ1Rnk3Z1c3M01MeXJQWkxHNEg5Yk5yNDlBWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Chen Y, Fan R S, Wang J X, &lt;i&gt;et al&lt;/i&gt;.High resolution image classification method combining with minimum noise fraction rotation and convolution neural network[J].Laser &amp;amp; Optoelectronics Progress, 2017, 54 (10) :102801.陈洋, 范荣双, 王竞雪, 等.结合最小噪声分离变换和卷积神经网络的高分辨影像分类方法[J].激光与光电子学进展, 2017, 54 (10) :102801.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_10" title=" Yang Y, Newsam S.Spatial pyramid co-occurrence for image classification[C]//Proceedings of International Conference on Computer Vision, November 6-13, 2011, Barcelona, Spain.New York:IEEE, 2011:1465-1472." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial pyramid co-occurrence for image classification">
                                        <b>[10]</b>
                                         Yang Y, Newsam S.Spatial pyramid co-occurrence for image classification[C]//Proceedings of International Conference on Computer Vision, November 6-13, 2011, Barcelona, Spain.New York:IEEE, 2011:1465-1472.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_11" title=" Xu S H, Mu X D, Zhao P, &lt;i&gt;et al&lt;/i&gt;.Scene classification of remote sensing image based on multi-scale feature and deep neural network[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (7) :834-840.许夙晖, 慕晓冬, 赵鹏, 等.利用多尺度特征与深度网络对遥感影像进行场景分类[J].测绘学报, 2016, 45 (7) :834-840." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201607012&amp;v=Mjg3NTBmTXFJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdnVzczTUppWFRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Xu S H, Mu X D, Zhao P, &lt;i&gt;et al&lt;/i&gt;.Scene classification of remote sensing image based on multi-scale feature and deep neural network[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (7) :834-840.许夙晖, 慕晓冬, 赵鹏, 等.利用多尺度特征与深度网络对遥感影像进行场景分类[J].测绘学报, 2016, 45 (7) :834-840.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_12" title=" He X F, ZouZ R, Tao C, &lt;i&gt;et al&lt;/i&gt;.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201609011&amp;v=MTgyNzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk3Z1c3M01KaVhUYkxHNEg5Zk1wbzlFWllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         He X F, ZouZ R, Tao C, &lt;i&gt;et al&lt;/i&gt;.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_13" title=" Chen S Z, Tian Y L.Pyramid of spatial relatons for scene-level land use classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 53 (4) :1947-1957." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pyramid of spatial relatons for scene-level land use classification">
                                        <b>[13]</b>
                                         Chen S Z, Tian Y L.Pyramid of spatial relatons for scene-level land use classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 53 (4) :1947-1957.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_14" title=" Chan T H, Jia K, Gao S H, &lt;i&gt;et al&lt;/i&gt;.PCANet:a simple deep learning baseline for image classification[J].IEEE Transactions on Image Processing, 2015, 24 (12) :5017-5032." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PCANet:A simple deep learning baseline for image classification?">
                                        <b>[14]</b>
                                         Chan T H, Jia K, Gao S H, &lt;i&gt;et al&lt;/i&gt;.PCANet:a simple deep learning baseline for image classification[J].IEEE Transactions on Image Processing, 2015, 24 (12) :5017-5032.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-17 10:57</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(04),115-123 DOI:10.3788/AOS201939.0410001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于稀疏编码和卷积神经网络的地貌图像分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E8%8A%B3&amp;code=06289103&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘芳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E9%91%AB&amp;code=06300206&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王鑫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B7%AF%E4%B8%BD%E9%9C%9E&amp;code=34754815&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">路丽霞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E5%85%89%E4%BC%9F&amp;code=34873934&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄光伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%B4%AA%E5%A8%9F&amp;code=36915940&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王洪娟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%83%A8&amp;code=0034856&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京工业大学信息学部</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出了一种基于稀疏编码和卷积神经网络的地貌场景图像分类算法;利用非下采样Contourlet变换对训练样本进行多尺度分解;在训练样本中选择图像, 利用稀疏编码学习局部特征, 对特征向量进行排序;选择灰度平均梯度较大的特征向量对卷积神经网络卷积核进行初始化。结果表明:所提算法可以获得比传统底层视觉特征更好的分类结果, 有效避免了网络训练陷入局部最优的问题, 提高了自然场景下无人机着陆地貌的分类准确率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9C%B0%E8%B2%8C%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">地貌图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏编码;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机视觉;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *王鑫, E-mail:752963336@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61171119);</span>
                                <span>北京工业大学研究生科技基金 (ykj-2016-00004);</span>
                    </p>
            </div>
                    <h1><b>Landform Image Classification Based on Sparse Coding and Convolutional Neural Network</b></h1>
                    <h2>
                    <span>Liu Fang</span>
                    <span>Wang Xin</span>
                    <span>Lu Lixia</span>
                    <span>Huang Guangwei</span>
                    <span>Wang Hongjuan</span>
            </h2>
                    <h2>
                    <span>Information Department, Beijing University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A landform image classification algorithm based on sparse coding and convolutional neural network is proposed. The non-subsampled Contourlet transform is applied to the training samples for multi-scale decomposition. The images are selected in the training samples to learn the local features by using sparse coding, and the feature vectors are sorted. The feature vectors with larger gray-scale mean gradients are selected to initialize the convolutional neural network convolution kernel. The results show that the proposed algorithm can obtain better classification results than traditional underlying visual features, which effectively avoids the problem of network training falling into local optimum, and improves the classification accuracy of unmanned aerial vehicles landing landform in natural scenes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=landform%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">landform image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20coding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse coding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=computer%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">computer vision;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="40" name="40" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="41">随着技术的进步, 无人机 (UAV) 被广泛应用到军事侦察、地质勘探、目标跟踪、交通监控等领域。针对无人机在未知区域飞行时可能会受到突发因素的影响而无法安全着陆的问题, 研究人员依据无人机的实际飞行情况, 通过视觉导航技术采取避障措施或航迹重规划, 结合图像分类技术选择合适的着陆地点, 实现了无人机自主着陆。无人机地貌图像中的目标场景分布信息是无人机自主安全着陆的重要依据。由于无人机的飞行环境复杂多样, 无人机地貌图像具有场景复杂、纹理信息丰富、范围大、视角宽的特点, 因此, 快速、有效的地貌分类技术成为无人机执行飞行任务的安全保障。</p>
                </div>
                <div class="p1">
                    <p id="42">近年来, 深度学习被引入到图像分类中, Hinton等<citation id="114" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出了用深度学习的思想对图像进行识别。卷积神经网络 (CNN) 在图像分类中具有较好的分类效果<citation id="115" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。Simonyan等<citation id="116" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>在CNN的两个全连接层采用了Dropout策略, 该策略可以防止某些特征仅在其他特殊特征出现时才产生作用, 从而有效避免了网络中各特征之间的相互依赖性。孙艳丰等<citation id="117" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了基于改进Fisher准则的深度CNN识别算法, 反向传播采用Fisher约束准则, 加入判别准则的能量函数在迭代求解权值的搜索空间会受到判别条件的约束, 从全局搜索缩小到更有利于分类的局部空间搜索, 从而使权值更快地逼近便于分类的最优值。朱明明等<citation id="118" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种结合级联的区域建议网络和检测网络的遥感图像机场检测方法, 通过改进区域建议网络, 实现了两个网络的卷积层共享, 从而使得检测时间大幅缩短, 并提高了检测准确率。</p>
                </div>
                <div class="p1">
                    <p id="43">无论是卷积层的改进, 还是降采样层及全连接层的改进, 都是针对网络的学习能力及学习效率两方面的改进。由于CNN的学习能力可以通过调节网络的深度来增强, 因此增加模型深度可以有效优化网络的性能。以上基于CNN的图像分类算法虽然都取得了较高的分类准确率, 但CNN采用有监督的训练方式, 训练时需要使用大量的标记样本, 而有些图像样本的采集比较困难 (例如无人机地貌图像, 其样本数量少) , 会导致网络的前几层无法得到充分训练, 从而劣化网络的性能。</p>
                </div>
                <div class="p1">
                    <p id="44">针对此问题, Kavukcuoglu等<citation id="119" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>利用独立成分分析 (ICA) 预训练对CNN进行权值初始化;张文达等<citation id="120" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>利用稀疏自动编码器 (SAE) 对CNN进行非监督预训练, 通过最小化重构误差获得待识别图像的隐含层表示, 学习得到含有训练数据统计特性的滤波器集合;史鹤欢等<citation id="121" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>利用主成分分析 (PCA) 非监督预训练初始化CNN;陈洋等<citation id="122" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>采用最小噪声分离分析非监督训练初始化CNN, 结果表明, 分类方法的分类精度明显提高。以上初始化权值的方法都使CNN的识别率得到了一定程度的提高, 但上述方法在对训练得到的初始卷积核进行特征提取时, 数据特征的提取效果一般。</p>
                </div>
                <div class="p1">
                    <p id="45">为了提高无人机地貌图像在小样本数据条件下着陆点地貌场景的分类准确率, 本文以无人机自然地貌图像为研究对象, 提出了一种基于稀疏编码 (SC) 和CNN的地貌图像分类算法。该算法首先对训练样本进行非下采样Contourlet变换, 对原图像进行多尺度分解, 并选取前两层分解图像来扩充训练样本集;然后在训练样本中随机选择图像, 利用SC方法学习局部特征, 并对特征向量按照其灰度平均梯度 (GMG) 从大到小排序;最后选择GMG较大的特征向量对CNN卷积核进行初始化, 通过特征学习得到全局特征向量, 并将其输入到支持向量机 (SVM) 中得到地貌图像的分类结果。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 SC非监督预训练</h3>
                <div class="p1">
                    <p id="47">SC非监督学习得到的基向量能够最大程度地表示输入图像的局部特征信息, 这里采用SC对CNN的卷积核进行预训练。采用SC对地貌样本图像进行处理, 得到具有训练样本特征表达信息的基函数集合, 将基函数集合作为CNN的初始化卷积核。SC主要用来寻找一组超完备的基向量, 也就是字典, 用来表示输入数据。字典可视化表达如图1所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 字典可视化表达。 (a) 示例1; (b) 示例2" src="Detail/GetImg?filename=images/GXXB201904014_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 字典可视化表达。 (a) 示例1; (b) 示例2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Dictionary visualization expression. (a) Example 1; (b) example 2</p>

                </div>
                <div class="p1">
                    <p id="49">SC过程分为如下两个阶段:</p>
                </div>
                <div class="p1">
                    <p id="50">1) 训练阶段。给定样本图像 (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>) , 其中<i>n</i>为样本数, 需要从这些样本中学习得到一组基向量ϕ= (ϕ<sub>1</sub>, ϕ<sub>2</sub>, …, ϕ<sub><i>n</i></sub>) , 这组基向量即为字典。训练过程是一个重复迭代的过程, 为了得到超完备基向量, 需要使目标函数值最小。通过交替更改稀疏向量<b><i>a</i></b>和基向量ϕ的值, 使目标函数最小。目标函数为</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow></mstyle><mrow><mi mathvariant="bold-italic">a</mi><mo>, </mo><mtext>ϕ</mtext></mrow></munder></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mtext>ϕ</mtext><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">|</mo></mstyle></mrow></mstyle><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo stretchy="false">|</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>i</i>、<i>j</i>、<i>k</i>为正整数, <i>k</i>&gt;<i>n</i>;<i>a</i><sub><i>i</i>, <i>j</i></sub>为稀疏向量<b><i>a</i></b>中的元素;<i>λ</i>为稀疏系数。</p>
                </div>
                <div class="p1">
                    <p id="53">迭代过程可以分为两个步骤:①固定字典ϕ, 然后不断调整稀疏向量<b><i>a</i></b>, 使 (1) 式中的目标函数最小;②固定稀疏向量<b><i>a</i></b>, 然后不断调整ϕ, 使 (1) 式中的目标函数最小。</p>
                </div>
                <div class="p1">
                    <p id="54">通过不断迭代, 直到目标函数收敛, 就可以得到一组可以较好地表示样本图像的基向量, 也就是字典。</p>
                </div>
                <div class="p1">
                    <p id="55">2) 编码阶段。输入一个新的图像, 通过步骤1) 中的训练阶段得到字典, 然后将其代入 (1) 式, 求解目标函数中的稀疏向量<b><i>a</i></b>, 这个稀疏向量就是输入到图像中的一个稀疏表达。</p>
                </div>
                <div class="p1">
                    <p id="56">假设CNN的输入训练图像有<i>N</i>幅大小为<i>m</i>×<i>n</i> (<i>m</i>为正整数) 的训练图像{<i>I</i><sub><i>i</i></sub>}<mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>, 卷积核的大小为k<sub>1</sub>×k<sub>2</sub>, 训练图像I<sub>i</sub>分成大小为k<sub>1</sub>×k<sub>2</sub>的图像块, 表示为<b><i>x</i></b><sub><i>i</i>, 1</sub>, <b><i>x</i></b><sub><i>i</i>, 2</sub>, …, <b><i>x</i></b><sub><i>i</i>, <i>mn</i></sub>∈<i>R</i><sup><i>k</i><sub>1</sub><i>k</i><sub>2</sub></sup>, 其中<b><i>x</i></b><sub><i>i</i>, <i>j</i></sub>为图像<i>I</i><sub><i>i</i></sub>中第<i>j</i> (<i>j</i>=1, 2, …, <i>mn</i>) 个图像块, <i>R</i><sup><i>k</i><sub>1</sub><i>k</i><sub>2</sub></sup>为训练图像集。图像<i>I</i><sub><i>i</i></sub>的图像块数据为</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>m</mi><mi>n</mi></mrow></msub><mo stretchy="false">) </mo><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">同理, 训练图像的图像块数据为</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">) </mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mi>k</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>×</mo><mo stretchy="false"> (</mo><mi>Ν</mi><mi>m</mi><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<b><i>X</i></b>为训练图像, <b><i>X</i></b>分成大小为 (<i>k</i><sub>1</sub><i>k</i><sub>2</sub>) × (<i>mn</i>) 的图像块, 表示为<b><i>X</i></b><sub>1</sub>, <b><i>X</i></b><sub>2</sub>, …, <b><i>X</i></b><sub><i>N</i></sub>∈<i>R</i><sup> (<i>k</i><sub>1</sub><i>k</i><sub>2</sub>) × (<i>mn</i>) </sup>。</p>
                </div>
                <div class="p1">
                    <p id="62">利用 (1) 式求出超完备基向量, 则SC学习到的初始化CNN的卷积核组为</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>l</mi><mi>n</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mi>k</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false"> (</mo><mtext>ϕ</mtext><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mi>k</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>×</mo><mo stretchy="false"> (</mo><mi>Ν</mi><mi>m</mi><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">式中:<b><i>m</i></b><sub><i>k</i><sub>1</sub><i>k</i><sub>2</sub></sub> (ϕ) 为将向量ϕ∈<i>R</i><sup> (<i>k</i><sub>1</sub><i>k</i><sub>2</sub>) × (<i>Nmn</i>) </sup>映射到<b><i>W</i></b>∈<i>R</i><sup> (<i>k</i><sub>1</sub><i>k</i><sub>2</sub>) × (<i>Nmn</i>) </sup>;ϕ<sub><i>l</i></sub>为<b><i>X</i></b>的第<i>l</i>个超完备基向量。</p>
                </div>
                <div class="p1">
                    <p id="65">通过SC非监督训练能获得训练图像局部图像块的超完备基向量, 这些基向量能够最大程度地表示数据的局部特征。将得到的基向量作为CNN的卷积核, 在卷积操作时能够很好地获得原图像中局部特征的主要信息以及特征之间的变化和差异。与卷积核随机初始化相比, 预训练得到的卷积核提取的特征更加贴近原图像。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag">3 基于SC和CNN的模型</h3>
                <div class="p1">
                    <p id="67">卷积核是影响CNN分类准确率的核心, CNN的训练是对卷积核不断地进行调整, 从而对学习到的特征不断地进行调整的过程。由于CNN的卷积核是随机初始化的, 在处理图像内容比较复杂且样本数量少的分类问题时, 很容易限于局部最优, 因此很难通过网络训练得到合适的卷积核。SC非监督学习得到的基向量能够最大程度地表示输入图像的局部特征信息, 特征基向量作为卷积核初始化值可以获得更好的视觉表达特征和更高的效率, 也可以解决随机初始化陷入局部最优的问题。但是, SC学习到的特征会出现边缘性, 边缘性的强弱代表特征学习的效果, 不同类别的图像学习到的基向量没有顺序规律, 因此本研究在SC无监督特征学习后按照边缘性强弱对特征基向量进行排序, 选择出具有代表性的基向量作为CNN的初始化卷积核。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>3.1 模型的建立</b></h4>
                <div class="p1">
                    <p id="69">本研究提出的网络模型如图2所示, 模型分为4个部分:1) 图像多尺度分解。利用非下采样Contourlet变换, 将输入图像分解为相同尺寸的<i>n</i>幅图像。2) 对SC非监督学习得到的基向量采用GMG方法进行排序、选择。根据选择标准, 选择出具有相应大小、数量的基向量作为CNN的卷积核。3) 将分解后的图像输入到训练好的CNN中, 对各图像提取图像特征。4) 用SVM进行分类。将得到的图像特征向量作为输入对SVM进行训练, 得到最终的图像分类结果。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于SC和CNN的模型" src="Detail/GetImg?filename=images/GXXB201904014_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于SC和CNN的模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Model based on SC and CNN</p>

                </div>
                <div class="p1">
                    <p id="71">无人机在户外实际飞行过程中, 会受到环境、自身拍摄设备以及飞行状况的影响, 采集到的地貌图像会出现分辨率低的情况, 经过非下采样Contourlet变换后的分解图像在第3层及之后的图像中包含的信息较少。为了解决地貌图像的小样本问题, 本课题组采用非下采样Contourlet变换后的前两层分解图像 (即1个低频子带图像和1个高频子带图像) 来扩充无人机地貌图像数据集。</p>
                </div>
                <div class="p1">
                    <p id="72">在深度网络的学习和训练中, 如果样本数量过少或者网络层数较多, 网络结构复杂, 就会导致深度网络训练不充分, 网络的整体性能劣化, 从而使得在特征学习时提取的特征不完整, 分类准确率降低。针对无人机地貌图像的小样本问题, 为了取得较高的图像分类准确率, 防止出现网络过拟合现象, 本课题组提出了基于SC和CNN的模型 (如图2所示) , 该模型的网络结构如表1所示, 其中<i>x</i>为输入层, <i>h</i><sub>1</sub>～<i>h</i><sub>12</sub>为各功能层, <i>o</i>为输出层, <i>v</i>为输出类别。模型的网络结构包括1个输入层、5个卷积层、3个池化层、4个ReLU层和1个输出层。同时, 为了提取高层语义特征并减少网络的计算量, 将采集到的无人机地貌图像大小统一为256 pixel×256 pixel。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit">表1 基于SC和CNN的模型的网络结构 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Network structure of model based on SC and CNN</p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td>Layer</td><td>Type</td><td>Patch size</td><td>Stride</td><td>Zero padding</td><td>Output size</td></tr><tr><td><br /><i>x</i></td><td>Input</td><td></td><td></td><td></td><td>256×256×3</td></tr><tr><td><br /><i>h</i><sub>1</sub></td><td>Convolution</td><td>5×5</td><td>5</td><td>2</td><td>128×128×64</td></tr><tr><td><br /><i>h</i><sub>2</sub></td><td>ReLU</td><td></td><td></td><td></td><td>128×128×64</td></tr><tr><td><br /><i>h</i><sub>3</sub></td><td>Mean pooling</td><td>3×3</td><td>2</td><td></td><td>64×64×64</td></tr><tr><td><br /><i>h</i><sub>4</sub></td><td>Convolution</td><td>3×3</td><td>2</td><td>0</td><td>32×32×64</td></tr><tr><td><br /><i>h</i><sub>5</sub></td><td>ReLU</td><td></td><td></td><td></td><td>32×32×64</td></tr><tr><td><br /><i>h</i><sub>6</sub></td><td>Max pooling</td><td>3×3</td><td>2</td><td></td><td>16×16×64</td></tr><tr><td><br /><i>h</i><sub>7</sub></td><td>Convolution</td><td>7×7</td><td>1</td><td>2</td><td>14×14×128</td></tr><tr><td><br /><i>h</i><sub>8</sub></td><td>ReLU</td><td></td><td></td><td></td><td>14×14×128</td></tr><tr><td><br /><i>h</i><sub>9</sub></td><td>Max pooling</td><td>3×3</td><td>2</td><td></td><td>7×7×128</td></tr><tr><td><br /><i>h</i><sub>10</sub></td><td>Convolution</td><td>7×7</td><td>1</td><td>0</td><td>1×1×128</td></tr><tr><td><br /><i>h</i><sub>11</sub></td><td>ReLU</td><td></td><td></td><td></td><td>1×1×128</td></tr><tr><td><br /><i>h</i><sub>12</sub></td><td>Convolution</td><td>1×1</td><td>1</td><td>0</td><td>1×1×20</td></tr><tr><td><br /><i>o</i></td><td>SVM</td><td></td><td></td><td></td><td><i>v</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>3.2 模型的算法流程</b></h4>
                <div class="p1">
                    <p id="75">图3所示为基于SC和CNN的地貌图像场景分类算法流程图。算法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="76">1) 对训练样本进行非下采样Contourlet变换, 对原图像进行多尺度分解, 并选取前2层分解图像来扩充无人机的地貌图像数据集;</p>
                </div>
                <div class="p1">
                    <p id="77">2) 将地貌图像数据集中的图像裁剪成与卷积核尺寸相同的图像块, 卷积核尺寸为patchDim{1, 3, 5, 7}, 利用SC学习局部特征, 通过 (1) 式得到图像的超完备基向量;</p>
                </div>
                <div class="p1">
                    <p id="78">3) 利用步骤2) 中的基向量计算GMG, 并对特征向量按照其GMG从大到小排序;</p>
                </div>
                <div class="p1">
                    <p id="79">4) 选择GMG较大的特征向量对CNN的卷积核进行初始化, 然后将样本图像输入到CNN中进行训练, 逐层学习图像样本的特征, 并得到全局特征响应;</p>
                </div>
                <div class="p1">
                    <p id="80">5) 将特征向量输入到SVM中得到地貌图像的分类结果。</p>
                </div>
                <h3 id="81" name="81" class="anchor-tag">4 仿真实验</h3>
                <h4 class="anchor-tag" id="82" name="82"><b>4.1 实验数据</b></h4>
                <div class="p1">
                    <p id="83">实验数据集采用UC Merced LU数据库<citation id="123" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和无人机采集到的无人机地貌数据库3, 无人机地貌数据库3中包含无人机地貌数据库1中的单一地貌图像和无人机地貌数据库2中的复杂地貌图像。无人机地貌数据库3是综合无人机飞行中拍摄的图像和视频获得的数据集, 所有图像和视频全部来自于无人机的实际拍摄, 其中约70%为通过无人机采集的视频和图像, 约30%为从互联网上搜集到的无人机飞行航拍视频和图像 (共有8类10000张图像, 其中8000张作为训练图像, 2000张作为测试图像) 。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于SC和CNN的地貌场景分类算法流程图" src="Detail/GetImg?filename=images/GXXB201904014_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于SC和CNN的地貌场景分类算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Algorithm flowchart of landform scene classification based on SC and CNN</p>

                </div>
                <div class="p1">
                    <p id="86">UC Merced LU数据库和无人机地貌数据库3经过非下采样Contourlet变换后, 保留前两层分解图像, 即1个低频子带图像和1个高频子带图像。通过对样本数量进行扩充, UC Merced LU数据库和无人机地貌数据库3这两个数据库中的地貌图像样本量变为6300张和30000张, 样本数量为原来的3倍。</p>
                </div>
                <div class="p1">
                    <p id="87">实验采用表1构建的CNN结构, 利用10折交叉验证方法, 交叉验证重复10次, 每个子样本验证1次, 平均10次的结果最终可得到1个单一估测值。实验所用计算机配置为Windows 7系统、Inter (R) Core (TM) 2 Duo CPU@ 3.0GHZ处理器、NVIDIA GeForce GTX 970M的GPU、16 GB内存、64位MATLAB R2016a仿真平台。</p>
                </div>
                <div class="p1">
                    <p id="88">CNN模型采用随机梯度下降算法训练, 其中, 设置训练参数batch为100, 权重衰减为0.0005, 学习率为0.001。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>4.2 SC非监督学习</b></h4>
                <div class="p1">
                    <p id="90">采用SC对CNN进行预训练所用的UC Merced LU数据库和无人机地貌数据库3包含两个数据库的所有地貌种类。采用随机方式, 分别从UC Merced LU数据库和无人机地貌数据库3中采集50000和100000个图像块, 其中图像块的大小有patchDim{1, 3, 5, 7}4种, 并且在最终的分类实验中, 对每个数据库都进行10次重复实验来测试随机采样时样本图像对CNN整体性能的影响。</p>
                </div>
                <div class="p1">
                    <p id="91">采用SC在两个数据库中学习到的特征可视化表示如图4所示。为了方便观察特征可视化图像, 且限于篇幅, 仅给出两类图像块大小的特征可视化图像。从图4中可以看出:当样本数量过少时, 学习到的特征比较模糊 (UC Merced LU数据库) ;随着训练样本数增加, 特征学习效果明显得到改善 (无人机地貌数据库3) , 当训练样本为100000时, 从无人机地貌数据库3中能学习到更多边缘较清晰的特征。此外, 按照GMG值对特征进行降序排列, 即GMG值大的在上面, 特征的上半部分边缘性更明显。从图4中还可以看出, GMG值能反映图像特征的边缘性, 也就是能反映特征学习的优劣。采用GMG方法, 按照边缘性强弱对特征进行排序划分, 排序后可以更直观地观察和对比学习效果, 从而方便提取边缘性较强的特征作为卷积核初始化值。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 采用SC在两个数据库中对大小为14&#215;14的图像块进行特征学习得到的特征可视化表示。 (a) 无人机地貌数据库3, 特征排序前; (b) 无人机地貌数据库3, 特征排序后; (c) UC Merced LU数据库, 特征排序前; (d) UC Merced LU数据 库, 特征排序后" src="Detail/GetImg?filename=images/GXXB201904014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 采用SC在两个数据库中对大小为14×14的图像块进行特征学习得到的特征可视化表示。 (a) 无人机地貌数据库3, 特征排序前; (b) 无人机地貌数据库3, 特征排序后; (c) UC Merced LU数据库, 特征排序前; (d) UC Merced LU数据 库, 特征排序后  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Feature visualization of image blocks with size of 14×14 on two databases by using SC. (a) UAV landform database 3, before feature sorting; (b) UAV landform database 3, after feature sorting; (c) UC Merced LU database, before feature sorting (d) UC Merced LU database, after feature sorting</p>

                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>4.3 训练收敛性能分析</b></h4>
                <div class="p1">
                    <p id="95">采用所提算法SC-CNN以及多尺度特征深度网络 (MS-DCNN) <citation id="124" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>算法、基于离散傅里叶变换的卷积神经网络 ( DCT-CNN) 算法、CNN (未经过SC预训练的网络) 算法分别对标准UC Merced LU数据库图像进行训练, 得到训练5000代的收敛曲线, 如图5 (a) 所示。从图5 (a) 中可以看出, 在4种方法的训练过程中, 所提算法的分类准确率最高, 在最后迭代训练中, DCT-CNN的收敛曲线几乎与SC-CNN重合, 说明本研究设计的CNN针对地貌图像具有较好的分类性能。</p>
                </div>
                <div class="p1">
                    <p id="96">利用SC-CNN分别对标准UC Merced LU数据库中的原图像、低频图像和高频图像进行网络训练, 得到训练5000代的收敛曲线, 如图5 (b) 所示。从图5 (b) 中可以看出, SC-CNN方法在原图像、低频图像和高频图像上的分类准确率分别为92.37%、93.85%、83.69%。低频图像的收敛曲线与原图像的收敛曲线基本重合, 且低频图像的收敛速度比原图像收敛速度稍快。高频图像包含的图像信息特征较少, 因此分类准确率最低。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 UC Merced LU数据库的训练收敛曲线。 (a) 4种方法得到的训练收敛曲线; (b) SC-CNN算法得到的训练收敛曲线" src="Detail/GetImg?filename=images/GXXB201904014_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 UC Merced LU数据库的训练收敛曲线。 (a) 4种方法得到的训练收敛曲线; (b) SC-CNN算法得到的训练收敛曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Training convergence curves for UC Merced LU database. (a) Training convergence curves obtained with four different methods; (b) training convergence curves obtained with SC-CNN algorithm</p>

                </div>
                <div class="p1">
                    <p id="98">由仿真结果可知, SC-CNN算法取得了较好的分类结果。经过非下采样Contourlet变换后的图像保留了原图像中的有用特征信息, 特别是低频图像, 经过非下采样Contourlet变换后, 去除了与目标特征无关的冗余信息。高频图像中也包含原图像中有用的信息特征, 通过非下采样Contourlet变换对样本图像进行扩充, 分类准确率得到了一定提高。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>4.4 分类性能的比较</b></h4>
                <div class="p1">
                    <p id="100">为了验证所提算法对地貌图像的分类效果, 对比联合显著性和多层卷积神经网络 (CS-CNN) <citation id="125" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、空间关系金字塔算法 (PSR) <citation id="126" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、MS-DCNN<citation id="127" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、主成分分析网络 (PCANet) <citation id="128" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、经典方法SVM与所提算法SC-CNN对标准UC Merced LU数据库和无人机地貌数据库3的分类准确率, 分类效果如表2和表3所示。实验是利用同一设备在相同实验条件下进行的, 文献<citation id="130" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</citation>中的算法是针对无人机图像分类算法中具有较好分类效果的算法, 文献<citation id="129" type="reference">[<a class="sup">13</a>]</citation>中的算法同样采用非下采样Contourlet变换对原图像进行多尺度分解, 但是网络结构与所提算法不同。</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit">表2 不同算法在UC Merced LU数据库中的分类准确率 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Classification accuracy of different algorithms on UC Merced LU database</p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td><br />Algorithm</td><td>Training accuracy /%</td><td>Training time /h</td></tr><tr><td><br />SVM</td><td>78.57</td><td>0.7</td></tr><tr><td><br />CS-CNN<sup>[12]</sup></td><td>92.86</td><td>4.5</td></tr><tr><td><br />PSR<sup>[13]</sup></td><td>89.10</td><td>5.2</td></tr><tr><td><br />MS-DCNN<sup>[11]</sup></td><td>91.34</td><td>5.9</td></tr><tr><td><br />SC-CNN</td><td>98.14</td><td>4.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="102">
                    <p class="img_tit">表3 不同算法在无人机地貌数据库3中的分类准确率 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Classification accuracy of existing methods on UAV landform database 3</p>
                    <p class="img_note"></p>
                    <table id="102" border="1"><tr><td><br />Algorithm</td><td>Training accuracy /%</td><td>Training time /h</td></tr><tr><td><br />SVM</td><td>76.96</td><td>2.6</td></tr><tr><td><br />CS-CNN<sup>[12]</sup></td><td>92.91</td><td>12.9</td></tr><tr><td><br />MS-DCNN<sup>[11]</sup></td><td>91.53</td><td>13.7</td></tr><tr><td><br />PCANet<sup>[14]</sup></td><td>86.49</td><td>11.1</td></tr><tr><td><br />SC-CNN</td><td>97.50</td><td>10.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="103">从表2和表3中可以看出, 所提算法在两个数据库中都具有较高的分类准确率。文献<citation id="131" type="reference">[<a class="sup">13</a>]</citation>中的算法也利用非下采样Contourlet变换对原图像进行多尺度分解, 本研究与文献<citation id="132" type="reference">[<a class="sup">13</a>]</citation>中的方法同样扩展了数据库图像的数量, 但是相对于MS-DCNN算法, 所提算法的分类准确率提高了6%。因为本研究采用SC预训练CNN, 对学习到的原图像字典特征求其GMG, 选择边缘性较好的特征向量作为CNN卷积核进行初始化, 这些卷积核具有原图像的统计特性和特征规律, 在网络训练和特征学习时能得到较好的高层语义特征表达。综上, SC-CNN算法对地貌图像具有较高的分类准确率。</p>
                </div>
                <div class="p1">
                    <p id="104">利用SC-CNN算法对UC Merced LU数据库进行地貌分类得到的混淆矩阵如图6所示。从图6中可以看出, 该算法对street和tall building等纹理差异性较小的地貌具有较好的分类效果, 但对图像场景内容较相似的图像容易发生错分。</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 采用SC-CNN算法对地貌进行分类得到的混淆矩阵" src="Detail/GetImg?filename=images/GXXB201904014_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 采用SC-CNN算法对地貌进行分类得到的混淆矩阵  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Confusion matrix obtained by classify landforms with SC-CNN algorithm SC-CNN</p>

                </div>
                <div class="p1">
                    <p id="106">综上, 相对于其他各算法, 所提算法对小样本的无人机地貌图像具有较好的分类效果, 且分类性能优于其他算法。实验结果验证了所提SC-CNN算法的有效性, 该算法通过非下采样Contourlet变换对小样本地貌图像进行扩充, 并且能够综合高频图像和低频图像的优势, 在图像地貌分类中具有明显的分类优势。此外, 基于SC预训练的CNN对学习到的原图像字典特征求GMG, 并按照GMG从大到小对特征进行排序, 选择边缘性较好的特征向量作为CNN卷积核初始化, 这些初始化的卷积核具有原图像的统计特性和特征规律, 在网络训练和特征学习时能得到较好的高层语义特征。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>4.5 自然地貌图像的无人机着陆场景分类</b></h4>
                <div class="p1">
                    <p id="108">为了验证所提算法对自然地貌图像中地貌的分类效果, 通过仿真实验对含有多种地貌的复杂自然图像进行分类和识别。将每个图像块扩充后输入到SC预训练的CNN模型中进行特征学习和分类, 然后统计每个图像块得到的地貌分类结果, 并针对不同地貌采用不同的颜色进行标记, 进一步划分出大范围内着陆区的各种地貌类型, 确定图像中可着陆区域的具体分布情况。本课题组以小型旋翼无人机在飞行时所观测到的自然地貌图像为研究对象, 对自然地貌图像进行分类, 进而确定无人机可着陆区域。</p>
                </div>
                <div class="p1">
                    <p id="109">以下对含有复杂地貌的图像进行分类实验。图7 (a) 为无人机实拍图像, 图7 (b) 为人工划分的地貌区域图, 图7 (c) 为分块后的图像 (分块大小为32×32) 。将每个图像块输入到训练好的SC-CNN模型中进行特征学习和分类, 得到无人机着陆地貌分类效果图, 如图7 (d) 所示。对图7 (b) 与图7 (d) 进行比较后可以看出, 分块标记的地貌区域与人工划分的区域大致相同。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904014_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 复杂地貌图像的分类效果图。 (a) 地貌图像; (b) 人工地貌划分; (c) 分块后的图像; (d) 地貌分类效果图" src="Detail/GetImg?filename=images/GXXB201904014_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 复杂地貌图像的分类效果图。 (a) 地貌图像; (b) 人工地貌划分; (c) 分块后的图像; (d) 地貌分类效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904014_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Classification effect maps of complex landforms image. (a) Landform image; (b) artificial landform division; (c) post-blocking image; (d) landform classification effect map</p>

                </div>
                <div class="p1">
                    <p id="111">无人机一般选择在平坦、宽阔、安全的着陆点进行野外着陆。在实际生活中, 可安全着陆的地貌有公路、草地、沙地、泥地等, 不可着陆的地貌有水域、建筑物、沼泽、山脉等。当无人机进行着陆场景识别时, 根据得到的分类效果图, 选择安全的着陆区域, 尽量不选择地貌间交汇的区域作为着陆点, 然后把适宜的地貌用特定的颜色进行标识, 无人机可以迅速识别出可着陆的区域, 从而提高了无人机在未知区域着陆的自主性和安全性。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="113">为了提高无人机地貌图像在小样本数据条件下着陆点地貌场景的分类准确率, 以无人机自然地貌图像为研究对象, 本课题组提出了一种基于SC和CNN小样本的地貌场景图像分类算法。首先对训练样本进行非下采样Contourlet变换, 对原图像进行多尺度分解, 并选取前两层分解图像来扩充训练样本集;然后在训练样本中随机选择图像, 利用SC学习局部特征, 对特征向量按照GMG从大到小排序;最后选择GMG较大的特征向量对CNN卷积核进行初始化, 通过特征学习得到全局特征向量, 并将其输入到SVM中得到地貌图像的分类结果。实验结果表明, 采用SC学习到原图像中具有统计特性的特征, 利用该特征对CNN卷积核进行初始化, 可以获得比传统底层视觉特征更好的分类结果, 可以有效避免网络训练陷入局部最优。所提算法综合了高频子带和低频子带对不同地貌场景的识别优势, 在训练样本有限的情况下, 提高了自然地貌场景下无人机着陆地貌的分类准确率, 降低了无人机对外界信息和仪器的依赖性, 增强了无人机的独立自主性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="12">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012538&amp;v=MTIxMzFUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lKbHNjYUJZPU5pZkpaYks5SHRqTXFvOUZaT29OQ1g4eG9CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Hinton G E, Osindero S, Teh Y W.A fast learning algorithm for deep belief nets[J].Neural Computation, 2006, 18 (7) :1527-1554.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going Deeper with Convolutions">

                                <b>[2]</b> Szegedy C, Liu W, Jia Y Q, <i>et al</i>.Going deeper with convolutions[EB/OL]. (2014-09-17) [2018-09-18].https://arxiv.org/abs/1409.4842.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">

                                <b>[3]</b> Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[EB/OL]. (2015-04-10) [2018-09-18].https://arxiv.org/abs/1409.1556v1.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJGD201506007&amp;v=MDczMjk5VE1xWTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk3Z1c3M01KeWZNYXJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Sun Y F, Qi G L, Hu Y L, <i>et al</i>.Deep convolution neural network recognition algorithm based on improved Fisher criterion[J].Journal of Beijing University of Technology, 2015, 41 (6) :835-841.孙艳丰, 齐光磊, 胡永利, 等.基于改进Fisher准则的深度卷积神经网络识别算法[J].北京工业大学学报, 2015, 41 (6) :835-841.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807042&amp;v=MjQxMTQ3Z1c3M01JalhUYkxHNEg5bk1xSTlCWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Zhu M M, Xu Y L, Ma S P, <i>et al</i>.Airport detection method with improved region-based convolutional neural network[J].Acta Optica Sinica, 2018, 38 (7) :0728001.朱明明, 许悦雷, 马时平, 等.改进区域卷积神经网络的机场检测方法[J].光学学报, 2018, 38 (7) :0728001.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning convolutional feature hierarchies for visual recognition">

                                <b>[6]</b> Kavukcuoglu K, Sermanet P, Boureau Y L, <i>et al</i>.Learning convolutional feature hierarchies for visual recognition[C]//Proceedings of 23rd International Conference on Neural Information Processing Systems, December 6-9, 2010, Vancouver, British Columbia, Canada.New York:Curran Associates Inc., 2010:1090-1098.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201604030&amp;v=MjEwMDhIOWZNcTQ5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2dXNzNNTHo3QmQ3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Zhang W D, Xu Y L, Ni J C, <i>et al</i>.Image target recognition method based on multi-scale block convolutional neural network[J].Journal of Computer Applications, 2016, 36 (4) :1033-1038.张文达, 许悦雷, 倪嘉成, 等.基于多尺度分块卷积神经网络的图像目标识别算法[J].计算机应用, 2016, 36 (4) :1033-1038.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201603028&amp;v=MDM5NTc3M01QU25BYXJHNEg5Zk1ySTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk3Z1c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Shi H H, Xu Y L, Ma S P, <i>et al</i>.Convolutional neural networks recognition algorithm based on PCA[J].Journal of Xidian University (Natural Science) , 2016, 43 (3) :161-166.史鹤欢, 许悦雷, 马时平, 等.PCA预训练的卷积神经网络目标识别算法[J].西安电子科技大学学报 (自然科学版) , 2016, 43 (3) :161-166.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201710056&amp;v=MDEwODVMRzRIOWJOcjQ5QVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2dXNzNNTHlyUFo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Chen Y, Fan R S, Wang J X, <i>et al</i>.High resolution image classification method combining with minimum noise fraction rotation and convolution neural network[J].Laser &amp; Optoelectronics Progress, 2017, 54 (10) :102801.陈洋, 范荣双, 王竞雪, 等.结合最小噪声分离变换和卷积神经网络的高分辨影像分类方法[J].激光与光电子学进展, 2017, 54 (10) :102801.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial pyramid co-occurrence for image classification">

                                <b>[10]</b> Yang Y, Newsam S.Spatial pyramid co-occurrence for image classification[C]//Proceedings of International Conference on Computer Vision, November 6-13, 2011, Barcelona, Spain.New York:IEEE, 2011:1465-1472.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201607012&amp;v=MzA1MDg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdnVzczTUppWFRiTEc0SDlmTXFJOUVab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Xu S H, Mu X D, Zhao P, <i>et al</i>.Scene classification of remote sensing image based on multi-scale feature and deep neural network[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (7) :834-840.许夙晖, 慕晓冬, 赵鹏, 等.利用多尺度特征与深度网络对遥感影像进行场景分类[J].测绘学报, 2016, 45 (7) :834-840.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHXB201609011&amp;v=MjUwODJYVGJMRzRIOWZNcG85RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2dXNzNNSmk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> He X F, ZouZ R, Tao C, <i>et al</i>.Combined saliency with multi-convolutional neural network for high resolution remote sensing scene classification[J].Acta Geodaetica et Cartographica Sinica, 2016, 45 (9) :1073-1080.何小飞, 邹峥嵘, 陶超, 等.联合显著性和多层卷积神经网络的高分影像场景分类[J].测绘学报, 2016, 45 (9) :1073-1080.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pyramid of spatial relatons for scene-level land use classification">

                                <b>[13]</b> Chen S Z, Tian Y L.Pyramid of spatial relatons for scene-level land use classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 53 (4) :1947-1957.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PCANet:A simple deep learning baseline for image classification?">

                                <b>[14]</b> Chan T H, Jia K, Gao S H, <i>et al</i>.PCANet:a simple deep learning baseline for image classification[J].IEEE Transactions on Image Processing, 2015, 24 (12) :5017-5032.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201904014" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904014&amp;v=MTA2NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdnVzczTUlqWFRiTEc0SDlqTXE0OUVZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

