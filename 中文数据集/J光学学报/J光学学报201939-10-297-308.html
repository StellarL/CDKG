

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133119394190000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dGXXB201910036%26RESULT%3d1%26SIGN%3dmS9cD9YCn5PhRAE4LQ2TFSdL3VY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910036&amp;v=MzE3NzZxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0JJalhUYkxHNEg5ak5yNDlHWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#44" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="2 理论基础知识 ">2 理论基础知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="&lt;b&gt;2.1 GAN&lt;/b&gt;"><b>2.1 GAN</b></a></li>
                                                <li><a href="#55" data-title="&lt;b&gt;2.2 DCGAN&lt;/b&gt;"><b>2.2 DCGAN</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="3 基于双通道GAN的高光谱图像分类算法的设计 ">3 基于双通道GAN的高光谱图像分类算法的设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="&lt;b&gt;3.1 高光谱图像GAN分类模型&lt;/b&gt;"><b>3.1 高光谱图像GAN分类模型</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;3.2 改进的一维GAN分类框架设计&lt;/b&gt;"><b>3.2 改进的一维GAN分类框架设计</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;3.3 改进的二维GAN分类框架设计&lt;/b&gt;"><b>3.3 改进的二维GAN分类框架设计</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;3.4 双通道GAN分类框架设计&lt;/b&gt;"><b>3.4 双通道GAN分类框架设计</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="4 实验仿真与分析 ">4 实验仿真与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#104" data-title="&lt;b&gt;4.1 Salinas数据集仿真实验&lt;/b&gt;"><b>4.1 Salinas数据集仿真实验</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;4.2 Indian pines数据集仿真实验&lt;/b&gt;"><b>4.2 Indian pines数据集仿真实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#123" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="图1 GAN框架结构">图1 GAN框架结构</a></li>
                                                <li><a href="#59" data-title="图2 DCGAN在LSUN数据集上的结构图">图2 DCGAN在LSUN数据集上的结构图</a></li>
                                                <li><a href="#69" data-title="图3 高光谱图像GAN分类框架">图3 高光谱图像GAN分类框架</a></li>
                                                <li><a href="#78" data-title="表1 改进的一维GAN分类框架">表1 改进的一维GAN分类框架</a></li>
                                                <li><a href="#79" data-title="图4 改进的一维GAN分类结构">图4 改进的一维GAN分类结构</a></li>
                                                <li><a href="#84" data-title="图5 改进的二维GAN分类结构">图5 改进的二维GAN分类结构</a></li>
                                                <li><a href="#85" data-title="表2 改进的二维GAN分类框架">表2 改进的二维GAN分类框架</a></li>
                                                <li><a href="#89" data-title="图6 双通道GAN分类结构">图6 双通道GAN分类结构</a></li>
                                                <li><a href="#106" data-title="图7 Salinas数据集。">图7 Salinas数据集。</a></li>
                                                <li><a href="#108" data-title="表3 Salinas数据集样本表">表3 Salinas数据集样本表</a></li>
                                                <li><a href="#110" data-title="表4 8种算法在Salinas数据集上的分类性能比较">表4 8种算法在Salinas数据集上的分类性能比较</a></li>
                                                <li><a href="#113" data-title="图8 Salinas数据集上8种算法的分类结果。">图8 Salinas数据集上8种算法的分类结果。</a></li>
                                                <li><a href="#116" data-title="图9 Indian pines数据集。">图9 Indian pines数据集。</a></li>
                                                <li><a href="#117" data-title="表5 Indian pines数据集样本表">表5 Indian pines数据集样本表</a></li>
                                                <li><a href="#119" data-title="表6 8种算法在Indian pines数据集上的分类性能比较">表6 8种算法在Indian pines数据集上的分类性能比较</a></li>
                                                <li><a href="#121" data-title="图10 Indian pines数据集上8种算法的分类结果。">图10 Indian pines数据集上8种算法的分类结果。</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" Cui Y,Xu K,Lu Z J,&lt;i&gt;et al&lt;/i&gt;.Combination strategy of active learning for hyperspectral images classification[J].Journal on Communications,2018,39(4):2018067.崔颖,徐凯,陆忠军,等.主动学习策略融合算法在高光谱图像分类中的应用[J].通信学报,2018,39(4):2018067." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201804010&amp;v=MjQ3MTBWdkZ5M2xVTC9BTVRYVGJMRzRIOW5NcTQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Cui Y,Xu K,Lu Z J,&lt;i&gt;et al&lt;/i&gt;.Combination strategy of active learning for hyperspectral images classification[J].Journal on Communications,2018,39(4):2018067.崔颖,徐凯,陆忠军,等.主动学习策略融合算法在高光谱图像分类中的应用[J].通信学报,2018,39(4):2018067.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" Dong A G,Li J X,Zhang B,&lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica,2017,37(8):0828005.董安国,李佳逊,张蓓,等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报,2017,37(8):0828005." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MTc3Nzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5M2xVTC9BSWpYVGJMRzRIOWJNcDQ5Qlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Dong A G,Li J X,Zhang B,&lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica,2017,37(8):0828005.董安国,李佳逊,张蓓,等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报,2017,37(8):0828005.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" Hou B H,Yao M L,Wang R,&lt;i&gt;et al&lt;/i&gt;.Spatial-spectral semi-supervised local discriminant analysis for hyperspectral image classification[J].Acta Optica Sinica,2017,37(7):0728002.侯榜焕,姚敏立,王榕,等.面向高光谱图像分类的空谱半监督局部判别分析[J].光学学报,2017,37(7):0728002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201707038&amp;v=Mjg2MTlBSWpYVGJMRzRIOWJNcUk5R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5M2xVTC8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Hou B H,Yao M L,Wang R,&lt;i&gt;et al&lt;/i&gt;.Spatial-spectral semi-supervised local discriminant analysis for hyperspectral image classification[J].Acta Optica Sinica,2017,37(7):0728002.侯榜焕,姚敏立,王榕,等.面向高光谱图像分类的空谱半监督局部判别分析[J].光学学报,2017,37(7):0728002.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" Yu C Y,Zhao M,Song M P,&lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica,2018,38(6):0628003.于纯妍,赵猛,宋梅萍,等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报,2018,38(6):0628003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806044&amp;v=MzA0OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FJalhUYkxHNEg5bk1xWTlCWUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Yu C Y,Zhao M,Song M P,&lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica,2018,38(6):0628003.于纯妍,赵猛,宋梅萍,等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报,2018,38(6):0628003.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Chen Y S,Jiang H L,Li C Y,&lt;i&gt;et al&lt;/i&gt;.Deep feature extraction and classification of hyperspectral images based on convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(10):6232-6251.</a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     Li Y,Zhang H K,Shen Q.Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network[J].Remote Sensing,2017,9(1):67.</a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" Wu H,Prasad S.Convolutional recurrent neural networks for hyperspectral data classification[J].Remote Sensing,2017,9(3):298." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional Recurrent Neural Networks forHyperspectral Data Classification">
                                        <b>[7]</b>
                                         Wu H,Prasad S.Convolutional recurrent neural networks for hyperspectral data classification[J].Remote Sensing,2017,9(3):298.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" Zhao W Z,Du S H.Spectral-spatial feature extraction for hyperspectral image classification:a dimension reduction and deep learning approach[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(8):4544-4554." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial feature extraction for hyperspectral image classification:a dimension reduction and deep learning approach">
                                        <b>[8]</b>
                                         Zhao W Z,Du S H.Spectral-spatial feature extraction for hyperspectral image classification:a dimension reduction and deep learning approach[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(8):4544-4554.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" Aptoula E,Ozdemir M C,Yanikoglu B.Deep learning with attribute profiles for hyperspectral image classification[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1970-1974." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Learning With Attr ibute Profiles for Hyperspectral Image Classification">
                                        <b>[9]</b>
                                         Aptoula E,Ozdemir M C,Yanikoglu B.Deep learning with attribute profiles for hyperspectral image classification[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1970-1974.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" Zhang H K,Li Y,Jiang Y N.Deep learning for hyperspectral imagery classification:the state of the art and prospects[J].Acta Automatica Sinica,2018,44(6):961-977.张号逵,李映,姜晔楠.深度学习在高光谱图像分类领域的研究现状与展望[J].自动化学报,2018,44(6):961-977." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201806001&amp;v=MjI3NDViRzRIOW5NcVk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5M2xVTC9BS0NMZlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Zhang H K,Li Y,Jiang Y N.Deep learning for hyperspectral imagery classification:the state of the art and prospects[J].Acta Automatica Sinica,2018,44(6):961-977.张号逵,李映,姜晔楠.深度学习在高光谱图像分类领域的研究现状与展望[J].自动化学报,2018,44(6):961-977.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" Goodfellow I J,Pouget-Abadie J,Mirza M,&lt;i&gt;et al&lt;/i&gt;.Generative adversarial nets[C]∥Proceedings of the 27th International Conference on Neural Information Processing Systems,December 8-13,2014,Montreal,Canada.Cambridge,MA,USA:MIT Press,2014,2:2672-2680." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">
                                        <b>[11]</b>
                                         Goodfellow I J,Pouget-Abadie J,Mirza M,&lt;i&gt;et al&lt;/i&gt;.Generative adversarial nets[C]∥Proceedings of the 27th International Conference on Neural Information Processing Systems,December 8-13,2014,Montreal,Canada.Cambridge,MA,USA:MIT Press,2014,2:2672-2680.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" Zhan Y,Hu D,Wang Y T,&lt;i&gt;et al&lt;/i&gt;.Semisupervised hyperspectral image classification based on generative adversarial networks[J].IEEE Geoscience and Remote Sensing Letters,2018,15(2):212-216." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semisupervised hyperspectral image classification based on generative adversarial networks">
                                        <b>[12]</b>
                                         Zhan Y,Hu D,Wang Y T,&lt;i&gt;et al&lt;/i&gt;.Semisupervised hyperspectral image classification based on generative adversarial networks[J].IEEE Geoscience and Remote Sensing Letters,2018,15(2):212-216.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" Zhu L,Chen Y S,Ghamisi P,&lt;i&gt;et al&lt;/i&gt;.Generative adversarial networks for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing,2018,56(9):5046-5063." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial networks for hyperspectral image classification">
                                        <b>[13]</b>
                                         Zhu L,Chen Y S,Ghamisi P,&lt;i&gt;et al&lt;/i&gt;.Generative adversarial networks for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing,2018,56(9):5046-5063.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" Radford A,Metz L,Chintala S.Unsupervised representation learning with deep convolutional generative adversarial networks[J/OL].(2016-01-07)[2019-02-10].https://arxiv.org/abs/1511.06434." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised representation learning with deep convolutional generative adversarial networks">
                                        <b>[14]</b>
                                         Radford A,Metz L,Chintala S.Unsupervised representation learning with deep convolutional generative adversarial networks[J/OL].(2016-01-07)[2019-02-10].https://arxiv.org/abs/1511.06434.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" Yang S S.Research on conditional generative adversarial networks model based on VAE[D].Changchun:Jilin University,2018:26-29.杨韶晟.基于VAE的条件生成式对抗网络模型研究[D].长春:吉林大学,2018:26-29." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018223777.nh&amp;v=Mjc1NjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FWRjI2RnJHNkhkYkxxSkViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Yang S S.Research on conditional generative adversarial networks model based on VAE[D].Changchun:Jilin University,2018:26-29.杨韶晟.基于VAE的条件生成式对抗网络模型研究[D].长春:吉林大学,2018:26-29.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier GANs[C]∥Proceedings of the 34th International Conference on Machine Learning,August 6-11,2017,Sydney,Australis.Massachusetts:JMLR.org,2017:2642-2651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier GANs">
                                        <b>[16]</b>
                                         Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier GANs[C]∥Proceedings of the 34th International Conference on Machine Learning,August 6-11,2017,Sydney,Australis.Massachusetts:JMLR.org,2017:2642-2651.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_17" title=" Ma X R.Hyperspectral imagery classification based on deep learning[D].Dalian:Dalian University of Technology,2017:30-31.马晓瑞.基于深度学习的高光谱影像分类方法研究[D].大连:大连理工大学,2017:30-31." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017035052.nh&amp;v=MjgwOThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FWRjI2R2JPN0c5SEpyWkViUEk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Ma X R.Hyperspectral imagery classification based on deep learning[D].Dalian:Dalian University of Technology,2017:30-31.马晓瑞.基于深度学习的高光谱影像分类方法研究[D].大连:大连理工大学,2017:30-31.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-06-24 17:08</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(10),297-308 DOI:10.3788/AOS201939.1028002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于双通道GAN的高光谱图像分类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AF%95%E6%99%93%E5%90%9B&amp;code=41759249&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">毕晓君</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%B3%BD%E5%AE%87&amp;code=40679661&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周泽宇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%A4%AE%E6%B0%91%E6%97%8F%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0073629&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中央民族大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%93%88%E5%B0%94%E6%BB%A8%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0119964&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">哈尔滨工程大学信息与通信工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对现有高光谱图像生成式对抗网络(GAN)分类算法中存在不能充分提取光谱特征和空谱联合特征而导致高光谱图像分类精度降低的问题,提出一种基于双通道GAN的高光谱图像分类算法。通过搭建改进的一维GAN分类框架和二维GAN分类框架来分别提取完整的光谱特征和空间特征,并将光谱特征和空间特征进行非线性融合形成更为全面的空谱联合特征,最后将其送入到分类器中进行分类。对常用的高光谱图像数据集进行了分析验证,结果表明本文算法得到了最高的分类精度,验证了本文算法的有效性和先进性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA%E8%B0%B1%E8%81%94%E5%90%88%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空谱联合特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成式对抗网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *周泽宇,E-mail:zhouzeyu100@hrbeu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(51779050);</span>
                    </p>
            </div>
                    <h1><b>Hyperspectral Image Classification Algorithm Based on Two-Channel Generative Adversarial Network</b></h1>
                    <h2>
                    <span>Bi Xiaojun</span>
                    <span>Zhou Zeyu</span>
            </h2>
                    <h2>
                    <span>Department of Information Engineering, Minzu University of China</span>
                    <span>College of Information and Communication Engineering, Harbin Engineering University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The existing hyperspectral image generative adversarial network(GAN) classification algorithm cannot fully extract spectral and spatial-spectral features, which leads to the degradation of hyperspectral image classification accuracy. To resolve this issue, this study proposes a hyperspectral image classification algorithm based on a two-channel GAN. Improved one-and two-dimensional GAN classification frameworks are used to extract complete spectral and spatial-spectral features, respectively. Those features are nonlinearly fused to form a more comprehensive spatial-spectral features for classification. The experiments on two commonly used hyperspectral image datasets show that the proposed algorithm achieves the best classification accuracy; further, the results verify the effectiveness and advantages of the proposed algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial-spectral%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial-spectral features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20adversarial%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative adversarial network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-22</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="44" name="44" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="45">高光谱图像分类问题是高光谱遥感图像处理问题中的研究基础,它的主要目的是根据高光谱遥感图像中的光谱信息和空间信息将图像中的每个像元划分为不同的地物类别<citation id="132" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。高光谱图像分类技术被广泛应用于环境监测、矿产勘探、军事目标识别等领域,然而高光谱图像的高维特性、波段间的高度相关性、光谱混合等使得高光谱图像分类面临着巨大的挑战。因此,高光谱图像分类问题越来越受到学者们的广泛关注<citation id="133" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="46">近年来,深度学习在图像处理方面表现出的优势,让高光谱图像分类的研究学者们受到了启发<citation id="139" type="reference"><link href="18" rel="bibliography" /><link href="20" rel="bibliography" /><link href="22" rel="bibliography" /><link href="24" rel="bibliography" /><link href="26" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。深度神经网络(DNN)的研究取得了重大进展,深度神经网络在图像、视频、语音、文本等领域都表现出优异的特征提取能力,目前已经成为计算机视觉、人工智能和机器学习等领域中最为热门的研究方向之一。尽管使用基于深度神经网络的方法在高光谱图像分类中取得了很大进展,但深度神经网络模型需要大量的训练样本来学习网络参数,而高光谱图像分类数据集训练样本有限,因此网络通常会面临过拟合的问题,这意味着网络在训练阶段表现很好,但是在测试阶段的效果很差<citation id="134" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。2014年,Goodfellow教授等<citation id="135" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了生成对抗网络(GAN),该网络可以在很大程度上缓解过拟合的现象,并在小样本训练中获得了很好的效果。2018年,Zhan等<citation id="136" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>首次使用GAN来提取高光谱图像的光谱特征,在小样本数据训练问题中,该方法与深度神经网络相比获得了更好的分类效果,但是该方法的框架是固定的,应用于不同数据集时需要调整框架;此外,该方法没有考虑像元之间的空间相关性,分类精度仍有待提高。同年,Zhu等<citation id="137" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>将深度卷积生成式对抗网络<citation id="138" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation> (DCGAN)引入到高光谱图像分类中,并提出了基于光谱特征的一维生成式对抗网络(1D-GAN)和基于空谱联合特征的三维生成式对抗网络(3D-GAN)分类框架,得到了很好的分类效果,但是该方法由于生成器不能有效地模拟高维数据,所以在提取光谱特征和空谱联合特征时需要大幅度降维处理,这将损失较多的光谱特征和空谱联合特征。</p>
                </div>
                <div class="p1">
                    <p id="47">为此,本文提出一种基于双通道GAN的高光谱图像分类算法。提出改进的一维GAN分类框架,用以提取全部光谱特征,提出改进的二维GAN分类框架,用以提取空间特征;然后结合上述两种框架提出双通道GAN分类框架,采用该框架对光谱特征和空间特征进行融合得到更为全面的空谱联合特征,将该联合特征送入到分类器中进行分类,以提升高光谱图像的分类精度。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">2 理论基础知识</h3>
                <h4 class="anchor-tag" id="49" name="49"><b>2.1 GAN</b></h4>
                <div class="p1">
                    <p id="50">GAN是一种训练生成模型的新方法,也是训练分类器的有效方法。一般情况下,GAN分为两部分:生成器G和判别器D。生成器G用于捕获真实样本的潜在分布进而生成新的数据;判别器D本质上是一个二分类器,用来判别输入的样本是真实的还是虚假的。GAN中的信息传递是从产生假样本的生成器G到判别器D的前馈通道,其目的是为了评估生成器G的输出。GAN的框架结构如图1所示。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 GAN框架结构" src="Detail/GetImg?filename=images/GXXB201910036_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 GAN框架结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 GAN framework structure</p>

                </div>
                <div class="p1">
                    <p id="52">为了通过真实样本<i>x</i>学习生成器G的分布率<i>p</i><sub>g</sub>,假设真实样本的分布率为<i>p</i>(<i>x</i>),输入噪声的分布率为<i>p</i>(<i>z</i>)。生成器G接收一个随机噪声<i>z</i>作为输入,并产生一个映射到数据空间的假样本<i>G</i>(<i>z</i>)。<i>D</i>(<i>x</i>)用于估计来自训练样本的<i>x</i>为真实样本的概率。在优化的过程中,为了使正确标签分给正确样本的概率最大,希望通过训练判别器D使得log[<i>D</i>(<i>x</i>)]最大化;与此同时,训练生成器G使得log{1-<i>D</i>[<i>G</i>(<i>z</i>)]}最小化。因此,本文进行优化的最终目的是求解判别器和生成器的最大最小化问题,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mtext>G</mtext></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mtext>D</mtext></munder><mi>V</mi><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">{</mo><mi>log</mi><mo stretchy="false">[</mo><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>E</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">{</mo><mi>log</mi><mo stretchy="false">{</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">[</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mo stretchy="false">}</mo><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">式中<i>E</i>表示期望。从判别器D的角度来说,它希望能够尽可能地判断出真实样本和生成的假样本,也就是使<i>D</i>(<i>x</i>)尽可能大而<i>D</i>[<i>G</i>(<i>z</i>)]尽可能小,即使<i>V</i>(<i>D</i>,<i>G</i>)尽可能大。而从生成器G的角度来说,它希望自己生成的假样本能够尽可能地接近真实样本,也就是希望<i>D</i>[<i>G</i>(<i>z</i>)]尽可能大而<i>D</i>(<i>x</i>)尽可能小,即使<i>V</i>(<i>D</i>,<i>G</i>)尽可能小。因此,生成器G和判别器D这两个模型在训练过程中不断地相互对抗,最终达到全局最优。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55"><b>2.2 DCGAN</b></h4>
                <div class="p1">
                    <p id="56">DCGAN是对GAN结构的改进模型,它在GAN中引入了CNN的网络拓扑结构,并设置了一系列的限制使其可以进行稳定的训练,因此在很多情况下具备更好的稳定性<citation id="140" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="57">DCGAN在原始GAN上做了以下几点改进:其一,在DCGAN中,将原始GAN所有的池化操作用卷积操作来代替,其中判别器D中的池化层用卷积层来代替,而生成器G中的池化层则用反卷积层来替代,这使得生成器G能够学习它自己的空间上采样,而判别器D可以学习它自己的空间下采样;其二,DCGAN在除了生成器G的输出层和判别器D的输入层外的其他层使用批量标准化操作(BN)来稳定学习,有助于处理初始化不良导致的训练结果差的问题;其三,移除了更深层架构的全连接隐藏层,提升了收敛速度;其四,在生成器G的所有反卷积层上使用ReLU激活函数,只有输出层使用Tanh激活函数;其五,在判别器D的所有卷积层上使用LeakyReLU激活函数。</p>
                </div>
                <div class="p1">
                    <p id="58">图2所示为DCGAN在LSUN数据集情境下的生成器G和判别器D的结构,其中Conv表示卷积,Deconv表示反卷积。在生成器G的结构中,将均匀分布的100维随机噪声<i>z</i>作为输入,<i>z</i>通过投影和重塑之后通过4个反卷积层,最终输出64×64×3大小的图像,而判别器D的结构操作则与生成器G的结构操作相反。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 DCGAN在LSUN数据集上的结构图" src="Detail/GetImg?filename=images/GXXB201910036_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 DCGAN在LSUN数据集上的结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Structural diagram of DCGAN on LSUN dataset</p>

                </div>
                <h3 id="60" name="60" class="anchor-tag">3 基于双通道GAN的高光谱图像分类算法的设计</h3>
                <h4 class="anchor-tag" id="61" name="61"><b>3.1 高光谱图像GAN分类模型</b></h4>
                <div class="p1">
                    <p id="62">高光谱图像GAN分类模型<citation id="141" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>利用了DCGAN的框架,并借鉴了条件标签生成式对抗网络<citation id="142" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>(ACGAN)的思想,引入了ACGAN中的softmax分类器和目标函数,并将其目标函数加以修改来生成适合高光谱图像分类的目标函数。softmax分类器在多分类中表现出很好的性能,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mtext>e</mtext><mtext>x</mtext><mtext>p</mtext></mrow><mspace width="0.25em" /><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mspace width="0.25em" /><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">式中:<i>i</i>=<i>j</i>=1,2,…,<i>n</i>,<i>n</i>为输入张量的维度;<i>x</i><sub><i>i</i></sub>为输入张量第<i>i</i>维的元素;<i>x</i><sub><i>j</i></sub>为输入张量第<i>j</i>维的元素。softmax的主要目的是将输入张量的每个元素缩放到(0,1)区间且使其和为1,从而通过不同幅度的概率值来进行多分类。</p>
                </div>
                <div class="p1">
                    <p id="65">高光谱图像GAN分类模型考虑了真实数据样本的似然概率和正确标签的似然概率,其框架如图3所示。图中,噪声被送到生成器G中,生成器G生成的假数据样本和高光谱真实数据样本被送入到判别器D中,判别器D的输出被分别送入到sigmoid中判别真假和送入到softmax中对数据样本进行分类。</p>
                </div>
                <div class="p1">
                    <p id="66">在高光谱图像GAN分类模型的训练过程中,将噪声<i>z</i>送入到生成器G中,因此生成器G的输出可以定义为</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>a</mtext><mtext>k</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">将真实训练数据样本和由G生成的假数据样本作为判别器D的输入。真实数据样本的概率分布<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>及类别标签上的概率分布<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>被送入判别器D中,其中<i>X</i>表示图像数据。因此,网络的目标函数包括两部分,即正确判别输入数据的对数似然函数<i>L</i><sub><i>S</i></sub>和正确判别标签类别的对数似然函数<i>L</i><sub><i>C</i></sub>,表达式为</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 高光谱图像GAN分类框架" src="Detail/GetImg?filename=images/GXXB201910036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 高光谱图像GAN分类框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 GAN classification framework of hyperspectral image</p>

                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>L</mi><msub><mrow></mrow><mi>S</mi></msub><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>log</mi><mspace width="0.25em" /><mi>Ρ</mi><mo stretchy="false">(</mo><mi>S</mi><mo>=</mo><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mtext>l</mtext><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>E</mi><mo stretchy="false">[</mo><mi>log</mi><mspace width="0.25em" /><mi>Ρ</mi><mo stretchy="false">(</mo><mi>S</mi><mo>=</mo><mtext>f</mtext><mtext>a</mtext><mtext>k</mtext><mtext>e</mtext><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>a</mtext><mtext>k</mtext><mtext>e</mtext></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd columnalign="left"><mi>L</mi><msub><mrow></mrow><mi>C</mi></msub><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>log</mi><mspace width="0.25em" /><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><mo>=</mo><mi>c</mi><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>E</mi><mo stretchy="false">[</mo><mi>log</mi><mspace width="0.25em" /><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><mo>=</mo><mi>c</mi><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>a</mtext><mtext>k</mtext><mtext>e</mtext></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">式中:<i>X</i><sub>real</sub>为真实数据;<i>C</i>为类别;<i>c</i>为第<i>c</i>类;<i>S</i>=real表示当前数据被判别为真实数据,<i>S</i>=fake表示当前数据被判别为生成的假数据。</p>
                </div>
                <div class="p1">
                    <p id="73">在高光谱图像GAN分类框架中,本文的目的是优化判别器D使<i>L</i><sub><i>S</i></sub>+<i>L</i><sub><i>C</i></sub>最大,优化生成器G使<i>L</i><sub><i>C</i></sub>-<i>L</i><sub><i>S</i></sub>最大。</p>
                </div>
                <div class="p1">
                    <p id="74">文献<citation id="143" type="reference">[<a class="sup">13</a>]</citation>中提出的高光谱图像GAN分类模型取得了很好分类的结果,但是由于该方法不能有效地模拟高维数据,所以在提取光谱特征和空谱联合特征时需要降维处理,这将损失较多的光谱特征。为此,本文基于上述方法的思想,通过不断实验,一共设计了三个适用于高光谱图像分类问题的框架,即单独提取全部光谱特征的改进一维GAN分类框架、单独提取空间特征的改进二维GAN分类框架和结合上述两个框架提取空谱联合特征的双通道GAN分类框架。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>3.2 改进的一维GAN分类框架设计</b></h4>
                <div class="p1">
                    <p id="76">改进的一维GAN分类框架借鉴了1D-GAN<citation id="144" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>的结构,在此基础上不断实验,更改了网络结构和参数,搭建了新的网络模型框架,以提取高光谱图像全部的光谱特征。该算法不需要对高光谱数据进行降维预处理,也无需随着高光谱图像数据维度的变化而改变网络结构,可以直接将高光谱图像数据送入到网络中,提取全部的光谱特征。由于高光谱图像数据的维度有几百维,信息高度冗余,生成器G可能难以模拟真实数据,为了使生成器G训练稳定且生成的数据能够更加贴近真实样本,本文使用了DCGAN的结构形式,在判别器D中应用了卷积层,在生成器G中应用了反卷积层,并加深了生成器G和判别器D的网络。</p>
                </div>
                <div class="p1">
                    <p id="77">改进的一维GAN分类算法的框架和结构如表1和图4所示。生成器G中包含了5个反卷积层和一个全连接层,判别器D中包含了7个卷积层。其中<i>a</i>=<i>n</i><sub>nc</sub>/4(向下取整),<i>n</i><sub>nc</sub>为高光谱图像的维度,<i>n</i><sub>nclass</sub>表示图像中包含的地物类别数。生成器G中的全连接层是将生成器G中生成的假数据统一成1×<i>n</i><sub>nc</sub>大小的形式,这样可以保证无论高光谱图像数据的维度怎样变化,生成器G都能生成与其真实样本数据维度一致的假样本数据。在改进的一维GAN分类算法中,首先将1×100维的噪声作为输入送入生成器G中,通过5层反卷积操作和1层全连接操作,得到生成的1×<i>n</i><sub>nc</sub>大小的假数据样本,再将真实数据样本与假数据样本送入到判别器D中,最后,通过7层卷积操作将得到的输出结果作为样本的光谱特征分别送入sigmoid二分类器中(判别真假)和softmax多分类器中(对样本进行分类)。</p>
                </div>
                <div class="area_img" id="78">
                    <p class="img_tit">表1 改进的一维GAN分类框架 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Improved one-dimensional GAN classification framework</p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td>Networks</td><td>Layer</td><td>Operation</td><td>Kernel size</td><td>BN</td><td>Stride</td><td>Padding</td><td>Activation function</td></tr><tr><td rowspan="7"><br />Generator</td><td>1</td><td>Deconv</td><td>1×1×1024</td><td>No</td><td>1</td><td>0</td><td>ReLU</td></tr><tr><td><br />2</td><td>Deconv</td><td>1×1×128×<i>a</i></td><td>Yes</td><td>1</td><td>0</td><td>ReLU</td></tr><tr><td><br />3</td><td>Reshape</td><td>-</td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td><br />4</td><td>Deconv</td><td>4×1×256</td><td>Yes</td><td>2</td><td>1</td><td>ReLU</td></tr><tr><td><br />5</td><td>Deconv</td><td>4×1×64</td><td>Yes</td><td>2</td><td>1</td><td>ReLU</td></tr><tr><td><br />6</td><td>Deconv</td><td>1×1×1</td><td>No</td><td>1</td><td>0</td><td>Tanh</td></tr><tr><td><br />7</td><td>Full</td><td>1×<i>n</i><sub>nc</sub></td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td rowspan="18">Discriminator</td><td><br />1</td><td rowspan="2">Conv</td><td rowspan="2">3×1×32</td><td rowspan="2">No</td><td rowspan="2">1</td><td rowspan="2">1</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />2</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">3×1×64</td><td rowspan="2">No</td><td rowspan="2">1</td><td rowspan="2">0</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />3</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">3×1×128</td><td rowspan="2">No</td><td rowspan="2">2</td><td rowspan="2">1</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />4</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">3×1×256</td><td rowspan="2">No</td><td rowspan="2">1</td><td rowspan="2">0</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />5</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">3×1×128</td><td rowspan="2">No</td><td rowspan="2">1</td><td rowspan="2">0</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />6</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">3×1×32</td><td rowspan="2">No</td><td rowspan="2">2</td><td rowspan="2">1</td><td rowspan="2">LeakyReLU</td></tr><tr><td rowspan="2"><br />7</td></tr><tr><td rowspan="2"><br />Reshape</td><td rowspan="2">-</td><td rowspan="2">No</td><td rowspan="2">-</td><td rowspan="2">-</td><td rowspan="2">No</td></tr><tr><td rowspan="2"><br />8</td></tr><tr><td rowspan="2"><br />Conv</td><td rowspan="2">1×1×1024</td><td rowspan="2">No</td><td rowspan="2">1</td><td rowspan="2">0</td><td rowspan="2">No</td></tr><tr><td rowspan="3"><br />9</td></tr><tr><td><br />Softmax</td><td>1024×<i>n</i><sub>nclass</sub></td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td><br />Sigmoid</td><td>1024×2</td><td>No</td><td>-</td><td>-</td><td>No</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 改进的一维GAN分类结构" src="Detail/GetImg?filename=images/GXXB201910036_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 改进的一维GAN分类结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Improved one-dimensional GAN classification structure</p>

                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>3.3 改进的二维GAN分类框架设计</b></h4>
                <div class="p1">
                    <p id="82">改进的二维GAN分类框架在DCGAN框架的基础上重新进行了搭建,使其能够适用于高光谱图像分类问题,以便更好地提取高光谱图像的空间特征,进而提升高光谱图像分类的精度。本文使用主成分分析(PCA)将高光谱图像降维成三维来提取高光谱图像的空间特征。</p>
                </div>
                <div class="p1">
                    <p id="83">采用改进的二维GAN分类算法设计的框架和结构如图5和表2所示。生成器G包含了5个反卷积层,判别器D包含了5个卷积层。在改进的二维GAN分类算法中,首先将1×100维的噪声送入到生成器G中,经过5个反卷积层后生成假的样本数据,然后将生成的假数据与真实高光谱数据一同送入到判别器D中进行判别,最后,将假样本数据和真实样本数据通过判别器D中的5个卷积层后得到的输出结果作为样本的空间信息特征,将此特征分别送入sigmoid二分类器(进行判别)和softmax多分类器(进行分类)。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 改进的二维GAN分类结构" src="Detail/GetImg?filename=images/GXXB201910036_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 改进的二维GAN分类结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Improved two-dimensional GAN classification structure</p>

                </div>
                <div class="area_img" id="85">
                    <p class="img_tit">表2 改进的二维GAN分类框架 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Improved two-dimensional GAN classification framework</p>
                    <p class="img_note"></p>
                    <table id="85" border="1"><tr><td>Networks</td><td>Layer</td><td>Operation</td><td>Kernel size</td><td>BN</td><td>Stride</td><td>Padding</td><td>Activation function</td></tr><tr><td rowspan="6"><br />Generator</td><td>1</td><td>Deconv</td><td>1×1×1024</td><td>No</td><td>1</td><td>0</td><td>ReLU</td></tr><tr><td><br />2</td><td>Reshape</td><td>-</td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td><br />3</td><td>Deconv</td><td>4×4×128</td><td>Yes</td><td>2</td><td>1</td><td>ReLU</td></tr><tr><td><br />4</td><td>Deconv</td><td>4×4×256</td><td>Yes</td><td>2</td><td>1</td><td>ReLU</td></tr><tr><td><br />5</td><td>Deconv</td><td>4×4×128</td><td>Yes</td><td>2</td><td>1</td><td>ReLU</td></tr><tr><td><br />6</td><td>Deconv</td><td>4×4×3</td><td>No</td><td>2</td><td>1</td><td>Tanh</td></tr><tr><td rowspan="8"><br />Discriminator</td><td><br />1</td><td>Conv</td><td>3×3×32</td><td>No</td><td>2</td><td>1</td><td>LeakyReLU</td></tr><tr><td><br />2</td><td><br />Conv</td><td>3×3×64</td><td>No</td><td>2</td><td>1</td><td>LeakyReLU</td></tr><tr><td><br />3</td><td><br />Conv</td><td>3×3×128</td><td>No</td><td>2</td><td>1</td><td>LeakyReLU</td></tr><tr><td><br />4</td><td><br />Conv</td><td>3×3×64</td><td>No</td><td>2</td><td>1</td><td>LeakyReLU</td></tr><tr><td><br />5</td><td><br />Reshape</td><td>-</td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td><br />6</td><td><br />Conv</td><td>1×1×1024</td><td>No</td><td>1</td><td>0</td><td>No</td></tr><tr><td rowspan="2"><br />7</td><td><br />Softmax</td><td>1024×<i>n</i><sub>nclass</sub></td><td>No</td><td>-</td><td>-</td><td>No</td></tr><tr><td><br />Sigmoid</td><td>1024×2</td><td>No</td><td>-</td><td>-</td><td>No</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>3.4 双通道GAN分类框架设计</b></h4>
                <div class="p1">
                    <p id="87">高光谱图像不仅包含光谱特征也包含空间特征,基于空谱联合特征的分类方法往往比基于单特征的分类方法更为有效<citation id="145" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。因此,为了提取更为全面的光谱特征和空间特征,本文以上述两种模型框架为基础,引入空谱联合特征的思想,设计了如图6所示的双通道GAN分类框架。在这个框架中,首先通过训练改进的一维GAN分类框架提取到光谱特征<i>F</i><sub>1</sub>,将光谱特征通过一个全连接层和一个ReLU非线性激活函数生成具有非线性的光谱特征<i>F</i><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>,再通过训练改进的二维<i>GAN</i>分类框架提取到空间特征F<sub>2</sub>,将空间特征同样送入到一个全连接层和<i>ReLU</i>非线性激活函数中来获取具有非线性的空间特征F<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>,最后将得到的非线性光谱特征F<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>和非线性空间特征F<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>进行叠加生成光谱特征和空间特征融合的空谱联合特征F<sub>3</sub>,并将空谱联合特征F<sub>3</sub>送入到<i>softmax</i>多分类器中进行分类,进而得到了最后的分类结果。空谱联合特征F<sub>3</sub>的表达式为</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mi>F</mi><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup><mo>+</mo><mi>F</mi><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 双通道GAN分类结构" src="Detail/GetImg?filename=images/GXXB201910036_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 双通道GAN分类结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Two-channel GAN classification structure</p>

                </div>
                <h3 id="90" name="90" class="anchor-tag">4 实验仿真与分析</h3>
                <div class="p1">
                    <p id="91">实验仿真采用的是常用于高光谱图像分类的两组数据集,Salinas和Indian pines数据集,这两组数据集都是公开的高光谱基准数据,且包含相对准确的地物覆盖真值,它们的空间和光谱分辨率不同,可以更加全面验证算法的有效性和稳定性,所有数据集将在后续章节中进行详细介绍。为了验证所提算法的有效性和先进性,对比算法采用的是高光谱图像分类算法中的深度卷积分类算法1D-CNN<citation id="146" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、2D-CNN<citation id="147" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、3D-CNN<citation id="148" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和目前效果最好的高光谱GAN分类算法1D-GAN<citation id="149" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>和3D-GAN<citation id="150" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。改进的一维GAN分类框架(以下简称为HS-1D-GAN)的batchsize设置为100,生成器G和判别器D的迭代次数为1000,学习率设置为0.0002。改进的二维GAN分类框架(以下简称HS-2D-GAN)的batchsize设置为50,生成器G和判别器D迭代次数设置为1000,学习率为0.0002。双通道GAN分类框架(以下简称为HS-TC-GAN)的batchsize设置为50,生成器G和判别器D迭代次数设置为1000,后接softmax分类器的迭代次数为200,学习率设置为0.0002。为了公平对比并验证所提算法在小样本量数据集上的有效性,在所有算法实验过程中,对每一个数据集都选取500个样本作为训练集,数据集中的其余样本作为测试集。其他对比算法中的参数都参照相应文献中给出的参数进行实验。在实验中,将测试所有本文提出算法的精度和性能。所有算法均独立运行20次,最终结果是20次实验结果的平均值。</p>
                </div>
                <div class="p1">
                    <p id="92">本文采用常用于评价高光谱图像分类结果的三个精度评价指标来评估所提算法的性能,它们分别是总分类精度(OA)、平均分类精度(AA)和Kappa统计量<citation id="151" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="93">混淆矩阵<i><b>C</b></i>是用于评价分类精度的基本指标,通过将真实地物标签与分类的结果相比较进行计算可得到<i><b>C</b></i>,再根据<i><b>C</b></i>计算出总分类精度、平均分类精度和Kappa统计量。</p>
                </div>
                <div class="p1">
                    <p id="94">总分类精度表示全部测试数据集中被正确分类的样本个数与全部测试集中样本个数之比,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ο</mtext><mtext>A</mtext><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>C</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mi>Ν</mi></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">式中:OA表示总分类精度;<i>K</i>表示类别数;<i>N</i>表示样本总数;<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>C</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></math></mathml>为第<i>i</i>类被正确分类的总个数。</p>
                </div>
                <div class="p1">
                    <p id="97">平均分类精度表示每一个类别分类精度的平均值,其表达式为</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>A</mtext><mtext>A</mtext><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mtext>Ο</mtext></mstyle><mtext>A</mtext><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msub></mrow><mi>Κ</mi></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">式中:AA表示平均分类精度; OA<sub>(</sub><sub><i>i</i></sub><sub>)</sub>表示第<i>i</i>类的总分类精度。</p>
                </div>
                <div class="p1">
                    <p id="100">Kappa系数表示的是一个预测的分类结果与真实结果吻合程度的指标,它在考虑样本被正确分类的同时,也考虑了各种漏分(某些样本没有被分到应属于的类别中)和错分(某类样本被错误地分到其他类别中)的情况,其计算式为</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Κ</mtext><mtext>a</mtext><mtext>p</mtext><mtext>p</mtext><mtext>a</mtext><mo>=</mo><mfrac><mrow><mi>Ν</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>C</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>C</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mo>+</mo><mo stretchy="false">)</mo><mi>C</mi><mo stretchy="false">(</mo><mo>+</mo><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Ν</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>C</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mo>+</mo><mo stretchy="false">)</mo><mi>C</mi><mo stretchy="false">(</mo><mo>+</mo><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">式中<i>C</i>(<i>i</i>,+)和<i>C</i>(+,<i>i</i>)分别表示第<i>i</i>行和第<i>i</i>列的总样本个数。</p>
                </div>
                <div class="p1">
                    <p id="103">本文所有实验的硬件平台采用Inter(R)Core(TM)i7-8700k CPU,3.70 GHz,内存32 GB,GPU为GeForce GTX 1080Ti,软件平台采用python 3.6.6和pytorch 0.4.0。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>4.1 Salinas数据集仿真实验</b></h4>
                <div class="p1">
                    <p id="105">Salinas数据集是1998年由AVIRIS从美国加州萨利纳斯山谷采集得到的,该数据波段为0.4～2.5 μm,原始数据包含了224个波段,其空间分辨率为3.7 m,每个波段的图像大小为 512 pixel×217 pixel,去除第108～第112、第154～第167和第224个水吸收波段后,剩余204个可用的光谱波段。图7显示了Salinas高光谱伪彩色合成图和真实地物参考图,合成图由波段54、31和21合成,该数据集地物分布均匀且空间分辨率较高,覆盖地区为农作物种植区,一共有16个地物类别,其样本数如表3所示。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 Salinas数据集。" src="Detail/GetImg?filename=images/GXXB201910036_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 Salinas数据集。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Salinas dataset. </p>
                                <p class="img_note">(a) 伪彩色合成图;(b) 地物参考图</p>
                                <p class="img_note">(a) Pseudo color composite map; 
(b) feature reference map</p>

                </div>
                <div class="p1">
                    <p id="107">表4给出了1D-CNN、1D-GAN、2D-CNN、3D-CNN、3D-GAN算法和本文提出的三种算法(HS-1D-GAN、HS-2D-GAN和HS-TC-GAN)在Salinas数据集上的分类性能比较。根据表4中的数据进行分析,在基于光谱特征的分类算法中,HS-1D-GAN算法与1D-CNN、1D-GAN算法相比较,得到的三种指标的分类精度最高,与对比算法中表现最好的1D-GAN算法相比,OA、AA和Kappa系数分别提升了3.34%、1.81%和3.71%。在基于空间特征的分类算法中,HS-2D-GAN算法与2D-CNN算法相比较,OA、AA和Kappa系数分别提升了9.31%、7.10%和10.38%。在基于空谱联合特征的分类算法中,HS-TC-GAN算法与3D-CNN和3D-GAN算法相比较,分类精度也最高,与对比算法中表现最好的3D-GAN算法相比,OA、AA和Kappa系数分别提升了6.29%、4.25%和7.00%。这证明了在Salinas数据集中,基于GAN分类算法在使用小样本数据进行训练时,能获得比基于CNN分类算法更高的分类精度;并且与现有的GAN分类算法相比,本文提出的算法表现出更高的分类性能,验证了本文提出的算法的有效性。单独比较本文提出的HS-1D-GAN、HS-2D-GAN和HS-TC-GAN分类算法时,HS-TC-GAN算法的分类精度最高,与HS-1D-GAN算法相比,OA、AA和Kappa系数分别提高了9.45%、5.40%和10.53%,与HS-2D-GAN算法相比,OA、AA和Kappa系数分别提高了2.52%、2.49%和2.81%。这说明在Salinas数据实验中,基于空谱联合特征的双通道GAN分类框架的算法与单独使用光谱特征的分类算法和单独使用空间特征的分类算法相比,能够更为有效地提升分类精度。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit">表3 Salinas数据集样本表 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Salinas dataset sample table</p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td>No.</td><td>Color</td><td>Class</td><td>Sample number</td></tr><tr><td>1</td><td><img src="images\GXXB201910036_152.jpg" /></td><td>Brocoli_green_weeds_1</td><td>1977</td></tr><tr><td><br />2</td><td><img src="images\GXXB201910036_153.jpg" /></td><td>Brocoli_green_weeds_2</td><td>3726</td></tr><tr><td><br />3</td><td><img src="images\GXXB201910036_154.jpg" /></td><td>Fallow</td><td>1976</td></tr><tr><td><br />4</td><td><img src="images\GXXB201910036_155.jpg" /></td><td>Fallow_rough_plow</td><td>1394</td></tr><tr><td><br />5</td><td><img src="images\GXXB201910036_156.jpg" /></td><td>Fallow_smooth</td><td>2678</td></tr><tr><td><br />6</td><td><img src="images\GXXB201910036_157.jpg" /></td><td>Stubble</td><td>3959</td></tr><tr><td><br />7</td><td><img src="images\GXXB201910036_158.jpg" /></td><td>Celery</td><td>3579</td></tr><tr><td><br />8</td><td><img src="images\GXXB201910036_159.jpg" /></td><td>Grapes_untrained</td><td>11213</td></tr><tr><td><br />9</td><td><img src="images\GXXB201910036_160.jpg" /></td><td>Soil_vinyard_develop</td><td>6197</td></tr><tr><td><br />10</td><td><img src="images\GXXB201910036_161.jpg" /></td><td>Corn_senesced_green_weeds</td><td>3249</td></tr><tr><td><br />11</td><td><img src="images\GXXB201910036_162.jpg" /></td><td>Lettuce_romaine_4wk</td><td>1058</td></tr><tr><td><br />12</td><td><img src="images\GXXB201910036_163.jpg" /></td><td>Lettuce_romaine_5wk</td><td>1908</td></tr><tr><td><br />13</td><td><img src="images\GXXB201910036_164.jpg" /></td><td>Lettuce_romaine_6wk</td><td>909</td></tr><tr><td><br />14</td><td><img src="images\GXXB201910036_165.jpg" /></td><td>Lettuce_romaine_7wk</td><td>1061</td></tr><tr><td><br />15</td><td><img src="images\GXXB201910036_166.jpg" /></td><td>Vinyard_untrained</td><td>7164</td></tr><tr><td><br />16</td><td><img src="images\GXXB201910036_167.jpg" /></td><td>Vinyard_vertical_trellis</td><td>1737</td></tr><tr><td colspan="3"><br />Total</td><td>53785</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit">表4 8种算法在Salinas数据集上的分类性能比较 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Comparison of classification performances of eight algorithms on Salinas dataset</p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td><br />Index</td><td>1D-CNN</td><td>1D-GAN</td><td>HS-1D-GAN</td><td>2D-CNN</td><td>HS-2D-GAN</td><td>3D-CNN</td><td>3D-GAN</td><td>HS-TC-GAN</td></tr><tr><td><br />OA /%</td><td>86.12</td><td>86.88</td><td>90.22</td><td>87.84</td><td>97.15</td><td>92.04</td><td>93.38</td><td><b>99.67</b></td></tr><tr><td><br />AA /%</td><td>89.63</td><td>92.24</td><td>94.05</td><td>89.86</td><td>96.96</td><td>94.54</td><td>95.20</td><td><b>99.45</b></td></tr><tr><td><br />Kappa /%</td><td>84.48</td><td>85.39</td><td>89.10</td><td>86.44</td><td>96.82</td><td>91.13</td><td>92.63</td><td><b>99.63</b></td></tr><tr><td><br />Train time /s</td><td><b>8.96</b></td><td>19.67</td><td>120.99</td><td>94.61</td><td>195.60</td><td>211.90</td><td>350.49</td><td>385.27</td></tr><tr><td><br />Test time /s</td><td><b>0.51</b></td><td>0.54</td><td>2.87</td><td>3.95</td><td>2.43</td><td>4.00</td><td>3.48</td><td>5.11</td></tr><tr><td><br />Total time /s</td><td><b>9.47</b></td><td>20.21</td><td>123.86</td><td>98.56</td><td>198.03</td><td>215.90</td><td>353.97</td><td>390.38</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="111">在Salinas数据集实验中,将算法的训练时间、测试时间和总时间作对比,在比较基于GAN的分类算法和基于CNN的分类算法时,由于GAN需要生成器G和判别器D两个网络一起训练,网络相较CNN复杂,所需参数量更多,所以在基于深度学习的算法中,CNN的训练时间较短。在基于GAN的各类算法中,由于卷积核的选取,网络层数搭建的深度及分别提取光谱特征、空间特征和空谱联合特征所需计算量不同等因素,各类GAN的训练时间也有所不同,其中HS-TC-GAN算法由于有两个通道,相当于两个GAN网络框架,且需要提取空谱联合特征,因此,其训练时间最长,在基于深度学习的算法中测试时间也最长;而1D-CNN算法的网络结构最为简单,仅需对光谱特征进行处理,所以在基于深度学习的分类算法中训练时间最短,在所有算法中测试时间最短。</p>
                </div>
                <div class="p1">
                    <p id="112">图8给出了8种算法在Salinas数据集上的图像分类结果。从视觉直观来看,在基于光谱特征的分类算法中,HS-1D-GAN算法与1D-CNN、1D-GAN算法相比较,HS-1D-GAN算法中同种地物错分的情况要更少。在基于空间特征的分类算法中,HS-2D-GAN算法与2D-CNN算法相比较,HS-2D-GAN算法的分类视觉效果更好一些,如左上角紫色对应地物的分类,HS-2D-GAN算法显然比2D-CNN算法更为准确,紫色区域的分类效果更好。在基于空谱联合特征的分类算法中,HS-TC-GAN算法与3D-CNN和3D-GAN算法相比较,HS-TC-GAN算法的分类结果几乎接近了真实地物参考图,而3D-CNN和3D-GAN算法仍存在明显的错分情况。比较本文提出的HS-1D-GAN、HS-2D-GAN和HS-TC-GAN分类算法可知,HS-TC-GAN分类算法的分类结果具有最好的视觉效果,说明在Salinas数据实验中,基于空谱联合特征的双通道GAN分类方法的效果要比单独利用光谱特征和单独利用空间特征的分类效果更好。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 Salinas数据集上8种算法的分类结果。" src="Detail/GetImg?filename=images/GXXB201910036_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 Salinas数据集上8种算法的分类结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Classification results of the eight algorithms on the Salinas dataset. </p>
                                <p class="img_note">(a) 真实地物参考图; (b) 1D-CNN; (c) 1D-GAN; (d) HS-1D-GAN; 
(e) 2D-CNN; (f) HS-2D-GAN; (g) 3D-CNN; (h) 3D-GAN; (i) HS-TC-GAN</p>
                                <p class="img_note">(a) Real feature reference map; (b) 1D-CNN; 
(c) 1D-GAN; (d) HS-1D-GAN; (e) 2D-CNN; (f) HS-2D-GAN; (g) 3D-CNN; (h) 3D-GAN; (i) HS-TC-GAN</p>

                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>4.2 Indian pines数据集仿真实验</b></h4>
                <div class="p1">
                    <p id="115">Indian pines数据集由AVIRIS于1992年采集于美国印第安州西北部普渡大学农场,该数据集波段为0.4～2.5 μm,其原始数据包含了220个通道,空间分辨率为20 m,图像大小为145 pixel×145 pixel。去除第104～第108,第150～第163及第220个水吸收波段后,剩余200个可用波段。图9显示了该高光谱的伪彩色合成图和真实地物参考图,该合成图是由波段50、27及17合成的。该数据集共有16类地物,表5为Indian pines数据集样本表。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 Indian pines数据集。" src="Detail/GetImg?filename=images/GXXB201910036_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 Indian pines数据集。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Indian pines dataset.</p>
                                <p class="img_note">(a) 伪彩色合成图;
(b) 地物参考图</p>
                                <p class="img_note">(a) Pseudo color composite map;
(b) feature reference map</p>

                </div>
                <div class="area_img" id="117">
                    <p class="img_tit">表5 Indian pines数据集样本表 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Indian pines dataset sample table</p>
                    <p class="img_note"></p>
                    <table id="117" border="1"><tr><td>No.</td><td>Color</td><td>Class</td><td>Sample number</td></tr><tr><td>1</td><td><img src="images\GXXB201910036_168.jpg" /></td><td>Alfalfa</td><td>46</td></tr><tr><td><br />2</td><td><img src="images\GXXB201910036_169.jpg" /></td><td>Corn-notill</td><td>1428</td></tr><tr><td><br />3</td><td><img src="images\GXXB201910036_170.jpg" /></td><td>Corn-min</td><td>830</td></tr><tr><td><br />4</td><td><img src="images\GXXB201910036_171.jpg" /></td><td>Corn</td><td>237</td></tr><tr><td><br />5</td><td><img src="images\GXXB201910036_172.jpg" /></td><td>Grass-pasture</td><td>483</td></tr><tr><td><br />6</td><td><img src="images\GXXB201910036_173.jpg" /></td><td>Grass-trees</td><td>730</td></tr><tr><td><br />7</td><td><img src="images\GXXB201910036_174.jpg" /></td><td>Grass-pasture-mowed</td><td>28</td></tr><tr><td><br />8</td><td><img src="images\GXXB201910036_175.jpg" /></td><td>Hay-windrowed</td><td>478</td></tr><tr><td><br />9</td><td><img src="images\GXXB201910036_176.jpg" /></td><td>Oats</td><td>20</td></tr><tr><td><br />10</td><td><img src="images\GXXB201910036_177.jpg" /></td><td>Soybean-notill</td><td>972</td></tr><tr><td><br />11</td><td><img src="images\GXXB201910036_178.jpg" /></td><td>Soybean-mintill</td><td>2455</td></tr><tr><td><br />12</td><td><img src="images\GXXB201910036_179.jpg" /></td><td>Soybean-clean</td><td>593</td></tr><tr><td><br />13</td><td><img src="images\GXXB201910036_180.jpg" /></td><td>Wheat</td><td>205</td></tr><tr><td><br />14</td><td><img src="images\GXXB201910036_181.jpg" /></td><td>Woods</td><td>1265</td></tr><tr><td><br />15</td><td><img src="images\GXXB201910036_182.jpg" /></td><td>Buildings-Grass-Trees</td><td>386</td></tr><tr><td><br />16</td><td><img src="images\GXXB201910036_183.jpg" /></td><td>Stone-Steel-Towers</td><td>93</td></tr><tr><td colspan="3"><br />Total</td><td>10249</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="118">表6给出了1D-CNN、1D-GAN、2D-CNN、3D-CNN、3D-GAN算法和本文提出的三种算法在Indian pines数据集上的分类性能比较。根据表6中的数据进行分析,在基于光谱特征的分类算法中,HS-1D-GAN算法与1D-CNN、1D-GAN算法相比较,HS-1D-GAN算法获得了最高的分类精度(与1D-GAN相比,OA、AA和Kappa系数分别提升了4.98%、4.34%和5.88%)。在基于空间特征的分类算法中,HS-2D-GAN算法与2D-CNN算法相比较,HS-2D-GAN算法的OA、AA和Kappa系数分别提升了1.98%、6.25%和2.28%。在基于空谱联合特征的分类算法中,HS-TC-GAN算法与3D-CNN和3D-GAN算法相比,HS-TC-GAN算法的分类精度最高(与3D-GAN算法相比,OA、AA和Kappa系数分别提升了6.40%、10.72%和7.31%)。这证明了在Indian pines数据集中,基于GAN分类算法在小训练样本的情况下也获得了比基于CNN分类算法更高的分类精度,并且本文提出的算法与现有的1D-GAN、3D-GAN算法相比同样获得了更高的分类精度。单独比较HS-1D-GAN、HS-2D-GAN和HS-TC-GAN分类算法后可知,HS-TC-GAN算法获得了最好的分类结果,HS-TC-GAN算法比HS-1D-GAN算法的OA、AA和Kappa系数分别提高了30.84%、37.24%和35.41%,HS-TC-GAN算法比HS-2D-GAN算法的OA、AA和Kappa系数分别提高了5.38%、6.40%和6.13%。在Indian pines数据集上比较各类算法的训练时间、测试时间和总时间后可知, 1D-CNN算法的测试时间、训练时间和总时间最短。</p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit">表6 8种算法在Indian pines数据集上的分类性能比较 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 6 Comparison of classification performances of eight algorithms on Indian pines dataset</p>
                    <p class="img_note"></p>
                    <table id="119" border="1"><tr><td><br />Index</td><td>1D-CNN</td><td>1D-GAN</td><td>HS-1D-GAN</td><td>2D-CNN</td><td>HS-2D-GAN</td><td>3D-CNN</td><td>3D-GAN</td><td>HS-TC-GAN</td></tr><tr><td><br />OA /%</td><td>62.55</td><td>63.92</td><td>68.90</td><td>92.38</td><td>94.36</td><td>92.50</td><td>93.34</td><td><b>99.74</b></td></tr><tr><td><br />AA /%</td><td>53.29</td><td>55.94</td><td>60.28</td><td>84.87</td><td>91.12</td><td>89.78</td><td>86.80</td><td><b>97.52</b></td></tr><tr><td><br />Kappa /%</td><td>56.51</td><td>58.41</td><td>64.29</td><td>91.29</td><td>93.57</td><td>91.44</td><td>92.39</td><td><b>99.70</b></td></tr><tr><td><br />Train time /s</td><td><b>9.06</b></td><td>19.46</td><td>122.06</td><td>92.36</td><td>194.33</td><td>201.48</td><td>333.63</td><td>386.05</td></tr><tr><td><br />Test time /s</td><td><b>0.13</b></td><td>0.13</td><td>1.96</td><td>0.84</td><td>0.55</td><td>0.93</td><td>0.72</td><td>2.07</td></tr><tr><td><br />Total time /s</td><td><b>9.19</b></td><td>19.59</td><td>124.02</td><td>93.20</td><td>194.88</td><td>202.41</td><td>334.39</td><td>388.12</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="120">图10给出了本文3种算法和其他5种对比算法在Indian pines数据集上的图像分类结果。在基于光谱特征的分类算法中,HS-1D-GAN算法与1D-CNN、1D-GAN算法得到的分类图像相比,三种算法的错分都很严重,但是仔细观察得到的分类图像(如图像的左上角)可知,HS-1D-GAN算法的分类结果更贴近真实地物分类结果。在基于空间特征的分类算法中, HS-2D-GAN算法的分类结果显然比2D-CNN算法的分类结果更贴近于真实地物图像。在基于空谱联合特征的分类算法中,与3D-CNN和3D-GAN算法相比,HS-TC-GAN算法的分类结果几乎与真实地物图像一致,仅有少数几个错分的点,而3D-CNN和3D-GAN两种算法虽然与真实地物较为相近,但是可以明显地看出错分的情况较多。同样,单独比较本文提出的三种分类算法后可知,HS-TC-GAN分类算法的分类结果从视觉角度观察是最好的,这说明在对Indian pines数据进行实验时,利用空谱联合特征的结果有助于提升分类精度和视觉效果。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910036_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 Indian pines数据集上8种算法的分类结果。" src="Detail/GetImg?filename=images/GXXB201910036_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 Indian pines数据集上8种算法的分类结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910036_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Classification results of the eight algorithms on the Indian pines dataset. </p>
                                <p class="img_note">(a) 真实地物参考图; (b) 1D-CNN; (c) 1D-GAN; 
(d) HS-1D-GAN; (e) 2D-CNN; (f) HS-2D-GAN; (g) 3D-CNN; (h) 3D-GAN; (i) HS-TC-GAN</p>
                                <p class="img_note">(a) Real feature reference map; 
(b) 1D-CNN; (c) 1D-GAN; (d) HS-1D-GAN; (e) 2D-CNN; (f) HS-2D-GAN; (g) 3D-CNN; (h) 3D-GAN; (i) HS-TC-GAN</p>

                </div>
                <h3 id="123" name="123" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="124">针对现有高光谱图像GAN分类算法提取光谱特征和空谱联合特征不全面而导致的分类精度不高的问题,提出了基于双通道GAN的高光谱图像分类算法。首先,提出了改进的一维GAN分类框架和改进的二维GAN分类框架,并采用这两个框架分别提取高光谱图像全部的光谱特征和空间特征;其次,结合上述两种框架搭建双通道GAN分类框架,采用该框架将得到的光谱特征和空间特征进行融合,并利用得到的空谱联合特征进行高光谱图像分类。实验结果表明,与其他算法相比,本文算法获得了最高的分类精度,证明了本文算法对小样本训练有效的同时,也说明了本文算法对光谱特征和空谱联合特征的提取较现有的高光谱图像GAN分类算法更为全面,高光谱图像的分类精度大幅度提升,验证了本文算法的先进性和有效性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201804010&amp;v=MjA2MTE0TzN6cXFCdEdGckNVUkxPZVplVnZGeTNsVUwvQU1UWFRiTEc0SDluTXE0OUVaSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Cui Y,Xu K,Lu Z J,<i>et al</i>.Combination strategy of active learning for hyperspectral images classification[J].Journal on Communications,2018,39(4):2018067.崔颖,徐凯,陆忠军,等.主动学习策略融合算法在高光谱图像分类中的应用[J].通信学报,2018,39(4):2018067.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MjUzNzgvQUlqWFRiTEc0SDliTXA0OUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTNsVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Dong A G,Li J X,Zhang B,<i>et al</i>.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica,2017,37(8):0828005.董安国,李佳逊,张蓓,等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报,2017,37(8):0828005.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201707038&amp;v=MjI3MzVsVUwvQUlqWFRiTEc0SDliTXFJOUdiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Hou B H,Yao M L,Wang R,<i>et al</i>.Spatial-spectral semi-supervised local discriminant analysis for hyperspectral image classification[J].Acta Optica Sinica,2017,37(7):0728002.侯榜焕,姚敏立,王榕,等.面向高光谱图像分类的空谱半监督局部判别分析[J].光学学报,2017,37(7):0728002.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806044&amp;v=MDUyNzN5M2xVTC9BSWpYVGJMRzRIOW5NcVk5QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Yu C Y,Zhao M,Song M P,<i>et al</i>.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica,2018,38(6):0628003.于纯妍,赵猛,宋梅萍,等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报,2018,38(6):0628003.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Chen Y S,Jiang H L,Li C Y,<i>et al</i>.Deep feature extraction and classification of hyperspectral images based on convolutional neural networks[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(10):6232-6251.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 Li Y,Zhang H K,Shen Q.Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network[J].Remote Sensing,2017,9(1):67.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional Recurrent Neural Networks forHyperspectral Data Classification">

                                <b>[7]</b> Wu H,Prasad S.Convolutional recurrent neural networks for hyperspectral data classification[J].Remote Sensing,2017,9(3):298.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial feature extraction for hyperspectral image classification:a dimension reduction and deep learning approach">

                                <b>[8]</b> Zhao W Z,Du S H.Spectral-spatial feature extraction for hyperspectral image classification:a dimension reduction and deep learning approach[J].IEEE Transactions on Geoscience and Remote Sensing,2016,54(8):4544-4554.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Learning With Attr ibute Profiles for Hyperspectral Image Classification">

                                <b>[9]</b> Aptoula E,Ozdemir M C,Yanikoglu B.Deep learning with attribute profiles for hyperspectral image classification[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1970-1974.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201806001&amp;v=MjMxNjNmWWJHNEg5bk1xWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FLQ0w=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Zhang H K,Li Y,Jiang Y N.Deep learning for hyperspectral imagery classification:the state of the art and prospects[J].Acta Automatica Sinica,2018,44(6):961-977.张号逵,李映,姜晔楠.深度学习在高光谱图像分类领域的研究现状与展望[J].自动化学报,2018,44(6):961-977.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">

                                <b>[11]</b> Goodfellow I J,Pouget-Abadie J,Mirza M,<i>et al</i>.Generative adversarial nets[C]∥Proceedings of the 27th International Conference on Neural Information Processing Systems,December 8-13,2014,Montreal,Canada.Cambridge,MA,USA:MIT Press,2014,2:2672-2680.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semisupervised hyperspectral image classification based on generative adversarial networks">

                                <b>[12]</b> Zhan Y,Hu D,Wang Y T,<i>et al</i>.Semisupervised hyperspectral image classification based on generative adversarial networks[J].IEEE Geoscience and Remote Sensing Letters,2018,15(2):212-216.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial networks for hyperspectral image classification">

                                <b>[13]</b> Zhu L,Chen Y S,Ghamisi P,<i>et al</i>.Generative adversarial networks for hyperspectral image classification[J].IEEE Transactions on Geoscience and Remote Sensing,2018,56(9):5046-5063.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised representation learning with deep convolutional generative adversarial networks">

                                <b>[14]</b> Radford A,Metz L,Chintala S.Unsupervised representation learning with deep convolutional generative adversarial networks[J/OL].(2016-01-07)[2019-02-10].https://arxiv.org/abs/1511.06434.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018223777.nh&amp;v=MjgxNjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FWRjI2RnJHNkhkYkxxSkViUElRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Yang S S.Research on conditional generative adversarial networks model based on VAE[D].Changchun:Jilin University,2018:26-29.杨韶晟.基于VAE的条件生成式对抗网络模型研究[D].长春:吉林大学,2018:26-29.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier GANs">

                                <b>[16]</b> Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier GANs[C]∥Proceedings of the 34th International Conference on Machine Learning,August 6-11,2017,Sydney,Australis.Massachusetts:JMLR.org,2017:2642-2651.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017035052.nh&amp;v=MjA3MzMzenFxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0FWRjI2R2JPN0c5SEpyWkViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Ma X R.Hyperspectral imagery classification based on deep learning[D].Dalian:Dalian University of Technology,2017:30-31.马晓瑞.基于深度学习的高光谱影像分类方法研究[D].大连:大连理工大学,2017:30-31.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201910036" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910036&amp;v=MzE3NzZxQnRHRnJDVVJMT2VaZVZ2RnkzbFVML0JJalhUYkxHNEg5ak5yNDlHWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01EbTY1YWlNVTlZaDFrek84dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

