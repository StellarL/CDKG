

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134008198877500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905016%26RESULT%3d1%26SIGN%3dLnBPa0zmBVj6x5%252fMybugVJX%252fdO8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905016&amp;v=MTI0MDNVUkxPZVplVnVGeTNoVWIzQklqWFRiTEc0SDlqTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#8" data-title="2 LRF构建原理 ">2 LRF构建原理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#22" data-title="3 鼻尖点定位 ">3 鼻尖点定位</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#24" data-title="3.1 人脸矢量场构建">3.1 人脸矢量场构建</a></li>
                                                <li><a href="#30" data-title="3.2 基于LRFE特征的候选点筛选">3.2 基于LRFE特征的候选点筛选</a></li>
                                                <li><a href="#49" data-title="3.3 LRFE特征的旋转不变性">3.3 LRFE特征的旋转不变性</a></li>
                                                <li><a href="#66" data-title="3.4 对鼻尖点的精确定位">3.4 对鼻尖点的精确定位</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="4 结果与分析 ">4 结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="4.1 人脸数据库描述">4.1 人脸数据库描述</a></li>
                                                <li><a href="#81" data-title="4.2 算法指标">4.2 算法指标</a></li>
                                                <li><a href="#88" data-title="4.3 算法实时性检测">4.3 算法实时性检测</a></li>
                                                <li><a href="#98" data-title="4.4 对姿态稳健性的验证">4.4 对姿态稳健性的验证</a></li>
                                                <li><a href="#102" data-title="4.5 算法准确率的验证">4.5 算法准确率的验证</a></li>
                                                <li><a href="#105" data-title="4.6 实际场景中检测">4.6 实际场景中检测</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="5 结论 ">5 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="图1 人脸法向量分布。 (a) 法向量计算; (b) 人脸三维 (3D) 矢量场">图1 人脸法向量分布。 (a) 法向量计算; (b) 人脸三维 (3D) 矢量场</a></li>
                                                <li><a href="#38" data-title="图2 LRFE特征提取">图2 LRFE特征提取</a></li>
                                                <li><a href="#48" data-title="图3 基于LRFE算法的人脸鼻尖点迭代筛选">图3 基于LRFE算法的人脸鼻尖点迭代筛选</a></li>
                                                <li><a href="#51" data-title="图4 人脸旋转方向示意图">图4 人脸旋转方向示意图</a></li>
                                                <li><a href="#68" data-title="图5 散度能量图。 (a) 矢量场膨胀与收缩; (b) 曲面散度能量图; (c) 人脸散度能量图">图5 散度能量图。 (a) 矢量场膨胀与收缩; (b) 曲面散度能量图; (c) 人脸散度能量图</a></li>
                                                <li><a href="#90" data-title="图6 用LRFE算法对不同对象的定位结果">图6 用LRFE算法对不同对象的定位结果</a></li>
                                                <li><a href="#91" data-title="图7 迭代次数与候选点数量的关系曲线">图7 迭代次数与候选点数量的关系曲线</a></li>
                                                <li><a href="#93" data-title="图8 迭代次数与算法耗时的关系曲线">图8 迭代次数与算法耗时的关系曲线</a></li>
                                                <li><a href="#97" data-title="表1 所提方法与现有方法的耗时比较">表1 所提方法与现有方法的耗时比较</a></li>
                                                <li><a href="#100" data-title="图9 Bosphorus库中的姿态变化">图9 Bosphorus库中的姿态变化</a></li>
                                                <li><a href="#101" data-title="图1 0 N、YR30、YR45、PR、YR90类别的定位准确率">图1 0 N、YR30、YR45、PR、YR90类别的定位准确率</a></li>
                                                <li><a href="#104" data-title="表2 所提方法与现有方法的误差对比">表2 所提方法与现有方法的误差对比</a></li>
                                                <li><a href="#110" data-title="表3 实际环境下的检测结果">表3 实际环境下的检测结果</a></li>
                                                <li><a href="#111" data-title="图1 1 实际场景鼻尖定位。 (a) 形状指数分布; (b) 散度分布; (c) 候选点; (d) 定位结果">图1 1 实际场景鼻尖定位。 (a) 形状指数分布; (b) 散度分布; (c) 候选点; (d) ......</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="114">


                                    <a id="bibliography_1" title="Wang Y M, Liu J Z, Tang X O.Robust 3Dface recognition by local shape difference boosting[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (10) :1858-1870." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust 3D Face Recognition by Local Shape Difference Boosting">
                                        <b>[1]</b>
                                        Wang Y M, Liu J Z, Tang X O.Robust 3Dface recognition by local shape difference boosting[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (10) :1858-1870.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_2" title="Chang K I, Bowyer K W, Flynn P J.Multimodal 2Dand 3D biometrics for face recognition[C]//2003IEEE International SOI Conference.Proceedings (Cat.no.03CH37443) , 17-17 Oct.2003, Nice, France, 2003:187-194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multimodal 2Dand 3D biometrics for face recognition">
                                        <b>[2]</b>
                                        Chang K I, Bowyer K W, Flynn P J.Multimodal 2Dand 3D biometrics for face recognition[C]//2003IEEE International SOI Conference.Proceedings (Cat.no.03CH37443) , 17-17 Oct.2003, Nice, France, 2003:187-194.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_3" title="Xu C H, Tan T N, Wang Y H, et al.Combining local features for robust nose location in 3Dfacial data[J].Pattern Recognition Letters, 2006, 27 (13) :1487-1494." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414780&amp;v=MjQ5NzNPb0xDM1E1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSlZvV2FCcz1OaWZPZmJLN0h0RE9ySTlGWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Xu C H, Tan T N, Wang Y H, et al.Combining local features for robust nose location in 3Dfacial data[J].Pattern Recognition Letters, 2006, 27 (13) :1487-1494.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_4" title="Nguyen D H, Na J, Yi J.Nose tip detection from 3Dfacial mesh data using a rotationally invariant local shape descriptor[C]//2012 5th IAPR International Conference on Biometrics (ICB) , 29 March-1 April2012, New Delhi, India, 2012:91-96." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nose tip detection from 3Dfacial mesh data using a rotationally invariant local shape descriptor">
                                        <b>[4]</b>
                                        Nguyen D H, Na J, Yi J.Nose tip detection from 3Dfacial mesh data using a rotationally invariant local shape descriptor[C]//2012 5th IAPR International Conference on Biometrics (ICB) , 29 March-1 April2012, New Delhi, India, 2012:91-96.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_5" title="Liu J, Zhang Q, Zhang C, et al.Robust nose tip detection for face range images based on local features in scale-space[C]//2015International Conference on3D Imaging (IC3D) , 14-15 Dec.2015, Liege, Belgium, 2015:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust nose tip detection for face range images based on local features in scale-space">
                                        <b>[5]</b>
                                        Liu J, Zhang Q, Zhang C, et al.Robust nose tip detection for face range images based on local features in scale-space[C]//2015International Conference on3D Imaging (IC3D) , 14-15 Dec.2015, Liege, Belgium, 2015:1-8.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_6" title="ter Haar F B, Veltkamp R C.A 3Dface matching framework for facial curves[J].Graphical Models, 2009, 71 (2) :77-91." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300445028&amp;v=MDc5NjhySTlGWU84S0RINHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lKVm9XYUJzPU5pZk9mYks3SHRETg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        ter Haar F B, Veltkamp R C.A 3Dface matching framework for facial curves[J].Graphical Models, 2009, 71 (2) :77-91.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_7" title="Liu R, Hu R, Yu H M.Nose detection on 3Dface images by depth-based template matching[C]//20147th International Congress on Image and Signal Processing, 14-16 Oct.2014, Dalian, China, 2014:302-307." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nose detection on 3D face images by depth-based template matching">
                                        <b>[7]</b>
                                        Liu R, Hu R, Yu H M.Nose detection on 3Dface images by depth-based template matching[C]//20147th International Congress on Image and Signal Processing, 14-16 Oct.2014, Dalian, China, 2014:302-307.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_8" title="Cai Y, Huang Y J, Zhang S G.A method for nose tip location and head pose estimation in 3D face data[C]//International Conference on Automatic Control and Artificial Intelligence, IET, 2013:115-118." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A method for nose tip location and head pose estimation in 3D face data">
                                        <b>[8]</b>
                                        Cai Y, Huang Y J, Zhang S G.A method for nose tip location and head pose estimation in 3D face data[C]//International Conference on Automatic Control and Artificial Intelligence, IET, 2013:115-118.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_9" title="Colombo A, Cusano C, Schettini R.3Dface detection using curvature analysis[J].Pattern Recognition, 2006, 39 (3) :444-455." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739946&amp;v=MTAyOTBnL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpWb1dhQnM9TmlmT2ZiSzdIdEROcVk5RlkrZ0dCWA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Colombo A, Cusano C, Schettini R.3Dface detection using curvature analysis[J].Pattern Recognition, 2006, 39 (3) :444-455.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_10" title="Chang K I, Bowyer K W, Flynn P J.Multiple nose region matching for 3Dface recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple Nose Region Matching for 3D Face Recognition under Varying Facial Expression">
                                        <b>[10]</b>
                                        Chang K I, Bowyer K W, Flynn P J.Multiple nose region matching for 3Dface recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_11" title="Li Y, Wang B B, Sui L S, et al.Nose tip detection on three-dimensional faces using pose-invariant differential surface features[J].IET Computer Vision, 2015, 9 (1) :75-84." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nose tip detection on threedimensional faces using pose-invariant differential surface features">
                                        <b>[11]</b>
                                        Li Y, Wang B B, Sui L S, et al.Nose tip detection on three-dimensional faces using pose-invariant differential surface features[J].IET Computer Vision, 2015, 9 (1) :75-84.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_12" title="Pan L Q, Xu H L, Wei Y, et al.Nose tip location based on the corner detection of face silhouette[J].Computer Engineering and Applications, 2018, 54 (13) :191-195.潘腊青, 徐海黎, 韦勇, 等.基于人脸侧影线角点检测的鼻尖点定位方法[J].计算机工程与应用, 2018, 54 (13) :191-195." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813030&amp;v=MjcyMTZxQnRHRnJDVVJMT2VaZVZ1RnkzaFViM0JMejdNYWJHNEg5bk5ySTlHWklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Pan L Q, Xu H L, Wei Y, et al.Nose tip location based on the corner detection of face silhouette[J].Computer Engineering and Applications, 2018, 54 (13) :191-195.潘腊青, 徐海黎, 韦勇, 等.基于人脸侧影线角点检测的鼻尖点定位方法[J].计算机工程与应用, 2018, 54 (13) :191-195.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_13" title="Guo Y L, Sohel F, Bennamoun M, et al.Rotational projection statistics for 3Dlocal surface description and object recognition[J].International Journal of Computer Vision, 2013, 105 (1) :63-86." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13081300000476&amp;v=MjU1NzU3SHRuTnJJOUZaT3NQQ0hzL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpWb1dhQnM9Tmo3QmFySw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Guo Y L, Sohel F, Bennamoun M, et al.Rotational projection statistics for 3Dlocal surface description and object recognition[J].International Journal of Computer Vision, 2013, 105 (1) :63-86.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_14" title="Shah S A A, Bennamoun M, Boussaid F.A novel feature representation for automatic 3D object recognition in cluttered scenes[J].Neurocomputing, 2016, 205:1-15." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1F06DC8A440984412ED80029E66ADFD2&amp;v=Mjg1NDV4Y1JuMHQxU0gvZ3BXY3pmOFBnTTg2ZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHdieTl3cUU9TmlmT2ZiTE9IdGU0M0ljMFlPOFBCWFE5eQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Shah S A A, Bennamoun M, Boussaid F.A novel feature representation for automatic 3D object recognition in cluttered scenes[J].Neurocomputing, 2016, 205:1-15.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_15" title="Perakis P, Passalis G, Theoharis T, et al.3Dfacial landmark detection under large yaw and expression variations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (7) :1552-1564." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D facial landmark detection under large yaw and expression variations">
                                        <b>[15]</b>
                                        Perakis P, Passalis G, Theoharis T, et al.3Dfacial landmark detection under large yaw and expression variations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (7) :1552-1564.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_16" title="Shah S A A, Bennamoun M, Boussaid F.Automatic3Dface landmark localization based on 3Dvector field analysis[C]//2015International Conference on Image and Vision Computing New Zealand (IVCNZ) , 23-24Nov.2015, Auckland, New Zealand, 2015:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic3Dface landmark localization based on 3Dvector field analysis">
                                        <b>[16]</b>
                                        Shah S A A, Bennamoun M, Boussaid F.Automatic3Dface landmark localization based on 3Dvector field analysis[C]//2015International Conference on Image and Vision Computing New Zealand (IVCNZ) , 23-24Nov.2015, Auckland, New Zealand, 2015:1-6.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_17" title="Song M L, Tao D C, Sun S P, et al.Robust 3Dface landmark localization based on local coordinate coding[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5108-5122." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust 3Dface landmark localization based on local coordinate coding">
                                        <b>[17]</b>
                                        Song M L, Tao D C, Sun S P, et al.Robust 3Dface landmark localization based on local coordinate coding[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5108-5122.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_18" title="Da F P, Gai S Y.Fringe projection 3D precision measurement[M].Beijing:Science Press, 2011.达飞鹏, 盖绍彦.光栅投影三维精密测量[M].北京:科学出版社, 2011." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030300010001&amp;v=MzE0OTNiTzdIdExNcjQ5RVpPc1BEUk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDcmxVN3JNSWx3ZFhGcXpH&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Da F P, Gai S Y.Fringe projection 3D precision measurement[M].Beijing:Science Press, 2011.达飞鹏, 盖绍彦.光栅投影三维精密测量[M].北京:科学出版社, 2011.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-08 10:05</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),124-132 DOI:10.3788/AOS201939.0510001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">一种对姿态稳健的鼻尖点快速定位算法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E4%BA%AE&amp;code=25408101&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪亮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%9B%96%E7%BB%8D%E5%BD%A6&amp;code=06608645&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">盖绍彦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0220478&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">东南大学自动化学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6%E5%A4%8D%E6%9D%82%E5%B7%A5%E7%A8%8B%E7%B3%BB%E7%BB%9F%E6%B5%8B%E9%87%8F%E4%B8%8E%E6%8E%A7%E5%88%B6%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">东南大学复杂工程系统测量与控制教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出了一种对姿态稳健的鼻尖点快速定位算法。在局部基准坐标 (LRF) 下计算顶点的平面距离能量, 并设计了一种新的迭代筛选算法, 计算得到候选点;计算候选点集中的每个顶点在人脸三维矢量场中的散度, 将散度值最大的顶点作为鼻尖点。在FRGC v2.0和Bosphorus人脸库上对算法进行验证, 在Bosphorus库上最终平均每张人脸定位仅耗时0.62s, 在FRGC v2.0库上的定位准确率为95.6%。最后与当前其他算法进行对比, 所提算法在速度和精度上均取得了较好的结果。实验结果证明所提算法不仅有望达到实时处理的要求, 还具有较高的准确率, 且对人脸姿态变化具有稳健性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%BC%BB%E5%B0%96%E7%82%B9%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鼻尖点定位;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E5%9F%BA%E5%87%86%E5%9D%90%E6%A0%87%E8%83%BD%E9%87%8F%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部基准坐标能量特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%80%99%E9%80%89%E7%82%B9%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">候选点提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E7%9F%A2%E9%87%8F%E5%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维矢量场;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%A3%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">散度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    汪亮, E-mail:wlight@seu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (51475092, 61462072, 61628304);</span>
                                <span>高等学校博士学科点专项科研基金 (20130092110027);</span>
                                <span>中央高校基本科研业务费专项资金;</span>
                                <span>江苏省普通高校研究生科研创新计划 (KYLX15_0117);</span>
                                <span>省基础研究计划 (BK20160693);</span>
                    </p>
            </div>
                    <h1>Pose-Invariant and Fast Method for Nose Tip Localization</h1>
                    <h2>
                    <span>Wang Liang</span>
                    <span>Gai Shaoyan</span>
            </h2>
                    <h2>
                    <span>School of Automation, Southeast University</span>
                    <span>Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This study proposes a fast algorithm for nose tip localization, which is robust to pose variations.Based on the coordinates of the local reference frame (LRF) , the plane-distance energy of each vertex is calculated and a novel iteration algorithm for selecting candidate points is designed.For each vertex with centralized candidate points, the divergence on the three-dimensional (3D) vector field is computed.The nose tip denotes the point with the maximum divergence value.The efficiency of the algorithm is verified by applying it to the FRGC v2.0 and Bosphorus face libraries.The average runtime of nose tip location is only 0.62 son the Bosphorus library, whereas the location accuracy is 95.6% on the FRGC v2.0 library.Finally, compared with other state-of-the-art algorithms, the proposed algorithm ranks the first both in speed and accuracy.The results show that the proposed algorithm can meet the requirements of real-time processing, has relatively high accuracy, and is robust to the pose variations in human faces.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=nose%20tip%20localization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">nose tip localization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=local%20reference%20frame%20energy%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">local reference frame energy feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=candidate%20point%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">candidate point extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-dimensional%20vector%20field&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-dimensional vector field;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=divergence&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">divergence;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-15</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">近年来, 由于基于二维图像的人脸识别一直饱受光线姿态等外部条件的困扰, 因此三维人脸识别逐步成为学术研究的热点。三维人脸识别首先需要提取人脸感兴趣区域, 目前主流方法都以鼻尖点为中心并以一定的半径进行人脸切割<citation id="150" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 因此鼻尖点是否准确定位直接影响识别结果的好坏<citation id="151" type="reference"><link href="116" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。目前鼻尖点定位方法主要分为三种:</p>
                </div>
                <div class="p1">
                    <p id="3">1) 基于空间点几何特性的方法。Wang等<citation id="152" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出了一种由粗到精的方法, 首先用一个平面切割人脸, 根据点到平面的距离得到鼻尖初始位置, 然后在人脸对称面和人脸的交线上对该位置进行矫正, 但这种方法对于鼻尖区域较扁平的人脸会失效。Xu等<citation id="153" type="reference"><link href="118" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>结合局部特征, 提出了一种多级筛选鼻尖候选点的方法, 利用有效能量和支持向量机 (SVM) 进行分类。Nguyen等<citation id="154" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>在文献<citation id="155" type="reference">[<a class="sup">3</a>]</citation>的基础上融合距离信息和傅里叶变换, 得到傅里叶距离 (DF) 描述子。Liu等<citation id="156" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>通过在多尺度空间下提取有效能量集合来定位鼻尖点。然而, 这些方法中提取出的有效能量均不稳定, 容易剔除可能为鼻尖点的顶点。</p>
                </div>
                <div class="p1">
                    <p id="4">2) 基于模板匹配的方法。ter Haar等<citation id="157" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>利用两个不同的鼻尖模板, 通过刚性匹配来寻找鼻尖点;该方法需要两次最近邻迭代 (ICP) , 复杂度过高。Liu等<citation id="158" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了基于深度图上鼻尖模板匹配的方法, 但该方法对人脸姿态变化不敏感, 而模板训练的情况直接影响定位结果, 因此算法稳健性较差。</p>
                </div>
                <div class="p1">
                    <p id="5">3) 使用较为广泛的基于曲率的方法。Cai等<citation id="159" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了用平均曲率特征在人脸上筛选鼻尖点候选区域, 并在区域内提取局部统计特征, 最后用SVM分类器进行精确定位。Colombo等<citation id="160" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>认为在人脸网格图上, 平均曲率大于一定阈值的区域为鼻子区域。Chang等<citation id="161" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>在文献<citation id="162" type="reference">[<a class="sup">9</a>]</citation>的基础上, 增加了高斯曲率作为约束条件来寻找鼻尖区域。Li等<citation id="163" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>利用高斯曲率在人脸轮廓线上对鼻尖进行定位, 但该方法实时性较差。Pan等<citation id="164" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>首先在人脸侧影线上通过角点检测得到鼻尖点候选区域, 然后利用形状指数和深度信息提取鼻尖点, 但对于纹理较复杂的人脸侧影线会产生错误角点, 不利于候选点的筛选。</p>
                </div>
                <div class="p1">
                    <p id="6">近年来, 局部基准坐标 (LRF) 在三维目标识别领域得到了广泛的应用<citation id="165" type="reference"><link href="138" rel="bibliography" /><link href="140" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。对于三维物体的网格曲面, 利用LRF能有效表达局部块内顶点的空间关系。在一个局部曲面中, 利用所有三角面片计算得到散布矩阵, 通过对散布矩阵进行特征值分解得到三个特征向量, 即LRF, 相比于传统方法在一个特征点中提取特征, 在LRF坐标下提取特征能够得到更深层的信息。</p>
                </div>
                <div class="p1">
                    <p id="7">为了解决鼻尖点定位算法存在的模型复杂、计算量较大、特征不稳定等问题, 本研究将LRF运用于鼻尖点定位算法中, 在此基础上, 得到了一种新的特征局部基准坐标能量 (LRFE) , 该能量是在鼻尖附近提取得到, 基于该特性设计了一种迭代筛选鼻尖候选点算法, 其优点在于:1) 能够快速排除大量非鼻尖点顶点, 显著提高了算法整体的速度和效率;2) LRFE特征只依赖于顶点和周围顶点在空间中的相对关系, 具有旋转不变性, 不受物体姿态变化的影响, 稳健性较好;3) 可多级筛选候选点, 对于不同条件的人脸点云 (如稀疏或密集点云) , 可以通过调节筛选的次数, 使算法更具有普适性。最后, 提出了利用散度特征在点数较少的候选点中确定鼻尖点的策略。相对于传统的基于曲率特征的方法, 散度定位鼻尖的准确性更高, 并通过实验证明了所提算法的精确性和时效性。对于点云密度较大的人脸, 所提方法依然具有良好的实时定位性能。</p>
                </div>
                <h3 id="8" name="8" class="anchor-tag">2 LRF构建原理</h3>
                <div class="p1">
                    <p id="9">以给定的一个顶点为球心, 用V<sub>n</sub>表示顶点坐标向量, 并以限定的半径r切割曲面, 可以得到一个局部曲面, 该曲面包含了u<sub>n</sub>个三角面片和h<sub>n</sub>个顶点。该面片内任意一点的坐标V<sub>ni</sub> (s, t) 可表示为</p>
                </div>
                <div class="area_img" id="10">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="11">式中:V<sub>ni1</sub>, V<sub>ni2</sub>, V<sub>ni3</sub>为第i个三角面片中的顶点坐标向量;s、t为比例系数, 0≤s, t≤1, s+t≤1。散布矩阵C<sub>i</sub>的计算公式如下<citation id="166" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="12">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="13">式中:T表示矩阵的转置。利用 (1) 、 (2) 式可以得出</p>
                </div>
                <div class="area_img" id="14">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_01400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="15">式中:j, k为三角面片内的顶点序号。通过每个三角面片的散布矩阵的权重可以得到顶点V的总体散布矩阵C:</p>
                </div>
                <div class="area_img" id="16">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_01600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="17">式中:h<sub>n</sub>为三角面片的个数;w<sub>i1</sub>为权重, 反映了第i个三角面片与局部曲面S面积的比值, <image id="184" type="formula" href="images/GXXB201905016_18400.jpg" display="inline" placement="inline"><alt></alt></image><image id="184" type="formula" href="images/GXXB201905016_18401.jpg" display="inline" placement="inline"><alt></alt></image>;w<sub>i2</sub>为权重, 反映了质心间的距离, <image id="185" type="formula" href="images/GXXB201905016_18500.jpg" display="inline" placement="inline"><alt></alt></image><image id="185" type="formula" href="images/GXXB201905016_18501.jpg" display="inline" placement="inline"><alt></alt></image>。w<sub>i1</sub>和w<sub>i2</sub>能够有效增大每个三角面片的位置距离和面积大小对总体散布矩阵的影响。通过对散布矩阵C进行特征值分解, 得到LRF的基坐标:</p>
                </div>
                <div class="area_img" id="20">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_02000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="21">式中:E为特征值矩阵;V为特征矩阵。求解 (5) 式可得到V中的三个特征向量v<sub>1</sub>, v<sub>2</sub>, v<sub>3</sub>, 将这3个特征向量定义为LRF。在LRF坐标轴下进行三维目标的局部特征提取和特征匹配, 从而提高有效性和准确性。因此, 结合鼻尖点在整张人脸中的几何特性, 提取出LRFE特征, 利用此特征可以快速、有效地筛选出鼻尖点候选点。</p>
                </div>
                <h3 id="22" name="22" class="anchor-tag">3 鼻尖点定位</h3>
                <div class="p1">
                    <p id="23">对于三维人脸数据, 通常认为鼻尖附近的点含有如下两个特点:1) 鼻尖是局部区域的最高点<citation id="167" type="reference"><link href="118" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>;2) 鼻尖附近点的法向量方向变化明显。</p>
                </div>
                <h4 class="anchor-tag" id="24" name="24">3.1 人脸矢量场构建</h4>
                <div class="p1">
                    <p id="25">三维人脸曲面的数据包括点云的散点坐标和三角面片, 可以用一对集合V和F来表示, 其中V={v<sub>μ</sub>:1&lt;μ&lt;n<sub>v</sub>}表示顶点集, F={f<sub>k</sub>:1&lt;k&lt;n<sub>f</sub>}表示三角面片集, 其中n<sub>v</sub>、n<sub>f</sub>分别为顶点和三角面片的数量, 按照右手定则将面片每条边的矢量进行统一。其中的某个三角面片f<sub>k</sub>的法向量N<sub>fk</sub>计算公式为</p>
                </div>
                <div class="area_img" id="26">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_02600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="27">式中:V<sub>ki1</sub>, V<sub>ki2</sub>, V<sub>ki3</sub>为一个三角面片的顶点坐标向量, 如图1 (a) 所示。根据三角面片的法向量可以得到顶点的法向量:</p>
                </div>
                <div class="area_img" id="28">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_02800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="29">式中:N<sub>fk</sub>为每个三角网格面的法向量;σ为该顶点构成的三角面片的数量。将所有顶点的法向量集合称为矢量场, 如图1 (b) 所示。</p>
                </div>
                <h4 class="anchor-tag" id="30" name="30">3.2 基于LRFE特征的候选点筛选</h4>
                <div class="p1">
                    <p id="31">对于人脸点云O中的某个顶点, 用V<sub>n</sub>代表其坐标向量, 则经过N<sub>v</sub>的平面集P^为</p>
                </div>
                <div class="area_img" id="32">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_03200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="33"> (8) 式中包含6个平面, 每两个相邻平面间的角度为30°, 每个平面与人脸曲面会形成一条交线, 得到曲线集L<sub>n</sub>:</p>
                </div>
                <div class="area_img" id="34">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_03400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="35">如图2所示, 曲线集中的点包含了顶点V<sub>n</sub>各个方向的大部分邻域点, 取其中每条曲线上离V<sub>n</sub>最近的顶点得到邻域顶点集合, 记作M。依据第2节所述方法计算得到LRF坐标轴, 即v<sub>1</sub>, v<sub>2</sub>, v<sub>3</sub>, 不妨设与N<sub>v</sub>夹角最小的向量为v<sub>3</sub>, 用其余两个向量v<sub>1</sub>、v<sub>2</sub>和顶点V<sub>n</sub>构成平面P (λ) , 定义其方程为</p>
                </div>
                <div class="area_img" id="36">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 人脸法向量分布。 (a) 法向量计算; (b) 人脸三维 (3D) 矢量场" src="Detail/GetImg?filename=images/GXXB201905016_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 人脸法向量分布。 (a) 法向量计算; (b) 人脸三维 (3D) 矢量场  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Distribution of normal vectors on human face. (a) Computation of normal vectors; (b) 3D vector field on human face</p>

                </div>
                <div class="area_img" id="37">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="38">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_03800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 LRFE特征提取" src="Detail/GetImg?filename=images/GXXB201905016_03800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 LRFE特征提取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_03800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 LRFE feature extraction</p>

                </div>
                <div class="p1">
                    <p id="39">式中:R<sup>3</sup>代表平面P (λ) 上任意点的坐标向量λ的维数。计算M中每个顶点到P的垂直矢量并进行加权求和:</p>
                </div>
                <div class="area_img" id="40">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="186">式中:权重<image id="187" type="formula" href="images/GXXB201905016_18700.jpg" display="inline" placement="inline"><alt></alt></image>, υ为M中包含的顶点坐标向量。在LRF坐标轴下得到的局部平面距离矢量和, 即 (11) 式中的E<sub>LRF</sub>可以有效表示顶点V<sub>n</sub>在局部曲面内的能量, 将其定义为LRFE特征。E<sub>LRF</sub>的方向与v<sub>3</sub>平行, 其与法向量N<sub>v</sub>的夹角θ表示局部曲面的凹凸性, E<sub>LRF</sub>的模长表示局部曲面的凹凸程度, 选取满足如下条件的顶点为候选点:</p>
                </div>
                <div class="area_img" id="44">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_04400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="45">式中:c为筛选次数;ε为稠密度系数。经过筛选后, 鼻尖点搜索空间大幅缩小。</p>
                </div>
                <div class="p1">
                    <p id="46">此时, 候选点集仍然包含大量顶点, 需要进一步筛选, 对于M中的每个顶点V<sub>M</sub>, 取V<sub>M</sub>所在曲线上离V<sub>M</sub>最近的点并将其加入到M中, 对候选点集重复上一步筛选规则, 进一步减少鼻尖点候选点的数量。反复上述操作, 在经过多次筛选后, 候选点的数量基本处于500个点以内, 如图3所示。对整个候选点的筛选代码如下:</p>
                </div>
                <div class="area_img" id="188">
                                <img alt="" src="Detail/GetImg?filename=images/GXXB201905016_18800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_04800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于LRFE算法的人脸鼻尖点迭代筛选" src="Detail/GetImg?filename=images/GXXB201905016_04800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于LRFE算法的人脸鼻尖点迭代筛选  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_04800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Iterative screening of candidate points based on LRFE algorithm</p>

                </div>
                <h4 class="anchor-tag" id="49" name="49">3.3 LRFE特征的旋转不变性</h4>
                <div class="p1">
                    <p id="50">人脸的旋转方向有三个, 一般来说可以分成绕x轴的旋转 (pitch) 、绕y轴的旋转 (yaw) 、绕z轴的旋转 (roll) 。设定z轴正方向为人脸的正面朝向, 如图4所示。假设人脸在空间中发生了任意角度的旋转, 用α、β、θ表示人脸绕x、y、z轴旋转的角度。假设某个顶点坐标向量为V<sub>n</sub>, 在三维空间中发生任意旋转后的坐标向量p′为</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 人脸旋转方向示意图" src="Detail/GetImg?filename=images/GXXB201905016_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 人脸旋转方向示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Schematic of human face rotation direction</p>

                </div>
                <div class="area_img" id="52">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="189">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_18900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="59">将 (13) 式代入 (3) 、 (4) 式中, 可以得到旋转后顶点V<sub>n</sub>的散布矩阵为</p>
                </div>
                <div class="area_img" id="60">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="61">将 (14) 式代入 (5) 式中, 可得到</p>
                </div>
                <div class="area_img" id="62">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="63">式中:E′表示旋转后的LRF特征值矩阵。由于旋转矩阵满足RR<sup>T</sup>=I, I为单位矩阵, 因此对比 (5) 式可以得出旋转前后LRF坐标轴的关系为</p>
                </div>
                <div class="area_img" id="64">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="65">由此可知, 人脸在空间中任意旋转后, 每个顶点的LRF坐标轴的旋转矩阵与该顶点保持一致。而由 (11) 式可知, LRFE特征只取决于周围邻域点和LRF坐标轴, 因此所提出的LRFE特征与人脸的姿态无关, 是一种对姿态稳健的局部特征。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">3.4 对鼻尖点的精确定位</h4>
                <div class="p1">
                    <p id="67">对于鼻尖候选点, 考虑到鼻尖点处于一个较突起区域, 所提算法利用散度在候选点中选取鼻尖点。图5 (a) 、 (b) 展示了一个三维曲面的矢量分布和对应的散度能量分布图, 可以观察到图5 (a) 中的矢量膨胀区域对应的散度值较高, 而矢量收缩区域的散度值较低, 由此可知, 散度可以用来反映与曲面凹凸程度有关的某种特征。图5 (c) 显示了在整个人脸区域的旋度能量, 由于人脸表面大部分区域接近于平面, 而鼻尖处的散度值远大于其他凸起区域, 因此散度特征可以用来定位鼻尖点。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_06800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 散度能量图。 (a) 矢量场膨胀与收缩; (b) 曲面散度能量图; (c) 人脸散度能量图" src="Detail/GetImg?filename=images/GXXB201905016_06800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 散度能量图。 (a) 矢量场膨胀与收缩; (b) 曲面散度能量图; (c) 人脸散度能量图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_06800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Divergence energy maps. (a) Expansion and shrinkage of vector field; (b) divergence map on surface; (c) divergence energy map on human face</p>

                </div>
                <div class="p1">
                    <p id="69">接下来计算候选点集中每个顶点在矢量场中的散度, 计算式为</p>
                </div>
                <div class="area_img" id="70">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="71">由 (17) 式可以求出每个顶点的散度, 散度是一个标量, 其正负性和大小由该局部区域的膨胀和收缩程度决定。由于得到的候选点为稀疏点云, 得到的矢量场不具有连续性, 用 (17) 式无法直接求解, 因此需要对候选点集进行矢量场重建, 设候选点集S′={V<sub>g</sub>, g=1, …, ρ}, 其中ρ为候选点数目, V<sub>g</sub>为顶点坐标向量, 设N<sub>g</sub>为顶点V<sub>g</sub>处的单位法向量, 则连续矢量场可表示为</p>
                </div>
                <div class="area_img" id="72">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="73">式中:ζ代表空间中任意一点的坐标向量;ρ为候选点的数目。权值函数计算式为</p>
                </div>
                <div class="area_img" id="74">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="75">式中:h为比例系数;b为候选点的序号;V<sub>b</sub>为候选点集中的顶点坐标向量;d为两个顶点的欧式距离。 (19) 式为归一化后的高斯权重函数。由于鼻尖附近的矢量场膨胀程度最大, 因此拥有最大散度值的顶点为鼻尖点。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">4 结果与分析</h3>
                <h4 class="anchor-tag" id="77" name="77">4.1 人脸数据库描述</h4>
                <div class="p1">
                    <p id="190">FRGCv2.0 (First Recognition Grand Challenge ver2.0) 人脸库:FRGCv2.0数据库是一个大型的人脸库, 其中共有4007个三维人脸点云, 包括466个对象, 有各种表情变化, 包括中性、微笑、吃惊、生气等表情, 部分还含有姿态变化和遮挡。为了检测算法的准确率, 手工标记1007张人脸的鼻尖点位置作为检测标准点。</p>
                </div>
                <div class="p1">
                    <p id="80">Bosphorus人脸库:Bosphorus人脸数据库共有4666个点云, 包含105个对象, 其中61个为男性, 44个为女性, 不仅包含了各种表情变化的人脸, 还包括人脸在空间中三个方向上姿态的变化, 部分人脸还有遮挡和丢失。另外, Bosphorus数据库已经提供了手工标记好的人脸五官点, 因此无需再手动标记鼻尖点。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">4.2 算法指标</h4>
                <div class="p1">
                    <p id="82">为了验证所提出的算法在定位鼻尖点时的实时性和准确性, 在处理器为Corei7、内存大小为8G、操作系统为Windows10的机器上通过Matlab2016平台进行编程。图6显示了所提算法对不同对象的定位结果。其中第一行实验对象来自Bosphorus库, 第二行实验对象来自FRGC v2.0库。从图6中可以直观地看出, 所提算法能够准确定位鼻尖点的位置。为了对鼻尖点定位算法的效果进行量化描述, 使用了以下评价指标<citation id="169" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="83">1) 距离误差, 即算法定位的鼻尖点与手动标记的鼻尖点的欧式距离。</p>
                </div>
                <div class="p1">
                    <p id="84">2) 可接受距离, 即判定定位是否正确的阈值。距离误差小于该阈值, 即认为定位准确。</p>
                </div>
                <div class="p1">
                    <p id="85">3) 鼻尖点检测误差, 可由一个数据集鼻尖点的距离误差的均值和标准差表示。其中距离误差的均值称为特征点平均误差, 距离误差的标准差称为鼻尖点标准差。</p>
                </div>
                <div class="p1">
                    <p id="86">4) 特征点检测准确率, 即数据集检测某个特征点的距离误差在可接受距离内的比率。</p>
                </div>
                <div class="p1">
                    <p id="87">5) 算法检测时间, 即从输入一个原始点云和对应的三角网格到输出最终的鼻尖坐标的时间。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">4.3 算法实时性检测</h4>
                <div class="p1">
                    <p id="89">首先从FRGC v2.0库中随机选取50个男性和50个女性, 针对每个对象选取5张带有不同表情变化的人脸, 因此共选出500个测试人脸。所提算法首先需要确定多次筛选候选点时迭代的次数对整个算法时间的影响, 图7显示了迭代次数与筛选的候选点的关系, 可以看出, 在经过第一次筛选后, 候选点集的数量从1.0×10<sup>5</sup>降到了3.7×10<sup>4</sup>左右, 筛选6次以后候选点的数量基本不再变化。图8显示了迭代次数与整个算法耗时的关系, 可以看出, 在筛选次数小于5次时, 整个算法的耗时随着筛选次数的增多而缩短;筛选次数达到5次时, 平均每张人脸的识别耗时最短为1.57s;筛选次数大于5次后, 算法耗时随着筛选次数的增多而延长, 由于本实验候选点的数量变化较小, 而邻域点的数量与筛选次数成正比, 计算LRFE特征的时间代价增大, 因此整个算法的耗时反而延长。因此在后续实验中筛选次数设为5次。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 用LRFE算法对不同对象的定位结果" src="Detail/GetImg?filename=images/GXXB201905016_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 用LRFE算法对不同对象的定位结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Localization results on different persons based on LRFE algorithm</p>

                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 迭代次数与候选点数量的关系曲线" src="Detail/GetImg?filename=images/GXXB201905016_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 迭代次数与候选点数量的关系曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Relationship between iteration number and candidate point number</p>

                </div>
                <div class="p1">
                    <p id="92">对所提算法与当前几种鼻尖点定位算法的实时性进行比较, 文献<citation id="170" type="reference">[<a class="sup">1</a>]</citation>使用了人脸对称线, 依赖于ICP算法的精度。文献<citation id="171" type="reference">[<a class="sup">16</a>]</citation>使用旋度 (CURL) 特征来直接定位鼻尖。文献<citation id="172" type="reference">[<a class="sup">17</a>]</citation>结合顶点的局部特征和SVM分类器进行鼻尖定位。表1显示了这几种方法在FRGC v2.0库和Bosphorus库上平均每张人脸识别所花费的时间。文献FRGC v2.0库中每个样本的原始点云数量在1.1×10<sup>5</sup>左右, 顶点之间的欧氏距离为0.5～0.7mm;Bosphorus库中每个样本的原始点云数量在3.5×10<sup>4</sup>左右, 顶点之间的欧氏距离为1～2mm。 (12) 式中ε取值范围为0.65～0.74。由于点云稀释会造成人脸表面纹理信息的丢失, 同时为了验证算法对大密度点云的实时性, 所提算法对点云数据不做任何稀释处理。由表1可以看出:</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 迭代次数与算法耗时的关系曲线" src="Detail/GetImg?filename=images/GXXB201905016_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 迭代次数与算法耗时的关系曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Relationship between iteration number and running time of algorithm</p>

                </div>
                <div class="p1">
                    <p id="94">1) 所提算法在Bosphorus库中的定位平均耗时为0.62s, 相比文献<citation id="173" type="reference">[<a class="sup">16</a>]</citation>中的2.91s, 快了近4倍。在FRGC v2.0库中文献<citation id="174" type="reference">[<a class="sup">1</a>]</citation>与文献<citation id="175" type="reference">[<a class="sup">17</a>]</citation>的定位耗时均超过10s, 而所提算法的平均定位耗时1.29s, 且依然能保持良好的实时性能。</p>
                </div>
                <div class="p1">
                    <p id="95">2) 文献<citation id="176" type="reference">[<a class="sup">16</a>]</citation>中采用直接基于旋度来提取鼻尖点的方法, 虽然算法流程较为简单, 在Bosphorus库集上的实时性表现也较为突出, 但是没有考虑鼻尖点的几何特性, 对于所有顶点都需要计算旋度值, 存在大量无用计算, 无法处理点云数量较大的人脸。通过LRFE特征则可快速筛选出鼻尖点候选点, 筛选速度得到明显提升。</p>
                </div>
                <div class="p1">
                    <p id="96">3) 文献<citation id="177" type="reference">[<a class="sup">17</a>]</citation>中的方法依赖于SVM分类器, 而所提方法不需要训练过程, 因此不会受到训练样本对定位结果的影响, 其稳健性更好。文献<citation id="178" type="reference">[<a class="sup">1</a>]</citation>在寻找人脸对称面时需要使用ICP算法, 耗时较长, 不适于密度较大的点云。</p>
                </div>
                <div class="area_img" id="97">
                                            <p class="img_tit">
                                                表1 所提方法与现有方法的耗时比较
                                                    <br />
                                                Table 1 Running time comparison of proposed method and current method
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905016_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note">s</p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 所提方法与现有方法的耗时比较" src="Detail/GetImg?filename=images/GXXB201905016_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="98" name="98">4.4 对姿态稳健性的验证</h4>
                <div class="p1">
                    <p id="99">在Bosphorus库中设计实验来验证算法对人脸姿态变化的稳健性。如图9所示, 按人脸姿态变化的方向和角度将测试样本分为5种类别:1) 中性表情正面 (N) , 共466个测试样本;2) 绕y轴人脸向右侧旋转 (YR30) , yaw为10°～30°, 共367个样本;3) 绕y轴人脸向左侧旋转 (YR45) , yaw为-45°, 共105个样本;4) 极端情况, 绕y轴人脸旋转至纯侧脸 (YR90) , yaw为90°和-90°, 共210个样本;5) 绕x轴人脸向上和向下旋转 (PR) , pitch为—30°～30°, 共269个样本。图10反映了这5种类别的定位准确率在不同可接受距离下的情况。从图10中可以看出, N、YR30、YR45、PR这4种类别的定位准确率基本相当, 当可接受距离大于6mm时, N、YR30类别的定位准确率接近100%;当可接受距离大于7mm时, YR45、PR类别的定位准确率也已经接近100%, 说明一定幅度的姿态变化对算法的定位准确率基本没有影响, 而纯侧脸情况下YR90类别的定位准确率不高, 原因在于纯侧脸情况下鼻尖附近丢失了一半以上的邻域信息, 改变了鼻尖区域的局部形状, 因此定位准确率在可接受距离大于10mm后依然没有达到100%, 出现了错误定位的情况。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 Bosphorus库中的姿态变化" src="Detail/GetImg?filename=images/GXXB201905016_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 Bosphorus库中的姿态变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 Pose variations in Bosphorus library</p>

                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 0 N、YR30、YR45、PR、YR90类别的定位准确率" src="Detail/GetImg?filename=images/GXXB201905016_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 0 N、YR30、YR45、PR、YR90类别的定位准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Localization accuracy of N, YR30, YR45, PR and YR90category</p>

                </div>
                <h4 class="anchor-tag" id="102" name="102">4.5 算法准确率的验证</h4>
                <div class="p1">
                    <p id="103">在FRGC v2.0人脸数据库上对算法的准确率进行验证, 首先从FRGC v2.0人脸库中选取30个男性和30个女性, 每个对象包含15张不同表情和姿态的人脸。依据文献<citation id="179" type="reference">[<a class="sup">15</a>]</citation>对可接受距离的探讨, 设定该值为5mm。从表2可以看到, 所提算法取得了95.6%的定位准确率, 文献<citation id="180" type="reference">[<a class="sup">16</a>]</citation>取得了92.8%的定位准确率, 仅次于所提算法。除此之外, 所提算法的标准差最小, 由于人脸表面存在局部突出的尖锐点, 采用基于曲率<citation id="181" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>的方法或者轮廓线<citation id="182" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>的方法时, 这些点都极有可能成为误检点, 由于所提算法的第一步筛选候选点算法通过多次迭代扩大了邻域点的范围, 这些点的LRFE特征值在邻域范围较大的情况下会减小, 因而这些点被筛除。实验结果也证明了所提算法对这些噪点不敏感, 定位稳定性更强。</p>
                </div>
                <div class="area_img" id="104">
                                            <p class="img_tit">
                                                表2 所提方法与现有方法的误差对比
                                                    <br />
                                                Table 2 Comparison of error between proposed method and current methods
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905016_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 所提方法与现有方法的误差对比" src="Detail/GetImg?filename=images/GXXB201905016_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="105" name="105">4.6 实际场景中检测</h4>
                <div class="p1">
                    <p id="106">对实际环境下采集的人脸数据库进行测试。利用光栅投影测量技术<citation id="183" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>采集了19个对象的人脸点云, 包括12个男生和7个女生, 共57个点云数据。一般情况下采集的点云与公开数据库的不同之处在于:</p>
                </div>
                <div class="p1">
                    <p id="107">1) 点云密度不均匀;2) 有较多的噪点;3) 点云缺失部位较多, 形成数量较多的孔洞。其中, 点云密度不均匀会导致人脸表面的信息更加复杂, 噪点会影响定位的准确率;点云缺失部位较多会给人脸网格化带来一定的困难。从图11中可以看出, 网格化后的人脸下巴区域有凹凸不平的表面, 这会导致曲率分布不均衡, 选取形状指数 (SI) 来论证上述问题, 其计算公式如下:</p>
                </div>
                <div class="area_img" id="108">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905016_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="109">式中:k<sub>1</sub>, k<sub>2</sub>为主曲率。从图11 (a) 中可以直观地看出, 除了鼻尖附近的值较高外, 其他部位均出现了形状指数较高的情况。使用曲率来定位鼻尖会有很大的困难, 而利用散度来定位鼻尖可以大幅减少这种情况。图11 (b) 反映了整副人脸的散度能量分布, 图11 (c) 为所提算法筛选出的候选点集, 可以看出候选点和旋度值较高的顶点均集中在鼻尖附近, 这也反映出所提算法能适用于一般环境下采集的人脸数据。表3记录了完整的实验数据, 其中平均每个样本的检测耗时为0.72s。图11 (d) 中蓝色标志点为真实鼻尖的位置, 红色标志点为算法定位的鼻尖位置, 直观上可以看出算法定位出的鼻尖点与真实位置的差距较小。虽然实际场景中的人脸表面纹理不够清晰, 噪点较多, 但所提算法依旧取得了较快的速度和较高的准确率, 说明所提算法具有较好的实用性。</p>
                </div>
                <div class="area_img" id="110">
                                            <p class="img_tit">
                                                表3 实际环境下的检测结果
                                                    <br />
                                                Table 3 Test results in actual environment
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905016_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 实际环境下的检测结果" src="Detail/GetImg?filename=images/GXXB201905016_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905016_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 1 实际场景鼻尖定位。 (a) 形状指数分布; (b) 散度分布; (c) 候选点; (d) 定位结果" src="Detail/GetImg?filename=images/GXXB201905016_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 1 实际场景鼻尖定位。 (a) 形状指数分布; (b) 散度分布; (c) 候选点; (d) 定位结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905016_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Localization of nose tip in real scene. (a) Shape index distribution; (b) divergence distribution; (c) candidate points; (d) localization result</p>

                </div>
                <h3 id="112" name="112" class="anchor-tag">5 结论</h3>
                <div class="p1">
                    <p id="113">提出了一种对姿态稳健的三维人脸鼻尖点的定位算法, 首先提取多条等分曲线上的点为邻域点, 在LRF坐标下提取法向量与周围邻域点的局部平面距离能量, 得到一种新的旋转不变性特征LRFE, 利用LRFE特征多次迭代筛选鼻尖点候选点。最后利用散度特征得到最终鼻尖点坐标。在FRGC v2.0和Bosphorus库中的实验充分证明了所提算法的实时性和准确性。该算法具有如下优点:1) 不需要任何训练模型或者统计模型, 算法流程简单;2) 能够快速排除大量非鼻尖点区域, 显著提高了算法整体的效率;3) LRFE特征只依赖于顶点和周围顶点在空间中的相对关系, 具有旋转不变性, 不受物体姿态变化的影响, 稳健性较好;4) 算法多级筛选候选点, 对于不同条件的人脸点云例如稀疏或密集, 可以通过调节筛选的次数和稠密度等参数, 使算法具有更好的实用价值;5) 相对于传统的曲率特征, 散度特征更加适用于鼻尖点的定位。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="114">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust 3D Face Recognition by Local Shape Difference Boosting">

                                <b>[1]</b>Wang Y M, Liu J Z, Tang X O.Robust 3Dface recognition by local shape difference boosting[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (10) :1858-1870.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multimodal 2Dand 3D biometrics for face recognition">

                                <b>[2]</b>Chang K I, Bowyer K W, Flynn P J.Multimodal 2Dand 3D biometrics for face recognition[C]//2003IEEE International SOI Conference.Proceedings (Cat.no.03CH37443) , 17-17 Oct.2003, Nice, France, 2003:187-194.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414780&amp;v=MTgyMjVpZk9mYks3SHRET3JJOUZZT29MQzNRNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpWb1dhQnM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Xu C H, Tan T N, Wang Y H, et al.Combining local features for robust nose location in 3Dfacial data[J].Pattern Recognition Letters, 2006, 27 (13) :1487-1494.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nose tip detection from 3Dfacial mesh data using a rotationally invariant local shape descriptor">

                                <b>[4]</b>Nguyen D H, Na J, Yi J.Nose tip detection from 3Dfacial mesh data using a rotationally invariant local shape descriptor[C]//2012 5th IAPR International Conference on Biometrics (ICB) , 29 March-1 April2012, New Delhi, India, 2012:91-96.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust nose tip detection for face range images based on local features in scale-space">

                                <b>[5]</b>Liu J, Zhang Q, Zhang C, et al.Robust nose tip detection for face range images based on local features in scale-space[C]//2015International Conference on3D Imaging (IC3D) , 14-15 Dec.2015, Liege, Belgium, 2015:1-8.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300445028&amp;v=MjY5OTdpZk9mYks3SHRETnJJOUZZTzhLREg0eG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUpWb1dhQnM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>ter Haar F B, Veltkamp R C.A 3Dface matching framework for facial curves[J].Graphical Models, 2009, 71 (2) :77-91.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nose detection on 3D face images by depth-based template matching">

                                <b>[7]</b>Liu R, Hu R, Yu H M.Nose detection on 3Dface images by depth-based template matching[C]//20147th International Congress on Image and Signal Processing, 14-16 Oct.2014, Dalian, China, 2014:302-307.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A method for nose tip location and head pose estimation in 3D face data">

                                <b>[8]</b>Cai Y, Huang Y J, Zhang S G.A method for nose tip location and head pose estimation in 3D face data[C]//International Conference on Automatic Control and Artificial Intelligence, IET, 2013:115-118.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739946&amp;v=MTM2OTdUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSlZvV2FCcz1OaWZPZmJLN0h0RE5xWTlGWStnR0JYZy9vQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Colombo A, Cusano C, Schettini R.3Dface detection using curvature analysis[J].Pattern Recognition, 2006, 39 (3) :444-455.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple Nose Region Matching for 3D Face Recognition under Varying Facial Expression">

                                <b>[10]</b>Chang K I, Bowyer K W, Flynn P J.Multiple nose region matching for 3Dface recognition under varying facial expression[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (10) :1695-1700.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nose tip detection on threedimensional faces using pose-invariant differential surface features">

                                <b>[11]</b>Li Y, Wang B B, Sui L S, et al.Nose tip detection on three-dimensional faces using pose-invariant differential surface features[J].IET Computer Vision, 2015, 9 (1) :75-84.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813030&amp;v=MDkwMjg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTNoVWIzQkx6N01hYkc0SDluTnJJOUdaSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Pan L Q, Xu H L, Wei Y, et al.Nose tip location based on the corner detection of face silhouette[J].Computer Engineering and Applications, 2018, 54 (13) :191-195.潘腊青, 徐海黎, 韦勇, 等.基于人脸侧影线角点检测的鼻尖点定位方法[J].计算机工程与应用, 2018, 54 (13) :191-195.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13081300000476&amp;v=MjU4NDNCYXJLN0h0bk5ySTlGWk9zUENIcy9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lKVm9XYUJzPU5qNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Guo Y L, Sohel F, Bennamoun M, et al.Rotational projection statistics for 3Dlocal surface description and object recognition[J].International Journal of Computer Vision, 2013, 105 (1) :63-86.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1F06DC8A440984412ED80029E66ADFD2&amp;v=MTU2MDFTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhod2J5OXdxRT1OaWZPZmJMT0h0ZTQzSWMwWU84UEJYUTl5eGNSbjB0MVNIL2dwV2N6ZjhQZ004NmRDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Shah S A A, Bennamoun M, Boussaid F.A novel feature representation for automatic 3D object recognition in cluttered scenes[J].Neurocomputing, 2016, 205:1-15.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D facial landmark detection under large yaw and expression variations">

                                <b>[15]</b>Perakis P, Passalis G, Theoharis T, et al.3Dfacial landmark detection under large yaw and expression variations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (7) :1552-1564.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic3Dface landmark localization based on 3Dvector field analysis">

                                <b>[16]</b>Shah S A A, Bennamoun M, Boussaid F.Automatic3Dface landmark localization based on 3Dvector field analysis[C]//2015International Conference on Image and Vision Computing New Zealand (IVCNZ) , 23-24Nov.2015, Auckland, New Zealand, 2015:1-6.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust 3Dface landmark localization based on local coordinate coding">

                                <b>[17]</b>Song M L, Tao D C, Sun S P, et al.Robust 3Dface landmark localization based on local coordinate coding[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5108-5122.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030300010001&amp;v=MjU2MDRHYk83SHRMTXI0OUVaT3NQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3JsVTdyTUlsd2RYRnF6&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Da F P, Gai S Y.Fringe projection 3D precision measurement[M].Beijing:Science Press, 2011.达飞鹏, 盖绍彦.光栅投影三维精密测量[M].北京:科学出版社, 2011.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905016&amp;v=MTI0MDNVUkxPZVplVnVGeTNoVWIzQklqWFRiTEc0SDlqTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

