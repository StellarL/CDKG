

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133092075908750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dGXXB201910027%26RESULT%3d1%26SIGN%3dhcdKOVQyaKokDN52TcZJpki2qcI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910027&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910027&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910027&amp;v=MDg2NzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnlybVZMck9JalhUYkxHNEg5ak5yNDlIWTRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#52" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="2 技术总体方案 ">2 技术总体方案</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="3 投影散斑纹理生成算法 ">3 投影散斑纹理生成算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 数字散斑图案生成算法设计&lt;/b&gt;"><b>3.1 数字散斑图案生成算法设计</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;3.2 投影散斑的匹配验证&lt;/b&gt;"><b>3.2 投影散斑的匹配验证</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="4 无编码点的多视图几何结构求解方法 ">4 无编码点的多视图几何结构求解方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="&lt;b&gt;4.1 大旋转图像的DIC退相关效应&lt;/b&gt;"><b>4.1 大旋转图像的DIC退相关效应</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;4.2 带旋转补偿的RFDIC匹配方法&lt;/b&gt;"><b>4.2 带旋转补偿的RFDIC匹配方法</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;4.3 多视图几何结构求解策略&lt;/b&gt;"><b>4.3 多视图几何结构求解策略</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="5 无编码点工业摄影测量技术的实验验证 ">5 无编码点工业摄影测量技术的实验验证</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#107" data-title="&lt;b&gt;5.1 实验方案设计&lt;/b&gt;"><b>5.1 实验方案设计</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;5.2 多视图几何结构重建精度验证&lt;/b&gt;"><b>5.2 多视图几何结构重建精度验证</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;5.3 稠密点云重建精度验证&lt;/b&gt;"><b>5.3 稠密点云重建精度验证</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="6 结  论 ">6 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 无编码点摄影测量方法示意图">图1 无编码点摄影测量方法示意图</a></li>
                                                <li><a href="#61" data-title="图2 无编码点重建多视图结构的技术路线">图2 无编码点重建多视图结构的技术路线</a></li>
                                                <li><a href="#68" data-title="图3 数字散斑图案的白色底纹">图3 数字散斑图案的白色底纹</a></li>
                                                <li><a href="#70" data-title="图4 散斑颗粒随机生长法伪代码">图4 散斑颗粒随机生长法伪代码</a></li>
                                                <li><a href="#71" data-title="图5 随机形状的散斑颗粒">图5 随机形状的散斑颗粒</a></li>
                                                <li><a href="#73" data-title="图6 不同散斑颗粒半径下的散斑图案。 ">图6 不同散斑颗粒半径下的散斑图案。 </a></li>
                                                <li><a href="#74" data-title="图7 不同散斑占空比下的散斑图案。">图7 不同散斑占空比下的散斑图案。</a></li>
                                                <li><a href="#75" data-title="图8 不同灰度范围(0～255)下的散斑颗粒生成的散斑图案。">图8 不同灰度范围(0～255)下的散斑颗粒生成的散斑图案。</a></li>
                                                <li><a href="#79" data-title="图9 投影散斑的DIC匹配结果。">图9 投影散斑的DIC匹配结果。</a></li>
                                                <li><a href="#83" data-title="图10 大旋转角度下图像的DIC误匹配问题。">图10 大旋转角度下图像的DIC误匹配问题。</a></li>
                                                <li><a href="#89" data-title="图11 RFDIC匹配策略">图11 RFDIC匹配策略</a></li>
                                                <li><a href="#98" data-title="图12 &lt;i&gt;RFDIC&lt;/i&gt;和&lt;i&gt;Patch Matching&lt;/i&gt;方法的匹配结果。">图12 <i>RFDIC</i>和<i>Patch Matching</i>方法的匹配结果。</a></li>
                                                <li><a href="#99" data-title="表1 &lt;i&gt;RFDIC&lt;/i&gt;方法和&lt;i&gt;Patch Matching&lt;/i&gt;方法匹配结果的对比">表1 <i>RFDIC</i>方法和<i>Patch Matching</i>方法匹配结果的对比</a></li>
                                                <li><a href="#101" data-title="表2 &lt;i&gt;RFDIC&lt;/i&gt;方法和&lt;i&gt;Patch Matching&lt;/i&gt;方法重建的运行时间和点云误差对比">表2 <i>RFDIC</i>方法和<i>Patch Matching</i>方法重建的运行时间和点云误差对比</a></li>
                                                <li><a href="#104" data-title="图13 无编码点的多视图几何重建算法伪代码">图13 无编码点的多视图几何重建算法伪代码</a></li>
                                                <li><a href="#109" data-title="图14 飞机蒙皮钣金件">图14 飞机蒙皮钣金件</a></li>
                                                <li><a href="#112" data-title="图15 无编码点摄影测量实验场景">图15 无编码点摄影测量实验场景</a></li>
                                                <li><a href="#116" data-title="图16 无编码点摄影测量重建的多视图结构">图16 无编码点摄影测量重建的多视图结构</a></li>
                                                <li><a href="#118" data-title="表3 多视图结构的重投影的误差均值和标准误差">表3 多视图结构的重投影的误差均值和标准误差</a></li>
                                                <li><a href="#122" data-title="表4 标尺长度的重建结果及误差对比">表4 标尺长度的重建结果及误差对比</a></li>
                                                <li><a href="#125" data-title="图17 两视图重建的点云及三角网格模型">图17 两视图重建的点云及三角网格模型</a></li>
                                                <li><a href="#128" data-title="表5 两视图重建的点云偏差对比">表5 两视图重建的点云偏差对比</a></li>
                                                <li><a href="#129" data-title="图18 点云整体偏差示对比">图18 点云整体偏差示对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" Huang G P.Digital close range industry photogrammetry[M].Beijing:Science Press,2016.黄桂平.数字近景工业摄影测量理论、方法与应用[M].北京:科学出版社,2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030464309000&amp;v=MTMxOTE3SHRYS3E0eEZiZXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3JrVTczTEoxc1NYRnF6R2JP&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Huang G P.Digital close range industry photogrammetry[M].Beijing:Science Press,2016.黄桂平.数字近景工业摄影测量理论、方法与应用[M].北京:科学出版社,2016.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" Hartley R,Zisserman A.Multiple view geometry in computer vision[M].Cambridge:Cambridge University Press,2003." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple view geometry in computer vision">
                                        <b>[2]</b>
                                         Hartley R,Zisserman A.Multiple view geometry in computer vision[M].Cambridge:Cambridge University Press,2003.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" Song L M,Chen C M,Chen Z,&lt;i&gt;et al&lt;/i&gt;.Detection and recognition of cyclic coded targets[J].Optics and Precision Engineering,2013,21(12):3239-3247.宋丽梅,陈昌曼,陈卓,等.环状编码标记点的检测与识别[J].光学精密工程,2013,21(12):3239-3247." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201312034&amp;v=MjU5MTVtVkxyT0lqWEJZN0c0SDlMTnJZOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Song L M,Chen C M,Chen Z,&lt;i&gt;et al&lt;/i&gt;.Detection and recognition of cyclic coded targets[J].Optics and Precision Engineering,2013,21(12):3239-3247.宋丽梅,陈昌曼,陈卓,等.环状编码标记点的检测与识别[J].光学精密工程,2013,21(12):3239-3247.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" Agarwal S,Furukawa Y,Snavley N,&lt;i&gt;et al&lt;/i&gt;.Reconstructing Rome[J].Computer,2010,43(6):40-47." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reconstructing Rome">
                                        <b>[4]</b>
                                         Agarwal S,Furukawa Y,Snavley N,&lt;i&gt;et al&lt;/i&gt;.Reconstructing Rome[J].Computer,2010,43(6):40-47.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDU1MDVqN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVWJ6UEpWZz1O&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" title=" Bay H,Ess A,Tuytelaars T,&lt;i&gt;et al&lt;/i&gt;.Speeded-up robust features (SURF)[J].Computer Vision and Image Understanding,2008,110(3):346-359." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=MDIxMDc9TmlmT2ZiSzdIdEROcW85RVpPTU1CSFF4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSWwwVGJ4UQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Bay H,Ess A,Tuytelaars T,&lt;i&gt;et al&lt;/i&gt;.Speeded-up robust features (SURF)[J].Computer Vision and Image Understanding,2008,110(3):346-359.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" Bruck H A,McNeill S R,Sutton M A,&lt;i&gt;et al&lt;/i&gt;.Digital image correlation using Newton-Raphson method of partial differential correction[J].Experimental Mechanics,1989,29(3):261-267." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001196855&amp;v=MjcyMjR6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RlNubFVielBKVmc9Tmo3QmFyTzRIdEhOcm9aRGJPNEtZM2s1&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Bruck H A,McNeill S R,Sutton M A,&lt;i&gt;et al&lt;/i&gt;.Digital image correlation using Newton-Raphson method of partial differential correction[J].Experimental Mechanics,1989,29(3):261-267.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" Pan B,Li K.A fast digital image correlation method for deformation measurement[J].Optics and Lasers in Engineering,2011,49(7):841-847." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011400063178&amp;v=MDE2MTltVWI3SUlsMFRieFE9TmlmT2ZiSzdIdEROcTQ5RlpPME1EWHN4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Pan B,Li K.A fast digital image correlation method for deformation measurement[J].Optics and Lasers in Engineering,2011,49(7):841-847.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" Pan B,Xie H M,Li Y J.Three-dimensional digital image correlation method for shape and deformation measurement of an object surface[J].Journal of Experimental Mechanics,2007,22(6):556-567.潘兵,谢惠民,李艳杰.用于物体表面形貌和变形测量的三维数字图像相关方法[J].实验力学,2007,22(6):556-567." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYLX200706002&amp;v=MjI0OTVtVkxyT05qVEhkckc0SHRiTXFZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Pan B,Xie H M,Li Y J.Three-dimensional digital image correlation method for shape and deformation measurement of an object surface[J].Journal of Experimental Mechanics,2007,22(6):556-567.潘兵,谢惠民,李艳杰.用于物体表面形貌和变形测量的三维数字图像相关方法[J].实验力学,2007,22(6):556-567.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" Harvent J,Coudrin B,Br&#232;thes L,&lt;i&gt;et al&lt;/i&gt;.Multi-view dense 3D modelling of untextured objects from a moving projector-cameras system[J].Machine Vision and Applications,2013,24(8):1645-1659." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13102400016220&amp;v=MjgwMTRRPU5qN0Jhcks3SDlIT3E0OUZaT29KRG40NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUlsMFRieA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Harvent J,Coudrin B,Br&#232;thes L,&lt;i&gt;et al&lt;/i&gt;.Multi-view dense 3D modelling of untextured objects from a moving projector-cameras system[J].Machine Vision and Applications,2013,24(8):1645-1659.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" Zhang K W,Liang J,You W,&lt;i&gt;et al&lt;/i&gt;.Fast morphology measurement based on the binocular vision and speckle projection[J].Laser &amp;amp; Infrared,2016,46(12):1517-1520.张扣文,梁晋,尤威,等.基于双目视觉和散斑投射的快速形貌测量[J].激光与红外,2016,46(12):1517-1520." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201612017&amp;v=MjQwODg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXJtVkxyT0x5ckRlYkc0SDlmTnJZOUVZNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Zhang K W,Liang J,You W,&lt;i&gt;et al&lt;/i&gt;.Fast morphology measurement based on the binocular vision and speckle projection[J].Laser &amp;amp; Infrared,2016,46(12):1517-1520.张扣文,梁晋,尤威,等.基于双目视觉和散斑投射的快速形貌测量[J].激光与红外,2016,46(12):1517-1520.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" Hang C,Yan Q.Structural surface topography measurement based on projection speckle method[J].Science Technology and Engineering,2018,18(19):230-236.杭超,燕群.基于投影散斑的结构表面形貌测量[J].科学技术与工程,2018,18(19):230-236." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201819036&amp;v=MTg1MDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnlybVZMck9MalhCZmJHNEg5bk5wbzlHWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Hang C,Yan Q.Structural surface topography measurement based on projection speckle method[J].Science Technology and Engineering,2018,18(19):230-236.杭超,燕群.基于投影散斑的结构表面形貌测量[J].科学技术与工程,2018,18(19):230-236.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" Zhong F,Quan C.Digital image correlation in polar coordinate robust to a large rotation[J].Optics and Lasers in Engineering,2017,98:153-158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4BF119BE0A633F9157CAE0AF44E61513&amp;v=MDkzNzZ4cnU0eGE0PU5pZk9mYmZLYU5ETnB2MHdaSm9KRDM5UHhoY1c3VXdNUFgrVDJoWXhETFNWUUx1Y0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRsaA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Zhong F,Quan C.Digital image correlation in polar coordinate robust to a large rotation[J].Optics and Lasers in Engineering,2017,98:153-158.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" LePage W S,Shaw J A,Daly S H.Optimum paint sequence for speckle patterns in digital image correlation[J].Experimental Techniques,2017,41(5):557-563." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimum paint sequence for speckle patterns in digital image correlation">
                                        <b>[14]</b>
                                         LePage W S,Shaw J A,Daly S H.Optimum paint sequence for speckle patterns in digital image correlation[J].Experimental Techniques,2017,41(5):557-563.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" Ye N,Zhang L Y.Improved fractionized displacement transfer algorithm based on digital image correlation in large deformation applications[J].Acta Optica Sinica,2010,30(4):976-983.叶南,张丽艳.大变形下基于数字图像相关的改进分段位移传递法[J].光学学报,2010,30(4):976-983." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201004018&amp;v=MDQyMzlHRnJDVVJMT2VaZVZ2RnlybVZMck9JalhUYkxHNEg5SE1xNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Ye N,Zhang L Y.Improved fractionized displacement transfer algorithm based on digital image correlation in large deformation applications[J].Acta Optica Sinica,2010,30(4):976-983.叶南,张丽艳.大变形下基于数字图像相关的改进分段位移传递法[J].光学学报,2010,30(4):976-983.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" Ye N,Zhang L Y.Key techniques and system of sheet metal forming limit strain measurement based on stereo vision[J].Acta Aeronautica et Astronautica Sinica,2010,31(10):2093-2102.叶南,张丽艳.基于立体视觉的板料成形极限应变测量关键技术及其系统[J].航空学报,2010,31(10):2093-2102." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKXB201010025&amp;v=MDUzMjZPZVplVnZGeXJtVkxyT0xTYlRiTEc0SDlITnI0OUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Ye N,Zhang L Y.Key techniques and system of sheet metal forming limit strain measurement based on stereo vision[J].Acta Aeronautica et Astronautica Sinica,2010,31(10):2093-2102.叶南,张丽艳.基于立体视觉的板料成形极限应变测量关键技术及其系统[J].航空学报,2010,31(10):2093-2102.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_17" title=" Furukawa Y,Ponce J.Accurate,dense,and robust multiview stereopsis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(8):1362-1376." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate, dense, and robust multiview stereopsis">
                                        <b>[17]</b>
                                         Furukawa Y,Ponce J.Accurate,dense,and robust multiview stereopsis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(8):1362-1376.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_18" title=" Schonberger J L,Frahm J M.Structure-from-motion revisited[C]∥2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),June 27-30,2016,Las Vegas,NV,USA.New York:IEEE,2016:4104-4113." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structure-from-motion revisited">
                                        <b>[18]</b>
                                         Schonberger J L,Frahm J M.Structure-from-motion revisited[C]∥2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),June 27-30,2016,Las Vegas,NV,USA.New York:IEEE,2016:4104-4113.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_19" title=" Snavely N.Bundler:Structure from Motion (SfM) for Unordered Image Collections[DB/OL].[2019-03-22].http://www.cs.cornell.edu/～snavely/bundler/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bundler:Structure from Motion (SfM) for Unordered Image Collections">
                                        <b>[19]</b>
                                         Snavely N.Bundler:Structure from Motion (SfM) for Unordered Image Collections[DB/OL].[2019-03-22].http://www.cs.cornell.edu/～snavely/bundler/.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_20" title=" Wu C C.VisualSFM:a visual structure from motion system[DB/OL].[2019-03-22].http://ccwu.me/vsfm/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VisualSFM:a visual structure from motion system">
                                        <b>[20]</b>
                                         Wu C C.VisualSFM:a visual structure from motion system[DB/OL].[2019-03-22].http://ccwu.me/vsfm/.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_21" title=" Moulon P,Monasse P,Perrot R,&lt;i&gt;et al&lt;/i&gt;.OpenMVG:open multiple view geometry[M]∥Kerautret B,Colom M,Monasse P.Reproducible research in pattern recognition.Lecture notes in computer science.Cham:Springer,2017,10214:60-74." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OpenMVG:open multiple view geometry">
                                        <b>[21]</b>
                                         Moulon P,Monasse P,Perrot R,&lt;i&gt;et al&lt;/i&gt;.OpenMVG:open multiple view geometry[M]∥Kerautret B,Colom M,Monasse P.Reproducible research in pattern recognition.Lecture notes in computer science.Cham:Springer,2017,10214:60-74.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-07-01 09:35</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(10),227-236 DOI:10.3788/AOS201939.1015002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>无编码点的工业摄影测量技术的研究及实现</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%A5%E4%BF%8A&amp;code=08730400&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">严俊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B6%E5%8D%97&amp;code=24358205&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">叶南</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%BB%B7%E6%88%90&amp;code=42454113&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李廷成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A5%9D%E9%B8%BF%E5%AE%87&amp;code=42454114&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">祝鸿宇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%A4%A7%E5%AD%A6%E6%9C%BA%E7%94%B5%E5%AD%A6%E9%99%A2&amp;code=0014291&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京航空航天大学机电学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的工业摄影测量系统通常需要在被测物表面布设一定数量的编码点,但是许多工业产品表面并不具备布设编码点的条件。为此,提出一种无需布设编码点的工业摄影测量的实现方法。该方法只需利用一台向被测物投射散斑纹理的投射装置、一把恢复尺度的标尺,以及一台能对被测物体多角度拍摄的相机。为了完成高精度的多视图几何框架的求解,采用一种“由粗到精”的两步重建策略,并提出一种带旋转补偿的数字图像相关(RFDIC)方法来解决大旋转角度图像间的高精度匹配问题。实验结果表明,RFDIC方法对标尺长度测量的误差小于0.01 mm/m,与最新商用的三维测量系统点云重建算法相比,二者的误差约为0.055 mm,满足工业摄影测量的精度要求。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E7%BC%96%E7%A0%81%E7%82%B9%E6%91%84%E5%BD%B1%E6%B5%8B%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无编码点摄影测量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8A%95%E5%BD%B1%E6%95%A3%E6%96%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">投影散斑;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E7%9B%B8%E5%85%B3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数字图像相关;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多视图几何;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *叶南,E-mail:yen@nuaa.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(51605222);</span>
                                <span>江苏省基础研究计划(BK20160799);</span>
                                <span>上海航天科技创新基金资助项目;</span>
                    </p>
            </div>
                    <h1><b>Research and Implementation of Industrial Photogrammetry Without Coded Points</b></h1>
                    <h2>
                    <span>Yan Jun</span>
                    <span>Ye Nan</span>
                    <span>Li Tingcheng</span>
                    <span>Zhu Hongyu</span>
            </h2>
                    <h2>
                    <span>College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Placing a certain number of coded points is generally required in the current industrial photogrammetry system. However, many industrial products are not suitable for the arrangement of coded points. This study proposes a novel method of industrial photogrammetry without using coded points. Our method only requires a projection device to project the speckle texture, a scale bar to recover scale, and a multi-angle camera to capture various images of the measured object. A “coarse-to-fine” two-step reconstruction strategy is devised to solve the multi-view geometry with high precision. Moreover, a rotation-free digital image correlation(RFDIC) method is proposed for high-accuracy point-matching between images with large rotational angles. The experimental results verify that the error in measuring the length of scale bar by the RFDIC method is below 0.01 mm/m and the error of the RFDIC method compared with that of the latest commercial point cloud construction method for three dimensional measurement system can reach approximately 0.055 mm, which satisfies the precision requirements of industrial photogrammetry.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=photogrammetry%20without%20coded%20points&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">photogrammetry without coded points;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=projected%20speckle&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">projected speckle;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=digital%20image%20correlation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">digital image correlation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-view%20geometry&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-view geometry;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="52" name="52" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="53">工业摄影测量在航空航天、机械制造、零件装配、产品外形检测等方面有着广泛的应用<citation id="135" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在利用单相机围绕被测物体进行自由拍摄的过程中,通常需要借助计算机视觉的相关理论知识来完成各次拍摄时相机位姿的求解和目标点三维重建。在构建多视图几何结构<citation id="136" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的方法上,大部分的工业摄影测量系统都需要事先在被测物表面布设特征明显的标志物(编码点)<citation id="137" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,并需要根据图像上提取出的特征中心点来建立多图的同名匹配点信息。工业零件表面的色泽一般较为单一,缺乏丰富的特征信息。编码点则可以提供易于识别的视觉标志物,且编码点具有规则化的几何图形,便于提取出精确的图像特征点,从而完成高精度的多视图几何结构的求解。然而,在物体表面布设编码点比较耗时、繁琐,尤其当被测物是飞机蒙皮之类的大型复杂的产品零件时,所需的编码点数量可能多达上百个。此外,有些零件表面不允许粘贴标记点或不具备布点条件,例如,非铁磁性的金属材料无法使用磁吸附式的编码标志物,只能依靠粘贴的方式来固定编码点,这可能对高精度的零件表面造成破坏。</p>
                </div>
                <div class="p1">
                    <p id="54">目前学术界有大量的学者在研究利用物体自身特征信息求解多视图几何结构的方法,但他们的研究对象主要集中在室外场景,如城市建筑或名胜古迹等。Agarwal等<citation id="138" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>利用互联网上搜集得到的大量罗马建筑的照片,进行城市规模的三维模型重建。重建的首要步骤就是根据图像上的特征信息构建多视图几何结构,求解出每幅图像拍摄时相机的内外参数。由于建筑表面的纹理信息较为丰富,故可利用SIFT(Scale-Invariant Feature Transform)<citation id="139" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、SURF(Speeded up Robust Features)<citation id="140" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等特征描述一致性较强的算子来提取图像上的特征点。虽然上述特征算子可以方便、快速地提取出图像上的同名匹配点,但其匹配精度还无法达到工业编码点提取精度的水准,导致多视图几何结构求解的精度无法达到摄影测量的精度要求。因此,上述方法只能用于对精度要求不高的室外建筑等场景的三维模型重建。</p>
                </div>
                <div class="p1">
                    <p id="55">近年来,随着投射散斑技术的出现和数字图像相关(DIC)法<citation id="143" type="reference"><link href="22" rel="bibliography" /><link href="24" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>的日趋成熟,利用投影装置人为地给物体表面添加散斑纹理信息,并采用DIC算法计算图像上的匹配点可重建出高精度的稠密点云。该方法被逐渐应用于三维测量领域当中<citation id="144" type="reference"><link href="26" rel="bibliography" /><link href="28" rel="bibliography" /><link href="30" rel="bibliography" /><link href="32" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。借助散斑纹理和DIC匹配技术可以建立高精度的图像匹配点,然而传统的DIC算法在进行大旋转图像间的匹配计算时不可避免地会产生退相关效应<citation id="141" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>,导致匹配点计算失败。虽然不少学者指出,基于Patch的匹配方法<citation id="142" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>不受图像间旋转角度的影响,但是该方法依赖于事先已有的三维模型和精确的相机内外参数。</p>
                </div>
                <div class="p1">
                    <p id="56">针对上述问题,本文提出了一种无编码点的工业摄影测量技术实现方法。该方法只需利用纹理投射装置将散斑纹理投射至被测物表面,并在视野范围内放置数把标尺,然后采用单相机围绕被测物体进行自由拍摄即可求解出拍摄场景的多视图几何结构。对于建立图像间高精度匹配点,提出了一种带旋转补偿的DIC(RFDIC)匹配方法,以解决大旋转图像间的像点匹配问题。通过进行前后两次“由粗到精”的相机位姿求解,该方法可以完成高精度的多视图结构重建。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">2 技术总体方案</h3>
                <div class="p1">
                    <p id="58">无编码点工业摄影测量方式如图1所示,使用到的硬件设备有纹理投射装置、单反相机和工业标尺。利用一个或多个纹理投射装置向被测物投射散斑纹理,保证投射的纹理覆盖整个被测物体的表面,利用单反相机围绕被测物进行全局拍摄。拍摄的过程中需要保持被测物体表面的散斑纹理不发生变化,即保持投射装置与被测物绝对静止。拍摄过程中,要让相机在不同的位置以不同的姿态进行多角度自由拍摄,并确保图像之间存在部分重叠区域。被测物体旁放置的标尺是用于对重建出的结构进行尺度恢复的,故同样需要将拍摄标尺上的定位标记点至图像里。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 无编码点摄影测量方法示意图" src="Detail/GetImg?filename=images/GXXB201910027_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 无编码点摄影测量方法示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Schematic of photogrammetry without coded points</p>

                </div>
                <div class="p1">
                    <p id="60">无编码点的多视图几何结构重建的总体技术路线如图2所示。在向被测物投射散斑纹理后,利用SIFT算子结合SFM(Structure from Motion)获取粗略的重建结果。此后,再利用DIC匹配算法结合SFM获取精确的重建结果。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 无编码点重建多视图结构的技术路线" src="Detail/GetImg?filename=images/GXXB201910027_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 无编码点重建多视图结构的技术路线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Process of multi-view structure reconstruction without coded points</p>

                </div>
                <h3 id="62" name="62" class="anchor-tag">3 投影散斑纹理生成算法</h3>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 数字散斑图案生成算法设计</b></h4>
                <div class="p1">
                    <p id="64">大部分文献资料是针对喷涂散斑纹理的特征对DIC算法的匹配精度、稳健性、效率等方面的影响进行研究,极少对投射散斑纹理的特性进行详细研究。例如在文献<citation id="145" type="reference">[<a class="sup">14</a>]</citation>中,作者比较了黑色底纹、白色斑点的散斑和白色底纹、黑色斑点的散斑对DIC匹配成功率的影响。该文献给出的结论是白色底纹、黑色斑点的散斑纹理更适合DIC算法。</p>
                </div>
                <div class="p1">
                    <p id="65">借鉴喷涂散斑步骤的思路,本文提出一种具有可调控性的散斑纹理生成算法。该算法可对散斑纹理的模式包括散斑颗粒的大小、占空比和灰度3个参数进行调控,以满足不同场景下对具体纹理特性的要求。生成一张质量较好的数字散斑图案同样需要两个步骤:生成底色背景和添加散斑颗粒。为了生成偏白色的底纹,将图像像素的灰度值设置在较高的值域范围内,并利用随机函数Rand()为每个大的像素块生成一个随机灰度值,即</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mtext>R</mtext><mtext>a</mtext><mtext>n</mtext><mtext>d</mtext><mo stretchy="false">(</mo><mi>g</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo>,</mo><mi>g</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">)</mo><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">式中:<i>g</i><sub><i>i</i></sub>表示每个像素块的灰度值;<i>g</i><sub>min</sub>和<i>g</i><sub>max</sub>分别表示设定灰度值的最小值和最大值。图3为由上述方法生成的一张数字散斑底纹图案,其中<i>g</i><sub>min</sub>设置为150,<i>g</i><sub>max</sub>设置为220。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 数字散斑图案的白色底纹" src="Detail/GetImg?filename=images/GXXB201910027_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 数字散斑图案的白色底纹  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 White basecoat of digital speckle pattern</p>

                </div>
                <div class="p1">
                    <p id="69">为了增加散斑图案纹理的随机性,在生成散斑颗粒时要体现出颗粒形状的随机性。因此,在生成随机形状的颗粒时采用了随机生长法。随机生长法可让单个像素点在一个半径大小可变的圆形区域内生长。在每次判断像素点是否生长到区域边界时,用随机数去设置该区域的半径大小,从而可以得到形状随机的散斑颗粒。该算法的伪代码如图4所示,该算法生成得到的随机形状的散斑颗粒图案如图5所示。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 散斑颗粒随机生长法伪代码" src="Detail/GetImg?filename=images/GXXB201910027_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 散斑颗粒随机生长法伪代码  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Pseudocode of random growth method 
of speckle particle</p>

                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 随机形状的散斑颗粒" src="Detail/GetImg?filename=images/GXXB201910027_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 随机形状的散斑颗粒  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Speckle particles with random shapes</p>

                </div>
                <div class="p1">
                    <p id="72">由于投影光照强度、被测物表面反射率及相机分辨率等因素对散斑特征的要求均不一样,因此利用不同半径、占空比和灰度的散斑颗粒对本文提出的散斑生成算法进行对比验证,验证结果如图6～8所示。图6为不同颗粒半径下生成的散斑图案,图7为不同散斑占空比下生成的散斑图案,图8为不同灰度下的散斑颗粒生成的散斑图案。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同散斑颗粒半径下的散斑图案。" src="Detail/GetImg?filename=images/GXXB201910027_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同散斑颗粒半径下的散斑图案。   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Speckle patterns with different sizes of speckle 
particles. </p>
                                <p class="img_note">(a) 5～8 pixel; 
(b) 9～12 pixel; (c) 13～20 pixel</p>
                                <p class="img_note">(a) 5-8 pixel; (b) 9-12 pixel; (c) 13-20 pixel</p>

                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同散斑占空比下的散斑图案。" src="Detail/GetImg?filename=images/GXXB201910027_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同散斑占空比下的散斑图案。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Speckle patterns with different proportions of 
speckle particles. </p>
                                <p class="img_note">(a) 20%; 
(b) 40%; (c) 60%</p>
                                <p class="img_note">(a) 20%; (b) 40%; (c) 60%</p>

                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同灰度范围(0～255)下的散斑颗粒生成的散斑图案。" src="Detail/GetImg?filename=images/GXXB201910027_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同灰度范围(0～255)下的散斑颗粒生成的散斑图案。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Speckle patterns with different grayscale ranges (0-255) 
of speckle particles. </p>
                                <p class="img_note">(a) 40～100; (b) 20～80; (c) 0～60</p>
                                <p class="img_note">(a) 40-100; (b) 20-80; (c) 0-60</p>

                </div>
                <h4 class="anchor-tag" id="76" name="76"><b>3.2 投影散斑的匹配验证</b></h4>
                <div class="p1">
                    <p id="77">在得到散斑图案后,对投射出的散斑纹理进行DIC匹配验证。采用的DIC匹配算法为基于N-R(Newton-Raphson)算法<citation id="146" type="reference"><link href="38" rel="bibliography" /><link href="40" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>迭代求解的数字图像相关法,该算法以ZNCC(Zero Normalized Cross Correlation)系数作为评价图像子区的相关准则。ZNCC系数越接近于1,表示图像子区的相似程度越高,子区中心点的匹配精度也越高。</p>
                </div>
                <div class="p1">
                    <p id="78">利用影像投影仪将散斑纹理投射到弯曲的白纸表面,并使用双目CCD相机进行图像采集。使用上述的DIC算法计算左右图像的对应匹配像点,匹配结果如图9所示。图9中的白点即为左右图像的对应匹配点,匹配点的ZNCC系数平均在0.99以上。该结果验证了上述数字散斑纹理生成算法的有效性。</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 投影散斑的DIC匹配结果。" src="Detail/GetImg?filename=images/GXXB201910027_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 投影散斑的DIC匹配结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 DIC matching results of projected speckles. </p>
                                <p class="img_note">(a)左图像;(b)右图像</p>
                                <p class="img_note">(aa Left image; (b) right image</p>

                </div>
                <h3 id="80" name="80" class="anchor-tag">4 无编码点的多视图几何结构求解方法</h3>
                <h4 class="anchor-tag" id="81" name="81"><b>4.1 大旋转图像的DIC退相关效应</b></h4>
                <div class="p1">
                    <p id="82">传统DIC算法虽然能够精确、快速地计算图像上的匹配点,但是当图像在相机光轴方向上产生较大的旋转角度时,DIC算法往往会出现退相关效应,导致误匹配率升高、匹配精度和质量下降。当两幅图像之间的旋转角度达到30°时,待匹配图像上开始出现大量的误匹配点,如图10所示,此时ZNCC系数下降到了0.90以下。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 大旋转角度下图像的DIC误匹配问题。" src="Detail/GetImg?filename=images/GXXB201910027_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 大旋转角度下图像的DIC误匹配问题。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Mismatching problem of DIC between images with large rotation angle. </p>
                                <p class="img_note">(a)左图像;(b)右图像</p>
                                <p class="img_note">(a) Left image; (b) right image</p>

                </div>
                <div class="p1">
                    <p id="84">工业摄影测量首先需要使用单相机对被测物进行自由拍照,那么相机在自由拍摄的过程中必然会使得不同图像间产生较大的旋转角度。因此,在建立图像点之间的匹配关系的方法上,传统的DIC方法不再适用。此时就需要寻求一种不受图像旋转角度限制的匹配方法来精确地计算图像之间的匹配点。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>4.2 带旋转补偿的RFDIC匹配方法</b></h4>
                <div class="p1">
                    <p id="86">虽然DIC方法采用的一阶或二阶位移模式可以表达图像子区之间的旋转,但是该旋转仅限于局部子区的小角度旋转。如果图像在光轴的方向上发生了较大角度的旋转,图像子区间的位移模式则无法表达图像整体的旋转角度。当位移模式不足以表达图像之间的形变模型时,退相关效应就会出现,导致匹配计算失败。</p>
                </div>
                <div class="p1">
                    <p id="87">本研究提出了一种带旋转补偿的RFDIC匹配方法,用于解决大旋转图像间的像点匹配问题。该方法的思路如下:1)将旋转角度较大的待匹配图像通过仿射变换校正过来,使其成为沿光轴方向无大旋转角度的图像;2)对参考图像和校正后的图像施加DIC运算,寻找二者之间的匹配点;3)根据仿射变换的逆变换求出待匹配图像与参考图像间对应的匹配点。这样就可以解决旋转角度较大的图像之间的匹配问题。一般来说,校正后的图像需要进行灰度插值,但是灰度插值会造成图像失真,影响DIC匹配的精度。因此,在使用DIC匹配时,并没有直接使用校正后的图像灰度进行ZNCC系数的计算,而是将待匹配图像子区内的每个匹配点坐标通过仿射变换转换到校正后的图像坐标系下,再将其代入DIC的一阶位移模式当中参与优化求解。校正后图像坐标系下的图像点对应的灰度值依然通过待匹配图像进行求取,以计算ZNCC相关系数。</p>
                </div>
                <div class="p1">
                    <p id="88">如图11所示,假设左右两幅图像<i>I</i><sub>0</sub>和<i>I</i><sub>1</sub>之间存在较大的旋转角度,<i>p</i><sub><i>I</i></sub><sub>0</sub>(<i>x</i><sub>0</sub>,<i>y</i><sub>0</sub>)为参考图像子区<i>S</i><sub>0</sub>上的中心点,<i>p</i><sub><i>I</i></sub><sub>1</sub>(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>)为待匹配图像子区<i>S</i><sub>1</sub>上对应的待匹配点。<i>I</i><sub>0</sub>和<i>I</i><sub>1</sub>对应的相机内参矩阵为<i><b>K</b></i>,相机之间的旋转变换矩阵为<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msubsup></mrow></math></mathml><i><b>R</b></i>,其中,<i>C</i><sub>0</sub>表示参考图像<i>I</i><sub>0</sub>所在的相机坐标系{<i>C</i><sub>0</sub>},<i>C</i><sub>1</sub>表示待匹配图像<i>I</i><sub>1</sub>所在的相机坐标系{<i>C</i><sub>1</sub>}。<sup><i>C</i></sup><sub><sup>1</sup></sub><sub><i>C</i></sub><sub>0</sub><i><b>R</b></i>表示{<i>C</i><sub>0</sub>}坐标系下的三维点变换到{<i>C</i><sub>1</sub>}坐标系下的旋转变换矩阵。由于<i>I</i><sub>0</sub>和<i>I</i><sub>1</sub>之间存在较大的旋转角度,直接根据DIC方法建立两者之间准确的匹配关系较为困难。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 RFDIC匹配策略" src="Detail/GetImg?filename=images/GXXB201910027_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 RFDIC匹配策略  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Matching strategy of RFDIC</p>

                </div>
                <div class="p1">
                    <p id="90">RFDIC方法的具体计算步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="91">1)对<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msubsup></mrow></math></mathml><i><b>R</b></i>进行欧拉角分解,即<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msubsup></mrow></math></mathml><i><b>R</b></i>=<i><b>R</b></i>(<i>θ</i><sub><i>z</i></sub>)·<i><b>R</b></i>(<i>θ</i><sub><i>y</i></sub>)·<i><b>R</b></i>(<i>θ</i><sub><i>x</i></sub>),其中,<i>θ</i><sub><i>x</i></sub>,<i>θ</i><sub><i>y</i></sub>和<i>θ</i><sub><i>z</i></sub>分别为按顺序绕{<i>C</i><sub>0</sub>}的<i>x</i>轴、<i>y</i>轴和<i>z</i>轴的旋转角度。因此,<i>θ</i><sub><i>z</i></sub>可视为图像<i>I</i><sub>0</sub>和<i>I</i><sub>1</sub>之间绕主点坐标的面内旋转角度,主点坐标可从相机内参<i><b>K</b></i>的主点坐标(<i>u</i><sub>0</sub>,<i>v</i><sub>0</sub>)获得。绕主点坐标的面内旋转可表达为在<i>I</i><sub>1</sub>图像坐标系下的仿射变换矩阵<i><b>A</b></i>,其计算公式为</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>α</mi></mtd><mtd><mi>β</mi></mtd><mtd><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>β</mi><mo>⋅</mo><mi>v</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd><mo>-</mo><mi>β</mi></mtd><mtd><mi>α</mi></mtd><mtd><mi>β</mi><mo>⋅</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>v</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">式中:<i>α</i>=cos <i>θ</i><sub><i>z</i></sub>,<i>β</i>=sin <i>θ</i><sub><i>z</i></sub>。利用仿射变换矩阵<i><b>A</b></i>可将图像<i>I</i><sub>1</sub>校正为无旋转角度的图像<i>I</i>′<sub>1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="94">2)在图像<i>I</i>′<sub>1</sub>上使用DIC算法计算相应的匹配点。此时,图像<i>I</i>′<sub>1</sub>和<i>I</i><sub>0</sub>之间的旋转角度极小,可使用DIC方法来计算<i>p</i><sub><i>I</i></sub><sub>0</sub>(<i>x</i><sub>0</sub>,<i>y</i><sub>0</sub>)对应的匹配点<i>p</i><sub><i>I</i></sub><sub>′1</sub>的图像坐标(<i>x</i>′<sub>1</sub>,<i>y</i>′<sub>1</sub>)。因为待匹配图像具有原始的灰度分布,校正过后的图像灰度值是经过插值计算得到的,其值会有一定的灰阶损失,从而影响匹配精度,所以在DIC求解的过程中需以待匹配图像<i>I</i><sub>1</sub>的灰度值代替校正后的图像<i>I</i>′<sub>1</sub>对应像素点的灰度值。经过DIC迭代求解过后的<i>p</i><sub><i>I</i></sub><sub>′1</sub>的图像坐标(<i>x</i>′<sub>1</sub>,<i>y</i>′<sub>1</sub>)为<i>x</i>′<sub>1</sub>=<i>x</i><sub>0</sub>+<i>u</i>,<i>y</i>′<sub>1</sub>=<i>y</i><sub>0</sub>+<i>v</i>,其中,(<i>u</i>,<i>v</i>)为参考图像子区中心到校正后图像子区中心的偏移量。</p>
                </div>
                <div class="p1">
                    <p id="95">3)根据仿射变换矩阵<i><b>A</b></i>的逆变换<i><b>A</b></i><sup>-1</sup>计算出<i>I</i><sub>1</sub>的对应图像点<i>p</i><sub>I1</sub>(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),该过程的表达式为</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>⋅</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">Furukawa等<citation id="147" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>基于Patch的空间切平面模型实现了多视图稠密点云的精确重建,可有效地解决大视觉变形的图像匹配问题。为了验证本文提出的RFDIC方法的精度和效率,将其与基于Patch的匹配方法(Patch Matching Method)进行对比。利用双目CCD相机采集散斑纹理图案,获得一对匹配图像。该双目相机的内外参数通过事先标定计算得到。在相同的参考图像上选择相同的图像区域和相同的种子点,将图像子区的边界点和生长步长均设置为相同的值,分别使用上述两种方法在同样的待匹配图像上寻找待匹配点,匹配结果如图12和表1所示。从表1可见,两种方法的匹配率均达到100%,且相关系数都保持在0.99以上,呈现出高质量的匹配,因此两种方法的匹配精度是一致的。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 RFDIC和Patch Matching方法的匹配结果。" src="Detail/GetImg?filename=images/GXXB201910027_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 <i>RFDIC</i>和<i>Patch Matching</i>方法的匹配结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 12 <i>Matching results of RFDIC and Patch Matching methods</i>. </p>
                                <p class="img_note">(a) 参考图像;(b) RFDIC方法;(c) Patch Matching方法</p>
                                <p class="img_note">(a) Reference image; 
(b) RFDIC method; (c) Patch Matching method</p>

                </div>
                <div class="area_img" id="99">
                    <p class="img_tit">表1 <i>RFDIC</i>方法和<i>Patch Matching</i>方法匹配结果的对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Table</i> 1 <i>Comparison of matching results between</i><i>RFDIC and Patch Matching methods</i></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td><i>Algorithm</i></td><td><i>Number of</i><br /><i>matching point</i></td><td><i>Matching</i><br /><i>rate</i> /%</td><td><i>Correlation</i><br /><i>coefficient</i></td></tr><tr><td><br /><i>RFDIC</i></td><td>3142</td><td>100</td><td>&gt;0.99</td></tr><tr><td><br /><i>Patch Matching</i></td><td>3142</td><td>100</td><td>&gt;0.99</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">对匹配点进行三维重建,<i>RFDIC</i>方法和<i>Patch Matching</i>方法的结果如表2所示。结果显示,两种匹配方法重建出同样的空间三维点的平均误差约为0.055 <i>mm</i>,但在运行效率上,<i>RFDIC</i>方法的运算速度明显比<i>Patch Matching</i>方法的快。</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit">表2 <i>RFDIC</i>方法和<i>Patch Matching</i>方法重建的运行时间和点云误差对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Table</i> 2 <i>Comparison of running time and point cloud error</i><i>between RFDIC and Patch Matching methods</i></p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td colspan="2"><br /><i>Running time</i>/<i>s</i></td><td rowspan="2"><i>Average</i><br /><i>error</i> /<i>mm</i></td><td rowspan="2"><i>Standard</i><br /><i>deviation</i> /<i>mm</i></td></tr><tr><td><br /><i>RFDIC</i></td><td><i>Patch Matching</i></td></tr><tr><td>1.67</td><td>71.15</td><td>0.0548</td><td>0.0096</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>4.3 多视图几何结构求解策略</b></h4>
                <div class="p1">
                    <p id="103">RFDIC匹配方法需要利用已有的相机内参及位姿信息。但是,对于本文所采用的单相机自由拍照的方式来说,相机的内外参数是未知的,并且根据文献<citation id="148" type="reference">[<a class="sup">15</a>]</citation>可知,利用DIC算法计算高精度匹配点需要给定一对初始匹配点,而通过人工选取初始匹配点显然不合适。因此,利用RFDIC方法一次性完成多视图结构的高精度重建是非常困难的。本文采用的做法是将这一过程分为2个步骤:1)利用SIFT或SURF等描述算子提取图像的匹配点,并采用增量式的SFM重建算法<citation id="149" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>完成相机位姿的初始求解。此时可以建立出一个完整的多视图几何结构,但精度还不能达到工业摄影测量的要求。2)根据已有的初始匹配点和相机内外参数信息,采用本文提出的RFDIC方法计算高精度的匹配像点,并进行第二次精确的多视图几何框架求解。在完成上述2个步骤以后,根据标尺长度对整体重建的结构进行尺度恢复。本文提出的“由粗到精”多视图几何结构的两步重建算法伪代码如图13所示。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 无编码点的多视图几何重建算法伪代码" src="Detail/GetImg?filename=images/GXXB201910027_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 无编码点的多视图几何重建算法伪代码  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 13 Pseudocode of multi-view geometry 
reconstruction without coded points</p>

                </div>
                <h3 id="105" name="105" class="anchor-tag">5 无编码点工业摄影测量技术的实验验证</h3>
                <div class="p1">
                    <p id="106">为了验证本文提出的无编码点的工业摄影测量技术的有效性和求解精度,以飞机蒙皮零件为研究对象进行相关的实验验证。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>5.1 实验方案设计</b></h4>
                <div class="p1">
                    <p id="108">本实验所选用的工业零件为飞机蒙皮钣金件,如图14所示,该零件的空间尺寸约为1.75 m×1.03 m。</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图14 飞机蒙皮钣金件" src="Detail/GetImg?filename=images/GXXB201910027_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图14 飞机蒙皮钣金件  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 14 Sheet metal of aircraft skin</p>

                </div>
                <div class="p1">
                    <p id="110">本实验采用的纹理投射装置为明基PL755C型号的影像投影仪,该投影仪采用了数字光处理(DLP)投影技术,投影的散斑图案分辨率为1920 pixel×1080 pixel,传感器采用互补金属氧化物半导体(COMS)。用于图像采集的单反相机为Nikon D7100,相机镜头为焦距24 mm的定焦镜头,像素物理尺寸为3.9 μm,相机分辨率为6000 pixel×4000 pixel。</p>
                </div>
                <div class="p1">
                    <p id="111">测量方案如下:在零件两旁放置两把绝对长度已知的标尺,一把标尺用于恢复多视图结构的尺度,另一把用于验证重建精度,两把标尺之间的距离约为1.5 m。采用单反相机围绕蒙皮凹侧一面以不同的位置和姿态自由拍摄共16张照片,实验场景如图15所示。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图15 无编码点摄影测量实验场景" src="Detail/GetImg?filename=images/GXXB201910027_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图15 无编码点摄影测量实验场景  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 15 Experimental scene of photogrammetry 
without coded points</p>

                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>5.2 多视图几何结构重建精度验证</b></h4>
                <div class="p1">
                    <p id="114">目前关于多视图几何的研究已经十分成熟,学者们建立了许多成熟的开源算法库,例如:Snavely<citation id="150" type="reference"><link href="46" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>开发的Bundler、Wu<citation id="151" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>开发的VisualSFM、Moulon等<citation id="152" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>开发的OpenMVG开源多视角立体几何库等。由于OpenMVG算法功能齐全,可扩展性强,易于使用并且算法稳定,可满足工业摄影测量技术对算法稳定性和算法执行效率等要求,因此本研究以OpenMVG算法库作为多视图几何框架求解的系统,以此来建立多视图几何结构。</p>
                </div>
                <div class="p1">
                    <p id="115">根据上述步骤,首先使用SIFT算子建立图像间的初始匹配点,其次利用OpenMVG的增量式重建算法求解相机的初始位姿信息,然后再次使用RFDIC方法计算图像间的高精度匹配点,并完成第二次多视图结构的重建,最终重建出的稀疏点云和相机中心位置如图16所示,前后两次重建的重投影的均值和标准误差(RMSE)如表3所示。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图16 无编码点摄影测量重建的多视图结构" src="Detail/GetImg?filename=images/GXXB201910027_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图16 无编码点摄影测量重建的多视图结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 16 Multi-view structure reconstructed by 
photogrammetry without coded points</p>

                </div>
                <div class="p1">
                    <p id="117">由表3中的结果可以看出,SIFT算子重建的初始结构的重投影平均误差为0.124 pixel,RFDIC算法重建的高精度结构的重投影的平均误差为0.053 pixel,可见二次投影重建的精度有了明显的提高。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit">表3 多视图结构的重投影的误差均值和标准误差 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Reprojection mean error and RMSE of multi-view structure</p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />Method</td><td>Average error /pixel</td><td>RMSE /pixel</td></tr><tr><td><br />SIFT</td><td>0.124</td><td>0.205</td></tr><tr><td><br />RFDIC</td><td>0.053</td><td>0.074</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="120">此外,还计算了传统的布设编码点方式求解的多视图结构的精度,并根据标尺长度的重建距离和误差来对比三种方法的求解精度,对比结果如表4所示。</p>
                </div>
                <div class="p1">
                    <p id="121">由表4可知,基于SIFT算子建立匹配点的方式重建的标尺长度误差约为0.117 mm,该误差相对较大,且无法满足工业摄影测量的精度要求。基于RFDIC算法建立匹配点的方式重建的标尺长度误差下降到0.005 mm,与基于布设编码点的方式重建的标尺长度误差(约为0.004 mm)水平相当,二者均达到了工业摄影测量的精度要求。</p>
                </div>
                <div class="area_img" id="122">
                    <p class="img_tit">表4 标尺长度的重建结果及误差对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Reconstruction results and error comparison of scale bars’ length</p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td>Method</td><td>Scale bar to <br />recover scale</td><td>Scale bar to <br />be verified</td><td>Standard <br />distance /mm</td><td>Reconstructed <br />distance /mm</td><td>Error /mm</td></tr><tr><td rowspan="2"><br />SIFT</td><td>1</td><td>2</td><td>860.916</td><td>860.799</td><td>-0.117</td></tr><tr><td><br />2</td><td>1</td><td>861.115</td><td>861.231</td><td>0.116</td></tr><tr><td rowspan="2"><br />Code points</td><td>1</td><td>2</td><td>860.916</td><td>860.912</td><td>-0.004</td></tr><tr><td><br />2</td><td>1</td><td>861.115</td><td>861.118</td><td>0.003</td></tr><tr><td rowspan="2"><br />RFDIC</td><td>1</td><td>2</td><td>860.916</td><td>860.921</td><td>0.005</td></tr><tr><td><br />2</td><td>1</td><td>861.115</td><td>861.110</td><td>-0.005</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>5.3 稠密点云重建精度验证</b></h4>
                <div class="p1">
                    <p id="124">基于本文提出的无编码点工业摄影测量技术,对上述飞机蒙皮表面进行稠密点云三维重建,并进行重建精度验证。在以上所有视图中挑选两张相机基线距离和拍摄角度较为合理、匹配点数据较为完整的视图进行两视图三维重建。利用RFDIC算法计算图像间的稠密匹配点,然后根据空间三角法<citation id="153" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>进行三维重建,重建出的稠密点云及三角网格化后的模型如图17所示。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图17 两视图重建的点云及三角网格模型" src="Detail/GetImg?filename=images/GXXB201910027_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图17 两视图重建的点云及三角网格模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 17 Point cloud and triangular mesh model 
reconstructed from two views</p>

                </div>
                <div class="p1">
                    <p id="126">将上述点云数据与德国GOM公司的光学三维测量设备(ATOS Compact 5M)测得的点云模型进行对比,对比误差的平均值及标准偏差如表5所示,点云的整体偏差示意图如图18所示。</p>
                </div>
                <div class="p1">
                    <p id="127">可以看出,本文提出的RFDIC算法重建的点云数据与商用的光学三维测量设备ATOS Compact 5M的平均偏差约为0.055 mm,这表明本文提出的RFDIC算法求解出的相机位姿能够满足工业三维测量的精度要求。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit">表5 两视图重建的点云偏差对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Comparison of point cloud deviations reconstructed from two views</p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td>Direction</td><td>Maximum /mm</td><td>Average /mm</td><td>Standard <br />deviation /mm</td></tr><tr><td>Negative</td><td>-0.4605</td><td>-0.0559</td><td>0.0475</td></tr><tr><td><br />Absolute</td><td>0.4605</td><td>0.0542</td><td>0.0464</td></tr><tr><td><br />Positive</td><td>0.4379</td><td>0.0521</td><td>0.0450</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910027_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图18 点云整体偏差示对比" src="Detail/GetImg?filename=images/GXXB201910027_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图18 点云整体偏差示对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910027_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 18 Comparison of overall deviation of point cloud</p>

                </div>
                <h3 id="130" name="130" class="anchor-tag">6 结  论</h3>
                <div class="p1">
                    <p id="131">提出了一种无需布设编码点的工业摄影测量的实现方法。为增强物体表面纹理信息,提出了一种具有可调控性的散斑纹理生成算法。采用SIFT或SURF匹配算子,初步建立多视图几何结构。为解决大旋转角度下传统DIC方法的退相关效应的问题,提出了一种不受旋转角度影响的RFDIC匹配方法。首先通过RFDIC方法获得高精度匹配点,再对多视图几何结构进行精确优化,最后通过已知距离的高精度标尺长度恢复几何尺度,从而形成一种无编码点的工业摄影测量方法,并将该方法用于高精度的相机位姿参数求解和物体表面三维点云重建。利用具体工业零件的摄影测量进行实验验证,本文所提出的方法对标尺的重建精度可达到0.01 mm/m,与目前最新的商用三维测量系统ATOS Compact 5M的点云测量偏差约为0.055 mm。与布设编码点方式的摄影测量技术相比,本文提出的方法可以节省大量繁琐的人工劳动,更适合工业现场的快速测量。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030464309000&amp;v=MDM4NjM4enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDcmtVNzNMSjFzU1hGcXpHYk83SHRYS3E0eEZiZXNQREJN&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Huang G P.Digital close range industry photogrammetry[M].Beijing:Science Press,2016.黄桂平.数字近景工业摄影测量理论、方法与应用[M].北京:科学出版社,2016.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple view geometry in computer vision">

                                <b>[2]</b> Hartley R,Zisserman A.Multiple view geometry in computer vision[M].Cambridge:Cambridge University Press,2003.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201312034&amp;v=MTE2NzVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5cm1WTHJPSWpYQlk3RzRIOUxOclk5R1lJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Song L M,Chen C M,Chen Z,<i>et al</i>.Detection and recognition of cyclic coded targets[J].Optics and Precision Engineering,2013,21(12):3239-3247.宋丽梅,陈昌曼,陈卓,等.环状编码标记点的检测与识别[J].光学精密工程,2013,21(12):3239-3247.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reconstructing Rome">

                                <b>[4]</b> Agarwal S,Furukawa Y,Snavley N,<i>et al</i>.Reconstructing Rome[J].Computer,2010,43(6):40-47.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDA2NzhveGNNSDdSN3FlYnVkdEZTbmxVYnpQSlZnPU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=MTAxNjdpclJkR2VycVFUTW53WmVadUh5am1VYjdJSWwwVGJ4UT1OaWZPZmJLN0h0RE5xbzlFWk9NTUJIUXhvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Bay H,Ess A,Tuytelaars T,<i>et al</i>.Speeded-up robust features (SURF)[J].Computer Vision and Image Understanding,2008,110(3):346-359.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001196855&amp;v=MjcxNjY5OVNYcVJyeG94Y01IN1I3cWVidWR0RlNubFVielBKVmc9Tmo3QmFyTzRIdEhOcm9aRGJPNEtZM2s1ekJkaDRq&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Bruck H A,McNeill S R,Sutton M A,<i>et al</i>.Digital image correlation using Newton-Raphson method of partial differential correction[J].Experimental Mechanics,1989,29(3):261-267.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011400063178&amp;v=Mjk1NzZieFE9TmlmT2ZiSzdIdEROcTQ5RlpPME1EWHN4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSWwwVA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Pan B,Li K.A fast digital image correlation method for deformation measurement[J].Optics and Lasers in Engineering,2011,49(7):841-847.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYLX200706002&amp;v=Mjk5Nzh0R0ZyQ1VSTE9lWmVWdkZ5cm1WTHJPTmpUSGRyRzRIdGJNcVk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Pan B,Xie H M,Li Y J.Three-dimensional digital image correlation method for shape and deformation measurement of an object surface[J].Journal of Experimental Mechanics,2007,22(6):556-567.潘兵,谢惠民,李艳杰.用于物体表面形貌和变形测量的三维数字图像相关方法[J].实验力学,2007,22(6):556-567.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13102400016220&amp;v=MTAyMTM0OUZaT29KRG40NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUlsMFRieFE9Tmo3QmFySzdIOUhPcQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Harvent J,Coudrin B,Brèthes L,<i>et al</i>.Multi-view dense 3D modelling of untextured objects from a moving projector-cameras system[J].Machine Vision and Applications,2013,24(8):1645-1659.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201612017&amp;v=MzAyNTQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5cm1WTHJPTHlyRGViRzRIOWZOclk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Zhang K W,Liang J,You W,<i>et al</i>.Fast morphology measurement based on the binocular vision and speckle projection[J].Laser &amp; Infrared,2016,46(12):1517-1520.张扣文,梁晋,尤威,等.基于双目视觉和散斑投射的快速形貌测量[J].激光与红外,2016,46(12):1517-1520.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201819036&amp;v=Mjg2MTBWdkZ5cm1WTHJPTGpYQmZiRzRIOW5OcG85R1lvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Hang C,Yan Q.Structural surface topography measurement based on projection speckle method[J].Science Technology and Engineering,2018,18(19):230-236.杭超,燕群.基于投影散斑的结构表面形貌测量[J].科学技术与工程,2018,18(19):230-236.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4BF119BE0A633F9157CAE0AF44E61513&amp;v=MTk1NjRJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkbGh4cnU0eGE0PU5pZk9mYmZLYU5ETnB2MHdaSm9KRDM5UHhoY1c3VXdNUFgrVDJoWXhETFNWUUx1Y0NPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Zhong F,Quan C.Digital image correlation in polar coordinate robust to a large rotation[J].Optics and Lasers in Engineering,2017,98:153-158.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimum paint sequence for speckle patterns in digital image correlation">

                                <b>[14]</b> LePage W S,Shaw J A,Daly S H.Optimum paint sequence for speckle patterns in digital image correlation[J].Experimental Techniques,2017,41(5):557-563.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201004018&amp;v=MTM4Njk5SE1xNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnlybVZMck9JalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Ye N,Zhang L Y.Improved fractionized displacement transfer algorithm based on digital image correlation in large deformation applications[J].Acta Optica Sinica,2010,30(4):976-983.叶南,张丽艳.大变形下基于数字图像相关的改进分段位移传递法[J].光学学报,2010,30(4):976-983.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKXB201010025&amp;v=MDk2OTdCdEdGckNVUkxPZVplVnZGeXJtVkxyT0xTYlRiTEc0SDlITnI0OUhZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Ye N,Zhang L Y.Key techniques and system of sheet metal forming limit strain measurement based on stereo vision[J].Acta Aeronautica et Astronautica Sinica,2010,31(10):2093-2102.叶南,张丽艳.基于立体视觉的板料成形极限应变测量关键技术及其系统[J].航空学报,2010,31(10):2093-2102.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate, dense, and robust multiview stereopsis">

                                <b>[17]</b> Furukawa Y,Ponce J.Accurate,dense,and robust multiview stereopsis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,32(8):1362-1376.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structure-from-motion revisited">

                                <b>[18]</b> Schonberger J L,Frahm J M.Structure-from-motion revisited[C]∥2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),June 27-30,2016,Las Vegas,NV,USA.New York:IEEE,2016:4104-4113.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bundler:Structure from Motion (SfM) for Unordered Image Collections">

                                <b>[19]</b> Snavely N.Bundler:Structure from Motion (SfM) for Unordered Image Collections[DB/OL].[2019-03-22].http://www.cs.cornell.edu/～snavely/bundler/.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VisualSFM:a visual structure from motion system">

                                <b>[20]</b> Wu C C.VisualSFM:a visual structure from motion system[DB/OL].[2019-03-22].http://ccwu.me/vsfm/.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OpenMVG:open multiple view geometry">

                                <b>[21]</b> Moulon P,Monasse P,Perrot R,<i>et al</i>.OpenMVG:open multiple view geometry[M]∥Kerautret B,Colom M,Monasse P.Reproducible research in pattern recognition.Lecture notes in computer science.Cham:Springer,2017,10214:60-74.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201910027" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910027&amp;v=MDg2NzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnlybVZMck9JalhUYkxHNEg5ak5yNDlIWTRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0NYeHlWeFdJdzdmQitCc1pzVVVuYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

