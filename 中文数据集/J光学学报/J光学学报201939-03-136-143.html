

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134135523565000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201903015%26RESULT%3d1%26SIGN%3d%252fQe6UgFjwq7txzCwbrGhWTBpinw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903015&amp;v=MjA4NzVtVjd2SklqWFRiTEc0SDlqTXJJOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#50" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="2 计算模型 ">2 计算模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="&lt;b&gt;2.1 计算模型&lt;/b&gt;"><b>2.1 计算模型</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;2.2 非经典感受野模型&lt;/b&gt;"><b>2.2 非经典感受野模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="3 抑制模型 ">3 抑制模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="4 分析与讨论 ">4 分析与讨论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="图1 抑制模型的权重模板">图1 抑制模型的权重模板</a></li>
                                                <li><a href="#110" data-title="图2 非经典感受野抑制过程">图2 非经典感受野抑制过程</a></li>
                                                <li><a href="#116" data-title="图3 不同算法下的提取轮廓">图3 不同算法下的提取轮廓</a></li>
                                                <li><a href="#117" data-title="表1 不同算法下的P值">表1 不同算法下的P值</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" &lt;i&gt;Hubel D H&lt;/i&gt;, &lt;i&gt;Wiesel T N&lt;/i&gt;. &lt;i&gt;Receptive fields of single neurones in the cat&lt;/i&gt;′&lt;i&gt;s striate cortex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;The Journal of Physiology&lt;/i&gt;, 1959, 148 (3) : 574-591." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Receptive fields of single neurons in the cat&amp;#39;s striate cortex">
                                        <b>[1]</b>
                                         &lt;i&gt;Hubel D H&lt;/i&gt;, &lt;i&gt;Wiesel T N&lt;/i&gt;. &lt;i&gt;Receptive fields of single neurones in the cat&lt;/i&gt;′&lt;i&gt;s striate cortex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;The Journal of Physiology&lt;/i&gt;, 1959, 148 (3) : 574-591.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" &lt;i&gt;Zeng C&lt;/i&gt;, &lt;i&gt;Li Y J&lt;/i&gt;, &lt;i&gt;Yang K F&lt;/i&gt;, et al. &lt;i&gt;Contour detection based on a non&lt;/i&gt;-&lt;i&gt;classical receptive field model with butterfly&lt;/i&gt;-&lt;i&gt;shaped inhibition subregions&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Neurocomputing&lt;/i&gt;, 2011, 74 (10) : 1527-1534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911359&amp;v=MjUzNDZadUh5am1VYi9JS1YwUWJoTT1OaWZPZmJLN0h0RE5xbzlFYmVvT0Qza3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         &lt;i&gt;Zeng C&lt;/i&gt;, &lt;i&gt;Li Y J&lt;/i&gt;, &lt;i&gt;Yang K F&lt;/i&gt;, et al. &lt;i&gt;Contour detection based on a non&lt;/i&gt;-&lt;i&gt;classical receptive field model with butterfly&lt;/i&gt;-&lt;i&gt;shaped inhibition subregions&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Neurocomputing&lt;/i&gt;, 2011, 74 (10) : 1527-1534.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" &lt;i&gt;Grigorescu C&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, &lt;i&gt;Westenberg M A&lt;/i&gt;. &lt;i&gt;Contour detection based on nonclassical receptive field inhibition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;, 2003, 12 (7) : 729-739." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contour detection based on nonclassical receptive field inhibition">
                                        <b>[3]</b>
                                         &lt;i&gt;Grigorescu C&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, &lt;i&gt;Westenberg M A&lt;/i&gt;. &lt;i&gt;Contour detection based on nonclassical receptive field inhibition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;, 2003, 12 (7) : 729-739.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" &lt;i&gt;Sang N&lt;/i&gt;, &lt;i&gt;Tang Q L&lt;/i&gt;, &lt;i&gt;Zhang T X&lt;/i&gt;. &lt;i&gt;Contour detection based on inhibition of primary visual cortex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Journal of Infrared and Millimeter Waves&lt;/i&gt;, 2007, 26 (1) : 47-51, 60. 桑农, 唐奇伶, 张天序. 基于初级视皮层抑制的轮廓检测方法 [&lt;i&gt;J&lt;/i&gt;]. 红外与毫米波学报, 2007, 26 (1) : 47-51, 60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH200701010&amp;v=MzEwOTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVjd2SkxUclNackc0SHRiTXJvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         &lt;i&gt;Sang N&lt;/i&gt;, &lt;i&gt;Tang Q L&lt;/i&gt;, &lt;i&gt;Zhang T X&lt;/i&gt;. &lt;i&gt;Contour detection based on inhibition of primary visual cortex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Journal of Infrared and Millimeter Waves&lt;/i&gt;, 2007, 26 (1) : 47-51, 60. 桑农, 唐奇伶, 张天序. 基于初级视皮层抑制的轮廓检测方法 [&lt;i&gt;J&lt;/i&gt;]. 红外与毫米波学报, 2007, 26 (1) : 47-51, 60.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" &lt;i&gt;Papari G&lt;/i&gt;, &lt;i&gt;Campisi P&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, et al. &lt;i&gt;A biologically motivated multiresolution approach to contour detection&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;EURASIP Journal on Advances in Signal Processing&lt;/i&gt;, 2007, 2007: 071828." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A biologically motivated multiresolution approach to contour detection">
                                        <b>[5]</b>
                                         &lt;i&gt;Papari G&lt;/i&gt;, &lt;i&gt;Campisi P&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, et al. &lt;i&gt;A biologically motivated multiresolution approach to contour detection&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;EURASIP Journal on Advances in Signal Processing&lt;/i&gt;, 2007, 2007: 071828.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     &lt;i&gt;Qiu F S&lt;/i&gt;. &lt;i&gt;Spatial structure and color characteristics of the integrated field of visual cortex neurons in awake monkeys&lt;/i&gt;[&lt;i&gt;D&lt;/i&gt;]. &lt;i&gt;Shanghai&lt;/i&gt;: &lt;i&gt;Shanghai Institutes for Biological Sciences&lt;/i&gt;, &lt;i&gt;Chinese Academy of Sciences&lt;/i&gt;, 1998. 邱芳士. 清醒猴视皮层神经元整合野的空间和颜色特性[&lt;i&gt;D&lt;/i&gt;]. 上海: 中国科学院上海生理研究所, 1998.</a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" &lt;i&gt;Dou Y&lt;/i&gt;. &lt;i&gt;Research on computational model and experiments of visual attention based on space and object&lt;/i&gt;[&lt;i&gt;D&lt;/i&gt;]. &lt;i&gt;Qinhuangdao&lt;/i&gt;: &lt;i&gt;Yanshan University&lt;/i&gt;, 2010. 窦燕. 基于空间和物体的视觉注意计算方法及实验研究 [&lt;i&gt;D&lt;/i&gt;]. 秦皇岛: 燕山大学, 2010." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=2010088809.nh&amp;v=MDU2OTJGeUhtVjd2SlYxMjZIck93RnRuTXBwRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         &lt;i&gt;Dou Y&lt;/i&gt;. &lt;i&gt;Research on computational model and experiments of visual attention based on space and object&lt;/i&gt;[&lt;i&gt;D&lt;/i&gt;]. &lt;i&gt;Qinhuangdao&lt;/i&gt;: &lt;i&gt;Yanshan University&lt;/i&gt;, 2010. 窦燕. 基于空间和物体的视觉注意计算方法及实验研究 [&lt;i&gt;D&lt;/i&gt;]. 秦皇岛: 燕山大学, 2010.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" &lt;i&gt;Yang K F&lt;/i&gt;, &lt;i&gt;Li C Y&lt;/i&gt;, &lt;i&gt;Li Y J&lt;/i&gt;. &lt;i&gt;Multifeature&lt;/i&gt;-&lt;i&gt;based surround inhibition improves contour detection in natural images&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;, 2014, 23 (12) : 5020-5032." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multifeature-based surround inhibition improves contour detection in natural images">
                                        <b>[8]</b>
                                         &lt;i&gt;Yang K F&lt;/i&gt;, &lt;i&gt;Li C Y&lt;/i&gt;, &lt;i&gt;Li Y J&lt;/i&gt;. &lt;i&gt;Multifeature&lt;/i&gt;-&lt;i&gt;based surround inhibition improves contour detection in natural images&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;, 2014, 23 (12) : 5020-5032.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" &lt;i&gt;Wei H&lt;/i&gt;, &lt;i&gt;Lang B&lt;/i&gt;, &lt;i&gt;Zuo Q S&lt;/i&gt;. &lt;i&gt;An image representation of infrastructure based on non&lt;/i&gt;-&lt;i&gt;classical receptive field&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Soft Computing&lt;/i&gt;, 2014, 18 (1) : 109-123." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300020258&amp;v=MDc1MzBadUh5am1VYi9JS1YwUWJoTT1OajdCYXJLOEh0TE1ySTlGWk9rUERua3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         &lt;i&gt;Wei H&lt;/i&gt;, &lt;i&gt;Lang B&lt;/i&gt;, &lt;i&gt;Zuo Q S&lt;/i&gt;. &lt;i&gt;An image representation of infrastructure based on non&lt;/i&gt;-&lt;i&gt;classical receptive field&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Soft Computing&lt;/i&gt;, 2014, 18 (1) : 109-123.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" &lt;i&gt;Ditchburn R W&lt;/i&gt;, &lt;i&gt;Ginsborg B L&lt;/i&gt;. &lt;i&gt;Vision with a stabilized retinal image&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Nature&lt;/i&gt;, 1952, 170 (4314) : 36-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vision with a stabilized retinal image">
                                        <b>[10]</b>
                                         &lt;i&gt;Ditchburn R W&lt;/i&gt;, &lt;i&gt;Ginsborg B L&lt;/i&gt;. &lt;i&gt;Vision with a stabilized retinal image&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Nature&lt;/i&gt;, 1952, 170 (4314) : 36-37.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" &lt;i&gt;Lin C&lt;/i&gt;, &lt;i&gt;Li Y&lt;/i&gt;, &lt;i&gt;Cao Y J&lt;/i&gt;. &lt;i&gt;Contour detection model with movement mechanism based on receptive field properties&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Computer Engineering and Applications&lt;/i&gt;, 2016, 52 (24) : 210-216. 林川, 李亚, 曹以隽. 考虑微动机制与感受野特性的轮廓检测模型[&lt;i&gt;J&lt;/i&gt;]. 计算机工程与应用, 2016, 52 (24) : 210-216." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201624039&amp;v=MTM3MjVMT2VaZVZ1RnlIbVY3dkpMejdNYWJHNEg5Zk9xNDlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         &lt;i&gt;Lin C&lt;/i&gt;, &lt;i&gt;Li Y&lt;/i&gt;, &lt;i&gt;Cao Y J&lt;/i&gt;. &lt;i&gt;Contour detection model with movement mechanism based on receptive field properties&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Computer Engineering and Applications&lt;/i&gt;, 2016, 52 (24) : 210-216. 林川, 李亚, 曹以隽. 考虑微动机制与感受野特性的轮廓检测模型[&lt;i&gt;J&lt;/i&gt;]. 计算机工程与应用, 2016, 52 (24) : 210-216.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" &lt;i&gt;Du X F&lt;/i&gt;, &lt;i&gt;Li C H&lt;/i&gt;, &lt;i&gt;Li J&lt;/i&gt;. &lt;i&gt;Contour detection based on compound receptive field&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Journal of Electronics&lt;/i&gt; &amp;amp; &lt;i&gt;Information Technology&lt;/i&gt;, 2009, 31 (7) : 1630-1634.  杜晓凤, 李翠华, 李晶. 基于复合感受野的轮廓检测算法[&lt;i&gt;J&lt;/i&gt;]. 电子与信息学报, 2009, 31 (7) : 1630-1634." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200907022&amp;v=MjA3OTdCdEdGckNVUkxPZVplVnVGeUhtVjd2SklUZlNkckc0SHRqTXFJOUhab1FLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         &lt;i&gt;Du X F&lt;/i&gt;, &lt;i&gt;Li C H&lt;/i&gt;, &lt;i&gt;Li J&lt;/i&gt;. &lt;i&gt;Contour detection based on compound receptive field&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Journal of Electronics&lt;/i&gt; &amp;amp; &lt;i&gt;Information Technology&lt;/i&gt;, 2009, 31 (7) : 1630-1634.  杜晓凤, 李翠华, 李晶. 基于复合感受野的轮廓检测算法[&lt;i&gt;J&lt;/i&gt;]. 电子与信息学报, 2009, 31 (7) : 1630-1634.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" &lt;i&gt;Li C&lt;/i&gt;, &lt;i&gt;Lu C Y&lt;/i&gt;, &lt;i&gt;Zhao X&lt;/i&gt;, et al. &lt;i&gt;Scale adaptive correlation filtering tracing algorithm based on feature fusion&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Acta Optica Sinica&lt;/i&gt;, 2018, 38 (5) : 0515001. 李聪, 鹿存跃, 赵珣, 等. 特征融合的尺度自适应相关滤波跟踪算法[&lt;i&gt;J&lt;/i&gt;]. 光学学报, 2018, 38 (5) : 0515001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201805026&amp;v=MTg3ODRiTEc0SDluTXFvOUhZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVjd2SklqWFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         &lt;i&gt;Li C&lt;/i&gt;, &lt;i&gt;Lu C Y&lt;/i&gt;, &lt;i&gt;Zhao X&lt;/i&gt;, et al. &lt;i&gt;Scale adaptive correlation filtering tracing algorithm based on feature fusion&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Acta Optica Sinica&lt;/i&gt;, 2018, 38 (5) : 0515001. 李聪, 鹿存跃, 赵珣, 等. 特征融合的尺度自适应相关滤波跟踪算法[&lt;i&gt;J&lt;/i&gt;]. 光学学报, 2018, 38 (5) : 0515001.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" &lt;i&gt;Papari G&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;. &lt;i&gt;Edge and line oriented contour detection&lt;/i&gt;: &lt;i&gt;state of the art&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Image and Vision Computing&lt;/i&gt;, 2011, 29 (2/3) : 79-103." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201348826&amp;v=MjI3NTRxUVRNbndaZVp1SHlqbVViL0lLVjBRYmhNPU5pZk9mYks3SHRET3JZOUVaKzhIQkg0L29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         &lt;i&gt;Papari G&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;. &lt;i&gt;Edge and line oriented contour detection&lt;/i&gt;: &lt;i&gt;state of the art&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Image and Vision Computing&lt;/i&gt;, 2011, 29 (2/3) : 79-103.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" &lt;i&gt;Liu H&lt;/i&gt;, &lt;i&gt;Zhao W J&lt;/i&gt;, &lt;i&gt;Wu W&lt;/i&gt;. &lt;i&gt;Edge extraction of infrared image based on the eye movement mechanism&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Microcomputer&lt;/i&gt; &amp;amp; &lt;i&gt;Its Applications&lt;/i&gt;, 2010, 29 (20) : 56-58.  刘辉, 赵文杰, 吴畏. 基于人眼微动机理的红外图像边缘提取[&lt;i&gt;J&lt;/i&gt;]. 微型机与应用, 2010, 29 (20) : 56-58." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201020020&amp;v=MzA2NjU3RzRIOUhPcjQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5SG1WN3ZKTWpYQmQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         &lt;i&gt;Liu H&lt;/i&gt;, &lt;i&gt;Zhao W J&lt;/i&gt;, &lt;i&gt;Wu W&lt;/i&gt;. &lt;i&gt;Edge extraction of infrared image based on the eye movement mechanism&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Microcomputer&lt;/i&gt; &amp;amp; &lt;i&gt;Its Applications&lt;/i&gt;, 2010, 29 (20) : 56-58.  刘辉, 赵文杰, 吴畏. 基于人眼微动机理的红外图像边缘提取[&lt;i&gt;J&lt;/i&gt;]. 微型机与应用, 2010, 29 (20) : 56-58.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" &lt;i&gt;Richards W&lt;/i&gt;, &lt;i&gt;Noshihara H K&lt;/i&gt;, &lt;i&gt;Dawson B&lt;/i&gt;. &lt;i&gt;CARTOON&lt;/i&gt;: &lt;i&gt;a biologically motivated edge detection algorithm&lt;/i&gt;[&lt;i&gt;Z&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;]. (1982-06-01) [2018-09-01]. &lt;i&gt;http&lt;/i&gt;://&lt;i&gt;hdl&lt;/i&gt;.&lt;i&gt;handle&lt;/i&gt;.&lt;i&gt;net&lt;/i&gt;/1721.1/5681" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CARTOON: a biologically motivated edge detection algorithm[Z/OL]">
                                        <b>[16]</b>
                                         &lt;i&gt;Richards W&lt;/i&gt;, &lt;i&gt;Noshihara H K&lt;/i&gt;, &lt;i&gt;Dawson B&lt;/i&gt;. &lt;i&gt;CARTOON&lt;/i&gt;: &lt;i&gt;a biologically motivated edge detection algorithm&lt;/i&gt;[&lt;i&gt;Z&lt;/i&gt;/&lt;i&gt;OL&lt;/i&gt;]. (1982-06-01) [2018-09-01]. &lt;i&gt;http&lt;/i&gt;://&lt;i&gt;hdl&lt;/i&gt;.&lt;i&gt;handle&lt;/i&gt;.&lt;i&gt;net&lt;/i&gt;/1721.1/5681
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_17" title=" &lt;i&gt;Grigorescu C&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, &lt;i&gt;Westenberg M A&lt;/i&gt;. &lt;i&gt;Contour and boundary detection improved by surround suppression of texture edges&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Image and Vision Computing&lt;/i&gt;, 2004, 22 (8) : 609-622." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349800&amp;v=MjEzMTBNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JS1YwUWJoTT1OaWZPZmJLN0h0RE9yWTlFWis4R0JIdzVvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         &lt;i&gt;Grigorescu C&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;, &lt;i&gt;Westenberg M A&lt;/i&gt;. &lt;i&gt;Contour and boundary detection improved by surround suppression of texture edges&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Image and Vision Computing&lt;/i&gt;, 2004, 22 (8) : 609-622.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_18" title=" &lt;i&gt;Azzopardi G&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;. &lt;i&gt;A CORF computational model of a simple cell that relies on LGN input outperforms the Gabor function model&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Biological Cybernetics&lt;/i&gt;, 2012, 106 (3) : 177-189." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120504000107&amp;v=MzA0ODZNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3JsVTdiTEpGb1ZOajdCYXJLNkh0VE1xNDlGWk9vUEN4&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         &lt;i&gt;Azzopardi G&lt;/i&gt;, &lt;i&gt;Petkov N&lt;/i&gt;. &lt;i&gt;A CORF computational model of a simple cell that relies on LGN input outperforms the Gabor function model&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Biological Cybernetics&lt;/i&gt;, 2012, 106 (3) : 177-189.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_19" title=" &lt;i&gt;Xu Y Y&lt;/i&gt;, &lt;i&gt;Lang B&lt;/i&gt;, &lt;i&gt;Huang J&lt;/i&gt;. &lt;i&gt;A model of image representation based on non&lt;/i&gt;-&lt;i&gt;classical receptive fields&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Computer&lt;/i&gt; &amp;amp; &lt;i&gt;Digital Engineering&lt;/i&gt;, 2017, 45 (12) : 2485-2488. 许跃颖, 郎波, 黄静. 利用非经典感受野竞争机制实现有效图像表征的方法[&lt;i&gt;J&lt;/i&gt;]. 计算机与数字工程, 2017, 45 (12) : 2485-2488." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201712034&amp;v=MDMyODVMT2VaZVZ1RnlIbVY3dkpMejdZYWJHNEg5Yk5yWTlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         &lt;i&gt;Xu Y Y&lt;/i&gt;, &lt;i&gt;Lang B&lt;/i&gt;, &lt;i&gt;Huang J&lt;/i&gt;. &lt;i&gt;A model of image representation based on non&lt;/i&gt;-&lt;i&gt;classical receptive fields&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Computer&lt;/i&gt; &amp;amp; &lt;i&gt;Digital Engineering&lt;/i&gt;, 2017, 45 (12) : 2485-2488. 许跃颖, 郎波, 黄静. 利用非经典感受野竞争机制实现有效图像表征的方法[&lt;i&gt;J&lt;/i&gt;]. 计算机与数字工程, 2017, 45 (12) : 2485-2488.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_20" title=" &lt;i&gt;Yuan W Q&lt;/i&gt;, &lt;i&gt;Bai X G&lt;/i&gt;. &lt;i&gt;A new iris edge extraction method&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Acta Optica Sinica&lt;/i&gt;, 2009, 29 (8) : 2158-2163.  苑玮琦, 白晓光. 一种新颖的虹膜轮廓提取方法[&lt;i&gt;J&lt;/i&gt;]. 光学学报, 2009, 29 (8) : 2158-2163." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB200908027&amp;v=MDcxNTVIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlIbVY3dkpJalhUYkxHNEh0ak1wNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         &lt;i&gt;Yuan W Q&lt;/i&gt;, &lt;i&gt;Bai X G&lt;/i&gt;. &lt;i&gt;A new iris edge extraction method&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;]. &lt;i&gt;Acta Optica Sinica&lt;/i&gt;, 2009, 29 (8) : 2158-2163.  苑玮琦, 白晓光. 一种新颖的虹膜轮廓提取方法[&lt;i&gt;J&lt;/i&gt;]. 光学学报, 2009, 29 (8) : 2158-2163.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-13 10:07</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(03),136-143 DOI:10.3788/AOS201939.0310002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合人眼微动的新型非经典感受野模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%AA%A6%E7%87%95&amp;code=09261567&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">窦燕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BA%B7%E9%94%A6%E5%8D%8E&amp;code=41392348&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">康锦华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%BD%E7%9B%BC&amp;code=41392349&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王丽盼</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%87%95%E5%B1%B1%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0022354&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">燕山大学信息科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%87%95%E5%B1%B1%E5%A4%A7%E5%AD%A6%E6%B2%B3%E5%8C%97%E7%9C%81%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">燕山大学河北省软件工程重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于眼球微动机理, 提出了一种结合静态、动态机理的贴近非经典感受野的模型。该模型以感受野轴两侧的两个半椭圆环为非经典感受野抑制区, 并在其中设立子区域。通过抑制方向角度模拟微动, 结合抑制权值与图像亮度特征, 得到最后能量值。研究结果表明, 利用该模型提取目标轮廓时, 可较好地抑制背景纹理, 保留较多轮廓, 相比于传统模型有较好的效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E7%BB%8F%E5%85%B8%E6%84%9F%E5%8F%97%E9%87%8E&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非经典感受野;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9C%BC%E7%90%83%E5%BE%AE%E5%8A%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">眼球微动;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%AE%E5%BA%A6%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">亮度特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E6%99%AF%E7%BA%B9%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背景纹理;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *窦燕 E-mail:douyan@ysu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61379065);</span>
                    </p>
            </div>
                    <h1><b>Novel Non-Classical Receptive Field Model Combined with Human Eye Fretting</b></h1>
                    <h2>
                    <span>Dou Yan</span>
                    <span>Kang Jinhua</span>
                    <span>Wang Lipan</span>
            </h2>
                    <h2>
                    <span>Institution of Information Science and Engineering, Yanshan University</span>
                    <span>Key Laboratory of Hebei Software Engineering, Yanshan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Based on the mechanism of eyeball fretting, a model combining with the static and dynamic mechanisms is proposed, which is close to the non-classical receptive field model. In this model, two semi-elliptical rings on both sides of the receptive field axis are regarded as the non-classical receptive field suppression areas and the sub-regions are established as well. The fretting is simulated by suppressing the direction angle, and the final energy value is obtained by combining the suppression weight and the luminance features of the image. The experimental results show that using the proposed model to extract the target contours can restrain the background texture well and retain more contours, which is better than that of the traditional model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-classical%20receptive%20field&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-classical receptive field;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=eyeball%20fretting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">eyeball fretting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=luminance%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">luminance feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=background%20texture&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">background texture;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="50" name="50" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="51">随着解剖学和神经生理学的发展, 研究人员对生物视觉系统的研究逐步加深。通过研究猴子和猫的视觉系统生理过程, 发现视觉皮层中部分神经元的作用类似边缘检测器。神经元上有一块区域受到外界刺激时会产生响应, 并传递给上位中枢, 该区域为感受野<citation id="121" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。然而, 有响应就应该有抑制, 才可以区分不同的边缘, 研究发现感受野周边相邻区会抑制其产生的响应, 可以很好地把目标与背景区分开, 该区域为非经典感受野<citation id="122" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。在感受野和非经典感受野的配合下, 人类视觉系统具有从杂乱的场景中迅速分离背景和目标轮廓的能力, 这便推动研究人员为计算机视觉设计更好的轮廓探测器。</p>
                </div>
                <div class="p1">
                    <p id="52">用于模拟人类视觉神经元运转机理的滤波器可以从复杂背景中提取目标, 通过建立非经典感受野模型, 有效构建该滤波器。其中Grigorescu等<citation id="123" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>利用二维Gabor 能量模型, 模拟初级视皮层经典感受野的方向选择特性, 并且依靠非经典感受野的抑制特性进行轮廓检测, 提出一种圆形的抑制区域并采用高斯差分 (DoG) 建立抑制模型, 以模拟其距离权重。该方法成功地模拟了生物视觉构造轮廓检测器, 促使了学者对非经典感受野的深入研究。桑农等<citation id="124" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了蝶形域抑制方法, 对神经元周边抑制作用域的描述更加详细, 较好地抑制了背景纹理产生的有向边缘。Papari等<citation id="125" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>构造了一个感受野轴向为两个半圆环的非经典感受野模型, 加强对纹理的抑制, 但容易造成目标轮廓自身边缘不完整。邱芳士等<citation id="126" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在相同方向的边缘比不同方向的边缘具有更强抑制效果的前提下, 提出大多数神经元的感受野外周抑制区域呈椭圆形, 以长度稍大于宽度为基础, 模拟非经典感受野机制。窦燕<citation id="127" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>考虑非经典感受野抑制区域与对应中心感受野的角度关系, 设计了两个半椭圆环的非经典感受野模型, 更好地抑制了背景纹理。Yang等<citation id="128" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>通过上下文调制视觉系统中的不同视觉特征来调节最终的神经元周边的抑制作用, 以获取轮廓信息。Wei等<citation id="129" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>通过动态调节感受野尺度, 验证其在图像局部表达过程中的重要作用。</p>
                </div>
                <div class="p1">
                    <p id="53">上述模型的建立都是基于神经元的静态研究, 模拟神经元中的中心感受野和非经典感受野, 但Ditchburn等<citation id="130" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>的研究表明观察过程中停止眼球的所有运动时, 静止的图像会变得模糊并且逐渐消失, 而生物看到静态的物体不会消失是因为生物的眼球在静止状态下也不会停止运转, 这种运转被称为固视微动。微动会使反射到视觉内的图像处于运动状态, 克服由均衡视网膜刺激导致的视觉信息丢失的问题, 对生物视觉获取目标提供了有效的信息, 因此眼动特别是固视微动与视觉系统有着密切的关系。在非经典感受野中引入微动可以更好地模拟生物视觉<citation id="131" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 并且针对目标亮度值与背景纹理亮度值的差值, 在新模型中加入亮度调节机制, 便于模型更好地区别前景和背景, 从而提高模型提取轮廓的准确度。</p>
                </div>
                <div class="p1">
                    <p id="54">本文提出的新型非经典感受野模型首先通过腐蚀膨胀对图像做预处理, 然后应用二维Gabor函数模拟视皮层感受野响应, 基于感受野方向角度, 在轴向两个半椭圆环的非经典感受野同方向中构建子区域, 通过子区域和感受野相应角度方位数值交换来模拟人眼微动, 由非经典感受野竞争机制获得抑制权值, 然后计算原图像中各个像素的亮度值, 将其与获得的抑制权值线性结合, 得到能量图。采用非极大抑制<citation id="132" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和滞后阈值化方法细化图像边缘并去除伪边缘, 从而获得目标轮廓。</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag">2 计算模型</h3>
                <h4 class="anchor-tag" id="56" name="56"><b>2.1 计算模型</b></h4>
                <div class="p1">
                    <p id="57">通过对生物视皮层的深入研究, 发现视觉信息的处理是分级的, 其顺序依次是:简单细胞、复杂细胞、超复杂细胞、更高级的超复杂细胞。针对简单细胞中的感受野, 研究表明Gabor变换属于加窗傅里叶变换, 该函数可以在频域不同尺度、不同方向上提取相关的特征<citation id="133" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。Gabor滤波器<citation id="134" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>的频率和方向类似于人类的视觉系统, 所以能很好地描述简单细胞中感受野的响应, 该函数可以有效地模拟相位和朝向的选择性。根据二维Gabor相位奇偶建立的反应模可以模拟复杂细胞的响应, 复杂细胞可以看成局部方位能量算子, 进而更深入地探索视觉, 通过Gabor模拟复杂细胞的响应。</p>
                </div>
                <div class="p1">
                    <p id="58">二维Gabor是一个由正弦平面波调制的高斯核函数, 可表示为</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mtext>ϕ</mtext><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mrow><mo> (</mo><mrow><mfrac><mrow><msup><mi>x</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>γ</mi><msup><mi>y</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>⋅</mo></mtd></mtr><mtr><mtd><mi>cos</mi><mrow><mo> (</mo><mrow><mn>2</mn><mtext>π</mtext><mfrac><msup><mi>x</mi><mo>′</mo></msup><mi>λ</mi></mfrac><mo>+</mo><mtext>ϕ</mtext></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">式中: (<i>x</i>, <i>y</i>) 为像素点的位置; <i>θ</i>为Gabor滤波器相同条纹的方向角;<i>x</i>′=<i>x</i>cos <i>θ</i>+<i>y</i>sin <i>θ</i>;<i>y</i>′=-<i>x</i>sin <i>θ</i>+<i>y</i>cos <i>θ</i>;<i>γ</i>为空间纵横比, 决定Gabor的形状, 可用来描述椭圆率, 通常该值为0.5;<i>σ</i>为高斯因子的标准差, 决定感受野的大小;<i>λ</i>为波长, 它的值以像素为单位指定, 1/<i>λ</i>为正弦载波的中心频率, <i>σ</i>/<i>λ</i>为滤波器的半响应空间频率带宽;ϕ为正弦函数的相位偏移。</p>
                </div>
                <div class="p1">
                    <p id="61">生物视皮层简单细胞对目标的二维灰度图像响应函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mtext>ϕ</mtext><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>*</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mtext>ϕ</mtext><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">式中:<i>I</i> (<i>x</i>, <i>y</i>) 为输入的二维灰度图像;*代表卷积运算。</p>
                </div>
                <div class="p1">
                    <p id="64">对于主视皮层V1区复杂细胞, 通过二维Gabor相位奇偶建立的反应模来模拟复杂细胞的响应, 该响应由一对相位角度相差为π/2的简单细胞响应组成。反应模可表示为</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><msqrt><mrow><mi>r</mi><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mn>0</mn><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>r</mi><mrow><mo> (</mo><mrow><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mo>-</mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">大脑视皮层区感受野对不同方向刺激产生的响应具有差异, Gabor滤波器通过<i>θ</i> (0°～360°) 可以很好地模拟各个方向的响应值, 取每个像素点各个方向上响应能量的最大值构成综合能量图, 像素能量最大方向即为该点最优方向。综合能量可表示为</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>E</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>max</mi><mo stretchy="false">{</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo>, </mo><mi>L</mi><mo>, </mo><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mtext>π</mtext></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub></mrow></mfrac><mo>, </mo><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mi>L</mi><mo>, </mo><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">式中:<i>L</i>为角度分量;<i>N</i>为最大分量值;<i>i</i>为方向的分割数;</p>
                </div>
                <div class="p1">
                    <p id="71">各像素的最优方向可表示为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>A</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>k</mi><mo>=</mo><mi>arg</mi><mspace width="0.25em" /><mi>max</mi><mo stretchy="false">{</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式中:<i>A</i> (<i>x</i>, <i>y</i>) 为最优方向;<i>k</i>为各个方向的参数编号。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>2.2 非经典感受野模型</b></h4>
                <div class="p1">
                    <p id="75">随着对生物视皮层中各级细胞形态、结构和功能的深入探索, 人类对视觉信息加工脑机制的认识不断更新。研究发现经典感受野外还存在一个大范围的区域, 其直径约为经典感受野的3.8倍, 单独刺激该区域并不能直接引起细胞的反应, 但可以在一定程度上影响经典感受野内刺激产生的响应, 该范围被称作非经典感受野。对于高等动物的大脑来说, 识别景物图形结构与背景图形结构之间的差异 (图形边界与背景边界) 比单纯识别景物或背景本身具有更加重要的生物学意义, 而非经典感受野可对感受野响应进行调整, 通过对图像中不同像素点的响应度来决定其是否凸显, 从而达到图像中前景和背景的区分。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">3 抑制模型</h3>
                <div class="p1">
                    <p id="77">人类通过视觉系统可以了解大千世界的信息, 通过人脑对图像信息的深度处理获取信息, 但眼睛的作用不单单是图像摄取。生理研究表明眼睛的运动是一种研究视觉系统信息处理的重要手段之一, 通过对眼动的深入研究, 发现眼球<citation id="135" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>的运动对图像中边缘有突出和抑制的效果, 因此在图像边缘检测中应用该机制会有很好的效果。而传统非经典感受野大部分是针对静态注视设计的滤波器, 并没有考虑人眼微动机制。受该机制的影响, 所提算法设计一种新型的感受野模型, 通过眼球微动和区别于传统非经典感受野模型双向调节经典感受野的响应机制, 可以更好地提高轮廓从复杂的背景图像中提取的精度和稳定性。根据Gabor滤波器的输出响应在方向参数的垂直方向为最高响应, 所提算法构造两个半椭圆环来模拟非经典感受野区域相位差的位置敏感性, 同时在相同方向上的非经典感受野中设置子模板, 通过子模板相位角方位与感受野距离数值交换来模拟微动机制, 图1为构建的抑制模型。</p>
                </div>
                <div class="p1">
                    <p id="78">图1中<i>a</i>表示两个半椭圆环之间的距离, 置零区域用函数<i>S</i> (<i>x</i>, <i>y</i>, <i>d</i>, <i>φ</i>) 模拟, <i>S</i> (<i>x</i>, <i>y</i>, <i>d</i>, <i>φ</i>) 可表示为</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 抑制模型的权重模板" src="Detail/GetImg?filename=images/GXXB201903015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 抑制模型的权重模板  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Weight template of inhibition model</p>

                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>d</mi><mo>, </mo><mi>φ</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>d</mi><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>θ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>y</mi><mo>-</mo><mi>d</mi><mtext>c</mtext><mtext>o</mtext><mtext>s</mtext><mspace width="0.25em" /><mi>θ</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>≤</mo><mi>R</mi><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>d</mi><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>θ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>y</mi><mo>-</mo><mi>d</mi><mtext>c</mtext><mtext>o</mtext><mtext>s</mtext><mspace width="0.25em" /><mi>θ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>&gt;</mo><mi>R</mi><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">式中:<i>R</i>为非经典感受野的半径;<i>d</i>为置零区中心到感受野中心的距离。研究表明非经典感受野的直径约为经典感受野的3.8倍, 因此所提算法取<i>R</i>=8<i>σ</i>, 通过实验对不同情况下各取值 (整数倍) 都进行了验证, 最终得出:当<i>d</i>为感受野半径的6倍时所提算法具有较好的稳健性, 因而采用<i>d</i>=6<i>σ</i>。</p>
                </div>
                <div class="p1">
                    <p id="82">首先构建一个椭圆环形的DoG函数 (<i>G</i><sub>DoGS</sub>) :</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow></msub><mo>=</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mo stretchy="false"> (</mo><mn>4</mn><mi>σ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><msup><mi>x</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>γ</mi><msup><mi>y</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mo stretchy="false"> (</mo><mn>4</mn><mi>σ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>-</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><msup><mi>x</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>γ</mi><msup><mi>y</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">式中:<i>γ</i>表示高斯窗口的椭圆程度, 取值为0.5。</p>
                </div>
                <div class="p1">
                    <p id="85">定义半波校正公式[·]<sup>+</sup>为</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">[</mo><mi>η</mi><mo stretchy="false">]</mo><msup><mrow></mrow><mo>+</mo></msup><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>η</mi><mo>, </mo><mspace width="0.25em" /><mi>η</mi><mo>≥</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>η</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">将椭圆分割成两个半环, 以过椭圆中心处且与最优<i>θ</i>的垂直方向平行的轴为中心轴, 在此中心轴上将两个半环各移动<i>a</i>/2的距离, 得到两个半椭圆环的函数:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>G</mi><msubsup><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow><mo>+</mo></msubsup><mo>=</mo><mi>G</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>V</mi><mrow><mo> (</mo><mrow><msup><mi>x</mi><mo>′</mo></msup><mo>-</mo><mfrac><mi>a</mi><mn>2</mn></mfrac></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>G</mi><msubsup><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow><mo>-</mo></msubsup><mo>=</mo><mi>G</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>V</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mi>a</mi><mn>2</mn></mfrac><mo>-</mo><msup><mi>x</mi><mo>′</mo></msup></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">式中:<i>a</i>=2<i>σ</i>;<image id="141" type="formula" href="images/GXXB201903015_14100.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="92">对 (11) 、 (12) 式进行归一化处理, 得到距离权重函数为</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msup><mrow></mrow><mo>±</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>G</mi><msubsup><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow><mo>±</mo></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∬</mo><mrow><mi>R</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msub><mi>G</mi></mrow></mstyle><msubsup><mrow></mrow><mrow><mtext>D</mtext><mtext>o</mtext><mtext>G</mtext><mtext>S</mtext></mrow><mo>±</mo></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow></mfrac><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">根据感受野最优方位与周边环境最优方位的角度关系, 构造相位函数:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><msup><mi>A</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>exp</mi><mrow><mo>[</mo><mrow><mo>-</mo><mfrac><mrow><mi>min</mi><mo stretchy="false"> (</mo><mo stretchy="false">|</mo><mi>A</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>θ</mi><mo stretchy="false">|</mo><mo>, </mo><mtext>π</mtext><mo>-</mo><mo stretchy="false">|</mo><mi>A</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>θ</mi><mo stretchy="false">|</mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mtext>Δ</mtext><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">式中:σ<sub><i>Δ</i></sub>为高斯方差, 控制相位差对权重值的衰减程度。</p>
                </div>
                <div class="p1">
                    <p id="97">因此, 非经典感受野根据微动下的距离权重函数与相位权重函数对感受野下响应能量的抑制作用H (x, y) 可表示为</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>min</mi><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><msup><mi>E</mi><mo>′</mo></msup><mo>*</mo><mi>W</mi><msup><mrow></mrow><mo>+</mo></msup><mo>*</mo><msup><mi>A</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mi>A</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><msup><mi>E</mi><mo>′</mo></msup><mo>*</mo><mi>W</mi><msup><mrow></mrow><mo>-</mo></msup><mo>*</mo><msup><mi>A</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mi>A</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">式中:E′为距离权重函数;W为相位权重函数;A′为感受野下的相应能量;上标+表示模型上面椭圆对应的值;上标-为模型下面椭圆对应的值。</p>
                </div>
                <div class="p1">
                    <p id="100">计算图像亮度值, 目标亮度与背景亮度存在差异性, 并且获取的边缘 (即一个属性与另一个属性区域交接处是区域属性发生突变的地方) 与周边邻域内像素值差值较大, 融入该亮度机制可以更好地凸显边缘。构造函数K (x, y) 模拟亮度, 即</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ζ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>Ζ</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>Ζ</mi><msub><mrow></mrow><mn>8</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mn>3</mn></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ζ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext><mtext>r</mtext><mtext>a</mtext><mtext>g</mtext><mtext>e</mtext><mo stretchy="false"> (</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">式中:n为邻域序号; Z<sub>n</sub> (x, y) 为第n邻域的亮度值;f (x, y) 表示该像素点的值; <i>average</i> (n-1) 表示除去该值的邻域平均值。</p>
                </div>
                <div class="p1">
                    <p id="103">尺度为σ且经过微动的非经典感受野与亮度调节机制后的图像轮廓点的<i>Gabor</i>能量响应C<sub>σ</sub> (x, y) 可表示为</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mi>σ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">[</mo><mover accent="true"><mi>E</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>α</mi><mi>Η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mo>+</mo></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">式中:<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>E</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>为像素能量值;H为抑制能量值;α控制着抑制强度。</p>
                </div>
                <div class="p1">
                    <p id="107">获取的<i>Gabor</i>值较大, 表示该点在边缘上的可能性大;获取的<i>Gabor</i>值较小, 表示该点在边缘上的可能性小。经过模型处理得到像素点的能量值, 通过非极大值抑制, 将计算得到的边缘点能量值与其相同方向前后点能量值相比较, 若边缘点能量值大于相同方向前后点能量值则保留, 小于则去除。对非极大值处理后的边缘点进行双阈值处理, 基于能量值的范围选取两个阈值, 判断其是否大于高阈值, 若大于则保留, 否则判断其是否在大于低阈值的前提下周边3×3邻域中有大于高阈值的点, 若满足则保留。最终获取更大概率的边缘像素点。然后使用最小二乘法拟合边缘点。通过区域生长方法去除一些伪边缘, 得到最终的轮廓图, 图2为非经典感受野抑制过程。</p>
                </div>
                <h3 id="108" name="108" class="anchor-tag">4 分析与讨论</h3>
                <div class="p1">
                    <p id="109">视皮层建立的滤波器经常通过图像的轮廓检测来衡量各种模型的性能。为便于比较, 所提算法对比图均来源于<i>http</i>://<i>www</i>.<i>cs</i>.<i>rug</i>.<i>nl</i>/～<i>imaging</i>。将所提算法与<i>Canny</i>算法、<i>CARTOO</i><citation id="136" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>算法、<i>Single scale surround</i><citation id="137" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>算法、 <i>Grigorescu</i>等<citation id="138" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出的<i>CORF</i> (<i>Combination of Receptive Fields</i>) 模型进行对比。对网址<i>http</i>://<i>www</i>.<i>cs</i>.<i>rug</i>.<i>nl</i>/～<i>imaging</i>中的数据集进行了对比, 在此只列出其中5幅图像作为实验结果。在<i>MATLAB</i> 2016<i>a</i>仿真软件中对<i>CORF</i>模型进行仿真, 在<i>Visual Studio</i> 2013+<i>OpenCV</i>2.4.10中对<i>Canny</i>模型进行仿真。图3为不同算法提取的轮廓, 第1行为从图库里选的5幅原图, 第2行为<i>Ground Truth</i>, 第3行为<i>Canny</i>算法的轮廓图, 第4行为<i>CARTOO</i>算法的轮廓图, 第5行为<i>Single scale surround</i>算法的轮廓图, 第6行为<i>Grigorescu</i>等提出的<i>CORF</i>模型检测出来的轮廓图, 第7行为所提模型检测出来的轮廓图。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903015_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 非经典感受野抑制过程" src="Detail/GetImg?filename=images/GXXB201903015_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 非经典感受野抑制过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903015_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 2 <i>Inhibition process of nonclassical receptive field</i></p>

                </div>
                <div class="p1">
                    <p id="111">所提算法根据人类视觉感知系统提取图像中显著性物体轮廓, 针对比较完整的物体, 在保存轮廓图的同时可最大程度地抑制背景纹理。从实验结果来看, 所提算法相对<i>Canny</i>算法、<i>CARTOO</i>算法、<i>Single scale surround</i>算法和<i>CORF</i>模型而言, 在抑制背景纹理的同时更加贴近人类视觉感官, 加大对背景纹理的抑制和减小对目标物体的抑制, <i>Canny</i>算法是流行较广的一种轮廓提取算法, 针对面比较广, 但不能很好地抑制特定的自然图像背景中的纹理, 在复杂背景下不能很好地区分前景和背景, 所以该算法在较好的保存目标轮廓的同时抑制背景纹理的程度较弱。而<i>CARTOO</i>算法、<i>Single scale surround</i>算法在图像背景纹理抑制方面优于<i>Canny</i>算法, 但从图像结果来看抑制效果不佳, <i>CORF</i>是初级视觉皮层中简单细胞的计算模型, 它使用感受野在中心的非经典感受野模型和感受野偏离中心的非经典感受野模型对<i>LGN</i> (<i>lateral geniculate nucleus</i>) 细胞经行建模, 并将它们的响应与加权几何平均值相结合。对接近前景的背景区分不明显, 在较大程度地抑制背景的情况下会使目标轮廓不明显。</p>
                </div>
                <div class="p1">
                    <p id="112">采用文献<citation id="139" type="reference">[<a class="sup">19</a>]</citation>中的评测方法对实验中得到的图像数据进行评测, 可得</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mtext>c</mtext><mtext>a</mtext><mtext>r</mtext><mtext>d</mtext><mo stretchy="false"> (</mo><mi>C</mi><mo stretchy="false">) </mo></mrow><mrow><mtext>c</mtext><mtext>a</mtext><mtext>r</mtext><mtext>d</mtext><mo stretchy="false"> (</mo><mi>C</mi><mo stretchy="false">) </mo><mo>+</mo><mtext>c</mtext><mtext>a</mtext><mtext>r</mtext><mtext>d</mtext><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ρ</mtext></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mtext>c</mtext><mtext>a</mtext><mtext>r</mtext><mtext>d</mtext><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">式中: C<sub><i>FN</i></sub>表示漏检轮廓, C<sub><i>FN</i></sub>=B<sub><i>D</i></sub>∩E<sub><i>GT</i></sub>, 其中E<sub><i>GT</i></sub>表示轮廓集, B<sub><i>D</i></sub>表示检测结果图中的背景轮廓;C<sub><i>FP</i></sub>表示虚假轮廓, C<sub><i>FP</i></sub>=E<sub><i>D</i></sub>∩B<sub><i>GT</i></sub>, 其中E<sub><i>D</i></sub>表示检测结果图中的目标轮廓, B<sub><i>GT</i></sub>表示背景集;<i>card</i> (C) 表示真实轮廓C (C=E<sub><i>D</i></sub>∩E<sub><i>GT</i></sub>) 中成员的数目。基准轮廓图是由人类观察者确定的真实轮廓图, 对图像的轮廓进行手工描绘, 其中包括的轮廓线并不一定属于物体, 但该轮廓是人类视觉感知的最优轮廓图 (<i>Ground Truth</i>) 。检测时, 由于检测的图像与<i>Ground Truth</i>不可能一一对应, 存在空间上的误差, 所以各算法检测所得轮廓允许存在一定的空间位置误差。在以检测像素为中心的5×5邻域内, 若存在相应的真实目标轮廓像素点, 则认为该轮廓像素检测正确。P值表示0和1之间的一个数, 正确检测出来的轮廓<citation id="140" type="reference"><link href="48" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>越多, 虚假轮廓越少, 漏检轮廓越少, 则P值越大, 算法效果越好。</p>
                </div>
                <div class="p1">
                    <p id="115">表1为各个算法计算出的P值, 客观上利用该值可对算法进行评价。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903015_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同算法下的提取轮廓" src="Detail/GetImg?filename=images/GXXB201903015_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同算法下的提取轮廓  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903015_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Contour extraction under different algorithms</i></p>

                </div>
                <div class="area_img" id="117">
                    <p class="img_tit">表1 不同算法下的P值 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><i>Table</i> 1 P <i>values under different algorithms</i></p>
                    <p class="img_note"></p>
                    <table id="117" border="1"><tr><td><i>Image type</i></td><td><i>Canny</i></td><td><i>CARTOO</i></td><td><i>Single scale surround</i></td><td><i>CORF</i></td><td><i>Proposed algorithm</i></td></tr><tr><td><br /><i>Rino</i></td><td>0.17</td><td>0.15</td><td>0.21</td><td>0.35</td><td>0.36</td></tr><tr><td><br /><i>Gezalle</i></td><td>0.30</td><td>0.35</td><td>0.39</td><td>0.48</td><td>0.49</td></tr><tr><td><br /><i>Hyena</i></td><td>0.28</td><td>0.40</td><td>0.44</td><td>0.50</td><td>0.53</td></tr><tr><td><br /><i>Elephants</i>_<i>gt</i>_<i>binary</i></td><td>0.52</td><td>0.61</td><td>0.67</td><td>0.78</td><td>0.80</td></tr><tr><td><br /><i>Gazelle</i>_2</td><td>0.22</td><td>0.28</td><td>0.30</td><td>0.35</td><td>0.37</td></tr><tr><td><br /><i>Elephants</i>_2</td><td>0.29</td><td>0.33</td><td>0.36</td><td>0.48</td><td>0.49</td></tr><tr><td><br /><i>Bear</i>4</td><td>0.15</td><td>0.15</td><td>0.17</td><td>0.25</td><td>0.25</td></tr><tr><td><br /><i>Goat</i>_3</td><td>0.13</td><td>0.17</td><td>0.20</td><td>0.31</td><td>0.32</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="118">表1中罗列的数据图像分别为<i>Rino</i> (犀牛) 、<i>Gazelle</i> (瞪羚) 、<i>Hyena</i> (土狼) 、<i>Elephants</i>_<i>gt</i>_<i>binary</i> (两只小熊) 、<i>Gazelle</i>_2 (鹿) 、<i>Elephants</i>_2 (大象) 、<i>Bear</i>4 (水里的熊) 和<i>Goat</i>_3 (山羊) 。其中<i>Canny</i>算法通过<i>Otsu</i> (大津阈值) 选取每幅图像的最佳阈值, 然后进行实验。<i>CARTOO</i>算法和<i>Single scale surround</i>算法是通过<i>http</i>://<i>www</i>.<i>cs</i>.<i>rug</i>.<i>nl</i>/～<i>imaging</i>/<i>papari</i>/<i>JASP</i>/<i>results</i>.<i>html</i>所示的方法获取该算法的结果图片, 并进行数据测试。<i>CORF</i>算法中<i>sigma</i> (σ) 高斯因子的标准差σ={1.0, 1.4, 1.8, 2.4, 2.8, 3.2, 3.6, 4.0}, t滞后阈值中高阈值t={0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9}。所提算法中σ的高斯因子的标准差σ={2.0, 2.5, 3.0, 3.5, 4.0}, α={0.4, 0.6, 0.8, 1.0, 1.2}。 实验中P值均是在选取最优参数下获取的数据。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="120">在自然图像中, 背景纹理往往会占据图像中很大一部分, 对目标的获取造成很大的影响, 而人类视觉能很快地从复杂的图像中分辨出目标物体, 这便引发学者对人类视觉的研究。所提出的非经典感受野抑制模型更加贴近生物视觉, 将图像调整到最优状态, 更好地模拟人类视觉系统的运转, 在目标轮廓凸显方面增加了亮度调节机制, 使得目标在整幅图像中显著表达, 从而促进对目标后续的处理, 最终能更好地针对目标进行轮廓提取。将该模型应用于轮廓检测的实验表明, 所提算法在消除背景纹理的同时较大程度地保证了目标轮廓的完整性, 但在针对目标本身毛发较多的情况下, 该算法会保留一部分目标毛发, 保证目标完整性的同时对其本身轮廓的评估较低, 因此有待进一步的研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Receptive fields of single neurons in the cat&amp;#39;s striate cortex">

                                <b>[1]</b> <i>Hubel D H</i>, <i>Wiesel T N</i>. <i>Receptive fields of single neurones in the cat</i>′<i>s striate cortex</i>[<i>J</i>]. <i>The Journal of Physiology</i>, 1959, 148 (3) : 574-591.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911359&amp;v=MTY2MzVRVE1ud1plWnVIeWptVWIvSUtWMFFiaE09TmlmT2ZiSzdIdEROcW85RWJlb09EM2t3b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> <i>Zeng C</i>, <i>Li Y J</i>, <i>Yang K F</i>, et al. <i>Contour detection based on a non</i>-<i>classical receptive field model with butterfly</i>-<i>shaped inhibition subregions</i>[<i>J</i>]. <i>Neurocomputing</i>, 2011, 74 (10) : 1527-1534.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contour detection based on nonclassical receptive field inhibition">

                                <b>[3]</b> <i>Grigorescu C</i>, <i>Petkov N</i>, <i>Westenberg M A</i>. <i>Contour detection based on nonclassical receptive field inhibition</i>[<i>J</i>]. <i>IEEE Transactions on Image Processing</i>, 2003, 12 (7) : 729-739.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH200701010&amp;v=MjA1OTBiTXJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVjd2SkxUclNackc0SHQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> <i>Sang N</i>, <i>Tang Q L</i>, <i>Zhang T X</i>. <i>Contour detection based on inhibition of primary visual cortex</i>[<i>J</i>]. <i>Journal of Infrared and Millimeter Waves</i>, 2007, 26 (1) : 47-51, 60. 桑农, 唐奇伶, 张天序. 基于初级视皮层抑制的轮廓检测方法 [<i>J</i>]. 红外与毫米波学报, 2007, 26 (1) : 47-51, 60.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A biologically motivated multiresolution approach to contour detection">

                                <b>[5]</b> <i>Papari G</i>, <i>Campisi P</i>, <i>Petkov N</i>, et al. <i>A biologically motivated multiresolution approach to contour detection</i>[<i>J</i>]. <i>EURASIP Journal on Advances in Signal Processing</i>, 2007, 2007: 071828.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 <i>Qiu F S</i>. <i>Spatial structure and color characteristics of the integrated field of visual cortex neurons in awake monkeys</i>[<i>D</i>]. <i>Shanghai</i>: <i>Shanghai Institutes for Biological Sciences</i>, <i>Chinese Academy of Sciences</i>, 1998. 邱芳士. 清醒猴视皮层神经元整合野的空间和颜色特性[<i>D</i>]. 上海: 中国科学院上海生理研究所, 1998.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=2010088809.nh&amp;v=MDEzNzlKVjEyNkhyT3dGdG5NcHBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5SG1WN3Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> <i>Dou Y</i>. <i>Research on computational model and experiments of visual attention based on space and object</i>[<i>D</i>]. <i>Qinhuangdao</i>: <i>Yanshan University</i>, 2010. 窦燕. 基于空间和物体的视觉注意计算方法及实验研究 [<i>D</i>]. 秦皇岛: 燕山大学, 2010.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multifeature-based surround inhibition improves contour detection in natural images">

                                <b>[8]</b> <i>Yang K F</i>, <i>Li C Y</i>, <i>Li Y J</i>. <i>Multifeature</i>-<i>based surround inhibition improves contour detection in natural images</i>[<i>J</i>]. <i>IEEE Transactions on Image Processing</i>, 2014, 23 (12) : 5020-5032.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300020258&amp;v=MjQ1MjBlcnFRVE1ud1plWnVIeWptVWIvSUtWMFFiaE09Tmo3QmFySzhIdExNckk5RlpPa1BEbmt4b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> <i>Wei H</i>, <i>Lang B</i>, <i>Zuo Q S</i>. <i>An image representation of infrastructure based on non</i>-<i>classical receptive field</i>[<i>J</i>]. <i>Soft Computing</i>, 2014, 18 (1) : 109-123.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vision with a stabilized retinal image">

                                <b>[10]</b> <i>Ditchburn R W</i>, <i>Ginsborg B L</i>. <i>Vision with a stabilized retinal image</i>[<i>J</i>]. <i>Nature</i>, 1952, 170 (4314) : 36-37.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201624039&amp;v=MTUxNjZPZVplVnVGeUhtVjd2Skx6N01hYkc0SDlmT3E0OUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> <i>Lin C</i>, <i>Li Y</i>, <i>Cao Y J</i>. <i>Contour detection model with movement mechanism based on receptive field properties</i>[<i>J</i>]. <i>Computer Engineering and Applications</i>, 2016, 52 (24) : 210-216. 林川, 李亚, 曹以隽. 考虑微动机制与感受野特性的轮廓检测模型[<i>J</i>]. 计算机工程与应用, 2016, 52 (24) : 210-216.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200907022&amp;v=MDk2MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVjd2SklUZlNkckc0SHRqTXFJOUhab1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> <i>Du X F</i>, <i>Li C H</i>, <i>Li J</i>. <i>Contour detection based on compound receptive field</i>[<i>J</i>]. <i>Journal of Electronics</i> &amp; <i>Information Technology</i>, 2009, 31 (7) : 1630-1634.  杜晓凤, 李翠华, 李晶. 基于复合感受野的轮廓检测算法[<i>J</i>]. 电子与信息学报, 2009, 31 (7) : 1630-1634.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201805026&amp;v=MzEzMTRIbVY3dkpJalhUYkxHNEg5bk1xbzlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> <i>Li C</i>, <i>Lu C Y</i>, <i>Zhao X</i>, et al. <i>Scale adaptive correlation filtering tracing algorithm based on feature fusion</i>[<i>J</i>]. <i>Acta Optica Sinica</i>, 2018, 38 (5) : 0515001. 李聪, 鹿存跃, 赵珣, 等. 特征融合的尺度自适应相关滤波跟踪算法[<i>J</i>]. 光学学报, 2018, 38 (5) : 0515001.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201348826&amp;v=MjUzNTBqbVViL0lLVjBRYmhNPU5pZk9mYks3SHRET3JZOUVaKzhIQkg0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> <i>Papari G</i>, <i>Petkov N</i>. <i>Edge and line oriented contour detection</i>: <i>state of the art</i>[<i>J</i>]. <i>Image and Vision Computing</i>, 2011, 29 (2/3) : 79-103.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201020020&amp;v=MTk4NzZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVjd2Sk1qWEJkN0c0SDlIT3I0OUg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> <i>Liu H</i>, <i>Zhao W J</i>, <i>Wu W</i>. <i>Edge extraction of infrared image based on the eye movement mechanism</i>[<i>J</i>]. <i>Microcomputer</i> &amp; <i>Its Applications</i>, 2010, 29 (20) : 56-58.  刘辉, 赵文杰, 吴畏. 基于人眼微动机理的红外图像边缘提取[<i>J</i>]. 微型机与应用, 2010, 29 (20) : 56-58.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CARTOON: a biologically motivated edge detection algorithm[Z/OL]">

                                <b>[16]</b> <i>Richards W</i>, <i>Noshihara H K</i>, <i>Dawson B</i>. <i>CARTOON</i>: <i>a biologically motivated edge detection algorithm</i>[<i>Z</i>/<i>OL</i>]. (1982-06-01) [2018-09-01]. <i>http</i>://<i>hdl</i>.<i>handle</i>.<i>net</i>/1721.1/5681
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349800&amp;v=MjEzMjZxUVRNbndaZVp1SHlqbVViL0lLVjBRYmhNPU5pZk9mYks3SHRET3JZOUVaKzhHQkh3NW9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> <i>Grigorescu C</i>, <i>Petkov N</i>, <i>Westenberg M A</i>. <i>Contour and boundary detection improved by surround suppression of texture edges</i>[<i>J</i>]. <i>Image and Vision Computing</i>, 2004, 22 (8) : 609-622.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120504000107&amp;v=MDU4MTF1RkNybFU3YkxKRm9WTmo3QmFySzZIdFRNcTQ5RlpPb1BDeE04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> <i>Azzopardi G</i>, <i>Petkov N</i>. <i>A CORF computational model of a simple cell that relies on LGN input outperforms the Gabor function model</i>[<i>J</i>]. <i>Biological Cybernetics</i>, 2012, 106 (3) : 177-189.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201712034&amp;v=MDgzMzF1RnlIbVY3dkpMejdZYWJHNEg5Yk5yWTlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> <i>Xu Y Y</i>, <i>Lang B</i>, <i>Huang J</i>. <i>A model of image representation based on non</i>-<i>classical receptive fields</i>[<i>J</i>]. <i>Computer</i> &amp; <i>Digital Engineering</i>, 2017, 45 (12) : 2485-2488. 许跃颖, 郎波, 黄静. 利用非经典感受野竞争机制实现有效图像表征的方法[<i>J</i>]. 计算机与数字工程, 2017, 45 (12) : 2485-2488.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB200908027&amp;v=MjEzMzdCdEdGckNVUkxPZVplVnVGeUhtVjd2SklqWFRiTEc0SHRqTXA0OUhZNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> <i>Yuan W Q</i>, <i>Bai X G</i>. <i>A new iris edge extraction method</i>[<i>J</i>]. <i>Acta Optica Sinica</i>, 2009, 29 (8) : 2158-2163.  苑玮琦, 白晓光. 一种新颖的虹膜轮廓提取方法[<i>J</i>]. 光学学报, 2009, 29 (8) : 2158-2163.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201903015" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903015&amp;v=MjA4NzVtVjd2SklqWFRiTEc0SDlqTXJJOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

