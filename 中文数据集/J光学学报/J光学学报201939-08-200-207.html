

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133843279346250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201908024%26RESULT%3d1%26SIGN%3dNqmBnyH6HNeCz07pUHMs9C57pk0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908024&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908024&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908024&amp;v=MjIxMzN5bmxXcnJQSWpYVGJMRzRIOWpNcDQ5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="2 LYTRO相机成像模型与深度分辨率 ">2 LYTRO相机成像模型与深度分辨率</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 LYTRO相机的成像模型&lt;/b&gt;"><b>2.1 LYTRO相机的成像模型</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;2.2 LYTRO相机图像景深分辨率&lt;/b&gt;"><b>2.2 LYTRO相机图像景深分辨率</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="3 &lt;i&gt;LYTRO&lt;/i&gt;相机快速测距算法 ">3 <i>LYTRO</i>相机快速测距算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="&lt;b&gt;3.1 图像预处理&lt;/b&gt;"><b>3.1 图像预处理</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;3.2 直接测距法&lt;/b&gt;"><b>3.2 直接测距法</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;3.3 相对测距法优化&lt;/b&gt;"><b>3.3 相对测距法优化</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;3.4 算法验证&lt;/b&gt;"><b>3.4 算法验证</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="&lt;b&gt;4.1 实验1&lt;/b&gt;"><b>4.1 实验1</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;4.2 实验2&lt;/b&gt;"><b>4.2 实验2</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 光场相机双平面参数化表征">图1 光场相机双平面参数化表征</a></li>
                                                <li><a href="#54" data-title="图2 光场成像结构">图2 光场成像结构</a></li>
                                                <li><a href="#64" data-title="图3 图像深度提取原理">图3 图像深度提取原理</a></li>
                                                <li><a href="#78" data-title="图4 算法结构图">图4 算法结构图</a></li>
                                                <li><a href="#86" data-title="图5 原始图像及局部放大图像。">图5 原始图像及局部放大图像。</a></li>
                                                <li><a href="#87" data-title="图6 超分辨恢复结果。">图6 超分辨恢复结果。</a></li>
                                                <li><a href="#88" data-title="图7 重聚焦图像序列。">图7 重聚焦图像序列。</a></li>
                                                <li><a href="#91" data-title="图8 贴片示意图">图8 贴片示意图</a></li>
                                                <li><a href="#104" data-title="图9 贴片标准值测量。">图9 贴片标准值测量。</a></li>
                                                <li><a href="#107" data-title="图10 贴片标准值测量。">图10 贴片标准值测量。</a></li>
                                                <li><a href="#112" data-title="图11 算法验证">图11 算法验证</a></li>
                                                <li><a href="#117" data-title="图12 6组待测目标图像。目标物1的距离固定为20 cm, 目标物2的距离分别为 (a) 25 cm; (b) 30 cm; (c) 40 cm; (d) 50 cm; (e) 60 cm; (f) 70 cm">图12 6组待测目标图像。目标物1的距离固定为20 cm, 目标物2的距离分别为 (a) 25 cm......</a></li>
                                                <li><a href="#118" data-title="表1 实验1数据">表1 实验1数据</a></li>
                                                <li><a href="#122" data-title="图13 4组待测目标图像。">图13 4组待测目标图像。</a></li>
                                                <li><a href="#123" data-title="表2 实验2数据">表2 实验2数据</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="11">


                                    <a id="bibliography_1" title=" Wilburn B, Joshi N, Vaish V, &lt;i&gt;et al&lt;/i&gt;.High performance imaging using large camera arrays[J].ACM Transactions on Graphics, 2005, 24 (3) :765-776." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098252&amp;v=MjgzOThxUVRNbndaZVp1SHlqbVViL0lJVjRkYnhVPU5pZklZN0s3SHRqTnI0OUZaT0lIRG5rN29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Wilburn B, Joshi N, Vaish V, &lt;i&gt;et al&lt;/i&gt;.High performance imaging using large camera arrays[J].ACM Transactions on Graphics, 2005, 24 (3) :765-776.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_2" title=" Matusik W, Pfister H.3D TV:a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes[J].ACM Transactions on Graphics, 2004, 23 (3) :814-824." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D TV: A scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes">
                                        <b>[2]</b>
                                         Matusik W, Pfister H.3D TV:a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes[J].ACM Transactions on Graphics, 2004, 23 (3) :814-824.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_3" title=" Liu Y B, Dai Q H, Xu W L.A real time interactive dynamic light field transmission system[C]//2006 IEEE International Conference on Multimedia and Expo, July 9-12, 2006, Toronto, Ont., Canada.New York:IEEE, 2006:2173-2176." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A real time interactive dynamic light field transmission system">
                                        <b>[3]</b>
                                         Liu Y B, Dai Q H, Xu W L.A real time interactive dynamic light field transmission system[C]//2006 IEEE International Conference on Multimedia and Expo, July 9-12, 2006, Toronto, Ont., Canada.New York:IEEE, 2006:2173-2176.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_4" title=" Ng R, Levoy M, Br&#233;dif M, &lt;i&gt;et al&lt;/i&gt;.Light field photography with a hand-held plenoptic camera[J].Stanford Tech Report CTSR, 2005, 2:1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Light Field Photography with a Hand-Held Plenoptic Camera">
                                        <b>[4]</b>
                                         Ng R, Levoy M, Br&#233;dif M, &lt;i&gt;et al&lt;/i&gt;.Light field photography with a hand-held plenoptic camera[J].Stanford Tech Report CTSR, 2005, 2:1-11.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_5" title=" Ng R.Fourier slice photography[J].ACM Transactions on Graphics, 2005, 24 (3) :735-744." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098249&amp;v=MjMwNjF0ak5yNDlGWk9JSERuZ3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVjRkYnhVPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Ng R.Fourier slice photography[J].ACM Transactions on Graphics, 2005, 24 (3) :735-744.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_6" title=" Veeraraghavan A, Raskar R, Agrawal A, &lt;i&gt;et al&lt;/i&gt;.Dappled photography:mask enhanced cameras for heterodyned light fields and code aperture refocusing[J].ACM Transactions on Graphics, 2007, 26 (3) :69." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098521&amp;v=MjcxNjI0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVjRkYnhVPU5pZklZN0s3SHRqTnI0OUZaT0lIQ1g0NG9CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Veeraraghavan A, Raskar R, Agrawal A, &lt;i&gt;et al&lt;/i&gt;.Dappled photography:mask enhanced cameras for heterodyned light fields and code aperture refocusing[J].ACM Transactions on Graphics, 2007, 26 (3) :69.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_7" title=" Liang C K, Lin T H, Wong B Y, &lt;i&gt;et al&lt;/i&gt;.Programmable aperture photography:multiplexed light field acquisition[J].ACM Transactions on Graphics, 2008, 27 (3) :55." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098623&amp;v=MTQzNTBmSVk3SzdIdGpOcjQ5RlpPSUhDbjQ2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSVY0ZGJ4VT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Liang C K, Lin T H, Wong B Y, &lt;i&gt;et al&lt;/i&gt;.Programmable aperture photography:multiplexed light field acquisition[J].ACM Transactions on Graphics, 2008, 27 (3) :55.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_8" title=" Pelican[OL].[2019-02-15].http://www.pelican.com/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pelican[OL]">
                                        <b>[8]</b>
                                         Pelican[OL].[2019-02-15].http://www.pelican.com/.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_9" title=" Georgiev T, Yu Z, Lumsdaine A, &lt;i&gt;et al&lt;/i&gt;.Lytro camera technology:theory, algorithms, performance analysis[J] Proceeding of SPIE, 2013, 8667:86671J." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lytro camera technology:theory,algorithms,performance analysis">
                                        <b>[9]</b>
                                         Georgiev T, Yu Z, Lumsdaine A, &lt;i&gt;et al&lt;/i&gt;.Lytro camera technology:theory, algorithms, performance analysis[J] Proceeding of SPIE, 2013, 8667:86671J.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_10" title=" Ding J H.Research on depth map estimation of micro lens array light field photography[D].Taiyuan:North University of China, 2017.丁江华.基于微透镜阵列的光场图像深度估计研究[D].太原:中北大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017167288.nh&amp;v=MTU1NzlHRnJDVVJMT2VaZVZ1RnlubFdyclBWRjI2R2JLK0dkUEVwNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Ding J H.Research on depth map estimation of micro lens array light field photography[D].Taiyuan:North University of China, 2017.丁江华.基于微透镜阵列的光场图像深度估计研究[D].太原:中北大学, 2017.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_11" title=" Jiang X D, Yu J Y, Zhu L K, &lt;i&gt;et al&lt;/i&gt;.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J] 光学学报, 2018, 38 (10) :1036001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810052&amp;v=MjY3Mjg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sV3JyUElqWFRiTEc0SDluTnI0OUFab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Jiang X D, Yu J Y, Zhu L K, &lt;i&gt;et al&lt;/i&gt;.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J] 光学学报, 2018, 38 (10) :1036001.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_12" title=" Nie Y F, Xiangli B, Zhou Z L.Advances in light field photography technique[J].Journal of Graduate University of Chinese Academy of Sciences, 2011, 28 (5) :563-572.聂云峰, 相里斌, 周志良.光场成像技术进展[J].中国科学院研究生院学报, 2011, 28 (5) :563-572." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKYB201105002&amp;v=MjYxMjg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sV3JyUFB5YlNiTEc0SDlETXFvOUZab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Nie Y F, Xiangli B, Zhou Z L.Advances in light field photography technique[J].Journal of Graduate University of Chinese Academy of Sciences, 2011, 28 (5) :563-572.聂云峰, 相里斌, 周志良.光场成像技术进展[J].中国科学院研究生院学报, 2011, 28 (5) :563-572.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_13" title=" Sun J Y, Sun J, Xu C L, &lt;i&gt;et al&lt;/i&gt;.A calibration method of focused light field cameras based on light field images[J].Acta Optica Sinica, 2017, 37 (5) :0515002.孙俊阳, 孙俊, 许传龙, 等.一种基于光场图像的聚焦光场相机标定方法[J].光学学报, 2017, 37 (5) :0515002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705022&amp;v=MDg2MDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXcnJQSWpYVGJMRzRIOWJNcW85SFpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Sun J Y, Sun J, Xu C L, &lt;i&gt;et al&lt;/i&gt;.A calibration method of focused light field cameras based on light field images[J].Acta Optica Sinica, 2017, 37 (5) :0515002.孙俊阳, 孙俊, 许传龙, 等.一种基于光场图像的聚焦光场相机标定方法[J].光学学报, 2017, 37 (5) :0515002.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_14" title=" Perwa&#223; C, Wietzke L.Single lens 3D-camera with extended depth-of-field[J].Proceedings of SPIE, 2012, 8291:829108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single lens 3D-camera with extended depth-of-field">
                                        <b>[14]</b>
                                         Perwa&#223; C, Wietzke L.Single lens 3D-camera with extended depth-of-field[J].Proceedings of SPIE, 2012, 8291:829108.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_15" title=" Sun F S, Han X.Super-resolution algorithm based on precise color vector constraint of light field camera[J].Acta Optica Sinica, 2019, 39 (3) :0304001.孙福盛, 韩燮.光场相机精确色彩矢量约束下的超分辨率算法[J].光学学报, 2019, 39 (3) :0304001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903006&amp;v=Mjg5NDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXcnJQSWpYVGJMRzRIOWpNckk5RllvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Sun F S, Han X.Super-resolution algorithm based on precise color vector constraint of light field camera[J].Acta Optica Sinica, 2019, 39 (3) :0304001.孙福盛, 韩燮.光场相机精确色彩矢量约束下的超分辨率算法[J].光学学报, 2019, 39 (3) :0304001.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_16" title=" Sun F S, Han X, Ding J H, &lt;i&gt;et al&lt;/i&gt;.Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J].Computer Engineering and Applications, 2018, 54 (13) :175-180.孙福盛, 韩燮, 丁江华, 等.LYTRO相机光场图像深度估计算法及重建的研究[J].计算机工程与应用, 2018, 54 (13) :175-180." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813028&amp;v=MjM4NjJDVVJMT2VaZVZ1RnlubFdyclBMejdNYWJHNEg5bk5ySTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Sun F S, Han X, Ding J H, &lt;i&gt;et al&lt;/i&gt;.Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J].Computer Engineering and Applications, 2018, 54 (13) :175-180.孙福盛, 韩燮, 丁江华, 等.LYTRO相机光场图像深度估计算法及重建的研究[J].计算机工程与应用, 2018, 54 (13) :175-180.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-16 17:46</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(08),200-207 DOI:10.3788/AOS201939.0815001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于微透镜阵列型光场相机的多目标快速测距方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E7%A6%8F%E7%9B%9B&amp;code=27517913&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙福盛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A9%E7%87%AE&amp;code=09479268&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">韩燮</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8C%97%E5%A4%A7%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E9%99%A2&amp;code=0036109&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中北大学大数据学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>以LYTRO相机为例, 提出一种基于微透镜阵列型 (MLA) 光场相机的多目标快速测距方法。该方法的研究过程分为三个部分:第一部分, 通过对原始数据进行点扩展函数计算及色彩恢复, 并对数据进行超分辨处理, 获取重聚焦序列图像, 完成对待测目标的预处理过程;第二部分, 利用三角形定理, 通过贴片的方法, 提出一种直接测距法;第三部分, 对现有的相对测距法进行超分辨处理, 大幅提高算法精度, 同时利用改进型的拉普拉斯算子验证算法的正确性。最后将这两种算法结合, 即得到一种MLA光场相机的多目标快速测距算法。实验证明, 对于少量待测物体, 直接测距法精度高, 速度快;对于数量较多的待测物体, 将直接测距法与相对测距法相结合, 不但能够保证精度, 还可以提高时效性。该方法为光场相机深度获取、三维重建等方面的研究提供了重要的数据参考及较为精准的评价依据。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BF%AB%E9%80%9F%E6%B5%8B%E8%B7%9D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">快速测距;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E9%80%8F%E9%95%9C%E9%98%B5%E5%88%97%E5%9E%8B%E5%85%89%E5%9C%BA%E7%9B%B8%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微透镜阵列型光场相机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超分辨率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E7%9B%AE%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多目标;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *孙福盛 E-mail:sfs2699@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61672473);</span>
                                <span>山西省重点研发技术项目 (201803D121081);</span>
                                <span>山西省自然科学基金 (2015021093);</span>
                    </p>
            </div>
                    <h1><b>Multi-Objective Fast Ranging Method Based on Microlens Array Light Field Camera</b></h1>
                    <h2>
                    <span>Sun Fusheng</span>
                    <span>Han Xie</span>
            </h2>
                    <h2>
                    <span>School of Data Science and Technology, North University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Taking LYTRO camera as an example, a fast multi-target ranging method based on microlens array (MLA) light field camera is proposed. The process of the method is divided into three parts. In the first part, the paper acquire the re-focusing sequence images of the data by calculating the point spread function, restoring the color of the original data and conducting the super resolution. Then the pretreatment process of the target is completed. In the second part, a direct ranging method is proposed by using the principle of triangle and patch method. In the third part, the existing relative ranging method is optimized by super-resolution processing, which greatly improves the accuracy of the original algorithm. At the same time, the correctness of the algorithm is verified by the improved Laplace operator. Finally, a fast multi-target ranging algorithm for MLA light field camera is obtained by combining the two algorithms. Experiments results show that, for small number of objects to be measured, the direct ranging method is with high accuracy and fast speed, and for large number of objects to be measured, the combination of direct ranging method and relative ranging method can not only ensure the accuracy, but also greatly improve the timeliness. The proposed method can provide important data reference and more accurate evaluation basis for depth acquisition and three-dimensional reconstruction of light field camera.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fast%20ranging&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fast ranging;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=microlens%20array%20light%20field%20camera&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">microlens array light field camera;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=super%20resolution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">super resolution;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multiple%20target&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multiple target;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="44">随着计算机科学领域在高精尖技术支持下取得巨大发展, 计算机视觉领域的研究也获得了巨大的进步。在计算机视觉领域, 光场成像技术应用非常广泛。光场成像系统有多种不同的实现方式, 其中包括像机阵列<citation id="130" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、微透镜阵列 (MLA) <citation id="131" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、掩模<citation id="132" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>、物镜阵列<citation id="128" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等。其中MLA光场相机最符合成本效益, 因而被广泛地应用于学术研究及商业领域<citation id="129" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="45">国内外的专家学者对MLA光场相机进行研究时, 研究重点为深度恢复、超分辨率及三维重建等方面。在光场相机深度获取的研究过程中, 国内外相关研究报告所提到的评价参数大多为实测距离, 但MLA光场相机的光学透镜组部件位于光场相机内部, 对距离进行实际测量时, 由于测量点位置的不确定性, 即使使用精度相当高的激光测距, 测量结果仍存在较大误差。现阶段在光场相机的测距研究方面, 国内外研究文献非常少<citation id="133" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 而双目的测距方法多用于远距离目标的测距, 且采集的图像信息分辨率非常高<citation id="134" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。所以对MLA光场相机的测距研究在三维空间深度获取、三维重建等方面具有重要的意义。</p>
                </div>
                <div class="p1">
                    <p id="46">为给深度获取实验数据提供较为准确的评价参数, 本文提出一种为光场相机深度处理服务的多目标测距算法, 通过一次拍照即可完成多目标物的测距工作, 且算法结构简单、时间短、效率高。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">2 LYTRO相机成像模型与深度分辨率</h3>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 LYTRO相机的成像模型</b></h4>
                <div class="p1">
                    <p id="49">光场相机中的光场, 是指空间中所有光线光辐射函数的总体<citation id="135" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。光场包含位置信息 (<i>x</i>, <i>y</i>) 和方向信息 (<i>u</i>, <i>v</i>) , 四维光场数据<citation id="136" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>的获取在光场相机的测距研究中是必不可少的一环。光场的参数化表示方法有很多, 当今最流行的是用光线与两个平行平面的交点坐标进行参数化表征<citation id="137" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 如图1所示。<i>L</i> (<i>x</i>, <i>y</i>, <i>u</i>, <i>v</i>) 表示光场的一个采样, 各变量代表的意义如下:<i>L</i>表示光线强度; (<i>x</i>, <i>y</i>) 和 (<i>u</i>, <i>v</i>) 表示光线与两个平面的交点坐标, 分别代表位置信息和方向信息。在四维光场中, 每一条光线对应光场的一个采样点。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 光场相机双平面参数化表征" src="Detail/GetImg?filename=images/GXXB201908024_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 光场相机双平面参数化表征  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Parametric representation of light field camera in two planes</p>

                </div>
                <div class="p1">
                    <p id="51">令物体入射光在主透镜成像面的坐标为 (<i>x</i>, <i>y</i>) , 物体上的坐标为 (<i>d</i><sub><i>x</i></sub>, <i>d</i><sub><i>y</i></sub>) , 物体到主透镜的距离为<i>s</i>, 在则入射光与透镜的角度为</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mo>=</mo><mi>arctan</mi><mspace width="0.25em" /><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo><mo>/</mo><mi>s</mi><mo stretchy="false">]</mo><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">如图2所示, <i>s</i>为物体到主透镜的距离, <i>F</i>为主透镜焦距, <i>f</i>为微透镜焦距。</p>
                </div>
                <div class="area_img" id="54">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 光场成像结构" src="Detail/GetImg?filename=images/GXXB201908024_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 光场成像结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Light field imaging structure</p>

                </div>
                <div class="p1">
                    <p id="55">定义<b><i>M</i></b>为主透镜的折射矩阵, <b><i>T</i></b>为主透镜与微透镜之间的转换矩阵, <b><i>m</i></b>为微透镜的折射矩阵, <b><i>t</i></b>为微透镜与探测器之间的传播矩阵, 则有</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Μ</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mfrac><mrow><mo>-</mo><mn>1</mn></mrow><mi>F</mi></mfrac></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /><mspace width="0.25em" /><mi mathvariant="bold-italic">Τ</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>F</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mfrac><mrow><mo>-</mo><mn>1</mn></mrow><mi>f</mi></mfrac></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">t</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>f</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">定义<i>a</i>′为主透镜的转换距离, <i>b</i>′为微透镜的移动距离。其中, <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>y</mi><mo>;</mo><mi>arctan</mi><mrow><mo> (</mo><mrow><mfrac><mrow><mi>y</mi><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>y</mi></msub></mrow><mi>s</mi></mfrac></mrow><mo>) </mo></mrow></mrow><mo>]</mo></mrow></mrow></math></mathml>为主透镜转换参数, <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mn>0</mn><mo>;</mo><mfrac><mi>x</mi><mi>f</mi></mfrac></mrow><mo>]</mo></mrow></mrow></math></mathml>为微透镜平移矩阵。</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><msup><mi>a</mi><mo>′</mo></msup><mo>=</mo><mi mathvariant="bold-italic">Τ</mi><mo>×</mo><mi mathvariant="bold-italic">Μ</mi><mo>×</mo><mrow><mo>[</mo><mrow><mi>y</mi><mo>;</mo><mi>arctan</mi><mrow><mo> (</mo><mrow><mfrac><mrow><mi>y</mi><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>y</mi></msub></mrow><mi>s</mi></mfrac></mrow><mo>) </mo></mrow></mrow><mo>]</mo></mrow><mo>, </mo></mtd></mtr><mtr><mtd columnalign="left"><msup><mi>b</mi><mo>′</mo></msup><mo>=</mo><mi mathvariant="bold-italic">Τ</mi><mo>×</mo><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">Μ</mi><mo>×</mo><msup><mi>a</mi><mo>′</mo></msup><mo>+</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>;</mo><mfrac><mi>x</mi><mi>f</mi></mfrac></mrow><mo>]</mo></mrow></mrow><mo>}</mo></mrow><mo>。</mo></mtd></mtr></mtable></mrow></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">由此便可构建光场成像模型。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>2.2 LYTRO相机图像景深分辨率</b></h4>
                <div class="p1">
                    <p id="63">为增加LYTRO相机的测距范围及测距精度, 提高相机的图像景深分辨率是十分必要的。LYTRO相机深度提取的原理是基于主镜像面上同一点在不同微像中存在的视差<citation id="138" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。如图3所示, 距离微透镜镜面距离为<i>a</i>的主镜像面上, 处于两微透镜交会视场中心的一点经两微透镜成像后, 在各自微像中的像素坐标分别为<i>x</i>和-<i>x</i>, 该点在两微像中的视差为2<i>x</i>。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 图像深度提取原理" src="Detail/GetImg?filename=images/GXXB201908024_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 图像深度提取原理  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Principle of image depth extraction</p>

                </div>
                <div class="p1">
                    <p id="65">根据相似三角形定理</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>2</mn><mi>x</mi><mo>=</mo><mn>2</mn><mi>h</mi><mfrac><mi>b</mi><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">式中:<i>b</i>为探测器与微透镜阵列之间的距离;<i>h</i>为目标微透镜中心到主光轴的距离, <i>h</i>=<i>kd</i><sub>p</sub>/2, <i>k</i>为目标微透镜个数, <i>k</i>的最大值取决于<i>a</i>, <i>k</i>=1, 2, 3;<i>d</i><sub>p</sub>为相邻微透镜中心的像素间隔。根据孔径匹配条件, 主镜像面上一点的全孔径光束覆盖的微透镜数为<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow><mi>b</mi></mfrac><mfrac><mrow><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>a</mi></mrow></mfrac><mo>, </mo><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>为微透镜阵列与主镜出瞳面间距, 当|a|相对于L<sub>1</sub>较小时, 该式约等于|a|/b, k的最大值为<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow><mi>b</mi></mfrac><mo>-</mo><mn>1</mn></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="70">对于两微透镜交会视场中一般位置的点, 若成像后的视差记为p<sub><i>plx</i></sub>, 同样有</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>l</mtext><mtext>x</mtext></mrow></msub><mo>=</mo><mn>2</mn><mi>h</mi><mfrac><mi>b</mi><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">要从原始光场图像得到a, 只需要在中心间距为2h的两微像中找到对应同一物点的像点, 然后确定他们在各自微像中的坐标并计算视差值p<sub><i>plx</i></sub>。若h=kd<sub><i>p</i></sub>/2, 则|a|应不小于 (k+1) b, 可能获得的最大视差值为kd<sub><i>p</i></sub>/ (k+1) 。随着|a|的增加, 视差会逐渐减小。若|a|增加<i>Δ</i>a, 视差值减小一个像素 (本文以一个像素作为最小的可识别视差变化量, 实际中可以小于一个像素, 如文献<citation id="139" type="reference">[<a class="sup">13</a>]</citation>中的亚像素偏移量为1/10个像素) 以提高深度分辨能力, 即</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mn>2</mn><mi>h</mi><mi>b</mi></mrow><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>-</mo><mfrac><mrow><mn>2</mn><mi>h</mi><mi>b</mi></mrow><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo><mo>+</mo><mtext>Δ</mtext><mi>a</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mspace width="0.25em" /><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">则像方深度分辨率为</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>a</mi><mo>=</mo><mfrac><mrow><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>h</mi><mi>b</mi><mo>-</mo><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">3 <i>LYTRO</i>相机快速测距算法</h3>
                <div class="p1">
                    <p id="77"><i>LYTRO</i>相机快速测距算法主要分为图像预处理及算法实现两个步骤。算法实现过程又分为直接测距算法、相对测距算法优化、融合算法三个部分, 具体算法结构如图4所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 算法结构图" src="Detail/GetImg?filename=images/GXXB201908024_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 算法结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Structural diagram of the algorithm</p>

                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>3.1 图像预处理</b></h4>
                <div class="p1">
                    <p id="80">MLA光场相机有两个限制问题, 低空间分辨率和窄基线。低空间分辨率限制了光场相机的通用性和适用性, 而窄基线限制了深度估计的范围和精度。本文对数据进行预处理, 有效地增加深度估计的范围和精度, 使得测距精度大幅提高。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">3.1.1 通过点扩展函数对图像进行超分辨处理</h4>
                <div class="p1">
                    <p id="82">LYTRO相机对原始图像进行拍摄, 获取的结果如图5所示。图5 (b) 为图5 (a) 中方框的放大图像, 图5 (c) 为图5 (b) 中方框的放大图像。</p>
                </div>
                <div class="p1">
                    <p id="83">按照文献<citation id="140" type="reference">[<a class="sup">15</a>]</citation>的方法, 对原始图像进行超分辨处理, 结果如图6所示。图6 (b) 、 (c) 分别为图6 (a) 中上方方框及下方方框的放大图像 (局部放大图像1和局部放大图像2) , 图6 (d) 为图6 (c) 的局部放大图像3。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">3.1.2 图像重聚焦</h4>
                <div class="p1">
                    <p id="85">使用文献<citation id="141" type="reference">[<a class="sup">5</a>]</citation>的方法, 通过设置不同的<i>α</i>值, 在频域中通过对四维光场数据进行傅里叶变换及逆变换得到一组重聚焦序列图像。图像序列中图像的个数由待测物体数量决定, 为待测物体数量的<i>l</i>倍 (<i>l</i>≥1) , 数量越大, 精度越高, 计算量越大, 时间复杂度就会越高, 同时还会引入噪声<citation id="142" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。经过实验, 将<i>l</i>设置为1.5或2.0较为合适。如图7所示, 图7 (a) 为24只彩色水笔组成的原始图像;图7 (b) 为由36张图像构成的图像序列。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 原始图像及局部放大图像。" src="Detail/GetImg?filename=images/GXXB201908024_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 原始图像及局部放大图像。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Original image and local enlarged images.</p>
                                <p class="img_note"> (a) 原始图像; (b) 局部放大图像; (c) 局部二次放大图像</p>
                                <p class="img_note"> (a) Original image; (b) local enlarged image; (c) local two-time enlarged image</p>

                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 超分辨恢复结果。" src="Detail/GetImg?filename=images/GXXB201908024_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 超分辨恢复结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Super-resolution recovery results.</p>
                                <p class="img_note"> (a) 原始图像; (b) 局部放大图像1; (c) 局部放大图像2; (d) 局部二次放大图像3</p>
                                <p class="img_note"> (a) Original image; (b) local enlarged image 1; (c) local enlarged image 2; (d) local two-time enlarged image 3</p>

                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 重聚焦图像序列。" src="Detail/GetImg?filename=images/GXXB201908024_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 重聚焦图像序列。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Re-focusing image sequence. </p>
                                <p class="img_note"> (a) 原始图像; (b) 重聚焦图像序列 (36张) </p>
                                <p class="img_note"> (a) Original image; (b) refocus image sequence (36 pieces) </p>

                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>3.2 直接测距法</b></h4>
                <div class="p1">
                    <p id="90">直接测距法需要对目标物进行贴片处理, 如图8所示。文中使用的贴片为点云扫描仪所使用的制式贴片, 由于贴片的双层圆面有固定的比例关系, 因此在计算贴片像素大小时, 能够保证实验精度, 减小实验误差。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 贴片示意图" src="Detail/GetImg?filename=images/GXXB201908024_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 贴片示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Schematic of the patch</p>

                </div>
                <div class="p1">
                    <p id="92">经预处理后, 对目标物作标准化测量, 如图9中所示。测距公式为</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow><mi>s</mi></mfrac><mo>=</mo><mfrac><mi>n</mi><mi>d</mi></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式中:<i>s</i>为待测目标的距离;<i>n</i><sub><i>s</i></sub>为待测目标的贴片像素大小;<i>d</i>为实测标准距离;<i>n</i>为实测标准距离下目标物贴片像素大小。值得注意的是, 公式中<i>n</i>、<i>n</i><sub><i>s</i></sub>均为超分辨处理后贴片的像素大小。</p>
                </div>
                <div class="p1">
                    <p id="95">算法流程如下:</p>
                </div>
                <div class="p1">
                    <p id="96">1) 对本组实验目标物进行贴片处理;</p>
                </div>
                <div class="p1">
                    <p id="97">2) 经过实际测量可得, 图9 (a) 中贴片木块距相机镜头距离为5 cm, 图9 (b) 中贴片木块距相机镜头距离为10 cm, 图9 (c) 中贴片木块距相机镜头距离为20 cm;</p>
                </div>
                <div class="p1">
                    <p id="98">3) 用LYTRO相机对目标物进行拍照, 并对照片作预处理;</p>
                </div>
                <div class="p1">
                    <p id="99">4)  在重聚焦图像序列中选出贴片位置最清晰的图像 (以清晰度评价函数作为选择依据) ;</p>
                </div>
                <div class="p1">
                    <p id="100">5) 利用文献<citation id="143" type="reference">[<a class="sup">13</a>]</citation>的亚像素偏移窗口选择算法, 确定贴片位置;</p>
                </div>
                <div class="p1">
                    <p id="101">6) 计算贴片中灰色亮片的像素大小 (图9中已用圆圈标识出) ;</p>
                </div>
                <div class="p1">
                    <p id="102">7) 测得的像素大小与距离作为测量标准值;</p>
                </div>
                <div class="p1">
                    <p id="103">8) 利用三角形定理, 结合测量标准值, 按照 (8) 式, 即可换算出待测目标的距离。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 贴片标准值测量。" src="Detail/GetImg?filename=images/GXXB201908024_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 贴片标准值测量。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Standard value measurement of the patch. </p>
                                <p class="img_note"> (a) 距离为5 cm; (b) 距离为10 cm; (c) 距离为20 cm</p>
                                <p class="img_note"> (a) Distance is 5 cm; (b) distance is 10 cm; (c) distance is 20 cm</p>

                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>3.3 相对测距法优化</b></h4>
                <div class="p1">
                    <p id="106">通过对待测目标物进行预处理及超分辨处理后, 目标数据的图像景深分辨率获得大幅提高, 使得相对测距法的实验精度也有很大的提升。在此基础上对文献<citation id="144" type="reference">[<a class="sup">10</a>]</citation>算法进行优化, 实验过程如图10所示。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 贴片标准值测量。" src="Detail/GetImg?filename=images/GXXB201908024_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 贴片标准值测量。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Standard value measurement of the patch. </p>
                                <p class="img_note"> (a) 文献数据; (b) 本文数据</p>
                                <p class="img_note"> (a) Literature data; (b) data in this paper</p>

                </div>
                <div class="p1">
                    <p id="108">文献<citation id="145" type="reference">[<a class="sup">10</a>]</citation>中测得两个待测目标的距离范围始终是6550～6992 μm, 与理论值<i>f</i>=6440 μm之间的偏差范围是1.71%～8.5%。</p>
                </div>
                <div class="p1">
                    <p id="109">本文对实验目标图像进行超分辨处理后, 通过相同的算法处理, 得到两个待测目标的距离范围为6449～6465 μm, 与理论值<i>f</i>=6440 μm之间的偏差范围是1.53%～3.89%。测量精度相比文献<citation id="146" type="reference">[<a class="sup">10</a>]</citation>, 有了很大的提高。根据透镜成像原理, 主透镜与微透镜阵列的距离<i>d</i><sub>0</sub>大于初始焦距<i>F</i>, 这验证了本算法的正确性。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.4 算法验证</b></h4>
                <div class="p1">
                    <p id="111">采用文献<citation id="147" type="reference">[<a class="sup">10</a>]</citation>中的改进型拉普拉斯算子作为聚焦度评价算子对重聚焦光场图像序列进行清晰度评价, 实验结果如图11所示。其中, 图11 (a) 是文献<citation id="148" type="reference">[<a class="sup">10</a>]</citation>中采用改进型拉普拉斯算子得到的深度图像;图11 (b) 是通过文献<citation id="149" type="reference">[<a class="sup">16</a>]</citation>对本文中待测目标进行深度估计处理后得到的深度图像。颜色越深, 说明目标距离相机越近, 反之亦然。深度图的一致性证明本文优化后算法的正确性。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 算法验证" src="Detail/GetImg?filename=images/GXXB201908024_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 算法验证  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Algorithm validation.</p>
                                <p class="img_note">。 (a) 文献算法结果; (b) 本文算法结果</p>
                                <p class="img_note"> (a) Results of algorithm in literature; (b) results of proposed algorithm</p>

                </div>
                <h3 id="113" name="113" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="114">实验相机为第一代LYTRO相机, 相机序列号:sn-A502390678, 运行环境:Windows 8, 64位操作系统, 处理器:AMD Athlon (tm) ×4740 Quad Core Processor 3.20 GHz。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>4.1 实验1</b></h4>
                <div class="p1">
                    <p id="116">本组实验针对少量待测目标, 如图12所示, 设置6组不同距离、相同数量的待测目标, 每组实验目标均为2个已贴片木块, 图中目标物1固定位置, 目标物2位置不断变换。实验数据如表1所示。表1中的实际距离与实验距离均为相机镜头到待测目标之间的直线距离。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 6组待测目标图像。目标物1的距离固定为20 cm, 目标物2的距离分别为 (a) 25 cm; (b) 30 cm; (c) 40 cm; (d) 50 cm; (e) 60 cm; (f) 70 cm" src="Detail/GetImg?filename=images/GXXB201908024_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 6组待测目标图像。目标物1的距离固定为20 cm, 目标物2的距离分别为 (a) 25 cm; (b) 30 cm; (c) 40 cm; (d) 50 cm; (e) 60 cm; (f) 70 cm  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 Six groups of target images to be measured. The distance of target 1 is fixed as 20 cm, and the distance of target 2 is (a) 25 cm; (b) 30 cm; (c) 40 cm; (d) 50 cm; (e) 60 cm; (f) 70 cm</p>

                </div>
                <div class="area_img" id="118">
                    <p class="img_tit">表1 实验1数据 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Experiment 1 data </p>
                    <p class="img_note">cm</p>
                    <table id="118" border="1"><tr><td><br />Experiment 1</td><td>Fig. 12 (a) </td><td>Fig. 12 (b) </td><td>Fig. 12 (c) </td><td>Fig. 12 (d) </td><td>Fig. 12 (e) </td><td>Fig. 12 (f) </td></tr><tr><td><br />Actual distance of target 1</td><td>20</td><td>20</td><td>20</td><td>20</td><td>20</td><td>20</td></tr><tr><td><br />Experimental distance of target 1</td><td>19.868</td><td>20.153</td><td>19.912</td><td>19.930</td><td>19.895</td><td>20.064</td></tr><tr><td><br />Actual distance of target 2</td><td>25</td><td>30</td><td>40</td><td>50</td><td>60</td><td>70</td></tr><tr><td><br />Experimental distance of target 2</td><td>24.733</td><td>29.617</td><td>39.389</td><td>49.051</td><td>57.816</td><td>66.175</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="119">对表1分析, 待测目标物距离相机越远, 测量精度越低。当距离小于50 cm时, 测量误差小于2%;在距离大于50 cm后, 测量误差明显上升, 误差大于3.5%。其原因可能是由于距离较远时, 图像超分辨效果降低, 实验测得的贴片像素值小于实际像素值。因此, 本算法若在保证高精度的前提下, 在测距范围上有一定的限制, 在今后的研究过程中, 超分辨算法还有待继续优化与提高。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>4.2 实验2</b></h4>
                <div class="p1">
                    <p id="121">本组实验针对大量待测目标, 如图13所示, 设置了4组不同距离、不同数量的待测目标, 每组实验目标由2种算法计算, 算法时间如表2所示。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908024_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 4组待测目标图像。" src="Detail/GetImg?filename=images/GXXB201908024_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 4组待测目标图像。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908024_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 13 Four groups of target images to be measured.</p>
                                <p class="img_note"> (a) 3个目标物; (b) 7个目标物; (c) 10个目标物; (d) 12个目标物</p>
                                <p class="img_note"> (a) 3 targets; (b) 7 targets; (c) 10 targets; (d) 12 targets</p>

                </div>
                <div class="area_img" id="123">
                    <p class="img_tit">表2 实验2数据 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Experiment 2 data</p>
                    <p class="img_note"></p>
                    <table id="123" border="1"><tr><td><br />Experiment 2</td><td>Fig. 13 (a) </td><td>Fig. 13 (b) </td><td>Fig. 13 (c) </td><td>Fig. 13 (d) </td></tr><tr><td><br />Number of objects</td><td>3</td><td>7</td><td>10</td><td>12</td></tr><tr><td><br />Measured number</td><td>3</td><td>6</td><td>10</td><td>12</td></tr><tr><td><br />Direct algorithm time /s</td><td>6.5176</td><td>13.6583</td><td>25.8174</td><td>41.2637</td></tr><tr><td><br />Indirect algorithm time /s</td><td>12.1361</td><td>22.1569</td><td>31.7033</td><td>40.8609</td></tr><tr><td><br />The shortest time of composition algorithms /s</td><td>6.5176</td><td>13.6583</td><td>25.8174</td><td>38.9540</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="124">对表2分析, 随着待测目标数量的增加, 两种测距方法的算法时间也在逐渐增加。对于少量待测目标而言, 直接法时效性更高;但当待测目标数量大于10个时, 结合算法的时效性优于2种算法单独使用。对于图13 (b) 中被遮挡的待测物体 (target 3) , 由于待测物体摆放位置的原因, 待测贴片被前一目标物所遮挡, 无法完成测距。但在实际情况中, 由于待测目标物为客观存在, 贴片操作作为标记物为算法提供支持, 为后续操作, 因此, 算法的缺点可以避免。同时, 该算法可适用于不同型号的MLA光场相机 (对于微透镜阵列型光场相机, 在成像原理相同的情况下, 该算法均可适用;但对于相机阵列、掩模及其他类型的光场相机并不适用) , 算法适应性较高。</p>
                </div>
                <h3 id="125" name="125" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="126">提出一种基于MLA光场相机的多目标快速测距方法。文中使用的优化算法及融合算法对测距方法的整体时间进行大幅优化, 且通过一次拍照即可完成对多目标物的测距工作。少量待测物体, 直接测距法精度高, 速度快;数量较多的待测物体, 将直接测距法与相对测距法结合, 不但能够保证精度, 而且时效性也会大幅提高。本文算法同样适用于运动目标的测距, 在对运动目标进行测距时, 可通过外接触发器对运动目标进行连续、快速地拍摄, 通过对每一帧图像的分别处理完成对运动目标的测距, 同时可从测距结果中获得运动目标的轨迹深度图信息, 这将是下一阶段的重点研究内容。</p>
                </div>
                <div class="p1">
                    <p id="127">在今后的研究学习中, 在如何优化测距算法、使用融合测距算法时如何确定直接测距法的中心待测目标位置、间接测距法的最短路径、提高算法时效性等问题上, 还需作进一步的研究。而对于更多数量的待测目标测距算法的研究仍是今后的研究重点。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="11">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098252&amp;v=MDk4NDN1SHlqbVViL0lJVjRkYnhVPU5pZklZN0s3SHRqTnI0OUZaT0lIRG5rN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Wilburn B, Joshi N, Vaish V, <i>et al</i>.High performance imaging using large camera arrays[J].ACM Transactions on Graphics, 2005, 24 (3) :765-776.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D TV: A scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes">

                                <b>[2]</b> Matusik W, Pfister H.3D TV:a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes[J].ACM Transactions on Graphics, 2004, 23 (3) :814-824.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A real time interactive dynamic light field transmission system">

                                <b>[3]</b> Liu Y B, Dai Q H, Xu W L.A real time interactive dynamic light field transmission system[C]//2006 IEEE International Conference on Multimedia and Expo, July 9-12, 2006, Toronto, Ont., Canada.New York:IEEE, 2006:2173-2176.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Light Field Photography with a Hand-Held Plenoptic Camera">

                                <b>[4]</b> Ng R, Levoy M, Brédif M, <i>et al</i>.Light field photography with a hand-held plenoptic camera[J].Stanford Tech Report CTSR, 2005, 2:1-11.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098249&amp;v=MDI2MzhqbVViL0lJVjRkYnhVPU5pZklZN0s3SHRqTnI0OUZaT0lIRG5nd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Ng R.Fourier slice photography[J].ACM Transactions on Graphics, 2005, 24 (3) :735-744.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098521&amp;v=MDk5MTJIeWptVWIvSUlWNGRieFU9TmlmSVk3SzdIdGpOcjQ5RlpPSUhDWDQ0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Veeraraghavan A, Raskar R, Agrawal A, <i>et al</i>.Dappled photography:mask enhanced cameras for heterodyned light fields and code aperture refocusing[J].ACM Transactions on Graphics, 2007, 26 (3) :69.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098623&amp;v=MDk1OTZIdGpOcjQ5RlpPSUhDbjQ2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSVY0ZGJ4VT1OaWZJWTdLNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Liang C K, Lin T H, Wong B Y, <i>et al</i>.Programmable aperture photography:multiplexed light field acquisition[J].ACM Transactions on Graphics, 2008, 27 (3) :55.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pelican[OL]">

                                <b>[8]</b> Pelican[OL].[2019-02-15].http://www.pelican.com/.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lytro camera technology:theory,algorithms,performance analysis">

                                <b>[9]</b> Georgiev T, Yu Z, Lumsdaine A, <i>et al</i>.Lytro camera technology:theory, algorithms, performance analysis[J] Proceeding of SPIE, 2013, 8667:86671J.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017167288.nh&amp;v=MjY5NzE0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sV3JyUFZGMjZHYksrR2RQRXA1RWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Ding J H.Research on depth map estimation of micro lens array light field photography[D].Taiyuan:North University of China, 2017.丁江华.基于微透镜阵列的光场图像深度估计研究[D].太原:中北大学, 2017.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810052&amp;v=MjY3OTVxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXcnJQSWpYVGJMRzRIOW5OcjQ5QVpvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Jiang X D, Yu J Y, Zhu L K, <i>et al</i>.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J] 光学学报, 2018, 38 (10) :1036001.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKYB201105002&amp;v=MTAxNTJxbzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlubFdyclBQeWJTYkxHNEg5RE0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Nie Y F, Xiangli B, Zhou Z L.Advances in light field photography technique[J].Journal of Graduate University of Chinese Academy of Sciences, 2011, 28 (5) :563-572.聂云峰, 相里斌, 周志良.光场成像技术进展[J].中国科学院研究生院学报, 2011, 28 (5) :563-572.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705022&amp;v=MDY4NzR6cXFCdEdGckNVUkxPZVplVnVGeW5sV3JyUElqWFRiTEc0SDliTXFvOUhab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Sun J Y, Sun J, Xu C L, <i>et al</i>.A calibration method of focused light field cameras based on light field images[J].Acta Optica Sinica, 2017, 37 (5) :0515002.孙俊阳, 孙俊, 许传龙, 等.一种基于光场图像的聚焦光场相机标定方法[J].光学学报, 2017, 37 (5) :0515002.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single lens 3D-camera with extended depth-of-field">

                                <b>[14]</b> Perwaß C, Wietzke L.Single lens 3D-camera with extended depth-of-field[J].Proceedings of SPIE, 2012, 8291:829108.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903006&amp;v=MTUzNTJGeW5sV3JyUElqWFRiTEc0SDlqTXJJOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Sun F S, Han X.Super-resolution algorithm based on precise color vector constraint of light field camera[J].Acta Optica Sinica, 2019, 39 (3) :0304001.孙福盛, 韩燮.光场相机精确色彩矢量约束下的超分辨率算法[J].光学学报, 2019, 39 (3) :0304001.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813028&amp;v=MDE3NzR6cXFCdEdGckNVUkxPZVplVnVGeW5sV3JyUEx6N01hYkc0SDluTnJJOUhiSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Sun F S, Han X, Ding J H, <i>et al</i>.Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J].Computer Engineering and Applications, 2018, 54 (13) :175-180.孙福盛, 韩燮, 丁江华, 等.LYTRO相机光场图像深度估计算法及重建的研究[J].计算机工程与应用, 2018, 54 (13) :175-180.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201908024" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908024&amp;v=MjIxMzN5bmxXcnJQSWpYVGJMRzRIOWpNcDQ5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

