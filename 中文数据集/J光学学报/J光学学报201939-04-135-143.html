

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134114199658750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201904016%26RESULT%3d1%26SIGN%3diMJ0vCTUtyPh0jL71WTrTRCyIac%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904016&amp;v=MjcxMjRiTEc0SDlqTXE0OUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdoVXIvQklqWFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#60" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#65" data-title="2 算法描述 ">2 算法描述</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#66" data-title="&lt;b&gt;2.1 线性嵌入流形结构&lt;/b&gt;"><b>2.1 线性嵌入流形结构</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;2.2 张量流形降维框架&lt;/b&gt;"><b>2.2 张量流形降维框架</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;2.3 显式映射优化求解&lt;/b&gt;"><b>2.3 显式映射优化求解</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#134" data-title="3 实验验证 ">3 实验验证</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#135" data-title="&lt;b&gt;3.1 实验数据说明&lt;/b&gt;"><b>3.1 实验数据说明</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;3.2 降维算法比较&lt;/b&gt;"><b>3.2 降维算法比较</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="图1 流形差异示意图。 (a) LLE算法; (b) GLE算法">图1 流形差异示意图。 (a) LLE算法; (b) GLE算法</a></li>
                                                <li><a href="#98" data-title="图2 张量流形降维框架">图2 张量流形降维框架</a></li>
                                                <li><a href="#139" data-title="图3 &lt;i&gt;Indian Pines&lt;/i&gt;高光谱数据。 (&lt;i&gt;a&lt;/i&gt;) 伪彩色图; (&lt;i&gt;b&lt;/i&gt;) 真实的地物图">图3 <i>Indian Pines</i>高光谱数据。 (<i>a</i>) 伪彩色图; (<i>b</i>) 真实的地物图</a></li>
                                                <li><a href="#142" data-title="图4 &lt;i&gt;PaviaU&lt;/i&gt; 高光谱数据。 (&lt;i&gt;a&lt;/i&gt;) 伪彩色图; (&lt;i&gt;b&lt;/i&gt;) 真实的地物图">图4 <i>PaviaU</i> 高光谱数据。 (<i>a</i>) 伪彩色图; (<i>b</i>) 真实的地物图</a></li>
                                                <li><a href="#147" data-title="图5 稀疏参数λ对分类性能的影响 (&lt;i&gt;Indian Pines&lt;/i&gt;数据) ">图5 稀疏参数λ对分类性能的影响 (<i>Indian Pines</i>数据) </a></li>
                                                <li><a href="#150" data-title="图6 不同算法对&lt;i&gt;Indian Pines&lt;/i&gt;数据的降维效果。 (&lt;i&gt;a&lt;/i&gt;) 真实的地物图; (&lt;i&gt;b&lt;/i&gt;) &lt;i&gt;PCA&lt;/i&gt;算法; (&lt;i&gt;c&lt;/i&gt;) &lt;i&gt;MNF&lt;/i&gt;算法; (&lt;i&gt;d&lt;/i&gt;) &lt;i&gt;LLE&lt;/i&gt;算法; (&lt;i&gt;e&lt;/i&gt;) &lt;i&gt;LE&lt;/i&gt;算法; (&lt;i&gt;f&lt;/i&gt;) &lt;i&gt;LPP&lt;/i&gt;算法; (&lt;i&gt;g&lt;/i&gt;) &lt;i&gt;RP&lt;/i&gt;算法; (&lt;i&gt;h&lt;/i&gt;) 所提算法">图6 不同算法对<i>Indian Pines</i>数据的降维效果。 (<i>a</i>) 真实的地物图; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法</a></li>
                                                <li><a href="#151" data-title="图7 不同算法对&lt;i&gt;PaviaU&lt;/i&gt;数据的降维效果。 (&lt;i&gt;a&lt;/i&gt;) 真实的地物图; (&lt;i&gt;b&lt;/i&gt;) &lt;i&gt;PCA&lt;/i&gt;算法; (&lt;i&gt;c&lt;/i&gt;) &lt;i&gt;MNF&lt;/i&gt;算法; (&lt;i&gt;d&lt;/i&gt;) &lt;i&gt;LLE&lt;/i&gt;算法; (&lt;i&gt;e&lt;/i&gt;) &lt;i&gt;LE&lt;/i&gt;算法; (&lt;i&gt;f&lt;/i&gt;) &lt;i&gt;LPP&lt;/i&gt;算法; (&lt;i&gt;g&lt;/i&gt;) &lt;i&gt;RP&lt;/i&gt;算法; (&lt;i&gt;h&lt;/i&gt;) 所提算法">图7 不同算法对<i>PaviaU</i>数据的降维效果。 (<i>a</i>) 真实的地物图; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法</a></li>
                                                <li><a href="#153" data-title="图8 不同降维算法的投影结果 (&lt;i&gt;Indian Pines&lt;/i&gt;数据) 。 (&lt;i&gt;a&lt;/i&gt;) 原数据 (波段1 &amp;amp; 2) ; (&lt;i&gt;b&lt;/i&gt;) &lt;i&gt;PCA&lt;/i&gt;算法; (&lt;i&gt;c&lt;/i&gt;) &lt;i&gt;MNF&lt;/i&gt;算法; (&lt;i&gt;d&lt;/i&gt;) &lt;i&gt;LLE&lt;/i&gt;算法; (&lt;i&gt;e&lt;/i&gt;) &lt;i&gt;LE&lt;/i&gt;算法; (&lt;i&gt;f&lt;/i&gt;) &lt;i&gt;LPP&lt;/i&gt;算法; (&lt;i&gt;g&lt;/i&gt;) &lt;i&gt;RP&lt;/i&gt;算法; (&lt;i&gt;h&lt;/i&gt;) 所提算法">图8 不同降维算法的投影结果 (<i>Indian Pines</i>数据) 。 (<i>a</i>) 原数据 (波段1 &amp; 2) ; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法</a></li>
                                                <li><a href="#159" data-title="表1 不同降维算法的分类精度">表1 不同降维算法的分类精度</a></li>
                                                <li><a href="#160" data-title="图9 不同嵌入维度下各算法的分类性能。 (a) Indian Pines数据; (b) PaviaU数据">图9 不同嵌入维度下各算法的分类性能。 (a) Indian Pines数据; (b) PaviaU......</a></li>
                                                <li><a href="#162" data-title="表2 各算法的时间复杂度">表2 各算法的时间复杂度</a></li>
                                                <li><a href="#164" data-title="表3 各算法的计算时间">表3 各算法的计算时间</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="12">


                                    <a id="bibliography_1" title=" Ghamisi P, Yokoya N, Li J, &lt;i&gt;et al&lt;/i&gt;.Advances in hyperspectral image and signal processing:a comprehensive overview of the state of the art[J].Proceedings of the IEEE, 2017, 5 (4) :37-78." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advances in hyperspectral image and signal processing: a comprehensive overview of the state of the art">
                                        <b>[1]</b>
                                         Ghamisi P, Yokoya N, Li J, &lt;i&gt;et al&lt;/i&gt;.Advances in hyperspectral image and signal processing:a comprehensive overview of the state of the art[J].Proceedings of the IEEE, 2017, 5 (4) :37-78.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_2" title=" Bioucas-Dias J M, Plaza A, Camps-Valls G, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral remote sensing data analysis and future challenges[J].Proceedings of the IEEE, 2013, 1 (2) :6-36." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hyperspectral remote sensing data analysis and future challenges">
                                        <b>[2]</b>
                                         Bioucas-Dias J M, Plaza A, Camps-Valls G, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral remote sensing data analysis and future challenges[J].Proceedings of the IEEE, 2013, 1 (2) :6-36.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_3" title=" Li W, Feng F B, Li H C, &lt;i&gt;et al&lt;/i&gt;.Discriminant analysis-based dimension reduction for hyperspectral image classification:a survey of the most recent advances and an experimental comparison of different techniques[J].Proceedings of the IEEE, 2018, 6 (1) :15-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminant analysis-based dimension reduction for hyperspectral image classification:a survey of the most recent advances and an experimental comparison of different techniques">
                                        <b>[3]</b>
                                         Li W, Feng F B, Li H C, &lt;i&gt;et al&lt;/i&gt;.Discriminant analysis-based dimension reduction for hyperspectral image classification:a survey of the most recent advances and an experimental comparison of different techniques[J].Proceedings of the IEEE, 2018, 6 (1) :15-34.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_4" title=" Sun W W, Yang G, Du B, &lt;i&gt;et al&lt;/i&gt;.A sparse and low-rank near-isometric linear embedding method for feature extraction in hyperspectral imagery classification[J].Proceedings of the IEEE, 2017, 55 (7) :4032-4046." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A sparse and low-rank near-isometric linear embedding method for feature extraction in hyperspectral imagery classification">
                                        <b>[4]</b>
                                         Sun W W, Yang G, Du B, &lt;i&gt;et al&lt;/i&gt;.A sparse and low-rank near-isometric linear embedding method for feature extraction in hyperspectral imagery classification[J].Proceedings of the IEEE, 2017, 55 (7) :4032-4046.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_5" title=" Dong A G, Li J X, Zhang B, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :0828005.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :0828005." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MjYyODVMRzRIOWJNcDQ5Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2hVci9CSWpYVGI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Dong A G, Li J X, Zhang B, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :0828005.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :0828005.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_6" title=" Zhang W Q, Li X R, Dou Y X, &lt;i&gt;et al&lt;/i&gt;.A geometry-based band selection approach for hyperspectral image analysis[J].Proceedings of the IEEE, 2018, 56 (8) :4318-4333." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A geometry-based band selection approach for hyperspectral image analysis">
                                        <b>[6]</b>
                                         Zhang W Q, Li X R, Dou Y X, &lt;i&gt;et al&lt;/i&gt;.A geometry-based band selection approach for hyperspectral image analysis[J].Proceedings of the IEEE, 2018, 56 (8) :4318-4333.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_7" title=" Wang M D, Yu J, Niu L J, &lt;i&gt;et al&lt;/i&gt;.Feature extraction for hyperspectral images using low-rank representation with neighborhood preserving regularization[J].Proceedings of the IEEE, 2017, 14 (6) :836-840." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature extraction for hyperspectral images using low-rank representation with neighborhood preserving regularization">
                                        <b>[7]</b>
                                         Wang M D, Yu J, Niu L J, &lt;i&gt;et al&lt;/i&gt;.Feature extraction for hyperspectral images using low-rank representation with neighborhood preserving regularization[J].Proceedings of the IEEE, 2017, 14 (6) :836-840.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_8" title=" Wei F, He M Y, Feng Y, &lt;i&gt;et al&lt;/i&gt;.Feature extraction on matrix factorization for hyperspectral data[J].Journal of Infrared and Millimeter Waves, 2014, 33 (6) :674-679.魏峰, 何明一, 冯燕, 等.基于矩阵分解的高光谱数据特征提取[J].红外与毫米波学报, 2014, 33 (6) :674-679." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201406018&amp;v=MjI4MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5N2hVci9CTFRyU1pyRzRIOVhNcVk5RWJJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Wei F, He M Y, Feng Y, &lt;i&gt;et al&lt;/i&gt;.Feature extraction on matrix factorization for hyperspectral data[J].Journal of Infrared and Millimeter Waves, 2014, 33 (6) :674-679.魏峰, 何明一, 冯燕, 等.基于矩阵分解的高光谱数据特征提取[J].红外与毫米波学报, 2014, 33 (6) :674-679.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_9" title=" Licciardi G, Marpu P R, Chanussot J, &lt;i&gt;et al&lt;/i&gt;.Linear versus nonlinear PCA for the classification of hyperspectral data based on the extended morphological profiles[J].Proceedings of the IEEE, 2012, 9 (3) :447-451." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linear Versus Nonlinear PCA for the Classification of Hyperspectral Data Based on the Extended Morphological Profiles">
                                        <b>[9]</b>
                                         Licciardi G, Marpu P R, Chanussot J, &lt;i&gt;et al&lt;/i&gt;.Linear versus nonlinear PCA for the classification of hyperspectral data based on the extended morphological profiles[J].Proceedings of the IEEE, 2012, 9 (3) :447-451.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_10" title=" Green A A, Berman M, Switzer P, &lt;i&gt;et al&lt;/i&gt;.A transformation for ordering multispectral data in terms of image quality with implications for noise removal[J].Proceedings of the IEEE, 1988, 26 (1) :65-74." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A transformation for ordering multispectral data in terms of image quality with implications for noise removal">
                                        <b>[10]</b>
                                         Green A A, Berman M, Switzer P, &lt;i&gt;et al&lt;/i&gt;.A transformation for ordering multispectral data in terms of image quality with implications for noise removal[J].Proceedings of the IEEE, 1988, 26 (1) :65-74.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_11" title=" Crawford M, Held A A, Burger J.Nonlinear manifolds for feature extraction:opportunities and challenge[J].Proceedings of the IEEE, 2011:1-3." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear manifolds for feature extraction:opportunities and challenge">
                                        <b>[11]</b>
                                         Crawford M, Held A A, Burger J.Nonlinear manifolds for feature extraction:opportunities and challenge[J].Proceedings of the IEEE, 2011:1-3.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_12" title=" Lunga D, Prasad S, Crawford M M, &lt;i&gt;et al&lt;/i&gt;.Manifold-learning-based feature extraction for classification of hyperspectral data:a review of advances in manifold learning[J].Proceedings of the IEEE, 2014, 31 (1) :55-66." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Manifold-learning-based feature extraction for classification of hyperspectral data:a review of advances in manifold learning">
                                        <b>[12]</b>
                                         Lunga D, Prasad S, Crawford M M, &lt;i&gt;et al&lt;/i&gt;.Manifold-learning-based feature extraction for classification of hyperspectral data:a review of advances in manifold learning[J].Proceedings of the IEEE, 2014, 31 (1) :55-66.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_13" title=" Ma L, Crawford M M, Yang X Q, &lt;i&gt;et al&lt;/i&gt;.Local-manifold-learning-based graph construction for semisupervised hyperspectral image classification[J].Proceedings of the IEEE, 2015, 53 (5) :2832-2844." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local-manifold-learning-based graph construction for semisupervised hyperspectral image classification">
                                        <b>[13]</b>
                                         Ma L, Crawford M M, Yang X Q, &lt;i&gt;et al&lt;/i&gt;.Local-manifold-learning-based graph construction for semisupervised hyperspectral image classification[J].Proceedings of the IEEE, 2015, 53 (5) :2832-2844.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_14" title=" Zhai Y G, Zhang L F, Wang N, &lt;i&gt;et al&lt;/i&gt;.A modified locality-preserving projection approach for hyperspectral image classification[J].Proceedings of the IEEE, 2016, 13 (8) :1059-1063." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A modified locality-preserving projection approach for hyperspectral image classification">
                                        <b>[14]</b>
                                         Zhai Y G, Zhang L F, Wang N, &lt;i&gt;et al&lt;/i&gt;.A modified locality-preserving projection approach for hyperspectral image classification[J].Proceedings of the IEEE, 2016, 13 (8) :1059-1063.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_15" title=" Chen X Z, Hu H J, Wang X S.Dimensionality reduction for hyperspectral data using weighted neighborhood preserving embedding[J].Journal of China University of Mining &amp;amp; Technology, 2013, 42 (6) :1066-1072.陈新忠, 胡汇涓, 王雪松.基于加权近邻保持嵌入的高光谱数据降维方法[J].中国矿业大学学报, 2013, 42 (6) :1066-1072." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGKD201306028&amp;v=MTcxNDVMT2VaZVZ1Rnk3aFVyL0JQeXJBYXJHNEg5TE1xWTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Chen X Z, Hu H J, Wang X S.Dimensionality reduction for hyperspectral data using weighted neighborhood preserving embedding[J].Journal of China University of Mining &amp;amp; Technology, 2013, 42 (6) :1066-1072.陈新忠, 胡汇涓, 王雪松.基于加权近邻保持嵌入的高光谱数据降维方法[J].中国矿业大学学报, 2013, 42 (6) :1066-1072.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_16" title=" He X F, Niyogi P.Locality preserving projection[C].Advances in Neural Information Processing System, 2004 (16) :153-160." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locality preserving projections">
                                        <b>[16]</b>
                                         He X F, Niyogi P.Locality preserving projection[C].Advances in Neural Information Processing System, 2004 (16) :153-160.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_17" title=" Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">
                                        <b>[17]</b>
                                         Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_18" title=" Chen Z, Wang B, Zhang L M.Dimensionality reduction and classification based on lower rank tensor analysis for hyperspectral imagery[J].Journal of Infrared and Millimeter Waves, 2013, 32 (6) :569-575.陈昭, 王斌, 张立明.基于低秩张量分析的高光谱图像降维与分类[J].红外与毫米波学报, 2013, 32 (6) :569-575." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201306017&amp;v=MDQxNDRackc0SDlMTXFZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdoVXIvQkxUclM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Chen Z, Wang B, Zhang L M.Dimensionality reduction and classification based on lower rank tensor analysis for hyperspectral imagery[J].Journal of Infrared and Millimeter Waves, 2013, 32 (6) :569-575.陈昭, 王斌, 张立明.基于低秩张量分析的高光谱图像降维与分类[J].红外与毫米波学报, 2013, 32 (6) :569-575.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_19" title=" An J L, Zhang X R, Zhou H Y, &lt;i&gt;et al&lt;/i&gt;.Tensor-based low-rank graph with multimanifold regularization for dimensionality reduction of hyperspectral images[J].Proceedings of the IEEE, 2018, 56 (8) :4731-4746." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor-based low-rank graph with multimanifold regularization for dimensionality reduction of hyperspectral images">
                                        <b>[19]</b>
                                         An J L, Zhang X R, Zhou H Y, &lt;i&gt;et al&lt;/i&gt;.Tensor-based low-rank graph with multimanifold regularization for dimensionality reduction of hyperspectral images[J].Proceedings of the IEEE, 2018, 56 (8) :4731-4746.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_20" title=" Li W, Du Q.Collaborative representation for hyperspectral anomaly detection[J].Proceedings of the IEEE, 2015, 53 (3) :1463-1474." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative representation for hyperspectral anomaly detection">
                                        <b>[20]</b>
                                         Li W, Du Q.Collaborative representation for hyperspectral anomaly detection[J].Proceedings of the IEEE, 2015, 53 (3) :1463-1474.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_21" title=" Sidiropoulos N D, de Lathauwer L, Fu X, &lt;i&gt;et al&lt;/i&gt;.Tensor decomposition for signal processing and machine learning[J].Proceedings of the IEEE, 2017, 65 (13) :3551-3582." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor decomposition for signal processing and machine learning">
                                        <b>[21]</b>
                                         Sidiropoulos N D, de Lathauwer L, Fu X, &lt;i&gt;et al&lt;/i&gt;.Tensor decomposition for signal processing and machine learning[J].Proceedings of the IEEE, 2017, 65 (13) :3551-3582.
                                    </a>
                                </li>
                                <li id="54">


                                    <a id="bibliography_22" title=" Deng Y J, Li H C, Fu K, &lt;i&gt;et al&lt;/i&gt;.Tensor low-rank discriminant embedding for hyperspectral image dimensionality reduction[J].Proceedings of the IEEE, 2018, 56 (12) :7183-7194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor low-rank discriminant embedding for hyperspectral image dimensionality reduction">
                                        <b>[22]</b>
                                         Deng Y J, Li H C, Fu K, &lt;i&gt;et al&lt;/i&gt;.Tensor low-rank discriminant embedding for hyperspectral image dimensionality reduction[J].Proceedings of the IEEE, 2018, 56 (12) :7183-7194.
                                    </a>
                                </li>
                                <li id="56">


                                    <a id="bibliography_23" title=" Makantasis K, Doulamis A D, Doulamis N D, &lt;i&gt;et al&lt;/i&gt;.Tensor-based classification models for hyperspectral data analysis[J].Proceedings of the IEEE, 2018, 56 (12) :6884-6898." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor-based classification models for hyperspectral data analysis">
                                        <b>[23]</b>
                                         Makantasis K, Doulamis A D, Doulamis N D, &lt;i&gt;et al&lt;/i&gt;.Tensor-based classification models for hyperspectral data analysis[J].Proceedings of the IEEE, 2018, 56 (12) :6884-6898.
                                    </a>
                                </li>
                                <li id="58">


                                    <a id="bibliography_24" title=" Zhang T H, Tao D C, Li X L, &lt;i&gt;et al&lt;/i&gt;.Patch alignment for dimensionality reduction[J].Proceedings of the IEEE, 2009, 21 (9) :1299-1313." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Patch alignment for dimensionality reduction">
                                        <b>[24]</b>
                                         Zhang T H, Tao D C, Li X L, &lt;i&gt;et al&lt;/i&gt;.Patch alignment for dimensionality reduction[J].Proceedings of the IEEE, 2009, 21 (9) :1299-1313.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-17 10:57</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(04),135-143 DOI:10.3788/AOS201939.0412001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于线性嵌入和张量流形的高光谱特征提取</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E4%B8%96%E6%AC%A3&amp;code=39620724&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马世欣</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%98%A5%E6%A1%90&amp;code=36104529&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘春桐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%B4%AA%E6%89%8D&amp;code=36104531&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李洪才</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%80%BF&amp;code=32064855&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张耿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E7%A5%AF%E9%91%AB&amp;code=36104532&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何祯鑫</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%81%AB%E7%AE%AD%E5%86%9B%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E5%AF%BC%E5%BC%B9%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699750&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">火箭军工程大学导弹工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%A5%BF%E5%AE%89%E5%85%89%E5%AD%A6%E7%B2%BE%E5%AF%86%E6%9C%BA%E6%A2%B0%E7%A0%94%E7%A9%B6%E6%89%80%E5%85%89%E8%B0%B1%E6%88%90%E5%83%8F%E6%8A%80%E6%9C%AF%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0224294&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院西安光学精密机械研究所光谱成像技术重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了使降维结果更好地体现高光谱数据的空间结构信息, 并进一步提高分类精度, 提出了一种基于线性嵌入和张量流形的高光谱特征提取算法。不同于其他流形结构的表达方法, 所提算法采用协同表示理论求解全局线性嵌入的权重矩阵, 更有利于保持高维数据的全局信息, 提高了流形结构表达的准确性。同时, 建立了基于多特征描述的张量流形降维框架, 得到的显式映射具有较强的可靠性和全局适应性。实验结果表明:与主成分分析、局部线性嵌入、拉普拉斯特征映射和线性保留投影等算法相比, 所提算法表现出了更优越的分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%99%8D%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">降维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">线性嵌入;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流形学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%A0%E9%87%8F%E8%A1%A8%E8%BE%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张量表达;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *马世欣, E-mail:mashixin0106@sina.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (41574008, 61501465);</span>
                    </p>
            </div>
                    <h1><b>Feature Extraction Based on Linear Embedding and Tensor Manifold for Hyperspectral Image</b></h1>
                    <h2>
                    <span>Ma Shixin</span>
                    <span>Liu Chuntong</span>
                    <span>Li Hongcai</span>
                    <span>Zhang Geng</span>
                    <span>He Zhenxin</span>
            </h2>
                    <h2>
                    <span>College of Missile Engineering, Rocket Force University of Engineering</span>
                    <span>Key Laboratory of Spectral Imaging Technology, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to express the spatial structure information of hyperspectral image more effectively and improve the classification accuracy after dimensionality reduction, we propose a hyperspectral feature extraction algorithm based on linear embedding and tensor manifold. Different from other manifold structure expression methods, the proposed algorithm uses the cooperative representation theory to solve the weight matrix for globally linear embedding, which is more beneficial to maintain the global information of high dimensional data and improve the accuracy of manifold structure expression. At the same time, the dimension reduction framework of tensor manifold based on multi-feature description is established, and the obtained explicit mapping has strong reliability and global adaptability. Experimental results show that compared with the principal component analysis, locally linear embedding, Laplacian Eigenmap, linearity preserving projection and other algorithms, the proposed algorithm has better classification performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dimensionality%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dimensionality reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=linear%20embedding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">linear embedding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=manifold%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">manifold learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=tensor%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">tensor representation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="60" name="60" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="61">近些年来, 高光谱成像技术得到了飞速发展, 相应的谱分辨率和空间分辨率显著提高, 从而有利于地表地物的精确分类与识别<citation id="170" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。然而, 纳米级的谱分辨率造成了严重的谱相关和谱冗余, 成百上千个波段对于数据的传输、存储和处理带来了巨大挑战<citation id="167" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。同时, 光谱维度的提高也引起了“Hughes”现象, 即在有限样本的前提下, 较高的特征维度反而会降低分类精度<citation id="168" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。针对此问题, 一方面, 可以通过改善分类方法, 采用空谱信息融合的算法提高分类精度<citation id="169" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>;另一方面, 可以改善特征提取 (FE) 算法, 降低光谱数据的特征维度。</p>
                </div>
                <div class="p1">
                    <p id="62">目前, 主流的高光谱降维方法主要包含波段选择 (BS) 和特征提取两种<citation id="171" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。与波段选择相比, 特征提取算法可以根据波段间的内在关系和规律, 发掘隐藏在高维光谱空间背后的低维子空间, 既能降低特征维度, 又能保留高光谱图像的主要特征<citation id="172" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。特征提取算法可分为监督类和非监督类。相对而言, 监督类特征提取算法通过对少量样本进行标记, 可以更好地表达光谱间的差异性, 因此, 降维后的数据具有较好的泛化性能<citation id="173" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。但在实际应用过程中, 样本标记结果的准确性往往未知, 且对样本的标记本身就是一个繁琐的过程, 所以本文主要研究的是非监督条件下高光谱特征提取算法。</p>
                </div>
                <div class="p1">
                    <p id="63">主成分分析 (PCA) <citation id="174" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和最大噪声分数 (MNF) <citation id="175" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>是高光谱图像处理中最为常用的特征提取算法。PCA算法通过对光谱维协方差矩阵进行特征值分解, 将相关波段特征转化为少数几个不相关的变量, 取得了不错的降维效果。而MNF算法则着重改善了PCA算法对噪声敏感的问题, 采用信噪比排列的方式提高了主成分的图像质量。其他的诸如多维尺度变换 (MDS) 、非负矩阵分解 (NMF) 、随机投影 (RP) 等线性降维算法, 虽然表现出了较好的适应性和较快的计算效率, 但并不能保留空间像元间的非线性结构属性。近些年来, 流形学习算法被广泛应用于高光谱数据的降维<citation id="178" type="reference"><link href="32" rel="bibliography" /><link href="34" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>, 先后出现了等距映射 (ISOMAP) 、拉普拉斯特征映射 (LE) 、局部线性嵌入 (LLE) 和最大方差展开 (MVU) 等流形降维算法, 通过构造高维空间中的非线性低维流形, 保持了空间像元的内在结构<citation id="176" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。然而, 非显式的映射方法严重制约了降维算法的适应性。为方便对未知高光谱图像进行非线性嵌入, 一些基于线性逼近的流形学习降维算法<citation id="179" type="reference"><link href="38" rel="bibliography" /><link href="40" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>被提出。线性保留投影算法LPP<citation id="177" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>是最常见的显式流形降维算法, 它通过引入线性变换矩阵求解得到高维空间到低维空间的显式投影, 对LE算法进行改进, 提高了分类效果, 而且更具有实际应用价值。然而, 这些算法并不能描述全局的流形结构, 且基于局部邻域图的流形表达方式在得到局部低维嵌入的同时牺牲了计算效率, 通常只适用于小样本的降维<citation id="180" type="reference"><link href="32" rel="bibliography" /><link href="34" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="64">为克服上述算法的缺点, 本课题组基于权值重构<citation id="181" type="reference"><link href="44" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和张量表达<citation id="182" type="reference"><link href="46" rel="bibliography" /><link href="48" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>的思想, 提出了基于线性嵌入和张量流形的高光谱特征提取算法——LETM算法。LETM算法克服了局部线性嵌入流形的不足, 采用协同表示理论构建了反映全局流形的权值矩阵, 并对权值矩阵添加稀疏约束以提高算法的计算效率;建立了权值保持的低维嵌入张量流形框架, 并对低秩目标矩阵进行奇异值分解, 将反映切空间正交基的左奇异特征向量作为投影矩阵。此外, 为减小空间计算的复杂度, 针对非监督条件下的小样本数据进行训练, 采用等间隔均匀抽样选取代表样本, 实验结果表明:训练得到的显式映射具有较强的可靠性和全局适应性。</p>
                </div>
                <h3 id="65" name="65" class="anchor-tag">2 算法描述</h3>
                <h4 class="anchor-tag" id="66" name="66"><b>2.1 线性嵌入流形结构</b></h4>
                <div class="p1">
                    <p id="67">流形学习算法的关键在于求取流形结构, 并给出流形结构的局部或全局表达。全局线性嵌入 (GLE) 的思想来源于LLE算法, 即:将高维数据点表示为近邻数据点的线性组合, 非线性的流形结构就是对数据点与近邻数据点权重关系的保持。LLE思想并不是基于保持高维数据集的全局信息, 而是通过局部权重关系的保持实现低维嵌入流形。构建高维特征空间的重构误差, 将求解得到的最优权重值代入到低维空间的重构误差函数中, 通过特征值分解得到的特征向量即为特征提取结果。</p>
                </div>
                <div class="p1">
                    <p id="68">不同于LLE算法, GLE算法采用全局样本点描述某一像元, 如图1所示。通过协同表示理论<citation id="183" type="reference"><link href="50" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>求取每个样本与全部样本之间的线性关系。同时, 全局样本点的数量决定了权值矩阵必然是稀疏的, 因此, 添加了权值矩阵的稀疏约束, 并用拉格朗日优化函数进行求解, 得到统一规范的求解表达式。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 流形差异示意图。 (a) LLE算法; (b) GLE算法" src="Detail/GetImg?filename=images/GXXB201904016_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 流形差异示意图。 (a) LLE算法; (b) GLE算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Diagrams of manifold difference. (a) LLE algorithm; (b) GLE algorithm</p>

                </div>
                <div class="p1">
                    <p id="70">考虑高光谱数据<b><i>X</i></b>中的第<i>i</i>个像元<b><i>x</i></b><sub><i>i</i></sub>, 它与其他任意像元的关系可以用权重<b><i>w</i></b><sub><i>i</i></sub>来表示, 即</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≈</mo><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">理想的结果就是得到重构像元<b><i>x</i></b><sub><i>i</i></sub>的最佳权值, 使得重构误差<i>ε</i><sub><i>i</i></sub>最小。那么, 第<i>i</i>个像元的重构误差<i>ε</i><sub><i>i</i></sub>可以表示为<i>l</i><sub>2</sub>范数形式:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">式中:<i>w</i><sub><i>ij</i></sub>为像元<i>i</i>与像元<i>j</i>之间的权值。</p>
                </div>
                <div class="p1">
                    <p id="75">将 (2) 式转化为一个优化问题, 也就是求解目标函数<i>ε</i><sub><i>i</i></sub>最小时的权值<b><i>w</i></b><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">采用所有的样本点对<b><i>x</i></b><sub><i>i</i></sub>进行表示。为保证重构结果的准确性, 将被表示的像元<b><i>x</i></b><sub><i>i</i></sub>的重构权值<i>w</i><sub><i>ii</i></sub>设为0。同时, 全局像元的数量决定了权重向量<b><i>w</i></b><sub><i>i</i></sub>必然是稀疏的, 差异越大的像元权重值越小, 差异越小的像元权重值越大。</p>
                </div>
                <div class="p1">
                    <p id="78">为保证权重向量<b><i>w</i></b><sub><i>i</i></sub>的稀疏性, 同时使<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>最小, (3) 式的优化问题采用拉格朗日乘数法进行求解, 即:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">式中:λ为拉格朗日乘子。常数λ代表对优化目标<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>的惩罚项。</p>
                </div>
                <div class="p1">
                    <p id="83">将 (4) 式进行化简可得:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mo stretchy="false">[</mo><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">式中:<b><i>I</i></b>为单位矩阵。为简化运算过程, (5) 式中省略了<b><i>x</i></b><sup>T</sup><sub><i>i</i></sub><b><i>x</i></b><sub><i>i</i></sub>项, 但这并不会影响上述优化问题的求解结果。</p>
                </div>
                <div class="p1">
                    <p id="86">对<b><i>w</i></b><sub><i>i</i></sub>求导, 可得稀疏权重估计值<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">w</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>的表达式为</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">w</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">为了保证权重求解结果的规范性, 对<b><i>w</i></b><sub><i>i</i></sub>添加归一化约束, 令<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover><mo>=</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">X</mi></mrow></math></mathml>;<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo stretchy="false">]</mo><mo>, </mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>;1], 则有</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">w</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mo>∼</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">在实际计算过程中, 往往选取具有代表性的样本集。假设存在选择矩阵<b><i>S</i></b>, 则权重矩阵<b><i>W</i></b>可以表示为</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">X</mi></mstyle><mo>∼</mo></mover><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="95" name="95"><b>2.2 张量流形降维框架</b></h4>
                <div class="p1">
                    <p id="96">近些年来, 张量理论在大数据、人工智能和图像处理等方面应用广泛。张量代数理论其实就是多维线性理论, 对于高维数据, 使用张量代替向量会使表达更简洁, 尤其是对于多特征描述下的模式识别问题, 张量表达不需要改变数据结构, 可以最大程度地表达原数据的固有信息<citation id="184" type="reference"><link href="52" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="97">正是由于张量理论在数据表达上的独特优势, 国内外开始将张量理论用于高光谱去噪、重建、降维、分类和目标探测等领域<citation id="185" type="reference"><link href="54" rel="bibliography" /><link href="56" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>。所提算法并没有将高光谱数据表达成三阶张量的形式, 而是在将高光谱数据排列成二阶张量的前提下, 考虑多特征描述下的张量流形降维框架 (如图2所示) 。其中, <i>M</i>阶张量代表的特征维度为 (<i>M</i>-1) 。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 张量流形降维框架" src="Detail/GetImg?filename=images/GXXB201904016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 张量流形降维框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Dimensionality reduction frame of tensor manifold</p>

                </div>
                <div class="p1">
                    <p id="99">不妨假设存在多特征描述下的数据<b><i>X</i></b>, 样本个数为<i>N</i>, 设降维前后第<i>m</i>维的特征维度为<i>l</i><sub><i>m</i></sub>和<i>l</i>′<sub><i>m</i></sub>, 对数据<b><i>X</i></b>的原始特征空间采用<i>M</i>阶张量表示, 即<b><i>X</i></b>∈<b>R</b><sup><i>l</i><sub>1</sub>×<i>l</i><sub>2</sub>×…×<i>l</i><sub><i>M</i>-1</sub>×<i>N</i></sup> (<b>R</b>为实数集) , 降维之后的特征空间为<b><i>Y</i></b>∈<b>R</b><sup><i>l</i><sup>′</sup><sub>1</sub>×<i>l</i><sup>′</sup><sub>2</sub>×…×<i>l</i><sup>′</sup><sub><i>M</i>-1</sub>×<i>N</i></sup>。则 (3) 式中的目标函数可以转化为张量表达形式:</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>o</mtext></mrow><mn>2</mn></msubsup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">式中:<b><i>W</i></b>∈<b>R</b><sup><i>N</i>×<i>N</i></sup>为二阶权重张量;<b><i>Y</i></b><sub><i>i</i></sub>为单个样本的特征张量;张量范数<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>o</mtext></mrow><mn>2</mn></msubsup></mrow></math></mathml>为张量<b><i>F</i></b><sub>1</sub>和张量<b><i>F</i></b><sub>2</sub>之间的距离;⨂为张量的缩并运算符。</p>
                </div>
                <div class="p1">
                    <p id="103">对 (9) 式展开可得:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi>Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>-</mo></mtd></mtr><mtr><mtd><mn>2</mn><mo>〈</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>〉</mo><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>o</mtext></mrow><mn>2</mn></msubsup><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">类似地, 可以将[<b><i>Y</i></b><sub><i>i</i></sub>⨂<b><i>Y</i></b><sub><i>i</i></sub>; (1:<i>M</i>) (1:<i>M</i>) ]视为常数项省去, 则 (10) 式等价为</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo>|</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>o</mtext></mrow><mn>2</mn></msubsup><mo>-</mo></mtd></mtr><mtr><mtd><mn>2</mn><mo>〈</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>〉</mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">为了进一步简化目标函数, 可将权重张量约简成权重矩阵<b><i>W</i></b>={<b><i>w</i></b><sub><i>i</i></sub>}<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>∈<b>R</b><sup><i>N</i>×<i>N</i></sup>, 以此基础上, 对 (11) 式展开可得:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mspace width="0.25em" /><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>×</mo><mi>Ν</mi><mo stretchy="false">) </mo></mrow></msub><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo></mtd></mtr><mtr><mtd><mn>2</mn><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="bold-italic">w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mtext>Τ</mtext></msubsup><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>;</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">式中:<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Μ</mi><mo stretchy="true">˜</mo></mover></mrow></math></mathml>为对除第M阶外的其他阶全部进行缩并运算的结果。</p>
                </div>
                <div class="p1">
                    <p id="112">用矩阵表示上述目标函数, 可以得到更一般的表达式:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mrow><mrow><mo>[</mo><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mo stretchy="false">) </mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>×</mo><mi>Ν</mi><mo stretchy="false">) </mo></mrow></msub><mo>-</mo><mn>2</mn><mrow><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>×</mo><mi>Ν</mi><mo stretchy="false">) </mo></mrow></msub></mrow><mo>]</mo></mrow></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>g</mi><mo>, </mo><mi>h</mi><mo stretchy="false">) </mo></mrow></msub><mo>⋅</mo></mtd></mtr><mtr><mtd><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mover accent="true"><mi>Μ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>g</mi><mo>, </mo><mi>h</mi><mo stretchy="false">) </mo></mrow></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">式中:g和h都为矩阵的行列下标。</p>
                </div>
                <div class="p1">
                    <p id="115">目标函数左侧矩阵采用Q<sub>i</sub>表示, 将各像元的目标函数相加后就可以得到最终的目标优化模型Ω:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ω</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi mathvariant="bold-italic">Q</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi mathvariant="bold-italic">Y</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mi>Ω</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>g</mi><mi>h</mi></mrow></msub><mo>⋅</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Y</mi><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><mo>;</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>g</mi><mo>, </mo><mi>h</mi><mo stretchy="false">) </mo></mrow></msub><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">更多情况下, 需要得到从高维数据<b><i>X</i></b>到低维数据<b><i>Y</i></b>的显式映射<b><i>U</i></b>, 使得<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><mover><mo stretchy="true" symmetric="false">→</mo><mi mathvariant="bold-italic">U</mi></mover><mi mathvariant="bold-italic">Y</mi></mrow></math></mathml>成立。则有:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi mathvariant="bold-italic">U</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mi>Ω</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>g</mi><mi>h</mi></mrow></msub><mo>⋅</mo><mo stretchy="false">[</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">X</mi><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo>×</mo></mstyle><msub><mrow></mrow><mi>m</mi></msub><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mi>m</mi><mtext>Τ</mtext></msubsup></mrow><mo>) </mo></mrow><mo>⊗</mo></mtd></mtr><mtr><mtd><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">X</mi><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo>×</mo></mstyle><msub><mrow></mrow><mi>m</mi></msub><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mi>m</mi><mtext>Τ</mtext></msubsup></mrow><mo>) </mo></mrow><mo>;</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>Μ</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>g</mi><mo>, </mo><mi>h</mi><mo stretchy="false">) </mo></mrow></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">式中:<b><i>U</i></b><sub><i>m</i></sub>为第<i>m</i>阶特征的显式映射。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>2.3 显式映射优化求解</b></h4>
                <div class="p1">
                    <p id="122">通过引入线性化表达的方法得到了如 (16) 式所示的关于显式映射<b><i>U</i></b>的目标函数表达式。该问题实际上是多变量的非凸优化问题, 目前没有方法可以直接一次性求解出全部的目标变量, 虽然Zhang等<citation id="186" type="reference"><link href="58" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>给出了交替迭代的收敛解法, 但求解过程较为复杂。因此, 这里只给出高光谱多元特征降维的张量流形框架, 而高光谱数据的多元特征描述和分投影矩阵求解并不作为本研究的重点。</p>
                </div>
                <div class="p1">
                    <p id="123">不考虑多元特征, 将高光谱数据用二阶张量描述, 则 (16) 式可简化为</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi mathvariant="bold-italic">U</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mi>Ω</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>g</mi><mi>h</mi></mrow></msub><mo>⋅</mo></mtd></mtr><mtr><mtd><mrow><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>×</mo><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo><mo>⊗</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo>×</mo><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>g</mi><mo>, </mo><mi>h</mi><mo stretchy="false">) </mo></mrow></msub><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">为保证 (17) 式有解, 需对投影矩阵添加归一化约束<b><i>U</i></b><sup>T</sup><b><i>U</i></b>=<b><i>I</i></b>。因此, 目标函数 (17) 式可以进一步改写为</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi mathvariant="bold-italic">U</mi><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">U</mi><mo>=</mo><mi mathvariant="bold-italic">Ι</mi></mrow></mrow></mrow></munder><mspace width="0.25em" /><mtext>t</mtext><mtext>r</mtext><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo>{</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>Ω</mi><msub><mrow></mrow><mrow><mi>g</mi><mi>h</mi></mrow></msub><mo>⋅</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><msubsup><mrow></mrow><mi>g</mi><mtext>Τ</mtext></msubsup><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><mo>}</mo></mrow><mi mathvariant="bold-italic">U</mi></mrow><mo>}</mo></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">令</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">F</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>g</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>h</mi></munder><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>Ω</mi><msub><mrow></mrow><mrow><mi>g</mi><mi>h</mi></mrow></msub><mo>⋅</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><msubsup><mrow></mrow><mi>g</mi><mtext>Τ</mtext></msubsup><mo>⊗</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">很显然, (18) 式所对应的优化问题的解就是由矩阵<b><i>F</i></b>的最小<i>k</i>个特征值所对应的特征向量组成的。在实际计算过程中, 权重矩阵<b><i>W</i></b>的稀疏性决定了矩阵<b><i>F</i></b>必然是低秩的。因此, 在实际计算过程中, 奇异值的收敛速度比特征值快很多, 且奇异值分解得到的左侧奇异特征向量反映了切平面的正交基, 比直接采用广义特征值分解得到的结果更准确。因此, 采用奇异值分解求取显式映射<b><i>U</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="130" class="code-formula">
                        <mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">F</mi><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><mi mathvariant="bold-italic">Λ</mi><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="131">式中:<i>Λ</i>为奇异值矩阵;<b><i>P</i></b>为正交投影矩阵;<b><i>V</i></b>为奇异特征矩阵。则显式映射<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">U</mi><mo>^</mo></mover></math></mathml>可以表达为<b><i>P</i></b>的前<i>k</i>个奇异特征向量:</p>
                </div>
                <div class="p1">
                    <p id="133" class="code-formula">
                        <mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">U</mi><mo>^</mo></mover><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><mo stretchy="false"> (</mo><mo>:</mo><mo>, </mo><mn>1</mn><mo>:</mo><mi>k</mi><mo stretchy="false">) </mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="134" name="134" class="anchor-tag">3 实验验证</h3>
                <h4 class="anchor-tag" id="135" name="135"><b>3.1 实验数据说明</b></h4>
                <div class="p1">
                    <p id="136">为验证所提算法的正确性和可靠性, 选用两组高光谱图像进行对比实验。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">3.1.1 数据1的实验结果</h4>
                <div class="p1">
                    <p id="138">图3 (a) 为AVIRIS高光谱仪于1992年拍摄的美国印第安纳州 (Indian Pines) 的高光谱图像, 图像的空间分辨率为2 m, 光谱分辨率为10 nm, 光谱的覆盖范围约为400～2400 nm。数据集的大小为145 pixel×145 pixel, 除去水汽吸收等造成的不可用波段, 共得到200个波段用于实验。图3 (b) 显示了16类地物的彩色图。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Indian Pines高光谱数据。 (a) 伪彩色图; (b) 真实的地物图" src="Detail/GetImg?filename=images/GXXB201904016_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>Indian Pines</i>高光谱数据。 (<i>a</i>) 伪彩色图; (<i>b</i>) 真实的地物图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 3 <i>Indian Pines hyperspectral data</i>. (<i>a</i>) <i>Pseudo</i>-<i>color image</i>; (<i>b</i>) <i>ground</i>-<i>truth map</i></p>

                </div>
                <h4 class="anchor-tag" id="140" name="140">3.1.2 数据2的实验结果</h4>
                <div class="p1">
                    <p id="141">图4 (<i>a</i>) 为<i>ROSIS</i>高光谱仪拍摄的意大利北部帕维亚大学 (<i>PaviaU</i>) 的高光谱图像, 图像的空间分辨率为1.3 <i>m</i>。数据集的大小为610 <i>pixel</i>×340 <i>pixel</i>, 除去信噪比较低的波段, 共有103个波段用于实验。图4 (<i>b</i>) 中显示了9种地物的彩色图。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 PaviaU 高光谱数据。 (a) 伪彩色图; (b) 真实的地物图" src="Detail/GetImg?filename=images/GXXB201904016_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 <i>PaviaU</i> 高光谱数据。 (<i>a</i>) 伪彩色图; (<i>b</i>) 真实的地物图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 4 <i>PaviaU hyperspectral data</i>. (<i>a</i>) <i>Pseudo</i>-<i>color image</i>; (<i>b</i>) <i>ground</i>-<i>truth map</i></p>

                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>3.2 降维算法比较</b></h4>
                <h4 class="anchor-tag" id="144" name="144">3.2.1 实验参数说明</h4>
                <div class="p1">
                    <p id="145">为了证明所提算法的优越性, 主要针对降维之后的分类性能和计算效率进行分析。在分类方面, 采用支持向量机 (<i>SVM</i>) 作为分类器, 随机选取20%的样本数据作为训练集, 核函数选择较为常用的高斯径向基核函数 (<i>RBF</i>) , 并在训练前用<i>Cross</i>-<i>Validation</i>方法和<i>Grid</i>-<i>Search</i>方法得到最优参数c和g。</p>
                </div>
                <div class="p1">
                    <p id="146">所提算法在进行显式映射求解时, 样本对降维效果的影响较大, 因此采用等间隔均匀抽样的方法, 选取的小样本数据占总数据的5%。同时比较了不同的λ值对降维算法分类性能的影响。图5为不同样本数量下, <i>Indian Pines</i>数据的整体分类精度曲线。从图5可以看出, λ值对嵌入效果和分类精度的影响较小。故, 综合考虑后设定λ的大小为0.01。</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 稀疏参数λ对分类性能的影响 (Indian Pines数据)" src="Detail/GetImg?filename=images/GXXB201904016_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 稀疏参数λ对分类性能的影响 (<i>Indian Pines</i>数据)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 5 <i>Influence of sparse parameters</i> λ <i>on classification</i><i>performance</i> (<i>Indian Pines data</i>) </p>

                </div>
                <h4 class="anchor-tag" id="148" name="148">3.2.2 分类性能比较</h4>
                <div class="p1">
                    <p id="149">将所提算法与<i>PCA</i>、<i>MNF</i>、<i>LLE</i>、<i>LE</i>、<i>LPP</i>、<i>RP</i>算法的降维效果进行对比。考虑到不同高光谱图像原有的特征维度, 设定<i>Indian Pines</i>数据和<i>PaviaU</i>数据的降维维度M分别为30和20, 并令λ的大小为0.01, 最终得到了如图6～7所示的分类结果。</p>
                </div>
                <div class="area_img" id="150">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法对Indian Pines数据的降维效果。 (a) 真实的地物图; (b) PCA算法; (c) MNF算法; (d) LLE算法; (e) LE算法; (f) LPP算法; (g) RP算法; (h) 所提算法" src="Detail/GetImg?filename=images/GXXB201904016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法对<i>Indian Pines</i>数据的降维效果。 (<i>a</i>) 真实的地物图; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 6 <i>Dimensionality reduction performance of Indian Pines data obtained with different algorithms</i>. (<i>a</i>) <i>Ground</i>-<i>truth map</i>; (<i>b</i>) <i>PCA algorithm</i>; (<i>c</i>) <i>MNF algorithm</i>; (<i>d</i>) <i>LLE algorithm</i>; (<i>e</i>) <i>LE algorithm</i>; (<i>f</i>) <i>LPP algorithm</i>; (<i>g</i>) <i>RP algorithm</i>; (<i>h</i>) <i>proposed algorithm</i></p>

                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法对PaviaU数据的降维效果。 (a) 真实的地物图; (b) PCA算法; (c) MNF算法; (d) LLE算法; (e) LE算法; (f) LPP算法; (g) RP算法; (h) 所提算法" src="Detail/GetImg?filename=images/GXXB201904016_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法对<i>PaviaU</i>数据的降维效果。 (<i>a</i>) 真实的地物图; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 7 <i>Dimensionality reduction performance of PaviaU data obtained with different algorithms</i>. (<i>a</i>) <i>Ground</i>-<i>truth map</i>; (<i>b</i>) <i>PCA</i><i>algorithm</i>; (<i>c</i>) <i>MNF algorithm</i>; (<i>d</i>) <i>LLE algorithm</i>; (<i>e</i>) <i>LE algorithm</i>; (<i>f</i>) <i>LPP algorithm</i>; (<i>g</i>) <i>RP algorithm</i>; (<i>h</i>) <i>proposed algorithm</i></p>

                </div>
                <div class="p1">
                    <p id="152">从图6～7中可以直观地比较不同降维算法的分类效果, 可以看出:<i>LE</i>算法和<i>RP</i>算法的分类性能较差, 所提降维算法的分类性能优于其他降维算法。为了更直观地比较不同降维算法的优劣, 从<i>Indian Pines</i>数据集中选取六类地物, 分别为免耕大豆地、大豆幼苗、免耕玉米地、小麦、木材和大厦-草-树-机器, 每一个类别选取200个样本, 可以得到二维空间的投影结果, 如图8所示。图8 (<i>a</i>) 为原始图像前两个波段的分布图。图8 (<i>b</i>) ～8 (<i>h</i>) 为不同特征提取算法得到的前两个主成分的二维分布图, 可以明显看出:<i>LLE</i>算法、<i>LE</i>算法以及<i>LPP</i>算法的类间可分性表现较差, 而<i>PCA</i>算法、<i>MNF</i>算法以及<i>RP</i>算法由于均是全局线性特征提取算法, 很难提取数据的非线性信息, 且基于贡献率排序规则, 前两个主成分集中了大部分的有用信息, 表现出一定的可分性;所提算法在提取光谱数据的非线性特征、类别可分性等方面具有较强优势, 从各类离散点的分布来看, 表现出了较强的可分性。</p>
                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同降维算法的投影结果 (Indian Pines数据) 。 (a) 原数据 (波段1 &amp; 2) ; (b) PCA算法; (c) MNF算法; (d) LLE算法; (e) LE算法; (f) LPP算法; (g) RP算法; (h) 所提算法" src="Detail/GetImg?filename=images/GXXB201904016_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同降维算法的投影结果 (<i>Indian Pines</i>数据) 。 (<i>a</i>) 原数据 (波段1 &amp; 2) ; (<i>b</i>) <i>PCA</i>算法; (<i>c</i>) <i>MNF</i>算法; (<i>d</i>) <i>LLE</i>算法; (<i>e</i>) <i>LE</i>算法; (<i>f</i>) <i>LPP</i>算法; (<i>g</i>) <i>RP</i>算法; (<i>h</i>) 所提算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 8 <i>Projection results obtained with different dimensionality reduction algorithms</i> (<i>Indian Pines data</i>) . (<i>a</i>) <i>Original data</i> (<i>band</i> 1 &amp; 2) ; (<i>b</i>) <i>PCA algorithm</i>; (<i>c</i>) <i>MNF algorithm</i>; (<i>d</i>) <i>LLE algorithm</i>; (<i>e</i>) <i>LE algorithm</i>; (<i>f</i>) <i>LPP algorithm</i>; (<i>g</i>) <i>RP algorithm</i>; (<i>h</i>) <i>proposed algorithm</i></p>

                </div>
                <div class="p1">
                    <p id="154">为了进一步比较不同降维算法的优劣, 计算得到了不同降维算法的整体分类精度 (<i>OCA</i>) 和平均分类精度 (<i>ACA</i>) , 如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="155">从表1可以看出:在训练样本数量较少的情况下 (分类训练样本占总体样本的20%, <i>LETM</i>算法的训练样本占总体样本的5%) , 所提算法取得了较好的分类性能, 尤其是对 <i>PaviaU</i>数据的整体分类精度更是达到了95.55%, 远优于其他特征提取算法的分类精度。</p>
                </div>
                <div class="p1">
                    <p id="156">为进一步验证所提算法的降维效果, 分别比较了不同嵌入维度下各算法的整体分类性能, 结果如图9所示。从图9可以看出, <i>LETM</i>算法在各个维度下的分类效果都要明显优于其他算法。</p>
                </div>
                <h4 class="anchor-tag" id="157" name="157">3.2.3 计算效率的比较</h4>
                <div class="p1">
                    <p id="158">降维算法的计算复杂度和实时性对算法的实际应用影响较大, 因此, 有必要对所提算法进行时间复杂度分析。假设训练样本占总体数目的比例为t, 高光谱像元数目为N, 波段数为D, 降维之后的维度为M, <i>LE</i>算法和<i>LPP</i>算法的邻域像元数目为k。<i>LETM</i>算法主要包含了矩阵乘法、矩阵的广义逆以及奇异值分解等运算。其中:稀疏权重<b><i>W</i></b>求解过程的时间复杂度为<i>O</i> (2<i>t</i><sup>3</sup><i>N</i><sup>3</sup>+2<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i>) , 计算目标函数矩阵<b><i>F</i></b>的时间复杂度为<i>O</i> (<i>t</i><sup>4</sup><i>N</i><sup>4</sup>+<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i><sup>2</sup>) , 对矩阵<b><i>F</i></b>进行奇异值分解的复杂度为<i>O</i> (<i>kMD</i><sup>2</sup>) 。因此, LETM算法总的时间复杂度可以渐进表达为<i>O</i> (<i>t</i><sup>4</sup><i>N</i><sup>4</sup>+<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i><sup>2</sup>+2<i>t</i><sup>3</sup><i>N</i><sup>3</sup>+2<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i>+<i>kMD</i><sup>2</sup>) 。其他算法的时间复杂度如表2所示。</p>
                </div>
                <div class="area_img" id="159">
                    <p class="img_tit">表1 不同降维算法的分类精度 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Classification accuracy of different dimensionality reduction algorithms</p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td><br />Dataset</td><td>SVM classification</td><td>PCA</td><td>MNF</td><td>LLE</td><td>LE</td><td>LPP</td><td>RP</td><td>LETM</td></tr><tr><td rowspan="2"><br />Indian Pines <br /> (<i>M</i>=30) </td><td><br />OCA /%</td><td>76.69</td><td>83.74</td><td>71.44</td><td>68.88</td><td>79.09</td><td>81.16</td><td>85.10</td></tr><tr><td><br />ACA /%</td><td>69.26</td><td>79.74</td><td>70.08</td><td>63.52</td><td>75.48</td><td>77.95</td><td>81.96</td></tr><tr><td rowspan="2"><br />PaviaU<br /> (<i>M</i>=20) </td><td><br />OCA /%</td><td>92.46</td><td>93.09</td><td>85.67</td><td>82.58</td><td>93.56</td><td>90.56</td><td>95.55</td></tr><tr><td><br />ACA /%</td><td>89.04</td><td>91.94</td><td>82.15</td><td>75.98</td><td>90.55</td><td>86.98</td><td>93.93</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="160">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同嵌入维度下各算法的分类性能。 (a) Indian Pines数据; (b) PaviaU数据" src="Detail/GetImg?filename=images/GXXB201904016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同嵌入维度下各算法的分类性能。 (a) Indian Pines数据; (b) PaviaU数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Classification accuracy of different algorithms obtained at different embedding dimensions. (a) Indian Pines data; (b) PaviaU data</p>

                </div>
                <div class="p1">
                    <p id="161">从表2可以看出:LETM算法具有较大的时间复杂度, 对于小样本数据来讲, LETM算法的时间复杂度较高;然而, 对于大样本数据来讲, LETM算法的时间复杂度依赖于选取训练样本的比例<i>t</i>, 因此明显优于LE和LPP两种流形降维算法。表3给出了不同降维算法所用的计算时间。算法所用的实验平台为Intel Core i5-2450M处理器, 频率为2.5 GHz (睿频可达3.1 GHz) , 操作系统为Win 10, 内存为16 G, 硬盘为250 G固态硬盘。为保证时间统计的准确性, 结果均为运行5次的平均值。</p>
                </div>
                <div class="area_img" id="162">
                    <p class="img_tit">表2 各算法的时间复杂度 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Time complexity of different algorithms</p>
                    <p class="img_note"></p>
                    <table id="162" border="1"><tr><td><br />Algorithm</td><td>Time complexity</td></tr><tr><td><br />PCA</td><td><i>O</i> (<i>N</i><sup>2</sup><i>D</i>) </td></tr><tr><td><br />MNF</td><td><i>O</i> (2<i>N</i><sup>2</sup><i>D</i>) </td></tr><tr><td><br />LLE</td><td><i>O</i>[<i>ND</i>lb <i>k</i>·lb <i>D</i>+<i>NDk</i><sup>3</sup>+<i>DN</i><sup>2</sup>+<i>N</i><sup>3</sup>]</td></tr><tr><td><br />LE</td><td><i>O</i>[<i>ND</i>lb <i>k</i>·lb <i>D</i>+<i>NDk</i><sup>3</sup>+MD<sup>2</sup>]</td></tr><tr><td><br />LPP</td><td><i>O</i>[<i>ND</i>lb <i>k</i>·lb <i>D</i>+<i>NDk</i><sup>3</sup>+2<i>DMN</i>+<i>kMD</i><sup>2</sup>]</td></tr><tr><td><br />RP</td><td><i>O</i> (<i>DMN</i>) </td></tr><tr><td><br />LETM</td><td><i>O</i> (<i>t</i><sup>4</sup><i>N</i><sup>4</sup>+<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i><sup>2</sup>+2<i>t</i><sup>3</sup><i>N</i><sup>3</sup>+2<i>t</i><sup>2</sup><i>N</i><sup>2</sup><i>D</i>+<i>kMD</i><sup>2</sup>) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="163">从表3中的数据可以看出:RP算法和PCA算法具有较好的实时性, 主要原因是算法原理比较简单, 算法复杂度不高, 而LLE算法、LE算法和LPP算法在处理大样本数据时, 计算效率明显下降, 体现出流形学习算法普遍对空间维度较为敏感;所提算法采用等间隔均匀抽样的方法降低了算法的空间维度, 而且从嵌入方法表达的效果来看, 降维前后的流形结构表现出较强的稳定性, 在提高计算效率的同时, 取得了不错的降维效果。尽管LETM算法没有表现出像PCA、RP等线性降维方法一样的时效性, 但对于大部分高光谱应用来讲, LETM算法的计算效率能够满足要求。</p>
                </div>
                <div class="area_img" id="164">
                    <p class="img_tit">表3 各算法的计算时间 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Computation time of different algorithms</p>
                    <p class="img_note"></p>
                    <table id="164" border="1"><tr><td rowspan="2"><br />Data</td><td rowspan="2">Reduced <br />dimensionality</td><td colspan="7"><br />Computation times /s</td></tr><tr><td><br />PCA</td><td>NMF</td><td>LLE</td><td>LE</td><td>LPP</td><td>RP</td><td>LETM</td></tr><tr><td rowspan="3"><br />Indian Pines</td><td>10</td><td>0.273</td><td>0.386</td><td>44.912</td><td>13.520</td><td>13.065</td><td>0.079</td><td>42.367</td></tr><tr><td><br />30</td><td>0.274</td><td>0.391</td><td>45.774</td><td>13.733</td><td>13.177</td><td>0.079</td><td>42.803</td></tr><tr><td><br />50</td><td>0.277</td><td>0.403</td><td>46.265</td><td>14.210</td><td>13.313</td><td>0.090</td><td>43.116</td></tr><tr><td rowspan="3"><br />PaviaU</td><td>10</td><td>0.763</td><td>1.039</td><td>3633.611</td><td>2187.667</td><td>2454.708</td><td>0.239</td><td>304.150</td></tr><tr><td><br />30</td><td>0.807</td><td>1.068</td><td>3672.186</td><td>2193.203</td><td>2454.845</td><td>0.294</td><td>307.489</td></tr><tr><td><br />50</td><td>0.811</td><td>1.085</td><td>3714.503</td><td>2199.186</td><td>2454.896</td><td>0.401</td><td>310.316</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="165" name="165" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="166">提出了基于线性嵌入和张量流形的高光谱特征提取算法。实验结果表明:与其他流形结构表达方法相比, 采用协同表示方法的全局线性嵌入流形结构更有利于保持高维数据的全局信息, 通过添加稀疏约束可以保证优化目标的低秩特性, 提高流形结构表达的准确度。本研究提供了一种基于多特征描述的张量流形降维思路, 并推导得到了优化目标函数, 给出了显示映射的求解方法, 有利于未知样本数据的降维。此外, 所提算法采用小样本训练权重, 显著降低了计算量, 并且得到了最优的空间投影结果, 具有较强的可靠性。相比于PCA、MNF、LLE、LE、LLP等算法, 所提算法表现出了更优越的分类性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="12">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advances in hyperspectral image and signal processing: a comprehensive overview of the state of the art">

                                <b>[1]</b> Ghamisi P, Yokoya N, Li J, <i>et al</i>.Advances in hyperspectral image and signal processing:a comprehensive overview of the state of the art[J].Proceedings of the IEEE, 2017, 5 (4) :37-78.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hyperspectral remote sensing data analysis and future challenges">

                                <b>[2]</b> Bioucas-Dias J M, Plaza A, Camps-Valls G, <i>et al</i>.Hyperspectral remote sensing data analysis and future challenges[J].Proceedings of the IEEE, 2013, 1 (2) :6-36.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminant analysis-based dimension reduction for hyperspectral image classification:a survey of the most recent advances and an experimental comparison of different techniques">

                                <b>[3]</b> Li W, Feng F B, Li H C, <i>et al</i>.Discriminant analysis-based dimension reduction for hyperspectral image classification:a survey of the most recent advances and an experimental comparison of different techniques[J].Proceedings of the IEEE, 2018, 6 (1) :15-34.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A sparse and low-rank near-isometric linear embedding method for feature extraction in hyperspectral imagery classification">

                                <b>[4]</b> Sun W W, Yang G, Du B, <i>et al</i>.A sparse and low-rank near-isometric linear embedding method for feature extraction in hyperspectral imagery classification[J].Proceedings of the IEEE, 2017, 55 (7) :4032-4046.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MjM4NTlHRnJDVVJMT2VaZVZ1Rnk3aFVyL0JJalhUYkxHNEg5Yk1wNDlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Dong A G, Li J X, Zhang B, <i>et al</i>.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :0828005.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :0828005.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A geometry-based band selection approach for hyperspectral image analysis">

                                <b>[6]</b> Zhang W Q, Li X R, Dou Y X, <i>et al</i>.A geometry-based band selection approach for hyperspectral image analysis[J].Proceedings of the IEEE, 2018, 56 (8) :4318-4333.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature extraction for hyperspectral images using low-rank representation with neighborhood preserving regularization">

                                <b>[7]</b> Wang M D, Yu J, Niu L J, <i>et al</i>.Feature extraction for hyperspectral images using low-rank representation with neighborhood preserving regularization[J].Proceedings of the IEEE, 2017, 14 (6) :836-840.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201406018&amp;v=MDY2OTMzenFxQnRHRnJDVVJMT2VaZVZ1Rnk3aFVyL0JMVHJTWnJHNEg5WE1xWTlFYklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Wei F, He M Y, Feng Y, <i>et al</i>.Feature extraction on matrix factorization for hyperspectral data[J].Journal of Infrared and Millimeter Waves, 2014, 33 (6) :674-679.魏峰, 何明一, 冯燕, 等.基于矩阵分解的高光谱数据特征提取[J].红外与毫米波学报, 2014, 33 (6) :674-679.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linear Versus Nonlinear PCA for the Classification of Hyperspectral Data Based on the Extended Morphological Profiles">

                                <b>[9]</b> Licciardi G, Marpu P R, Chanussot J, <i>et al</i>.Linear versus nonlinear PCA for the classification of hyperspectral data based on the extended morphological profiles[J].Proceedings of the IEEE, 2012, 9 (3) :447-451.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A transformation for ordering multispectral data in terms of image quality with implications for noise removal">

                                <b>[10]</b> Green A A, Berman M, Switzer P, <i>et al</i>.A transformation for ordering multispectral data in terms of image quality with implications for noise removal[J].Proceedings of the IEEE, 1988, 26 (1) :65-74.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear manifolds for feature extraction:opportunities and challenge">

                                <b>[11]</b> Crawford M, Held A A, Burger J.Nonlinear manifolds for feature extraction:opportunities and challenge[J].Proceedings of the IEEE, 2011:1-3.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Manifold-learning-based feature extraction for classification of hyperspectral data:a review of advances in manifold learning">

                                <b>[12]</b> Lunga D, Prasad S, Crawford M M, <i>et al</i>.Manifold-learning-based feature extraction for classification of hyperspectral data:a review of advances in manifold learning[J].Proceedings of the IEEE, 2014, 31 (1) :55-66.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local-manifold-learning-based graph construction for semisupervised hyperspectral image classification">

                                <b>[13]</b> Ma L, Crawford M M, Yang X Q, <i>et al</i>.Local-manifold-learning-based graph construction for semisupervised hyperspectral image classification[J].Proceedings of the IEEE, 2015, 53 (5) :2832-2844.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A modified locality-preserving projection approach for hyperspectral image classification">

                                <b>[14]</b> Zhai Y G, Zhang L F, Wang N, <i>et al</i>.A modified locality-preserving projection approach for hyperspectral image classification[J].Proceedings of the IEEE, 2016, 13 (8) :1059-1063.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGKD201306028&amp;v=MjkwNzZxQnRHRnJDVVJMT2VaZVZ1Rnk3aFVyL0JQeXJBYXJHNEg5TE1xWTlIYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Chen X Z, Hu H J, Wang X S.Dimensionality reduction for hyperspectral data using weighted neighborhood preserving embedding[J].Journal of China University of Mining &amp; Technology, 2013, 42 (6) :1066-1072.陈新忠, 胡汇涓, 王雪松.基于加权近邻保持嵌入的高光谱数据降维方法[J].中国矿业大学学报, 2013, 42 (6) :1066-1072.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locality preserving projections">

                                <b>[16]</b> He X F, Niyogi P.Locality preserving projection[C].Advances in Neural Information Processing System, 2004 (16) :153-160.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">

                                <b>[17]</b> Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201306017&amp;v=MDQ1ODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdoVXIvQkxUclNackc0SDlMTXFZOUVZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Chen Z, Wang B, Zhang L M.Dimensionality reduction and classification based on lower rank tensor analysis for hyperspectral imagery[J].Journal of Infrared and Millimeter Waves, 2013, 32 (6) :569-575.陈昭, 王斌, 张立明.基于低秩张量分析的高光谱图像降维与分类[J].红外与毫米波学报, 2013, 32 (6) :569-575.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor-based low-rank graph with multimanifold regularization for dimensionality reduction of hyperspectral images">

                                <b>[19]</b> An J L, Zhang X R, Zhou H Y, <i>et al</i>.Tensor-based low-rank graph with multimanifold regularization for dimensionality reduction of hyperspectral images[J].Proceedings of the IEEE, 2018, 56 (8) :4731-4746.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative representation for hyperspectral anomaly detection">

                                <b>[20]</b> Li W, Du Q.Collaborative representation for hyperspectral anomaly detection[J].Proceedings of the IEEE, 2015, 53 (3) :1463-1474.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor decomposition for signal processing and machine learning">

                                <b>[21]</b> Sidiropoulos N D, de Lathauwer L, Fu X, <i>et al</i>.Tensor decomposition for signal processing and machine learning[J].Proceedings of the IEEE, 2017, 65 (13) :3551-3582.
                            </a>
                        </p>
                        <p id="54">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor low-rank discriminant embedding for hyperspectral image dimensionality reduction">

                                <b>[22]</b> Deng Y J, Li H C, Fu K, <i>et al</i>.Tensor low-rank discriminant embedding for hyperspectral image dimensionality reduction[J].Proceedings of the IEEE, 2018, 56 (12) :7183-7194.
                            </a>
                        </p>
                        <p id="56">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor-based classification models for hyperspectral data analysis">

                                <b>[23]</b> Makantasis K, Doulamis A D, Doulamis N D, <i>et al</i>.Tensor-based classification models for hyperspectral data analysis[J].Proceedings of the IEEE, 2018, 56 (12) :6884-6898.
                            </a>
                        </p>
                        <p id="58">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Patch alignment for dimensionality reduction">

                                <b>[24]</b> Zhang T H, Tao D C, Li X L, <i>et al</i>.Patch alignment for dimensionality reduction[J].Proceedings of the IEEE, 2009, 21 (9) :1299-1313.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201904016" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904016&amp;v=MjcxMjRiTEc0SDlqTXE0OUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdoVXIvQklqWFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

