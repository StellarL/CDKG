

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134013324971250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905032%26RESULT%3d1%26SIGN%3do8ASSGJto%252fAD3u6w6XIddsUFRtM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905032&amp;v=MjU0MTA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0pJalhUYkxHNEg5ak1xbzlHWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#6" data-title="2 材料与方法 ">2 材料与方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#7" data-title="2.1 实验材料">2.1 实验材料</a></li>
                                                <li><a href="#9" data-title="2.2 图像同步采集系统构建">2.2 图像同步采集系统构建</a></li>
                                                <li><a href="#11" data-title="2.3 采集方法">2.3 采集方法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#13" data-title="3 大豆三维点云快速重建 ">3 大豆三维点云快速重建</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#17" data-title="3.1 Kinect相机标定">3.1 Kinect相机标定</a></li>
                                                <li><a href="#35" data-title="3.2 具有颜色信息的三维点云重建">3.2 具有颜色信息的三维点云重建</a></li>
                                                <li><a href="#38" data-title="3.3 具有颜色信息的大豆冠层点云提取方法">3.3 具有颜色信息的大豆冠层点云提取方法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="4 基于深度信息的株高计算方法研究 ">4 基于深度信息的株高计算方法研究</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="4.1 单盆大豆株高计算">4.1 单盆大豆株高计算</a></li>
                                                <li><a href="#69" data-title="4.2 群体大豆株高计算">4.2 群体大豆株高计算</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="5 大豆株高计算方法有效性验证 ">5 大豆株高计算方法有效性验证</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="5.1 大豆冠层三维重建效果">5.1 大豆冠层三维重建效果</a></li>
                                                <li><a href="#88" data-title="5.2 大豆株高计算值比较结果">5.2 大豆株高计算值比较结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="6 结论 ">6 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#15" data-title="图1 大豆植株采集方式示意图">图1 大豆植株采集方式示意图</a></li>
                                                <li><a href="#37" data-title="图2 具有颜色信息的大豆冠层三维 (3D) 重建流程图。 (a) 图像同步采集系统; (b) 深度图像; (c) 彩色图像; (d) 原始三维点云; (e) 彩色图像灰度直方图; (f) 原始点云距离图; (g) 具有颜色信息的原始点云距离图; (h) 分割后大豆冠层距离图; (i) 分割后具有颜色信息的大豆冠层距离图">图2 具有颜色信息的大豆冠层三维 (3D) 重建流程图。 (a) 图像同步采集系统; (b) 深度图......</a></li>
                                                <li><a href="#40" data-title="图3 Kinect相机视觉模型">图3 Kinect相机视觉模型</a></li>
                                                <li><a href="#41" data-title="图4 棋盘格与相机的相对位置关系。 (a) 彩色相机拍摄的棋盘格角点检测; (b) 深度相机拍摄的棋盘格角点检测">图4 棋盘格与相机的相对位置关系。 (a) 彩色相机拍摄的棋盘格角点检测; (b) 深度相机拍摄的棋......</a></li>
                                                <li><a href="#63" data-title="图5 具有颜色信息的大豆冠层三维重建。 (a) 原始三维点云; (b) 具有颜色信息的原始三维点云; (c) 分割后大豆冠层三维点云距离正视图; (d) 分割后大豆冠层三维点云距离侧视图; (e) 具有颜色信息的大豆冠层三维点云正视图; (f) 具有颜色信息的大豆冠层三维点云俯视图">图5 具有颜色信息的大豆冠层三维重建。 (a) 原始三维点云; (b) 具有颜色信息的原始三维点云;......</a></li>
                                                <li><a href="#71" data-title="图6 单盆大豆冠层三维图像采集方法">图6 单盆大豆冠层三维图像采集方法</a></li>
                                                <li><a href="#72" data-title="图7 群体大豆株高计算方法">图7 群体大豆株高计算方法</a></li>
                                                <li><a href="#75" data-title="图8 盆间距示意图">图8 盆间距示意图</a></li>
                                                <li><a href="#86" data-title="图9 2018年7月19日获得的大豆冠层三维重建效果。 (a) 单盆重建; (b) 群体重建">图9 2018年7月19日获得的大豆冠层三维重建效果。 (a) 单盆重建; (b) 群体重建</a></li>
                                                <li><a href="#91" data-title="图1 0 大豆9-5号的2018年6月19日 (0619) —2018年9月5日 (0905) 生殖生长期的冠层3D重建效果">图1 0 大豆9-5号的2018年6月19日 (0619) —2018年9月5日 (0905) 生殖......</a></li>
                                                <li><a href="#96" data-title="图1 1 三个品种大豆株高的测量值与计算值的比较。 (a) 抗线9号的对比结果; (b) 抗线13号的对比结果; (c) 富豆6号的对比结果">图1 1 三个品种大豆株高的测量值与计算值的比较。 (a) 抗线9号的对比结果; (b) 抗线13号......</a></li>
                                                <li><a href="#97" data-title="图1 2 基于时间序列的三个品种大豆株高动态变化图">图1 2 基于时间序列的三个品种大豆株高动态变化图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="101">


                                    <a id="bibliography_1" title="Garrido M, Paraforos D S, Reiser D, et al.3D Maize plant reconstruction based on georeferenced overlapping LiDAR point clouds[J].Remote Sensing, 2015, 7 (12) :17077-17096." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D maize plant reconstruction based on georeferenced overlapping LiDAR point clouds">
                                        <b>[1]</b>
                                        Garrido M, Paraforos D S, Reiser D, et al.3D Maize plant reconstruction based on georeferenced overlapping LiDAR point clouds[J].Remote Sensing, 2015, 7 (12) :17077-17096.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_2" title="Lipka A E, Kandianis C B, Hudson M E, et al.From association to prediction:statistical methods for the dissection and selection of complex traits in plants[J].Current Opinion in Plant Biology, 2015, 24:110-118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD2CD2E9E1605897E44C9F1B6C9258B39&amp;v=MjUwNTZQbjZRcW1FOGU3ZWNON21XQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhod0xtOHdLZz1OaWZPZmNlNmJhWE8yb1l3WmUwUENYUXd5R01YN2t4MA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Lipka A E, Kandianis C B, Hudson M E, et al.From association to prediction:statistical methods for the dissection and selection of complex traits in plants[J].Current Opinion in Plant Biology, 2015, 24:110-118.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_3" title="Haughton A J, Bohan D A, Clark S J, et al.Dedicated biomass crops can enhance biodiversity in the arable landscape[J].Global Change Biology Bioenergy, 2016, 8 (6) :1071-1081." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDE2009204D066E6468EBAB05B788FE94B&amp;v=MjE0ODBUTDd0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhod0xtOHdLZz1OaWZjYXNhNkh0SEZyWTlCRU9zSkNnay95eEFibjAwTU9uL24zaFU5Y2NUaA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Haughton A J, Bohan D A, Clark S J, et al.Dedicated biomass crops can enhance biodiversity in the arable landscape[J].Global Change Biology Bioenergy, 2016, 8 (6) :1071-1081.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_4" title="Song Q P, Tang J L, Xin J.3-dimensional reconstruction for soybean plant of seedling stage based on growth model[J].Computer Engineering, 2017, 43 (5) :275-280.宋祺鹏, 唐晶磊, 辛菁.基于生长模型的苗期大豆植株三维重建[J].计算机工程, 2017, 43 (5) :275-280." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201705045&amp;v=MjY3NzZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUx6N0JiYkc0SDliTXFvOUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Song Q P, Tang J L, Xin J.3-dimensional reconstruction for soybean plant of seedling stage based on growth model[J].Computer Engineering, 2017, 43 (5) :275-280.宋祺鹏, 唐晶磊, 辛菁.基于生长模型的苗期大豆植株三维重建[J].计算机工程, 2017, 43 (5) :275-280.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_5" title="Pratap A, Tomar R, Kumar J, et al.High-throughput plant phenotyping platforms[J].Phenomics in Crop Plants:Trends Options and Limitations, 2015:285-296." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-Throughput Plant Phenotyping Platforms">
                                        <b>[5]</b>
                                        Pratap A, Tomar R, Kumar J, et al.High-throughput plant phenotyping platforms[J].Phenomics in Crop Plants:Trends Options and Limitations, 2015:285-296.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_6" title="Barker III J, Zhang N Q, Sharon J, et al.Development of a field-based high-throughput mobile phenotyping platform[J].Computers and Electronics in Agriculture, 2016, 122:74-85." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4C267E23F65A38B1D77A20632BD36329&amp;v=MDMyOTRmQ3BiUTM1ZGhod0xtOHdLZz1OaWZPZmJmTEhOZkwybzFHRXUwS2ZYOHh2UmRuN1RnTVNuL2tyeEJIRGJHU1JyaVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        Barker III J, Zhang N Q, Sharon J, et al.Development of a field-based high-throughput mobile phenotyping platform[J].Computers and Electronics in Agriculture, 2016, 122:74-85.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_7" title="Palanichamy D, Cobb J N.Agronomic field trait phenomics[M].New York:Springer, 2015:83-99." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Agronomic field trait phenomics">
                                        <b>[7]</b>
                                        Palanichamy D, Cobb J N.Agronomic field trait phenomics[M].New York:Springer, 2015:83-99.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_8" title="Li H.3D reconstruction of maize leaves based on virtual visual technology[J].Bulletin of Science and Technology, 2016, 32 (5) :96-101.李辉.基于虚拟双目视觉的玉米叶片三维重建方法[J].科技通报, 2016, 32 (5) :96-101." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJTB201605019&amp;v=MjA3MzJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JTGlmZmJMRzRIOWZNcW85RWJZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Li H.3D reconstruction of maize leaves based on virtual visual technology[J].Bulletin of Science and Technology, 2016, 32 (5) :96-101.李辉.基于虚拟双目视觉的玉米叶片三维重建方法[J].科技通报, 2016, 32 (5) :96-101.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_9" title="Li S H, Guan H O, Yu S, et al.Whole 3Dreconstruction based on fast SCAN corn and parameter calculation method[J].Journal of Agricultural Mechanization Research, 2018, 40 (4) :162-166.李抒昊, 关海鸥, 于崧, 等.基于FastSCAN玉米整株三维重构及参数计算方法[J].农机化研究, 2018, 40 (4) :162-166." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201804031&amp;v=MTA3NTM0OUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUt5ZlNaTEc0SDluTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Li S H, Guan H O, Yu S, et al.Whole 3Dreconstruction based on fast SCAN corn and parameter calculation method[J].Journal of Agricultural Mechanization Research, 2018, 40 (4) :162-166.李抒昊, 关海鸥, 于崧, 等.基于FastSCAN玉米整株三维重构及参数计算方法[J].农机化研究, 2018, 40 (4) :162-166.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_10" title="Jiang P, Geng N.Crop height non-destructive remote measurement based on IP camera[J].Journal of Agricultural Mechanization Research, 2015, 37 (4) :68-72.蒋普, 耿楠.基于网络摄像机的株高远程无损测量系统[J].农机化研究, 2015, 37 (4) :68-72." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201504017&amp;v=MTc5OTBWdUZ5emtVTC9JS3lmU1pMRzRIOVRNcTQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Jiang P, Geng N.Crop height non-destructive remote measurement based on IP camera[J].Journal of Agricultural Mechanization Research, 2015, 37 (4) :68-72.蒋普, 耿楠.基于网络摄像机的株高远程无损测量系统[J].农机化研究, 2015, 37 (4) :68-72.
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_11" title="Li Q, Cheng X J, Tian R, et al.Correction and normalization of multi-scan terrestrial three-dimensional laser scanning intensity[J].Laser&amp;amp;Optoelectronics Progress, 2017, 54 (12) :122802.李泉, 程效军, 田芮, 等.多站地面三维激光扫描强度数据纠正与归一化[J].激光与光电子学进展, 2017, 54 (12) :122802." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201712058&amp;v=Mjk5OTgvSUx5clBaTEc0SDliTnJZOUFiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Li Q, Cheng X J, Tian R, et al.Correction and normalization of multi-scan terrestrial three-dimensional laser scanning intensity[J].Laser&amp;amp;Optoelectronics Progress, 2017, 54 (12) :122802.李泉, 程效军, 田芮, 等.多站地面三维激光扫描强度数据纠正与归一化[J].激光与光电子学进展, 2017, 54 (12) :122802.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_12" title="Xiao Y, Hu S X, Xiao S, et al.A fast statistical method of tree information from 3D laser point clouds[J].Chinese Journal of Lasers, 2018, 45 (5) :0510007.肖杨, 胡少兴, 肖深, 等.从三维激光点云中快速统计树木信息的方法[J].中国激光, 2018, 45 (5) :0510007." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201805036&amp;v=MTIzNDllVnVGeXprVUwvSUx5ZlJkTEc0SDluTXFvOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Xiao Y, Hu S X, Xiao S, et al.A fast statistical method of tree information from 3D laser point clouds[J].Chinese Journal of Lasers, 2018, 45 (5) :0510007.肖杨, 胡少兴, 肖深, 等.从三维激光点云中快速统计树木信息的方法[J].中国激光, 2018, 45 (5) :0510007.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_13" title="Ma X D, Guo C L, Zhang X, et al.Calculation of light distribution of apple tree canopy based on color characteristics of 3Dpoint cloud[J].Transactions of the Chinese Society for Agricultural Machinery, 2015, 46 (6) :263-268.马晓丹, 郭彩玲, 张雪, 等.基于三维点云颜色特征的苹果树冠层光照分布计算方法[J].农业机械学报, 2015, 46 (6) :263-268." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201506038&amp;v=MjgzOTJxWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lLelRCZHJHNEg5VE0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Ma X D, Guo C L, Zhang X, et al.Calculation of light distribution of apple tree canopy based on color characteristics of 3Dpoint cloud[J].Transactions of the Chinese Society for Agricultural Machinery, 2015, 46 (6) :263-268.马晓丹, 郭彩玲, 张雪, 等.基于三维点云颜色特征的苹果树冠层光照分布计算方法[J].农业机械学报, 2015, 46 (6) :263-268.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_14" title="Ma X D, Guo C L, Zhang X, et al.Calculation of chlorophyll fluorescence characters in different light area to apple tree canopy[J].Spectroscopy and Spectral Analysis, 2016, 36 (12) :3986-3990.马晓丹, 郭彩玲, 张雪, 等.苹果树冠层不同光照区域叶绿素荧光性状计算方法[J].光谱学与光谱分析, 2016, 36 (12) :3986-3990." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201612036&amp;v=MTk5MjBJampLWUxHNEg5Zk5yWTlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0k=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Ma X D, Guo C L, Zhang X, et al.Calculation of chlorophyll fluorescence characters in different light area to apple tree canopy[J].Spectroscopy and Spectral Analysis, 2016, 36 (12) :3986-3990.马晓丹, 郭彩玲, 张雪, 等.苹果树冠层不同光照区域叶绿素荧光性状计算方法[J].光谱学与光谱分析, 2016, 36 (12) :3986-3990.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_15" title="Jiang Y, Li C Y, Paterson A H.High throughput phenotyping of cotton plant height using depth images under field conditions[J].Computers and Electronics in Agriculture, 2016, 130:57-68." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High throughput phenotyping of cotton plant height using depth images under field conditions">
                                        <b>[15]</b>
                                        Jiang Y, Li C Y, Paterson A H.High throughput phenotyping of cotton plant height using depth images under field conditions[J].Computers and Electronics in Agriculture, 2016, 130:57-68.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_16" title="Ma X D, Feng J R, Guan H O, et al.Prediction of chlorophyll content in different light areas of apple tree canopies based on the color characteristics of 3Dreconstruction[J].Remote Sensing, 2018, 10 (3) :429." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Prediction of chlorophyll content in different light areas of apple tree canopies based on the color characteristics of 3Dreconstruction">
                                        <b>[16]</b>
                                        Ma X D, Feng J R, Guan H O, et al.Prediction of chlorophyll content in different light areas of apple tree canopies based on the color characteristics of 3Dreconstruction[J].Remote Sensing, 2018, 10 (3) :429.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_17" title="Skerik F, Volf J, Linda M, et al.Methods for detection of objects in agriculture, Prague[C]∥Conference Proceeding-5th International Conference, TAE 2013:Trends in Agricultural Engineering, September 3-6, 2013.Czech University of Life Sciences Prague, 2013, 599-601." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Methods for detection of objects in agriculture,Prague">
                                        <b>[17]</b>
                                        Skerik F, Volf J, Linda M, et al.Methods for detection of objects in agriculture, Prague[C]∥Conference Proceeding-5th International Conference, TAE 2013:Trends in Agricultural Engineering, September 3-6, 2013.Czech University of Life Sciences Prague, 2013, 599-601.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_18" title="Yamamoto S, Hayashi S, Saito S, et al.Measurement of growth information of a strawberry plantusing a natural interaction device[C]∥2012Dallas, Texas, July 29-August 1, 2012.American Society of Agricultural and Biological Engineers, 2012:121341108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Measurement of growth information of a strawberry plantusing a natural interaction device">
                                        <b>[18]</b>
                                        Yamamoto S, Hayashi S, Saito S, et al.Measurement of growth information of a strawberry plantusing a natural interaction device[C]∥2012Dallas, Texas, July 29-August 1, 2012.American Society of Agricultural and Biological Engineers, 2012:121341108.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_19" title="Shen Y, Zhu J H, Liu H, et al.Plant image mosaic based on depth and color dual information feature source from Kinect[J].Transactions of the Chinese Society of Agricultural Engineering, 2018, 34 (5) :176-182.沈跃, 朱嘉慧, 刘慧, 等.基于深度和彩色双信息特征源的Kinect植物图像拼接[J].农业工程学报, 2018, 34 (5) :176-182." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201805023&amp;v=MjQ4NDc0SDluTXFvOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUt6VE1lN0c=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Shen Y, Zhu J H, Liu H, et al.Plant image mosaic based on depth and color dual information feature source from Kinect[J].Transactions of the Chinese Society of Agricultural Engineering, 2018, 34 (5) :176-182.沈跃, 朱嘉慧, 刘慧, 等.基于深度和彩色双信息特征源的Kinect植物图像拼接[J].农业工程学报, 2018, 34 (5) :176-182.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_20" title="Liu M, Bu W Z, Yang W Y, et al.Correlation analysis of yield and agronomic traits of soybean for intercropping in Shangdong[J].Chinese Journal of Oil Crop Sciences, 2018, 40 (3) :344-351.刘明, 卜伟召, 杨文钰, 等.山东间作大豆产量与主要农艺性状关联分析[J].中国油料作物学报, 2018, 40 (3) :344-351." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGYW201803005&amp;v=MjE4NTJySTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lQeXJTZWJHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Liu M, Bu W Z, Yang W Y, et al.Correlation analysis of yield and agronomic traits of soybean for intercropping in Shangdong[J].Chinese Journal of Oil Crop Sciences, 2018, 40 (3) :344-351.刘明, 卜伟召, 杨文钰, 等.山东间作大豆产量与主要农艺性状关联分析[J].中国油料作物学报, 2018, 40 (3) :344-351.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_21" title="Liu G, Zhang X, Zong Z, et al.3Dreconstruction of strawberry based on depth information[J].Transactions of the Chinese Society for Agricultural Machinery, 2017, 48 (4) :160-165, 172.刘刚, 张雪, 宗泽, 等.基于深度信息的草莓三维重建技术[J].农业机械学报, 2017, 48 (4) :160-165, 172." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201704021&amp;v=Mjk4MjZHNEg5Yk1xNDlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lLelRCZHI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Liu G, Zhang X, Zong Z, et al.3Dreconstruction of strawberry based on depth information[J].Transactions of the Chinese Society for Agricultural Machinery, 2017, 48 (4) :160-165, 172.刘刚, 张雪, 宗泽, 等.基于深度信息的草莓三维重建技术[J].农业机械学报, 2017, 48 (4) :160-165, 172.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_22" title="Yu X L, Wang D D, Niu L L, et al.The applications and research progress of kinect in the information field of modern agriculturae[J].Journal of Agricultural Mechanization Research, 2015, 37 (11) :216-221.余秀丽, 王丹丹, 牛磊磊, 等.Kinect在现代农业信息领域中的应用与研究进展[J].农机化研究, 2015, 37 (11) :216-221." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201511049&amp;v=MjA1NzF1Rnl6a1VML0lLeWZTWkxHNEg5VE5ybzlCYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Yu X L, Wang D D, Niu L L, et al.The applications and research progress of kinect in the information field of modern agriculturae[J].Journal of Agricultural Mechanization Research, 2015, 37 (11) :216-221.余秀丽, 王丹丹, 牛磊磊, 等.Kinect在现代农业信息领域中的应用与研究进展[J].农机化研究, 2015, 37 (11) :216-221.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_23" title="Guo L P, Chen X N, Liu B.Calibration of Kinect sensor with depth and color camera[J].Journal of Image and Graphics, 2014, 19 (11) :1584-1590.郭连朋, 陈向宁, 刘彬.Kinect传感器的彩色和深度相机标定[J].中国图象图形学报, 2014, 19 (11) :1584-1590." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201411005&amp;v=MTg1OTN5emtVTC9JUHlyZmJMRzRIOVhOcm85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Guo L P, Chen X N, Liu B.Calibration of Kinect sensor with depth and color camera[J].Journal of Image and Graphics, 2014, 19 (11) :1584-1590.郭连朋, 陈向宁, 刘彬.Kinect传感器的彩色和深度相机标定[J].中国图象图形学报, 2014, 19 (11) :1584-1590.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_24" title="Li Y N.Research on calibration algorithm of Kinect depth camera[D].Xi′an:Xidian University, 2014.李雅娜.Kinect深度相机标定算法研究[D].西安:西安电子科技大学, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015437326.nh&amp;v=MjE4MzdML0lWRjI2RzdlN0dkTE9xWkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Li Y N.Research on calibration algorithm of Kinect depth camera[D].Xi′an:Xidian University, 2014.李雅娜.Kinect深度相机标定算法研究[D].西安:西安电子科技大学, 2014.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_25" title="Wang S, Xu X.3Dreconstruction based on horopter[J].Acta Optica Sinica, 2017, 37 (5) :0515004.王珊, 徐晓.基于双目单视面的三维重建[J].光学学报, 2017, 37 (5) :0515004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705024&amp;v=MTc0MTQ5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JSWpYVGJMRzRIOWJNcW8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                        Wang S, Xu X.3Dreconstruction based on horopter[J].Acta Optica Sinica, 2017, 37 (5) :0515004.王珊, 徐晓.基于双目单视面的三维重建[J].光学学报, 2017, 37 (5) :0515004.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_26" title="Zhou W, Ma X D, Zhang L J, et al.Three dimensional point cloud splicing of tree canopy based on multi-source camera[J].Acta Optica Sinica, 2014, 34 (12) :1215003.周薇, 马晓丹, 张丽娇, 等.基于多源信息融合的果树冠层三维点云拼接方法研究[J].光学学报, 2014, 34 (12) :1215003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201412028&amp;v=MDY2NzQ5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JSWpYVGJMRzRIOVhOclk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                        Zhou W, Ma X D, Zhang L J, et al.Three dimensional point cloud splicing of tree canopy based on multi-source camera[J].Acta Optica Sinica, 2014, 34 (12) :1215003.周薇, 马晓丹, 张丽娇, 等.基于多源信息融合的果树冠层三维点云拼接方法研究[J].光学学报, 2014, 34 (12) :1215003.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_27" title="Wang M B.Study on three-dimensional reconstruction of crop plants based on point cloud[J].Journal of Ezhou University, 2018, 25 (1) :104-106, 109.王孟博.基于点云的作物植株三维重建技术研究[J].鄂州大学学报, 2018, 25 (1) :104-106, 109." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=EZDX201801035&amp;v=MjA0NzFNcm85R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JSURmUGRyRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                        Wang M B.Study on three-dimensional reconstruction of crop plants based on point cloud[J].Journal of Ezhou University, 2018, 25 (1) :104-106, 109.王孟博.基于点云的作物植株三维重建技术研究[J].鄂州大学学报, 2018, 25 (1) :104-106, 109.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_28" title="Li X Q.Research on image threshold segmentation algorithm based on Matlab[J].Software Guide, 2014, 13 (12) :76-78.李小琦.基于Matlab的图像阈值分割算法研究[J].软件导刊, 2014, 13 (12) :76-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJDK201412029&amp;v=MjcxNjZPZVplVnVGeXprVUwvSU55ZlBaYkc0SDlYTnJZOUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[28]</b>
                                        Li X Q.Research on image threshold segmentation algorithm based on Matlab[J].Software Guide, 2014, 13 (12) :76-78.李小琦.基于Matlab的图像阈值分割算法研究[J].软件导刊, 2014, 13 (12) :76-78.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_29" title="Guan H O, Liu M, Ma X D, et al.Threedimensional reconstruction of soybean canopies using multisource imaging for phenotyping analysis[J].Remote Sensing, 2018, 10 (8) :1206." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Threedimensional reconstruction of soybean canopies using multisource imaging for phenotyping analysis">
                                        <b>[29]</b>
                                        Guan H O, Liu M, Ma X D, et al.Threedimensional reconstruction of soybean canopies using multisource imaging for phenotyping analysis[J].Remote Sensing, 2018, 10 (8) :1206.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_30" title="Zhu B L, Liu F S, Zhu J Y, et al.Three-dimensional quantifications of plant growth dynamics in fieldgrown plants based on machine vision method[J].Transactions of the Chinese Society for Agricultural Machinery, 2018, 49 (5) :256-262.朱冰琳, 刘扶桑, 朱晋宇, 等.基于机器视觉的大田植株生长动态三维定量化研究[J].农业机械学报, 2018, 49 (5) :256-262." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201805030&amp;v=MzE4Mjg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUt6VEJkckc0SDluTXFvOUdaSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[30]</b>
                                        Zhu B L, Liu F S, Zhu J Y, et al.Three-dimensional quantifications of plant growth dynamics in fieldgrown plants based on machine vision method[J].Transactions of the Chinese Society for Agricultural Machinery, 2018, 49 (5) :256-262.朱冰琳, 刘扶桑, 朱晋宇, 等.基于机器视觉的大田植株生长动态三维定量化研究[J].农业机械学报, 2018, 49 (5) :256-262.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_31" title="Carlone L, Dong J, Fenu S, et al.Towards 4Dcrop analysis in precision agriculture:estimating plant height and crown radius over time via expectationmaximization[C]∥IEEE ICRA Workshop on Robotics in Agriculture, May 26-30, 2015Seattle, WA, USA, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards 4Dcrop analysis in precision agriculture:estimating plant height and crown radius over time via expectationmaximization">
                                        <b>[31]</b>
                                        Carlone L, Dong J, Fenu S, et al.Towards 4Dcrop analysis in precision agriculture:estimating plant height and crown radius over time via expectationmaximization[C]∥IEEE ICRA Workshop on Robotics in Agriculture, May 26-30, 2015Seattle, WA, USA, 2015.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-02-25 09:20</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),258-268 DOI:10.3788/AOS201939.0515003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于深度信息的大豆株高计算方法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%AF%E4%BD%B3%E7%9D%BF&amp;code=41130460&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冯佳睿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E6%99%93%E4%B8%B9&amp;code=10553890&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马晓丹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%85%B3%E6%B5%B7%E9%B8%A5&amp;code=14029955&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关海鸥</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%8F%AF%E5%BF%83&amp;code=41130459&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱可心</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E8%8F%98&amp;code=41926329&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于菘</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%BB%91%E9%BE%99%E6%B1%9F%E5%85%AB%E4%B8%80%E5%86%9C%E5%9E%A6%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0350828&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黑龙江八一农垦大学电气与信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%BB%91%E9%BE%99%E6%B1%9F%E5%85%AB%E4%B8%80%E5%86%9C%E5%9E%A6%E5%A4%A7%E5%AD%A6%E5%86%9C%E5%AD%A6%E9%99%A2&amp;code=0350828&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黑龙江八一农垦大学农学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为高通量地计算农作物株高, 克服传统测量方法低效、耗时耗力等不足, 以抗线9号、13号和富豆6号寒地大豆为研究对象, 构建了基于Kinect 2.0的大豆冠层图像同步采集平台, 并在三维重建大豆冠层结构形态的基础上, 提出了基于深度信息的个体和群体大豆株高计算方法。实验结果表明, 与实测值相比, 计算得到的个体和群体大豆株高的平均误差分别为0.14cm和0.54cm, 抗线9号、13号和富豆6号株高计算值与实测值之间的决定系数依次为0.9717, 0.9730, 0.9697。所提方法能够较为精确地计算大豆植株的株高特征。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E8%B1%86%E5%86%A0%E5%B1%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大豆冠层;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kinect%202.0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kinect 2.0;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A1%A8%E5%9E%8B%E5%8F%82%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">表型参数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%AA%E9%AB%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">株高;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    马晓丹, E-mail:bynd_mxd@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家青年科学基金 (31601220);</span>
                                <span>黑龙江省青年科学基金 (QC2016031);</span>
                                <span>中国博士后科学基金 (2016M601464);</span>
                                <span>黑龙江八一农垦大学青年创新人才支持计划 (CXRC2016-14) ;黑龙江八一农垦大学自然科学人才支持计划 (ZRCQC201806);</span>
                    </p>
            </div>
                    <h1>Calculation Method of Soybean Plant Height Based on Depth Information</h1>
                    <h2>
                    <span>Feng Jiarui</span>
                    <span>Ma Xiaodan</span>
                    <span>Guan Haiou</span>
                    <span>Zhu Kexin</span>
                    <span>Yu Song</span>
            </h2>
                    <h2>
                    <span>College of Electrical and Information, Heilongjiang Bayi Agricultural University</span>
                    <span>Agronomy College of Heilongjiang Bayi Agricultural University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In this study, three cold soybean varieties, namely Kangxian-9, Kangxian-13, and Fudou-6, were used for the high-throughput calculation of soybean plant heights.Three varieties were used to overcome the disadvantages of the traditional measurement methods, which were inefficient and laborious.The method for calculating the plant heights of individual and grouped soybean plants was proposed using the depth information acquired from the three-dimensional reconstruction of soybean canopies obtained using the Kinect V2.0 synchronous image acquisition platform.The experimental results show that compared with the measured value, the average errors of the proposed calculation method for the plant heights of individual and grouped soybean plants are 0.14 cm and 0.54 cm, respectively.The determination coefficients between calculated and measured values for Kangxian-9, Kangxian-13, and Fudou-6 are 0.9717, 0.9730, and 0.9697, respectively.Thus, the proposed method can accurately calculate the heights of soybean plants.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=soybean%20canopy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">soybean canopy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=depth%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">depth information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kinect%202.0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kinect 2.0;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=three-dimensional%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">three-dimensional reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=phenotypic%20parameters&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">phenotypic parameters;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=plant%20height&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">plant height;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">大豆作物在生长过程中所体现出的形态特征对选育大豆优良品种具有重要作用<citation id="163" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。株高的动态变化不同程度地影响大豆产量, 研究该表型特征不仅有助于基因-环境相互作用的定量分析, 而且对提升大豆品质至关重要<citation id="164" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="3">传统株高测量方法是利用直尺、手持式激光测距仪等设备手动测量冠层最高点到植株根部的垂直长度, 这种方法不仅费时费力, 而且结果易受测量者主观因素的影响。为了弥补传统测量技术的不足, 信息化的测量技术被广泛地应用到农作物表型特征的研究中。</p>
                </div>
                <div class="p1">
                    <p id="4">目前植物表型参数测量研究大多局限于实验室环境或是基于虚拟植株三维重建, 无法反映田间植株真实的生长情况<citation id="169" type="reference"><link href="105" rel="bibliography" /><link href="107" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。基于田间的高通量表型参数测量手段是制约植物基因组研究和作物改良的主要因素<citation id="165" type="reference"><link href="109" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。目前农作物冠层信息获取技术主要包括手持式传感器、基于双目相机的立体视觉技术、手持式激光扫描技术和三维激光扫描及雷达技术等<citation id="170" type="reference"><link href="111" rel="bibliography" /><link href="113" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。手持式传感器采用的是接触式测量方法, 会导致农作物发生形变。基于双目相机的立体视觉技术<citation id="166" type="reference"><link href="115" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 可对作物冠层图像进行非接触式无损采集, 且不破坏作物生长形态, 但采集的图像质量受光照影响较大, 进而降低了表型参数计算的准确性。手持式激光扫描技术 (如FastSCAN型激光扫描仪和Artec EVA型激光扫描仪) 虽然能够高精度地重构作物冠层的三维结构形态, 但其采集速度较慢<citation id="167" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。近年来, 在地物表型参数分析的基础上, 研究人员提出了空间上高通量的测量方法, 如网络相机远程表型测量<citation id="168" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 这种方法虽然实现了农作物表型特征的快速采集, 但其测量结果误差波动范围较大。三维激光扫描及雷达技术<citation id="171" type="reference"><link href="121" rel="bibliography" /><link href="123" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation> (如FARO Focus3D120型地物激光扫描) 能快速精确地获取植物冠层点云信息, 但获取的点云信息中存在大量的冗余背景信息, 需要进行点云筛选等操作才能精确构建冠层三维结构形态, 且昂贵的价格进一步限制了该设备的广泛应用<citation id="172" type="reference"><link href="125" rel="bibliography" /><link href="127" rel="bibliography" /><link href="129" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。上述技术手段已经在大田作物 (如玉米和水稻) 和树木等的表型参数计算中取得了较多的研究成果, 但针对大豆的表型研究相对较少。</p>
                </div>
                <div class="p1">
                    <p id="5">本文提出了一种价格相对低廉且精确度相对较高的农作物冠层信息获取方法。Kinect传感器具有较精确和快速获取空间信息的优势, 已经被广泛用于农产品检测、农作物实时监控和植物表型参数获取等研究中<citation id="173" type="reference"><link href="131" rel="bibliography" /><link href="133" rel="bibliography" /><link href="135" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>。在此构建了基于Kinect 2.0传感器的大豆冠层图像采集平台, 以快速高效地获取自然环境下大豆冠层彩色及距离点云数据, 并以此开展大豆株高的计算方法研究。该研究成果为田间农作物高通量表型技术的研究提供了一种有力的获取手段, 为大豆优良品种的选育提供了精确的数据支持<citation id="174" type="reference"><link href="137" rel="bibliography" /><link href="139" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>。</p>
                </div>
                <h3 id="6" name="6" class="anchor-tag">2 材料与方法</h3>
                <h4 class="anchor-tag" id="7" name="7">2.1 实验材料</h4>
                <div class="p1">
                    <p id="8">大豆种植及其冠层信息的采集工作是在黑龙江八一农垦大学农学院卓越农业人才创新创业训练园开展的。在自然光强为0～1200μmol·m<sup>-2</sup>·s<sup>-1</sup>、温度为20～34℃的室外条件下, 选取抗线9号、抗线13号和富豆6号这3个品种的大豆作为研究对象, 其中抗线9号和抗线13号大豆的抗线虫能力较强, 富豆6号富含丰富的油脂。将种子经过精选后进行消毒、催芽, 播种于花盆中。具体操作为:首先将中等土块铺平于直径为0.3m、高为0.18m的聚氯乙烯 (PVC) 材料的盆底, 装入筛选好的非盐碱细土, 直至盆重为4.5kg, 均匀平铺复合肥后继续在盆中放入细土至7.5kg。在2018年5月21日种植第一批上述三个大豆品种, 分别在9d后和18d后种植第二批和第三批大豆。每个品种的大豆各15盆, 三批大豆共计45盆。</p>
                </div>
                <h4 class="anchor-tag" id="9" name="9">2.2 图像同步采集系统构建</h4>
                <div class="p1">
                    <p id="10">构建基于Kinect 2.0的大豆冠层三维数据同步采集系统, 动态采集大豆冠层彩色图像和深度信息的多源数据。该系统由Kinect 2.0相机、笔记本电脑、线圈和可上下左右调节的铁架组成。通过云台把Kinect 2.0相机安装在可调拍摄架的固定位置处, 通过USB 3.0接口连接Kinect 2.0相机和笔记本电脑。Kinect 2.0由彩色摄像头 (RGB Camera) 、深度 (红外) 摄像头和红外发射器组成<citation id="175" type="reference"><link href="141" rel="bibliography" /><link href="143" rel="bibliography" /><sup>[<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>。其中彩色摄像头用于拍摄彩色图像, 其分辨率为1920pixel×1080pixel。深度 (红外) 摄像头用于获取红外光谱并创建可视范围内的物体深度图像, 其分辨率为512pixel×424pixel, 帧速为30frame/s。深度数据获取范围为0.5～4.5m, 水平角度为70°, 垂直角度为60°。为保证大豆正常生长, 数据采集工作均在室外自然光照下进行。图1为大豆植株采集方式示意图。</p>
                </div>
                <h4 class="anchor-tag" id="11" name="11">2.3 采集方法</h4>
                <div class="p1">
                    <p id="12">为减少光照对大豆冠层图像的影响, 并保证所采集的实验图像的清晰度, 选择垂直方式获取大豆冠层图像信息, 并基于深度信息开展大豆株高计算方法研究。数据采集周期为7～10d。为保证深度信息的有效性, 将Kinect 2.0相机置于可调铁架中央, 通过调节铁架高度寻找最佳拍摄高度。大豆株高人工测量时间在设备采集的前一天或后一天进行, 测量工具为直尺, 单位为cm, 将所获取的测量值与计算值进行对比。</p>
                </div>
                <h3 id="13" name="13" class="anchor-tag">3 大豆三维点云快速重建</h3>
                <div class="p1">
                    <p id="14">为构建具有颜色信息的单盆及群体大豆冠层三维结构形态, 利用搭建的同步采集系统, 以顶视法采集富豆9号、抗线9号和13号大豆冠层的彩色图像及其深度图像, 获取的图像分别包括红、绿、蓝 (R、G、B) 通道的颜色分量值及x、y和z轴的距离值。由于彩色相机和深度相机的视场和分辨率不同, 颜色信息和深度图像的距离值不能直接一一对应, 因此, 需要对二者进行标定。标定方法为:求解图像坐标系和空间坐标系旋转矩阵, 利用所求得的旋转矩阵将彩色及深度图像转换到同一坐标系下, 实现彩色图像与深度图像的配准<citation id="176" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="15">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_01500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 大豆植株采集方式示意图" src="Detail/GetImg?filename=images/GXXB201905032_01500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 大豆植株采集方式示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_01500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Schematic of acquisition method for soybean plants</p>

                </div>
                <div class="p1">
                    <p id="16">以单株抗线9号大豆为例, 具有颜色信息的大豆冠层三维重建流程如图2所示。图2 (a) 为图像同步采集系统;图2 (b) 和图2 (c) 分别为在自然光环境下利用图像同步采集系统垂直拍摄得到的大豆冠层深度图像和彩色图像;图2 (d) 为构建的原始三维点云;图2 (e) 为彩色图像灰度直方图, 用于设定颜色分割阈值;图2 (f) 为原始点云距离图;图2 (g) 为构建的具有颜色信息的原始点云;图2 (h) 为分割后大豆冠层HSV (Hue, Saturation, Value) 距离颜色图;图2 (i) 为分割后具有颜色信息的大豆冠层距离图。</p>
                </div>
                <h4 class="anchor-tag" id="17" name="17">3.1 Kinect相机标定</h4>
                <div class="p1">
                    <p id="18">空间物体上任意一点 (p) 都与相机拍摄所得的图像存在对应关系, 该p点在二维图像 (O<sub>1</sub>-u<sub>L</sub>v<sub>L</sub>和O<sub>2</sub>-u<sub>R</sub>v<sub>R</sub>) 中的位置经过针孔模型可还原成三维。Kinect相机标定就是求解此对应关系, 将三维物体的空间坐标经过矩阵的旋转及平移运算后, 映射到相机的二维成像平面 (O<sub>L</sub>-x<sub>L</sub>y<sub>L</sub>和O<sub>R</sub>-x<sub>R</sub>y<sub>R</sub>) 上。由于实际情况中的参照物不同, 一般需要在统一的世界坐标系 (O<sub>W</sub>-X <sub>W</sub>Y<sub>W</sub>Z<sub>W</sub>) 下表示不同相机坐标系 (O<sub>cL</sub>-X<sub>L</sub>Y<sub>L</sub>Z<sub>L</sub>和O<sub>cR</sub>-X<sub>R</sub>Y<sub>R</sub>Z<sub>R</sub>) 下的空间信息, 该Kinect相机视觉模型<citation id="177" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>如图3所示。</p>
                </div>
                <div class="p1">
                    <p id="19">为精确标定彩色相机和深度相机, 首先, 分别获取Kinect相机视场下的12组不同位置的棋盘格彩色图像和红外图像, 由于红外图像与深度图像具有统一的视角和分辨率, 因此可用红外图像代替深度图像作为彩色图像标定的对象。利用MATLAB标定工具箱, 分别对两个相机进行标定<citation id="178" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。标定得到的棋盘格与相机的相对位置关系如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="20">世界坐标系中的坐标点经过旋转平移后, 可转化到相机坐标系O<sub>C</sub>-X<sub>C</sub>Y<sub>C</sub>Z<sub>C</sub>下, 其数学表达公式如下所示:</p>
                </div>
                <div class="area_img" id="185">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="25">式中:R为3×3的旋转矩阵;r<sub>ij</sub> (i=1, 2, 3;j=1, 2, 3) 为R的矩阵元;T为3×1的平移矩阵, 是相机的外部参数;t<sub>1</sub>、t<sub>2</sub>、t<sub>3</sub>为T的矩阵元<citation id="179" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>。将 (1) 式转化为齐次坐标, 即</p>
                </div>
                <div class="area_img" id="186">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_18600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="29">式中:0<sup>T</sup>= (0, 0, 0) 。通过上述求解运算, 可得</p>
                </div>
                <div class="area_img" id="187">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_18700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="35" name="35">3.2 具有颜色信息的三维点云重建</h4>
                <div class="p1">
                    <p id="36">利用上述标定关系, 将彩色相机坐标系转换到深度相机坐标系下, 即可得到深度图像中距离值与彩色图像中颜色值的对应关系。利用MATLAB的scatter3函数实现大豆冠层三维点云的重建, 重建后的三维模型仅包括形态结构信息<citation id="180" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>。为了重建具有完整颜色信息的大豆三维模型, 对采集的点云颜色数据进行了均值融合处理。最后, 根据相机间的标定关系, 将点云数据的RGB颜色信息赋值到对应的深度图像中, 最终重建了具有颜色信息的大豆冠层三维结构形态。</p>
                </div>
                <div class="area_img" id="37">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 具有颜色信息的大豆冠层三维 (3D) 重建流程图。 (a) 图像同步采集系统; (b) 深度图像; (c) 彩色图像; (d) 原始三维点云; (e) 彩色图像灰度直方图; (f) 原始点云距离图; (g) 具有颜色信息的原始点云距离图; (h) 分割后大豆冠层距离图; (i) 分割后具有颜色信息的大豆冠层距离图" src="Detail/GetImg?filename=images/GXXB201905032_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 具有颜色信息的大豆冠层三维 (3D) 重建流程图。 (a) 图像同步采集系统; (b) 深度图像; (c) 彩色图像; (d) 原始三维点云; (e) 彩色图像灰度直方图; (f) 原始点云距离图; (g) 具有颜色信息的原始点云距离图; (h) 分割后大豆冠层距离图; (i) 分割后具有颜色信息的大豆冠层距离图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2Flow chart of three dimensional (3D) reconstruction of soybean canopy with color information. (a) Synchronous acquisition system; (b) depth image; (c) color image; (d) raw 3Dpoint cloud; (e) gray histogram of color image; (f) distance image of raw data; (g) distance image of raw data with color information; (h) distance image of canopy after segmentation; (i) distance image of canopy with color information after segmentation</p>

                </div>
                <h4 class="anchor-tag" id="38" name="38">3.3 具有颜色信息的大豆冠层点云提取方法</h4>
                <div class="p1">
                    <p id="39">为提高后续大豆株高计算的速度及准确性, 需要对第3.2节重建后的三维点云进行分割, 即将大豆冠层点云从复杂的背景点云中提取出来。在此采用最大类间方差阈值分割法确定分割阈值T<citation id="181" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>。设 (x, y, z) 为距离图像中的任意一点, f (x, y, z) 为相应的灰度级。若灰度值大于阈值, 标记为大豆植株 (用1表示) , 否则标记为背景 (用0表示) 。标记值h (x, y) 可表示为</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Kinect相机视觉模型" src="Detail/GetImg?filename=images/GXXB201905032_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Kinect相机视觉模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Visual model of Kinect camera</p>

                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 棋盘格与相机的相对位置关系。 (a) 彩色相机拍摄的棋盘格角点检测; (b) 深度相机拍摄的棋盘格角点检测" src="Detail/GetImg?filename=images/GXXB201905032_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 棋盘格与相机的相对位置关系。 (a) 彩色相机拍摄的棋盘格角点检测; (b) 深度相机拍摄的棋盘格角点检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Relative position relationship between checkerboard and camera. (a) Corner detection of checkerboard by color camera; (b) corner detection of checkerboard by depth camera</p>

                </div>
                <div class="area_img" id="42">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_04200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="43">上述T的选取对于大豆冠层的有效提取至关重要, 其基本思路是以图像直方图中的某一灰度为阈值, 将图像分成两组并计算其方差。当两组之间的方差最大时, 将此灰度值确定为所需的阈值。图像概率分布的直方图可表示为</p>
                </div>
                <div class="area_img" id="44">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_04400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="45">式中:p<sub>i</sub>为概率分布;N为图像的像素;i为该图像灰度级, i∈[0, L-1];n为对应灰度级i的像素。</p>
                </div>
                <div class="p1">
                    <p id="46">假设T将图像中的像素按灰度值分为大豆冠层C<sub>0</sub>∈[0, T]和背景区域C<sub>1</sub>∈[T+1, L-1]两类, 这两类具有不同灰度分布概率的整幅图像的均值可表示为</p>
                </div>
                <div class="area_img" id="47">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_04700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="48">式中:u<sub>T</sub>为整幅图像的均值。</p>
                </div>
                <div class="p1">
                    <p id="49">大豆冠层像素均值为u<sub>0</sub>, 背景区域像素均值为u<sub>1</sub>, 其数学表达式分别为</p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_05000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="51">式中:w<sub>0</sub>为大豆冠层像素均值出现的概率;w<sub>1</sub>为背景区域像素均值出现的概率。w<sub>0</sub>和w<sub>1</sub>的数学表达式分别为</p>
                </div>
                <div class="area_img" id="52">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="53">式中:P<sub>r</sub> (·) 为所求区域 (大豆冠层或背景区域) 的概率分布。</p>
                </div>
                <div class="p1">
                    <p id="54">最终求得两类间的方差u<sub>L</sub>为</p>
                </div>
                <div class="area_img" id="55">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="56">当T的取值使得两类间的方差最大时, 即</p>
                </div>
                <div class="area_img" id="57">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="58">此时T值为最佳阈值。</p>
                </div>
                <div class="p1">
                    <p id="59">利用求解的T分割三维重建后具有颜色信息的三维点云, 提取得到的大豆冠层如图5所示。图5 (a) 、 (b) 分别为分割前大豆植株的原始三维点云和具有颜色信息的原始点云, 5 (c) 、 (d) 分别为分割后大豆冠层三维点云距离正视图和俯视图, 5 (e) 、 (f) 分别为融合RGB颜色信息后大豆冠层的正视图和俯视图。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">4 基于深度信息的株高计算方法研究</h3>
                <h4 class="anchor-tag" id="61" name="61">4.1 单盆大豆株高计算</h4>
                <div class="p1">
                    <p id="62">假设地面相对平坦, 即地面三维点云在z轴方向上波动较小。单盆大豆冠层三维图像采集方法如图6所示。为了提取大豆冠层三维点云图, 首先将扫描得到的所有区域进行栅格划分, 并将三维点云坐标投影到x-y、x-z或y-z的栅格平面上, 其两两垂直的三条边分别与笛卡儿坐标系的三个坐标轴平行。根据z轴上的距离值设定阈值, 去除三维点云中的背景部分后, 即可提取出大豆植株冠层三维点云。由于Kinect相机获取的坐标信息是无序的, 需通过改变x、y和z方向的阈值范围得到大豆冠层区域的三维点云集, 进而计算每一单盆大豆的株高h, 其计算公式分别如下:</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 具有颜色信息的大豆冠层三维重建。 (a) 原始三维点云; (b) 具有颜色信息的原始三维点云; (c) 分割后大豆冠层三维点云距离正视图; (d) 分割后大豆冠层三维点云距离侧视图; (e) 具有颜色信息的大豆冠层三维点云正视图; (f) 具有颜色信息的大豆冠层三维点云俯视图" src="Detail/GetImg?filename=images/GXXB201905032_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 具有颜色信息的大豆冠层三维重建。 (a) 原始三维点云; (b) 具有颜色信息的原始三维点云; (c) 分割后大豆冠层三维点云距离正视图; (d) 分割后大豆冠层三维点云距离侧视图; (e) 具有颜色信息的大豆冠层三维点云正视图; (f) 具有颜色信息的大豆冠层三维点云俯视图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 3Dreconstruction of soybean canopy with color information. (a) Raw 3Dpoint cloud; (b) raw 3Dpoint cloud with color information; (c) 3Dpoint cloud distance image of soybean canopy after segmentation under front view; (d) 3D point cloud distance image of soybean canopy after segmentation under side view; (e) 3Dreconstruction of soybean canopy with color information under front view; (f) 3Dreconstruction of soybean canopy with color information under top view</p>

                </div>
                <div class="area_img" id="64">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="65">式中: (x<sub>m</sub>, y<sub>m</sub>, z<sub>m</sub>) 为在阈值范围内对某点 (X<sub>0</sub>, Y<sub>0</sub>, Z<sub>0</sub>) 进行投影得到的点云坐标信息;[X<sub>1</sub>, X<sub>2</sub>], [Y<sub>1</sub>, Y<sub>2</sub>]和[Z<sub>1</sub>, Z<sub>2</sub>]分别为三个坐标方向上的大豆冠层阈值范围。则每一单盆大豆的株高h为</p>
                </div>
                <div class="area_img" id="66">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="67">式中:z<sub>max</sub>为z轴方向最大值;z<sub>min</sub>为z轴方向最小值。</p>
                </div>
                <div class="p1">
                    <p id="68">对单盆株高的计算总共进行了90次, 求解平均值并将其作为最终株高值。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">4.2 群体大豆株高计算</h4>
                <div class="p1">
                    <p id="70">为实现高通量大豆株高计算, 开展了群体的大豆株高计算方法研究。群体数据采集实验场景如图7所示。利用搭建的采集平台获取了大豆生长生殖过程中出枝期、开花期、结痂期和鼓粒期4个时期的彩色图像和深度图像, 利用单盆大豆的处理方法, 重建了具有颜色信息的群体大豆冠层三维结构形态, 并有效地提取了大豆冠层区域, 用于开展基于群体的大豆株高计算方法研究。大豆生长茂密时期植株叶片会出现遮挡现象, 因此需要对相机安装高度和群体大豆植株摆放的盆间距做出动态调整。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 单盆大豆冠层三维图像采集方法" src="Detail/GetImg?filename=images/GXXB201905032_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 单盆大豆冠层三维图像采集方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 3Dimage acquisition of individual soybean canopy</p>

                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 群体大豆株高计算方法" src="Detail/GetImg?filename=images/GXXB201905032_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 群体大豆株高计算方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Calculation method of plant height for grouped soybean plants</p>

                </div>
                <div class="p1">
                    <p id="73">群体大豆株高的计算方法如图7所示。其中H为Kinect相机安装位置距离地面的高度;h<sub>p</sub>为盆高 (h<sub>p</sub>=0.18m) ;d为两植株中心点投影到地面的距离 (图8) ;S为Kinect相机距离群体大豆中任意一盆大豆植株中心点顶端间的距离;h<sub>a</sub>为除去大豆冠层的地面部分 (包括地面和盆) 相机距离大豆冠层的距离;θ为相机扫描点与地面的水平夹角。含下标1的参数 (S<sub>1</sub>、θ<sub>1</sub>、h<sub>a1</sub>和h<sub>1</sub>) 表示最左侧一盆大豆的计算参数, 含下标2的参数 (S<sub>2</sub>、θ<sub>2</sub>、h<sub>a2</sub>和h<sub>2</sub>) 表示左侧第二盆大豆的计算参数。根据测量Kinect相机距离地面的高度确定点C (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) , 通过设定群体中每盆大豆冠层区域的范围来确定每盆大豆冠层顶端最高点三维坐标A (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) , 计算得到点C与点A之间的距离为</p>
                </div>
                <div class="area_img" id="74">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 盆间距示意图" src="Detail/GetImg?filename=images/GXXB201905032_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 盆间距示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Schematic of spacing between pots</p>

                </div>
                <div class="p1">
                    <p id="76">根据三角模型距离计算原理计算得到相机距离大豆冠层的距离为</p>
                </div>
                <div class="area_img" id="77">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="78">其中:</p>
                </div>
                <div class="area_img" id="79">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="80">从而得到群体图像中每盆大豆植株的株高为</p>
                </div>
                <div class="area_img" id="81">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905032_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="82" name="82" class="anchor-tag">5 大豆株高计算方法有效性验证</h3>
                <h4 class="anchor-tag" id="83" name="83">5.1 大豆冠层三维重建效果</h4>
                <div class="p1">
                    <p id="84">在标定彩色图像和红外图像的基础上, 遍历深度图像的所有三维点云, 根据求解得到的旋转矩阵和平移矢量, 将彩色图像坐标系转换到深度图像坐标系, 即将颜色信息赋值于对应的点云, 构建具有颜色信息的大豆冠层三维结构形态。</p>
                </div>
                <div class="p1">
                    <p id="85">为清晰观察到大豆植株三维重建效果, 在此以2018年7月19日获取的15盆大豆 (三个品种) 的冠层彩色和点云数据为例, 构建其三维结构形态, 三维重建效果如图9所示。图9 (a) 为逐一获取15盆大豆冠层数据后, 对其结构形态进行重建的单盆重建图;图9 (b) 为大豆冠层结构形态的群体重建图。从重建效果上看, 由于单盆拍摄时不存在冠层相互遮挡, 因此冠层重建更加完整。从重建时间上看, 重建单盆大豆三维结构形态需要0.587449s, 而群体重建15盆大豆需要1.312698s。因此, 所建立的采集平台及三维重建方法适用于重建大豆冠层三维结构形态的重建。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 2018年7月19日获得的大豆冠层三维重建效果。 (a) 单盆重建; (b) 群体重建" src="Detail/GetImg?filename=images/GXXB201905032_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 2018年7月19日获得的大豆冠层三维重建效果。 (a) 单盆重建; (b) 群体重建  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 3Dreconstruction effect of soybean canopy on July19, 2018. (a) 3D reconstruction of individual soybean plant; (b) 3Dreconstruction of grouped soybean plants</p>

                </div>
                <div class="p1">
                    <p id="87">重建采集的所有单盆大豆冠层图像, 三维重建的大豆冠层能够反映生殖生长期的大豆冠层生长状态的动态变化, 且重建后的冠层点云包含颜色信息, 通过提供连续的数据记录能较为真实地还原植株形态和生长状态<citation id="182" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>。以大豆9-5号为例, 其2018年6月19日 (0619) —2018年9月5日 (0905) 生殖生长期的冠层重建效果如图10所示。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">5.2 大豆株高计算值比较结果</h4>
                <div class="p1">
                    <p id="89">以重建大豆冠层点云为研究目的, 对大豆株高进行计算。分别对2018年6月6日—2018年7月19日的三个品种大豆植株冠层采用了单盆大豆株高测量方法, 计算值与实测值的平均误差为0.14cm (图11) 。对2018年7月27日—2018年9月5日的大豆植株冠层采用了群体大豆株高测量方法, 计算值与实测值的平均误差为0.54cm。单盆大豆图片清晰, 植株间无遮挡, 冠层信息完整, 但进行高吞吐量的株高计算的时间较慢, 如15个单盆大豆株高所需的计算时间约为1.223895s。而群体大豆株高测量方法可同时计算15盆大豆株高, 所需的计算时间约为0.798435s。</p>
                </div>
                <div class="p1">
                    <p id="90">每种样本总数为60盆。在群体采集方式下, 分别针对抗线9号、抗线13号和富豆6号三个品种进行株高计算, 计算值与实测值的相关系数R<sup>2</sup>分别为0.9717, 0.9730, 0.9697。实验结果表明, 在自然环境下基于深度信息的大豆株高测量方法能准确地进行高通量株高计算。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 0 大豆9-5号的2018年6月19日 (0619) —2018年9月5日 (0905) 生殖生长期的冠层3D重建效果" src="Detail/GetImg?filename=images/GXXB201905032_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 0 大豆9-5号的2018年6月19日 (0619) —2018年9月5日 (0905) 生殖生长期的冠层3D重建效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 3D reconstruction of 9-5 soybean canopy in reproductive period from June 19, 2018 (0619) to September 5, 2018 (0905) </p>

                </div>
                <div class="p1">
                    <p id="92">在大豆生长末期, 大豆株高的实测值与计算值均约为50cm。基于时间序列的三个品种大豆株高的动态变化如图12所示。随着大豆生长时期的变化, 观察到结痂期 (2018年8月19日) 叶片开始变黄脱落, 大豆株高的变化呈下降趋势。结合具有颜色信息的重建效果可见, 花期大豆植株长势增快、颜色青翠、叶片挺立, 但分枝增多、植株间叶片遮挡严重<citation id="183" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>, 且叶位不易确定等导致点云数据缺失, 这是影响计算精确度的主要因素。</p>
                </div>
                <div class="p1">
                    <p id="93">由图12可知, 计算值的动态变化相比实测值较平稳。但2018年8月19日的计算值与测量值误差较大。造成该测量误差的原因主要有:1) 实验仪器测量与人工测量并未在同一天进行, 两日自然天气相差较大;2) 大风、突然降雨和作物自身水分变化情况等因素极易导致大豆冠层叶片萎蔫不够坚挺, 使误差增大;3) 地面局部不平坦和人为操控实验仪器导致测量系统并非是水平的<citation id="184" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>。因此, 在晴朗无风且地面水平环境下采集大豆冠层彩色及深度数据, 能够获得更为精确的株高计算值。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag">6 结论</h3>
                <div class="p1">
                    <p id="95">在自然环境下, 利用所设计的大豆冠层图像同步采集系统, 采集了抗线9号、抗线13号以及富豆6号三个寒地大豆品种的生殖时期冠层彩色图像和深度图像数据, 标定了彩色相机和深度相机, 重建了以大豆生长时间为序列的发芽期、出枝期、开花期、结痂期和鼓粒期5个阶段的具有颜色信息的大豆冠层三维结构形态。在此三维重建的基础上, 计算得到的单盆和群体大豆株高平均误差分别为0.14cm和0.54cm。抗线9号、抗线13号和富豆6号的株高计算值与人工测量值的决定系数分别为0.9717, 0.9730, 0.9697。该研究成果为高通量计算农作物的其他表型参数提供了一种现实可行的数据获取手段。在未来工作中, 将继续利用该采集平台及技术探索大豆植株其他重要的表型特征 (如茎粗、冠幅和分枝角度等) 的计算方法, 为进一步实现大豆植株表型参数的高通量计算提供前期技术基础。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 1 三个品种大豆株高的测量值与计算值的比较。 (a) 抗线9号的对比结果; (b) 抗线13号的对比结果; (c) 富豆6号的对比结果" src="Detail/GetImg?filename=images/GXXB201905032_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 1 三个品种大豆株高的测量值与计算值的比较。 (a) 抗线9号的对比结果; (b) 抗线13号的对比结果; (c) 富豆6号的对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Comparison of manual measurement values and sensor measurement values of plant height for three soybean varieties. (a) Comparison result of Kangxian-9; (b) comparison result of Kangxian-13; (c) comparison result of Fudou-6</p>

                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 2 基于时间序列的三个品种大豆株高动态变化图" src="Detail/GetImg?filename=images/GXXB201905032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 2 基于时间序列的三个品种大豆株高动态变化图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.12 Dynamic change of mean value of plant height for three soybean varieties based on time sequence</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="101">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D maize plant reconstruction based on georeferenced overlapping LiDAR point clouds">

                                <b>[1]</b>Garrido M, Paraforos D S, Reiser D, et al.3D Maize plant reconstruction based on georeferenced overlapping LiDAR point clouds[J].Remote Sensing, 2015, 7 (12) :17077-17096.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD2CD2E9E1605897E44C9F1B6C9258B39&amp;v=MTAwMThoaHdMbTh3S2c9TmlmT2ZjZTZiYVhPMm9Zd1plMFBDWFF3eUdNWDdreDBQbjZRcW1FOGU3ZWNON21XQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Lipka A E, Kandianis C B, Hudson M E, et al.From association to prediction:statistical methods for the dissection and selection of complex traits in plants[J].Current Opinion in Plant Biology, 2015, 24:110-118.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDE2009204D066E6468EBAB05B788FE94B&amp;v=MTQzNTVjYXNhNkh0SEZyWTlCRU9zSkNnay95eEFibjAwTU9uL24zaFU5Y2NUaFRMN3RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh3TG04d0tnPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Haughton A J, Bohan D A, Clark S J, et al.Dedicated biomass crops can enhance biodiversity in the arable landscape[J].Global Change Biology Bioenergy, 2016, 8 (6) :1071-1081.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201705045&amp;v=Mjg3MDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUx6N0JiYkc0SDliTXFvOUJZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Song Q P, Tang J L, Xin J.3-dimensional reconstruction for soybean plant of seedling stage based on growth model[J].Computer Engineering, 2017, 43 (5) :275-280.宋祺鹏, 唐晶磊, 辛菁.基于生长模型的苗期大豆植株三维重建[J].计算机工程, 2017, 43 (5) :275-280.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-Throughput Plant Phenotyping Platforms">

                                <b>[5]</b>Pratap A, Tomar R, Kumar J, et al.High-throughput plant phenotyping platforms[J].Phenomics in Crop Plants:Trends Options and Limitations, 2015:285-296.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4C267E23F65A38B1D77A20632BD36329&amp;v=MjcyNzNiR1NScmlXQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhod0xtOHdLZz1OaWZPZmJmTEhOZkwybzFHRXUwS2ZYOHh2UmRuN1RnTVNuL2tyeEJIRA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>Barker III J, Zhang N Q, Sharon J, et al.Development of a field-based high-throughput mobile phenotyping platform[J].Computers and Electronics in Agriculture, 2016, 122:74-85.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Agronomic field trait phenomics">

                                <b>[7]</b>Palanichamy D, Cobb J N.Agronomic field trait phenomics[M].New York:Springer, 2015:83-99.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJTB201605019&amp;v=MTA3NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lMaWZmYkxHNEg5Zk1xbzlFYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Li H.3D reconstruction of maize leaves based on virtual visual technology[J].Bulletin of Science and Technology, 2016, 32 (5) :96-101.李辉.基于虚拟双目视觉的玉米叶片三维重建方法[J].科技通报, 2016, 32 (5) :96-101.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201804031&amp;v=MjM1NjllVnVGeXprVUwvSUt5ZlNaTEc0SDluTXE0OUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Li S H, Guan H O, Yu S, et al.Whole 3Dreconstruction based on fast SCAN corn and parameter calculation method[J].Journal of Agricultural Mechanization Research, 2018, 40 (4) :162-166.李抒昊, 关海鸥, 于崧, 等.基于FastSCAN玉米整株三维重构及参数计算方法[J].农机化研究, 2018, 40 (4) :162-166.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201504017&amp;v=MTU5NDllVnVGeXprVUwvSUt5ZlNaTEc0SDlUTXE0OUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Jiang P, Geng N.Crop height non-destructive remote measurement based on IP camera[J].Journal of Agricultural Mechanization Research, 2015, 37 (4) :68-72.蒋普, 耿楠.基于网络摄像机的株高远程无损测量系统[J].农机化研究, 2015, 37 (4) :68-72.
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201712058&amp;v=MDQzMDRSTE9lWmVWdUZ5emtVTC9JTHlyUFpMRzRIOWJOclk5QWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Li Q, Cheng X J, Tian R, et al.Correction and normalization of multi-scan terrestrial three-dimensional laser scanning intensity[J].Laser&amp;Optoelectronics Progress, 2017, 54 (12) :122802.李泉, 程效军, 田芮, 等.多站地面三维激光扫描强度数据纠正与归一化[J].激光与光电子学进展, 2017, 54 (12) :122802.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201805036&amp;v=MTgxOTNvOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUx5ZlJkTEc0SDluTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Xiao Y, Hu S X, Xiao S, et al.A fast statistical method of tree information from 3D laser point clouds[J].Chinese Journal of Lasers, 2018, 45 (5) :0510007.肖杨, 胡少兴, 肖深, 等.从三维激光点云中快速统计树木信息的方法[J].中国激光, 2018, 45 (5) :0510007.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201506038&amp;v=MDM3NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JS3pUQmRyRzRIOVRNcVk5R2JJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Ma X D, Guo C L, Zhang X, et al.Calculation of light distribution of apple tree canopy based on color characteristics of 3Dpoint cloud[J].Transactions of the Chinese Society for Agricultural Machinery, 2015, 46 (6) :263-268.马晓丹, 郭彩玲, 张雪, 等.基于三维点云颜色特征的苹果树冠层光照分布计算方法[J].农业机械学报, 2015, 46 (6) :263-268.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201612036&amp;v=MjQwMzR6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUlqaktZTEc0SDlmTnJZOUdZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Ma X D, Guo C L, Zhang X, et al.Calculation of chlorophyll fluorescence characters in different light area to apple tree canopy[J].Spectroscopy and Spectral Analysis, 2016, 36 (12) :3986-3990.马晓丹, 郭彩玲, 张雪, 等.苹果树冠层不同光照区域叶绿素荧光性状计算方法[J].光谱学与光谱分析, 2016, 36 (12) :3986-3990.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High throughput phenotyping of cotton plant height using depth images under field conditions">

                                <b>[15]</b>Jiang Y, Li C Y, Paterson A H.High throughput phenotyping of cotton plant height using depth images under field conditions[J].Computers and Electronics in Agriculture, 2016, 130:57-68.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Prediction of chlorophyll content in different light areas of apple tree canopies based on the color characteristics of 3Dreconstruction">

                                <b>[16]</b>Ma X D, Feng J R, Guan H O, et al.Prediction of chlorophyll content in different light areas of apple tree canopies based on the color characteristics of 3Dreconstruction[J].Remote Sensing, 2018, 10 (3) :429.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Methods for detection of objects in agriculture,Prague">

                                <b>[17]</b>Skerik F, Volf J, Linda M, et al.Methods for detection of objects in agriculture, Prague[C]∥Conference Proceeding-5th International Conference, TAE 2013:Trends in Agricultural Engineering, September 3-6, 2013.Czech University of Life Sciences Prague, 2013, 599-601.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Measurement of growth information of a strawberry plantusing a natural interaction device">

                                <b>[18]</b>Yamamoto S, Hayashi S, Saito S, et al.Measurement of growth information of a strawberry plantusing a natural interaction device[C]∥2012Dallas, Texas, July 29-August 1, 2012.American Society of Agricultural and Biological Engineers, 2012:121341108.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201805023&amp;v=MDM5NjNNZTdHNEg5bk1xbzlIWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lLelQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Shen Y, Zhu J H, Liu H, et al.Plant image mosaic based on depth and color dual information feature source from Kinect[J].Transactions of the Chinese Society of Agricultural Engineering, 2018, 34 (5) :176-182.沈跃, 朱嘉慧, 刘慧, 等.基于深度和彩色双信息特征源的Kinect植物图像拼接[J].农业工程学报, 2018, 34 (5) :176-182.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGYW201803005&amp;v=MTA1MTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSVB5clNlYkc0SDluTXJJOUZZWVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Liu M, Bu W Z, Yang W Y, et al.Correlation analysis of yield and agronomic traits of soybean for intercropping in Shangdong[J].Chinese Journal of Oil Crop Sciences, 2018, 40 (3) :344-351.刘明, 卜伟召, 杨文钰, 等.山东间作大豆产量与主要农艺性状关联分析[J].中国油料作物学报, 2018, 40 (3) :344-351.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201704021&amp;v=Mjc1ODBGckNVUkxPZVplVnVGeXprVUwvSUt6VEJkckc0SDliTXE0OUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Liu G, Zhang X, Zong Z, et al.3Dreconstruction of strawberry based on depth information[J].Transactions of the Chinese Society for Agricultural Machinery, 2017, 48 (4) :160-165, 172.刘刚, 张雪, 宗泽, 等.基于深度信息的草莓三维重建技术[J].农业机械学报, 2017, 48 (4) :160-165, 172.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYJ201511049&amp;v=MjU5MzJybzlCYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lLeWZTWkxHNEg5VE4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Yu X L, Wang D D, Niu L L, et al.The applications and research progress of kinect in the information field of modern agriculturae[J].Journal of Agricultural Mechanization Research, 2015, 37 (11) :216-221.余秀丽, 王丹丹, 牛磊磊, 等.Kinect在现代农业信息领域中的应用与研究进展[J].农机化研究, 2015, 37 (11) :216-221.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201411005&amp;v=MDkyOTgvSVB5cmZiTEc0SDlYTnJvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Guo L P, Chen X N, Liu B.Calibration of Kinect sensor with depth and color camera[J].Journal of Image and Graphics, 2014, 19 (11) :1584-1590.郭连朋, 陈向宁, 刘彬.Kinect传感器的彩色和深度相机标定[J].中国图象图形学报, 2014, 19 (11) :1584-1590.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015437326.nh&amp;v=MjEzOTMzenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0lWRjI2RzdlN0dkTE9xWkViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Li Y N.Research on calibration algorithm of Kinect depth camera[D].Xi′an:Xidian University, 2014.李雅娜.Kinect深度相机标定算法研究[D].西安:西安电子科技大学, 2014.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705024&amp;v=MjkzMjhaZVZ1Rnl6a1VML0lJalhUYkxHNEg5Yk1xbzlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b>Wang S, Xu X.3Dreconstruction based on horopter[J].Acta Optica Sinica, 2017, 37 (5) :0515004.王珊, 徐晓.基于双目单视面的三维重建[J].光学学报, 2017, 37 (5) :0515004.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201412028&amp;v=MzEzMDZPZVplVnVGeXprVUwvSUlqWFRiTEc0SDlYTnJZOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b>Zhou W, Ma X D, Zhang L J, et al.Three dimensional point cloud splicing of tree canopy based on multi-source camera[J].Acta Optica Sinica, 2014, 34 (12) :1215003.周薇, 马晓丹, 张丽娇, 等.基于多源信息融合的果树冠层三维点云拼接方法研究[J].光学学报, 2014, 34 (12) :1215003.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=EZDX201801035&amp;v=MTMzNTR6cXFCdEdGckNVUkxPZVplVnVGeXprVUwvSUlEZlBkckc0SDluTXJvOUdZWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b>Wang M B.Study on three-dimensional reconstruction of crop plants based on point cloud[J].Journal of Ezhou University, 2018, 25 (1) :104-106, 109.王孟博.基于点云的作物植株三维重建技术研究[J].鄂州大学学报, 2018, 25 (1) :104-106, 109.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_28" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJDK201412029&amp;v=MjE5NjhIOVhOclk5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVTC9JTnlmUFpiRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[28]</b>Li X Q.Research on image threshold segmentation algorithm based on Matlab[J].Software Guide, 2014, 13 (12) :76-78.李小琦.基于Matlab的图像阈值分割算法研究[J].软件导刊, 2014, 13 (12) :76-78.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Threedimensional reconstruction of soybean canopies using multisource imaging for phenotyping analysis">

                                <b>[29]</b>Guan H O, Liu M, Ma X D, et al.Threedimensional reconstruction of soybean canopies using multisource imaging for phenotyping analysis[J].Remote Sensing, 2018, 10 (8) :1206.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_30" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201805030&amp;v=MzE2NzdML0lLelRCZHJHNEg5bk1xbzlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[30]</b>Zhu B L, Liu F S, Zhu J Y, et al.Three-dimensional quantifications of plant growth dynamics in fieldgrown plants based on machine vision method[J].Transactions of the Chinese Society for Agricultural Machinery, 2018, 49 (5) :256-262.朱冰琳, 刘扶桑, 朱晋宇, 等.基于机器视觉的大田植株生长动态三维定量化研究[J].农业机械学报, 2018, 49 (5) :256-262.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards 4Dcrop analysis in precision agriculture:estimating plant height and crown radius over time via expectationmaximization">

                                <b>[31]</b>Carlone L, Dong J, Fenu S, et al.Towards 4Dcrop analysis in precision agriculture:estimating plant height and crown radius over time via expectationmaximization[C]∥IEEE ICRA Workshop on Robotics in Agriculture, May 26-30, 2015Seattle, WA, USA, 2015.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905032" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905032&amp;v=MjU0MTA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1VML0pJalhUYkxHNEg5ak1xbzlHWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

