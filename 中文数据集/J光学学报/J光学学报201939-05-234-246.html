

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134012776533750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905030%26RESULT%3d1%26SIGN%3dL8ZLL3v%252beuClVptYK4CxQzrJ3Uo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905030&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905030&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905030&amp;v=MTMwMzVHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3L1BJalhUYkxHNEg5ak1xbzk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#5" data-title="2 基于多摄像头的人体识别定位的原理和关键技术 ">2 基于多摄像头的人体识别定位的原理和关键技术</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#9" data-title="2.1 人体皮肤表面“振动信号”在多摄像头下的差异性和同步性">2.1 人体皮肤表面“振动信号”在多摄像头下的差异性和同步性</a></li>
                                                <li><a href="#24" data-title="2.2 多摄像头下的人体皮肤表面“振动信号”获取">2.2 多摄像头下的人体皮肤表面“振动信号”获取</a></li>
                                                <li><a href="#33" data-title="2.3 多摄像头人体识别">2.3 多摄像头人体识别</a></li>
                                                <li><a href="#39" data-title="2.4 多摄像头人体定位">2.4 多摄像头人体定位</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="3 基于多摄像头的人体识别定位的实现 ">3 基于多摄像头的人体识别定位的实现</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="3.1 人体皮肤表面“振动信号”的相似度比对及归一化">3.1 人体皮肤表面“振动信号”的相似度比对及归一化</a></li>
                                                <li><a href="#64" data-title="3.2 人体识别与定位实现">3.2 人体识别与定位实现</a></li>
                                                <li><a href="#68" data-title="3.3 多个人体的识别与定位">3.3 多个人体的识别与定位</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="4 与一般人体识别定位的比较 ">4 与一般人体识别定位的比较</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#92" data-title="5 结论 ">5 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#7" data-title="图1 基于皮肤表面“振动信号”的多个人体多摄像头识别和定位的场景示意图">图1 基于皮肤表面“振动信号”的多个人体多摄像头识别和定位的场景示意图</a></li>
                                                <li><a href="#8" data-title="表1 多摄像头人体识别定位方法对比">表1 多摄像头人体识别定位方法对比</a></li>
                                                <li><a href="#14" data-title="图2 人体皮肤表面“振动信号”的差异性和同步性原理推导">图2 人体皮肤表面“振动信号”的差异性和同步性原理推导</a></li>
                                                <li><a href="#18" data-title="图3 同步性及差异性验证。 (a) 实验场景1; (b) 实验场景2; (c) 同一摄像头下同一对象不同皮肤区域的IPPG信号获取个例; (d) 同一摄像头下不同对象不同皮肤区域的IPPG信号获取">图3 同步性及差异性验证。 (a) 实验场景1; (b) 实验场景2; (c) 同一摄像头下同一对象......</a></li>
                                                <li><a href="#22" data-title="图4 多摄像头下不同对象同一皮肤区域的IPPG信号获取">图4 多摄像头下不同对象同一皮肤区域的IPPG信号获取</a></li>
                                                <li><a href="#27" data-title="图5 基于多摄像头的人体识别定位系统流程图">图5 基于多摄像头的人体识别定位系统流程图</a></li>
                                                <li><a href="#28" data-title="图6 人体皮肤表面“振动信号”获取">图6 人体皮肤表面“振动信号”获取</a></li>
                                                <li><a href="#42" data-title="图7 三摄像头定位。 (a) 实验场景俯视图; (b) 定位原理图">图7 三摄像头定位。 (a) 实验场景俯视图; (b) 定位原理图</a></li>
                                                <li><a href="#58" data-title="图8 三摄像头采集视频中的一帧及跟踪的皮肤区域">图8 三摄像头采集视频中的一帧及跟踪的皮肤区域</a></li>
                                                <li><a href="#59" data-title="图9 摄像头3获取的IPPG信号">图9 摄像头3获取的IPPG信号</a></li>
                                                <li><a href="#60" data-title="表2 摄像头3获取的IPPG信号的相似度">表2 摄像头3获取的IPPG信号的相似度</a></li>
                                                <li><a href="#61" data-title="表3 摄像头2、3获取的IPPG信号的相似度">表3 摄像头2、3获取的IPPG信号的相似度</a></li>
                                                <li><a href="#62" data-title="图1 0 摄像头2、3获取的IPPG信号">图1 0 摄像头2、3获取的IPPG信号</a></li>
                                                <li><a href="#70" data-title="图1 1 对象A、B的多个坐标计算结果">图1 1 对象A、B的多个坐标计算结果</a></li>
                                                <li><a href="#74" data-title="图1 2 5个对象的三摄像头识别与定位实验场景。 (a) 多对象识别与定位实验场景; (b) 场景俯视图; (c) 三摄像头采集视频中的一帧及皮肤区域">图1 2 5个对象的三摄像头识别与定位实验场景。 (a) 多对象识别与定位实验场景; (b) 场景俯......</a></li>
                                                <li><a href="#76" data-title="表4 相似度比对和归一化的分类结果">表4 相似度比对和归一化的分类结果</a></li>
                                                <li><a href="#77" data-title="表5 相似度比对和归一化分类结果的精确率与召回率">表5 相似度比对和归一化分类结果的精确率与召回率</a></li>
                                                <li><a href="#81" data-title="图1 3 摄像头的精度区域分布示意图">图1 3 摄像头的精度区域分布示意图</a></li>
                                                <li><a href="#85" data-title="图1 4 5个对象的坐标计算结果">图1 4 5个对象的坐标计算结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="94">


                                    <a id="bibliography_1" title="Haritaoglu I, Harwood D, Davis L S.W4S:A realtime system for detecting and tracking people in 21/2D[M]∥Burkhardt H, Neumann B.eds.Computer Vision-ECCV’98.Lecture Notes in Computer Science, Berlin, Heidelberg:Springer, 1998:877-892." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=W4S:A Real-Time System for Detecting and Tracking People in 2 1/2D">
                                        <b>[1]</b>
                                        Haritaoglu I, Harwood D, Davis L S.W4S:A realtime system for detecting and tracking people in 21/2D[M]∥Burkhardt H, Neumann B.eds.Computer Vision-ECCV’98.Lecture Notes in Computer Science, Berlin, Heidelberg:Springer, 1998:877-892.
                                    </a>
                                </li>
                                <li id="96">


                                    <a id="bibliography_2" title="Huang K Q, Chen X T, Kang Y F, et al.Intelligent visual surveillance:a review[J].Chinese Journal of Computers, 2015, 38 (6) :1093-1118.黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 38 (6) :1093-1118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201506001&amp;v=MzExNzMzenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3L1BMejdCZHJHNEg5VE1xWTlGWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Huang K Q, Chen X T, Kang Y F, et al.Intelligent visual surveillance:a review[J].Chinese Journal of Computers, 2015, 38 (6) :1093-1118.黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 38 (6) :1093-1118.
                                    </a>
                                </li>
                                <li id="98">


                                    <a id="bibliography_3" title="Thakkar D.Top five biometrics:face, fingerprint, iris, palm and voice[EB/OL].[2018-04-10].https:∥www.bayometric.com/biometrics-face-finger-iris-palmvoice/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Top five biometrics:face,fingerprint,iris,palm and voice">
                                        <b>[3]</b>
                                        Thakkar D.Top five biometrics:face, fingerprint, iris, palm and voice[EB/OL].[2018-04-10].https:∥www.bayometric.com/biometrics-face-finger-iris-palmvoice/.
                                    </a>
                                </li>
                                <li id="100">


                                    <a id="bibliography_4" title="Ding C X, Tao D C.A comprehensive survey on poseinvariant face recognition[J].ACM Transactions on Intelligent Systems and Technology, 2016, 7 (3) :1-42." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM1F3A3B80A2F32CC6AA53236843DD6AEC&amp;v=MTk5NDJPR1FsZkNwYlEzNWRoaHdMbS93Szg9TmlmSVk3TE9IYURQM1lkRkZlbDVEMzVLdkJCaW16cCtTbnprcEJZMkRjYVNOTS9zQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Ding C X, Tao D C.A comprehensive survey on poseinvariant face recognition[J].ACM Transactions on Intelligent Systems and Technology, 2016, 7 (3) :1-42.
                                    </a>
                                </li>
                                <li id="102">


                                    <a id="bibliography_5" title="Haghighat M, Abdel-Mottaleb M.Low resolution face recognition in surveillance systems using discriminant correlation analysis[C]∥2017 12th IEEE International Conference on Automatic Face&amp;amp;Gesture Recognition (FG 2017) , May 30-June 3, 2017, Washington, D C, USA.New York:IEEE, 2017:912-917." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low resolution face recognition in surveillance systems using discriminant correlation analysis">
                                        <b>[5]</b>
                                        Haghighat M, Abdel-Mottaleb M.Low resolution face recognition in surveillance systems using discriminant correlation analysis[C]∥2017 12th IEEE International Conference on Automatic Face&amp;amp;Gesture Recognition (FG 2017) , May 30-June 3, 2017, Washington, D C, USA.New York:IEEE, 2017:912-917.
                                    </a>
                                </li>
                                <li id="104">


                                    <a id="bibliography_6" title="Linn J, Duane W M, Dotan Y, et al.Controlling access to a computerized resource based on authentication using pulse data:U.S.Patent 8, 902, 045[P].2014-12-2." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Controlling access to a computerized resource based on authentication using pulse data">
                                        <b>[6]</b>
                                        Linn J, Duane W M, Dotan Y, et al.Controlling access to a computerized resource based on authentication using pulse data:U.S.Patent 8, 902, 045[P].2014-12-2.
                                    </a>
                                </li>
                                <li id="106">


                                    <a id="bibliography_7" title="Shi W S, Gao W R, Chen C L.Handheld swept source optical coherence tomography for imaging human skin in vivo[J].Acta Optica Sinica, 2015, 35 (11) :1117001.史伟松, 高万荣, 陈朝良.人体皮肤在体手持式扫频光学相干层析系统[J].光学学报, 2015, 35 (11) :1117001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201511031&amp;v=MjkzNTVHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3L1BJalhUYkxHNEg5VE5ybzk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Shi W S, Gao W R, Chen C L.Handheld swept source optical coherence tomography for imaging human skin in vivo[J].Acta Optica Sinica, 2015, 35 (11) :1117001.史伟松, 高万荣, 陈朝良.人体皮肤在体手持式扫频光学相干层析系统[J].光学学报, 2015, 35 (11) :1117001.
                                    </a>
                                </li>
                                <li id="108">


                                    <a id="bibliography_8" title="Chen Z Y, Shao X X, Wu J L, et al.Full-field deformation measurement of human carotid artery based on water transfer printing speckle patterns[J].Acta Optica Sinica, 2017, 37 (3) :0312004.陈振宁, 邵新星, 吴家林, 等.水转印数字散斑场用于人体颈动脉全场测量[J].光学学报, 2017, 37 (3) :0312004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201703028&amp;v=MDM5MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVNy9QSWpYVGJMRzRIOWJNckk5SGJJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Chen Z Y, Shao X X, Wu J L, et al.Full-field deformation measurement of human carotid artery based on water transfer printing speckle patterns[J].Acta Optica Sinica, 2017, 37 (3) :0312004.陈振宁, 邵新星, 吴家林, 等.水转印数字散斑场用于人体颈动脉全场测量[J].光学学报, 2017, 37 (3) :0312004.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_9" title="Shelley K H, Shelley S.Pulse Oximeter Waveform:photoelectric plethysmography[M]∥Lake C, Hines R, Blitt C.Eds.Clinical Monitoring.Philadelphia:W.B.Saunders Company, 2001:420-423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pulse Oximeter Waveform:Photoelectric Plethysmography">
                                        <b>[9]</b>
                                        Shelley K H, Shelley S.Pulse Oximeter Waveform:photoelectric plethysmography[M]∥Lake C, Hines R, Blitt C.Eds.Clinical Monitoring.Philadelphia:W.B.Saunders Company, 2001:420-423.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_10" title="Verkruysse W, Svaasand L O, Nelson J S.Remote plethysmographic imaging using ambient light[J].Optics Express, 2008, 16 (26) :21434-21445." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote plethysmographic imaging using ambient light">
                                        <b>[10]</b>
                                        Verkruysse W, Svaasand L O, Nelson J S.Remote plethysmographic imaging using ambient light[J].Optics Express, 2008, 16 (26) :21434-21445.
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_11" title="Wu T, Blazek V, Schmitt H J.Photoplethysmography imaging:a new noninvasive and noncontact method for mapping of the dermal perfusion changes[J].Proceedings of SPIE, 2000, 4163:62-71." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Photoplethysmography imaging:a new noninvasive and noncontact method for mapping of the dermal perfusion changes">
                                        <b>[11]</b>
                                        Wu T, Blazek V, Schmitt H J.Photoplethysmography imaging:a new noninvasive and noncontact method for mapping of the dermal perfusion changes[J].Proceedings of SPIE, 2000, 4163:62-71.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_12" title="Kong L Q.Research on key techniques of the noncontact detection of physiological signals[D].Beijing:Beijing Institute of Technology, 2014.孔令琴.非接触式生理信号检测关键技术研究[D].北京:北京理工大学, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1014086665.nh&amp;v=MDMzNzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVNy9QVkYyNkdyT3dHTmZLcXBFYlA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Kong L Q.Research on key techniques of the noncontact detection of physiological signals[D].Beijing:Beijing Institute of Technology, 2014.孔令琴.非接触式生理信号检测关键技术研究[D].北京:北京理工大学, 2014.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_13" title="McCombie D B, Shaltis P A, Reisner A T, et al.Adaptive hydrostatic blood pressure calibration:development of a wearable, autonomous pulse wave velocity blood pressure monitor[C]∥29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Aug 22-26, 2007, Lyon, France.New York:IEEE, 2007:370-373." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive hydrostatic blood pressure calibration: development of a wearable, autonomous pulse wave velocity blood pressure monitor">
                                        <b>[13]</b>
                                        McCombie D B, Shaltis P A, Reisner A T, et al.Adaptive hydrostatic blood pressure calibration:development of a wearable, autonomous pulse wave velocity blood pressure monitor[C]∥29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Aug 22-26, 2007, Lyon, France.New York:IEEE, 2007:370-373.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_14" title="Li S L, Li Y B, Li H Y, et al.Non-invasive continuous measurement method of blood pressure based on phase difference of pulse wave[J].Transducer and Microsystem Technologies, 2016, 35 (1) :62-64.李申龙, 李毅彬, 李洪阳, 等.基于脉搏波相位差的无创连续血压测量方法[J].传感器与微系统, 2016, 35 (1) :62-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201601019&amp;v=MzEyNDdlWmVWdUZ5emtVNy9QSmlyYVpMRzRIOWZNcm85RWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Li S L, Li Y B, Li H Y, et al.Non-invasive continuous measurement method of blood pressure based on phase difference of pulse wave[J].Transducer and Microsystem Technologies, 2016, 35 (1) :62-64.李申龙, 李毅彬, 李洪阳, 等.基于脉搏波相位差的无创连续血压测量方法[J].传感器与微系统, 2016, 35 (1) :62-64.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_15" title="Xu W Y, Meng J, Zhao X M.Non-contact monitoring of ambulatory blood pressure based on high speed camera[J].Journal of Zhejiang University (Engineering Science) , 2017, 51 (10) :2077-2083.许文媛, 孟濬, 赵夕朦.基于高速摄像机的动态血压非接触获取[J].浙江大学学报 (工学版) , 2017, 51 (10) :2077-2083." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201710025&amp;v=MDY2OTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVNy9QUHluUmJiRzRIOWJOcjQ5SFlZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Xu W Y, Meng J, Zhao X M.Non-contact monitoring of ambulatory blood pressure based on high speed camera[J].Journal of Zhejiang University (Engineering Science) , 2017, 51 (10) :2077-2083.许文媛, 孟濬, 赵夕朦.基于高速摄像机的动态血压非接触获取[J].浙江大学学报 (工学版) , 2017, 51 (10) :2077-2083.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_16" title="Pal A, Gautam A K, Singh Y N.Evaluation of bioelectric signals for human recognition[J].Procedia Computer Science, 2015, 48:746-752." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES52ED24402FF63131D634513C86EFE5F5&amp;v=MzA1MzhtL3dLOD1OaWZPZmJhNmE2WE9xNHRGWnAxNUNuODR6QmRuN0R4NVRYN2gzeG96RE1UaFFNeWFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh3TA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Pal A, Gautam A K, Singh Y N.Evaluation of bioelectric signals for human recognition[J].Procedia Computer Science, 2015, 48:746-752.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_17" title="Nadzri N I M, Sidek K A, Ismail A F.Biometric recognition for twins inconsideration of age variability using PPG signals[J].Journal of Telecommunication, Electronic and Computer Engineering, 2018, 10 (1/2/3/4/5) :97-100." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Biometric recognition for twins inconsideration of age variability using PPG signals">
                                        <b>[17]</b>
                                        Nadzri N I M, Sidek K A, Ismail A F.Biometric recognition for twins inconsideration of age variability using PPG signals[J].Journal of Telecommunication, Electronic and Computer Engineering, 2018, 10 (1/2/3/4/5) :97-100.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-01-08 10:05</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),234-246 DOI:10.3788/AOS201939.0515001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于皮肤表面“振动信号”的多摄像头人体识别定位</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%9F%E6%BF%AC&amp;code=09380907&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孟濬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E5%A4%95%E6%9C%A6&amp;code=36034285&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵夕朦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B5%99%E6%B1%9F%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0157820&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">浙江大学电气工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出了一种适应场景广泛的基于皮肤表面“振动信号”的多摄像头人体识别定位方法。提出了同一人体皮肤表面“振动信号”在多摄像头下具有同步性而不同人体皮肤表面“振动信号”具有差异性的原理, 并通过实验进行了验证。基于肤色区域跟踪技术, 实现了多摄像头下的人体皮肤表面“振动信号”的获取;基于其差异性和同步性原理及余弦相似度, 实现了人体识别;并通过多摄像头坐标计算实现了多摄像头人体定位, 最大定位距离误差为61.01cm。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%91%84%E5%83%8F%E5%A4%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多摄像头;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E4%BD%93%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人体识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E4%BD%93%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人体定位;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E8%83%BD%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智能视频监控;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E6%8E%A5%E8%A7%A6%E8%84%89%E6%90%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非接触脉搏;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孟濬, E-mail:junmeng@zju.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>浙江省公益性技术应用研究计划 (2017C31079);</span>
                                <span>余姚浙江大学机器人研究院项目 (K11805);</span>
                    </p>
            </div>
                    <h1>Human Body Recognition and Positioning with Multiple Cameras Based on “Vibration Signals” from Skin Surfaces</h1>
                    <h2>
                    <span>Meng Jun</span>
                    <span>Zhao Ximeng</span>
            </h2>
                    <h2>
                    <span>College of Electrical Engineering, Zhejiang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In this study, we propose a method to recognize and position multiple people with multiple cameras based on the“vibration signals”obtained from their skin surfaces to adapt to an extensive range of scenes.Herein, the principles that the“vibration signals”obtained from the same person can be synchronized using multiple cameras and that the“vibration signals”obtained from different people are different are proposed and verified via experiments.The “vibration signals”are obtained from the human skin surfaces using multiple cameras based on skin-color detection and regional tracking.Further, individuals are recognized based on the difference and synchronization principle and the cosine similarity.Several people are positioned with multiple cameras via coordinate calculations, and the maximum positioning distance error is 61.01 cm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multiple%20cameras&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multiple cameras;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=people%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">people recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=people%20positioning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">people positioning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=intelligent%20video%20surveillance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">intelligent video surveillance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-contact%20pulse&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-contact pulse;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">随着计算机视觉的发展, 智能视频监控技术逐渐发展起来, 其中最核心的部分是基于计算机视觉的视频内容理解技术, 回答人们感兴趣的“是谁、在哪、干什么”的问题<citation id="128" type="reference"><link href="94" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。人体的识别与定位就包含了其中的两个问题 (目标是谁和目标在哪) , 因此其成为智能视频监控中很重要的两个环节<citation id="129" type="reference"><link href="96" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="3">在视频监控领域, 常见的人体识别方法主要是通过图像特征进行匹配和定位的人脸识别技术。人脸识别主要运用图像处理, 通过外部面容的不同来对不同的人进行区分。然而人脸识别在实际应用中有一定的局限性, 光线、表情、姿势变化、拍摄角度、遮挡、分辨率等因素都会对面部识别产生影响<citation id="131" type="reference"><link href="98" rel="bibliography" /><link href="100" rel="bibliography" /><link href="102" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 同时人的面部特征很容易被复制或改变。尽管人脸识别技术针对这些问题在算法上的研究越来越多, 也衍生出了其与其他生物特征相结合的优化方法<citation id="130" type="reference"><link href="104" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 但还是存在该技术不能适用的场景。如在个体面部未露出 (一个固定人体目标站在圆心, 同心圆上每隔120°放置一个摄像头, 共三个摄像头) 、面部被遮挡并换装 (嫌犯为了躲避追踪, 采用遮挡面部、与他人交换衣服并保持移动的方法) 、双胞胎同时面对不同摄像头 (双胞胎背靠背站在一起, 两人分别面对一个摄像头) 等场景中, 基于人脸识别的多摄像头人体识别定位体现出一定的劣势。</p>
                </div>
                <div class="p1">
                    <p id="4">针对这些局限, 本文提出一种通过视频提取人体皮肤表面的“振动信号”来识别和定位的方法, 该方法利用的是人体皮肤表面“振动信号”在多摄像头下的差异性和同步性。将这种振动信号作为匹配特征进行人体的识别和定位, 只需要裸露皮肤就能进行定位, 相当于增加了可识别的区域面积, 视角相对较广且难以隐蔽, 降低了对场景的要求, 不会产生根据图像特征进行定位时的盲区问题。同时相较于视频图像数据, 大大减少了数据的传输量问题, 具有较广阔的应用前景。</p>
                </div>
                <h3 id="5" name="5" class="anchor-tag">2 基于多摄像头的人体识别定位的原理和关键技术</h3>
                <div class="p1">
                    <p id="6">基于皮肤表面“振动信号”的多个人体多摄像头识别和定位的场景如图1所示。该“振动信号”是指血液容积随时间的变化引起的皮肤表面光强变化。表1展示了基于人脸识别和基于皮肤表面“振动信号”的多摄像头人体识别定位的方法对比。</p>
                </div>
                <div class="area_img" id="7">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_00700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于皮肤表面“振动信号”的多个人体多摄像头识别和定位的场景示意图" src="Detail/GetImg?filename=images/GXXB201905030_00700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于皮肤表面“振动信号”的多个人体多摄像头识别和定位的场景示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_00700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Illustration of multiple people recognition and positioning with multiple cameras based on“vibration signals”from skin surfaces</p>

                </div>
                <div class="area_img" id="8">
                                            <p class="img_tit">
                                                表1 多摄像头人体识别定位方法对比
                                                    <br />
                                                Table 1 Method comparison for multiple people recognition and positioning with multiple cameras
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_00800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905030_00800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_00800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 多摄像头人体识别定位方法对比" src="Detail/GetImg?filename=images/GXXB201905030_00800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="9" name="9">2.1 人体皮肤表面“振动信号”在多摄像头下的差异性和同步性</h4>
                <div class="p1">
                    <p id="10">基于光学方法对人体生理信号和皮下组织进行分析和测量已经成为一种常见的方法<citation id="136" type="reference"><link href="106" rel="bibliography" /><link href="108" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。光电容积脉搏波描记技术 (Photoplethysmography, PPG) 就是一种通过光学方法获得脉搏信号的方法, 通常是使用脉搏血氧仪照亮皮肤并通过测量光吸收的变化获得<citation id="132" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。PPG通常采用专用的光源 (如红光或红外) , 但是最近的研究表明将正常的环境光作为照明源也可以进行PPG测量<citation id="133" type="reference"><link href="112" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。而成像式光电容积描记技术 (Imaging Photoplethysmography, IPPG) 就是在此基础上发展起来的, 是一种利用成像设备对被测部位进行视频采集, 再通过图像处理提取脉搏波信号, 最后对其进行分析实现生理信号提取的方法<citation id="134" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。IPPG具有成本低、非接触、安全、能够连续测量、操作简单等多种优势, 为非接触式生理信号测量及远程医疗监控的研究提供了一种新的解决途径和方案<citation id="135" type="reference"><link href="116" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="11">对于同一个人来说, 不同部位的皮肤检测出来的脉搏信号具有同步性和相似性。目前一些血压测量方法利用的就是脉搏信号的相似性原理, 通过测量人体不同部位的脉搏信号的相位差来测量血压<citation id="138" type="reference"><link href="118" rel="bibliography" /><link href="120" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。此外, 基于该原理的非接触动态血压测量的方法也被证实有效<citation id="137" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。可见, 同一个人不同区域的皮肤表面脉搏信号的相似性是稳定存在的。</p>
                </div>
                <div class="p1">
                    <p id="12">对于不同人来说, 不同人的脉搏信号具有差异性。脉搏信号是心脏搏动沿动脉血管和血流向外周传播形成的, 是心脏、血管等器官共同作用产生的, 同时也是个体基因决定的, 理论上具有唯一性。而实际上, 不同个体的心电图 (ECG) 具有个体特异性, 利用该特异性进行生物特征识别被证明是可行的<citation id="139" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 信用卡巨头万事达还利用心跳识别技术进行具备支付功能的手环开发。同时, 不同个体的PPG信号也就是脉搏信号的个体特异性研究也已经展开, 为双胞胎识别提供了一种新的思路<citation id="140" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。可见, 不同人的脉搏信号的差异性也是稳定存在的。</p>
                </div>
                <div class="p1">
                    <p id="13">在环境光下通过摄像头获取的人体皮肤表面“振动信号”, 通过绿色通道像素平均的方法获取, 是一种简单的、没有经过过多处理的信号, 反映由血液容积变化引起的光强变化, 同时反映人体的容积脉搏波。</p>
                </div>
                <div class="area_img" id="14">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_01400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 人体皮肤表面“振动信号”的差异性和同步性原理推导" src="Detail/GetImg?filename=images/GXXB201905030_01400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 人体皮肤表面“振动信号”的差异性和同步性原理推导  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_01400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Principle derivation of difference and synchronization of“vibration signals”from skin surfaces</p>

                </div>
                <div class="p1">
                    <p id="15">基于上述理论基础与依据, 以及推导逻辑, 可以得出推论:不同人体的皮肤表面“振动信号” (以下简称为IPPG信号) 在多个摄像头下也应该存在一定的差异性和同步性。理论推导过程如图2所示。下面分两个实验对该原理进行验证。</p>
                </div>
                <div class="p1">
                    <p id="16">1) 同一摄像头下同一人的不同皮肤区域人体皮肤表面“振动信号”的同步性、不同人皮肤区域人体皮肤表面“振动信号”的差异性验证:</p>
                </div>
                <div class="p1">
                    <p id="17">验证实验场景如图3 (a) 所示。在对象1的左右手臂内侧分别标记一块皮肤区域, 将1个摄像头放置于手臂上方进行拍摄。对拍摄得到的视频序列, 在标记区域进行剪裁, 得到2个皮肤区域视频序列, 分别对应2块同一对象的皮肤。通过对皮肤区域视频序列的绿色通道进行像素平均, 得到IPPG信号。将同一对象的左右手臂逐渐拉开距离, 拍摄4段视频, 所得到的左右手臂的IPPG信号均呈现如图3 (c) 所示的同步性。其中, 在对象做完30个蹲起 (after 30pick ups) 心跳加快后, 该同步性依然存在。因此可以初步认为, 同一人的不同皮肤在同一摄像头下所提取的IPPG信号具有高度的同步性。</p>
                </div>
                <div class="area_img" id="18">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_01800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 同步性及差异性验证。 (a) 实验场景1; (b) 实验场景2; (c) 同一摄像头下同一对象不同皮肤区域的IPPG信号获取个例; (d) 同一摄像头下不同对象不同皮肤区域的IPPG信号获取" src="Detail/GetImg?filename=images/GXXB201905030_01800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 同步性及差异性验证。 (a) 实验场景1; (b) 实验场景2; (c) 同一摄像头下同一对象不同皮肤区域的IPPG信号获取个例; (d) 同一摄像头下不同对象不同皮肤区域的IPPG信号获取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_01800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Validation of synchronization and difference. (a) Experimental scene 1; (b) experimental scene 2; (c) example of IPPG signal acquisition for different skin areas of the same object under the same camera; (d) IPPG signal acquisition for different skin areas of different objects under the same camera</p>

                </div>
                <div class="p1">
                    <p id="19">为了排除光线变化等因素的干扰, 针对多个对象进行验证实验。考虑到摄像头可视角的局限, 选取3组对象, 每组4人 (其中相同对象1人) 的手臂同时进行拍摄。实验场景如图3 (b) 所示。每组实验中, 将1个摄像头放置于4双手臂上方进行拍摄, 在每个对象的左右手臂分别标记一块皮肤区域, 并在标记区域对拍摄得到的视频序列进行剪裁, 得到8个皮肤区域视频序列, 通过对皮肤区域视频序列的绿色通道进行像素平均, 得到IPPG信号。3组视频所得到同一对象的左右手臂的IPPG信号均呈现同步性, 且不同对象呈现差异性, 如图3 (d) 所示, 同一摄像头下所得信号的同步性和差异性得以验证。</p>
                </div>
                <div class="p1">
                    <p id="20">2) 三个摄像头下同一人的相同皮肤区域人体皮肤表面“振动信号”的同步性、不同人的皮肤区域人体皮肤表面“振动信号”的差异性验证:</p>
                </div>
                <div class="p1">
                    <p id="21">在对象1、2的手臂内侧分别标记一块皮肤区域, 将3个摄像头放置于手臂同一方向同时进行拍摄。对拍摄得到的视频序列, 在标记区域进行剪裁, 得到6个皮肤区域视频序列, 分别对应3个摄像头和2块不同对象的皮肤。通过对皮肤区域视频序列的绿色通道进行像素平均, 得到IPPG信号。对象2、3和对象3、4以及对象2、4均呈现如图4所示的特点, 不同人皮肤提取的表面“振动信号”具有较高的差异性, 而同一个人的同一块皮肤在三个摄像头下所提取的表面“振动信号”具有高度的同步性。也就是说, 不同摄像头对于所测信号的同步性和差异性没有影响。</p>
                </div>
                <div class="area_img" id="22">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_02200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 多摄像头下不同对象同一皮肤区域的IPPG信号获取" src="Detail/GetImg?filename=images/GXXB201905030_02200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 多摄像头下不同对象同一皮肤区域的IPPG信号获取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_02200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 IPPG signal acquisition for the same skin area of different objects under multiple cameras</p>

                </div>
                <div class="p1">
                    <p id="23">因此, 不同人体的皮肤表面“振动信号”在多个摄像头下存在着一定的差异性和同步性。借助这一原理, 可以将该振动信号作为匹配特征, 在多个摄像头的场景下对多个人体进行识别和定位, 系统流程图如图5所示。</p>
                </div>
                <h4 class="anchor-tag" id="24" name="24">2.2 多摄像头下的人体皮肤表面“振动信号”获取</h4>
                <div class="p1">
                    <p id="25">人体皮肤表面“振动信号”反映在肤色的颜色变化上, 需要对视频序列中的肤色区域进行检测与跟踪, 以提取人体皮肤表面“振动信号”, 如图6所示。具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="26">1) 预处理:为了在视频画面中更准确地检测到肤色区域、排除高分辨率图像带来的干扰, 首先需要对视频进行降低分辨率的预处理操作。图6中, 原尺度的视频每一帧图像大小为1080pixel×1920pixel, 压缩尺度后的视频每一帧图像大小为281pixel×500pixel。</p>
                </div>
                <div class="area_img" id="27">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于多摄像头的人体识别定位系统流程图" src="Detail/GetImg?filename=images/GXXB201905030_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于多摄像头的人体识别定位系统流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Flow chart of human body recognition and positioning system based on multiple cameras</p>

                </div>
                <div class="area_img" id="28">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_02800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 人体皮肤表面“振动信号”获取" src="Detail/GetImg?filename=images/GXXB201905030_02800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 人体皮肤表面“振动信号”获取  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_02800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Acquisition of“vibration signals”from human skin surfaces</p>

                </div>
                <div class="p1">
                    <p id="29">2) 肤色区域检测与跟踪:在压缩尺度后视频的每一帧图像上, 基于YCrCb颜色空间中的Cr分量采用阈值分割的方法进行肤色检测, 并采用连通区域标记的方法有序地标记出图像中的各个皮肤区域, 在整个视频流中进行跟踪。</p>
                </div>
                <div class="p1">
                    <p id="30">3) 平滑处理:考虑到人体在画面中的运动会导致检测出的肤色区域边界的抖动, 从而影响肤色区域的颜色变化, 干扰皮肤表面“振动信号”的提取。在肤色检测后进行各个肤色区域中心坐标的确定, 映射到原尺度的图像后在时间上对中心坐标的抖动进行平滑处理, 以获得视频中各个肤色区域中心较为准确的坐标变化。平滑处理采用的是6阶多项式拟合的方法。</p>
                </div>
                <div class="p1">
                    <p id="31">4) 皮肤区域截取与像素平均:按照平滑处理后的中心坐标在原视频大小上截取各个皮肤区域的视频序列, 并进行绿色通道的像素平均, 得到对应人体皮肤区域的“表面振动”信号也就是IPPG信号。</p>
                </div>
                <div class="p1">
                    <p id="32">同时, 为了降低人体皮肤“振动信号”测量的不确定度, 分别针对以下两方面误差来源采取对应的措施:1) 摄像头自身的误差, 采用相同的监控摄像头进行实验;2) 被测对象的不确定因素, 视频录制时间一般为6～10s, 室内环境光照稳定, 在每帧图像中对一定区域的皮肤进行绿色通道的像素平均来减少光线影响。</p>
                </div>
                <h4 class="anchor-tag" id="33" name="33">2.3 多摄像头人体识别</h4>
                <div class="p1">
                    <p id="34">基于不同人体的IPPG信号在多个摄像头下的差异性和同步性, 对三摄像头拍摄到的多个人体的多块皮肤进行检测, 提取IPPG信号, 进行人体的识别。如果摄像头获取的皮肤区域IPPG信号具有同步性, 那么判断该皮肤区域属于同一人, 反之则属于不同人。</p>
                </div>
                <div class="p1">
                    <p id="35">本文中, 同步性通过信号的相似度进行衡量, 具体采用余弦相似度 (Cosine Similarity) 的方法。余弦相似性通过测量两个非零向量之间的角度的余弦, 来度量的它们的相似性。将两个向量根据坐标绘制到向量空间中, 这两个向量的夹角越小, 余弦值越接近1, 则两个向量的方向更吻合, 则相似。</p>
                </div>
                <div class="p1">
                    <p id="36">已知向量A和向量B, 其余弦相似度cosω的求取公式如下:</p>
                </div>
                <div class="area_img" id="37">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="38">式中, n为向量维数, A<sub>i</sub>、B<sub>i</sub>分别为向量A、B的元素, i为元素序号。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">2.4 多摄像头人体定位</h4>
                <div class="p1">
                    <p id="40">搭建三摄像头场景, 如图7 (a) 所示, 三个摄像头构成一个有效的定位空间, 它们所在的坐标分别为 (x<sub>1</sub>, y<sub>1</sub>) , (x<sub>2</sub>, y<sub>2</sub>) , (x<sub>3</sub>, y<sub>3</sub>) 。通过对同一摄像头所拍图像上属于同一人的皮肤区域进行坐标运算, 即可在该摄像头拍摄画面中对该人进行定位, 也就是得到其与画面两侧距离d<sub>1</sub>、d<sub>2</sub>。如图7 (b) 所示, 实际空间中人体与拍摄范围两侧的距离D<sub>1</sub>、D<sub>2</sub>存在以下关系:</p>
                </div>
                <div class="area_img" id="41">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_04200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 三摄像头定位。 (a) 实验场景俯视图; (b) 定位原理图" src="Detail/GetImg?filename=images/GXXB201905030_04200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 三摄像头定位。 (a) 实验场景俯视图; (b) 定位原理图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_04200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7Positioning with three cameras. (a) Top view of experimental scene; (b) principle diagram of positioning</p>

                </div>
                <div class="p1">
                    <p id="43">摄像头和人连线将摄像头的可视角度分成了α和β两个角, 由于△ABC为等腰三角形, 根据正弦定理, 有</p>
                </div>
                <div class="area_img" id="44">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_04400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="45">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_04500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="46">式中θ为摄像头的可视角。</p>
                </div>
                <div class="p1">
                    <p id="47">结合 (2) ～ (4) 式, 可以得到:</p>
                </div>
                <div class="area_img" id="48">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_04800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="49">式中, d<sub>1</sub>、d<sub>2</sub>根据摄像头拍摄画面确定, θ通过摄像头的镜头焦距换算得到, 即可根据 (5) 式计算得到α的值:</p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905030_05000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="51">已知各个摄像头坐标、拍摄角度, 结合各个摄像头画面所计算的α值, 计算出人和摄像头连线所在直线的方程。通过不同摄像头下属于同一人皮肤的识别, 得到多条该人与摄像头连线的方程。采用至少两台摄像头, 即可通过计算直线交点坐标来确定人在空间中的二维坐标。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">3 基于多摄像头的人体识别定位的实现</h3>
                <h4 class="anchor-tag" id="53" name="53">3.1 人体皮肤表面“振动信号”的相似度比对及归一化</h4>
                <div class="p1">
                    <p id="54">基于图7 (a) 所示三摄像头场景 (对象A和对象B同时处于摄像头有效的定位空间内) , 进行三摄像头视频的同时采集。针对三个摄像头拍摄的视频, 分别进行人体皮肤表面“振动信号”的获取。三摄像头采集视频中的一帧及跟踪的皮肤区域, 如图8所示。</p>
                </div>
                <div class="p1">
                    <p id="55">以摄像头3为例, 其画面中检测到6块皮肤区域, 所提取的IPPG信号如图9所示。对IPPG信号进行去趋势化后, 计算其余弦相似度, 如表2所示。</p>
                </div>
                <div class="p1">
                    <p id="56">根据余弦相似度的判断规则可以看出, 同一摄像头下属于同一对象的皮肤区域所提取的IPPG信号的相似度相对较高, 而属于不同对象的相似度相对较低。这一结果与同一摄像头下IPPG信号目测的同步性与差异性相符。因此, 根据摄像头1、2、3 (分别简写为Cam1, Cam2, Cam3) 所提IPPG信号的余弦相似度, 对皮肤区域进行是否属于同一人的判断, 进而将画面中的皮肤区域进行对象的划分。</p>
                </div>
                <div class="p1">
                    <p id="57">考虑到三个摄像头的时间并不是完全对齐的, 由三个摄像头所拍摄视频提取的皮肤区域IPPG信号存在一定的相位差。以摄像头2、3为例, 在人为标定两个摄像头中的两块皮肤区域属于同一人的前提下, 对两个摄像头所拍视频得到的IPPG信号进行相位移动, 发现当摄像头3得到的IPPG信号向后移动10frame时, 信号的相似度与预期相符, 如图10、表3所示。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_05800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 三摄像头采集视频中的一帧及跟踪的皮肤区域" src="Detail/GetImg?filename=images/GXXB201905030_05800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 三摄像头采集视频中的一帧及跟踪的皮肤区域  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_05800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 One frame of acquired video with three cameras and tracked skin areas</p>

                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 摄像头3获取的IPPG信号" src="Detail/GetImg?filename=images/GXXB201905030_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 摄像头3获取的IPPG信号  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.9 IPPG signals acquired by camera 3</p>

                </div>
                <div class="area_img" id="60">
                                            <p class="img_tit">
                                                表2 摄像头3获取的IPPG信号的相似度
                                                    <br />
                                                Table 2 Similarity of IPPG signals acquired by camera 3
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905030_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 摄像头3获取的IPPG信号的相似度" src="Detail/GetImg?filename=images/GXXB201905030_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="61">
                                            <p class="img_tit">
                                                表3 摄像头2、3获取的IPPG信号的相似度
                                                    <br />
                                                Table 3 Similarity of IPPG signals acquired by cameras 2and 3
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905030_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 摄像头2、3获取的IPPG信号的相似度" src="Detail/GetImg?filename=images/GXXB201905030_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 0 摄像头2、3获取的IPPG信号" src="Detail/GetImg?filename=images/GXXB201905030_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 0 摄像头2、3获取的IPPG信号  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 IPPG signals acquired by cameras 2and 3</p>

                </div>
                <div class="p1">
                    <p id="63">根据余弦相似度的判断规则可以看出, 不同摄像头下属于同一对象的皮肤区域所提取的IPPG信号的相似度相对较高, 而属于不同对象的相似度相对较低。这一结果与不同摄像头下IPPG信号目测的同步性与差异性相符。因此, 根据所提IPPG信号的余弦相似度, 对不同摄像头所拍摄到的皮肤区域进行是否属于同一人的判断, 进而将不同摄像头下的皮肤区域进行对象的划分。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">3.2 人体识别与定位实现</h4>
                <div class="p1">
                    <p id="65">图7 (a) 所示三摄像头场景中, 摄像头1的坐标为 (x<sub>1</sub>=0, y<sub>1</sub>=0) , 摄像头2的坐标为 (x<sub>2</sub>=296, y<sub>2</sub>=-54) , 摄像头3的坐标为 (x<sub>3</sub>=313, y<sub>3</sub>=88) , 单位为cm。根据选用的摄像机焦距3.6mm, 可知其水平可视角度为75°。同时测量出2、3号摄像头拍摄角度的中轴线与x轴的夹角, 分别为-23°和33°。摄像头1、2、3同时对有效空间中的图像进行记录, 分别获得空间中对象A、B的三段视频, 每段视频6～10s, 共11组。依照IPPG信号的同步性与相似度, 判断各个摄像头画面中各个皮肤区域的归属对象。将同一画面中属于同一对象的皮肤区域的中心坐标进行平均, 作为对象在该摄像头画面中的坐标, 根据 (5) 式, 将3个摄像头得到的直线计算出来, 求取连线交点中心。</p>
                </div>
                <div class="p1">
                    <p id="66">基于11段视频, 得到11组站立位置 (每组两个对象的4组站立位置) 的22个计算坐标结果, 如图11所示。其中, 绝对误差x轴-44.91～32.42cm, y轴-1.83～24.22cm, 最大距离误差为46.03cm。</p>
                </div>
                <div class="p1">
                    <p id="67">误差的主要来源在于以下3点:1) 摄像头的坐标和拍摄角度以cm为单位手工测量, 会产生不可避免的误差, 而误差的累积对最终的定位结果有较大的影响;2) 将皮肤区域中心的平均值作为该对象在画面中的位置, 由于人体裸露的皮肤区域不一定均匀分布, 其皮肤区域中心可能会偏离实际的人体中心, 也会产生一定的误差;3) 对象虽然在真实坐标保持站立不动, 但其真正站立的位置与坐标位置还是有不可避免的误差, 同时人体还是会有轻微的晃动, 对实际的坐标带来影响。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">3.3 多个人体的识别与定位</h4>
                <div class="p1">
                    <p id="69">对于2个对象, 通过简单的相似度判断即可进行不同皮肤表面“振动信号”的对象划分。而对于多个对象, 相似度判断的标准相对单一, 所以需要更复杂的数据分析手段。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 1 对象A、B的多个坐标计算结果" src="Detail/GetImg?filename=images/GXXB201905030_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 1 对象A、B的多个坐标计算结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Multiple coordinate calculation results of objects A and B</p>

                </div>
                <div class="p1">
                    <p id="71">搭建多个对象识别与定位的实验场景, 如图12所示。其中, 三摄像头的坐标分别为Cam1: (x<sub>1</sub>=0, y<sub>1</sub>=0) , Cam2: (x<sub>2</sub>=269.8, y<sub>2</sub>=-239.7) , Cam3: (x<sub>3</sub>=319.5, y<sub>3</sub>=122.8) , 单位为cm。选用的摄像头为手机摄像头, 其水平可视角度为63°。同时测量出摄像头Cam2、Cam3拍摄角度的中轴线与x轴的夹角, 分别为-70°和50°。摄像头Cam1、Cam2、Cam3同时对有效空间中的图像进行记录, 分别获得空间中对象1～5的三段视频, 每段视频30s。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 2 5个对象的三摄像头识别与定位实验场景。 (a) 多对象识别与定位实验场景; (b) 场景俯视图; (c) 三摄像头采集视频中的一帧及皮肤区域" src="Detail/GetImg?filename=images/GXXB201905030_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 2 5个对象的三摄像头识别与定位实验场景。 (a) 多对象识别与定位实验场景; (b) 场景俯视图; (c) 三摄像头采集视频中的一帧及皮肤区域  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.12 Experimental scene of 5objects for recognition and positioning with 3cameras. (a) Experimental scene for multi-object recognition and positioning; (b) top view of scene; (c) one frame of acquired video by three cameras and skin areas</p>

                </div>
                <div class="p1">
                    <p id="75">对3个摄像头下分别属于5个对象的25处皮肤区域进行人体皮肤表面“振动信号”的相似度比对和归一化, 并基于组间的余弦相似度进行聚类分析。样本划分结果及准确率如表4、表5所示, 其中平均精确率为0.80, 平均召回率为0.73。</p>
                </div>
                <div class="area_img" id="76">
                                            <p class="img_tit">
                                                表4 相似度比对和归一化的分类结果
                                                    <br />
                                                Table 4 Classification results of similarity comparison and normalization
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_07600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905030_07600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_07600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 相似度比对和归一化的分类结果" src="Detail/GetImg?filename=images/GXXB201905030_07600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="77">
                                            <p class="img_tit">
                                                表5 相似度比对和归一化分类结果的精确率与召回率
                                                    <br />
                                                Table 5 Precision and recall rates of classification results of similarity comparison and normalization
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905030_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 相似度比对和归一化分类结果的精确率与召回率" src="Detail/GetImg?filename=images/GXXB201905030_07700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="78">识别误差的主要来源在于以下2点:1) 采用的是手机摄像头, 其可视角度相对于监控摄像头较小, 摄像头覆盖空间更大, 所以摄像头与人体皮肤的距离会出现较远的情况, 对皮肤表面的“振动信号”提取造成影响;2) 实验截取的手部的皮肤区域面积相对于手臂的皮肤区域较小, 也会对皮肤表面的“振动信号”提取造成影响;</p>
                </div>
                <div class="p1">
                    <p id="79">例如, 类别1也就是对象1的召回率较低, 一定程度上是因为对象1距离摄像头Cam2、Cam3较远, 同时因为对象1虽然距离摄像头Cam1较近, 但是其在摄像头Cam1拍摄方向的裸露皮肤面积较小;类别4也就是对象4的召回率较低的原因也是如此;类别2也就是对象2精确率较低, 正是因为对象1、4的召回率较低, 其皮肤区域混入到类别2中。</p>
                </div>
                <div class="p1">
                    <p id="80">摄像头采集的精度与焦距相关, 具有一个采集精度的区域分布, 如图13所示。同等光线情况下, 视角越大 (也就是同一物体占画面越大) , 其相对较高精度的区域离摄像头越近;视角越小 (也就是同一物体占画面越小) , 其相对较高精度的区域离摄像头越远。也就是说, 同等光线情况下, 对于距离摄像头更远的皮肤区域, 如果采用更大的焦距 (更小的视角) , 其“振动信号”的采集精度越高。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3 摄像头的精度区域分布示意图" src="Detail/GetImg?filename=images/GXXB201905030_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 3 摄像头的精度区域分布示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.13 Schematic of accuracy area distribution of camera</p>

                </div>
                <div class="p1">
                    <p id="82">考虑到会出现的皮肤区域面积过小的情况, 在实际的监控摄像头场景应用中, 可以对目标对象进行焦距调节, 对过小的皮肤区域进行放大, 从而减小皮肤区域过小对“振动信号”提取造成的影响。</p>
                </div>
                <div class="p1">
                    <p id="83">基于对3个摄像头下分别属于5个对象的25处皮肤区域进行人体皮肤表面“振动信号”的相似度比对和归一化, 对5个对象进行定位, 定位结果如图14所示。其中, 绝对误差x轴-17.65～55.75cm, y轴-33.25～24.79cm, 最大距离误差为61.01cm。5个对象的相对位置准确, 除3.2节中的误差来源外, 由于多对象实验采用的是手机摄像头、摄像头覆盖空间更大、摄像头距离对象更远, 所以其误差范围在可承受的范围内。</p>
                </div>
                <div class="p1">
                    <p id="84">综上, 可以看出, 基于皮肤表面“振动信号”的多摄像头人体识别定位具有以下特点:1) 在同一摄像头和不同摄像头下, 不同对象的皮肤表面“振动信号”明显不同, 而相同对象的皮肤表面“振动信号”都具有较高的同步性和余弦相似性;2) 只需2台摄像头即可对有效空间下的人体进行定位;3) 由于根据人体裸露皮肤区域进行识别和定位, 所以对人体面部是否露出没有要求, 增加了可识别的区域面积, 扩大了视角, 可以适应人体的各个角度的更多场景。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905030_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 4 5个对象的坐标计算结果" src="Detail/GetImg?filename=images/GXXB201905030_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 4 5个对象的坐标计算结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905030_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.14 Coordinate calculation results of 5objects</p>

                </div>
                <h3 id="86" name="86" class="anchor-tag">4 与一般人体识别定位的比较</h3>
                <div class="p1">
                    <p id="87">相较于基于图像特征进行定位的方法 (包括应用较为广泛的人脸识别定位技术) , 本文提出的人体识别和定位的方法场景限制小、对数据库没有要求、针对具有生命体征的人体进行定位, 可以解决人脸识别不能适用的场景, 具有较大的优势, 以例子具体说明:</p>
                </div>
                <div class="p1">
                    <p id="88">1) 一个固定人体目标站在圆心, 同心圆上每隔120°放置一个摄像头, 共三个摄像头。此时, 若采用基于图像特征的人脸识别定位方法, 三个摄像头对中间的人进行人脸识别定位都不可能实现, 因为必定有两个摄像头处于看不到或看不清脸的状态, 而人脸识别技术的核心是, 对准摄像头, 脸正方视角偏差不能超过15°, 还需要数据库中有该脸的正面照 (不能做鬼脸, 光线要好等) 。如果采用本文的定位方法, 只要有裸露的皮肤就能根据脉搏波数据的匹配对其进行定位, 无需数据库, 自身直接匹配比对即可, 也没有角度的限制。</p>
                </div>
                <div class="p1">
                    <p id="89">2) 嫌犯为了躲避追踪, 采用遮挡面部、与他人交换衣服并保持移动的方法。此时, 若采用基于图像特征的人脸识别定位方法, 很难将其进行定位, 甚至会出现定位错误的情况。如果采用本文的定位方法, 只要有裸露的皮肤就能根据脉搏波数据的匹配对其进行定位, 并且嫌犯很难对该定位方法采取应对措施 (若将皮肤完全遮盖起来相对于周围人反而更加突出) 。</p>
                </div>
                <div class="p1">
                    <p id="90">3) 双胞胎背靠背站在一起, 两人分别面对一个摄像头。此时, 若采用基于图像特征的定位方法, 很难将其进行定位, 甚至会出现定位错误的情况, 如将其定位为一个人。如果采用本文的定位方法, 根据裸露皮肤得到脉搏波数据的匹配对其进行定位, 就能够将两人区分开来。</p>
                </div>
                <div class="p1">
                    <p id="91">相较于用声音定位的技术和基于视频提取的声音信号的技术, 所提方法并不需要被定位生命体的配合 (如发声或做出产生声音的动作) , 定位通过的是视觉传感器采集的类似声音振动的活体脉搏波, 匹配的是身体不同区域的同一心脏发出的脉搏波, 只要是生命体就会产生脉搏, 就能对其进行定位。</p>
                </div>
                <h3 id="92" name="92" class="anchor-tag">5 结论</h3>
                <div class="p1">
                    <p id="93">与一般的识别定位手段相比, 基于皮肤表面“振动信号”的多摄像头识别定位手段, 只需要裸露的皮肤就能定位, 增加了可识别的区域面积, 视角相对较广且难以隐蔽, 避免了图像特征匹配带来的盲区问题, 降低了对识别定位对象的表情、姿势变化、拍摄角度、面部遮挡的要求, 无需数据库, 同时大大减少数据的传输量, 具有较广阔的应用前景。由于基于皮肤表面“振动信号”的多摄像头人体识别定位根据皮肤表面“振动信号”的同步性进行特征匹配, 从而可以结合更精准的目标跟踪技术实现对动态人体的识别和定位, 也可以作为人脸识别技术的辅助技术以提高其场景适应度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="94">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=W4S:A Real-Time System for Detecting and Tracking People in 2 1/2D">

                                <b>[1]</b>Haritaoglu I, Harwood D, Davis L S.W4S:A realtime system for detecting and tracking people in 21/2D[M]∥Burkhardt H, Neumann B.eds.Computer Vision-ECCV’98.Lecture Notes in Computer Science, Berlin, Heidelberg:Springer, 1998:877-892.
                            </a>
                        </p>
                        <p id="96">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201506001&amp;v=MDQ5NDg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVTcvUEx6N0Jkckc0SDlUTXFZOUZaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Huang K Q, Chen X T, Kang Y F, et al.Intelligent visual surveillance:a review[J].Chinese Journal of Computers, 2015, 38 (6) :1093-1118.黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 38 (6) :1093-1118.
                            </a>
                        </p>
                        <p id="98">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Top five biometrics:face,fingerprint,iris,palm and voice">

                                <b>[3]</b>Thakkar D.Top five biometrics:face, fingerprint, iris, palm and voice[EB/OL].[2018-04-10].https:∥www.bayometric.com/biometrics-face-finger-iris-palmvoice/.
                            </a>
                        </p>
                        <p id="100">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM1F3A3B80A2F32CC6AA53236843DD6AEC&amp;v=MDg2MjlsZkNwYlEzNWRoaHdMbS93Szg9TmlmSVk3TE9IYURQM1lkRkZlbDVEMzVLdkJCaW16cCtTbnprcEJZMkRjYVNOTS9zQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Ding C X, Tao D C.A comprehensive survey on poseinvariant face recognition[J].ACM Transactions on Intelligent Systems and Technology, 2016, 7 (3) :1-42.
                            </a>
                        </p>
                        <p id="102">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low resolution face recognition in surveillance systems using discriminant correlation analysis">

                                <b>[5]</b>Haghighat M, Abdel-Mottaleb M.Low resolution face recognition in surveillance systems using discriminant correlation analysis[C]∥2017 12th IEEE International Conference on Automatic Face&amp;Gesture Recognition (FG 2017) , May 30-June 3, 2017, Washington, D C, USA.New York:IEEE, 2017:912-917.
                            </a>
                        </p>
                        <p id="104">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Controlling access to a computerized resource based on authentication using pulse data">

                                <b>[6]</b>Linn J, Duane W M, Dotan Y, et al.Controlling access to a computerized resource based on authentication using pulse data:U.S.Patent 8, 902, 045[P].2014-12-2.
                            </a>
                        </p>
                        <p id="106">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201511031&amp;v=MDYyMTA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3L1BJalhUYkxHNEg5VE5ybzlHWllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Shi W S, Gao W R, Chen C L.Handheld swept source optical coherence tomography for imaging human skin in vivo[J].Acta Optica Sinica, 2015, 35 (11) :1117001.史伟松, 高万荣, 陈朝良.人体皮肤在体手持式扫频光学相干层析系统[J].光学学报, 2015, 35 (11) :1117001.
                            </a>
                        </p>
                        <p id="108">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201703028&amp;v=MTMzMTJGeXprVTcvUElqWFRiTEc0SDliTXJJOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Chen Z Y, Shao X X, Wu J L, et al.Full-field deformation measurement of human carotid artery based on water transfer printing speckle patterns[J].Acta Optica Sinica, 2017, 37 (3) :0312004.陈振宁, 邵新星, 吴家林, 等.水转印数字散斑场用于人体颈动脉全场测量[J].光学学报, 2017, 37 (3) :0312004.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pulse Oximeter Waveform:Photoelectric Plethysmography">

                                <b>[9]</b>Shelley K H, Shelley S.Pulse Oximeter Waveform:photoelectric plethysmography[M]∥Lake C, Hines R, Blitt C.Eds.Clinical Monitoring.Philadelphia:W.B.Saunders Company, 2001:420-423.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote plethysmographic imaging using ambient light">

                                <b>[10]</b>Verkruysse W, Svaasand L O, Nelson J S.Remote plethysmographic imaging using ambient light[J].Optics Express, 2008, 16 (26) :21434-21445.
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Photoplethysmography imaging:a new noninvasive and noncontact method for mapping of the dermal perfusion changes">

                                <b>[11]</b>Wu T, Blazek V, Schmitt H J.Photoplethysmography imaging:a new noninvasive and noncontact method for mapping of the dermal perfusion changes[J].Proceedings of SPIE, 2000, 4163:62-71.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1014086665.nh&amp;v=MzAwMjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprVTcvUFZGMjZHck93R05mS3FwRWJQSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Kong L Q.Research on key techniques of the noncontact detection of physiological signals[D].Beijing:Beijing Institute of Technology, 2014.孔令琴.非接触式生理信号检测关键技术研究[D].北京:北京理工大学, 2014.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive hydrostatic blood pressure calibration: development of a wearable, autonomous pulse wave velocity blood pressure monitor">

                                <b>[13]</b>McCombie D B, Shaltis P A, Reisner A T, et al.Adaptive hydrostatic blood pressure calibration:development of a wearable, autonomous pulse wave velocity blood pressure monitor[C]∥29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Aug 22-26, 2007, Lyon, France.New York:IEEE, 2007:370-373.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201601019&amp;v=MzE3MTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVNy9QSmlyYVpMRzRIOWZNcm85RWJZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Li S L, Li Y B, Li H Y, et al.Non-invasive continuous measurement method of blood pressure based on phase difference of pulse wave[J].Transducer and Microsystem Technologies, 2016, 35 (1) :62-64.李申龙, 李毅彬, 李洪阳, 等.基于脉搏波相位差的无创连续血压测量方法[J].传感器与微系统, 2016, 35 (1) :62-64.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201710025&amp;v=MTI1NDJuUmJiRzRIOWJOcjQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtVNy9QUHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Xu W Y, Meng J, Zhao X M.Non-contact monitoring of ambulatory blood pressure based on high speed camera[J].Journal of Zhejiang University (Engineering Science) , 2017, 51 (10) :2077-2083.许文媛, 孟濬, 赵夕朦.基于高速摄像机的动态血压非接触获取[J].浙江大学学报 (工学版) , 2017, 51 (10) :2077-2083.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES52ED24402FF63131D634513C86EFE5F5&amp;v=MzIzMzh5YUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHdMbS93Szg9TmlmT2ZiYTZhNlhPcTR0RlpwMTVDbjg0ekJkbjdEeDVUWDdoM3hvekRNVGhRTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Pal A, Gautam A K, Singh Y N.Evaluation of bioelectric signals for human recognition[J].Procedia Computer Science, 2015, 48:746-752.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Biometric recognition for twins inconsideration of age variability using PPG signals">

                                <b>[17]</b>Nadzri N I M, Sidek K A, Ismail A F.Biometric recognition for twins inconsideration of age variability using PPG signals[J].Journal of Telecommunication, Electronic and Computer Engineering, 2018, 10 (1/2/3/4/5) :97-100.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905030" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905030&amp;v=MTMwMzVHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1U3L1BJalhUYkxHNEg5ak1xbzk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

