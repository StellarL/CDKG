

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133843462158750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201908025%26RESULT%3d1%26SIGN%3djA4hDKdDq7vRaxeCfju%252f7HnuJik%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908025&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908025&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908025&amp;v=MzE3MjFyQ1VSTE9lWmVWdUZ5bmxXNzdOSWpYVGJMRzRIOWpNcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="2 理论和算法 ">2 理论和算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;2.1 YCbCr颜色空间特征&lt;/b&gt;"><b>2.1 YCbCr颜色空间特征</b></a></li>
                                                <li><a href="#47" data-title="&lt;b&gt;2.2 多尺度空间梯度特征&lt;/b&gt;"><b>2.2 多尺度空间梯度特征</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;2.3 视觉词典生成算法&lt;/b&gt;"><b>2.3 视觉词典生成算法</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;2.4 低秩稀疏耦合表示法&lt;/b&gt;"><b>2.4 低秩稀疏耦合表示法</b></a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;2.5 大间隔最邻近算法&lt;/b&gt;"><b>2.5 大间隔最邻近算法</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.6 算法总体构成&lt;/b&gt;"><b>2.6 算法总体构成</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="3 试验与分析 ">3 试验与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="&lt;b&gt;3.1 试验数据获取&lt;/b&gt;"><b>3.1 试验数据获取</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;3.2 YCbCr颜色空间特征分析&lt;/b&gt;"><b>3.2 YCbCr颜色空间特征分析</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;3.3 多尺度空间梯度特征分析&lt;/b&gt;"><b>3.3 多尺度空间梯度特征分析</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;3.4 算法性能分析&lt;/b&gt;"><b>3.4 算法性能分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="4 结  论 ">4 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="图1 基于可见光谱图的大豆外观品质判别方法系统流程图">图1 基于可见光谱图的大豆外观品质判别方法系统流程图</a></li>
                                                <li><a href="#87" data-title="图2 根据大豆外观品质将其分为3个等级的可见光谱图。 ">图2 根据大豆外观品质将其分为3个等级的可见光谱图。 </a></li>
                                                <li><a href="#88" data-title="图3 3CCD电荷耦合成像器收集到的原始黄豆的RGB色彩空间图像到YCbCr色彩空间图像的转换">图3 3CCD电荷耦合成像器收集到的原始黄豆的RGB色彩空间图像到YCbCr色彩空间图像的转换</a></li>
                                                <li><a href="#92" data-title="图4 大豆可见光谱图多尺度空间梯度特征。">图4 大豆可见光谱图多尺度空间梯度特征。</a></li>
                                                <li><a href="#95" data-title="表1 单模态特征与低秩稀疏耦合表示特征识别大豆外观品质等级的建模和预测精度值">表1 单模态特征与低秩稀疏耦合表示特征识别大豆外观品质等级的建模和预测精度值</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="11">


                                    <a id="bibliography_1" title=" Li K P.The impact and countermeasures analysis of Sino-US trade friction on China′s soybean [J].Economic Relations and Trade, 2018 (11) :41-44.李开鹏.中美贸易摩擦背景下大豆价格波动的影响及策略[J].对外经贸实务, 2018 (11) :41-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJW201811011&amp;v=MDg0MTNvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzc3TklUckJlYkc0SDluTnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Li K P.The impact and countermeasures analysis of Sino-US trade friction on China′s soybean [J].Economic Relations and Trade, 2018 (11) :41-44.李开鹏.中美贸易摩擦背景下大豆价格波动的影响及策略[J].对外经贸实务, 2018 (11) :41-44.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_2" title=" Li P W, Xie L H, Zhang W, &lt;i&gt;et al&lt;/i&gt;.Quality standard and detection technique of soybean[J].Food and Nutrition in China, 2003, 9 (4) :18-21.李培武, 谢立华, 张文, 等.大豆品质标准及检测技木[J].中国食物与营养, 2003, 9 (4) :18-21." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGWY200304004&amp;v=MTIwNzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXNzdOUHlyY2Q3RzRIdExNcTQ5Rlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Li P W, Xie L H, Zhang W, &lt;i&gt;et al&lt;/i&gt;.Quality standard and detection technique of soybean[J].Food and Nutrition in China, 2003, 9 (4) :18-21.李培武, 谢立华, 张文, 等.大豆品质标准及检测技木[J].中国食物与营养, 2003, 9 (4) :18-21.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_3" title=" Fang H, Zhang Z, Wang H L, &lt;i&gt;et al&lt;/i&gt;.Identification of transgenic soybean varieties using mid-infrared spectroscopy[J].Spectroscopy and Spectral Analysis, 2017, 37 (3) :760-765.方慧, 张昭, 王海龙, 等.基于中红外光谱技术鉴别转基因大豆的方法研究[J].光谱学与光谱分析, 2017, 37 (3) :760-765." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201703022&amp;v=MTM1NDNVUkxPZVplVnVGeW5sVzc3TklqaktZTEc0SDliTXJJOUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Fang H, Zhang Z, Wang H L, &lt;i&gt;et al&lt;/i&gt;.Identification of transgenic soybean varieties using mid-infrared spectroscopy[J].Spectroscopy and Spectral Analysis, 2017, 37 (3) :760-765.方慧, 张昭, 王海龙, 等.基于中红外光谱技术鉴别转基因大豆的方法研究[J].光谱学与光谱分析, 2017, 37 (3) :760-765.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_4" title=" Ahmad I S, Reid J F, Paulsen M R, &lt;i&gt;et al&lt;/i&gt;.Color classifier for symptomatic soybean seeds using image processing[J].Plant Disease, 1999, 83 (4) :320-327." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color classifier for symptomatic soybean seeds using image processing">
                                        <b>[4]</b>
                                         Ahmad I S, Reid J F, Paulsen M R, &lt;i&gt;et al&lt;/i&gt;.Color classifier for symptomatic soybean seeds using image processing[J].Plant Disease, 1999, 83 (4) :320-327.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_5" title=" Shatadal P, Tan J.Identifying damaged soybeans by color image analysis[J].Applied Engineering in Agriculture, 2003, 19 (1) :65-69." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Identifying Damaged Soybeans by Color Image Analysis">
                                        <b>[5]</b>
                                         Shatadal P, Tan J.Identifying damaged soybeans by color image analysis[J].Applied Engineering in Agriculture, 2003, 19 (1) :65-69.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_6" title=" Liu D J, Ning X F, Li Z M, &lt;i&gt;et al&lt;/i&gt;.Discriminating and elimination of damaged soybean seeds based on image characteristics[J].Journal of Stored Products Research, 2015, 60:67-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110600080788&amp;v=MjI4MjVNbndaZVp1SHlqbVViL0lJVjRjYXhjPU5pZk9mYks4SDlETXFZOUZaT01QQzNReG9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Liu D J, Ning X F, Li Z M, &lt;i&gt;et al&lt;/i&gt;.Discriminating and elimination of damaged soybean seeds based on image characteristics[J].Journal of Stored Products Research, 2015, 60:67-74.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_7" title=" Olgun M, Onarcan A O, &#214;zkan K, &lt;i&gt;et al&lt;/i&gt;.Wheat grain classification by using dense SIFT features with SVM classifier[J].Computers and Electronics in Agriculture, 2016, 122:185-190." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8BAA800E100B9584EFA8D086725B2F54&amp;v=MTM3NjVyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4Ymkzd2EwPU5pZk9mYnZLYjZERXI0OHdaZXNQZm5VOHh4Sm1uRTUxUEgvcXFoVTNmTUNXTTcrYkNPTnZGU2lXVw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Olgun M, Onarcan A O, &#214;zkan K, &lt;i&gt;et al&lt;/i&gt;.Wheat grain classification by using dense SIFT features with SVM classifier[J].Computers and Electronics in Agriculture, 2016, 122:185-190.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_8" title=" Xiao D Q, Feng J Z, Lin T Y, &lt;i&gt;et al&lt;/i&gt;.Classification and recognition scheme for vegetable pests based on the BOF-SVM model[J].International Journal of Agricultural and Biological Engineering, 2018, 11 (3) :190-196." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification and recognition scheme for vegetable pests based on the BOF-SVM model">
                                        <b>[8]</b>
                                         Xiao D Q, Feng J Z, Lin T Y, &lt;i&gt;et al&lt;/i&gt;.Classification and recognition scheme for vegetable pests based on the BOF-SVM model[J].International Journal of Agricultural and Biological Engineering, 2018, 11 (3) :190-196.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_9" title=" Feng J R, Ma X D, Guan H O, &lt;i&gt;et al&lt;/i&gt;.Calculation method of soybean plant height based on depth information[J].Acta Optica Sinica, 2019, 39 (5) :0515003.冯佳睿, 马晓丹, 关海鸥, 等.基于深度信息的大豆株高计算方法[J].光学学报, 2019, 39 (5) :0515003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905032&amp;v=MTgxMDFyQ1VSTE9lWmVWdUZ5bmxXNzdOSWpYVGJMRzRIOWpNcW85R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Feng J R, Ma X D, Guan H O, &lt;i&gt;et al&lt;/i&gt;.Calculation method of soybean plant height based on depth information[J].Acta Optica Sinica, 2019, 39 (5) :0515003.冯佳睿, 马晓丹, 关海鸥, 等.基于深度信息的大豆株高计算方法[J].光学学报, 2019, 39 (5) :0515003.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_10" title=" Jiang X D, Yu J Y, Zhu L K, &lt;i&gt;et al&lt;/i&gt;.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J].光学学报, 2018, 38 (10) :1036001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810052&amp;v=MjIyMTZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzc3TklqWFRiTEc0SDluTnI0OUE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Jiang X D, Yu J Y, Zhu L K, &lt;i&gt;et al&lt;/i&gt;.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J].光学学报, 2018, 38 (10) :1036001.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_11" title=" Jia L, Li M, Zhang P, &lt;i&gt;et al&lt;/i&gt;.SAR image change detection based on multiple kernel K-means clustering with local-neighborhood information[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (6) :856-860." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SAR image change detection based on multiple kernel k-means clustering with local-neighborhood information">
                                        <b>[11]</b>
                                         Jia L, Li M, Zhang P, &lt;i&gt;et al&lt;/i&gt;.SAR image change detection based on multiple kernel K-means clustering with local-neighborhood information[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (6) :856-860.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_12" title=" Li F Y, Huo H T, Bai J, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral target detection based on sparse representation and adaptive model[J].Acta Optica Sinica, 2018, 38 (12) :1228004.李非燕, 霍宏涛, 白杰, 等.基于稀疏表示和自适应模型的高光谱目标检测[J].光学学报, 2018, 38 (12) :1228004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201812046&amp;v=MzA4MDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlubFc3N05JalhUYkxHNEg5bk5yWTlCWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Li F Y, Huo H T, Bai J, &lt;i&gt;et al&lt;/i&gt;.Hyperspectral target detection based on sparse representation and adaptive model[J].Acta Optica Sinica, 2018, 38 (12) :1228004.李非燕, 霍宏涛, 白杰, 等.基于稀疏表示和自适应模型的高光谱目标检测[J].光学学报, 2018, 38 (12) :1228004.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_13" title=" Shen J Y, Huang W P, Zhu D Y, &lt;i&gt;et al&lt;/i&gt;.A novel similarity measure model for multivariate time series based on LMNN and DTW[J].Neural Processing Letters, 2017, 45 (3) :925-937." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD97ECA4BF7F077619B2CC6D0AA0F2FA9C&amp;v=MDM4NjB3YTA9Tmo3QmFycS9hNks5cS8welk1MFBDM3Mvemg5aDZFd09UZ3ZpM1dNMUQ3RGlOTFBzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGJpMw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Shen J Y, Huang W P, Zhu D Y, &lt;i&gt;et al&lt;/i&gt;.A novel similarity measure model for multivariate time series based on LMNN and DTW[J].Neural Processing Letters, 2017, 45 (3) :925-937.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-16 17:45</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(08),208-215 DOI:10.3788/AOS201939.0815002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于可见光谱图的大豆外观品质判别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9E%97%E8%90%8D&amp;code=31109379&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">林萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E5%9D%9A%E5%BC%BA&amp;code=09293900&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何坚强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E5%BF%97%E5%8B%87&amp;code=27865054&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹志勇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B0%B8%E6%98%8E&amp;code=31109380&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈永明</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%9B%90%E5%9F%8E%E5%B7%A5%E5%AD%A6%E9%99%A2%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0095993&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">盐城工学院电气工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%86%9C%E4%B8%9A%E5%A4%A7%E5%AD%A6%E6%9C%BA%E7%94%B5%E5%AD%A6%E9%99%A2&amp;code=0155063&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川农业大学机电学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出一种基于可见光谱图多模态词典特征低秩稀疏表示框架的大豆外观品质判别方法, 以精确确定大豆品质等级。首先, 提取大豆粒子可见光谱图像的多尺度空间梯度特征和色差分量 (YCbCr) 颜色空间特征;将上述提取的空间梯度特征和颜色空间特征看作视觉词汇, 通过Kernel K-means聚类算法获取视觉词汇的核空间局部分布聚类中心, 形成视觉词典;然后, 使用低秩稀疏表示法耦合上述两种特征, 用于消除高维异质模态词典描述符中冗余信息的影响;最后, 在高维耦合空间中根据样本之间的度量对低秩稀疏耦合表示多模态词典特征进行分类。所提方法充分利用多模态多尺度空间梯度特征和YCbCr颜色空间特征来描述大豆粒子外观品质的语义特征归属。实验结果表明:建模集和预测集总的识别精度分别达92.7%和80.1%, 所提方法的识别精度优于文献中提出的基于单一模态的视觉词典特征表示方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E8%B1%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大豆;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%96%E8%A7%82%E5%93%81%E8%B4%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">外观品质;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%AF%E8%A7%81%E5%85%89%E8%B0%B1%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">可见光谱图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E7%A7%A9%E7%A8%80%E7%96%8F%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低秩稀疏表示;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%BE%E7%BB%86%E5%88%86%E9%80%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">精细分选;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *陈永明 E-mail:billrange@126.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-05</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (31601227, 31501221, 61803325);</span>
                                <span>江苏省自然科学基金 (BK20161310, BK20140467, BK20181049);</span>
                                <span>国家住建部科技项目 (2016-K1-09);</span>
                                <span>江苏省高校自然科学研究面上项目 (18KJB510046);</span>
                                <span>江苏省住建厅科技项目 (2015ZD61);</span>
                    </p>
            </div>
                    <h1><b>Soybean Appearance Quality Discrimination Based on Visible Spectrogram</b></h1>
                    <h2>
                    <span>Lin Ping</span>
                    <span>He Jianqiang</span>
                    <span>Zou Zhiyong</span>
                    <span>Chen Yongming</span>
            </h2>
                    <h2>
                    <span>School of Electrical Engineering, Yancheng Institute of Technology</span>
                    <span>College of Mechanical and Electrical Engineering, Sichuan Agricultural University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A method for discriminating the appearance quality of soybeans based on the low-rank sparse (LRS) representation frame of multimodal lexicon features in the visible spectrogram is presented to accurately determine the soybean quality level. Firstly, multi-scale spatial gradient features and YCbCr color space features of the visible spectrogram of soybeans are extracted and regarded as visual vocabularies. The Kernel K-means clustering algorithm is used to form the local distribution cluster center of visual vocabularies in kernel space, thereby generating a vision lexicon. Secondly, the LRS representation method is used to couple the two type of features, thereby eliminating the effect of redundant information in high-dimensional heterogeneous modal dictionary descriptors. Finally, the LRS representation coupling multi-modal dictionary features are classified according to the metric between samples in the high-dimensional coupling space. The proposed method makes full use of multi-modal and multi-scale spatial gradient features and YCbCr color space features to describe the semantic feature attribution of appearance quality of soybeans. The experimental results show that the recognition accuracies of training set and prediction set are 92.7% and 80.1% respectively, and the discrimination accuracy of the proposed method is better than that of single-visual-mode based vision lexicon feature representation method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=soybean&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">soybean;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=appearance%20quality&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">appearance quality;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=visible%20spectrogram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">visible spectrogram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=low-rank%20sparse%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">low-rank sparse representation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fine%20sorting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fine sorting;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-05</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="38">大豆的进出口在国际农产品贸易中占有重要地位, 2017年全球大豆产量为34086万t, 其中美国、阿根廷、巴西等三国的大豆产量占比达82%, 其大豆产量直接影响全球大豆产量预期及市场行情。目前我国是世界上大豆的主要生产和消费国, 2017年我国国内大豆产量仅为1530万t, 进口大豆量达到9600万t, 其中美国和巴西的大豆分别占我国进口大豆总量的34%和53%, 我国大豆消费总量高达11130万t, 位居世界首位。大部分的大豆被收割后需经过干燥处理, 以较好地存储和用于工业化生产<citation id="99" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。干燥后大豆的种皮和果肉颜色变黄, 因此又被称为黄豆。大豆营养丰富, 其种子中高质量蛋白质的质量分数为40%, 无胆固醇油的质量分数为20%, 豆油中不仅含有对人体有益且质量分数超过88.6%的油酸、亚油酸和亚麻酸等不饱和脂肪酸, 还富含氨基酸、维生素、矿物质和脂肪等物质<citation id="100" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。大豆及其相关制品已经成为大多数人日常食用的健康食品<citation id="101" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。因此研究大豆及其制品的质量标准和相关的检测技术, 对于指导大豆生产及深加工利用, 提高大豆产品的市场竞争力具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="39">基于机器视觉和机器学习技术的人工智能系统被用于检测和区分大豆种子质量。Ahmad等<citation id="102" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>利用颜色信息对无症状和有症状的大豆种子进行分类。Shatadal等<citation id="103" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>利用RGB颜色特征训练了一个前馈神经网络, 将大豆粒子分为三类:完整的、损伤的和虫蚀的。Liu等<citation id="104" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提取黄豆色差分量 (YCbCr) 颜色特征、能量、熵、周长、面积、圆度、伸长率、紧凑度、偏心率、椭圆轴比和等效直径等特征作为BP (back propagation) 人工神经网络的输入, 并建立一个3层分类器, 用于对破碎和正常的大豆粒子进行分类。这些方法基本上利用颜色、形态和纹理的全局视觉特征来描述大豆粒子。全局特征通常包含大量无效的背景信息, 使用它们很容易掩盖局部详细信息。无效特征的引入和有效细节识别信息的丢失会不可避免地影响分类模型的性能, 从而影响识别的准确性。与使用全局特征描述有缺陷的大豆粒子相比, 有效的局部图像特征可以作为区分大豆粒子质量的关键手段。因此, 有必要开发新的局部特征算法, 以进一步提高大豆粒子的分类精度。</p>
                </div>
                <div class="p1">
                    <p id="40">近年来, 基于词典特征模型的局部视觉特征表示的技术在对农业对象识别方面显示出巨大的应用潜力。词典特征模型通过模仿文档分析方法将局部图像特征视为视觉单词来提取视觉词典特征, 以表示图像的属性。 Olgun等<citation id="105" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>利用密集尺度不变特征的词典特征模型对小麦籽粒品种进行分类。Xiao等<citation id="106" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出利用基于尺度不变特征变换的视觉词典模型特征对南方4种重要的蔬菜害虫进行分类。上述相关的研究仅使用了一种类型的视觉词典, 很难充分表达复杂的农业对象, 且未见报道有关针对大豆粒子品质检测的研究方法。</p>
                </div>
                <div class="p1">
                    <p id="41">为了实现对大豆粒子外观品质的精准分类, 本文采用一种电机驱动的水平线性成像装置获取大豆的可见光谱图像, 与传统的相机拍摄技术相比, 采用电机驱动的水平线性移动电子拍摄平台拍摄的照片可以确保每张大豆粒子在照片所有位置的几何度保持基本均匀。采用可见光谱图下多模态异质特征联合表达大豆粒子的外观品质, 可见光谱图多模态特征的简单组合会不可避免地导致表征图像的特征冗余, 并且在一定程度上影响特征识别过程中分类器的性能, 为了提高大豆品质智能识别系统的性能, 本文提出了一种多模态异质特征低秩稀疏表示法, 通过在低秩子稀疏子空间中生成新的低维稀疏描述符来耦合多模态异质特征的视觉语义词典, 在稀疏特征空间中消除不相关的语义词汇信息的影响, 提升可见光谱图下大豆粒子外观品质的分类精度。该方法可为实际大豆精加工中的外观品质精细分选工艺提供理论依据和技术支撑, 具有良好的应用前景, 市场价值可观。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">2 理论和算法</h3>
                <h4 class="anchor-tag" id="43" name="43"><b>2.1 YCbCr颜色空间特征</b></h4>
                <div class="p1">
                    <p id="44">RGB颜色模型适合图像显示与存储应用, 该颜色空间中从红色空间到绿色空间缺乏黄色和其他色彩的信息分量, 从绿色空间到蓝色空间又存在过多过渡色彩的信息分量, 因此不适合被应用于彩色图像处理。本文采用YCbCr颜色空间进行背景建模, 将RGB彩色模型转换成YCbCr颜色模型来表达大豆的图像特征, 转换公式为<citation id="107" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation><sup></sup></p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>Y</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>2</mn><mn>5</mn><mn>7</mn><mi>R</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mn>6</mn><mn>4</mn><mi>G</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>0</mn><mn>9</mn><mn>8</mn><mi>B</mi><mo>+</mo><mn>1</mn><mn>6</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>C</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mtext>b</mtext></mrow></msub><mo>=</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>1</mn><mn>4</mn><mn>8</mn><mi>R</mi><mo>-</mo><mn>0</mn><mo>.</mo><mn>2</mn><mn>9</mn><mn>1</mn><mi>G</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>4</mn><mn>3</mn><mn>9</mn><mi>B</mi><mo>+</mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>C</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mn>0</mn><mo>.</mo><mn>4</mn><mn>3</mn><mn>9</mn><mi>R</mi><mo>+</mo><mn>0</mn><mo>.</mo><mn>3</mn><mn>6</mn><mn>8</mn><mi>G</mi><mo>-</mo><mn>0</mn><mo>.</mo><mn>0</mn><mn>7</mn><mn>1</mn><mi>B</mi><mo>+</mo><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">式中:<i>Y</i>为图像的亮度指标;<i>C</i><sub>Cb</sub>和<i>C</i><sub>Cr</sub>分别表示蓝色分量和红色分量的浓度偏移量成分;<i>R</i>为红颜色值分量;<i>G</i>为绿颜色值分量;<i>B</i>为蓝颜色值分量。亮度指标和色度信息相互独立, <i>C</i><sub>Cb</sub>和<i>C</i><sub>Cr</sub>成分不受<i>Y</i>的影响。YCbCr颜色空间由于具备独立和稳定的颜色通道, 因此具有一定的抗噪声能力, 故选择YCbCr颜色空间作为大豆外观品质属性的判别特征。</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47"><b>2.2 多尺度空间梯度特征</b></h4>
                <div class="p1">
                    <p id="48">多尺度空间梯度特征算法<citation id="108" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>可对图像旋转、图像尺度伸缩、图像亮度的变化, 图像观测视角的变换, 图像仿射的变化, 以及图像内掺杂的噪声等具有一定程度的稳定性, 多尺度空间梯度特征的局部特征描述算法实现步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="49">1) 计算图像积分。假设获得的原始大豆影像为<i>I</i> (<i>x</i>, <i>y</i>) , 其中 (<i>x</i>, <i>y</i>) 表示影像上像素点的坐标值, 则图像积分的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ι</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><mi>x</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>v</mi><mi>y</mi></munderover><mi>Ι</mi></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">式中:<i>u</i>为大豆影像的横坐标值;<i>v</i>为大豆影像的纵坐标值。</p>
                </div>
                <div class="p1">
                    <p id="52">2) 建立多分辨率尺度空间图像。采用盒式滤波法替代Gaussian核与图像卷积来建立尺度空间, 通过变换盒滤波尺寸参数来获得多分辨率图像, 从而建立多分辨率、多层次的尺度空间图像。</p>
                </div>
                <div class="p1">
                    <p id="53">3) 计算尺度空间图像上的Hessain矩阵极值点。计算尺度空间影像中全部像素点的Hessian行列式值:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>det</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><mo stretchy="false">) </mo><mo>=</mo><mi>G</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mi>G</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo>-</mo><mo stretchy="false"> (</mo><mn>0</mn><mo>.</mo><mn>9</mn><mi>G</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<b><i>H</i></b>代表Hessian矩阵;<i>G</i><sub><i>xx</i></sub>、<i>G</i><sub><i>yy</i></sub>和<i>G</i><sub><i>xy</i></sub>表示图像沿着<i>x</i>、<i>y</i>和<i>xy</i>方向上Gaussian滤波后的二阶近似偏导数。对比指定像素的Hessian矩阵与同一尺度空间上的8个像素和邻近尺度空间上的9个像素点 (共26个像素点) 的行列式值, 选取最大或最小极值点来定义图像特征。</p>
                </div>
                <div class="p1">
                    <p id="56">4) 以极值点为中心构建一个半径为6<i>δ</i>的圆形区域, 其中<i>δ</i>为极值特征点所在的图像尺度, 即在60°扇形内, 每次将60°扇形区域旋转0.2 rad进行统计, 将值最大的扇形的方向作为该特征点的主方向。</p>
                </div>
                <div class="p1">
                    <p id="57">5) 在极值点附近通过Haar小波响应在12×12个规则平方间隔采样点处计算图像梯度, 然后沿着特征点主方向在周围邻域内计算4×4个子区域描述符, 在水平方向和垂直方向上的Haar小波响应的3×3平方区域中计算矢量和, 并利用其与相应兴趣点的主导方向相关来构建4×4子区域梯度强度特征, 最后将4×4子区域特征级联成64维梯度相关特征描述符来描述大豆粒子对象。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>2.3 视觉词典生成算法</b></h4>
                <div class="p1">
                    <p id="59">通过Kernel K-means聚类算法<citation id="109" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>实现视觉词典生成。获取视觉词汇的核空间局部分布聚类中心形成词典, 是指将视觉词汇通过核函数映射到核空间, 并进行聚类, 以形成视觉词典。采用的核函数Gaussian核表达式为</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi>γ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<i>γ</i>为核宽系数;<b><i>x</i></b><sub><i>i</i></sub>和<b><i>x</i></b><sub><i>j</i></sub>分别为第<i>i</i>和第<i>j</i>个样本特征;‖<b><i>x</i></b><sub><i>i</i></sub>-<b><i>x</i></b><sub><i>j</i></sub>‖为欧氏空间距离。经过Gaussian核化后特征空间中的样本具有较高的维数, 为了解决低维线性数据不便于用距离度量划分表示的问题, 本文没有采用传统的欧氏或马氏距离度量法, 而是采用学习最优的度量矩阵挖掘样本间的非线性特性:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mo stretchy="false">[</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>l</mi></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow><mo>⋅</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><mrow><mo>[</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>l</mi></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>l</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">式中:<i>D</i>为最优度量映射;<i>i</i>、<i>j</i>、<i>k</i>、<i>l</i>为样本编号;<b><i>A</i></b>为优化系数矩阵。核聚类算法可使视觉词汇不受特征数据维数的影响, 共同的高维线性同构语义词典空间的建立, 在一定程度上消除了异质纲量的影响。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.4 低秩稀疏耦合表示法</b></h4>
                <div class="p1">
                    <p id="65">低秩稀疏耦合表示法<citation id="110" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>假设Kernel K-means聚类算法生成的由梯度特征和颜色特征组合的高维数据具有低的内在维度, 因此低秩稀疏耦合表示法将原始数据<b><i>Y</i></b>分为低秩矩阵‖<b><i>X</i></b>‖<sub>*</sub>和稀疏误差矩阵‖<b><i>E</i></b>‖<sub>1</sub>两部分:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><mo>, </mo><mi mathvariant="bold-italic">E</mi></mrow></munder><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd columnalign="left"><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mi mathvariant="bold-italic">Y</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><mo>+</mo><mi mathvariant="bold-italic">E</mi></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">式中:‖·‖<sub>*</sub>表示核范数;‖·‖<sub>1</sub>表示<i>L</i>1范数;<i>λ</i>为正则化参数;<b><i>X</i></b>为输入低秩矩阵;<b><i>E</i></b>为残差矩阵。低秩稀疏表示法采用奇异值分解的方法交替地将残差投影到低秩矩阵, 同时通过设置硬阈值方法删除稀疏矩阵中的冗余变量, 从而消除相应高维异质模态字典描述符中冗余信息的影响, 即算法投影到输入矩阵和在给定迭代中获得的稀疏矩阵的残差, 该残差是在前一步骤中获得的输入矩阵和低秩矩阵的差值的稀疏投影, 迭代这两个步骤直到收敛为止。上述优化需解决的问题主要是在低维子空间中找到高维数据的最优投影。在去除残差后, 紧凑视觉字典集将被作为原始图像的有效表达。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>2.5 大间隔最邻近算法</b></h4>
                <div class="p1">
                    <p id="69">大间隔最邻近算法 (LMNN) <citation id="111" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>被用于将上述大豆粒子图像的低秩稀疏表示特征投影到高维特征空间中进行相似度计算, 从而估计出大豆粒子的外观品质特性。大间隔最邻近算法的实现过程如下:将低秩稀疏耦合成分<b><i>X</i></b><sup>*</sup><sub><i>i</i></sub>= (<b><i>x</i></b><sup>*</sup><sub><i>i</i>1</sub>, <b><i>x</i></b><sup>*</sup><sub><i>i</i>2</sub>, …, <b><i>x</i></b><sup>*</sup><sub><i>iK</i></sub>) (其中样本编号<i>i</i>=1, 2, …, <i>M</i>, <i>M</i>是数据集中的样本总数, <i>K</i>为低秩稀疏耦合成分数, <b><i>x</i></b><sup>*</sup><sub><i>iK</i></sub>是成分数为<i>K</i>的第<i>i</i>个样本的低秩稀疏耦合向量) 通过特征函数ϕ将数据映射到高维甚至是无限维的希尔伯特空间<i>Γ</i>, 其表达式为</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><mo>:</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mi>α</mi></msup><mo>↦</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>∈</mo><mi>Γ</mi><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">式中:<b>R</b>为实数集;<i>α</i>为实数集空间维度。其中, 大间隔最邻近算法的首个优化任务是完成输入大豆粒子样本ϕ (<b><i>X</i></b><sup>*</sup><sub><i>i</i></sub>) 与其目标近邻的大豆粒子特征平均度量的最小化, 表达式为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Μ</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>d</mi></mstyle><mo stretchy="false">[</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mo stretchy="false">[</mo></mstyle><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>-</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">[</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>-</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式中:<i>i</i>, <i>j</i>为样本编号;<i>d</i>为度量映射函数;<i>N</i><sub><i>i</i></sub>为第<i>i</i>个样本的目标近邻集;<i>Θ</i>为半正定矩阵。第二个优化任务是使输入样本<b><i>X</i></b><sup>*</sup><sub><i>i</i></sub>到其目标邻近度量与其到入侵近邻的距离至少保持1个单位的间隔, 表达式为</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo>∀</mo><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>l</mi><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>l</mi></msub><mo>≠</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mi>d</mi><mo stretchy="false">[</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mn>1</mn><mo>≤</mo></mtd></mtr><mtr><mtd><mi>d</mi><mo stretchy="false">[</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>l</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">式中:<i>l</i>为入侵样本编号;<i>y</i><sub><i>i</i></sub>为第<i>i</i>个样本的类标签;<i>y</i><sub><i>l</i></sub>为第<i>l</i>个入侵样本的类标签。该优化问题可以综合表达为</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Μ</mi></munder><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mo stretchy="false">[</mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mtext>ϕ</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>l</mi></mrow></munder><mi>ξ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>l</mi></mrow></msub><mo>, </mo></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mo>∀</mo><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>l</mi><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>l</mi></msub><mo>≠</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mi>d</mi><mo stretchy="false">[</mo><mover accent="true"><mtext>ϕ</mtext><mo>¯</mo></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mover accent="true"><mtext>ϕ</mtext><mo>¯</mo></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mn>1</mn><mo>≤</mo></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>d</mi><mo stretchy="false">[</mo><mover accent="true"><mtext>ϕ</mtext><mo>¯</mo></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mover accent="true"><mtext>ϕ</mtext><mo>¯</mo></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msubsup><mrow></mrow><mi>l</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mi>ξ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>l</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>ξ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>l</mi></mrow></msub><mo>≥</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">式中:<i>ξ</i><sub><i>ijl</i></sub>为松弛变量。</p>
                </div>
                <div class="p1">
                    <p id="78">最后, 根据每一个输入大豆粒子样本邻近的<i>Ω</i>个目标的核空间间距来确定样本的语义归属。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.6 算法总体构成</b></h4>
                <div class="p1">
                    <p id="80">基于可见光谱图的大豆外观品质判别方法的步骤为:1) 提取大豆粒子可见光谱图像的多尺度空间梯度特征和YCbCr颜色空间特征;2) 将上述提取的两种特征分别看成视觉词汇, 通过Kernel K-means聚类算法获取视觉词汇在核空间的局部分布聚类中心, 形成视觉词典, 视觉词典表示的是图像的语义信息, 一定程度上可消除异质纲量特征的影响;3) 采用低秩稀疏表示法耦合上述两种基于梯度和颜色相关的模态的词典特征, 用于消除高维异质模态词典描述符中冗余信息的影响;4) 在高维耦合空间中根据样本之间的度量对低秩稀疏耦合表示的多模态词典特征编码进行分类。系统流程图如图1所示。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于可见光谱图的大豆外观品质判别方法系统流程图" src="Detail/GetImg?filename=images/GXXB201908025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于可见光谱图的大豆外观品质判别方法系统流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908025_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of discrimination of soybean appearance quality based on visible spectrogram</p>

                </div>
                <h3 id="82" name="82" class="anchor-tag">3 试验与分析</h3>
                <h4 class="anchor-tag" id="83" name="83"><b>3.1 试验数据获取</b></h4>
                <div class="p1">
                    <p id="84">本文采用美国Epson公司生产的Perfection V850 Pro型可见光谱成像系统进行试验, 其主要部件包括:黑色吸光盖、透明平板、水平线性电机驱动移位电子平台、线程阵列全光谱发射光源、线程阵列全反射移动镜、线程阵列全反射固定镜、线程阵列电荷耦合成像器、大规模动态记忆装置、通信电缆和计算机等。将大豆样品以相等的间隔放置在透明板上;成像时黑色吸收盖覆盖于大豆粒子上方, 用于吸收线性阵列光源产生的光谱, 黑色吸收盖作为大豆粒子影像的背景;水平线性电机驱动移位电子平台上搭载的线程阵列全光谱发射光源和线程阵列全反射移动镜, 移动线程阵列全光谱发射光源输出的线性光束透过透明树脂平板后发射到样品表面;样品将光束反射回线程阵列全反射移动镜, 线程阵列全反射移动镜再将光束反射到线程阵列全反射固定镜, 由线程阵列电荷耦合成像器收集经由线程阵列全反射固定镜传输的样品的线性光谱, 并将其存储到大规模动态记忆装置中, 采用电机驱动水平线性移动电子拍摄平台拍摄的照片可以确保每张照片上大豆粒子在所有位置上的几何度保持基本均匀, 可作为大规模动态记忆装置中的样本。通信电缆将外部计算机与内部成像设备连接, 收集采集到的大豆图像样本数据。根据需识别大豆的外观品质, 将其分成良好、中等和劣质3个等级。良好等级指种皮完整、有光泽、子叶饱满的大豆粒子, 如图2 (a) 所示;中等等级指种皮破损、子叶开裂、子叶轻度萎缩的大豆粒子, 食用该粒子不会损害人体健康, 如图2 (b) 所示;劣质等级指种皮严重萎缩、有虫蚀, 发霉的大豆粒子, 即从外观上判断食用该类别的粒子会损害人体健康, 如图3 (c) 所示。图2显示了3种不同外观品质的大豆粒子样本图像, 3种大豆粒子的外观颜色特性均不同, 图2 (b) 中中等等级子叶暴露的大豆呈现出的黄色比图2 (a) 中良好等级黄色种皮完全包裹的大豆粒子呈现出的黄色更亮。图2 (c) 中劣质等级的大豆种皮和子叶部分呈现出灰白色, 因此可以采用可见光谱颜色特征来区分大豆粒子的品质。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>3.2 YCbCr颜色空间特征分析</b></h4>
                <div class="p1">
                    <p id="86">被可见光谱成像系统构件中的3组电荷耦合成像器 (3CCD) 收集到的大豆图像数据以彩色 (RGB) 颜色格式存储, 如图3所示。 RGB颜色模型取决于设备, 用于模拟物理显示或数据采集设备的输出。对大豆粒子图像的分类实际上是基于人类对大豆粒子颜色特征的视觉综合感知进行的, 并不是基于设备采集或存储形式。 YCbCr颜色空间通过模仿眼睛的非线性响应来保留大豆粒子图像的广泛色彩特征。如图3中部所示, RGB颜色空间在蓝色和绿色之间包含太多过渡颜色, 并且在绿色和红色之间缺少黄色和其他颜色。RGB色彩空间的成分在强度值之间存在较小差异, 因此基于RGB色彩空间的大豆粒子图像的3个成分的视觉感知非常接近。在完成RGB到YCbCr的色彩空间转换后, YCbCr色彩空间的分量在3个不同的色彩通道之间具有显著差异, 因此图3右部显示了3种截然不同的大豆粒子图像的视觉感知效果, YCbCr可以轻松量化颜色之间的视觉差异, 因为它更符合欧氏空间结构。转换后的可区分特征更适合随后的颜色特征字典的生成过程。为了更准确地表达大豆粒子核图像的颜色特征, 将RGB颜色描述符转换为YCbCr颜色描述符, 以用于后续的特征判别。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908025_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 根据大豆外观品质将其分为3个等级的可见光谱图。" src="Detail/GetImg?filename=images/GXXB201908025_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 根据大豆外观品质将其分为3个等级的可见光谱图。   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908025_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Visible spectrograms of soybeans are classified into three grades according to their appearance quality. </p>
                                <p class="img_note"> (a) 良好等级; (b) 中等等级; (c) 劣质等级</p>
                                <p class="img_note"> (a) Good grade; (b) medium grade; (c) inferior grade</p>

                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908025_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 3CCD电荷耦合成像器收集到的原始黄豆的RGB色彩空间图像到YCbCr色彩空间图像的转换" src="Detail/GetImg?filename=images/GXXB201908025_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 3CCD电荷耦合成像器收集到的原始黄豆的RGB色彩空间图像到YCbCr色彩空间图像的转换  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908025_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Conversion of RGB color space images of raw soybeans collected from 3CCD charge-coupled imager to YCbCr color space images</p>

                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>3.3 多尺度空间梯度特征分析</b></h4>
                <div class="p1">
                    <p id="91">图4为检测到的良好等级[图4 (a) ]和中等等级[图4 (b) ]的大豆粒子可见光谱图多尺度空间梯度特征。检测到的特征点主要分布在边缘和开裂[图3 (b) 中间开裂的位置]区域, 因此在这些位置处, 边缘处的梯度相对于其他图像区域变化较大。在边缘外侧检测到的梯度系数为负, 用实线圆圈标记;在内边缘上和破裂区域检测到的梯度系数为正, 用虚线圆圈标记。圆圈内半径表示梯度方向。在开裂的区域中, 梯度方向大致垂直于开裂的方向。多尺度空间梯度特征分析方法主要基于梯度算法, 因此这些图像像素变化较大的特征位置可被感知到, 检测到的开裂区域的梯度相关信息是估计大豆外观品质的关键参数。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908025_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 大豆可见光谱图多尺度空间梯度特征。" src="Detail/GetImg?filename=images/GXXB201908025_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 大豆可见光谱图多尺度空间梯度特征。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908025_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Visible spectrograms of soybeans with multi-scale spatial gradient characteristics.</p>
                                <p class="img_note"> (a) 良好等级; (b) 中等等级</p>
                                <p class="img_note"> (a) Good grade; (b) medium grade</p>

                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>3.4 算法性能分析</b></h4>
                <div class="p1">
                    <p id="94">本文选取600颗大豆粒子, 每类大豆粒子各包含200个样本, 随机选取其中的70%用于训练, 剩余的30%用于测试。整个过程分为建模和预测两个阶段, 其中建模阶段特征提取步骤包括提取数据库中大豆粒子外观图像的多尺度空间梯度特征和YCbCr颜色空间特征, 其中YCbCr颜色空间特征是指YCbCr颜色特征分量值耦合上对应颜色特征所在的空间位置信息。将上述提取的两种特征看成视觉词汇, 通过Kernel K-means聚类算法获取视觉词汇的Gaussain核空间局部分布聚类中心, 形成视觉词典, 视觉词典表示的是图像的语义信息, 因此在一定程度上消除了梯度纲量特征和颜色纲量特征的影响。在基于Kernel K-means聚类算法的视觉词典模型方法中, 视觉词典的大小将影响由视觉词汇构成的关于图像内容可解释性的特征, 低维度的词典可能无法完全描述图像特征, 而高维度的词典可能导致冗余的语义表达。 此外, 多尺度空间梯度特征和YCbCr的新联合模态特征将叠加字典的维数, 这将进一步增加大豆图像特征的冗余语义表达。为了解决这个问题, 本文首先设置大的视觉词典数 (900个) , 并从图像中提取高维度的可视字典, 然后采用低秩稀疏耦合表示方法在低维稀疏子空间中找到高维数据的最优投影, 消除冗余语义信息, 以获得紧凑视觉字典集作为原始图像的有效表达。采用大间隔最邻近算法对去量纲化特征的低秩稀疏表示多模态异质词典耦合编码进行分类。采用<i>k</i>-fold交叉验证法对建模数据集的预测精度进行估计, 建模集计算结果如表1所示, 总的识别精度达92.7%, 比单独基于颜色特征和梯度特征识别的方法分别高13.5%和6.2%。</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit">表1 单模态特征与低秩稀疏耦合表示特征识别大豆外观品质等级的建模和预测精度值 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Modeling and prediction accuracies of soybean discrimination using single-modal and low-rank sparse coupling representation features, respectively </p>
                    <p class="img_note">%</p>
                    <table id="95" border="1"><tr><td><br />Method</td><td>Modeling accuracy</td><td>Prediction accuracy</td></tr><tr><td><br />Gradient-based+K-means+LMNN</td><td>79.2</td><td>64.4</td></tr><tr><td><br />YCbCr-based+K-means+LMNN</td><td>86.5</td><td>70.8</td></tr><tr><td><br />LRS-based+Kernel K-means+LMNN</td><td>92.7</td><td>80.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="96">在预测阶段, 提取预测大豆粒子外观图像的多尺度空间梯度特征和YCbCr颜色空间特征。将上述提取的两种特征分别看成视觉词汇, 通过Kernel K-means聚类算法获取视觉词汇的Gaussian核空间局部分布聚类中心, 形成词典;对上述两种基于梯度和颜色相关的异质模态耦合的视觉词典特征采用低秩稀疏耦合表示法进行描述, 用于消除高维异质模态字典描述符中冗余信息的影响。将提取到的低秩稀疏表示多模态词典特征耦合编码输入到建立的大间隔最邻近模型中, 并进行预测, 预测结果如表1所示, 总的预测识别精度达80.1%, 比单独基于颜色特征和梯度特征识别的方法分别高15.7%和9.3%。</p>
                </div>
                <h3 id="97" name="97" class="anchor-tag">4 结  论</h3>
                <div class="p1">
                    <p id="98">在传统的基于设备的RGB颜色空间中, 从红色空间到绿色空间缺乏黄色和其他色彩信息分量, 从绿色空间到蓝色空间又存在过多的过渡色彩信息分量。RGB色彩空间的成分在强度值之间存在较小的差异, 因此RGB大豆图像的3个成分的视觉感知非常接近。在完成RGB到YCbCr的色彩空间转换后, YCbCr色彩空间的分量在3个不同的色彩通道之间具有显著差异, YCbCr可以轻松量化颜色之间的视觉差异, 因此可以更准确地表达大豆粒子的颜色特征。多尺度空间梯度特征分析方法主要基于梯度算法, 可以检测到图像梯度相对变化较大的区域, 检测到的开裂处的梯度相关信息可以作为估计大豆外观品质的关键参数。另外, 现有的多模态特征的简单组合将不可避免地导致图像的特征冗余表达, 并且在一定程度上影响分类器的判别性能, 故使用多模态特征来增强表达黄豆粒子的外观品质。为了进一步提高对大豆外观品质判别的识别系统的性能, 提出了一种低秩稀疏耦合表示法, 通过在低秩子稀疏子空间中生成新的低秩稀疏描述符来耦合不同类别的视觉语义词典, 并消除不相关的语义词典信息在该稀疏空间中产生的视觉噪声, 在Gaussian空间中采用大间隔最邻近算法对低秩稀疏表示多模态异质词典耦合编码进行分类, 提升了大豆粒子外观品质的分类精度, 为实际大豆精加工中外观品质精细分选工艺提供理论依据和技术支撑。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="11">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJW201811011&amp;v=MTgwNzZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzc3TUlUckJlYkc0SDluTnJvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Li K P.The impact and countermeasures analysis of Sino-US trade friction on China′s soybean [J].Economic Relations and Trade, 2018 (11) :41-44.李开鹏.中美贸易摩擦背景下大豆价格波动的影响及策略[J].对外经贸实务, 2018 (11) :41-44.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGWY200304004&amp;v=MDg5MjRSTE9lWmVWdUZ5bmxXNzdNUHlyY2Q3RzRIdExNcTQ5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Li P W, Xie L H, Zhang W, <i>et al</i>.Quality standard and detection technique of soybean[J].Food and Nutrition in China, 2003, 9 (4) :18-21.李培武, 谢立华, 张文, 等.大豆品质标准及检测技木[J].中国食物与营养, 2003, 9 (4) :18-21.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201703022&amp;v=MjUzNDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlubFc3N01JampLWUxHNEg5Yk1ySTlIWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Fang H, Zhang Z, Wang H L, <i>et al</i>.Identification of transgenic soybean varieties using mid-infrared spectroscopy[J].Spectroscopy and Spectral Analysis, 2017, 37 (3) :760-765.方慧, 张昭, 王海龙, 等.基于中红外光谱技术鉴别转基因大豆的方法研究[J].光谱学与光谱分析, 2017, 37 (3) :760-765.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color classifier for symptomatic soybean seeds using image processing">

                                <b>[4]</b> Ahmad I S, Reid J F, Paulsen M R, <i>et al</i>.Color classifier for symptomatic soybean seeds using image processing[J].Plant Disease, 1999, 83 (4) :320-327.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Identifying Damaged Soybeans by Color Image Analysis">

                                <b>[5]</b> Shatadal P, Tan J.Identifying damaged soybeans by color image analysis[J].Applied Engineering in Agriculture, 2003, 19 (1) :65-69.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110600080788&amp;v=MTkzNDA2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUlWNGNheFk9TmlmT2ZiSzhIOURNcVk5RlpPTVBDM1F4b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Liu D J, Ning X F, Li Z M, <i>et al</i>.Discriminating and elimination of damaged soybean seeds based on image characteristics[J].Journal of Stored Products Research, 2015, 60:67-74.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8BAA800E100B9584EFA8D086725B2F54&amp;v=MjQ1NTI1ZGhoeGJpM3dhdz1OaWZPZmJ2S2I2REVyNDh3WmVzUGZuVTh4eEptbkU1MVBIL3FxaFUzZk1DV003K2JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Olgun M, Onarcan A O, Özkan K, <i>et al</i>.Wheat grain classification by using dense SIFT features with SVM classifier[J].Computers and Electronics in Agriculture, 2016, 122:185-190.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification and recognition scheme for vegetable pests based on the BOF-SVM model">

                                <b>[8]</b> Xiao D Q, Feng J Z, Lin T Y, <i>et al</i>.Classification and recognition scheme for vegetable pests based on the BOF-SVM model[J].International Journal of Agricultural and Biological Engineering, 2018, 11 (3) :190-196.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905032&amp;v=MDc3MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXNzdNSWpYVGJMRzRIOWpNcW85R1pvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Feng J R, Ma X D, Guan H O, <i>et al</i>.Calculation method of soybean plant height based on depth information[J].Acta Optica Sinica, 2019, 39 (5) :0515003.冯佳睿, 马晓丹, 关海鸥, 等.基于深度信息的大豆株高计算方法[J].光学学报, 2019, 39 (5) :0515003.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810052&amp;v=MDA1MzBWdUZ5bmxXNzdNSWpYVGJMRzRIOW5OcjQ5QVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Jiang X D, Yu J Y, Zhu L K, <i>et al</i>.Self-calibrated binocular ranging system based on hardware SURF algorithm[J].Acta Optica Sinica, 2018, 38 (10) :1036001.蒋晓东, 于纪言, 朱立坤, 等.基于硬件SURF算法的自校准双目测距系统[J].光学学报, 2018, 38 (10) :1036001.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SAR image change detection based on multiple kernel k-means clustering with local-neighborhood information">

                                <b>[11]</b> Jia L, Li M, Zhang P, <i>et al</i>.SAR image change detection based on multiple kernel K-means clustering with local-neighborhood information[J].IEEE Geoscience and Remote Sensing Letters, 2016, 13 (6) :856-860.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201812046&amp;v=MDIzNDJYVGJMRzRIOW5Oclk5QllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXNzdNSWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Li F Y, Huo H T, Bai J, <i>et al</i>.Hyperspectral target detection based on sparse representation and adaptive model[J].Acta Optica Sinica, 2018, 38 (12) :1228004.李非燕, 霍宏涛, 白杰, 等.基于稀疏表示和自适应模型的高光谱目标检测[J].光学学报, 2018, 38 (12) :1228004.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD97ECA4BF7F077619B2CC6D0AA0F2FA9C&amp;v=Mjg0MTNiUTM1ZGhoeGJpM3dhdz1OajdCYXJxL2E2SzlxLzB6WTUwUEMzcy96aDloNkV3T1RndmkzV00xRDdEaU5MUHNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Shen J Y, Huang W P, Zhu D Y, <i>et al</i>.A novel similarity measure model for multivariate time series based on LMNN and DTW[J].Neural Processing Letters, 2017, 45 (3) :925-937.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201908025" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908025&amp;v=MzE3MjFyQ1VSTE9lWmVWdUZ5bmxXNzdOSWpYVGJMRzRIOWpNcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

