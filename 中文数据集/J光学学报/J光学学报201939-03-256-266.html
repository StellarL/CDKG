

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134140144815000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201903030%26RESULT%3d1%26SIGN%3d3unfJ%252b1TF691UCASiaBji7nFd3Y%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903030&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903030&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903030&amp;v=MjE1MzgzTElqWFRiTEc0SDlqTXJJOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhuVWI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#67" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="2 区域辐射一致性及移动阴影检测 ">2 区域辐射一致性及移动阴影检测</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;2.1 阴影一致性属性证明&lt;/b&gt;"><b>2.1 阴影一致性属性证明</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;2.2 一致性属性与统计参数&lt;/b&gt;"><b>2.2 一致性属性与统计参数</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;2.3 基于统计参数的目标超像素区域PCC分类&lt;/b&gt;"><b>2.3 基于统计参数的目标超像素区域PCC分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#148" data-title="3 阴影检测与目标掩码增长 ">3 阴影检测与目标掩码增长</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#149" data-title="&lt;b&gt;3.1 完整阴影检测与目标掩码增长框架&lt;/b&gt;"><b>3.1 完整阴影检测与目标掩码增长框架</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;3.2 完整阴影检测与目标掩码增长算法&lt;/b&gt;"><b>3.2 完整阴影检测与目标掩码增长算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#169" data-title="&lt;b&gt;4.1 参数分析&lt;/b&gt;"><b>4.1 参数分析</b></a></li>
                                                <li><a href="#187" data-title="&lt;b&gt;4.2 实验验证&lt;/b&gt;"><b>4.2 实验验证</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#208" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#140" data-title="图1 &lt;i&gt;PCC&lt;/i&gt;分类过程示意图">图1 <i>PCC</i>分类过程示意图</a></li>
                                                <li><a href="#155" data-title="图2 阴影检测与目标掩码增长框架">图2 阴影检测与目标掩码增长框架</a></li>
                                                <li><a href="#158" data-title="图3 区域生长和ViBe目标掩码融合示意图">图3 区域生长和ViBe目标掩码融合示意图</a></li>
                                                <li><a href="#166" data-title="图4 区域生长与目标掩码融合结果。">图4 区域生长与目标掩码融合结果。</a></li>
                                                <li><a href="#186" data-title="图5 &lt;i&gt;highway I&lt;/i&gt;序列实验结果">图5 <i>highway I</i>序列实验结果</a></li>
                                                <li><a href="#195" data-title="图6 不同场景下的算法处理过程">图6 不同场景下的算法处理过程</a></li>
                                                <li><a href="#198" data-title="表1 5种算法的评价结果">表1 5种算法的评价结果</a></li>
                                                <li><a href="#206" data-title="表2 目标掩码增长率与精度">表2 目标掩码增长率与精度</a></li>
                                                <li><a href="#207" data-title="图7 5种算法下的检测结果">图7 5种算法下的检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="9">


                                    <a id="bibliography_1" title=" Li S S, Zhao G P, Wang J Y. Distractor-aware object tracking based on multi-feature fusion and scale-adaption[J]. Acta Optica Sinica, 2017, 37 (5) : 0515005. 李双双, 赵高鹏, 王建宇. 基于特征融合和尺度自适应的干扰感知目标跟踪[J]. 光学学报, 2017, 37 (5) : 0515005." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705025&amp;v=MTYxMTh0R0ZyQ1VSTE9lWmVWdUZ5SG5VYjNMSWpYVGJMRzRIOWJNcW85SFlZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Li S S, Zhao G P, Wang J Y. Distractor-aware object tracking based on multi-feature fusion and scale-adaption[J]. Acta Optica Sinica, 2017, 37 (5) : 0515005. 李双双, 赵高鹏, 王建宇. 基于特征融合和尺度自适应的干扰感知目标跟踪[J]. 光学学报, 2017, 37 (5) : 0515005.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_2" title=" Mo S W, Deng X P, Wang S, &lt;i&gt;et al&lt;/i&gt;. Moving object detection algorithm based on improved visual background extractor[J]. Acta Optica Sinica, 2016, 36 (6) : 0615001. 莫邵文, 邓新蒲, 王帅, 等. 基于改进视觉背景提取的运动目标检测算法[J]. 光学学报, 2016, 36 (6) : 0615001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201606025&amp;v=MDIwODJDVVJMT2VaZVZ1RnlIblViM0xJalhUYkxHNEg5Zk1xWTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Mo S W, Deng X P, Wang S, &lt;i&gt;et al&lt;/i&gt;. Moving object detection algorithm based on improved visual background extractor[J]. Acta Optica Sinica, 2016, 36 (6) : 0615001. 莫邵文, 邓新蒲, 王帅, 等. 基于改进视觉背景提取的运动目标检测算法[J]. 光学学报, 2016, 36 (6) : 0615001.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_3" title=" Liu F, Shen T S, Ma X X. Convolutional neural network based multi-band ship target recognition with feature fusion[J]. Acta Optica Sinica, 2017, 37 (10) : 1015002. 刘峰, 沈同圣, 马新星. 特征融合的卷积神经网络多波段舰船目标识别[J]. 光学学报, 2017, 37 (10) : 1015002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201710031&amp;v=MjI5Mjk5Yk5yNDlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlIblViM0xJalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Liu F, Shen T S, Ma X X. Convolutional neural network based multi-band ship target recognition with feature fusion[J]. Acta Optica Sinica, 2017, 37 (10) : 1015002. 刘峰, 沈同圣, 马新星. 特征融合的卷积神经网络多波段舰船目标识别[J]. 光学学报, 2017, 37 (10) : 1015002.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_4" title=" Wu Y Y, He X H, Nguyen T Q. Moving object detection with a freely moving camera via background motion subtraction[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (2) : 236-248." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Moving Objects detection with freely moving camera via background motion subtraction">
                                        <b>[4]</b>
                                         Wu Y Y, He X H, Nguyen T Q. Moving object detection with a freely moving camera via background motion subtraction[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (2) : 236-248.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_5" title=" Amato A, Mozerov M G, Bagdanov A D, &lt;i&gt;et al&lt;/i&gt;. Accurate moving cast shadow suppression based on local color constancy detection[J]. IEEE Transactions on Image Processing, 2011, 20 (10) : 2954-2966." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate Moving Cast Shadow Suppression Based on Local Color Constancy Detection">
                                        <b>[5]</b>
                                         Amato A, Mozerov M G, Bagdanov A D, &lt;i&gt;et al&lt;/i&gt;. Accurate moving cast shadow suppression based on local color constancy detection[J]. IEEE Transactions on Image Processing, 2011, 20 (10) : 2954-2966.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_6" title=" Sanin A, Sanderson C, Lovell B C. Shadow detection: A survey and comparative evaluation of recent methods[J]. Pattern Recognition, 2012, 45 (4) : 1684-1695." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737947&amp;v=MTY1NDErZ0lCWGcrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JS1Z3V2FCRT1OaWZPZmJLN0h0RE5xWTlGWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Sanin A, Sanderson C, Lovell B C. Shadow detection: A survey and comparative evaluation of recent methods[J]. Pattern Recognition, 2012, 45 (4) : 1684-1695.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_7" title=" Nadimi S, Bhanu B. Physical models for moving shadow and object detection in video[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (8) : 1079-1087." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Physical models for moving shadow and object detection in video">
                                        <b>[7]</b>
                                         Nadimi S, Bhanu B. Physical models for moving shadow and object detection in video[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (8) : 1079-1087.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_8" title=" Zhang Y, Li X, Gao X, &lt;i&gt;et al&lt;/i&gt;. A simple algorithm of superpixel segmentation with boundary constraint[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (7) : 1502-1514." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A simple algorithm of superpixel segmentation with boundary constraint">
                                        <b>[8]</b>
                                         Zhang Y, Li X, Gao X, &lt;i&gt;et al&lt;/i&gt;. A simple algorithm of superpixel segmentation with boundary constraint[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (7) : 1502-1514.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_9" title=" Yang J, Price B, Shen X H, &lt;i&gt;et al&lt;/i&gt;. Fast appearance modeling for automatic primary video object segmentation[J]. IEEE Transactions on Image Processing, 2016, 25 (2) : 503-515." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast appearance modeling for automatic primary video object segmentation">
                                        <b>[9]</b>
                                         Yang J, Price B, Shen X H, &lt;i&gt;et al&lt;/i&gt;. Fast appearance modeling for automatic primary video object segmentation[J]. IEEE Transactions on Image Processing, 2016, 25 (2) : 503-515.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_10" title=" Russell M, Zou J J, Fang G, &lt;i&gt;et al&lt;/i&gt;. Feature-based image patch classification for moving shadow detection[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 14 (8) : 1-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature-based image patch classification for moving shadow detection">
                                        <b>[10]</b>
                                         Russell M, Zou J J, Fang G, &lt;i&gt;et al&lt;/i&gt;. Feature-based image patch classification for moving shadow detection[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 14 (8) : 1-14.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_11" title=" Cucchiara R, Grana C, Piccardi M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting moving objects, ghosts, and shadows in video streams">
                                        <b>[11]</b>
                                         Cucchiara R, Grana C, Piccardi M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_12" title=" Chen C T, Su C Y, Kao W C. An enhanced segmentation on vision-based shadow removal for vehicle detection[C]//The 2010 International Conference on Green Circuits and Systems, June 21-23, 2010, Shanghai, China. New York: IEEE, 2010: 679-682." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Enhanced Segmentation on Vision-Based Shadow Removal for Vehicle Detection">
                                        <b>[12]</b>
                                         Chen C T, Su C Y, Kao W C. An enhanced segmentation on vision-based shadow removal for vehicle detection[C]//The 2010 International Conference on Green Circuits and Systems, June 21-23, 2010, Shanghai, China. New York: IEEE, 2010: 679-682.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_13" title=" Wu Q, Zhang W D, Vijaya Kumar B V K. Strong shadow removal via patch-based shadow edge detection[C]//2012 IEEE International Conference on Robotics and Automation, May 14-18, 2012, Saint Paul, MN, USA. New York: IEEE 2012: 2177-2182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Strong shadow removal via patch-based shadow edge detection">
                                        <b>[13]</b>
                                         Wu Q, Zhang W D, Vijaya Kumar B V K. Strong shadow removal via patch-based shadow edge detection[C]//2012 IEEE International Conference on Robotics and Automation, May 14-18, 2012, Saint Paul, MN, USA. New York: IEEE 2012: 2177-2182.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_14" title=" Wang J, Wang Y H, Jiang M, &lt;i&gt;et al&lt;/i&gt;. Moving cast shadow detection using online sub-scene shadow modeling and object inner-edges analysis[J]. Journal of Visual Communication and Image Representation, 2014, 25 (5) : 978-993." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14032300121488&amp;v=MDQ4MzNiSzhIdExPckk5Rlpla09DSFF4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JS1Z3V2FCRT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Wang J, Wang Y H, Jiang M, &lt;i&gt;et al&lt;/i&gt;. Moving cast shadow detection using online sub-scene shadow modeling and object inner-edges analysis[J]. Journal of Visual Communication and Image Representation, 2014, 25 (5) : 978-993.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_15" title=" Huang J B, Chen C S. Moving cast shadow detection using physics-based features[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition, June 20-25, 2009, Miami, FL, USA. New York: IEEE, 2009: 2310-2317." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Moving cast shadow detection using physics-based features">
                                        <b>[15]</b>
                                         Huang J B, Chen C S. Moving cast shadow detection using physics-based features[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition, June 20-25, 2009, Miami, FL, USA. New York: IEEE, 2009: 2310-2317.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_16" title=" Joshi A J, Papanikolopoulos N P. Learning to detect moving shadows in dynamic environments[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (11) : 2055-2063." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning to Detect Moving Shadows in Dynamic Environments">
                                        <b>[16]</b>
                                         Joshi A J, Papanikolopoulos N P. Learning to detect moving shadows in dynamic environments[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (11) : 2055-2063.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_17" title=" Russell M, Zou J J, Fang G. A novel region-based method for moving shadow detection[C]∥2016 International Conference on Digital Image Computing: Techniques and Applications, November 30-December 2, 2016, Gold Coast, QLD, Australia. New York: IEEE, 2016: 1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel region-based method for moving shadow detection">
                                        <b>[17]</b>
                                         Russell M, Zou J J, Fang G. A novel region-based method for moving shadow detection[C]∥2016 International Conference on Digital Image Computing: Techniques and Applications, November 30-December 2, 2016, Gold Coast, QLD, Australia. New York: IEEE, 2016: 1-6.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_18" title=" Dai J Y, Han D Y. Region-based moving shadow detection using affinity propagation[J]. International Journal of Signal Processing, Image Processing and Pattern Recognition, 2015, 8 (3) : 65-74." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Region-based moving shadow detection using affinity propagation">
                                        <b>[18]</b>
                                         Dai J Y, Han D Y. Region-based moving shadow detection using affinity propagation[J]. International Journal of Signal Processing, Image Processing and Pattern Recognition, 2015, 8 (3) : 65-74.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_19" title=" Barnich O, van Droogenbroeck M. ViBe: A universal background subtraction algorithm for video sequences[J]. IEEE Transactions on Image Processing, 2011, 20 (6) : 1709-1724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ViBe: A Universal Background Subtraction Algorithm for Video Sequences">
                                        <b>[19]</b>
                                         Barnich O, van Droogenbroeck M. ViBe: A universal background subtraction algorithm for video sequences[J]. IEEE Transactions on Image Processing, 2011, 20 (6) : 1709-1724.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_20" title=" Dornaika F, El Traboulsi Y. Learning flexible graph-based semi-supervised embedding[J]. IEEE Transactions on Cybernetics, 2015, 46 (1) : 206-218." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning flexible graph-based semi-supervised embedding">
                                        <b>[20]</b>
                                         Dornaika F, El Traboulsi Y. Learning flexible graph-based semi-supervised embedding[J]. IEEE Transactions on Cybernetics, 2015, 46 (1) : 206-218.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_21" title=" Aqel S, Hmimid A, Sabri M A, &lt;i&gt;et al&lt;/i&gt;. Road traffic: Vehicle detection and classification[C]∥2017 Intelligent Systems and Computer Vision (ISCV) , April 17-19, 2017, Fez, Morocco. New York: IEEE, 2017: 1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Road traffic: Vehicle detection and classification">
                                        <b>[21]</b>
                                         Aqel S, Hmimid A, Sabri M A, &lt;i&gt;et al&lt;/i&gt;. Road traffic: Vehicle detection and classification[C]∥2017 Intelligent Systems and Computer Vision (ISCV) , April 17-19, 2017, Fez, Morocco. New York: IEEE, 2017: 1-5.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_22" title=" Russell M, Fang G, Zou J J. Real-time vehicle shadow detection[J]. Electronics Letters, 2015, 51 (16) : 1253-1255." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-Time Vehicle Shadow Detection">
                                        <b>[22]</b>
                                         Russell M, Fang G, Zou J J. Real-time vehicle shadow detection[J]. Electronics Letters, 2015, 51 (16) : 1253-1255.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_23" title=" Amirmazlaghani M, Rezghi M, Amindavar H. A novel robust scaling image watermarking scheme based on Gaussian Mixture Model[J]. Expert Systems with Applications, 2015, 42 (4) : 1960-1971." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3E42DCF6F3126A66A139CB9DD9CFF942&amp;v=MzExMTVPRG5wSXlSQmk2engwT3czcjJHWThDc1RpVEw2ZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHpicTl3cXM9TmlmT2ZiRE5HdE80M1BsREV1Zw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         Amirmazlaghani M, Rezghi M, Amindavar H. A novel robust scaling image watermarking scheme based on Gaussian Mixture Model[J]. Expert Systems with Applications, 2015, 42 (4) : 1960-1971.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_24" title=" Goyette N, Jodoin P M, Porikli F, &lt;i&gt;et al&lt;/i&gt;. Changedetection. net: A new change detection benchmark dataset[C]∥2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Changedetection.net:A new change detection benchmark dataset">
                                        <b>[24]</b>
                                         Goyette N, Jodoin P M, Porikli F, &lt;i&gt;et al&lt;/i&gt;. Changedetection. net: A new change detection benchmark dataset[C]∥2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 1-8.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_25" title=" Prati A, Mikic I, Trivedi M M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving shadows: Algorithms and evaluation[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (7) : 918-923." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting moving shadows: algorithms and evaluation">
                                        <b>[25]</b>
                                         Prati A, Mikic I, Trivedi M M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving shadows: Algorithms and evaluation[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (7) : 918-923.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_26" title=" Leone A, Distante C. Shadow detection for moving objects based on texture analysis[J]. Pattern Recognition, 2007, 40 (4) : 1222-1233." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739565&amp;v=MDQ2MzlGWStnR0NYbzhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lLVndXYUJFPU5pZk9mYks3SHRETnFZOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         Leone A, Distante C. Shadow detection for moving objects based on texture analysis[J]. Pattern Recognition, 2007, 40 (4) : 1222-1233.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_27" title=" Cucchiara R, Grana C, Piccardi M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting moving objects, ghosts, and shadows in video streams">
                                        <b>[27]</b>
                                         Cucchiara R, Grana C, Piccardi M, &lt;i&gt;et al&lt;/i&gt;. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_28" title=" Hsieh J W, Hu W F, Chang C J, &lt;i&gt;et al&lt;/i&gt;. Shadow elimination for effective moving object detection by Gaussian shadow modeling[J]. Image and Vision Computing, 2003, 21 (6) : 505-516." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349953&amp;v=Mjk2NThET3JZOUVaKzhHQlhrNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUtWd1dhQkU9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[28]</b>
                                         Hsieh J W, Hu W F, Chang C J, &lt;i&gt;et al&lt;/i&gt;. Shadow elimination for effective moving object detection by Gaussian shadow modeling[J]. Image and Vision Computing, 2003, 21 (6) : 505-516.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_29" title=" Sanin A, Sanderson C, Lovell B C. Improved shadow removal for robust person tracking in surveillance scenarios[C]//2010 20th International Conference on Pattern Recognition, August 23-26, 2010, Istanbul, Turkey. New York: IEEE, 2010: 141-144." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Shadow Removal for Robust Person Tracking in Surveillance Scenarios">
                                        <b>[29]</b>
                                         Sanin A, Sanderson C, Lovell B C. Improved shadow removal for robust person tracking in surveillance scenarios[C]//2010 20th International Conference on Pattern Recognition, August 23-26, 2010, Istanbul, Turkey. New York: IEEE, 2010: 141-144.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-11-13 10:55</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(03),256-266 DOI:10.3788/AOS201939.0315003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于区域辐射一致性的移动阴影检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B5%B7%E6%B0%B8&amp;code=24891468&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈海永</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%84%E4%B8%BD%E5%BF%A0&amp;code=37442484&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郄丽忠</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%9D%A4&amp;code=22672971&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘坤</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0149979&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河北工业大学人工智能与数据科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了同时检测本影与半影区域, 提出并证明了阴影区域辐射的一致性属性。获取超像素区域轮廓内的点集合, 将像素点集合 (PCC) 分为目标前景区域 (目标PCC) 和阴影区域 (阴影PCC) , 利用所提出的基于区域生长的完整阴影检测与目标掩码增长算法, 通过融合完整的阴影区域、完整的目标前景区域和ViBe掩码这三个部分, 实现了前景目标掩码反向增长。在公开数据集中的实验结果表明, 所提方法的阴影检测平均精度达到了82.5%, 性能显著优于传统方法。目标掩码的平均增长率达到了8.84%, 准确率达到了95%以上。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A7%BB%E5%8A%A8%E9%98%B4%E5%BD%B1%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">移动阴影检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E7%94%9F%E9%95%BF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域生长;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *刘坤 E-mail:liukun@hebut.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61403119);</span>
                                <span>河北省自然科学基金 (F2018202078);</span>
                                <span>河北省科技计划 (17211804D);</span>
                                <span>河北省青年拔尖人才 (210003);</span>
                    </p>
            </div>
                    <h1><b>Moving Shadow Detection Based on Regional Radiation Consistency</b></h1>
                    <h2>
                    <span>Chen Haiyong</span>
                    <span>Qie Lizhong</span>
                    <span>Liu Kun</span>
            </h2>
                    <h2>
                    <span>School of Artifical Intelligent, Hebei University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to simultaneously detect the shadow and penumbra regions, this study proposes and proves the consistent properties of shadow region radiation. Point collection in contour (PCC) within the outline of the super-pixel region corresponding to moving object is obtained, and the PCC is divided into the object foreground area (foreground PCC) and the shadow area (shadow PCC) . With the proposed region-based full shadow detection and object mask growth algorithm, the foreground object mask is inversely grown by combing the complete shadow region, the complete foreground region and the ViBe mask of the moving object. The experimental results in the public dataset show that the average accuracy of the shadow detection of the proposed method reaches 82.5%, and the performance is significantly better reaches the traditional method. The average growth rate of the object mask reaches 8.84%, and the accuracy rate reaches over 95%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=moving%20object%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">moving object detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=moving%20shadow%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">moving shadow detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=region%20growth&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">region growth;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-04-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="67" name="67" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="68">运动目标检测一直是重要和富有挑战的任务, 在许多场景有着重要的价值, 如跟踪<citation id="211" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、视频监控<citation id="214" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>和运动目标识别<citation id="212" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。运动目标检测的一个实现方法是背景差分方法, 该方法利用视频序列的每一帧与事先创建好的背景模型进行对比作差来得到运动目标。然而, 在同一场景中存在的移动阴影容易使运动目标检测发生误检。同时, 阴影也会导致目标合并、目标变形及目标丢失等现象的出现。当面对目标分类、目标跟踪、目标识别及目标计数等场合时, 阴影会严重影响系统的稳健性<citation id="213" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。因此, 移动阴影检测具有重大的价值和意义。</p>
                </div>
                <div class="p1">
                    <p id="69">阴影检测的关键在于定位阴影所对应的图像像素点或区域, 在前景目标中消除阴影像素点, 进而得到准确的运动目标。阴影的形状会随着光线的照射角度和目标形状的不同而变化。此外, 阴影与目标通常会伴随在一起, 并且有着相同的运动状态与表面形态<citation id="215" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。因此, 背景和阴影的颜色与纹理之间的相互作用是随机可变的, 深度的阴影会导致区域纹理信息的丢失。为了解决上述问题, 文献中提出许多基于像素和区域的阴影检测方法, 它们的共同点是对提取特征进行分类<citation id="216" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。这些特征描述符包括特定颜色空间的颜色和强度<citation id="217" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>, 阴影和前景目标边缘<citation id="218" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>, 以及纹理或区域的梯度<citation id="219" type="reference"><link href="19" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="70">为了克服基于单个像素的阴影检测造成的误差, 对视频序列的每一帧采用基于图的分割方法<citation id="222" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>进行分割并得到超像素, 可对每个超像素区域中的阴影进行分组和抑制。为了解决阴影表示问题, Russell等<citation id="220" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>引入了分块特征近似和稀疏表示技术, 为了解决漏检问题, 采取了后期形态学处理操作, 使得检测结果更加完整。基于像素颜色的方法充分利用了不同颜色空间中阴影区域的颜色信息来提取多个特征<citation id="223" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。基于半监督学习技术, 文献<citation id="221" type="reference">[<a class="sup">16</a>]</citation>提出了一种新的自适应技术来解决移动阴影检测的静态设置工作模式问题, 该技术具有自动适应场景条件变化的能力。</p>
                </div>
                <div class="p1">
                    <p id="71">基于区域的阴影检测与抑制方法, 利用区域纹理信息可以克服像素噪声问题。Amato等<citation id="224" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>利用阴影区域的局部颜色恒常性质, 将图像分割成多个运动区域 (超像素) 。Wu等<citation id="225" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种基于斑块的阴影边缘检测方法, 创建了边缘分类器, 通过训练阴影边缘和前景目标以获取阴影区域。Russell等<citation id="226" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation><sup></sup>利用像素几何方向, 结合像素梯度幅度, 获取新特征。Dai等<citation id="227" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>利用吸引子传播算法检测移动阴影区域, 使用该算法时不必事先指定聚类数目且能很好地解决非欧空间问题。目前, 大多数移动阴影检测算法都是基于前期运动目标检测算法的掩码结果, 对其中的目标与阴影进行分离。因此, 在阴影的检测结果中, 目标部分仅仅是对前期目标部分的保留, 而不能使目标掩码部分增长。这在一定程度上限制了阴影检测算法精度的提高<citation id="228" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="72">为此, 本文采用基于图的分割方法对当前图像进行分割<citation id="229" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 可得到若干超像素区域, 其目标超像素区域内所有像素点集合 (PCC) , 主要分为阴影PCC和目标PCC。进而, 提出一种基于掩码PCC种子的区域生长方法, 将阴影PCC生长为完整的阴影区域。最后, 通过融合生长后的目标PCC与前期运动目标检测算法得到的目标掩码中的真实目标区域, 实现目标掩码反向增长, 提升目标前景区域和阴影区域的检测精度。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag">2 区域辐射一致性及移动阴影检测</h3>
                <div class="p1">
                    <p id="74">本研究所提算法需要对比PCC内坐标点映射到背景图像和当前图像中的每个像素点的强度, 对两个图像中的像素强度进行分析, 二者分别为 PCC 元素对应于背景图像中的像素点 ( PB-PCC) 和 PCC 元素对应于当前图像中的像素点 ( PC-PCC) 。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.1 阴影一致性属性证明</b></h4>
                <div class="p1">
                    <p id="76">采用Lambert漫反射光照模型<citation id="230" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>对阴影区域进行描述, 表达式为</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">式中:<b><i>L</i></b> (<i>x</i>) =[<i>L</i><sub>r</sub> (<i>x</i>) , <i>L</i><sub>g</sub> (<i>x</i>) , <i>L</i><sub>b</sub> (<i>x</i>) ]<sup>T</sup>为图像平面在rgb颜色空间的光照反射矢量, <i>x</i>表示二维图像平面内的任意一点, <i>L</i><sub>r</sub>, <i>L</i><sub>g</sub>, <i>L</i><sub>b</sub>分别为rgb颜色空间中r, g, b通道的反射强度;<b><i>E</i></b> (<i>x</i>) =[<i>E</i><sub>r</sub> (<i>x</i>) , <i>E</i><sub>g</sub> (<i>x</i>) , <i>E</i><sub>b</sub> (<i>x</i>) ]<sup>T</sup>, <i>ρ</i> (<i>x</i>) =[<i>ρ</i><sub>r</sub> (<i>x</i>) , <i>ρ</i><sub>g</sub> (<i>x</i>) , <i>ρ</i><sub>b</sub> (<i>x</i>) ]<sup>T</sup>分别为输入光照辐射矢量和目标表面点<i>x</i>处的反射系数矢量, <i>E</i><sub>r</sub>、<i>E</i><sub>g</sub>、<i>E</i><sub>b</sub>、<i>ρ</i><sub>r</sub>、<i>ρ</i><sub>g</sub>、<i>ρ</i><sub>b</sub>分别表示相应的颜色通道辐射量与反射系数。</p>
                </div>
                <div class="p1">
                    <p id="79">阴影区域光照辐射模型为</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><msup><mtext>a</mtext><mo>′</mo></msup></msub><mo>+</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup></msub><mi>cos</mi><mo stretchy="false">[</mo><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi>τ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">式中: <b><i>C</i></b><sub>a′</sub>, <b><i>C</i></b><sub>b′</sub>分别表示周围环境光辐射和主光源光辐射;<i>θ</i>表示目标表面法线与主光源光线的夹角;<i>τ</i> (<i>x</i>) 取值范围为[0, 1], 表示半影区域内的阴影过渡参数。当<i>τ</i> (<i>x</i>) =0时, 像素点<i>x</i>的反射光均来自于周围环境光, 像素点位于本影区域;当0&lt;<i>τ</i> (<i>x</i>) &lt;1时, 像素点<i>x</i>位于半影区域;当<i>τ</i> (<i>x</i>) =1时, 像素点<i>x</i>位于阴影区域之外。</p>
                </div>
                <div class="p1">
                    <p id="82">将 (2) 式代入 (1) 式, 阴影区域的任意像素点<i>x</i>在背景图像中的反射光可表示为</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">L</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>a</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>+</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mi>cos</mi><mo stretchy="false">[</mo><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi>τ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">式中:<b><i>L</i></b><sup>B</sup><sub>Sh</sub> (<i>x</i>) 表示阴影区域内像素点<i>x</i>在背景图像中的强度, 即PB-PCC的强度;<b><i>C</i></b><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><msup><mtext>a</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow></math></mathml>、<b><i>C</i></b><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow></math></mathml>分别表示背景图像中阴影像素点<i>x</i>处的对应光源辐射; <i>ρ</i><sub>B</sub> (<i>x</i>) 表示背景图像中点<i>x</i>处的反射系数矢量。</p>
                </div>
                <div class="p1">
                    <p id="87">失去了主光源, 像素点在当前图像中的反射光可表示为</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">L</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>a</mtext><mo>′</mo></msup><mrow><mtext>C</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo stretchy="false">) </mo><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>C</mtext></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">式中: <b><i>L</i></b><sup>C</sup><sub>Sh</sub> (<i>x</i>) 、<b><i>C</i></b><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><msup><mtext>a</mtext><mo>′</mo></msup><mrow><mtext>C</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow></math></mathml>分别表示PC-PCC内的像素点反射强度和接收到的环境光照辐射强度;<i>ρ</i><sub>C</sub> (<i>x</i>) 表示当前图像中点<i>x</i>处的反射系数矢量。由于阴影区域中<i>ρ</i><sub>B</sub> (<i>x</i>) =<i>ρ</i><sub>C</sub> (<i>x</i>) , 所以反射光减少量可以表示为</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">L</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">L</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mi>cos</mi><mo stretchy="false">[</mo><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi>τ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>&gt;</mo><mn>0</mn><mspace width="0.25em" /><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">式中, 光线与表面法线的角度<i>θ</i>、阴影过渡参数<i>τ</i>, 以及反射系数矢量<i>ρ</i><sub>B</sub> (<i>x</i>) 均为恒定参数。由 (5) 式可知, 阴影区域内的像素强度变化只与<b><i>C</i></b><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow></math></mathml>有关。因此, 阴影区域像素点的反射光变化量只与当时的光源辐射有关。</p>
                </div>
                <div class="p1">
                    <p id="94">因为<b><i>C</i></b><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow></math></mathml>cos[<i>θ</i> (<i>x</i>) ]<i>τ</i> (<i>x</i>) <i>ρ</i><sub>B</sub> (<i>x</i>) &gt;0, 所以对于阴影区域内的像素点来说, 有</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>B</mtext></mrow></msub><mo>&gt;</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>C</mtext></mrow></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>B</mtext></mrow></msub><mo>&gt;</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>C</mtext></mrow></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>B</mtext></mrow></msub><mo>&gt;</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>C</mtext></mrow></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">式中, <i>I</i><sub><i>X</i>B</sub>和<i>I</i><sub><i>X</i>C</sub>分别表示像素点在背景图像与当前图像中, rgb颜色空间中的<i>X</i>通道中的强度 (<i>X</i>取为r、g、b) 。由 (6) 式可知, 相对于背景图像, 阴影区域像素点的三个通道强度都有所降低。这与一般的认知相符。</p>
                </div>
                <div class="p1">
                    <p id="98">令<i>Δ</i> (<i>x</i>) 表示图像平面内两相邻像素点之间的距离, 那么这两个像素点在背景图像与当前图像中反射光变化的差值为</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo><mi>Δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mi>cos</mi><mo stretchy="false">[</mo><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi>τ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>×</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mi>cos</mi><mo stretchy="false">{</mo><mi>θ</mi><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo><mi>Δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mi>τ</mi><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo></mtd></mtr><mtr><mtd><mi>Δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo><mi>Δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">假定<i>τ</i>和<i>θ</i>变化得非常缓慢, 即<i>τ</i> (<i>x</i>) ≈<i>τ</i>[<i>x</i>+<i>Δ</i> (<i>x</i>) ]和<i>θ</i> (<i>x</i>) ≈<i>θ</i>[<i>x</i>+<i>Δ</i> (<i>x</i>) ], 当阴影区域中点的反射系数<i>ρ</i><sub>B</sub> (<i>x</i>) ≈<i>ρ</i><sub>B</sub>[<i>x</i>+<i>Δ</i> (<i>x</i>) ]时, 可得到</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo><mi>Δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>≈</mo><mn>0</mn><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">这意味着, 在阴影区域内部相邻像素点之间的反射光变化量近似相等, 即都与主光源直接相关, 而通常认为主光源是常量。与此相反, 运动目标对应的像素点不符合这个规律, 因为像素点的<i>ρ</i><sub>B</sub> (<i>x</i>) ≠<i>ρ</i><sub>C</sub> (<i>x</i>) , 这样<b><i>D</i></b><sub>C</sub> (<i>x</i>) -<b><i>D</i></b><sub>C</sub>[<i>x</i>+<i>Δ</i> (<i>x</i>) ]≠0。</p>
                </div>
                <div class="p1">
                    <p id="103"> (8) 式是利用单光源模型推导出来的。当假设在 (2) 式中使用线性组合的多个光源时, 结论也同样成立, 这些假设符合大多数的场景要求, 在模型中将<b><i>C</i></b><sub>a′</sub>、<b><i>C</i></b><sub>b′</sub>定为常量是合理的<citation id="231" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。同样, 条件简化后的光照模型已被用于推导出其他的阴影抑制模型<citation id="232" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="104">由 (8) 式可知, 对于同一阴影区域内的像素点而言, 在RGB颜色空间中, 阴影区域对应的PB-PCC和PC-PCC中像素点之间的强度变化量近似一致, 而这在真实的非阴影目标区域是不成立的。将这种规律称为“阴影区域辐射一致性属性”, 简称一致性属性。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>2.2 一致性属性与统计参数</b></h4>
                <div class="p1">
                    <p id="106">基于阴影区域辐射一致性属性, 在阴影区域内, 由单个像素点扩展到PCC内全部元素。记cos[<i>θ</i> (<i>x</i>) ]<i>τ</i> (<i>x</i>) <i>ρ</i><sub>B</sub> (<i>x</i>) =<b><i>K</i></b> (<i>x</i>) , 那么, 阴影PCC中PB-PCC和PC-PCC强度变化可表示为</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mi>cos</mi><mo stretchy="false">[</mo><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mi>τ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">ρ</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">建立阴影PCC内的像素点的数学模型。假设, 当前图像中的每一个像素点强度出现的概率服从高斯分布<citation id="233" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 令<b><i>I</i></b> (<i>x</i>, <i>y</i>, <i>t</i>) 表示像素点<b><i>I</i></b> (<i>x</i>, <i>y</i>) 在<i>t</i>时刻的强度, 对于同一时刻<i>t</i>, 在同一PCC内的像素点集合服从高斯分布, 即</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mi>η</mi><mo stretchy="false"> (</mo><mi>i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>σ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mi>σ</mi><msub><mrow></mrow><mi>t</mi></msub><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt></mrow></mfrac><mi>exp</mi><mrow><mo>[</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mi>t</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">式中, (<i>x</i><sub><i>t</i></sub>, <i>y</i><sub><i>t</i></sub>) 表示区域对应的PCC内的所有元素, <i>i</i><sub><i>t</i></sub>表示点 (<i>x</i><sub><i>t</i></sub>, <i>y</i><sub><i>t</i></sub>) 的强度值, <i>μ</i><sub><i>t</i></sub>、<i>σ</i><sub><i>t</i></sub>表示<i>t</i>时刻该PCC内像素点集合对应的期望值与标准差。</p>
                </div>
                <div class="p1">
                    <p id="111">假设某图像中的阴影PCC集合为{<i>V</i><sub>1</sub>, <i>V</i><sub>2</sub>, …, <i>V</i><sub><i>k</i></sub>}, 且<i>V</i><sub><i>k</i></sub>={<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>n</i></sub>}, 其中<i>n</i>为<i>V</i><sub><i>k</i></sub>中的像素点数目, 则该PCC对应的所有PB-PCC的像素点强度均值为</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>1</mn><mtext>B</mtext></msubsup><mo>+</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>2</mn><mtext>B</mtext></msubsup><mo>+</mo><mo>⋯</mo><mo>+</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>n</mi><mtext>B</mtext></msubsup></mrow><mi>n</mi></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">式中, <b><i>p</i></b><sup>B</sup><sub><i>n</i></sub>表示背景图像中像素点强度, 相应地, 前景图像目标PCC的像素点强度均值为</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo>=</mo><mfrac><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>1</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo stretchy="false">]</mo><mo>+</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>2</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo stretchy="false">]</mo><mo>+</mo><mo>⋯</mo><mo>+</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>n</mi><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo stretchy="false">]</mo></mrow><mi>n</mi></mfrac><mo>=</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo>-</mo><mfrac><mrow><mi>n</mi><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup></mrow><mi>n</mi></mfrac><mo>=</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">则均值变化量为</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">对于不同的视频序列选取不同的阈值Δ<i>μ</i>, 当PB-PCC和PC-PCC任意两个通道均值偏差超过了这个阈值之后, 若它们的均值大小顺序没有改变, 则这个PCC是阴影PCC, 反之, 是目标PCC。也就是说这个PCC就是真正的运动目标 (不包括阴影) 中的PCC。</p>
                </div>
                <div class="p1">
                    <p id="118">更进一步, 对于阴影PCC而言, 区域内的每一个像素点相对于背景图像强度近似减少<i>μ</i><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup></mrow></math></mathml>, 背景图像中PB-PCC的方差为</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">σ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>1</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>2</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>n</mi><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>n</mi></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">而在当前图像中, PC-PCC的方差为</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">σ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>1</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>2</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi>C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>n</mi><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi>C</mi><msubsup><mrow></mrow><msup><mtext>b</mtext><mo>′</mo></msup><mrow><mtext>B</mtext><mtext>S</mtext><mtext>h</mtext></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>n</mi></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">将 (13) 式代入 (16) 式可得</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">σ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>C</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>1</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mn>2</mn><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>n</mi><mtext>B</mtext></msubsup><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>n</mi></mfrac><mo>=</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">σ</mi><msubsup><mrow></mrow><mrow><mtext>S</mtext><mtext>h</mtext></mrow><mtext>B</mtext></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">即阴影PCC对应的PB-PCC和PC-PCC强度的方差矢量相同。这样, 对于当前图像中的任意一个PCC而言, 如果对应的PB-PCC和PC-PCC标准差相差不大, 并且均值偏差没有超过上一个阈值条件, 则这个PCC符合阴影PCC的特征。反之, 则符合目标PCC的特征。这两个标准差的偏差阈值设置为Δ<i>σ</i>。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>2.3 基于统计参数的目标超像素区域PCC分类</b></h4>
                <div class="p1">
                    <p id="127">由前文可知, 对区域轮廓内的PCC进行分类的重点在于对PCC对应的PB-PCC和PC-PCC中的信息对比。为此, 利用阴影区域辐射一致性属性中所包含的4个指标 (<i>ω</i>, Δ<i>μ</i>, Δ<i>σ</i>, <i>τ</i><sub><i>k</i></sub>) 进行PCC分类。</p>
                </div>
                <h4 class="anchor-tag" id="128" name="128">1) <i>ω</i>:</h4>
                <div class="p1">
                    <p id="129">亮度实验阈值。假设<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><msup><mi>k</mi><mo>′</mo></msup></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>p</mi><msub><mrow></mrow><msup><mi>n</mi><mo>′</mo></msup></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>, 表示第<i>k</i>′个PCC一共包含<i>n</i>′个元素。统计这个PCC中对应的像素强度不满足 (6) 式的强度规则的像素数目占比, 当这个占比大于给定的阈值<i>ω</i>时, 就认为这个PCC为目标PCC, 否则为阴影PCC。<i>M</i><sub>1</sub>表示检测出的目标PCC, <i>M</i><sub>0</sub>表示所有的PCC, 如图1所示。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131">2) Δ<i>μ</i>:</h4>
                <div class="p1">
                    <p id="132">PCC均值超越阈值。这里的均值超越表示的是在PB-PCC和PC-PCC中像素点任意两个通道均值大小顺序颠倒。考虑到噪声的存在, 如果两个通道均值差值小于Δ<i>μ</i>, 则发生的均值超越不考虑。这一步将<i>M</i><sub>1</sub>再分类, 得到的运动目标PCC为<i>M</i><sub>2</sub>, 新的阴影候选PCC集合为∁<sub><i>V</i></sub><i>M</i><sub>2</sub>=<i>W</i>, 如图1所示。</p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">3) Δ<i>σ</i>:</h4>
                <div class="p1">
                    <p id="134">Δ<i>σ</i>表示PCC在三个通道的标准差偏差率阈值。如果PB-PCC和PC-PCC的至少一个通道标准差变化率Δ<i>k</i><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>X</mi><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup></mrow></math></mathml>大于<i>Δ</i>σ, 该<i>PCC</i>被分类为目标<i>PCC</i>。其中, </p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>k</mi><msubsup><mrow></mrow><mi>X</mi><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mi>X</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mi>X</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><mrow><mi>min</mi><mo stretchy="false"> (</mo><mi>σ</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mi>X</mi></mrow></msub><mo>, </mo><mi>σ</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mi>X</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">式中, <i>Δ</i>k<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>X</mi><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup></mrow></math></mathml>表示的是在<i>rgb</i>颜色空间中, <i>PB</i>-<i>PCC</i>和<i>PC</i>-<i>PCC</i>在X通道的标准差变化率。具体分类依据为</p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>c</mtext><mtext>u</mtext><mtext>r</mtext><mtext>r</mtext><mtext>e</mtext><mtext>n</mtext><mtext>t</mtext><mspace width="0.25em" /><mtext>Ρ</mtext><mtext>C</mtext><mtext>C</mtext><mspace width="0.25em" /><mtext>i</mtext><mtext>s</mtext><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext><mtext>e</mtext><mtext>c</mtext><mtext>t</mtext><mspace width="0.25em" /><mtext>Ρ</mtext><mtext>C</mtext><mtext>C</mtext><mo>, </mo><mspace width="0.25em" /><mtext>i</mtext><mtext>f</mtext><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mtext>Δ</mtext><mi>k</mi><msubsup><mrow></mrow><mtext>r</mtext><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup><mo>&gt;</mo><mtext>Δ</mtext><mi>σ</mi><mspace width="0.25em" /><mtext>o</mtext><mtext>r</mtext></mtd></mtr><mtr><mtd columnalign="left"><mtext>Δ</mtext><mi>k</mi><msubsup><mrow></mrow><mtext>g</mtext><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup><mo>&gt;</mo><mtext>Δ</mtext><mi>σ</mi><mspace width="0.25em" /><mtext>o</mtext><mtext>r</mtext></mtd></mtr><mtr><mtd columnalign="left"><mtext>Δ</mtext><mi>k</mi><msubsup><mrow></mrow><mtext>b</mtext><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup><mo>&gt;</mo><mtext>Δ</mtext><mi>σ</mi></mtd></mtr></mtable></mrow></mrow></mtd></mtr><mtr><mtd columnalign="left"><mtext>s</mtext><mtext>h</mtext><mtext>a</mtext><mtext>d</mtext><mtext>o</mtext><mtext>w</mtext><mspace width="0.25em" /><mtext>c</mtext><mtext>a</mtext><mtext>n</mtext><mtext>d</mtext><mtext>i</mtext><mtext>d</mtext><mtext>a</mtext><mtext>t</mtext><mtext>e</mtext><mspace width="0.25em" /><mtext>Ρ</mtext><mtext>C</mtext><mtext>C</mtext><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext><mtext>s</mtext></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 PCC分类过程示意图" src="Detail/GetImg?filename=images/GXXB201903030_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 <i>PCC</i>分类过程示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>Illustration of PCC classification process</i></p>

                </div>
                <div class="p1">
                    <p id="141">实验中将W中的<i>PCC</i>进行再分类, 得到的运动目标<i>PCC</i>为M<sub>3</sub>, 而新的阴影候选<i>PCC</i>集合为∁<sub>W</sub>M<sub>3</sub>=X, 如图1所示。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142">4) τ<sub>k</sub>:</h4>
                <div class="p1">
                    <p id="143">在文献<citation id="234" type="reference">[<a class="sup">5</a>]</citation>中称之为像素终点权重阈值。这里将这一标准应用于<i>PCC</i>中。其中<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>是阴影候选<i>PCC</i> S<sub>k</sub> (S<sub>k</sub>表示一个<i>PCC</i>对应的边界点) 外部终点像素点的个数, 也就是, <i>PCC</i> S<sub>k</sub>的边缘点与非运动目标<i>PCC</i>相靠近的点的数目。t<sub>k</sub>s<sub>k</sub>表示<i>PCC</i> S<sub>k</sub>所有的边界点个数:</p>
                </div>
                <div class="p1">
                    <p id="145" class="code-formula">
                        <mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>t</mi><msub><mrow></mrow><mi>k</mi></msub><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mfrac><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="146">通过以上分类过程, 由于光照导致的亮度与标准差变化非常明显, 运动目标的边缘侧<i>PCC</i>已经被正确地分类。但位于目标内部的阴影伪装区域未能被有效地识别出来。所以引入了<i>PCC</i>相对位置信息的衡量指标τ<sub>k</sub>。这样, 阴影<i>PCC</i>的像素终点权重偏大, 而目标内部的<i>PCC</i>像素终点权重很小。</p>
                </div>
                <div class="p1">
                    <p id="147">在不同的视频序列将X中的<i>PCC</i>进行再次分类, 可得到运动目标<i>PCC</i> M<sub>4</sub>和最终的阴影<i>PCC</i>集合为∁<sub>X</sub>M<sub>4</sub>=Y。到这里本研究得到了最终的阴影<i>PCC</i>为Y和目标<i>PCC</i> (M<sub>1</sub>, M<sub>2</sub>, M<sub>3</sub>, M<sub>4</sub>) , 如图1所示, 运动目标<i>PCC</i>的分类已经完成, 将在实验部分对分类过程的4个参数设置进行详细介绍。接下来, 将对分类后的阴影<i>PCC</i>和目标<i>PCC</i>分别进行区域生长, 并对生长后的目标<i>PCC</i>进行前景目标掩码融合, 进一步得到完整的目标区域。</p>
                </div>
                <h3 id="148" name="148" class="anchor-tag">3 阴影检测与目标掩码增长</h3>
                <h4 class="anchor-tag" id="149" name="149"><b>3.1 完整阴影检测与目标掩码增长框架</b></h4>
                <div class="p1">
                    <p id="150">由于超像素更有利于局部特征的提取与结构信息的表达, 本研究采用基于图的分割方法, 可得到当前图像若干超像素区域。利用所提算法进行阴影检测的前提是图像中的每一个像素点的强度值服从高斯分布<citation id="235" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。采用Change Detection<citation id="236" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>数据集中BusStation序列的第1047帧作为实验对象进行阐述, 完整移动阴影检测与目标掩码增长框架, 如图2所示, 共包含4个步骤。</p>
                </div>
                <div class="p1">
                    <p id="151">步骤1 区域轮廓内的点集合的创建 (图2 part 1) 。使用Graph-Based方法<citation id="237" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、ViBe算法和区域轮廓的提取方法, 获取当前帧图像中运动目标区域轮廓内的点坐标集合, 包括阴影PCC和目标PCC。</p>
                </div>
                <div class="p1">
                    <p id="152">步骤2 区域轮廓内的点集合分类 (图2 part 2) 。这一部分通过4个步骤实现PB-PCC和PC-PCC的分类。</p>
                </div>
                <div class="p1">
                    <p id="153">步骤3 阴影PCC区域生长 (图2 part 3) 。设置生长条件, 对阴影PCC进行基于超像素和基于轮廓边缘的区域生长, 可检测到完整的阴影区域。</p>
                </div>
                <div class="p1">
                    <p id="154">步骤4 目标PCC区域生长与目标掩码融合 (图2 part 4) 。对目标前景PCC进行基于超像素的区域生长 (生长后包含目标掩码增长部分的像素点) , 并将生长结果与ViBe掩码中的目标部分进行融合, 最终可得到增长后的完整的目标区域。</p>
                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 阴影检测与目标掩码增长框架" src="Detail/GetImg?filename=images/GXXB201903030_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 阴影检测与目标掩码增长框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Framework of shadow detection and object mask growth</p>

                </div>
                <h4 class="anchor-tag" id="156" name="156"><b>3.2 完整阴影检测与目标掩码增长算法</b></h4>
                <div class="p1">
                    <p id="157">在图2中的步骤2, 利用阴影区域辐射一致性属性的统计参数, 对PCC进行分类。再对分类后的阴影PCC和目标PCC分别进行区域生长, 可进一步得到完整的目标区域和完整的阴影区域, 算法流程如图3所示。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 区域生长和ViBe目标掩码融合示意图" src="Detail/GetImg?filename=images/GXXB201903030_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 区域生长和ViBe目标掩码融合示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Illustration of region growth and Vibe object mask fusion</p>

                </div>
                <div class="p1">
                    <p id="159">图3所示为区域生长与掩码融合的示意图, 为了使阴影区域、目标区域生长和掩码融合技术更加形象, 在图4中给出了超像素分割区域生长的每一步的中间结果。</p>
                </div>
                <div class="p1">
                    <p id="160">区域生长是图像分割技术的一种, 其基本思想是在一定条件下将具有相似性的像素合并到一个区域。该技术需要先选择区域生长的种子点, 并在种子点的8邻域对符合生长条件的像素进行合并, 新的像素又会作为新的种子继续生长。这里将ViBe掩码区域内的点作为生长的种子点, 并对阴影PCC和目标PCC分别设置不同的生长条件。</p>
                </div>
                <div class="p1">
                    <p id="161">阴影区域生长一共包含两个阶段。</p>
                </div>
                <div class="p1">
                    <p id="162">阶段一为基于超像素的阴影PCC生长。这个阶段是将每一个阴影区域内的任意一个像素作为种子点, 将图4 (b) 中的像素点生长为阴影点需要满足以下4个条件:1) 该点与阴影PCC内对应的点位于图4 (b) 中的同一个超像素中;2) 该点位于运动目标掩码外轮廓[图4 (d) 黑色轮廓线]内部, 这样可以避免图像分割不准确导致的生长出界问题;3) 该点没有生长到目标PCC附近邻域;4) 该点在ViBe掩码结果中被标记为运动目标。这样, 就得到了图4 (e) 中绿色标记的像素, 阴影PCC区域生长第一阶段结束。</p>
                </div>
                <div class="p1">
                    <p id="163">阶段二为基于超像素分割区域轮廓点的区域生长。这个阶段是将每一个阴影PCC边界的每一个点作为种子, 将图4 (b) 中的像素点生长为阴影点需要满足以下三个条件:1) 该点在ViBe掩码结果中被标记为运动目标;2) 该点位于运动目标掩码外轮廓[图4 (d) 黑色轮廓线]内部;3) 该点在阶段一中没有被生长。在这个阶段中, 能够得到由前期的形态学腐蚀掉的和超像素边缘的模糊分割导致的阴影像素的漏分割点, 这一部分生长的像素点为图4 (f) 中的红色部分。通过以上两个阶段, 可得到完整的阴影区域, 如图4 (f) 所示。</p>
                </div>
                <div class="p1">
                    <p id="164">目标PCC生长与阴影PCC生长的第一个阶段类似, 不同之处在于第3) 点为“没有生长到阴影区域附近邻域”, 生长后的结果为图4 (g) 中的紫色部分。</p>
                </div>
                <div class="p1">
                    <p id="165">经过超像素阴影PCC的两次区域生长得到了完整的阴影区域, 接着, 对ViBe掩码与完整的阴影区域进行差运算得到ViBe目标掩码, 对应图3中的“差运算”部分。对“差运算”输出部分与图4 (g) 中的紫色部分求或运算, 可得到最终完整的前景目标部分, 对应图3中的“或运算”部分。这种技术为反向前景目标掩码增长技术, 可用于实现前景目标的增长, 使检测目标更加完整。</p>
                </div>
                <div class="area_img" id="166">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 区域生长与目标掩码融合结果。" src="Detail/GetImg?filename=images/GXXB201903030_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 区域生长与目标掩码融合结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 (a) Result of region growth and mask fusion.</p>
                                <p class="img_note"> (b) Ground truth图像; (b) 超像素分割图; (c) 运动目标分割图; (d) 分类后的PCC结果; (e) 阴影PCC一阶段生长结果 (绿色部分) ; (f) 阴影PCC二阶段生长结果 (红色部分) ; (g) 目标PCC生长结 果; (h) 目标掩码融合结果</p>
                                <p class="img_note"> (a) Ground truth image; (b) super-pixel segmentation image; (c) segmentation of moving object; (d) classified PCC result; (e) first stage of shadow PCC growth (green part) ; (f) second stage of shadow PCC growth (red part) ; (g) result of object PCC growth; (h) result of object mask fusion</p>

                </div>
                <h3 id="168" name="168" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="169" name="169"><b>4.1 参数分析</b></h4>
                <div class="p1">
                    <p id="170">在2.3小节中, 经过4个步骤对目标前景区域和阴影区域进行分类。方法中涉及到几个必须要依据场景的不同而需要设定的参数。</p>
                </div>
                <h4 class="anchor-tag" id="171" name="171">1) PCC亮度检测中的阈值:</h4>
                <div class="p1">
                    <p id="172">对应于图2中的亮度检测, <i>ω</i>取值应满足</p>
                </div>
                <div class="p1">
                    <p id="173" class="code-formula">
                        <mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>n</mi><mo>×</mo><mn>5</mn><mi>%</mi><mo>, </mo></mtd><mtd columnalign="left"><mi>n</mi><mo>&gt;</mo><mn>2</mn><mn>0</mn><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>2</mn><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext><mtext>s</mtext></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="174">式中<i>n</i>为当前PCC内元素的个数。</p>
                </div>
                <h4 class="anchor-tag" id="175" name="175">2) PCC均值超越阈值Δ<i>μ</i>:</h4>
                <div class="p1">
                    <p id="176">对于同一个视频序列的不同PCC采用相同的数值。在不同序列中, 根据阴影强度, 选择合适的值。</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177">3) PCC标准差偏差率阈值Δ<i>σ</i>:</h4>
                <div class="p1">
                    <p id="178">对于不同的PCC, 实验中参数取值范围为[0.4, <i>ζ</i>]。其中, <i>ζ</i>理论上可以无限大, 这对应两个标准差偏差率的无限大。在实际应用中, 这个参数与图像分割精度直接相关。例如, 对于目标PCC而言, 图像分割越精细, min (<i>σ</i><sub>B<i>X</i></sub>, <i>σ</i><sub>C<i>X</i></sub>) 会越小, 而<mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mi>X</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mi>X</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>中的σ<sub><i>B</i>X</sub>会较大, 最终导致<i>Δ</i>k<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>X</mi><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup></mrow></math></mathml>很大。而对于阴影<i>PCC</i>, <mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mi>X</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mi>X</mi></mrow></msub></mrow><mo>|</mo></mrow><mo>→</mo><mn>0</mn></mrow></math></mathml>恒成立, 使得Δ<i>k</i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>X</mi><mrow><mtext>B</mtext><mtext>C</mtext></mrow></msubsup></mrow></math></mathml>偏小。</p>
                </div>
                <h4 class="anchor-tag" id="183" name="183">4) 边界点终点权重阈值τ<sub>k</sub>:</h4>
                <div class="p1">
                    <p id="184">在不同的视频序列中目标阴影形状大小各不相同, 在本研究的实验中τ<sub>k</sub>的取值范围一般为70%～80%, 这与所选择的视频序列中阴影区域具体形状有关。</p>
                </div>
                <div class="p1">
                    <p id="185">不同的视频序列中的目标形状和阴影形状等外部参数千变万化, 导致不同场景中的数据分布有着明显的差异。因此, 对每一个视频序列设置自定义的参数标准, 这需要根据经验值进行测试, 而一旦得到优化的参数范围, 就会在该类型视频序列中有均衡的表现, 图5所示为相同的参数在<i>Highway I</i>序列中的不同帧的实验结果。</p>
                </div>
                <div class="area_img" id="186">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 highway I序列实验结果" src="Detail/GetImg?filename=images/GXXB201903030_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 <i>highway I</i>序列实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 5 <i>Experimental results of highway I sequence</i></p>

                </div>
                <h4 class="anchor-tag" id="187" name="187"><b>4.2 实验验证</b></h4>
                <h4 class="anchor-tag" id="188" name="188">1) 定性实验:</h4>
                <div class="p1">
                    <p id="189">在公开数据集中选取6个视频序列, 通过记录所提算法每一步处理的中间过程, 定性说明所提算法在阴影检测方面的有效性, 详细结果如图6所示。其中:A′～D′分别为输入图像、ViBe掩码、掩码分割结果、超像素区域轮廓内的点集合图像;E1～E4分别为对PCC分类的4个步骤;F1、F2分别为阴影区域生长的两个阶段;G′为ViBe掩码减去F2的结果;H′为掩码融合后的目标掩码。</p>
                </div>
                <h4 class="anchor-tag" id="190" name="190">2) 定量实验:</h4>
                <div class="p1">
                    <p id="191">定量评估实验基于Prati等<citation id="238" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>介绍的用于评估投影检测算法性能的两个度量标准:阴影检测率<i>r</i><sub>s</sub>和阴影识别率<i>ξ</i>。这两个指标定义式为</p>
                </div>
                <div class="p1">
                    <p id="192" class="code-formula">
                        <mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>r</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo>=</mo><mfrac><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>S</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>ξ</mi><mo>=</mo><mfrac><mrow><mover accent="true"><mi>F</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>F</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>F</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="193">式中, <i>S</i>和<i>F</i>分别表示阴影像素点和前景目标像素点, <i>S</i><sub>TP</sub>表示正确分类的阴影像素点个数, <i>S</i><sub>FN</sub>表示被错误检测为其他类型的阴影像素点个数, <i>F</i><sub>TP</sub>表示被检测为前景点的像素点的个数, <mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>F</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow></math></mathml>表示前景像素点数目与被误检为阴影的前景像素点数目的差值, <i>F</i><sub>FN</sub>表示前景目标像素点被检测为其他类型点的个数。阴影检测率为正确检测出阴影像素点的指标, 而阴影识别率表征非阴影像素点被误分类为阴影点的可能性。本研究采用这两个指标在多个图像序列中的平均值作为他们各自的统计值。</p>
                </div>
                <div class="area_img" id="195">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_195.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同场景下的算法处理过程" src="Detail/GetImg?filename=images/GXXB201903030_195.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同场景下的算法处理过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_195.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Algorithm processing in different scenarios</p>

                </div>
                <div class="p1">
                    <p id="196">需要注意的是, 本研究进行阴影检测的基础是前期已经检测到了ViBe掩码区域。将该掩码区域和ground truth求与之后的结果作为本研究统计阴影检测与目标掩码增长性能指标的ground truth。这样做的目的在于突出阴影检测算法在ViBe中的检测精度。如果ViBe掩码检测率较低, 在这个掩码的基础上进行阴影检测时, 检测到的阴影像素点必然少, 若以原始ground truth作为统计精确率的基础, 必然会掩盖所提算法在ViBe中的检测率。反之, 如果将ViBe掩码与ground truth求与之后的结果作为新的ground truth, 并仅仅用于计算阴影检测率, 会彰显出在所提方法在ViBe基础上的阴影检测精度。 所提算法仅仅统计包含在原始ground truth中的并且被ViBe检测到的部分的阴影检测率。</p>
                </div>
                <div class="p1">
                    <p id="197">表1所示为5种方法在Campus、Hallway、Highway I、Lab和BusStation等5个视频序列中的实验统计结果。</p>
                </div>
                <div class="area_img" id="198">
                    <p class="img_tit">表1 5种算法的评价结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Appraisal results of five algorithms %</p>
                    <p class="img_note"></p>
                    <table id="198" border="1"><tr><td rowspan="3"><br />Method</td><td colspan="10"><br />Performance</td></tr><tr><td colspan="2"><br />Campus</td><td colspan="2">Hallway</td><td colspan="2">Highway I</td><td colspan="2">Lab</td><td colspan="2">BusStation</td></tr><tr><td><br /><i>r</i><sub>s</sub></td><td><i>ξ</i></td><td><i>r</i><sub>s</sub></td><td><i>ξ</i></td><td><i>r</i><sub>s</sub></td><td><i>ξ</i></td><td><i>r</i><sub>s</sub></td><td><i>ξ</i></td><td><i>r</i><sub>s</sub></td><td><i>ξ</i></td></tr><tr><td><br />Ref. [26]</td><td>35.33</td><td>86.82</td><td>78.43</td><td>69.49</td><td>57.84</td><td>82.48</td><td>46.33</td><td>85.88</td><td>80.79</td><td>63.5</td></tr><tr><td><br />Ref. [27]</td><td>57.38</td><td>48.08</td><td>82.53</td><td>81.72</td><td>86.23</td><td>58.68</td><td>82.87</td><td>75.08</td><td>88.61</td><td>61.5</td></tr><tr><td><br />Ref. [28]</td><td>79.99</td><td>58.92</td><td>55.17</td><td>79.8</td><td>64.05</td><td>82.29</td><td>52.49</td><td>80.54</td><td>85.3</td><td>53.52</td></tr><tr><td><br />Ref. [29]</td><td>78.67</td><td>58.14</td><td>84.56</td><td>78.75</td><td>91.00</td><td>58.14</td><td>59.12</td><td>81.35</td><td>73.24</td><td>84.24</td></tr><tr><td><br />Proposed method</td><td>80.98</td><td>88.2</td><td>83.13</td><td>85.79</td><td>86.01</td><td>82.53</td><td>79.54</td><td>85.81</td><td>83.13</td><td>88.95</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="199">由表1可以看出, 采用了4种经典的算法进行定量对比实验:文献<citation id="239" type="reference">[<a class="sup">26</a>]</citation>的SRtexture 方法, 文献<citation id="240" type="reference">[<a class="sup">28</a>]</citation>的Geometry方法, 文献<citation id="241" type="reference">[<a class="sup">29</a>]</citation>的 LRtexture 方法和文献<citation id="242" type="reference">[<a class="sup">27</a>]</citation>的Chromacity 方法。采用了Campus, Hallway, Highway I, Lab 和BusStation场景进行了定量实验。所提方法在阴影检测准确率和阴影识别率中的表现能够同时达到最好, 由图6可知, 由于浅阴影对背景信息的保留程度较大, 所以这一类的阴影检测率偏高, 而深度阴影的检测率相对偏低。其他4个算法在这两个指标中均不能同时保证最佳。</p>
                </div>
                <div class="p1">
                    <p id="200">为了衡量所提方法在掩码增长中的表现, 定义目标增长率<i>γ</i>和增长准确率<i>δ</i>, 对应的表达式为</p>
                </div>
                <div class="p1">
                    <p id="201" class="code-formula">
                        <mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>γ</mi><mo>=</mo><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ο</mi><msubsup><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow><mrow><mtext>Μ</mtext><mtext>A</mtext><mtext>S</mtext><mtext>Κ</mtext></mrow></msubsup></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>δ</mi><mo>=</mo><mfrac><mrow><mover accent="true"><mi>Ο</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>S</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="202">式中, <i>O</i><sub>TP</sub>表示相对于ViBe目标掩码而言所提方法对目标区域增长的像素点个数, <i>O</i><mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow><mrow><mtext>Μ</mtext><mtext>A</mtext><mtext>S</mtext><mtext>Κ</mtext></mrow></msubsup></mrow></math></mathml>表示ViBe掩码中属于目标的像素点个数, <mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ο</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow></math></mathml>表示增长的像素点中真正属于目标的像素点个数, <i>S</i><sub>FN</sub>表示增长的像素点中属于阴影或背景的像素点个数。这样, <i>γ</i>表示增长的强度, 而<i>δ</i>表示目标前景区域增长率为<i>γ</i>时对应的准确率。</p>
                </div>
                <div class="p1">
                    <p id="205">对比实验结果表明, 在相同的测试序列下, 所提方法的阴影检测率与阴影识别率最高。与此同时, 由表2可以看出, 所提方法还对运动目标进行了增长, 增长部分有较高的准确率。图7所示为所提方法与其他4种算法在输入图像相同时得到的检测结果。可以看出, 在另外4种方法中Chromacity方法有较高的阴影检测率, 而所提算法在7个场景中均表现优异。</p>
                </div>
                <div class="area_img" id="206">
                    <p class="img_tit">表2 目标掩码增长率与精度 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Growth rate and accuracy of object mask</p>
                    <p class="img_note"></p>
                    <table id="206" border="1"><tr><td rowspan="2"><br />Parameter</td><td colspan="5"><br />Video sequence</td></tr><tr><td><br />Campus</td><td>Hallway</td><td>Highway I</td><td>Lab</td><td>BusStation</td></tr><tr><td><br /><i>γ</i></td><td>11.44</td><td>8.69</td><td>3.93</td><td>11.83</td><td>8.32</td></tr><tr><td><br /><i>δ</i></td><td>96.75</td><td>95.52</td><td>96.81</td><td>95.34</td><td>94.25</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="207">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903030_207.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 5种算法下的检测结果" src="Detail/GetImg?filename=images/GXXB201903030_207.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 5种算法下的检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903030_207.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Test results of 5 algorithms</p>

                </div>
                <h3 id="208" name="208" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="209">为了解决移动阴影检测的难题, 提出了一个新的阴影检测与目标掩码增长框架。提出的阴影区域辐射一致性属性及统计参数有助于准确区分真实运动目标区域与移动阴影区域。提出了在超像素内部和PCC边缘的掩码生长策略, 使用该策略实现了完整阴影区域的检测和运动目标前景区域的增长, 提升了阴影区域和目标区域的完整性。采用阴影检测率、阴影识别率和目标增长率等定量评价指标, 将所提算法与4种阴影检测算法进行定量对比, 验证了所提算法的移动阴影的检测精度较好, 目标掩码增长的准确性较高。</p>
                </div>
                <div class="p1">
                    <p id="210">所提方法的不足之处在于没有实现PCC分类中的参数自适应化, 以及没有给出如何针对过小的PCC进行准确分类。后续研究将重点针对以上不足进行方法改进。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="9">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705025&amp;v=MjI3MDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlIblViM0xJalhUYkxHNEg5Yk1xbzlIWVlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Li S S, Zhao G P, Wang J Y. Distractor-aware object tracking based on multi-feature fusion and scale-adaption[J]. Acta Optica Sinica, 2017, 37 (5) : 0515005. 李双双, 赵高鹏, 王建宇. 基于特征融合和尺度自适应的干扰感知目标跟踪[J]. 光学学报, 2017, 37 (5) : 0515005.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201606025&amp;v=MDk5MzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlIblViM0xJalhUYkxHNEg5Zk1xWTlIWVlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Mo S W, Deng X P, Wang S, <i>et al</i>. Moving object detection algorithm based on improved visual background extractor[J]. Acta Optica Sinica, 2016, 36 (6) : 0615001. 莫邵文, 邓新蒲, 王帅, 等. 基于改进视觉背景提取的运动目标检测算法[J]. 光学学报, 2016, 36 (6) : 0615001.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201710031&amp;v=MTM5NzdiM0xJalhUYkxHNEg5Yk5yNDlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlIblU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Liu F, Shen T S, Ma X X. Convolutional neural network based multi-band ship target recognition with feature fusion[J]. Acta Optica Sinica, 2017, 37 (10) : 1015002. 刘峰, 沈同圣, 马新星. 特征融合的卷积神经网络多波段舰船目标识别[J]. 光学学报, 2017, 37 (10) : 1015002.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Moving Objects detection with freely moving camera via background motion subtraction">

                                <b>[4]</b> Wu Y Y, He X H, Nguyen T Q. Moving object detection with a freely moving camera via background motion subtraction[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (2) : 236-248.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate Moving Cast Shadow Suppression Based on Local Color Constancy Detection">

                                <b>[5]</b> Amato A, Mozerov M G, Bagdanov A D, <i>et al</i>. Accurate moving cast shadow suppression based on local color constancy detection[J]. IEEE Transactions on Image Processing, 2011, 20 (10) : 2954-2966.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737947&amp;v=MDIzMDZ3V2FCRT1OaWZPZmJLN0h0RE5xWTlGWStnSUJYZytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lLVg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Sanin A, Sanderson C, Lovell B C. Shadow detection: A survey and comparative evaluation of recent methods[J]. Pattern Recognition, 2012, 45 (4) : 1684-1695.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Physical models for moving shadow and object detection in video">

                                <b>[7]</b> Nadimi S, Bhanu B. Physical models for moving shadow and object detection in video[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (8) : 1079-1087.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A simple algorithm of superpixel segmentation with boundary constraint">

                                <b>[8]</b> Zhang Y, Li X, Gao X, <i>et al</i>. A simple algorithm of superpixel segmentation with boundary constraint[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 27 (7) : 1502-1514.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast appearance modeling for automatic primary video object segmentation">

                                <b>[9]</b> Yang J, Price B, Shen X H, <i>et al</i>. Fast appearance modeling for automatic primary video object segmentation[J]. IEEE Transactions on Image Processing, 2016, 25 (2) : 503-515.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature-based image patch classification for moving shadow detection">

                                <b>[10]</b> Russell M, Zou J J, Fang G, <i>et al</i>. Feature-based image patch classification for moving shadow detection[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2017, 14 (8) : 1-14.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting moving objects, ghosts, and shadows in video streams">

                                <b>[11]</b> Cucchiara R, Grana C, Piccardi M, <i>et al</i>. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Enhanced Segmentation on Vision-Based Shadow Removal for Vehicle Detection">

                                <b>[12]</b> Chen C T, Su C Y, Kao W C. An enhanced segmentation on vision-based shadow removal for vehicle detection[C]//The 2010 International Conference on Green Circuits and Systems, June 21-23, 2010, Shanghai, China. New York: IEEE, 2010: 679-682.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Strong shadow removal via patch-based shadow edge detection">

                                <b>[13]</b> Wu Q, Zhang W D, Vijaya Kumar B V K. Strong shadow removal via patch-based shadow edge detection[C]//2012 IEEE International Conference on Robotics and Automation, May 14-18, 2012, Saint Paul, MN, USA. New York: IEEE 2012: 2177-2182.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14032300121488&amp;v=MzE2NzN5am1VYi9JS1Z3V2FCRT1OaWZPZmJLOEh0TE9ySTlGWmVrT0NIUXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Wang J, Wang Y H, Jiang M, <i>et al</i>. Moving cast shadow detection using online sub-scene shadow modeling and object inner-edges analysis[J]. Journal of Visual Communication and Image Representation, 2014, 25 (5) : 978-993.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Moving cast shadow detection using physics-based features">

                                <b>[15]</b> Huang J B, Chen C S. Moving cast shadow detection using physics-based features[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition, June 20-25, 2009, Miami, FL, USA. New York: IEEE, 2009: 2310-2317.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning to Detect Moving Shadows in Dynamic Environments">

                                <b>[16]</b> Joshi A J, Papanikolopoulos N P. Learning to detect moving shadows in dynamic environments[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (11) : 2055-2063.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel region-based method for moving shadow detection">

                                <b>[17]</b> Russell M, Zou J J, Fang G. A novel region-based method for moving shadow detection[C]∥2016 International Conference on Digital Image Computing: Techniques and Applications, November 30-December 2, 2016, Gold Coast, QLD, Australia. New York: IEEE, 2016: 1-6.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Region-based moving shadow detection using affinity propagation">

                                <b>[18]</b> Dai J Y, Han D Y. Region-based moving shadow detection using affinity propagation[J]. International Journal of Signal Processing, Image Processing and Pattern Recognition, 2015, 8 (3) : 65-74.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ViBe: A Universal Background Subtraction Algorithm for Video Sequences">

                                <b>[19]</b> Barnich O, van Droogenbroeck M. ViBe: A universal background subtraction algorithm for video sequences[J]. IEEE Transactions on Image Processing, 2011, 20 (6) : 1709-1724.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning flexible graph-based semi-supervised embedding">

                                <b>[20]</b> Dornaika F, El Traboulsi Y. Learning flexible graph-based semi-supervised embedding[J]. IEEE Transactions on Cybernetics, 2015, 46 (1) : 206-218.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Road traffic: Vehicle detection and classification">

                                <b>[21]</b> Aqel S, Hmimid A, Sabri M A, <i>et al</i>. Road traffic: Vehicle detection and classification[C]∥2017 Intelligent Systems and Computer Vision (ISCV) , April 17-19, 2017, Fez, Morocco. New York: IEEE, 2017: 1-5.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-Time Vehicle Shadow Detection">

                                <b>[22]</b> Russell M, Fang G, Zou J J. Real-time vehicle shadow detection[J]. Electronics Letters, 2015, 51 (16) : 1253-1255.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3E42DCF6F3126A66A139CB9DD9CFF942&amp;v=MjIzODZ4ME93M3IyR1k4Q3NUaVRMNmRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh6YnE5d3FzPU5pZk9mYkROR3RPNDNQbERFdWdPRG5wSXlSQmk2eg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> Amirmazlaghani M, Rezghi M, Amindavar H. A novel robust scaling image watermarking scheme based on Gaussian Mixture Model[J]. Expert Systems with Applications, 2015, 42 (4) : 1960-1971.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Changedetection.net:A new change detection benchmark dataset">

                                <b>[24]</b> Goyette N, Jodoin P M, Porikli F, <i>et al</i>. Changedetection. net: A new change detection benchmark dataset[C]∥2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 1-8.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting moving shadows: algorithms and evaluation">

                                <b>[25]</b> Prati A, Mikic I, Trivedi M M, <i>et al</i>. Detecting moving shadows: Algorithms and evaluation[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (7) : 918-923.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739565&amp;v=MDUwMjFiL0lLVndXYUJFPU5pZk9mYks3SHRETnFZOUZZK2dHQ1hvOG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> Leone A, Distante C. Shadow detection for moving objects based on texture analysis[J]. Pattern Recognition, 2007, 40 (4) : 1222-1233.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting moving objects, ghosts, and shadows in video streams">

                                <b>[27]</b> Cucchiara R, Grana C, Piccardi M, <i>et al</i>. Detecting moving objects, ghosts, and shadows in video streams[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003, 25 (10) : 1337-1342.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_28" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349953&amp;v=Mjg3NDVlWnVIeWptVWIvSUtWd1dhQkU9TmlmT2ZiSzdIdERPclk5RVorOEdCWGs2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[28]</b> Hsieh J W, Hu W F, Chang C J, <i>et al</i>. Shadow elimination for effective moving object detection by Gaussian shadow modeling[J]. Image and Vision Computing, 2003, 21 (6) : 505-516.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Shadow Removal for Robust Person Tracking in Surveillance Scenarios">

                                <b>[29]</b> Sanin A, Sanderson C, Lovell B C. Improved shadow removal for robust person tracking in surveillance scenarios[C]//2010 20th International Conference on Pattern Recognition, August 23-26, 2010, Istanbul, Turkey. New York: IEEE, 2010: 141-144.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201903030" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903030&amp;v=MjE1MzgzTElqWFRiTEc0SDlqTXJJOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhuVWI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

