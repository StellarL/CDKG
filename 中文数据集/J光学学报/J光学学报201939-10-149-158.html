

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133089472627500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dGXXB201910018%26RESULT%3d1%26SIGN%3dWNXiSWYnUZUs5KBPfT3G3%252fWFKzg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201910018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910018&amp;v=MTYzNjBGckNVUkxPZVplVnZGeXJtVUx6UElqWFRiTEc0SDlqTnI0OUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="2 基本原理 ">2 基本原理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;2.1 大气散射模型&lt;/b&gt;"><b>2.1 大气散射模型</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;2.2 CNN&lt;/b&gt;"><b>2.2 CNN</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="3 本文方法 ">3 本文方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 网络模型设计&lt;/b&gt;"><b>3.1 网络模型设计</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;3.2 损失函数&lt;/b&gt;"><b>3.2 损失函数</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;3.3 大气光计算&lt;/b&gt;"><b>3.3 大气光计算</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;3.4 恢复无雾图像&lt;/b&gt;"><b>3.4 恢复无雾图像</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;3.5 算法步骤&lt;/b&gt;"><b>3.5 算法步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="4 实验及结果分析 ">4 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#96" data-title="&lt;b&gt;4.1 训练数据集&lt;/b&gt;"><b>4.1 训练数据集</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;4.2 合成有雾图像的实验结果&lt;/b&gt;"><b>4.2 合成有雾图像的实验结果</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;4.3 真实有雾图像的实验结果&lt;/b&gt;"><b>4.3 真实有雾图像的实验结果</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;4.4 运行时间&lt;/b&gt;"><b>4.4 运行时间</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#114" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="图1 大气散射物理模型">图1 大气散射物理模型</a></li>
                                                <li><a href="#66" data-title="图2 MSDN模型图">图2 MSDN模型图</a></li>
                                                <li><a href="#70" data-title="图3 激活函数比较。">图3 激活函数比较。</a></li>
                                                <li><a href="#75" data-title="表1 多尺度特征提取卷积核参数表">表1 多尺度特征提取卷积核参数表</a></li>
                                                <li><a href="#93" data-title="图4 本文算法步骤">图4 本文算法步骤</a></li>
                                                <li><a href="#100" data-title="图5 训练数据集。">图5 训练数据集。</a></li>
                                                <li><a href="#102" data-title="图6 合成有雾图像的实验结果。">图6 合成有雾图像的实验结果。</a></li>
                                                <li><a href="#106" data-title="表2 合成有雾图像的实验结果数据分析">表2 合成有雾图像的实验结果数据分析</a></li>
                                                <li><a href="#107" data-title="图7 真实室外有雾图像的实验结果。 ">图7 真实室外有雾图像的实验结果。 </a></li>
                                                <li><a href="#110" data-title="表3 室外有雾图像的实验结果数据分析">表3 室外有雾图像的实验结果数据分析</a></li>
                                                <li><a href="#113" data-title="表4 不同实验图像的算法运行时间">表4 不同实验图像的算法运行时间</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="289">


                                    <a id="bibliography_1" title=" Wu D,Zhu Q S.The latest research progress of image dehazing[J].Acta Automatica Sinica,2015,41(2):221-239.吴迪,朱青松.图像去雾的最新研究进展[J].自动化学报,2015,41(2):221-239." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201502001&amp;v=MjU5MTh6UEtDTGZZYkc0SDlUTXJZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXJtVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Wu D,Zhu Q S.The latest research progress of image dehazing[J].Acta Automatica Sinica,2015,41(2):221-239.吴迪,朱青松.图像去雾的最新研究进展[J].自动化学报,2015,41(2):221-239.
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_2" title=" Xu Y,Wen J,Fei L K,et al.Review of video and image defogging algorithms and related studies on image restoration and enhancement[J].IEEE Access,2016,4:165-188." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Review of video and image defogging algorithms and related studies on image restoration and enhancement">
                                        <b>[2]</b>
                                         Xu Y,Wen J,Fei L K,et al.Review of video and image defogging algorithms and related studies on image restoration and enhancement[J].IEEE Access,2016,4:165-188.
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_3" title=" Ma R Q,Zhang S J.An improved color image defogging algorithm using dark channel model and enhancing saturation[J].Optik,2019,180:997-1000." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14473704679A26EF6D56A1BB1357A5EF&amp;v=MDI0OTBLOEd0YlBxSTlCWXV3R2ZYNC91bUFWbmpwN09YNlEzaE0yZkxYbFFNL3BDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkbGh4cnU4dzY4PU5pZk9mYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Ma R Q,Zhang S J.An improved color image defogging algorithm using dark channel model and enhancing saturation[J].Optik,2019,180:997-1000.
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_4" title=" Liu D M,Chang F L.Coarse-to-fine saliency detection based on non-subsampled contourlet transform enhancement[J].Acta Optica Sinica,2019,39(1):0115003.刘冬梅,常发亮.基于非下采样轮廓小波变换增强的从粗到精的显著性检测[J].光学学报,2019,39(1):0115003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201901034&amp;v=MjU1MzdCdEdGckNVUkxPZVplVnZGeXJtVUx6UElqWFRiTEc0SDlqTXJvOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Liu D M,Chang F L.Coarse-to-fine saliency detection based on non-subsampled contourlet transform enhancement[J].Acta Optica Sinica,2019,39(1):0115003.刘冬梅,常发亮.基于非下采样轮廓小波变换增强的从粗到精的显著性检测[J].光学学报,2019,39(1):0115003.
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_5" title=" Ancuti C O,Ancuti C.Single image dehazing by multi-scale fusion[J].IEEE Transactions on Image Processing,2013,22(8):3271-3282." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single Image Dehazing by Multi-Scale Fusion">
                                        <b>[5]</b>
                                         Ancuti C O,Ancuti C.Single image dehazing by multi-scale fusion[J].IEEE Transactions on Image Processing,2013,22(8):3271-3282.
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_6" title=" He L Y,Zhao J Z,Zheng N N,et al.Haze removal using the difference-structure-preservation prior[J].IEEE Transactions on Image Processing,2017,26(3):1063-1075." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Haze removal using the difference-structure-preservation prior&amp;quot;">
                                        <b>[6]</b>
                                         He L Y,Zhao J Z,Zheng N N,et al.Haze removal using the difference-structure-preservation prior[J].IEEE Transactions on Image Processing,2017,26(3):1063-1075.
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_7" title=" He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition,June 20-25,2009,Miami,FL,USA.New York:IEEE,2009:1956-1963." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single image haze removal using dark channel prior">
                                        <b>[7]</b>
                                         He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition,June 20-25,2009,Miami,FL,USA.New York:IEEE,2009:1956-1963.
                                    </a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_8" title=" He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Guided Image Filtering">
                                        <b>[8]</b>
                                         He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409.
                                    </a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_9" title=" Jiang J L,Sun W,Wang Z D,et al.Integrated enhancement algorithm for hazy image using transmittance as weighting factor[J].Journal of Electronics &amp;amp; Information Technology,2018,40(10):2388-2394.江巨浪,孙伟,王振东,等.基于透射率权值因子的雾天图像融合增强算法[J].电子与信息学报,2018,40(10):2388-2394." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201810015&amp;v=MTIzOTVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5cm1VTHpQSVRmU2RyRzRIOW5OcjQ5RVlZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Jiang J L,Sun W,Wang Z D,et al.Integrated enhancement algorithm for hazy image using transmittance as weighting factor[J].Journal of Electronics &amp;amp; Information Technology,2018,40(10):2388-2394.江巨浪,孙伟,王振东,等.基于透射率权值因子的雾天图像融合增强算法[J].电子与信息学报,2018,40(10):2388-2394.
                                    </a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_10" title=" Lu H B,Zhao Y F,Zhao Y J,et al.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811027&amp;v=MjYyNjllVnZGeXJtVUx6UElqWFRiTEc0SDluTnJvOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Lu H B,Zhao Y F,Zhao Y J,et al.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004.
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_11" title=" Meng G F,Wang Y,Duan J Y,et al.Efficient image dehazing with boundary constraint and contextual regularization[C]//2013 IEEE International Conference on Computer Vision,December 1-8,2013,Sydney,Australia.New York:IEEE,2013:617-624." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient image dehazing with boundary constraint and contextual regularization">
                                        <b>[11]</b>
                                         Meng G F,Wang Y,Duan J Y,et al.Efficient image dehazing with boundary constraint and contextual regularization[C]//2013 IEEE International Conference on Computer Vision,December 1-8,2013,Sydney,Australia.New York:IEEE,2013:617-624.
                                    </a>
                                </li>
                                <li id="311">


                                    <a id="bibliography_12" title=" Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Investigating Haze-relevant Features in A Learning Framework for Image Dehazing">
                                        <b>[12]</b>
                                         Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002.
                                    </a>
                                </li>
                                <li id="313">


                                    <a id="bibliography_13" title=" Cai B L,Xu X M,Jia K,et al.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An end-to-end system for single image haze removal">
                                        <b>[13]</b>
                                         Cai B L,Xu X M,Jia K,et al.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198.
                                    </a>
                                </li>
                                <li id="315">


                                    <a id="bibliography_14" title=" Ren W Q,Liu S,Zhang H,et al.Single image dehazing via multi-scale convolutional neural networks[M]//Leibe B,Mata S,Sebe N,et al.Lecture notes in computer science.Cham:Springer,2016,9906:154-169." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single image dehazing via multi-scale convolutional neural networks">
                                        <b>[14]</b>
                                         Ren W Q,Liu S,Zhang H,et al.Single image dehazing via multi-scale convolutional neural networks[M]//Leibe B,Mata S,Sebe N,et al.Lecture notes in computer science.Cham:Springer,2016,9906:154-169.
                                    </a>
                                </li>
                                <li id="317">


                                    <a id="bibliography_15" title=" Cox L J.Optics of the atmosphere-scattering by molecules and particles[J].Optica Acta:International Journal of Optics,1977,24(7):779." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optics of the atmosphere-scattering by molecules and particles">
                                        <b>[15]</b>
                                         Cox L J.Optics of the atmosphere-scattering by molecules and particles[J].Optica Acta:International Journal of Optics,1977,24(7):779.
                                    </a>
                                </li>
                                <li id="319">


                                    <a id="bibliography_16" title=" Li B Y,Ren W Q,Fu D P,et al.RESIDE:a benchmark for single image dehazing[J/OL].(2018-08-27)[2019-03-10].https://arxiv.org/abs/1712.04143v1." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RESIDE:a benchmark for single image dehazing">
                                        <b>[16]</b>
                                         Li B Y,Ren W Q,Fu D P,et al.RESIDE:a benchmark for single image dehazing[J/OL].(2018-08-27)[2019-03-10].https://arxiv.org/abs/1712.04143v1.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-06-12 14:27</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(10),149-158 DOI:10.3788/AOS201939.1010001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多尺度卷积神经网络的单幅图像去雾方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B0%B8&amp;code=07916829&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈永</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E7%BA%A2%E5%85%89&amp;code=43189921&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭红光</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%89%BE%E4%BA%9A%E9%B9%8F&amp;code=43189922&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">艾亚鹏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%85%B0%E5%B7%9E%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0231149&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">兰州交通大学电子与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统的单幅图像去雾算法容易受到雾图先验知识制约及颜色失真等问题,提出了一种基于深度学习的多尺度卷积神经网络(CNN)单幅图像去雾方法,即通过学习雾天图像与大气透射率之间的映射关系实现图像去雾。根据大气散射模型形成雾图机理,设计了一个端到端的多尺度全CNN模型,通过卷积层运算提取有雾图像的浅层特征,利用多尺度卷积核并行提取得到有雾图像的深层特征,然后将浅层特征和深层特征进行跳跃连接融合,最后通过非线性回归得到雾图对应的透射率图特征,并根据大气散射模型恢复出无雾图像。采用雾图数据集对该模型进行训练测试。实验结果表明,所提方法在合成有雾图像和真实自然雾天图像的实验中均能取得良好的去雾效果,在主观评价和客观评价上均优于其他对比算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像去雾;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E6%81%A2%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像恢复;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多尺度卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%B0%94%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大气散射模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *陈永,E-mail:edukeylab@126.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61841303);</span>
                                <span>长江学者和创新团队发展计划(IRT_16R36);</span>
                                <span>教育部人文社会科学研究基金(19YJC760012);</span>
                    </p>
            </div>
                    <h1><b>Single Image Dehazing Method Based on Multi-Scale Convolution Neural Network</b></h1>
                    <h2>
                    <span>Chen Yong</span>
                    <span>Guo Hongguang</span>
                    <span>Ai Yapeng</span>
            </h2>
                    <h2>
                    <span>School of Electronic and Information Engineering, Lanzhou Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Since the traditional single image dehazing algorithm is susceptible to the prior knowledge constraint of hazy image and color distortion, this paper proposes a multi-scale convolutional neural network(CNN) single image dehazing method based on deep learning, which realizes image dehazing by learning the mapping relationship between hazy image and atmospheric transmission. According to the hazy image forming mechanism of atmospheric scattering model, an end-to-end multi-scale full CNN model is designed. The shallow layer features of hazy image are extracted by convolution layer operation, and then the deep features are extracted by multi-scale convolution kernel in parallel. Then the shallow layer features and deep features are fused by jump connection. Finally, the non-linear regression method is used to obtain the corresponding transmission features of the hazy image. According to the atmospheric scattering model, the haze-free image is restored. The model is trained by using hazy image data sets. The experimental results show that the proposed method can achieve good dehazing effect in the experiments of synthesizing hazy images and real natural hazy images. The proposed method is superior to other contrast algorithms in subjective and objective evaluations.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20dehazing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image dehazing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20restoration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image restoration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-scale%20convolution%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-scale convolution neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=atmospheric%20scattering%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">atmospheric scattering model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="42" name="42" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="43">雾是一种常见的自然天气现象。雾天场景下的空气中悬浮着大量的微小水滴,这些水滴的散射和折射作用会使成像系统获得的图像偏灰白色,导致图像的色彩饱和度和对比度下降,从而丢失很多重要的细节信息,不利于图像特征的提取和辨识,也增加了对图像进行后续处理的难度。因此,研究如何对雾天场景下获得的退化图像进行有效处理,对大气退化图像的复原和景物细节信息的增强有着非常重要的现实意义和广阔的应用前景<citation id="322" type="reference"><link href="289" rel="bibliography" /><link href="291" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。此外,随着对计算机视觉领域研究的不断深入,人们对成像设备采集的图像清晰度有了更高的要求,雾天图像清晰化已经成为计算机视觉的重要研究内容<citation id="321" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">众多的去雾方法主要分为以下两类:</p>
                </div>
                <div class="p1">
                    <p id="45">1) 基于非物理模型的图像增强方法<citation id="323" type="reference"><link href="295" rel="bibliography" /><link href="297" rel="bibliography" /><link href="299" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。该类方法未考虑图像降质的根本原因,主要通过增强有雾图像的对比度和饱和度来突出图像中有价值的信息,从而提高图像的质量,并不是真正意义上的去雾,如基于Retinex理论的方法、基于小波分解变换的方法和基于直方图均衡化的方法。</p>
                </div>
                <div class="p1">
                    <p id="46">2) 基于物理模型的图像复原方法<citation id="327" type="reference"><link href="301" rel="bibliography" /><link href="303" rel="bibliography" /><link href="305" rel="bibliography" /><link href="307" rel="bibliography" /><link href="309" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>。该类方法建立在大气散射模型的基础上,在反推物理模型的过程中完成参数估计,从而实现有雾图像的清晰化。如He等<citation id="328" type="reference"><link href="301" rel="bibliography" /><link href="303" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>提出了暗通道先验方法,通过有雾图像中的暗通道先验信息来求解大气散射模型,并取得了良好的去雾效果,但该算法使用软抠图方法,运算量较大。江巨浪等<citation id="324" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了将暗通道先验去雾算法与直方图均衡化结合的雾天图像融合增强算法,采用该算法去雾后,图像全局增强对比度有所改善,但是对于亮度较高的天空部分仍会出现颜色失真。卢辉斌等<citation id="325" type="reference"><link href="307" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>通过将亮通道与暗通道相结合的方法来估计大气光值和透射率,该方法可恢复图像的细节和颜色信息,但在大气光值计算过程中运算量较大,执行效率较低。Meng等<citation id="326" type="reference"><link href="309" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了一种基于边界约束的去雾方法,通过牺牲部分边界信息来获得去雾图像,该方法解决了去雾图像亮度偏低的问题,但是在去雾图像的部分区域仍然会出现颜色失真现象。尽管上述传统的图像去雾方法取得了很大进步,但它们大多依赖于各种先验信息或以假设条件为前提,并且采用人工方式提取雾的相关特征,而且有些方法中的假设条件在许多情况下并不能成立,仍然有局限性。</p>
                </div>
                <div class="p1">
                    <p id="47">近几年,随着深度学习的快速发展及其在图像处理领域中的广泛应用,越来越多的研究人员利用深度学习方法来处理图像去雾问题。如Tang等<citation id="329" type="reference"><link href="311" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>使用随机森林研究雾气图像的暗通道优先、最大对比度、颜色衰减先验等特征来恢复无雾图像,但是当去雾算法中随机森林决策树个数较多时,训练复杂性较大,而且随机森林去雾模型容易陷入过拟合问题。Cai等<citation id="330" type="reference"><link href="313" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种基于深度学习的端到端的去雾方法,通过特征提取,利用多尺度映射和最大池化等操作学习雾霾特征,得到了有雾图像的透射率图,实现了有雾图像的清晰化。Ren等<citation id="331" type="reference"><link href="315" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>通过建立粗尺度网络和细尺度网络模型来学习有雾图像与其对应的传输透射率之间的映射关系。上述深度学习图像去雾算法在网络模型中采用最大池化等操作,容易造成透射率学习过程中部分细节丢失,从而影响去雾效果。</p>
                </div>
                <div class="p1">
                    <p id="48">综上所述,针对传统去雾算法对于各种先验信息的依赖和深度学习算法对于雾图细节信息丢失的问题,本文提出了一种基于多尺度卷积神经网络(CNN)深度学习的单幅图像去雾方法,该方法通过学习雾天图像与大气透射率之间的映射关系实现图像去雾。在模型建立过程中,根据大气散射形成雾图的机理,设计了一个端到端的多尺度全CNN深度学习模型,首先通过卷积层运算提取有雾图像的浅层特征,接着利用多尺度卷积核并行提取得到雾图的深层特征,然后将浅层特征和深层特征进行跳跃连接融合,最后通过非线性回归得到雾图对应的透射率图特征。该算法最后根据深度学习得到大气透射率,通过计算得到大气光值,利用大气散射模型实现从有雾图像中恢复出无雾图像。通过与其他算法进行对比,可以发现本文提出的方法能够取得良好的去雾效果。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">2 基本原理</h3>
                <h4 class="anchor-tag" id="50" name="50"><b>2.1 大气散射模型</b></h4>
                <div class="p1">
                    <p id="51">在计算机视觉和计算机图像中,通常使用大气散射物理模型来模拟雾天图像的退化过程<citation id="332" type="reference"><link href="317" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。该模型认为引起观测成像图像降质(即雾图)的原因如下:太阳光等环境光受到大气中散射介质的散射作用形成背景光,以及目标物体自身受大气中悬浮粒子的吸收和物体自身散射作用,导致成像系统亮度降低,对比度下降,图像结果模糊不清,从而形成了雾图。大气散射物理模型空间表示如图1所示。该模型描绘了雾天图像的退化机制,可用数学模型表示为</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>A</mi><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">式中:<i>I</i>(<i>x</i>)为成像设备获取到的有雾图像;<i>J</i>(<i>x</i>)为要恢复的无雾图像;<i>A</i>为全球大气光值;<i>t</i>(<i>x</i>)为透射率;<i>x</i>为图像的像素坐标。此外,<i>t</i>(<i>x</i>)还可以表示为</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo stretchy="false">[</mo><mo>-</mo><mi>β</mi><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>β</i>为介质消光系数;<i>d</i>(<i>x</i>)为物体到成像系统的距离,即场景深度。</p>
                </div>
                <div class="p1">
                    <p id="56">对(1)式变形可以得到</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi>A</mi><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><mrow><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 大气散射物理模型" src="Detail/GetImg?filename=images/GXXB201910018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 大气散射物理模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Physical model of atmospheric scattering</p>

                </div>
                <div class="p1">
                    <p id="59">从(3)式中可以看出,目前已知的条件是<i>I</i>(<i>x</i>),需要求得<i>J</i>(<i>x</i>)。根据基本的代数知识可知,<i>t</i>(<i>x</i>)和<i>A</i>同时可变,这是一个有无数解的方程,只有在得知<i>t</i>(<i>x</i>)和<i>A</i>先验信息的基础上才能求出定解。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60"><b>2.2 CNN</b></h4>
                <div class="p1">
                    <p id="61">CNN是一类包含卷积计算且具有深度结构的前馈神经网络,是一种典型的深度学习网络。CNN的本质是一个多层感知机,采用局部连接和权值共享等方式,一方面减少了传统神经网络权值的数量,使得网络易于优化,另外也降低了模型的复杂度,减少了过拟合的风险。近年来,随着高性能数值计算设备的出现以及深度学习理论的完善,CNN得到了快速发展,并被大量应用于计算机视觉、自然语言处理等领域。CNN在图像处理问题中有明显的优势,它可以将图像直接作为网络的输入,避免了传统图像处理算法中复杂的特征提取和数据重建过程。基本的CNN通常由卷积层和池化层组成,在卷积层中,通过卷积核的滑动来提取输入图像的不同特征,卷积操作后通过激活函数进行输出,然后再通过池化层缩小网络规模,降低计算复杂度,从而实现对输入特征图的压缩。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">3 本文方法</h3>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 网络模型设计</b></h4>
                <div class="p1">
                    <p id="64">在利用大气散射模型去雾的过程中,对于给定的一幅有雾图像,通常通过估算其透射率和大气光值来获得清晰的无雾图像。对于大气散射模型的去雾模型的求解,文中(3)式是一个不定解方程,传统的图像去雾算法,例如暗通道去雾算法需要对先验信息或假设条件进行约束后再求解,从而达到图像去雾的效果。所谓暗通道是一个基本假设,这个假设认为,在绝大多数非天空的局部区域中,某一些像素总会有至少一个颜色通道具有很低的值。实际生活中造成这个假设的原因有很多,比如建筑物的阴影、颜色较暗的物体或者表面,这些景物的暗通道总是表现为比较暗的状态。传统图像去雾方法虽然取得了很大进步,但大部分算法依赖于各种先验信息或以假设条件为前提,具有一定的局限性。</p>
                </div>
                <div class="p1">
                    <p id="65">为了克服传统大气散射模型去雾算法对先验知识的约束,根据有雾图像的特征图与透射率之间存在的非线性映射关系<citation id="333" type="reference"><link href="311" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>,本文提出了一种基于多尺度的CNN去雾网络(MSDN)模型。通过对有雾图像特征图的不同特征进行多尺度提取,深度学习得到有雾图像与大气透射率之间的映射关系,从而克服了对图像去雾算法先验知识的制约,实现了去雾效果。本文提出的MSDN模型结构如图2所示,图中Conv表示卷积核。考虑到CNN对于图像去雾问题与传统CNN对于图像分类问题的差异性(在传统的CNN中包含池化层,通过最大池化或平均池化进行网络规模缩小,而图像去雾时需要保证深度学习训练后得到的大气透射率非常精细),为了避免池化操作对去雾图像透射率映射学习信息的丢失,MSDN模型建立时采用全卷积方式,输入为有雾图像,输出为学习训练后的透射率图。MSDN模型首先通过卷积操作进行特征提取得到有雾图像的浅层特征,然后进行卷积核大小分别为3×3、5×5、7×7的多尺度并行特征提取,得到深层特征,再将浅层特征和深层特征跳跃连接后进行卷积运算,最后经非线性回归得到透射率图。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 MSDN模型图" src="Detail/GetImg?filename=images/GXXB201910018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 MSDN模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 MSDN model diagram</p>

                </div>
                <div class="p1">
                    <p id="67">MSDN模型中,浅层特征提取部分主要包括两个卷积层,作用是提取有雾图像的浅层特征,如图像的边缘等特征。为了减少模型的参数,简化模型复杂度,在两层卷积层中,每层都使用大小为3×3的卷积核,个数都设置为10个,采用多个较小的3×3卷积核不仅可以提取到雾图较多的浅层信息,还能够降低卷积操作的复杂性。此外,为了保证卷积后的特征图与原始雾图大小不发生变化,卷积时采用零填充操作。每层10个卷积核之间通过局部连接、权值共享的方式与输入图像进行运算,以实现特征的学习,卷积公式为</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">[</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mo stretchy="false">(</mo></mstyle><mi>f</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>,</mo><mi>l</mi></mrow></msub><mo>*</mo><mi>k</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>,</mo><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">]</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中:*表示卷积运算;<i>m</i>和<i>n</i>为特征图的个数;<i>l</i>表示第<i>l</i>个卷积层;<i>f</i><sub><i>n</i></sub><sub>,</sub><sub><i>l</i></sub><sub>+1</sub>为第<i>l</i>+1卷积层输出的<i>n</i>个特征图;<i>σ</i>[·]为激活函数;<i>f</i><sub><i>m</i></sub><sub>,</sub><sub><i>l</i></sub>为第<i>l</i>+1卷积层输入的<i>m</i>个特征图;<i>k</i><sub><i>m</i></sub><sub>,</sub><sub><i>n</i></sub><sub>,</sub><sub><i>l</i></sub><sub>+1</sub>为第<i>l</i>+1卷积层的卷积核;<i>b</i><sub><i>n</i></sub><sub>,</sub><sub><i>l</i></sub><sub>+1</sub>为第<i>l</i>+1卷积层的偏置项。在选择激活函数<i>σ</i>[·]时,采用改进的带参数的修正线性单元(PReLU)激活函数。选择PReLU激活函数的原因为:传统的Sigmoid激活函数存在梯度弥散问题,即在神经网络反向传播过程中,都是通过微分的链式法则来计算各个权重<i>w</i>的微分,当反向传播经过多个Sigmoid函数后,<i>w</i>对损失函数几乎没影响,这样不利于权重的优化,这种问题称为梯度饱和,也可以叫梯度弥散。相比于Sigmoid函数,PReLU激活函数的优点是收敛速度更快,能够在一定程度上避免梯度弥散的发生。PReLU激活函数与传统的CNN采用的修正线性单元(ReLU)激活函数不同,如图3所示。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 激活函数比较。" src="Detail/GetImg?filename=images/GXXB201910018_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 激活函数比较。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Comparison of activation functions. </p>
                                <p class="img_note">(a) ReLU激活函数;
(b) PReLU激活函数</p>
                                <p class="img_note">(a) ReLU 
activation function; (b) PReLU activation function</p>

                </div>
                <div class="p1">
                    <p id="71">PReLU激活函数的表达式<i>X</i><sub>PReLU</sub>为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>R</mtext><mtext>e</mtext><mtext>L</mtext><mtext>U</mtext></mrow></msub><mo>=</mo><mi>max</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mi>min</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式中:<i>x</i><sub><i>i</i></sub>为第<i>i</i>层的正区间输入信号;<i>a</i><sub><i>i</i></sub>为第<i>i</i>层负区间的权系数,在ReLU激活函数中设置为0,而在PReLU激活函数中作为可学习的参数。PReLU激活函数克服了ReLU激活函数的“特征死亡”缺点,即ReLU神经元的一个较大梯度值可能导致权重更新后该神经元接收到的任何数据点都不会再被激活,如果发生这种情况,之后通过该单位点的梯度将永远是零;而且当输入是负数时,ReLU是完全不会被激活的,这就表明一旦输入负数,梯度就会完全为零。本文提出的MSDN模型中的激活函数采用PReLU,它是针对ReLU的一个改进型激活函数。在负数区域内,PReLU激活函数有一个很小的斜率,这样也可以避免ReLU激活函数出现“特征死亡”的问题。</p>
                </div>
                <div class="p1">
                    <p id="74">通过前两层的卷积层操作后,特征提取得到的是输入图像的边缘等浅层特征,此外图像中还包含着很多深层的细节信息,如纹理等,这些深层信息仅仅依靠简单的卷积层特征提取无法得到。因此,为了进一步提取有雾图像的细节信息,本文在MSDN模型网络的第3层使用了3组不同大小的滤波器进行并行卷积运算,对大小分别为3×3、5×5、7×7的卷积核进行并行特征提取,以提取输入图像的深层特征,其中的卷积计算采用零填充方式。具体的多尺度特征提取卷积核参数如表1所示。</p>
                </div>
                <div class="area_img" id="75">
                    <p class="img_tit">表1 多尺度特征提取卷积核参数表 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Parameter table of multi-scale feature extraction kernel</p>
                    <p class="img_note"></p>
                    <table id="75" border="1"><tr><td><br />Type</td><td colspan="3">Conv</td></tr><tr><td><br />Filter size</td><td>3×3</td><td>5×5</td><td>7×7</td></tr><tr><td><br />Filter number</td><td>5</td><td>5</td><td>5</td></tr><tr><td><br />Pad</td><td>0</td><td>0</td><td>0</td></tr><tr><td><br />Stride</td><td>1</td><td>1</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="76">多尺度卷积操作的公式为</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>q</mi></mrow></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">[</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mo stretchy="false">(</mo></mstyle><mi>f</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>,</mo><mi>l</mi></mrow></msub><mo>*</mo><mi>k</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>,</mo><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>q</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">]</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">式中:<i>f</i><sub><i>n</i></sub><sub>,</sub><sub><i>l</i></sub><sub>+1,</sub><sub><i>q</i></sub>为第<i>l</i>+1卷积层通过不同多尺度卷积运算后输出的<i>n</i>个特征图;<i>k</i><sub><i>m</i></sub><sub>,</sub><sub><i>n</i></sub><sub>,</sub><sub><i>l</i></sub><sub>+1,</sub><sub><i>q</i></sub>(<i>q</i>=1,2,3)表示多尺度卷积的3组不同大小的卷积核。每组卷积核运算后得到5个特征图,将每一组得到的特征图进行连接合并后共得到15个特征图。</p>
                </div>
                <div class="p1">
                    <p id="79">为了取得较好的去雾效果,要求估算出的透射率必须精细,而单独的浅层特征或深层特征都无法达到此目标。本文MSDN模型中♁表示Concat跳跃连接操作,跳跃连接可以解决网络层数较深情况下梯度消失的问题,同时有助于梯度的反向传播,加快训练过程。在MSDN模型中首先对不同尺度卷积核提取到的特征进行Concat连接操作。为了得到较大感受野的多尺度提取后的细节特征,利用2个连续的3×3卷积层组成的小网络来代替单个的5×5卷积层堆叠的方式。这是因为5×5卷积核虽然有较大的感受野提取范围,但是其卷积核的参数有25个,而每个3×3卷积核的参数只有9个,采用堆叠后,2个连续的3×3卷积层与5×5卷积核具有同样的感受野范围,但其参数大幅减少,计算时间更加优化,而且网络容量加大,更多的卷积核的使用可以使得激活函数具有更好的特征提取能力。在本文MSDN模型中,为了将特征提取得到的浅层特征和多尺度提取得到的深层特征跳跃连接合并,继续通过Concat跳跃连接操作,然后再进行卷积操作,这样得到的特征图不仅包含了有雾图像的浅层特征,还包含了更多的细节信息,从而避免了在后续去雾过程中造成信息丢失。同理,为了获得较大的跳跃连接后的雾图浅层和深层感受野的信息,在进行卷积操作时利用3个连续的3×3卷积层组成的小网络来代替单个的7×7卷积层堆叠,通过较小卷积核堆叠的形式在保持感受野范围的同时减少参数的数量。在雾图与透射率图映射过程中,由于特征图在输出前有多个通道,而模型最终需要的是单通道的透射率图,因此在模型最后一层采用非线性回归、使用1×1卷积核及应用PReLU激活函数来产生最终的输出。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>3.2 损失函数</b></h4>
                <div class="p1">
                    <p id="81">基于MSDN模型,通过深度学习得到有雾图像和透射率图之间的映射关系,使用均方误差作为损失函数,通过最小化损失函数来实现模型的训练。损失函数为</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>s</mtext><mtext>s</mtext></mrow></msub><mo stretchy="false">[</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>,</mo><mi>t</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>=</mo><mfrac><mn>1</mn><mi>u</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>u</mi></munderover><mrow><mo stretchy="false">∥</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi>t</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">∥</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">式中:<i>t</i><sup>*</sup>(<i>x</i>)为数据集中对应的透射率标签;<i>u</i>为训练样本的数目。训练过程使用反向传播算法和0.9动量的梯度下降法来最小化损失值。输入图像的一次训练所选取的样本数为100,初始学习率设置为0.001,每10轮之后图像衰减一次,衰减率为0.99,迭代次数设置为100。</p>
                </div>
                <div class="p1">
                    <p id="84">此外,为了使模型的泛化能力更强,需要避免过拟合现象的发生,因此在透射率图学习训练过程中使用了dropout方法,随机丢弃神经元的概率设置为0.5。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>3.3 大气光计算</b></h4>
                <div class="p1">
                    <p id="86">从(3)式中可得知,若要恢复清晰的无雾图像,除了需要计算出雾图场景透射率<i>t</i>(<i>x</i>)之外,还需要计算出大气光值<i>A</i><citation id="334" type="reference"><link href="315" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。根据(1)式所示大气散射模型,当<i>t</i>(<i>x</i>)→0时,<i>A</i>=<i>I</i>(<i>x</i>);根据(2)式,当成像景深<i>d</i>(<i>x</i>)→+∞时,<i>t</i>(<i>x</i>)→0。因此,通过在<i>t</i>(<i>x</i>)中选择0.1%的最暗像素[即<i>t</i>(<i>x</i>)→0的像素],然后在原始有雾图像<i>I</i>(<i>x</i>)中寻找对应位置具有最高亮度的像素,即可计算得到<i>A</i>。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>3.4 恢复无雾图像</b></h4>
                <div class="p1">
                    <p id="88">在估算出<i>t</i>(<i>x</i>)和<i>A</i>之后,恢复的无雾图像<i>J</i>(<i>x</i>)可表示为</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi>A</mi></mrow><mrow><mi>max</mi><mo stretchy="false">[</mo><mi>t</mi><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></mfrac><mo>+</mo><mi>A</mi><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">式中:<i>t</i><sub>0</sub>是为了避免当求得的透射率过小时得出的去雾图像向白场过渡而设置的一个透射率下限,本文中取值为0.1<citation id="335" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>3.5 算法步骤</b></h4>
                <div class="p1">
                    <p id="92">本文提出的多尺度CNN去雾算法步骤为:1)MSDN深度学习模型训练,利用该步骤可得到雾图与透射率图映射关系;2)网络模型测试,输入待去雾图像,测试得到对应透射率<i>t</i>(<i>x</i>);3)通过原始雾图与透射率图,计算得到大气光值<i>A</i>;4)将上述值通过大气散射模型[(8)式]来恢复无雾图像。本文算法步骤如图4所示。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 本文算法步骤" src="Detail/GetImg?filename=images/GXXB201910018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 本文算法步骤  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Algorithmic steps in this paper</p>

                </div>
                <h3 id="94" name="94" class="anchor-tag">4 实验及结果分析</h3>
                <div class="p1">
                    <p id="95">为了验证本文方法的有效性,从合成有雾图像和真实有雾图像两个方面进行了实验,并将本文算法与目前去雾效果较好的去雾方法(文献<citation id="336" type="reference">[<a class="sup">7</a>]</citation>,<citation id="337" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</citation>)的去雾结果进行对比分析。实验在Ubuntu 18.04系统下进行,使用Python编程语言,应用Tensorflow深度学习框架搭建网络并通过编程实现本文算法,硬件环境为Intel<sup>©</sup> Core<sup>TM</sup> i7-8750H CPU @3.60 GHz,16.0 GB RAM,NVIDIA GeForce GTX 1060,对比实验的硬件配置环境与此相同。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>4.1 训练数据集</b></h4>
                <div class="p1">
                    <p id="97">本文网络模型需要有雾图像对应的透射率图作为训练标签,为了训练网络模型,本文选取了有雾图像RESIDE数据集<citation id="338" type="reference"><link href="319" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的室内ITS(Indoor Training Set)子数据集和RESIDE-beta室外OTS(Outdoor Training Set)子数据集进行训练和测试,训练数据集如图5所示。其中室内ITS子数据集建立在Middlebury和NYU-Depth-V2数据集的基础上,包含了13990幅合成的室内有雾图像和对应的透射率图标签,如图5(a)所示,该数据集通过光学模型合成有雾图像,介质消光系数的选取范围为<i>β</i>∈{0.4,0.6,0.8,1.0,1.2,1.4,1.6}。OTS数据集收集了2061幅真实的复杂户外场景及相应的深度图,包含了72135幅合成的室外有雾图像,介质消光系数的选取范围为<i>β</i>∈{0.04,0.06,0.08,0.10,0.12,0.16,0.20},结合消光系数对深度图进行预处理,得到的室外雾图与对应的透射率图标签如图5(b)所示。在合理范围内随机选取的参数可以使生成的有雾图像更加多样化,更能体现出真实有雾图像中不同程度的雾,便于训练出泛化能力更强的网络模型。本文训练过程选取ITS和OTS数据集中70%的数据作为训练集,30%的数据作为测试集。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>4.2 合成有雾图像的实验结果</b></h4>
                <div class="p1">
                    <p id="99">在合成有雾图像的实验中,部分实验结果如图6所示。图中显示:文献方法有效去除了雾气,但是去雾图像整体亮度偏低,视觉效果不好;文献方法的去雾图像亮度高于文献方法,但是部分区域出现了颜色失真现象,如图6(d)第1幅图像中的地板部分;文献方法的去雾图像亮度提高明显,但是部分区域仍出现了颜色失真问题,如图6(e)第5幅图像中的地面部分;文献深度学习方法的去雾效果要优于文献和文献的传统去雾方法,但是存在去雾不彻底的现象,如图6(f)第2幅图像中的床头区域;文献方法整体效果良好,但是同样存在部分区域去雾不彻底的问题,如图6(g)第3幅图像中的红框内仍有残留的雾,图6(g)第4幅图像中床体部分去雾后雾气残留较多。本文提出的方法相比较于其他去雾方法,去雾效果良好,恢复图像的质量更高。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 训练数据集。" src="Detail/GetImg?filename=images/GXXB201910018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 训练数据集。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Training data set. </p>
                                <p class="img_note">(a) ITS室内数据集;(b) OTS室外数据集</p>
                                <p class="img_note">(a) Indoor data set ITS; (b) outdoor data set OTS</p>

                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 合成有雾图像的实验结果。" src="Detail/GetImg?filename=images/GXXB201910018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 合成有雾图像的实验结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Experimental results of synthesizing hazy images. </p>
                                <p class="img_note">(a)有雾图像;(b)标准无雾图像;(c)文献<citation id="339" type="reference"><link href="301" rel="bibliography" />[7]</citation>方法;(d)文献<citation id="340" type="reference"><link href="309" rel="bibliography" />[11]</citation>方法;
(e)文献<citation id="341" type="reference"><link href="311" rel="bibliography" />[12]</citation>方法;(f)文献<citation id="342" type="reference"><link href="313" rel="bibliography" />[13]</citation>方法;(g)文献<citation id="343" type="reference"><link href="315" rel="bibliography" />[14]</citation>方法;(h)本文方法</p>
                                <p class="img_note">(a) Hazy image; (b) standard haze-free image; (c) method in Ref. <citation id="344" type="reference"><link href="301" rel="bibliography" />[7]</citation>; (d) method in Ref. <citation id="345" type="reference"><link href="309" rel="bibliography" />[11]</citation>; (e) method in Ref. <citation id="346" type="reference"><link href="311" rel="bibliography" />[12]</citation>; (f) method in Ref. <citation id="347" type="reference"><link href="313" rel="bibliography" />[13]</citation>; (g) method in Ref. <citation id="348" type="reference"><link href="315" rel="bibliography" />[14]</citation>; (h) proposed method</p>

                </div>
                <div class="p1">
                    <p id="103">由于主观判断不能说明本文方法的有效性,因此进一步选取了结构相似性(SSIM)和峰值信噪比(PSNR)两个指标对实验结果进行数据分析。SSIM是一种衡量两幅图像相似度的指标,将去雾图像与真实标准无雾图像作比较,SSIM的值越大表明去雾图像的失真程度越小;PSNR是衡量图像质量的重要指标,是最大信号量与噪声强度的比值,PSNR的值越大表明去雾图像越接近于标准无雾图像。合成有雾图像的实验结果数据分析如表2所示。数据显示,本文方法去雾图像的PSNR值和SSIM值均高于文献<citation id="349" type="reference">[<a class="sup">7</a>]</citation>以及文献<citation id="350" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</citation>中的方法,表明本文的去雾图像更接近于标准无雾图像,复原质量相对较高,由此验证了本文方法的有效性。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>4.3 真实有雾图像的实验结果</b></h4>
                <div class="p1">
                    <p id="105">为了验证本文模型对恢复真实有雾图像的有效性,选择了8幅真实室外有雾图像进行了去雾实验,实验结果如图7所示。从图7中可以看出:对于文献中的方法,当有雾图像中不含天空区域时,该方法能取得不错的去雾效果,但是亮度偏低,影响了整体的视觉效果;当有雾图像中含有大面积天空区域时,去雾图像的天空部分出现了不同程度的颜色失真现象,如图7(b)中的第3幅图像。文献中的方法相比文献中的方法亮度有所提升,但是当有雾图像中含有大面积天空时出现了颜色失真,如图7(c)中第2幅图像的框中区域。文献中的方法的去雾效果良好,但是在天空部分出现了颜色过曝的现象,如图7(d)第5幅图像的框中天空部分。文献中的深度学习方法相较于文献和文献的传统去雾方法,没有出现天空失真现象,但是在景深较远区域存在去雾不彻底的现象,如图7(e)中第2幅图像远处的房顶和图7(e)中第4幅图像远处的树林。文献中的方法整体效果优于文献中的方法,但是部分区域仍有残留的雾气和轻微的偏色现象,如图7(f)第5幅图像中的汽车部分有残留雾气,图7(f)中第6幅图像的地面部分有偏色现象。本文方法有效去除了图像中的雾气,没有出现天空失真现象,并且整体亮度适中,视觉效果良好。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit">表2 合成有雾图像的实验结果数据分析 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Analysis of experimental data of synthetic hazy images</p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td rowspan="2"><br />Image<br />No.</td><td colspan="2"><br />Method in <br />Ref.[7]</td><td colspan="2">Method in <br />Ref.[11]</td><td colspan="2">Method in <br />Ref.[12]</td><td colspan="2">Method in <br />Ref.[13]</td><td colspan="2">Method in <br />Ref.[14]</td><td colspan="2">Proposed <br />method</td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td></tr><tr><td>PSNR /<br />dB</td><td>SSIM /<br />%</td><td>PSNR /<br />dB</td><td>SSIM /<br />%</td><td>PSNR /<br />dB</td><td>SSIM /<br />%</td><td>PSNR /<br />dB</td><td>SSIM /<br />%</td><td>PSNR /<br />dB</td><td>SSIM /<br />%</td><td>PSNR /<br />dB</td><td>SSIM /<br />%</td></tr><tr><td>1</td><td>23.5357</td><td>85.26</td><td>17.5424</td><td>59.51</td><td>20.1796</td><td>72.37</td><td>26.1247</td><td>85.33</td><td>22.9888</td><td>79.48</td><td>28.8218</td><td>86.41</td></tr><tr><td><br />2</td><td>19.3044</td><td>80.04</td><td>17.7552</td><td>72.36</td><td>21.6655</td><td>84.07</td><td>22.1977</td><td>88.70</td><td>20.7442</td><td>87.39</td><td>23.6027</td><td>91.66</td></tr><tr><td><br />3</td><td>17.8051</td><td>79.60</td><td>16.9521</td><td>72.87</td><td>20.3959</td><td>81.23</td><td>22.7414</td><td>89.35</td><td>19.0486</td><td>84.07</td><td>26.0691</td><td>89.73</td></tr><tr><td><br />4</td><td>20.1277</td><td>82.78</td><td>19.0534</td><td>79.38</td><td>21.5623</td><td>84.42</td><td>21.8444</td><td>86.42</td><td>19.4202</td><td>81.68</td><td>24.3402</td><td>91.60</td></tr><tr><td><br />5</td><td>20.2825</td><td>81.85</td><td>21.1444</td><td>82.85</td><td>17.8848</td><td>79.29</td><td>27.6081</td><td>93.54</td><td>25.4410</td><td>90.61</td><td>29.1285</td><td>94.78</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201910018_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 真实室外有雾图像的实验结果。" src="Detail/GetImg?filename=images/GXXB201910018_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 真实室外有雾图像的实验结果。   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201910018_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Experimental results of real outdoor hazy images. </p>
                                <p class="img_note">(a)有雾图像;(b)文献<citation id="351" type="reference"><link href="301" rel="bibliography" />[7]</citation>方法;(c)文献<citation id="352" type="reference"><link href="309" rel="bibliography" />[11]</citation>方法;(d)文献[12]方法;
(e)文献<citation id="353" type="reference"><link href="313" rel="bibliography" />[13]</citation>方法;(f)文献[14]方法;(g)本文方法</p>
                                <p class="img_note">(a) Hazy images; (b) method in Ref.<citation id="354" type="reference"><link href="301" rel="bibliography" />[7]</citation>; (c) method in Ref.<citation id="355" type="reference"><link href="309" rel="bibliography" />[11]</citation>; 
(d) method in Ref.<citation id="356" type="reference"><link href="311" rel="bibliography" />[12]</citation>; (e) method in Ref.<citation id="357" type="reference"><link href="313" rel="bibliography" />[13]</citation>; (f) method in Ref.<citation id="358" type="reference"><link href="315" rel="bibliography" />[14]</citation>; (e) proposed method</p>

                </div>
                <div class="p1">
                    <p id="109">为了进一步验证本文模型对于恢复室外有雾图像的有效性,选择了信息熵(IE)和平均梯度(AG)来对实验结果进行数据对比分析。IE反映了图像包含信息量的大小,是衡量图像信息丰富程度的一个重要指标,IE值越大,表明图像越清晰;AG反映了图像微小细节反差变化的速率,表征图像的相对清晰程度,AG越大,图像层次越多,也就越清晰。室外有雾图像的实验结果数据分析如表3所示。从表中可以看出,本文方法的去雾图像在IE和AG方面的表现均优于其他对比方法,表明本文方法的去雾图像更加清晰,验证了本文方法对于室外有雾图像的有效性。</p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit">表3 室外有雾图像的实验结果数据分析 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Analysis of experimental data of outdoor hazy images</p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td rowspan="2"><br />Image<br />No.</td><td colspan="2"><br />Method in <br />Ref.[7]</td><td colspan="2">Method in <br />Ref.[11]</td><td colspan="2">Method in <br />Ref.[12]</td><td colspan="2">Method in <br />Ref.[13]</td><td colspan="2">Method in <br />Ref.[14]</td><td colspan="2">Proposed <br />method</td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td><td rowspan="2" colspan="2"></td></tr><tr><td>IE</td><td>AG</td><td>IE</td><td>AG</td><td>IE</td><td>AG</td><td>IE</td><td>AG</td><td>IE</td><td>AG</td><td>IE</td><td>AG</td></tr><tr><td>1</td><td>7.0555</td><td>14.64</td><td>7.0652</td><td>18.34</td><td>7.3984</td><td>18.52</td><td>7.2445</td><td>17.22</td><td>7.4048</td><td>20.26</td><td>7.6821</td><td>23.32</td></tr><tr><td><br />2</td><td>7.5155</td><td>14.68</td><td>7.3049</td><td>17.04</td><td>7.8192</td><td>18.83</td><td>7.4186</td><td>13.93</td><td>7.6656</td><td>17.02</td><td>7.9266</td><td>18.99</td></tr><tr><td><br />3</td><td>7.3427</td><td>8.48</td><td>7.4737</td><td>10.89</td><td>7.8771</td><td>11.78</td><td>7.7043</td><td>8.62</td><td>7.6120</td><td>9.21</td><td>7.8935</td><td>12.08</td></tr><tr><td><br />4</td><td>7.5688</td><td>9.18</td><td>7.4250</td><td>11.93</td><td>7.8515</td><td>13.23</td><td>7.7608</td><td>9.62</td><td>7.7786</td><td>10.57</td><td>7.9815</td><td>14.31</td></tr><tr><td><br />5</td><td>7.2538</td><td>14.91</td><td>7.7213</td><td>18.17</td><td>7.3410</td><td>17.93</td><td>7.1746</td><td>10.43</td><td>7.3776</td><td>13.62</td><td>7.8690</td><td>19.41</td></tr><tr><td><br />6</td><td>7.1667</td><td>8.92</td><td>7.8371</td><td>10.40</td><td>7.7168</td><td>10.18</td><td>7.0263</td><td>7.85</td><td>7.2862</td><td>8.76</td><td>7.8937</td><td>10.47</td></tr><tr><td><br />7</td><td>7.2625</td><td>10.94</td><td>7.1136</td><td>12.96</td><td>7.6834</td><td>13.71</td><td>7.3200</td><td>8.67</td><td>7.5189</td><td>9.59</td><td>7.7274</td><td>14.06</td></tr><tr><td><br />8</td><td>6.2721</td><td>5.88</td><td>7.1459</td><td>7.32</td><td>7.3561</td><td>7.55</td><td>6.8363</td><td>5.97</td><td>6.9818</td><td>6.39</td><td>7.4534</td><td>7.57</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>4.4 运行时间</b></h4>
                <div class="p1">
                    <p id="112">上述两部分实验结果已经验证了本文方法的有效性,为了进一步验证本文方法在效率上的表现,通过对上述室内有雾图像和室外有雾图像的实验时间进行统计,得到了不同方法的平均运行时间,如表4所示。从表中可以看出:本文方法的运行速度明显快于文献<citation id="359" type="reference">[<a class="sup">7</a>]</citation>和文献<citation id="360" type="reference">[<a class="sup">11</a>]</citation>中的传统去雾方法;与文献<citation id="361" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</citation>中的深度学习去雾方法相比,本文方法在运行速度上也有优势。</p>
                </div>
                <div class="area_img" id="113">
                    <p class="img_tit">表4 不同实验图像的算法运行时间 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Running time of different algorithms for experimental images s</p>
                    <p class="img_note"></p>
                    <table id="113" border="1"><tr><td rowspan="2"><br />Method</td><td colspan="2"><br />Experiment</td></tr><tr><td><br />Indoor</td><td>Outdoot</td></tr><tr><td><br />Method in Ref.[7]</td><td>6.87</td><td>6.89</td></tr><tr><td><br />Method in Ref.[11]</td><td>3.41</td><td>3.65</td></tr><tr><td><br />Method in Ref.[12]</td><td>1.96</td><td>2.08</td></tr><tr><td><br />Method in Ref.[13]</td><td>1.21</td><td>1.26</td></tr><tr><td><br />Method in Ref.[14]</td><td>1.58</td><td>1.92</td></tr><tr><td><br />Proposed method</td><td>1.09</td><td>1.18</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="114" name="114" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="115">针对传统去雾方法需要依靠先验条件和人工提取雾的相关特征,从而导致的天空失真、对比度低等去雾效果稳定性差的问题,提出了一种基于深度学习的多尺度CNN的单幅图像去雾方法。设计了一个端到端的全CNN模型,提出了一种基于深度学习的图像去雾算法,即通过学习雾天图像与大气透射率之间的映射关系实现图像去雾。首先通过卷积层运算提取得到有雾图像的浅层特征,再通过多尺度卷积核运算映射得到有雾图像深层的不同细节特征,接着将浅层特征和深层特征进行跳跃连接融合,再经非线性回归得到雾图对应的透射率图特征,并采用雾图数据集对该模型进行训练。利用训练好的模型对室内和真实不同场景下待去雾图像进行了多种测试,获得了清晰的无雾图像。实验结果表明,本文提出的方法克服了传统单幅图像去雾算法容易受到雾图先验知识制约、对比度低的缺点,能够有效识别雾霾相关特征,增强视觉对比度,得到清晰的无雾图像,提高图像的质量和视觉效果,且能应用于实际,为图像的后续处理提供良好的基础。下一步准备开展的工作是如何优化去雾模型,从而获得更好的去雾效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="289">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201502001&amp;v=MTA3OTN5cm1VTHpQS0NMZlliRzRIOVRNclk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Wu D,Zhu Q S.The latest research progress of image dehazing[J].Acta Automatica Sinica,2015,41(2):221-239.吴迪,朱青松.图像去雾的最新研究进展[J].自动化学报,2015,41(2):221-239.
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Review of video and image defogging algorithms and related studies on image restoration and enhancement">

                                <b>[2]</b> Xu Y,Wen J,Fei L K,et al.Review of video and image defogging algorithms and related studies on image restoration and enhancement[J].IEEE Access,2016,4:165-188.
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14473704679A26EF6D56A1BB1357A5EF&amp;v=MTU2MjczNWRsaHhydTh3Njg9TmlmT2ZiSzhHdGJQcUk5Qll1d0dmWDQvdW1BVm5qcDdPWDZRM2hNMmZMWGxRTS9wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Ma R Q,Zhang S J.An improved color image defogging algorithm using dark channel model and enhancing saturation[J].Optik,2019,180:997-1000.
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201901034&amp;v=MzE3NDc0SDlqTXJvOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXJtVUx6UElqWFRiTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Liu D M,Chang F L.Coarse-to-fine saliency detection based on non-subsampled contourlet transform enhancement[J].Acta Optica Sinica,2019,39(1):0115003.刘冬梅,常发亮.基于非下采样轮廓小波变换增强的从粗到精的显著性检测[J].光学学报,2019,39(1):0115003.
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single Image Dehazing by Multi-Scale Fusion">

                                <b>[5]</b> Ancuti C O,Ancuti C.Single image dehazing by multi-scale fusion[J].IEEE Transactions on Image Processing,2013,22(8):3271-3282.
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Haze removal using the difference-structure-preservation prior&amp;quot;">

                                <b>[6]</b> He L Y,Zhao J Z,Zheng N N,et al.Haze removal using the difference-structure-preservation prior[J].IEEE Transactions on Image Processing,2017,26(3):1063-1075.
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single image haze removal using dark channel prior">

                                <b>[7]</b> He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition,June 20-25,2009,Miami,FL,USA.New York:IEEE,2009:1956-1963.
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Guided Image Filtering">

                                <b>[8]</b> He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409.
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201810015&amp;v=MjY1NDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RnlybVVMelBJVGZTZHJHNEg5bk5yNDlFWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Jiang J L,Sun W,Wang Z D,et al.Integrated enhancement algorithm for hazy image using transmittance as weighting factor[J].Journal of Electronics &amp; Information Technology,2018,40(10):2388-2394.江巨浪,孙伟,王振东,等.基于透射率权值因子的雾天图像融合增强算法[J].电子与信息学报,2018,40(10):2388-2394.
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811027&amp;v=MTU0OTZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXJtVUx6UElqWFRiTEc0SDluTnJvOUg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Lu H B,Zhao Y F,Zhao Y J,et al.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004.
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient image dehazing with boundary constraint and contextual regularization">

                                <b>[11]</b> Meng G F,Wang Y,Duan J Y,et al.Efficient image dehazing with boundary constraint and contextual regularization[C]//2013 IEEE International Conference on Computer Vision,December 1-8,2013,Sydney,Australia.New York:IEEE,2013:617-624.
                            </a>
                        </p>
                        <p id="311">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Investigating Haze-relevant Features in A Learning Framework for Image Dehazing">

                                <b>[12]</b> Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002.
                            </a>
                        </p>
                        <p id="313">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An end-to-end system for single image haze removal">

                                <b>[13]</b> Cai B L,Xu X M,Jia K,et al.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198.
                            </a>
                        </p>
                        <p id="315">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single image dehazing via multi-scale convolutional neural networks">

                                <b>[14]</b> Ren W Q,Liu S,Zhang H,et al.Single image dehazing via multi-scale convolutional neural networks[M]//Leibe B,Mata S,Sebe N,et al.Lecture notes in computer science.Cham:Springer,2016,9906:154-169.
                            </a>
                        </p>
                        <p id="317">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optics of the atmosphere-scattering by molecules and particles">

                                <b>[15]</b> Cox L J.Optics of the atmosphere-scattering by molecules and particles[J].Optica Acta:International Journal of Optics,1977,24(7):779.
                            </a>
                        </p>
                        <p id="319">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RESIDE:a benchmark for single image dehazing">

                                <b>[16]</b> Li B Y,Ren W Q,Fu D P,et al.RESIDE:a benchmark for single image dehazing[J/OL].(2018-08-27)[2019-03-10].https://arxiv.org/abs/1712.04143v1.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201910018" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201910018&amp;v=MTYzNjBGckNVUkxPZVplVnZGeXJtVUx6UElqWFRiTEc0SDlqTnI0OUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

