

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134017152471250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905043%26RESULT%3d1%26SIGN%3dcnJqAOhXOI%252fvDvPv%252b0HxoT%252bodzk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905043&amp;v=MjM2ODBGckNVUkxPZVplVnVGeXprV3IzS0lqWFRiTEc0SDlqTXFvOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#6" data-title="2 基本原理 ">2 基本原理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#7" data-title="2.1 稀疏表示">2.1 稀疏表示</a></li>
                                                <li><a href="#17" data-title="2.2 协同表示">2.2 协同表示</a></li>
                                                <li><a href="#136" data-title="2.3 MFISR">2.3 MFISR</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="3.1 Salinas数据集实验">3.1 Salinas数据集实验</a></li>
                                                <li><a href="#57" data-title="3.2 Indian Pines数据集实验">3.2 Indian Pines数据集实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="4 结论 ">4 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="图1 不同特征提取方法的结果图。 (a) LBP; (b) Gabor">图1 不同特征提取方法的结果图。 (a) LBP; (b) Gabor</a></li>
                                                <li><a href="#43" data-title="图2 MFISR流程图">图2 MFISR流程图</a></li>
                                                <li><a href="#49" data-title="图3 参数调整与精度变化">图3 参数调整与精度变化</a></li>
                                                <li><a href="#52" data-title="图4 Salinas图像。 (a) 伪彩色图; (b) 真值图">图4 Salinas图像。 (a) 伪彩色图; (b) 真值图</a></li>
                                                <li><a href="#53" data-title="表1 Salinas数据集中不同类别的训练样本和测试样本分布">表1 Salinas数据集中不同类别的训练样本和测试样本分布</a></li>
                                                <li><a href="#55" data-title="表2 不同方法在Salinas数据集上的分类精度">表2 不同方法在Salinas数据集上的分类精度</a></li>
                                                <li><a href="#59" data-title="图5 不同方法在Salinas数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR">图5 不同方法在Salinas数据集上的分类图。 (a) SVM; (b) SRC＿Spectral......</a></li>
                                                <li><a href="#60" data-title="图6 Indian Pines图像。 (a) 假彩色图; (b) 真值图">图6 Indian Pines图像。 (a) 假彩色图; (b) 真值图</a></li>
                                                <li><a href="#61" data-title="表3 Indian Pines数据集中不同类别地物的训练样本和测试样本分布">表3 Indian Pines数据集中不同类别地物的训练样本和测试样本分布</a></li>
                                                <li><a href="#64" data-title="表4 不同方法在Indian Pines数据集上的分类精度">表4 不同方法在Indian Pines数据集上的分类精度</a></li>
                                                <li><a href="#65" data-title="图7 不同方法在Indian Pines数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR">图7 不同方法在Indian Pines数据集上的分类图。 (a) SVM; (b) SRC＿Spe......</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="69">


                                    <a id="bibliography_1" title="Ye Z, Bai L, Nian Y J.Hyperspectral image classification algorithm based on Gabor feature and locality-preserving dimensionality reduction[J].Acta Optica Sinica, 2016, 36 (10) :512-521.叶珍, 白璘, 粘永健.基于Gabor特征与局部保护降维的高光谱图像分类算法[J].光学学报, 2016, 36 (10) :512-521." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201610055&amp;v=MDM1NDk5Zk5yNDlBWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1dyM0tJalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Ye Z, Bai L, Nian Y J.Hyperspectral image classification algorithm based on Gabor feature and locality-preserving dimensionality reduction[J].Acta Optica Sinica, 2016, 36 (10) :512-521.叶珍, 白璘, 粘永健.基于Gabor特征与局部保护降维的高光谱图像分类算法[J].光学学报, 2016, 36 (10) :512-521.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_2" title="Dong A G, Li J X, Zhang B, et al.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :356-363.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :356-363." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MzA4NDBJalhUYkxHNEg5Yk1wNDlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1dyM0s=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Dong A G, Li J X, Zhang B, et al.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :356-363.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :356-363.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_3" title="Charles A S, Olshausen B A, Rozell C J.Learning sparse codes for hyperspectral imagery[J].IEEEJournal of Selected Topics in Signal Processing, 2011, 5 (5) :963-978." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Sparse Codes for Hyperspectral Imagery">
                                        <b>[3]</b>
                                        Charles A S, Olshausen B A, Rozell C J.Learning sparse codes for hyperspectral imagery[J].IEEEJournal of Selected Topics in Signal Processing, 2011, 5 (5) :963-978.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_4" title="Kalluri H R, Prasad S, Bruce L M.Decision-level fusion of spectral reflectance and derivative information for robust hyperspectral land cover classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2010, 48 (11) :4047-4058." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Decision-Level Fusion of Spectral Reflectance and Derivative Information for Robust Hyperspectral Land Cover Classification">
                                        <b>[4]</b>
                                        Kalluri H R, Prasad S, Bruce L M.Decision-level fusion of spectral reflectance and derivative information for robust hyperspectral land cover classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2010, 48 (11) :4047-4058.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_5" title="Benediktsson J A, Palmason J A, Sveinsson J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEETransactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of hyperspectral data from urban areas based on extended morphological profiles">
                                        <b>[5]</b>
                                        Benediktsson J A, Palmason J A, Sveinsson J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEETransactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491.
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_6" title="Fauvel M, Benediktsson J A, Chanussot J, et al.Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2008, 46 (11) :3804-3814." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles">
                                        <b>[6]</b>
                                        Fauvel M, Benediktsson J A, Chanussot J, et al.Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2008, 46 (11) :3804-3814.
                                    </a>
                                </li>
                                <li id="81">


                                    <a id="bibliography_7" title="Chen C, Li W, Tramel E W, et al.Spectral-spatial preprocessing using multihypothesis prediction for noise-robust hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1047-1059." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial preprocessing using multihypothesis prediction for\snoise-robust hyperspectral image classification">
                                        <b>[7]</b>
                                        Chen C, Li W, Tramel E W, et al.Spectral-spatial preprocessing using multihypothesis prediction for noise-robust hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1047-1059.
                                    </a>
                                </li>
                                <li id="83">


                                    <a id="bibliography_8" title="Jimenez-Rodriguez L O, Arzuaga-Cruz E, VelezReyes M.Unsupervised linear feature-extraction methods and their effects in the classification of highdimensional data[J].IEEE Transactions on Geoscience and Remote Sensing, 2007, 45 (2) :469-483." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised linear feature-extraction methods and their effects in the classification of high-dimensional data">
                                        <b>[8]</b>
                                        Jimenez-Rodriguez L O, Arzuaga-Cruz E, VelezReyes M.Unsupervised linear feature-extraction methods and their effects in the classification of highdimensional data[J].IEEE Transactions on Geoscience and Remote Sensing, 2007, 45 (2) :469-483.
                                    </a>
                                </li>
                                <li id="85">


                                    <a id="bibliography_9" title="Zhang X R, Gao Z Y, An J L, et al.Joint multifeature hyperspectral image classification with spatial constraint in semantic manifold[C].2016 IEEEInternational Geoscience and Remote Sensing Symposium (IGARSS) , 10-15July 2016, Beijing, China, 2016:481-484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint multifeature hyperspectral image classification with spatial constraint in semantic manifold">
                                        <b>[9]</b>
                                        Zhang X R, Gao Z Y, An J L, et al.Joint multifeature hyperspectral image classification with spatial constraint in semantic manifold[C].2016 IEEEInternational Geoscience and Remote Sensing Symposium (IGARSS) , 10-15July 2016, Beijing, China, 2016:481-484.
                                    </a>
                                </li>
                                <li id="87">


                                    <a id="bibliography_10" title="Zhao C H, Li W.Collaborative representation-based binary hypothesis model with multi-features learning for target detection in hyperspectral imagery[J].Journal of the Indian Society of Remote Sensing, 2018, 46 (5) :847-862." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative representation-based binary hypothesis model with multi-features learning for target detection in hyperspectral imagery">
                                        <b>[10]</b>
                                        Zhao C H, Li W.Collaborative representation-based binary hypothesis model with multi-features learning for target detection in hyperspectral imagery[J].Journal of the Indian Society of Remote Sensing, 2018, 46 (5) :847-862.
                                    </a>
                                </li>
                                <li id="89">


                                    <a id="bibliography_11" title="Ojala T, Pietikainen M, Maenpaa T.Multiresolution gray-scale and rotation invariant texture classification with local binary patterns[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) :971-987." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiresolution gray-scale and rotation invariant texture classification with local binary patterns">
                                        <b>[11]</b>
                                        Ojala T, Pietikainen M, Maenpaa T.Multiresolution gray-scale and rotation invariant texture classification with local binary patterns[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) :971-987.
                                    </a>
                                </li>
                                <li id="91">


                                    <a id="bibliography_12" title="Li W, Du Q.Gabor-filtering-based nearest regularized subspace for hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1012-1022." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gabor-filtering-based Nearest Regularized Subspace for Hyperspectral Image Classification">
                                        <b>[12]</b>
                                        Li W, Du Q.Gabor-filtering-based nearest regularized subspace for hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1012-1022.
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_13" title="Yu C Y, Zhao M, Song M P, et al.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica, 2018, 38 (6) :0628003.于纯妍, 赵猛, 宋梅萍, 等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报, 2018, 38 (6) :0628003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806044&amp;v=MjkyNDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtXcjNLSWpYVGJMRzRIOW5NcVk5QllJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Yu C Y, Zhao M, Song M P, et al.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica, 2018, 38 (6) :0628003.于纯妍, 赵猛, 宋梅萍, 等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报, 2018, 38 (6) :0628003.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_14" title="Tarabalka Y, Fauvel M, Chanussot J, et al.SVM-and MRF-based method for accurate classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2010, 7 (4) :736-740." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SVM- and MRF-based method for accurate classification of hyperspectral images">
                                        <b>[14]</b>
                                        Tarabalka Y, Fauvel M, Chanussot J, et al.SVM-and MRF-based method for accurate classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2010, 7 (4) :736-740.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_15" title="Wright J, Yang A Y, Ganesh A, et al.Robust face recognition via sparse representation[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Face Recognition via Sparse Representation">
                                        <b>[15]</b>
                                        Wright J, Yang A Y, Ganesh A, et al.Robust face recognition via sparse representation[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.
                                    </a>
                                </li>
                                <li id="99">


                                    <a id="bibliography_16" title="Wu Y, Blasch E, Chen G, et al.Multiple source data fusion via sparse representation for robust visual tracking[C].14th International Conference on Information Fusion, July 2011, 5-8, Chicago, 2011:12177541." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple source data fusion via sparse representation for robust visual tracking">
                                        <b>[16]</b>
                                        Wu Y, Blasch E, Chen G, et al.Multiple source data fusion via sparse representation for robust visual tracking[C].14th International Conference on Information Fusion, July 2011, 5-8, Chicago, 2011:12177541.
                                    </a>
                                </li>
                                <li id="101">


                                    <a id="bibliography_17" title="Zhang E, Zhang X, Liu H, et al.Fast multifeature joint sparse representation for hyperspectral image classification[J].IEEE Geoscience Remote Sensing Letters, 2015, 12 (7) :1397-1401." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Multifeature Joint Sparse Representation for Hyperspectral Image Classification">
                                        <b>[17]</b>
                                        Zhang E, Zhang X, Liu H, et al.Fast multifeature joint sparse representation for hyperspectral image classification[J].IEEE Geoscience Remote Sensing Letters, 2015, 12 (7) :1397-1401.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_18" title="Gan L, Xia J S, Du P J, et al.Multiple feature kernel sparse representation classifier for hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (9) :5343-5356." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple feature kernel sparse representation classifier for hyperspectral imagery">
                                        <b>[18]</b>
                                        Gan L, Xia J S, Du P J, et al.Multiple feature kernel sparse representation classifier for hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (9) :5343-5356.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_19" title="Candes E J, Tao T.Decoding by linear programming[J].IEEE Transactions on Information Theory, 2005, 51 (12) :4203-4215." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Decoding by linear programming">
                                        <b>[19]</b>
                                        Candes E J, Tao T.Decoding by linear programming[J].IEEE Transactions on Information Theory, 2005, 51 (12) :4203-4215.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_20" title="Chen S S, Donoho D L, Saunders M A.Atomic decomposition by basis pursuit[J].SIAM Journal on Scientific Computing, 1998, 20 (1) :33-61." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Atomic decomposition by basis pursuit">
                                        <b>[20]</b>
                                        Chen S S, Donoho D L, Saunders M A.Atomic decomposition by basis pursuit[J].SIAM Journal on Scientific Computing, 1998, 20 (1) :33-61.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_21" title="Li W, Du Q, Zhang F, et al.Collaborative representation based k-nearest neighbor classifier for hyperspectral imagery[C].2014 6th Workshop on Hyperspectral Image and Signal Processing:Evolution in Remote Sensing (WHISPERS) , 24-27June 2014, Lausanne, Switzerland, 2014:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative representation based k-nearest neighbor classifier for hyperspectral imagery">
                                        <b>[21]</b>
                                        Li W, Du Q, Zhang F, et al.Collaborative representation based k-nearest neighbor classifier for hyperspectral imagery[C].2014 6th Workshop on Hyperspectral Image and Signal Processing:Evolution in Remote Sensing (WHISPERS) , 24-27June 2014, Lausanne, Switzerland, 2014:1-4.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_22" title="Hyperspectral data set[Z/OL].[2018-08-13].http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hyperspectral data set[Z/OL]">
                                        <b>[22]</b>
                                        Hyperspectral data set[Z/OL].[2018-08-13].http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-02-25 09:19</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),351-359 DOI:10.3788/AOS201939.0528004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于多特征和改进稀疏表示的高光谱图像分类</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%9D%9E%E7%87%95&amp;code=40906732&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李非燕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9C%8D%E5%AE%8F%E6%B6%9B&amp;code=09694769&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">霍宏涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%9D%99&amp;code=24561975&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%99%BD%E6%9D%B0&amp;code=40906733&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">白杰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%85%AC%E5%AE%89%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0021316&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民公安大学信息技术与网络安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了实现对高光谱图像的分类, 提出了一种基于多特征和改进稀疏表示的方法——MFISR。从高光谱图像中提取光谱特征、Gabor特征和局部二值模式 (LBP) 特征, 求解稀疏系数, 同时增加一个2范式约束, 利用所得系数得到每个测试像素的最终类别标签。实验结果表明:所提MFISR方法对小样本的检测效果显著, 分类性能稳定且较优。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高光谱图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏表示;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E6%A8%A1%E5%BC%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部二值模式;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    霍宏涛, E-mail:huotony@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>公安部技术研究计划 (2018JSYJA01);</span>
                                <span>国家重点研发计划 (2017YFC0822405);</span>
                                <span>高分辨率对地观测系统重大专项 (民用部分) (01-Y3XXXX-XX01-14/16);</span>
                    </p>
            </div>
                    <h1>Hyperspectral Image Classification via Multiple-Feature-Based Improved Sparse Representation</h1>
                    <h2>
                    <span>Li Feiyan</span>
                    <span>Huo Hongtao</span>
                    <span>Li Jing</span>
                    <span>Bai Jie</span>
            </h2>
                    <h2>
                    <span>Information Technology and Cyber Security Academy, People′s Public Security University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A multiple-feature-based improved sparse representation (MFISR) method is proposed herein for the classification of hyperspectral images.The spectral feature, Gabor feature, and local binary pattern (LBP) feature are extracted from the hyperspectral image;subsequently, the sparse coefficients are solved and a 2-paradigm constraint is added.These obtained coefficients are used to determine the final class label of each test pixel.The experimental results demonstrate that the proposed MSIFR method exhibits excellent results for the detection of small samples, and its classification performance is stable and good.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hyperspectral%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hyperspectral image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse representation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%20filter&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor filter;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=local%20binary%20pattern%20(LBP)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">local binary pattern (LBP) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-08-13</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">高光谱图像 (HSI) 具有很高的光谱分辨率, 通常使用数百个连续波段, 从红外线到紫外线有规律地间隔开。当其空间分辨率低至1m时, 高光谱图像的超高光谱分辨率意味着可以更加精确地确定地面物体的属性, 包括材料分类、地质特征识别和环境监测等<citation id="113" type="reference"><link href="69" rel="bibliography" /><link href="71" rel="bibliography" /><link href="73" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。高光谱图像分类是遥感定量分析中一项重要的课题, 其较高的光谱分辨率有利于地物的精细分类与识别。</p>
                </div>
                <div class="p1">
                    <p id="3">高光谱分类的整个流程一般包括特征提取和分类器分类。目前, 针对这两部分的工作有很多:在特征提取方面, Kalluri等<citation id="114" type="reference"><link href="75" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>从高光谱图像中提取基于光谱衍生的信息;Benediktsson等<citation id="115" type="reference"><link href="77" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和Fauvel等<citation id="116" type="reference"><link href="79" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>利用空间特征对形态特征进行了扩展;Chen等<citation id="117" type="reference"><link href="81" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了一种多假设预测策略, 用以稳健地应对高光谱分类中的噪声;Jimenez-Rodriguez等<citation id="118" type="reference"><link href="83" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>利用线性非监督方法从高光谱图像中提取特征;Zhang等<citation id="119" type="reference"><link href="85" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一个包括灰度共生矩阵 (GLCM) 、Gabor特征和梯度方向特征的多重条件随机场集成模型。此外, 文献<citation id="122" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>都对高光谱图像的多特征模型进行了研究, 并证明了多特征的有效性。因此, 本文也利用多特征模型的有效性, 并充分利用光谱信息和空间信息, 从全局和局部两方面出发建立对高光谱图像空间纹理信息的复杂描述。局部特征选用局部二值模式 (LBP) 特征。LBP特征<citation id="120" type="reference"><link href="89" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是一种旋转不变特征, 通过对中心像素值的邻域做二元阈值标记, 能去除图像中光影、位移角度等的影响, 且运行效率高。全局特征选用Gabor特征。Gabor滤波器<citation id="121" type="reference"><link href="91" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>是一种用于边缘提取的线性滤波器, 其频率和方向表达与人类的视觉系统类似, 具有对光照变换不敏感和良好的方向选择特性。</p>
                </div>
                <div class="p1">
                    <p id="4">在分类器设计方面, 传统的方法包括随机森林、支持向量机 (SVM) 、极限学习机 (ELM) 等<citation id="126" type="reference"><link href="93" rel="bibliography" /><link href="95" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。这些方法虽然比较经典, 但在面对不同特征时不能有效兼顾不同特征之间的共性和互补性。因此, 对于目标不同特征描述的建模, 关键在于如何从多特征中学到一个特征融合表示, 本文使用稀疏表示解决这一问题。基于稀疏表示的图像分类 (SRC) <citation id="123" type="reference"><link href="97" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>最初用于人脸识别。在高光谱图像中, 尽管不同的特征是从不同的角度对图像进行描述的, 但由于不同的特征都在表示相同的目标, 所以不同特征之间的关联性依然很强, 需要利用SRC的稀疏表示特性协同地学习相同或相似的特征描述。例如:Wu等<citation id="124" type="reference"><link href="99" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>使用l<sub>1</sub>范式最小化学习不同数据源特征的稀疏模型;Zhang等<citation id="125" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>通过对不同特征加一个l<sub>row, 0</sub>范式约束, 得到了多特征的快速联合稀疏表示。以上这些方法都取得了良好的分类效果, 但还存在一些问题, 例如:空间信息没有被充分利用, 仅用一个范式约束不能完全探索出不同特征之间的相似性和多样性。</p>
                </div>
                <div class="p1">
                    <p id="5">为了解决以上两个问题, 本文提出了一种基于改进稀疏表示的多特征方法 (MFISR) , 并采用该方法对高光谱图像进行分类。首先, 从原始高光谱图像中提取光谱特征和空间特征 (局部和全局) , 然后对不同特征同时使用l<sub>1</sub>范式和l<sub>2</sub>范式, 从而在利用不同特征之间相关性的同时更灵活地保留了它们的多样性, 最后根据不同特征中得到的联合系数共同决定测试像素的类别标签。</p>
                </div>
                <h3 id="6" name="6" class="anchor-tag">2 基本原理</h3>
                <h4 class="anchor-tag" id="7" name="7">2.1 稀疏表示</h4>
                <div class="p1">
                    <p id="8">由信号处理理论可知, 信号可以由基字典的线性组合表示, 这在遥感图像领域同样适用。之所以利用稀疏表示理论对遥感图像进行分类, 是因为稀疏重建过程具有天然的辨别性, 这基于一个潜在的前提, 即:观测样本理论上可由其同类训练样本的训练字典线性表示得到<citation id="127" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。稀疏表示旨在寻找给定信号的稀疏解:</p>
                </div>
                <div class="area_img" id="9">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_00900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="10">式中:‖·‖<sub>0</sub>为l<sub>0</sub>范式, 表示向量中非零原子的个数, 也叫做稀疏度;y为待观测信号;D为字典;γ为稀疏系数。由于在某些条件下, l<sub>0</sub>最小化求解问题等价于l<sub>1</sub>最小化求解问题<citation id="128" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 所以 (1) 式中的求解问题可以松弛为</p>
                </div>
                <div class="area_img" id="11">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_01100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="12">此时, <image id="132" type="formula" href="images/GXXB201905043_13200.jpg" display="inline" placement="inline"><alt></alt></image>, n为向量γ中元素的总数。考虑到高光谱分类的稀疏表示是由所有训练样本<image id="133" type="formula" href="images/GXXB201905043_13300.jpg" display="inline" placement="inline"><alt></alt></image> (b为波段数, R代表实数集) 线性组合而成的, 则对于任意一个测试样本y, 满足:</p>
                </div>
                <div class="area_img" id="13">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_01300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="14">式中:ω<sub>1</sub>为稀疏系数;λ<sub>1</sub>为正则化参数;D为所有训练样本组成的字典。ω<sub>1</sub>可以由基追踪 (BP) 算法<citation id="129" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>求解得到。在判断测试样本的类别时, 将测试样本及所有训练样本类别的子字典与对应系数的重建估计进行比较, 残差最小的为对应的类别。r<sub>l</sub><sup>1</sup> (y) 为测试样本y的残差, 即</p>
                </div>
                <div class="area_img" id="15">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_01500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="16">式中:l为某个特定类别;<image id="135" type="formula" href="images/GXXB201905043_13500.jpg" display="inline" placement="inline"><alt></alt></image>;C为总类别数;<image id="134" type="formula" href="images/GXXB201905043_13400.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <h4 class="anchor-tag" id="17" name="17">2.2 协同表示</h4>
                <div class="p1">
                    <p id="18">在稀疏表示理论中, 由于稀疏表示得到的系数过于稀疏, 可能会丢失重要的特征, 使精度降低。鉴于此, 文献<citation id="130" type="reference">[<a class="sup">21</a>]</citation>提出了协同表示方法, 对系数进行2范式约束, 以选择更多的字典原子来降低类内方差:</p>
                </div>
                <div class="area_img" id="19">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_01900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="20">式中:λ<sub>2</sub>为正则化参数。对 (7) 式求导并将等式设为0, 可以求得协同表示系数ω<sub>2</sub>的值为</p>
                </div>
                <div class="area_img" id="21">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_02100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="22">此时, 残差为</p>
                </div>
                <div class="area_img" id="23">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_02300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="136" name="136">2.3 MFISR</h4>
                <div class="p1">
                    <p id="24">LBP可在固定的邻域范围内计算该区域的纹理信息。由 (10) 式和 (11) 式提取LBP特征:</p>
                </div>
                <div class="area_img" id="25">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_02500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="26">其中, </p>
                </div>
                <div class="area_img" id="27">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="28">式中:g<sub>c</sub>为邻域中心像素;S (x) 为符号函数。在本算法中, LBP是定义在像素3×3邻域内的, 即p是此邻域内除中心像素之外的第p个像素点。</p>
                </div>
                <div class="p1">
                    <p id="137">Gabor滤波器定义为:</p>
                </div>
                <div class="area_img" id="138">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="29">式中: (x, y) 为像素;u和v分别表示方向和尺度;k为频率, 最大频率k<sub>max</sub>=π/2;σ为高斯窗宽度与波长之比。本算法中的Gabor特征G<sub>u, v</sub> (x, y) 是将高光谱每个波段的图像分别与Gabor滤波器做卷积得到的。图1分别是Indian Pines数据集 (数据详情见实验结果与分析) 提取完LBP和Gabor特征后的结果图, 可以看出:LBP很好地保留了地物轮廓的细节信息, 忽略了不同地物像素之间的相互作用;而Gabor信息刚好可以作为LBP局部信息的补充, 提供了全局地物结构的方向和大小。</p>
                </div>
                <div class="area_img" id="34">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_03400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同特征提取方法的结果图。 (a) LBP; (b) Gabor" src="Detail/GetImg?filename=images/GXXB201905043_03400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 不同特征提取方法的结果图。 (a) LBP; (b) Gabor  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_03400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Results of different feature extraction methods. (a) LBP; (b) Gabor</p>

                </div>
                <div class="p1">
                    <p id="35">在多特征表示中, 像素y可以由三种特征<image id="139" type="formula" href="images/GXXB201905043_13900.jpg" display="inline" placement="inline"><alt></alt></image>表示, y<sup>j</sup>是这个像素点的第j个特征向量。类似地, 此时的字典<image id="140" type="formula" href="images/GXXB201905043_14000.jpg" display="inline" placement="inline"><alt></alt></image>由所有特征组成。对于每个y<sup>MF</sup>, 与 (4) 式一样, 用BP算法求解得到相应的稀疏系数ω<sub>1</sub><sup>MF</sup>, 再用 (8) 式得到协同表示系数ω<sub>2</sub><sup>MF</sup>, 然后通过联合计算最小残差得到测试像素的类别标签:</p>
                </div>
                <div class="area_img" id="36">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905043_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="37">由于测试像素的三种特征描述属于同一类, 所以不但应将多特征稀疏系数限制在相同的类别稀疏模型下, 还应保证它们在另一种稀疏模型下的自由度和灵活性, 基于此提出了MFISR方法。该方法的具体流程图如图2所示。</p>
                </div>
                <div class="p1">
                    <p id="38">MFISR算法流程如下:</p>
                </div>
                <div class="p1">
                    <p id="39">输入:矩阵X∈R<sup>m×n×b</sup> (高光谱图像每个波段的尺寸为m pixel×n pixel, b为波段数) </p>
                </div>
                <div class="p1">
                    <p id="40">输出:标签类别矩阵L</p>
                </div>
                <div class="p1">
                    <p id="41">1) 读入图像, 利用 (10) 式和 (11) 式提取图像的局部LBP特征;</p>
                </div>
                <div class="p1">
                    <p id="42">2) 利用 (12) 式对图像做卷积得到图像全局Gabor特征;</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_04300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 MFISR流程图" src="Detail/GetImg?filename=images/GXXB201905043_04300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 MFISR流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_04300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of MFISR</p>

                </div>
                <div class="p1">
                    <p id="44">3) 从得到的两种空间特征和光谱特征中, 随机取出部分特征作为字典D<sup>MF</sup>;</p>
                </div>
                <div class="p1">
                    <p id="45">4) 利用BP算法求解得到稀疏系数ω<sub>1</sub><sup>MF</sup>, 再用 (8) 式得到协同表示系数ω<sub>2</sub><sup>MF</sup>;</p>
                </div>
                <div class="p1">
                    <p id="46">5) 利用 (13) 式得到最小重建误差以确定像素类别。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="48">为了证明所提方法的有效性, 实验部分使用Salinas和Indian Pines高光谱数据集 (数据集详见3.1和3.2) 进行目标检测, 将所提方法 (MFISR) 与传统的分类方法SVM以及基于光谱特征 (Spectral Value) 、局部空间特征 (LBP) 、全局空间特征 (Gabor) 和稀疏表示分类器 (SRC) 、协同表示分类器 (CRC) 自由组合的方法进行比较。在实验中, 用总体精度 (OA) 、平均精度 (AA) 对分类结果进行定量评估。参数λ是正则化参数, 用于调整稀疏系数和协同系数所占的权重。对于参数λ的选择, 经过大量实验后发现分类精度随着参数增大呈先上升后下降的趋势。为了突出这一趋势, 做出图3, 从图3中可以看到, 对于两个数据集而言, λ=0.01都表现最佳。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 参数调整与精度变化" src="Detail/GetImg?filename=images/GXXB201905043_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 参数调整与精度变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Parameter adjustment and accuracy change</p>

                </div>
                <h4 class="anchor-tag" id="50" name="50">3.1 Salinas数据集实验</h4>
                <div class="p1">
                    <p id="51">实验1所用的数据<citation id="131" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>是由美国宇航局在1998年10月8日利用机载可见光/红外成像光谱仪 (Airborne Visible/Infrared Imaging Spectrometer, AVIRIS) 采集的, 位于加利福尼亚州萨利纳斯 (Salinas) 山谷的高光谱图像, 大小为622pixel×468pixel, 空间分辨率为3.7m, 共有224个波段, 去掉坏波段和吸水带 (波段108～112、154～167和224, 共20个波段) 后还剩204个波段。用于实验的图像大小为512pixel×217pixel, 即图像共包含111104个像素, 其中背景像素有56975个, 待分类的像素有54129个。虽然总体待分类的像素较多, 但是各类样本像素之间的数量比较均匀, 这些像素包含绿色杂草、休耕地等在内的16类地物, 图4 (a) 是抽取3个波段叠加后的伪彩色图片, 图4 (b) 是用作评价结果的标准真值图。在本次实验中, 每一类地物只选用了2%的像素点作为训练样本, 如表1所示。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Salinas图像。 (a) 伪彩色图; (b) 真值图" src="Detail/GetImg?filename=images/GXXB201905043_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Salinas图像。 (a) 伪彩色图; (b) 真值图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Images of Salinas. (a) Pseudo-color image; (b) ground truth image</p>

                </div>
                <div class="area_img" id="53">
                                            <p class="img_tit">
                                                表1 Salinas数据集中不同类别的训练样本和测试样本分布
                                                    <br />
                                                Table 1 Training and test sample distributions of different class labels in Salinas dataset
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905043_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 Salinas数据集中不同类别的训练样本和测试样本分布" src="Detail/GetImg?filename=images/GXXB201905043_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="54">表2总结了不同的分类方法在Salinas数据集上的分类性能。为了避免结果出现偏差, 将实验重复了10次, 取平均值作为分类精度。定量分析结果采用每类的分类精度、总体分类精度和平均分类精度进行评价。表2中对每一类别的最高精度数据进行了加粗处理, 可见:从分类器角度, 无论是总体精度、平均精度, 还是绝大多数单个类别精度, SRC分类器都优于CRC, 而传统的分类器SVM则介于两者之间;从不同特征的表现来看, 只利用光谱信息进行类别分类, 精度较低, 加入空间特征后, 分类精度明显提高, 但LBP的总体精度比Gabor好。MFISR方法由于融合了前述所有方法的优点, 所以对16类地物中的8类表现很好, 其中有5类精度达到了100%。但是, MFISR的平均精度比SRC＿LBP下降了0.11%, 这主要是因为第13类地物的分类精度下降。对比图5 (h) 和图5 (d) 可以看出:MFISR方法容易将Lettuce＿romaine＿6wk误检成Lettuce＿romaine＿7wk;从分类精度的范围上看, SVM、SRC和CRC在不同地物上的分类精度差距较大, 而所提MFISR方法则相对稳定, 除第13类地物外, 对其他地物的分类精度大多都保持在95%以上。</p>
                </div>
                <div class="area_img" id="55">
                                            <p class="img_tit">
                                                表2 不同方法在Salinas数据集上的分类精度
                                                    <br />
                                                Table 2 Classification accuracies of different methods on Salinas dataset
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905043_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 不同方法在Salinas数据集上的分类精度" src="Detail/GetImg?filename=images/GXXB201905043_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="56">图5直观地展现了使用不同方法得到的高光谱分类图。为了便于比较, 图片中只展现了待分类的地物。这些分类图和表1中的结果一致。从图5可以看出:使用空间特征 (Gabor或LBP) 的分类结果图的噪声比使用光谱特征的分类图少;虽然CRC＿LBP和SRC＿LBP的分类图很清晰, 但在小样本区域上还是有明显的误检;而MFISR方法无论是对样本数量多的区域, 还是小样本区域, 都表现出了很强的稳健性。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57">3.2 Indian Pines数据集实验</h4>
                <div class="p1">
                    <p id="58">实验2所用的数据是在1992年6月12日由AVIRIS传感器采集的, 位于美国印第安纳西北100km<sup>2</sup>范围的关于印度松树的高光谱图像, 空间分辨率为20m, 波长范围为0.4～2.5μm, 共有220个波段, 去掉坏波段和吸水带 (波段104～108、150～163和220) , 用剩下的200个波段进行实验。图6 (a) 是选取3个波段合成的假彩色图, 图像大小为145pixel×145pixel, 其中背景像素为10776个, 地物像素为10249个, 包含16类地物。这16类地物主要是不同种类的庄稼, 所以不同地物的光谱曲线相似, 而且不同类别样本的像素点分布很不均匀, 最多的Soybean-mintill像素点个数为2455个, 最少的Oats只有20pixel, 这无疑加大了分类难度, 如图6 (b) 所示。因此, 在本次实验中, 为确保每一类样本都有训练数据, 所以对每一类地物选用了10%的像素点作为训练样本, 如表3所示。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同方法在Salinas数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR" src="Detail/GetImg?filename=images/GXXB201905043_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同方法在Salinas数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Classification maps of different methods on Salinas dataset. (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR</p>

                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Indian Pines图像。 (a) 假彩色图; (b) 真值图" src="Detail/GetImg?filename=images/GXXB201905043_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 Indian Pines图像。 (a) 假彩色图; (b) 真值图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Image of Indian Pines. (a) Pseudo-color image; (b) ground truth image</p>

                </div>
                <div class="area_img" id="61">
                                            <p class="img_tit">
                                                表3 Indian Pines数据集中不同类别地物的训练样本和测试样本分布
                                                    <br />
                                                Table 3 Training and test sample distributions of different class labels in Indian Pines dataset
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905043_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 Indian Pines数据集中不同类别地物的训练样本和测试样本分布" src="Detail/GetImg?filename=images/GXXB201905043_06100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="62">表4总结了不同分类方法在Indian Pines数据集上的分类性能。将10次实验结果的平均值作为分类精度。从表4中可以看到:从分类器角度看, 传统的SVM分类方法的精确度依然介于SRC和CRC之间。从不同特征的表现来看, 加入空间特征后的分类精度明显提高, 尤其是对于CRC分类器而言, 加入LBP空间特征后, 总体精度和平均精度都比只用光谱特征提高了26%以上;而MFISR方法无论是在总体精度上还是在平均精度上都表现最佳, 同时有7种地物分类精度都达到100% (其中类别1、7、9的训练样本数量都是个位数) 。从分类精度的范围上看, SVM、SRC和CRC在不同地物上的分类精度差距较大, 而MFISR方法依旧延续了分类精度稳定的优势, 所有地物的分类精度都保持在97%以上。从表1、3的数据分布可以看出, Indian Pines数据集与Salinas数据集最大的不同就是样本数量少, 大面积同质区域小, 在这种情况下, MFISR反而表现出了自己的优势, 平均精度和总体精度表现最优。</p>
                </div>
                <div class="p1">
                    <p id="63">图7分别给出了各方法的可视化分类结果图, 可以看出, SVM分类结果图中的噪声最多, SRC和CRC分类器仅使用光谱特征时表现不好, 而就空间信息而言, 局部特征的表现总体优于全局特征。虽然SRC＿LBP和CRC＿LBP取得了比其他分类方法更好的结果, 但所提方法在小区域轮廓细节的处理上更好。</p>
                </div>
                <div class="area_img" id="64">
                                            <p class="img_tit">
                                                表4 不同方法在Indian Pines数据集上的分类精度
                                                    <br />
                                                Table 4 Classification accuracies of different methods on Indian Pines dataset
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905043_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 不同方法在Indian Pines数据集上的分类精度" src="Detail/GetImg?filename=images/GXXB201905043_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905043_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同方法在Indian Pines数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR" src="Detail/GetImg?filename=images/GXXB201905043_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同方法在Indian Pines数据集上的分类图。 (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905043_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Classification maps of different methods on Indian Pines dataset. (a) SVM; (b) SRC＿Spectral; (c) SRC＿Gabor; (d) SRC＿LBP; (e) CRC＿Spectral; (f) CRC＿Gabor; (g) CRC＿LBP; (h) MFISR</p>

                </div>
                <h3 id="67" name="67" class="anchor-tag">4 结论</h3>
                <div class="p1">
                    <p id="68">提出了一种将多特征提取与改进的稀疏表示分类器联合起来的模型。一般情况下, 高光谱图像由于维度过高, 会产生休斯现象, 而提取特征之后, 尽管不同的特征之间能够相互弥补, 但过高的特征维度反而会造成分类精度下降。提出的MFISR方法能有效地利用不同特征之间的共性和互补性, 对多特征进行稀疏化处理。考虑到当权重系数太稀疏时, 分类结果会有偏差, 因此在l<sub>1</sub>范式的基础上增加l<sub>2</sub>范式约束, 这样既可增加不同类别特征之间的类间间距, 又可选择更多的特征原子, 使得类内更加紧凑, 充分挖掘多特征分类的潜力。在两个数据集上的实验结果证明了所提MFISR方法的优越性, 尤其是针对小样本目标的分类。在实验中, 字典是直接由特征构建的, 在未来的工作中, 将继续研究能对特征进行进一步抽象的自适应字典, 以减小字典的大小, 提高运行效率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="69">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201610055&amp;v=MzA0NjllVnVGeXprV3IzS0lqWFRiTEc0SDlmTnI0OUFZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Ye Z, Bai L, Nian Y J.Hyperspectral image classification algorithm based on Gabor feature and locality-preserving dimensionality reduction[J].Acta Optica Sinica, 2016, 36 (10) :512-521.叶珍, 白璘, 粘永健.基于Gabor特征与局部保护降维的高光谱图像分类算法[J].光学学报, 2016, 36 (10) :512-521.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201708043&amp;v=MzAwOTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtXcjNLSWpYVGJMRzRIOWJNcDQ5Qlo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Dong A G, Li J X, Zhang B, et al.Hyperspectral image classification algorithm based on spectral clustering and sparse representation[J].Acta Optica Sinica, 2017, 37 (8) :356-363.董安国, 李佳逊, 张蓓, 等.基于谱聚类和稀疏表示的高光谱图像分类算法[J].光学学报, 2017, 37 (8) :356-363.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Sparse Codes for Hyperspectral Imagery">

                                <b>[3]</b>Charles A S, Olshausen B A, Rozell C J.Learning sparse codes for hyperspectral imagery[J].IEEEJournal of Selected Topics in Signal Processing, 2011, 5 (5) :963-978.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Decision-Level Fusion of Spectral Reflectance and Derivative Information for Robust Hyperspectral Land Cover Classification">

                                <b>[4]</b>Kalluri H R, Prasad S, Bruce L M.Decision-level fusion of spectral reflectance and derivative information for robust hyperspectral land cover classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2010, 48 (11) :4047-4058.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of hyperspectral data from urban areas based on extended morphological profiles">

                                <b>[5]</b>Benediktsson J A, Palmason J A, Sveinsson J R.Classification of hyperspectral data from urban areas based on extended morphological profiles[J].IEEETransactions on Geoscience and Remote Sensing, 2005, 43 (3) :480-491.
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles">

                                <b>[6]</b>Fauvel M, Benediktsson J A, Chanussot J, et al.Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles[J].IEEE Transactions on Geoscience and Remote Sensing, 2008, 46 (11) :3804-3814.
                            </a>
                        </p>
                        <p id="81">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral-spatial preprocessing using multihypothesis prediction for\snoise-robust hyperspectral image classification">

                                <b>[7]</b>Chen C, Li W, Tramel E W, et al.Spectral-spatial preprocessing using multihypothesis prediction for noise-robust hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1047-1059.
                            </a>
                        </p>
                        <p id="83">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised linear feature-extraction methods and their effects in the classification of high-dimensional data">

                                <b>[8]</b>Jimenez-Rodriguez L O, Arzuaga-Cruz E, VelezReyes M.Unsupervised linear feature-extraction methods and their effects in the classification of highdimensional data[J].IEEE Transactions on Geoscience and Remote Sensing, 2007, 45 (2) :469-483.
                            </a>
                        </p>
                        <p id="85">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint multifeature hyperspectral image classification with spatial constraint in semantic manifold">

                                <b>[9]</b>Zhang X R, Gao Z Y, An J L, et al.Joint multifeature hyperspectral image classification with spatial constraint in semantic manifold[C].2016 IEEEInternational Geoscience and Remote Sensing Symposium (IGARSS) , 10-15July 2016, Beijing, China, 2016:481-484.
                            </a>
                        </p>
                        <p id="87">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative representation-based binary hypothesis model with multi-features learning for target detection in hyperspectral imagery">

                                <b>[10]</b>Zhao C H, Li W.Collaborative representation-based binary hypothesis model with multi-features learning for target detection in hyperspectral imagery[J].Journal of the Indian Society of Remote Sensing, 2018, 46 (5) :847-862.
                            </a>
                        </p>
                        <p id="89">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiresolution gray-scale and rotation invariant texture classification with local binary patterns">

                                <b>[11]</b>Ojala T, Pietikainen M, Maenpaa T.Multiresolution gray-scale and rotation invariant texture classification with local binary patterns[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) :971-987.
                            </a>
                        </p>
                        <p id="91">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gabor-filtering-based Nearest Regularized Subspace for Hyperspectral Image Classification">

                                <b>[12]</b>Li W, Du Q.Gabor-filtering-based nearest regularized subspace for hyperspectral image classification[J].IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014, 7 (4) :1012-1022.
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806044&amp;v=MjcxMTlLSWpYVGJMRzRIOW5NcVk5QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5emtXcjM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Yu C Y, Zhao M, Song M P, et al.Hyperspectral image classification method based on targets constraint and spectral-spatial iteration[J].Acta Optica Sinica, 2018, 38 (6) :0628003.于纯妍, 赵猛, 宋梅萍, 等.基于目标约束与谱空迭代的高光谱图像分类方法[J].光学学报, 2018, 38 (6) :0628003.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SVM- and MRF-based method for accurate classification of hyperspectral images">

                                <b>[14]</b>Tarabalka Y, Fauvel M, Chanussot J, et al.SVM-and MRF-based method for accurate classification of hyperspectral images[J].IEEE Geoscience and Remote Sensing Letters, 2010, 7 (4) :736-740.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Face Recognition via Sparse Representation">

                                <b>[15]</b>Wright J, Yang A Y, Ganesh A, et al.Robust face recognition via sparse representation[J].IEEETransactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.
                            </a>
                        </p>
                        <p id="99">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple source data fusion via sparse representation for robust visual tracking">

                                <b>[16]</b>Wu Y, Blasch E, Chen G, et al.Multiple source data fusion via sparse representation for robust visual tracking[C].14th International Conference on Information Fusion, July 2011, 5-8, Chicago, 2011:12177541.
                            </a>
                        </p>
                        <p id="101">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Multifeature Joint Sparse Representation for Hyperspectral Image Classification">

                                <b>[17]</b>Zhang E, Zhang X, Liu H, et al.Fast multifeature joint sparse representation for hyperspectral image classification[J].IEEE Geoscience Remote Sensing Letters, 2015, 12 (7) :1397-1401.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple feature kernel sparse representation classifier for hyperspectral imagery">

                                <b>[18]</b>Gan L, Xia J S, Du P J, et al.Multiple feature kernel sparse representation classifier for hyperspectral imagery[J].IEEE Transactions on Geoscience and Remote Sensing, 2018, 56 (9) :5343-5356.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Decoding by linear programming">

                                <b>[19]</b>Candes E J, Tao T.Decoding by linear programming[J].IEEE Transactions on Information Theory, 2005, 51 (12) :4203-4215.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Atomic decomposition by basis pursuit">

                                <b>[20]</b>Chen S S, Donoho D L, Saunders M A.Atomic decomposition by basis pursuit[J].SIAM Journal on Scientific Computing, 1998, 20 (1) :33-61.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative representation based k-nearest neighbor classifier for hyperspectral imagery">

                                <b>[21]</b>Li W, Du Q, Zhang F, et al.Collaborative representation based k-nearest neighbor classifier for hyperspectral imagery[C].2014 6th Workshop on Hyperspectral Image and Signal Processing:Evolution in Remote Sensing (WHISPERS) , 24-27June 2014, Lausanne, Switzerland, 2014:1-4.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hyperspectral data set[Z/OL]">

                                <b>[22]</b>Hyperspectral data set[Z/OL].[2018-08-13].http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905043" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905043&amp;v=MjM2ODBGckNVUkxPZVplVnVGeXprV3IzS0lqWFRiTEc0SDlqTXFvOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

