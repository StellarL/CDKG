

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134016871533750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201905042%26RESULT%3d1%26SIGN%3dcFL0EkjFf3zvOIetDzme2NNilKU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201905042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905042&amp;v=MDE1ODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprV3I3TUlqWFRiTEc0SDlqTXFvOUJab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="1 引言 ">1 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#7" data-title="2 激光雷达地图的生成 ">2 激光雷达地图的生成</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#15" data-title="3 激光雷达定位 ">3 激光雷达定位</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#17" data-title="3.1 基于ML-RANSAC算法的粗定位">3.1 基于ML-RANSAC算法的粗定位</a></li>
                                                <li><a href="#25" data-title="3.2 基于分支定界HF的精确定位">3.2 基于分支定界HF的精确定位</a></li>
                                                <li><a href="#32" data-title="3.3 基于高斯核密度估计的概率定位框架">3.3 基于高斯核密度估计的概率定位框架</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="4 结果与分析 ">4 结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="4.1 初始位姿误差持续增长的动态场景定位实验">4.1 初始位姿误差持续增长的动态场景定位实验</a></li>
                                                <li><a href="#60" data-title="4.2 初始位姿误差随机跳动的动态场景定位实验">4.2 初始位姿误差随机跳动的动态场景定位实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="5 结论 ">5 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#10" data-title="图1 利用所提算法构建的高精度地图。 (a) 高度地图; (b) 反射率地图">图1 利用所提算法构建的高精度地图。 (a) 高度地图; (b) 反射率地图</a></li>
                                                <li><a href="#20" data-title="图2 所提定位算法流程图">图2 所提定位算法流程图</a></li>
                                                <li><a href="#51" data-title="图3 实验路段的卫星图">图3 实验路段的卫星图</a></li>
                                                <li><a href="#56" data-title="图4 使用所提算法定位前后的运动轨迹">图4 使用所提算法定位前后的运动轨迹</a></li>
                                                <li><a href="#57" data-title="图5 3种算法在实验1中的定位结果。 (a) 横向误差; (b) 纵向误差; (c) 航向角误差">图5 3种算法在实验1中的定位结果。 (a) 横向误差; (b) 纵向误差; (c) 航向角误差</a></li>
                                                <li><a href="#59" data-title="图6 路口的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法">图6 路口的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF......</a></li>
                                                <li><a href="#64" data-title="图7 直道的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法">图7 直道的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF......</a></li>
                                                <li><a href="#65" data-title="图8 3种算法在不同初始位姿误差时的水平位置误差分布。 (a) 散点图; (b) 直方图">图8 3种算法在不同初始位姿误差时的水平位置误差分布。 (a) 散点图; (b) 直方图</a></li>
                                                <li><a href="#69" data-title="表1 3种算法在不同初始位置偏差时的定位统计结果">表1 3种算法在不同初始位置偏差时的定位统计结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="71">


                                    <a id="bibliography_1" title="Lee B H, Song J H, Im J H, et al.GPS/DR error estimation for autonomous vehicle localization[J].Sensors, 2015, 15 (8) :20779-20798." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPS/DR error estimation for autonomous vehicle localization">
                                        <b>[1]</b>
                                        Lee B H, Song J H, Im J H, et al.GPS/DR error estimation for autonomous vehicle localization[J].Sensors, 2015, 15 (8) :20779-20798.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_2" title="Levinson J, Montemerlo M, Thrun S.Map-based precision vehicle localization in urban environments[C]//Burgard W, Brock O, Stachniss C.Proceedings of the 3rd Conference on Robotics:Science and Systems, June 27-30, 2007, Georgia Institute of Technology, Atlanta, Georgia, USA.Cambridge:The MIT Press, 2007:352." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Map-based precision vehicle localization in urban environments">
                                        <b>[2]</b>
                                        Levinson J, Montemerlo M, Thrun S.Map-based precision vehicle localization in urban environments[C]//Burgard W, Brock O, Stachniss C.Proceedings of the 3rd Conference on Robotics:Science and Systems, June 27-30, 2007, Georgia Institute of Technology, Atlanta, Georgia, USA.Cambridge:The MIT Press, 2007:352.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_3" title="Levinson J, Thrun S.Robust vehicle localization in urban environments using probabilistic maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 3-7, 2010, Anchorage, AK, USA.New York:IEEE, 2010:4372-4378." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust vehicle localization in urban environments using probabilistic maps">
                                        <b>[3]</b>
                                        Levinson J, Thrun S.Robust vehicle localization in urban environments using probabilistic maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 3-7, 2010, Anchorage, AK, USA.New York:IEEE, 2010:4372-4378.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_4" title="Aldibaja M, Suganuma N, Yoneda K.Robust intensity-based localization method for autonomous driving on snow-wet road surface[J].IEEETransactions on Industrial Informatics, 2017, 13 (5) :2369-2378." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust intensity-based localization method for autonomous driving on snow-wet road surface">
                                        <b>[4]</b>
                                        Aldibaja M, Suganuma N, Yoneda K.Robust intensity-based localization method for autonomous driving on snow-wet road surface[J].IEEETransactions on Industrial Informatics, 2017, 13 (5) :2369-2378.
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_5" title="Kim H, Liu B B, Goh C Y, et al.Robust vehicle localization using entropy-weighted particle filterbased data fusion of vertical and road intensity information for a large scale urban area[J].IEEERobotics and Automation Letters, 2017, 2 (3) :1518-1524." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Vehicle Localization Using Entropy-Weighted Particle Filter-based Data Fusion of Vertical and Road Intensity Information for a Large Scale Urban Area">
                                        <b>[5]</b>
                                        Kim H, Liu B B, Goh C Y, et al.Robust vehicle localization using entropy-weighted particle filterbased data fusion of vertical and road intensity information for a large scale urban area[J].IEEERobotics and Automation Letters, 2017, 2 (3) :1518-1524.
                                    </a>
                                </li>
                                <li id="81">


                                    <a id="bibliography_6" title="Wolcott R W, Eustice R M.Fast LIDAR localization using multiresolution Gaussian mixture maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 26-30, 2015, Seattle, WA, USA.New York:IEEE, 2015:2814-2821." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast LIDAR Localization Using Multiresolution Gaussian Mixture Maps">
                                        <b>[6]</b>
                                        Wolcott R W, Eustice R M.Fast LIDAR localization using multiresolution Gaussian mixture maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 26-30, 2015, Seattle, WA, USA.New York:IEEE, 2015:2814-2821.
                                    </a>
                                </li>
                                <li id="83">


                                    <a id="bibliography_7" title="Wolcott R W, Eustice R M.Robust LIDARlocalization using multiresolution Gaussian mixture maps for autonomous driving[J].The International Journal of Robotics Research, 2017, 36 (3) :292-319." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust LIDAR localization using multiresolution Gaussian mixture maps for autonomous driving">
                                        <b>[7]</b>
                                        Wolcott R W, Eustice R M.Robust LIDARlocalization using multiresolution Gaussian mixture maps for autonomous driving[J].The International Journal of Robotics Research, 2017, 36 (3) :292-319.
                                    </a>
                                </li>
                                <li id="85">


                                    <a id="bibliography_8" title="Hata A Y, Wolf D F.Feature detection for vehicle localization in urban environments using a multilayer LIDAR[J].IEEE transactions on Intelligent Transportation Systems, 2016, 17 (2) :420-429." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature detection for vehicle localization in urban environments using a multilayer LiDAR">
                                        <b>[8]</b>
                                        Hata A Y, Wolf D F.Feature detection for vehicle localization in urban environments using a multilayer LIDAR[J].IEEE transactions on Intelligent Transportation Systems, 2016, 17 (2) :420-429.
                                    </a>
                                </li>
                                <li id="87">


                                    <a id="bibliography_9" title="Schlichting A, Brenner C.Vehicle localization by LiDAR point correlation improved by change detection[J].ISPRS-International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2016, XLI-B1:703-710." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vehicle localization by LIDAR point correlation improved by change detection">
                                        <b>[9]</b>
                                        Schlichting A, Brenner C.Vehicle localization by LiDAR point correlation improved by change detection[J].ISPRS-International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2016, XLI-B1:703-710.
                                    </a>
                                </li>
                                <li id="89">


                                    <a id="bibliography_10" title="Im J H, Im S H, Jee G I.Vertical corner feature based precise vehicle localization using 3DLIDAR in urban area[J].Sensors, 2016, 16 (8) :1268." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vertical corner feature based precise vehicle localization using 3DLIDAR in urban area">
                                        <b>[10]</b>
                                        Im J H, Im S H, Jee G I.Vertical corner feature based precise vehicle localization using 3DLIDAR in urban area[J].Sensors, 2016, 16 (8) :1268.
                                    </a>
                                </li>
                                <li id="91">


                                    <a id="bibliography_11" title="Wan G W, Yang X L, Cai R L, et al.Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 21-25, 2018, Brisbane, QLD, Australia.New York:IEEE, 2018:4670-4677." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes">
                                        <b>[11]</b>
                                        Wan G W, Yang X L, Cai R L, et al.Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 21-25, 2018, Brisbane, QLD, Australia.New York:IEEE, 2018:4670-4677.
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_12" title="Thrun S.Probabilistic robotics[J].Communications of the ACM, 2002, 45 (3) :52-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000028811&amp;v=MTYyODFUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSkY4ZGF4WT1OaWZJWTdLN0h0ak5yNDlGWk9rSEJIMDRvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Thrun S.Probabilistic robotics[J].Communications of the ACM, 2002, 45 (3) :52-57.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_13" title="Doucet A, de Freitas N, Murphy K, et al.RaoBlackwellised particle filtering for dynamic Bayesian networks[C]//Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, June 30-July 3, 2000, San Francisco, CA, USA.San Francisco:Morgan Kaufmann Publishers Inc., 2000:176-183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rao-blackwellised particle filtering for dynamic bayesian networks">
                                        <b>[13]</b>
                                        Doucet A, de Freitas N, Murphy K, et al.RaoBlackwellised particle filtering for dynamic Bayesian networks[C]//Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, June 30-July 3, 2000, San Francisco, CA, USA.San Francisco:Morgan Kaufmann Publishers Inc., 2000:176-183.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_14" title="Wang R D, Xu Y C, Qi Y, et al.A robust point cloud registration method in urban dynamic environment[J].Robot, 2018, 40 (3) :257-265.王任栋, 徐友春, 齐尧, 等.一种鲁棒的城市复杂动态场景点云配准方法[J].机器人, 2018, 40 (3) :257-265." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201803001&amp;v=MTY1MzMzenFxQnRHRnJDVVJMT2VaZVZ1Rnl6a1dyN01MenpaZkxHNEg5bk1ySTlGWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Wang R D, Xu Y C, Qi Y, et al.A robust point cloud registration method in urban dynamic environment[J].Robot, 2018, 40 (3) :257-265.王任栋, 徐友春, 齐尧, 等.一种鲁棒的城市复杂动态场景点云配准方法[J].机器人, 2018, 40 (3) :257-265.
                                    </a>
                                </li>
                                <li id="99">


                                    <a id="bibliography_15" title="Lu W J, Seignez E, Rodriguez F S A, et al.Lane marking based vehicle localization using particle filter and multi-kernel estimation[C]//Proceedings of the13th International Conference on Control, Automation, Robotics and Vision, December 10-12, 2014, Marina Bay Sands, Singapore.New York:IEEE, 2014:601-606." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lane Marking Based Vehicle Localization Using Particle Filter and Multi-kernel Estimation">
                                        <b>[15]</b>
                                        Lu W J, Seignez E, Rodriguez F S A, et al.Lane marking based vehicle localization using particle filter and multi-kernel estimation[C]//Proceedings of the13th International Conference on Control, Automation, Robotics and Vision, December 10-12, 2014, Marina Bay Sands, Singapore.New York:IEEE, 2014:601-606.
                                    </a>
                                </li>
                                <li id="101">


                                    <a id="bibliography_16" title="Han D B, Xu Y C, Wang R D, et al.Calibration of three-dimensional lidar extrinsic parameters based on multiple-point clouds matching[J].Laser&amp;amp;Optoelectronics Progress, 2018, 55 (2) :022803.韩栋斌, 徐友春, 王任栋, 等.基于多对点云匹配的三维激光雷达外参数标定[J].激光与光电子学进展, 2018, 55 (2) :022803." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201802059&amp;v=MTc1OTBuTXJZOUFiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprV3I3TUx5clBaTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Han D B, Xu Y C, Wang R D, et al.Calibration of three-dimensional lidar extrinsic parameters based on multiple-point clouds matching[J].Laser&amp;amp;Optoelectronics Progress, 2018, 55 (2) :022803.韩栋斌, 徐友春, 王任栋, 等.基于多对点云匹配的三维激光雷达外参数标定[J].激光与光电子学进展, 2018, 55 (2) :022803.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_17" title="Zhao K, Xu Y C, Li Y L, et al.Large-scale scattered point-cloud denoising based on VG-DBSCANalgorithm[J].Acta Optica Sinica, 2018, 38 (10) :1028001.赵凯, 徐友春, 李永乐, 等.基于VG-DBSCAN算法的大场景散乱点云去噪[J].光学学报, 2018, 38 (10) :1028001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810047&amp;v=MTQwODdlWmVWdUZ5emtXcjdNSWpYVGJMRzRIOW5OcjQ5Qlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Zhao K, Xu Y C, Li Y L, et al.Large-scale scattered point-cloud denoising based on VG-DBSCANalgorithm[J].Acta Optica Sinica, 2018, 38 (10) :1028001.赵凯, 徐友春, 李永乐, 等.基于VG-DBSCAN算法的大场景散乱点云去噪[J].光学学报, 2018, 38 (10) :1028001.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_18" title="Xiong F G, Huo W, Han X, et al.Removal method of mismatching keypoints in 3Dpoint cloud[J].Acta Optica Sinica, 2018, 38 (2) :0210003.熊风光, 霍旺, 韩燮, 等.三维点云中关键点误匹配剔除方法[J].光学学报, 2018, 38 (2) :0210003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201802016&amp;v=MjY2NjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprV3I3TUlqWFRiTEc0SDluTXJZOUVZb1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Xiong F G, Huo W, Han X, et al.Removal method of mismatching keypoints in 3Dpoint cloud[J].Acta Optica Sinica, 2018, 38 (2) :0210003.熊风光, 霍旺, 韩燮, 等.三维点云中关键点误匹配剔除方法[J].光学学报, 2018, 38 (2) :0210003.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(05),341-350 DOI:10.3788/AOS201939.0528003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于核密度估计的城市动态密集场景激光雷达定位</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BB%BB%E6%A0%8B&amp;code=38272970&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王任栋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%8D%8E&amp;code=38272926&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E5%87%AF&amp;code=39647893&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E5%8F%8B%E6%98%A5&amp;code=38272969&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐友春</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%99%86%E5%86%9B%E5%86%9B%E4%BA%8B%E4%BA%A4%E9%80%9A%E5%AD%A6%E9%99%A2&amp;code=1702102&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陆军军事交通学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>城市环境中的精确定位是自动驾驶领域的重点和难点, 现有的激光雷达定位算法虽然能够在多数情况下保持较高的精度, 但在一些比较复杂的城市动态场景中仍存在问题。针对这类场景中遮挡导致的全球定位系统定位精度下降, 以及运动目标和环境变化导致的有效点云特征减少的问题, 提出一个新的概率定位框架;该框架使用核密度估计的方法对改进后的多层次随机采样一致性算法和直方图滤波算法进行融合, 以有效克服多层次随机采样一致性算法在部分场景中的定位波动问题, 以及直方图滤波算法在位姿误差较大时的效率低下和局部最优问题。结果表明:所提框架在保证定位精度的前提下, 提升了对动态密集场景的适用性, 能够在现有算法容易出错的场景中实现更加稳定精确的定位, 并能够容忍更大的初始位姿误差。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">激光雷达;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">定位;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%B8%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">核密度估计;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E6%80%81%E5%AF%86%E9%9B%86%E5%9C%BA%E6%99%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动态密集场景;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B4%E6%96%B9%E5%9B%BE%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">直方图滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E4%B8%80%E8%87%B4%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机采样一致性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王任栋, E-mail:1243285824@qq.com;
                                </span>
                                <span>
                                    徐友春, E-mail:xu56419@126.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划 (2016YFB0100903);</span>
                    </p>
            </div>
                    <h1>Robust Localization Based on Kernel Density Estimation in Dynamic Diverse City Scenes Using Lidar</h1>
                    <h2>
                    <span>Wang Rendong</span>
                    <span>Li Hua</span>
                    <span>Zhao Kai</span>
                    <span>Xu Youchun</span>
            </h2>
                    <h2>
                    <span>Army Military Transportation University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Achieving high-accuracy localization in urban environments is challenging in autonomous driving.The existing LiDAR-based localization algorithms can ensure high accuracy in most cases;however, the localization problems in complex dynamic city scenes still need to be addressed.This study proposes a novel probabilistic localization framework to mitigate the accuracy degradation of the global positioning system caused by occlusion and to reduce the effective point cloud features caused by moving objects and changing environments in such scenarios.The proposed framework combines the improved multi-layer random sample consensus algorithm and the histogram filtering algorithm with the kernel density estimation method;this combination effectively overcomes the localization fluctuation of multi-layer random sample consensus in some scenes as well as the inefficiency and local optimum of histogram filtering when the pose error is large.The experimental results indicate that the proposed framework can provide more stable and accurate localization as well as tolerate larger initial pose errors compared with the existing localization methods when applied to complex dynamic city scenes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LiDAR&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LiDAR;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=localization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">localization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=kernel%20density%20estimation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">kernel density estimation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dynamic%20diverse%20scenes&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dynamic diverse scenes;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=histogram%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">histogram filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=random%20sample%20consensus&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">random sample consensus;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-17</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">1 引言</h3>
                <div class="p1">
                    <p id="2">定位技术是自动驾驶领域中一项非常关键的基础性工作。基于全球导航卫星系统 (GNSS) 的定位精度只能达到10 m左右<citation id="107" type="reference"><link href="71" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 无法达到自动驾驶的要求。基于载波相位差分 (RTK) 的卫星定位在信号良好的条件下可以保持厘米级的精度, 但其信号极易因周围高大物体的遮挡而减弱或产生多径效应, 从而导致定位结果的波动和定位精度的下降。将RTK-GNSS与惯性测量单元 (IMU) 或里程计进行结合的组合定位技术可以在一定程度上改善该问题。但IMU和里程计均存在累积误差, 如果要在卫星定位长期不稳定或失效的环境下保持高精度定位, 则需要IMU具有很高的精度, 而这种成本是非常高的。</p>
                </div>
                <div class="p1">
                    <p id="3">为了以较低的成本实现高精度定位, 目前主流的方法是使用激光雷达或视觉传感器, 结合已构建好的高精度地图, 通过匹配实时数据与地图数据, 将定位精度控制在可用范围内。通常情况下, 基于视觉方法定位的成本低于使用激光雷达定位的成本, 但其测距精度低, 且易受光线等因素的影响, 因此定位精度难以满足实际需求。相比于视觉方法而言, 激光雷达的精度和可靠性均较优。</p>
                </div>
                <div class="p1">
                    <p id="4">在定位数据方面, 激光雷达可以提供周围环境中物体表面的三维位置信息和反射强度信息, 二者均可以用来定位。基于反射率的定位<citation id="109" type="reference"><link href="73" rel="bibliography" /><link href="75" rel="bibliography" /><link href="77" rel="bibliography" /><link href="79" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>使用路面上的标志和车道线等平面静态信息可以实现精确定位, 该方法的定位精度高, 受车辆或行人等动态目标的影响小, 但该方法的应用场景比较有限, 雨雪天气会导致路面标志模糊不清, 从而影响定位精度;在非路口路段, 路面缺乏纵向特征, 纵向定位精度难以保证;而在乡村、野外等非结构化道路环境中, 路面无法提供有效的道路标志信息, 从而导致该定位方法完全失效。基于高度信息的定位<citation id="110" type="reference"><link href="81" rel="bibliography" /><link href="83" rel="bibliography" /><link href="85" rel="bibliography" /><link href="87" rel="bibliography" /><link href="89" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>应用场景更加广泛, 受天气影响小, 且均适用于结构化和非结构化道路, 但该方法面临的一个关键问题是需要克服环境中的运动目标 (行驶的车辆和行人) 、多变的静态目标 (城市改造, 停靠的车辆, 随季节变化的植被、树木) 以及由此产生的遮挡对激光雷达定位的影响。Wan等<citation id="108" type="reference"><link href="91" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>采用将两种信息进行融合的定位方法, 根据定位结果的置信度, 自适应地调整二者的权重, 但当地面标志被污染且周围环境存在大量动态目标时, 该方法便很难得到稳定、精确的定位结果。</p>
                </div>
                <div class="p1">
                    <p id="5">在定位算法方面, 粒子滤波 (PF) 是移动机器人领域中应用得最广泛的算法之一<citation id="112" type="reference"><link href="93" rel="bibliography" /><link href="95" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。考虑到无人驾驶的应用场景中, 卫星定位系统通常可以将定位误差限制在几米的范围内, Levinson等<citation id="111" type="reference"><link href="75" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>在PF的基础上提出了直方图滤波 (HF) 算法。该算法的优点在于不必担心粒子在正确位置附近丢失, 具有比PF更高的稳定性。HF和PF都属于贝叶斯滤波, 该类方法已成为目前主流的定位方法, 能够在多数场景中取得满足自动驾驶需求的精确定位结果, 但是对于一些复杂或极端场景, 仍存在一些局限。当全球定位系统 (GPS) 提供的初始定位偏差较大时, 定位的搜索空间会增大, HF和PF的效率都会显著下降, 并且二者均有收敛到局部最优的风险, 特别是在高动态的城市环境中, 实时场景与地图历史数据往往存在一定差异, 使得该风险进一步增大。</p>
                </div>
                <div class="p1">
                    <p id="6">为了解决上述问题, 并使基于地图的定位具有更高的稳健性和环境适应性, 本文基于目前主流的HF算法, 引入了多层次随机采样一致性 (ML-RANSAC) 算法<citation id="113" type="reference"><link href="97" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 以克服初始位置误差大、环境干扰多的问题。ML-RANSAC算法的定位精度较低, 无法满足自动驾驶的需求, 并且在一些特征差异不明显的场景中易出现定位结果波动的问题, 而HF算法具有精度高、波动小的优点。因此, 可将二者结合起来实现优势互补。随机采样一致性 (RANSAC) 算法得到的往往是确定性的结果, 而HF是一种概率定位方法, 为此, 本文对ML-RANSAC算法的输出和HF算法的输入分别进行改造, 使用分支定界<citation id="114" type="reference"><link href="81" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>改进的HF算法实现精确定位, 并使用高斯核密度估计 (KDE) <citation id="115" type="reference"><link href="99" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>作为中间衔接, 将二者统一到同一概率框架中。</p>
                </div>
                <h3 id="7" name="7" class="anchor-tag">2 激光雷达地图的生成</h3>
                <div class="p1">
                    <p id="8">首先使用RTK-GPS和IMU采集地图数据<citation id="116" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 并对采集的数据进行地面分割和动态障碍剔除<citation id="117" type="reference"><link href="97" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 然后采用Graph-SLAM技术进行三维重建, 最终生成二维概率栅格地图, 地图中主要包含障碍物和地面反射率的概率分布。文献<citation id="118" type="reference">[<a class="sup">2</a>]</citation>采用高斯分布来表示每个栅格的反射率信息和高度信息, 虽然这种方式能够取得良好的定位效果, 但事实上, 很多栅格中的数据分布并不满足高斯分布, 尤其是一些比较关键的信息, 如:障碍物和地面交界处的栅格, 其高度信息必然不满足高斯分布;在车道线、地面标志的边缘处, 高反射率的涂料和低反射率的柏油路组成的栅格的反射率数据也不满足高斯分布。文献<citation id="119" type="reference">[<a class="sup">6</a>]</citation>采用高斯混合模型 (GMM) 对每个栅格进行建模, 相对于高斯分布, 混合高斯模型对环境的表示更合理, 也更能表达环境的实际情况。</p>
                </div>
                <div class="p1">
                    <p id="9">采用含有两个分量的高斯模型分别对每个栅格的反射率和高度分布进行建模。对于高度信息, 两个高斯分量分别描述地面和障碍物的高度分布;对于反射率信息, 两个分量分别描述地面上的高反射率数据和低反射率数据的分布。此外, 每个栅格还统计了包含的扫描点个数。栅格的大小为20cm×20cm。图1所示为利用所提方法构建的地图, 图1 (a) 所示为地图中的高度信息, 图1 (b) 所示为地图中的反射率信息。虽然所构建的地图使用了高度和反射率, 但本研究仅使用高度信息进行定位。</p>
                </div>
                <div class="area_img" id="10">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 利用所提算法构建的高精度地图。 (a) 高度地图; (b) 反射率地图" src="Detail/GetImg?filename=images/GXXB201905042_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 利用所提算法构建的高精度地图。 (a) 高度地图; (b) 反射率地图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 High-accuracy maps constructed by proposed algorithm. (a) Height map; (b) reflectivity map</p>

                </div>
                <div class="p1">
                    <p id="11">对于随机变量x, 高斯混合模型为</p>
                </div>
                <div class="area_img" id="12">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="13">式中:μ<sub>k</sub>和σ<sub>k</sub>分别为高斯分布的均值和方差;N (x|μ<sub>k</sub>, σ<sub>k</sub>) 为混合模型的第k (k=1, 2, …, K) 个分量;π<sub>k</sub>为混合系数, 即每个分量的权重, 且满足</p>
                </div>
                <div class="area_img" id="14">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_01400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="15" name="15" class="anchor-tag">3 激光雷达定位</h3>
                <div class="p1">
                    <p id="16">激光雷达定位通过将实时采集的点云数据与先验概率地图的栅格数据进行匹配来获取车辆在世界坐标系下的二维水平位置和航向角。引入一种改进的RANSAC算法, 并提出一种基于高斯混合模型的概率框架, 将该算法与传统的滤波定位算法高效地融合在一起, 使其能够在初始误差大、动态目标多的复杂场景中实现快速、稳定、精确的定位。定位算法流程图如图2所示。</p>
                </div>
                <h4 class="anchor-tag" id="17" name="17">3.1 基于ML-RANSAC算法的粗定位</h4>
                <div class="p1">
                    <p id="18">ML-RANSAC算法是一种改进的RANSAC配准算法, 相比于传统的RANSAC算法, 能够适用更大的初始配准误差和更复杂的动态场景。由于PF和HF在采样空间较大时效率下降明显, 因此本研究采用ML-RANSAC算法进行粗定位, 为滤波定位提供较准确的初始位姿, 以确保其始终运行在效率较高的采样空间中, 同时将无用的动态目标剔除, 为滤波定位提供更加可靠的点云数据。此外, RANSAC算法的每次采样都具有随机性, 模型的每次估计结果之间具有独立性。因此, 可以利用该算法解决粒子贫化问题, 帮助滤波定位跳出局部最优。</p>
                </div>
                <div class="p1">
                    <p id="19">粗定位过程由两个步骤组成。首先需要对采集的实时点云和地图数据分别进行去噪<citation id="120" type="reference"><link href="103" rel="bibliography" /><link href="105" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>、分割和特征提取。采用基于多元几何约束的区域生长算法对激光雷达点云和栅格地图进行同步去噪和分割, 并将分割后各目标的重心点作为特征点进行后续的配准。多元几何约束包括栅格内的点云密度和栅格的高度信息。对于实时点云数据, 可以通过栅格化的方法统计上述信息;对于栅格地图, 则可以根据每个栅格存储中的高斯混合模型和扫描点个数计算得到上述信息。</p>
                </div>
                <div class="area_img" id="20">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_02000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 所提定位算法流程图" src="Detail/GetImg?filename=images/GXXB201905042_02000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 所提定位算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_02000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of proposed localization algorithm</p>

                </div>
                <div class="p1">
                    <p id="21">然后提取点云分割后每个目标的重心点, 进行ML-RANSAC计算。在ML-RANSAC计算过程中, 每次计算都需要从一帧数据A中随机选取一组点, 并在另一帧数据B中按照 (3) 式的方法找出其候选对应点。然后对每组候选对应点分别计算变换矩阵, 选出内点数最多的一组作为本次计算的结果。</p>
                </div>
                <div class="area_img" id="122">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_12200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="23">式中:A、B为两帧点云的集合;p<sub>1</sub>、p<sub>2</sub>为A中的点;q<sub>1</sub>、q<sub>2</sub>为B中的点;Q<sub>1</sub>为p<sub>1</sub>的K近邻点集;Q<sub>2</sub>为B中的候选对应点集合;ε为设定阈值;‖·‖为向量的长度。</p>
                </div>
                <div class="p1">
                    <p id="24">在利用ML-RANSAC算法找到变换矩阵后, 采用最近邻搜索和匈牙利算法对变换后的点云进行静态目标提取。</p>
                </div>
                <h4 class="anchor-tag" id="25" name="25">3.2 基于分支定界HF的精确定位</h4>
                <div class="p1">
                    <p id="26">PF和HF都是基于马尔可夫原理的贝叶斯滤波器的算法。PF通过从先验分布中随机抽取粒子来近似后验, HF则通过将状态空间分解成多个有限区域来近似后验。在初始位姿误差较小的环境中, HF具有比PF更好的稳定性。与大多数滤波器一样, HF也包含预测和更新两步。本节只分析和改进更新步, 而预测步则整合到3.3节的定位框架中。</p>
                </div>
                <div class="p1">
                    <p id="27">经典的HF一次性将整个搜索空间分割为固定大小的栅格。例如, 定位栅格的目标大小为15cm×15cm, 则直接使用15cm的栅格进行划分。本研究将该过程转换为一个迭代的分支定界过程。基于分支定界的HF允许在精确定位起始阶段使用尺寸更大的栅格对搜索空间进行划分, 从而减少划分的栅格数, 然后通过分支定界进行迭代, 在控制栅格数量的同时, 通过缩小栅格尺寸来提高定位精度。</p>
                </div>
                <div class="p1">
                    <p id="28">在第1次空间划分时使用更大的栅格, 本研究使用大小为60cm×60cm的栅格。使用 (4) 式计算每个定位栅格中心的概率, 即</p>
                </div>
                <div class="area_img" id="29">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_02900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="30">式中:z为LiDAR观测得到的位姿; (x, y) 为定位栅格中心的坐标;m为先验地图信息; (i<sub>n</sub>, j<sub>n</sub>) 为一帧数据中第n个扫描点在车辆位于 (x, y) 定位点时落入地图栅格的ID;η<sub>k</sub>、μ<sub>k</sub>、σ<sub>k</sub>为该地图栅格中的高斯混合模型参数;z<sub>n</sub>为第n个扫描点的高度。</p>
                </div>
                <div class="p1">
                    <p id="31">筛选出若干概率较高的定位栅格, 并将它们分别按维度二分, 取分裂后的栅格中心继续计算定位概率。对该过程进行迭代, 直至栅格的尺寸不大于目标栅格的尺寸, 取概率最大的位置作为本次激光雷达定位的结果。</p>
                </div>
                <h4 class="anchor-tag" id="32" name="32">3.3 基于高斯核密度估计的概率定位框架</h4>
                <div class="p1">
                    <p id="33">与大多数概率定位框架类似, 本研究中的定位框架包括位姿估计和位姿预测两部分, 其中高斯核密度估计主要用来在位姿估计部分对基于ML-RANSAC算法的粗定位和基于分支定界HF算法的精确定位进行衔接。</p>
                </div>
                <h4 class="anchor-tag" id="34" name="34">3.3.1 当前时刻的位姿估计</h4>
                <div class="p1">
                    <p id="35">传统的RANSAC算法通常在多次配准结果中选取内点比例最高的点作为粗配准结果, 虽然这种做法在大多数情况下是可靠的, 但在一些环境相似度比较高的场景中, 可能有很多位置具有较高的内点比例, 且比例最高的位置并不一定是车辆的实际位置。因此, 使用一个区域内的概率分布比使用一个点来描述定位结果更加合理, 同时也有助于后续的滤波定位和传感器融合等。</p>
                </div>
                <div class="p1">
                    <p id="36">为此, 本研究采用高斯混合模型表示车辆位置在一个区域内的概率分布。不同于传统的RANSAC算法只使用内点比例最大的结果, 本研究将RANSAC算法中每一次满足约束条件的采样和配准得到的内点比例作为该位置的权重或置信度, 使用核密度估计的方法对本次RANSAC计算中的全部定位结果进行聚类和拟合, 估计高斯混合模型的参数。</p>
                </div>
                <div class="p1">
                    <p id="37">核密度估计是一种用于估计概率密度函数的非参数方法, x<sub>1</sub>, x<sub>2</sub>, …, x<sub>s</sub>为独立同分布的s个样本点, 设其概率密度函数为f^<sub>h</sub> (x) , 核密度估计为</p>
                </div>
                <div class="area_img" id="38">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_03800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="39">式中:K (·) 为核函数, 这里采用高斯核函数;h为平滑带宽, h&gt;0。</p>
                </div>
                <div class="p1">
                    <p id="40">本研究需要对车辆的x、y、θ这3个参数进行估计, 其中θ为航向角。在该模型中, 只对水平位置进行建模和估计, 即x= (x, y) , 车辆的航向角使用每个高斯核中权重最大的位姿所对应的航向角。</p>
                </div>
                <div class="p1">
                    <p id="41">在RANSAC算法中, 内点距离阈值d<sub>inlier</sub>决定粗配准的误差范围, 而核密度估计的带宽h<sub>KDE</sub>和精确定位中滤波算法的采样空间大小w<sub>space</sub>均由该误差范围决定。因此, 通过该框架就可以很自然地将RANSAC算法中内的点距离阈值、高斯核密度估计中的带宽、滤波定位中的初始采样空间这3部分的关键参数统一在一起。</p>
                </div>
                <div class="p1">
                    <p id="42">在该分布的峰值 (概率分布函数可能存在多个峰值) 附近使用HF得到若干精确的高概率位置, 并依据估计位置的高斯混合模型概率分布和先验概率 (上一时刻对当前时刻的位姿预测) , 计算这些位置在当前时刻的后验概率。以后验概率最大的估计位置作为本次定位的最终位置。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43">3.3.2 下一时刻的位姿预测</h4>
                <div class="p1">
                    <p id="44">根据马尔可夫原理和贝叶斯法则, 利用IMU或里程计输出的运动状态信息, 分别预测这些位置对应的下一时刻定位的先验分布, 即</p>
                </div>
                <div class="area_img" id="45">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/GXXB201905042_04500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="46">式中:x<sub>t</sub>为车辆在t时刻的位置估计值;<image id="123" type="formula" href="images/GXXB201905042_12300.jpg" display="inline" placement="inline"><alt></alt></image>为车辆在t+1时刻的预测值;u<sub>t+1</sub>为车辆从t时刻到t+1时刻的运动状态, t+1时刻的车辆状态信息服从参数为μ<sub>t+1</sub>和σ<sub>t+1</sub>的高斯分布;Δx<sub>t+1</sub>, <sub>t</sub>为<image id="124" type="formula" href="images/GXXB201905042_12400.jpg" display="inline" placement="inline"><alt></alt></image>与x<sub>t</sub>的变化量;η为比例系数。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">4 结果与分析</h3>
                <div class="p1">
                    <p id="48">实验使用Velodyne HDL-64E型激光雷达进行点云数据的采集, 算法在主频为2.40GHz的四核工控机上运行, 内存为8GB, 采用Ubuntu 16.04操作系统。</p>
                </div>
                <div class="p1">
                    <p id="49">选取的测试路段如图3所示。路段全长为7.3km, 包含城市内部主干道、大型交叉路口、城市快速路、高架桥匝道等。该路段高精度地图的采集时间和实验数据的采集时间间隔为1年以上, 且实验数据分别为冬季的数据和夏季的数据。这意味着很多地方的环境已经发生了一定程度的变化。在图3所示的两组发生变化的场景中, 一组为交叉路口处道路设施的变化, 另一组为冬夏两季路两边植被的变化, 且冬季会给植被设置防冻围栏, 夏季则没有。这些静态场景的变化会增大激光雷达定位的难度。</p>
                </div>
                <div class="p1">
                    <p id="50">将所提算法与当前主流的HF定位算法以及文献<citation id="121" type="reference">[<a class="sup">14</a>]</citation>中提出的ML-RANSAC定位算法进行对比。根据初始位置偏差的类型不同, 实验分为两部分, 即初始位姿误差持续增长的动态场景定位实验 (实验1) 和初始位姿误差随机跳动的动态场景定位实验 (实验2) , 且均在含有大量动态目标的道路场景中进行实验。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 实验路段的卫星图" src="Detail/GetImg?filename=images/GXXB201905042_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 实验路段的卫星图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Satellite map of experimental section</p>

                </div>
                <h4 class="anchor-tag" id="52" name="52">4.1 初始位姿误差持续增长的动态场景定位实验</h4>
                <div class="p1">
                    <p id="53">实验1在不使用GNSS的情况下仅使用一个精度较低的IMU进行车辆位姿的推算, 将推算结果作为激光雷达定位的输入, 测试算法在有大量车辆和行人存在的高动态城市环境中的定位精度和稳定性。这种由纯推算产生的累积误差是连续缓慢变化的, 不存在位置的跳变。</p>
                </div>
                <div class="p1">
                    <p id="54">采集基于差分GPS的车辆行驶轨迹, 并在此基础上使用离线激光雷达SLAM技术作为车辆位置的真实数据。实验1包括AB和CD两段。图4所示为车辆行驶轨迹的真实数据、IMU推算的轨迹, 以及基于所提算法的激光雷达定位后的轨迹。</p>
                </div>
                <div class="p1">
                    <p id="55">3种算法在实验1中的定位误差如图5所示, 可见:无论是平均误差还是最大误差, 所提算法在3种算法中都是最小的;HF算法的精度较高, 其平均误差与所提算法的平均误差接近, 但其稳健性略差, 在一些动态场景中, 会因动态目标的遮挡和干扰而容易出现配准错误的情况;ML-RANSAC算法横向定位的稳定性优于HF算法, 但在一些纵向特征较少的场景中, 没有结合滤波定位算法及概率框架, 缺乏合理的置信度评估, 定位结果容易出现纵向波动, 且总体的定位精度较差。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_05600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 使用所提算法定位前后的运动轨迹" src="Detail/GetImg?filename=images/GXXB201905042_05600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 使用所提算法定位前后的运动轨迹  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_05600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Moving trajectories before and after localization by proposed algorithm</p>

                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种算法在实验1中的定位结果。 (a) 横向误差; (b) 纵向误差; (c) 航向角误差" src="Detail/GetImg?filename=images/GXXB201905042_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 3种算法在实验1中的定位结果。 (a) 横向误差; (b) 纵向误差; (c) 航向角误差  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Comparison of localization results in experiment 1by three algorithms. (a) Lateral error; (b) longitudinal error; (c) heading angle error</p>

                </div>
                <div class="p1">
                    <p id="58">图6和图7所示分别为一个路口和一段直道两组不同场景的定位结果。在这两组场景中, HF算法和ML-RANSAC算法的定位结果均出现了不同程度的偏差。图6 (a) 、 (b) 和图7 (a) 、 (b) 所示分别为激光雷达在高精度地图中使用所提算法得到的定位结果的俯视图和三维视图, 其中灰度图表示先验的高精度地图, 红色表示用于定位的实时点云数据, 蓝色表示通过配准得到的静态目标, 黄线为激光雷达定位的轨迹。图6 (c) 和图7 (c) 所示为车载前视相机拍摄的场景图。图6 (d) 、 (e) 、 (f) 和图7 (d) 、 (e) 、 (f) 所示分别为3种算法在各场景中定位结果的概率分布。由图6～7可知:在路口场景中, 动态目标的干扰使得HF算法定位分布的峰值明显偏离了正确位置, 而ML-RANSAC算法的定位分布更接近真实位置;在直线道路场景中, 环境纵向特征的匮乏使得HF算法的定位分布在纵向存在较大方差, 而ML-RANSAC算法的定位分布方差较小, 但在车辆纵向方向上存在多个峰值。所提算法通过将HF算法和ML-RANSAC进行融合, 在上述两组场景中均得到了峰值准确且方差较小的定位分布。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 路口的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法" src="Detail/GetImg?filename=images/GXXB201905042_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 路口的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_05900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Localization results of cross road. (a) Aerial view; (b) 3Dview; (c) forward camera view; (d) HF algorithm; (e) ML-RANSAC algorithm; (f) proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60">4.2 初始位姿误差随机跳动的动态场景定位实验</h4>
                <div class="p1">
                    <p id="61">实验2在实验1的基础上进一步提升难度, 在存在累积误差的推算结果中增加一个随机偏置作为激光雷达定位的输入, 模拟GPS因不完全遮挡和多径效应而产生的定位突变情况, 测试在有跳变误差存在的情况下, 所提算法的精度和稳定性。由于在长期推算的情况下, 定位已产生了很大的累积误差, 这时跳变结果可能是正确的, 也可能是错误的, 因此不能简单地通过运动的连续性来滤除。</p>
                </div>
                <div class="p1">
                    <p id="62">实验2 (初始位姿误差随机跳动的动态场景定位实验) 分为3组, 即航向角偏移量在 (-5°, 5°) 内随机波动, 而水平位置偏移量分别在2.5, 5, 10m的半径范围内随机波动。</p>
                </div>
                <div class="p1">
                    <p id="63">图8所示为3种定位算法在不同初始位姿误差条件下定位结果的水平误差分布散点图和误差分布直方图。为了更清晰地呈现定位误差的分布情况, 图8 (a) 的纵坐标使用对数坐标。由图8 (a) 可知, 所提算法的定位精度对初始位姿误差并不敏感, 定位精度始终保持在较高的水平, 而HF算法和ML-RANSAC算法定位结果的总体误差和波动均比较大。在该实验中, 只统计了激光雷达定位的结果, 剔除了2次激光雷达定位之间IMU的推算结果。由于3种算法在不同初始误差时完成一次定位的耗时不同, 因此对于同一段测试数据, 总时间相同, 不同初始误差范围条件下的定位次数不同, 随着初始位姿误差增大, 3种算法的定位次数呈明显的递减趋势。由图8 (b) 可知, 所提算法在水平误差小于0.1m时的次数远大于其他方法的, 且定位结果的误差集中分布在0.5m以内。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 直道的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法" src="Detail/GetImg?filename=images/GXXB201905042_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 直道的定位结果对比。 (a) 俯视图; (b) 三维视图; (c) 相机前视图; (d) HF算法; (e) ML-RANSAC算法; (f) 所提算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Localization results of straight road. (a) Aerial view; (b) 3Dview; (c) forward camera view; (d) HF algorithm; (e) ML-RANSAC algorithm; (f) proposed algorithm</p>

                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 3种算法在不同初始位姿误差时的水平位置误差分布。 (a) 散点图; (b) 直方图" src="Detail/GetImg?filename=images/GXXB201905042_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 3种算法在不同初始位姿误差时的水平位置误差分布。 (a) 散点图; (b) 直方图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Horizontal position error distributions by three algorithms under different initial pose deviations. (a) Scatter diagram; (b) histogram</p>

                </div>
                <div class="p1">
                    <p id="66">表1所示为3种算法在不同初始位姿误差时的定位统计结果, 包括横向、纵向、航向角、水平位置的方均根误差, 横向误差小于0.1m和0.4m的定位次数占总定位次数的百分数P<sub>horiz</sub>, 以及算法耗时的均值和标准差。当初始位姿误差为10m时, HF算法在0.4m误差内的P<sub>horiz</sub>为9.09%, 而所提方法的P<sub>horiz</sub>为93.18%。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag">5 结论</h3>
                <div class="p1">
                    <p id="68">在使用激光雷达点云数据和高精度先验地图进行定位的过程中, 针对目前主流的HF算法存在的在大初始误差、高动态干扰环境下定位效果差、易陷入局部最优的问题, 提出了一种将ML-RANSAC算法与HF算法相结合的定位算法, 并采用高斯核密度估计的方法将两种算法高效地统一到同一概率框架上, 实现了两种算法的优势互补。ML-RANSAC算法具有很强的稳健性, 能够适应较大的初始定位偏差和较多的动态目标干扰, 但算法的精度较低, 且在特征相似度较高的场景中易出现定位波动的情况;而HF算法则具有较高的定位精度, 但对动态环境的适用能力较差, 在运动目标较多的场景中易陷入局部最优, 且在初始定位偏差较大时, 定位效率会大幅下降。本课题组提出的概率框架不仅有效弥补了上述两种算法各自的缺点, 还进一步提升了算法的性能, 不仅能在常见的复杂动态场景中实现更加稳定和高效的定位, 还能容忍比之前更大的初始位姿误差, 有助于解决卫星定位失效而导致的位置出现大幅波动和漂移的问题。</p>
                </div>
                <div class="area_img" id="69">
                                            <p class="img_tit">
                                                表1 3种算法在不同初始位置偏差时的定位统计结果
                                                    <br />
                                                Table 1 Localization statistical results by three algorithms under different initial pose deviations
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201905042_06900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201905042_06900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201905042_06900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 3种算法在不同初始位置偏差时的定位统计结果" src="Detail/GetImg?filename=images/GXXB201905042_06900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="70">选用车辆和人流密集的城市道路场景进行了实验。结果表明, 无论是在连续累积的初始误差情况下, 还是在离散随机跳动的初始误差情况下, 所提算法均保持了较高的定位精度和较快的定位速度。相比于改进之前的ML-RANSAC算法和HF算法, 所提算法在保证定位精度和速度的前提下, 进一步提升了定位的稳健性, 能够适应更加复杂和极端的场景。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="71">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPS/DR error estimation for autonomous vehicle localization">

                                <b>[1]</b>Lee B H, Song J H, Im J H, et al.GPS/DR error estimation for autonomous vehicle localization[J].Sensors, 2015, 15 (8) :20779-20798.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Map-based precision vehicle localization in urban environments">

                                <b>[2]</b>Levinson J, Montemerlo M, Thrun S.Map-based precision vehicle localization in urban environments[C]//Burgard W, Brock O, Stachniss C.Proceedings of the 3rd Conference on Robotics:Science and Systems, June 27-30, 2007, Georgia Institute of Technology, Atlanta, Georgia, USA.Cambridge:The MIT Press, 2007:352.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust vehicle localization in urban environments using probabilistic maps">

                                <b>[3]</b>Levinson J, Thrun S.Robust vehicle localization in urban environments using probabilistic maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 3-7, 2010, Anchorage, AK, USA.New York:IEEE, 2010:4372-4378.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust intensity-based localization method for autonomous driving on snow-wet road surface">

                                <b>[4]</b>Aldibaja M, Suganuma N, Yoneda K.Robust intensity-based localization method for autonomous driving on snow-wet road surface[J].IEEETransactions on Industrial Informatics, 2017, 13 (5) :2369-2378.
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Vehicle Localization Using Entropy-Weighted Particle Filter-based Data Fusion of Vertical and Road Intensity Information for a Large Scale Urban Area">

                                <b>[5]</b>Kim H, Liu B B, Goh C Y, et al.Robust vehicle localization using entropy-weighted particle filterbased data fusion of vertical and road intensity information for a large scale urban area[J].IEEERobotics and Automation Letters, 2017, 2 (3) :1518-1524.
                            </a>
                        </p>
                        <p id="81">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast LIDAR Localization Using Multiresolution Gaussian Mixture Maps">

                                <b>[6]</b>Wolcott R W, Eustice R M.Fast LIDAR localization using multiresolution Gaussian mixture maps[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 26-30, 2015, Seattle, WA, USA.New York:IEEE, 2015:2814-2821.
                            </a>
                        </p>
                        <p id="83">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust LIDAR localization using multiresolution Gaussian mixture maps for autonomous driving">

                                <b>[7]</b>Wolcott R W, Eustice R M.Robust LIDARlocalization using multiresolution Gaussian mixture maps for autonomous driving[J].The International Journal of Robotics Research, 2017, 36 (3) :292-319.
                            </a>
                        </p>
                        <p id="85">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature detection for vehicle localization in urban environments using a multilayer LiDAR">

                                <b>[8]</b>Hata A Y, Wolf D F.Feature detection for vehicle localization in urban environments using a multilayer LIDAR[J].IEEE transactions on Intelligent Transportation Systems, 2016, 17 (2) :420-429.
                            </a>
                        </p>
                        <p id="87">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vehicle localization by LIDAR point correlation improved by change detection">

                                <b>[9]</b>Schlichting A, Brenner C.Vehicle localization by LiDAR point correlation improved by change detection[J].ISPRS-International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2016, XLI-B1:703-710.
                            </a>
                        </p>
                        <p id="89">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vertical corner feature based precise vehicle localization using 3DLIDAR in urban area">

                                <b>[10]</b>Im J H, Im S H, Jee G I.Vertical corner feature based precise vehicle localization using 3DLIDAR in urban area[J].Sensors, 2016, 16 (8) :1268.
                            </a>
                        </p>
                        <p id="91">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes">

                                <b>[11]</b>Wan G W, Yang X L, Cai R L, et al.Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes[C]//Proceedings of IEEE International Conference on Robotics and Automation, May 21-25, 2018, Brisbane, QLD, Australia.New York:IEEE, 2018:4670-4677.
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000028811&amp;v=Mjg2NTdUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSkY4ZGF4WT1OaWZJWTdLN0h0ak5yNDlGWk9rSEJIMDRvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Thrun S.Probabilistic robotics[J].Communications of the ACM, 2002, 45 (3) :52-57.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rao-blackwellised particle filtering for dynamic bayesian networks">

                                <b>[13]</b>Doucet A, de Freitas N, Murphy K, et al.RaoBlackwellised particle filtering for dynamic Bayesian networks[C]//Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, June 30-July 3, 2000, San Francisco, CA, USA.San Francisco:Morgan Kaufmann Publishers Inc., 2000:176-183.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201803001&amp;v=MTE0NTVrV3I3TUx6elpmTEc0SDluTXJJOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Wang R D, Xu Y C, Qi Y, et al.A robust point cloud registration method in urban dynamic environment[J].Robot, 2018, 40 (3) :257-265.王任栋, 徐友春, 齐尧, 等.一种鲁棒的城市复杂动态场景点云配准方法[J].机器人, 2018, 40 (3) :257-265.
                            </a>
                        </p>
                        <p id="99">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lane Marking Based Vehicle Localization Using Particle Filter and Multi-kernel Estimation">

                                <b>[15]</b>Lu W J, Seignez E, Rodriguez F S A, et al.Lane marking based vehicle localization using particle filter and multi-kernel estimation[C]//Proceedings of the13th International Conference on Control, Automation, Robotics and Vision, December 10-12, 2014, Marina Bay Sands, Singapore.New York:IEEE, 2014:601-606.
                            </a>
                        </p>
                        <p id="101">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201802059&amp;v=MTg2NDJDVVJMT2VaZVZ1Rnl6a1dyN01MeXJQWkxHNEg5bk1yWTlBYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Han D B, Xu Y C, Wang R D, et al.Calibration of three-dimensional lidar extrinsic parameters based on multiple-point clouds matching[J].Laser&amp;Optoelectronics Progress, 2018, 55 (2) :022803.韩栋斌, 徐友春, 王任栋, 等.基于多对点云匹配的三维激光雷达外参数标定[J].激光与光电子学进展, 2018, 55 (2) :022803.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201810047&amp;v=MjA1NjhaZVZ1Rnl6a1dyN01JalhUYkxHNEg5bk5yNDlCWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Zhao K, Xu Y C, Li Y L, et al.Large-scale scattered point-cloud denoising based on VG-DBSCANalgorithm[J].Acta Optica Sinica, 2018, 38 (10) :1028001.赵凯, 徐友春, 李永乐, 等.基于VG-DBSCAN算法的大场景散乱点云去噪[J].光学学报, 2018, 38 (10) :1028001.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201802016&amp;v=Mjc4OTZXcjdNSWpYVGJMRzRIOW5Nclk5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5ems=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Xiong F G, Huo W, Han X, et al.Removal method of mismatching keypoints in 3Dpoint cloud[J].Acta Optica Sinica, 2018, 38 (2) :0210003.熊风光, 霍旺, 韩燮, 等.三维点云中关键点误匹配剔除方法[J].光学学报, 2018, 38 (2) :0210003.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201905042" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201905042&amp;v=MDE1ODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXprV3I3TUlqWFRiTEc0SDlqTXFvOUJab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9ralVvUTBSTDAybXhOTGFHZWhJcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

