

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134132943408750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201903006%26RESULT%3d1%26SIGN%3dRHws690UDkNpOcO7MBrxjh3YPDw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201903006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903006&amp;v=MTQ2MzF1RnlIbVU3M0xJalhUYkxHNEg5ak1ySTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#82" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="2 LYTRO相机像素分布特性与点扩散函数 ">2 LYTRO相机像素分布特性与点扩散函数</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;2.1 LYTRO相机的像素分布特性&lt;/b&gt;"><b>2.1 LYTRO相机的像素分布特性</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;2.2 LYTRO相机点扩散函数测定&lt;/b&gt;"><b>2.2 LYTRO相机点扩散函数测定</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;2.3 测量结果&lt;/b&gt;"><b>2.3 测量结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="3 LYTRO相机像素点精确色彩恢复 ">3 LYTRO相机像素点精确色彩恢复</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#114" data-title="&lt;b&gt;3.1 色彩恢复算法&lt;/b&gt;"><b>3.1 色彩恢复算法</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;3.2 金字塔优化算法&lt;/b&gt;"><b>3.2 金字塔优化算法</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;3.3 色彩恢复实验验证与结果分析&lt;/b&gt;"><b>3.3 色彩恢复实验验证与结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#150" data-title="4 精确颜色矢量约束下的超分辨率图像恢复 ">4 精确颜色矢量约束下的超分辨率图像恢复</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#152" data-title="&lt;b&gt;4.1 LYTRO相机子孔径图像序列获取&lt;/b&gt;"><b>4.1 LYTRO相机子孔径图像序列获取</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;4.2 实验结果与对比分析&lt;/b&gt;"><b>4.2 实验结果与对比分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="图1 光场成像原理图">图1 光场成像原理图</a></li>
                                                <li><a href="#112" data-title="图2 LYTRO相机点扩散函数实测结果">图2 LYTRO相机点扩散函数实测结果</a></li>
                                                <li><a href="#117" data-title="图3 六边形RST坐标系">图3 六边形RST坐标系</a></li>
                                                <li><a href="#119" data-title="图4 扩散函数点的分布位置示意图 (a) 和局部放大图 (b) ">图4 扩散函数点的分布位置示意图 (a) 和局部放大图 (b) </a></li>
                                                <li><a href="#123" data-title="表1 不同层数的扩散函数点坐标">表1 不同层数的扩散函数点坐标</a></li>
                                                <li><a href="#126" data-title="图5 彩色滤波片与扩散函数点的分布">图5 彩色滤波片与扩散函数点的分布</a></li>
                                                <li><a href="#127" data-title="表2 彩色滤波片分布模式">表2 彩色滤波片分布模式</a></li>
                                                <li><a href="#132" data-title="图6 金字塔模型">图6 金字塔模型</a></li>
                                                <li><a href="#133" data-title="图7 LYTRO相机金字塔算法模型">图7 LYTRO相机金字塔算法模型</a></li>
                                                <li><a href="#136" data-title="图8 算法流程图">图8 算法流程图</a></li>
                                                <li><a href="#145" data-title="图9 LYTRO相机采集的原始图像信息。">图9 LYTRO相机采集的原始图像信息。</a></li>
                                                <li><a href="#147" data-title="图10 4种算法实验结果及局部放大图">图10 4种算法实验结果及局部放大图</a></li>
                                                <li><a href="#155" data-title="图11 两组图像色彩恢复结果。">图11 两组图像色彩恢复结果。</a></li>
                                                <li><a href="#156" data-title="表3 图像1评价数据">表3 图像1评价数据</a></li>
                                                <li><a href="#157" data-title="表4 图像2评价数据">表4 图像2评价数据</a></li>
                                                <li><a href="#158" data-title="图12 原始图像及子孔径图像。">图12 原始图像及子孔径图像。</a></li>
                                                <li><a href="#164" data-title="图13 原始图像及局部放大图像。">图13 原始图像及局部放大图像。</a></li>
                                                <li><a href="#166" data-title="图14 算法实验对比。">图14 算法实验对比。</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="12">


                                    <a id="bibliography_1" title=" Lippmann G. &#201;preuves r&#233;versibles donnant La sensation du relief[J]. Journal de Physique Th&#233;orique et Appliqu&#233;e, 1908, 7 (1) : 821-825." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;#233;preuves r&amp;#233;versibles donnant la sensation du relief">
                                        <b>[1]</b>
                                         Lippmann G. &#201;preuves r&#233;versibles donnant La sensation du relief[J]. Journal de Physique Th&#233;orique et Appliqu&#233;e, 1908, 7 (1) : 821-825.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_2" title=" Wilburn B, Joshi N, Vaish V, &lt;i&gt;et al&lt;/i&gt;. High performance imaging using large camera arrays[J]. ACM Transactions on Graphics, 2005, 24 (3) : 765-776." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098252&amp;v=MjczNDk0OUZaT0lIRG5rN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUtWMFVhQkU9TmlmSVk3SzdIdGpOcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Wilburn B, Joshi N, Vaish V, &lt;i&gt;et al&lt;/i&gt;. High performance imaging using large camera arrays[J]. ACM Transactions on Graphics, 2005, 24 (3) : 765-776.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_3" title=" Yang J C, Everett M, &lt;i&gt;et al&lt;/i&gt;. A real-time distributed light field camera[J]. Euro Graphics Workshop on Rendering, 2002: 77-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A real-time distributed light field camera">
                                        <b>[3]</b>
                                         Yang J C, Everett M, &lt;i&gt;et al&lt;/i&gt;. A real-time distributed light field camera[J]. Euro Graphics Workshop on Rendering, 2002: 77-86.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_4" title=" Lumsdaine A, Georgiev T. The focused plenoptic camera[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The focused plenoptic camera">
                                        <b>[4]</b>
                                         Lumsdaine A, Georgiev T. The focused plenoptic camera[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-8.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_5" title=" Ng R. Fourier slice photography[J]. ACM Transactions on Graphics, 2005, 24 (3) : 735-744." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098249&amp;v=MTcyNTNlWnVIeWptVWIvSUtWMFVhQkU9TmlmSVk3SzdIdGpOcjQ5RlpPSUhEbmd3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Ng R. Fourier slice photography[J]. ACM Transactions on Graphics, 2005, 24 (3) : 735-744.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_6" title=" Ashok V, Ramesh R Amit A, &lt;i&gt;et al&lt;/i&gt;. Dappled photography: mask enhanced cameras for heterodyned light fields and coded aperture refocusing[J]. ACM Transactions on Graphics, 2007, 26 (3) : 69." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098521&amp;v=MTUzODVPSUhDWDQ0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JS1YwVWFCRT1OaWZJWTdLN0h0ak5yNDlGWg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Ashok V, Ramesh R Amit A, &lt;i&gt;et al&lt;/i&gt;. Dappled photography: mask enhanced cameras for heterodyned light fields and coded aperture refocusing[J]. ACM Transactions on Graphics, 2007, 26 (3) : 69.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_7" title=" Georgiev T, Zheng K C, &lt;i&gt;et al&lt;/i&gt;. Spatio-angular resolution tradeoffs in integral photography[J]. Euro Graphics Conference on Rendering Techniques, 2006: 263-272." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatio-Angular Resolution Tradeoffs in IntegralPhotography">
                                        <b>[7]</b>
                                         Georgiev T, Zheng K C, &lt;i&gt;et al&lt;/i&gt;. Spatio-angular resolution tradeoffs in integral photography[J]. Euro Graphics Conference on Rendering Techniques, 2006: 263-272.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_8" title=" Unger J, Wenger A, &lt;i&gt;et al&lt;/i&gt;. Capturing and rendering with incident light fields[J]. Euro Graphics Workshop on Rendering, 2003: 141-149." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Capturing and rendering with incident light fields">
                                        <b>[8]</b>
                                         Unger J, Wenger A, &lt;i&gt;et al&lt;/i&gt;. Capturing and rendering with incident light fields[J]. Euro Graphics Workshop on Rendering, 2003: 141-149.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_9" title=" Lytro, http://lytro.com/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lytro">
                                        <b>[9]</b>
                                         Lytro, http://lytro.com/.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_10" title=" Raytrix, http: //www.raytrix.de/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Raytrix">
                                        <b>[10]</b>
                                         Raytrix, http: //www.raytrix.de/.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_11" title=" Dansereau D G, Pizarro O, Williams S B. Decoding, calibration and rectification for lenselet-based plenoptic cameras[C]∥2013 IEEE Conference on Computer Vision and Pattern Recognition, June 23-28, 2013, Portland, OR, USA. New York: IEEE, 2013: 1027-1034." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Decoding,calibration and rectification for lenselet-based plenoptic cameras">
                                        <b>[11]</b>
                                         Dansereau D G, Pizarro O, Williams S B. Decoding, calibration and rectification for lenselet-based plenoptic cameras[C]∥2013 IEEE Conference on Computer Vision and Pattern Recognition, June 23-28, 2013, Portland, OR, USA. New York: IEEE, 2013: 1027-1034.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_12" title=" Bishop T E, Zanetti S, Favaro P. Light field superresolution[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Light field superresolution">
                                        <b>[12]</b>
                                         Bishop T E, Zanetti S, Favaro P. Light field superresolution[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-9.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_13" title=" Mitra K, Veeraraghavan A. Light field denoising, light field superresolution and stereo camera based refocussing using a GMM light field patch prior[C]//2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 22-28." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Light field denoising,light field superresolution and stereo camera based refocussing using a GMM light field patch prior">
                                        <b>[13]</b>
                                         Mitra K, Veeraraghavan A. Light field denoising, light field superresolution and stereo camera based refocussing using a GMM light field patch prior[C]//2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 22-28.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_14" title=" Wanner S, Goldluecke B. Spatial and angular variational super-resolution of 4D light fields[M]//Fitzgibbon A, Lazebnik S, Perona P, &lt;i&gt;et al&lt;/i&gt;. eds. Computer Vision-ECCV 2012. Berlin, Heidelberg: Springer, 2012: 608-621." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial and angular variational super-resolution of4D light fields">
                                        <b>[14]</b>
                                         Wanner S, Goldluecke B. Spatial and angular variational super-resolution of 4D light fields[M]//Fitzgibbon A, Lazebnik S, Perona P, &lt;i&gt;et al&lt;/i&gt;. eds. Computer Vision-ECCV 2012. Berlin, Heidelberg: Springer, 2012: 608-621.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_15" title=" Qiu K, Yi B S, Xiang M, &lt;i&gt;et al&lt;/i&gt;. Collaborative sparse dictionary learning for reconstruction of single image super resolution[J]. Acta Optica Sinica, 2018, 38 (9) : 0910002. 邱康, 易本顺, 向勉, 等. 协作稀疏字典学习实现单幅图像超分辨率重建[J]. 光学学报, 2018, 38 (9) : 0910002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201809017&amp;v=MTA1NTgzTElqWFRiTEc0SDluTXBvOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVTc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Qiu K, Yi B S, Xiang M, &lt;i&gt;et al&lt;/i&gt;. Collaborative sparse dictionary learning for reconstruction of single image super resolution[J]. Acta Optica Sinica, 2018, 38 (9) : 0910002. 邱康, 易本顺, 向勉, 等. 协作稀疏字典学习实现单幅图像超分辨率重建[J]. 光学学报, 2018, 38 (9) : 0910002.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_16" title=" Tai Y, Yang J, Liu X M. Image super-resolution via deep recursive residual network[C]∥2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA. New York: IEEE, 2017: 2790-2798." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via deep recursive resid-ual network">
                                        <b>[16]</b>
                                         Tai Y, Yang J, Liu X M. Image super-resolution via deep recursive residual network[C]∥2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA. New York: IEEE, 2017: 2790-2798.
                                    </a>
                                </li>
                                <li id="44">


                                    <a id="bibliography_17" title=" Li S M, Lei G Q, Fan R. Depth map super-resolution reconstruction based on convolutional neural networks[J]. Acta Optica Sinica, 2017, 37 (12) : 1210002. 李素梅, 雷国庆, 范如. 基于卷积神经网络的深度图超分辨率重建[J]. 光学学报, 2017, 37 (12) : 1210002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201712015&amp;v=MDAxODc0SDliTnJZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeUhtVTczTElqWFRiTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Li S M, Lei G Q, Fan R. Depth map super-resolution reconstruction based on convolutional neural networks[J]. Acta Optica Sinica, 2017, 37 (12) : 1210002. 李素梅, 雷国庆, 范如. 基于卷积神经网络的深度图超分辨率重建[J]. 光学学报, 2017, 37 (12) : 1210002.
                                    </a>
                                </li>
                                <li id="46">


                                    <a id="bibliography_18" title=" P&#233;rez F, P&#233;rez A, Rodr&#237;guez M, &lt;i&gt;et al&lt;/i&gt;. Fourier slice super-resolution in plenoptic cameras[C]∥2012 IEEE International Conference on Computational Photography (ICCP) , April 28-29, 2012, Seattle, WA, USA. New York: IEEE, 2012: 1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fourier slice super-resolution in plenoptic cameras">
                                        <b>[18]</b>
                                         P&#233;rez F, P&#233;rez A, Rodr&#237;guez M, &lt;i&gt;et al&lt;/i&gt;. Fourier slice super-resolution in plenoptic cameras[C]∥2012 IEEE International Conference on Computational Photography (ICCP) , April 28-29, 2012, Seattle, WA, USA. New York: IEEE, 2012: 1-11.
                                    </a>
                                </li>
                                <li id="48">


                                    <a id="bibliography_19" title=" Shi L X, Hassanieh H, Davis A, &lt;i&gt;et al&lt;/i&gt;. Light field reconstruction using sparsity in the continuous Fourier domain[J]. ACM Transactions on Graphics, 2014, 34 (1) : 1-13." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Light Field Reconstruction Using Sparsity in the ContinuousFourier Domain">
                                        <b>[19]</b>
                                         Shi L X, Hassanieh H, Davis A, &lt;i&gt;et al&lt;/i&gt;. Light field reconstruction using sparsity in the continuous Fourier domain[J]. ACM Transactions on Graphics, 2014, 34 (1) : 1-13.
                                    </a>
                                </li>
                                <li id="50">


                                    <a id="bibliography_20" title=" Broxton M, Grosenick L, Yang S, &lt;i&gt;et al&lt;/i&gt;. Wave optics theory and 3-D deconvolution for the light field microscope[J]. Optics Express, 2013, 21 (21) : 25418-25439." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wave optics theory and 3-D deconvolution for the light field microscope">
                                        <b>[20]</b>
                                         Broxton M, Grosenick L, Yang S, &lt;i&gt;et al&lt;/i&gt;. Wave optics theory and 3-D deconvolution for the light field microscope[J]. Optics Express, 2013, 21 (21) : 25418-25439.
                                    </a>
                                </li>
                                <li id="52">


                                    <a id="bibliography_21" title=" Trujillo-Sevilla J M, Rodr&#237;guez-Ramos L F, Montilla I, &lt;i&gt;et al&lt;/i&gt;. High resolution imaging and wavefront aberration correction in plenoptic systems[J]. Optics Letters, 2014, 39 (17) : 5030-5033." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High resolution imaging and wavefront aberration correction in plenoptic systems">
                                        <b>[21]</b>
                                         Trujillo-Sevilla J M, Rodr&#237;guez-Ramos L F, Montilla I, &lt;i&gt;et al&lt;/i&gt;. High resolution imaging and wavefront aberration correction in plenoptic systems[J]. Optics Letters, 2014, 39 (17) : 5030-5033.
                                    </a>
                                </li>
                                <li id="54">


                                    <a id="bibliography_22" title=" Alam M Z, Gunturk B K. Hybrid stereo imaging including a light field and a regular camera[C]//2016 24th Signal Processing and Communication Application Conference (SIU) , May 16-19 2016, Zonguldak, Turkey. New York: IEEE, 2016: 1293-1296." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hybrid stereo imaging including a light field and a regular camera">
                                        <b>[22]</b>
                                         Alam M Z, Gunturk B K. Hybrid stereo imaging including a light field and a regular camera[C]//2016 24th Signal Processing and Communication Application Conference (SIU) , May 16-19 2016, Zonguldak, Turkey. New York: IEEE, 2016: 1293-1296.
                                    </a>
                                </li>
                                <li id="56">


                                    <a id="bibliography_23" title=" Wang X, Li L, Hou G Q. High-resolution light field reconstruction using a hybrid imaging system[J]. Applied Optics, 2016, 55 (10) : 2580-2593." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-resolution light field reconstruction using a hybrid imaging system">
                                        <b>[23]</b>
                                         Wang X, Li L, Hou G Q. High-resolution light field reconstruction using a hybrid imaging system[J]. Applied Optics, 2016, 55 (10) : 2580-2593.
                                    </a>
                                </li>
                                <li id="58">


                                    <a id="bibliography_24" title=" Wu J D, Wang H Q, Wang X Z, &lt;i&gt;et al&lt;/i&gt;. A novel light field super-resolution framework based on hybrid imaging system[C]∥2015 Visual Communications and Image Processing (VCIP) , December 13-16, 2015, Singapore, Singapore. New York: IEEE, 2015: 1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel light field super-resolution framework based on hybrid imaging system">
                                        <b>[24]</b>
                                         Wu J D, Wang H Q, Wang X Z, &lt;i&gt;et al&lt;/i&gt;. A novel light field super-resolution framework based on hybrid imaging system[C]∥2015 Visual Communications and Image Processing (VCIP) , December 13-16, 2015, Singapore, Singapore. New York: IEEE, 2015: 1-4.
                                    </a>
                                </li>
                                <li id="60">


                                    <a id="bibliography_25" title=" Ohashi K, Takahashi K, Tehrani M P, &lt;i&gt;et al&lt;/i&gt;. Super-resolution image synthesis using the physical pixel arrangement of a light field camera[C]//2015 IEEE International Conference on Image Processing (ICIP) , September 27-30, 2015, Quebec City, QC, Canada. New York: IEEE, 2015: 2964-2968." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Super-resolution Image Synthesis Using the Physical Pixel Arrangemen to Light Field Camera">
                                        <b>[25]</b>
                                         Ohashi K, Takahashi K, Tehrani M P, &lt;i&gt;et al&lt;/i&gt;. Super-resolution image synthesis using the physical pixel arrangement of a light field camera[C]//2015 IEEE International Conference on Image Processing (ICIP) , September 27-30, 2015, Quebec City, QC, Canada. New York: IEEE, 2015: 2964-2968.
                                    </a>
                                </li>
                                <li id="62">


                                    <a id="bibliography_26" title=" Li Z N. The principle of modern optical system[M]. Beijing: Beijing Polytechnic University Press, 1994: 155-160. 李志能. 现代光学系统原理[M]. 北京: 北京理工大学出版社, 1994: 155-160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810131133999&amp;v=Mjg1Mjl1OXVGQ3JsVTdiTElGd1hWVjI3R2J1NUh0RFBybzVHWitJR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZa&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         Li Z N. The principle of modern optical system[M]. Beijing: Beijing Polytechnic University Press, 1994: 155-160. 李志能. 现代光学系统原理[M]. 北京: 北京理工大学出版社, 1994: 155-160.
                                    </a>
                                </li>
                                <li id="64">


                                    <a id="bibliography_27" title=" Zhou W H, Lin L L. Light field image rectification and refocus method for Lytro camera[J]. Journal of Image and Graphics, 2014, 19 (7) : 1006-1011. 周文晖, 林丽莉. Lytro相机的光场图像校正与重对焦方法[J]. 中国图象图形学报, 2014, 19 (7) : 1006-1011." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201407003&amp;v=MDM1NzdCdEdGckNVUkxPZVplVnVGeUhtVTczTFB5cmZiTEc0SDlYTXFJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                         Zhou W H, Lin L L. Light field image rectification and refocus method for Lytro camera[J]. Journal of Image and Graphics, 2014, 19 (7) : 1006-1011. 周文晖, 林丽莉. Lytro相机的光场图像校正与重对焦方法[J]. 中国图象图形学报, 2014, 19 (7) : 1006-1011.
                                    </a>
                                </li>
                                <li id="66">


                                    <a id="bibliography_28" title=" Bayer B E. Color imaging array: US3971065[P]. 1976-07-27." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color imaging array">
                                        <b>[28]</b>
                                         Bayer B E. Color imaging array: US3971065[P]. 1976-07-27.
                                    </a>
                                </li>
                                <li id="68">


                                    <a id="bibliography_29" title=" Lu W M, Tan Y P. Color filter array demosaicking: new method and performance measures[J]. IEEE Transactions on Image Processing, 2003, 12 (10) : 1194-1210." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color filter array demosaicking: new method and performance measures">
                                        <b>[29]</b>
                                         Lu W M, Tan Y P. Color filter array demosaicking: new method and performance measures[J]. IEEE Transactions on Image Processing, 2003, 12 (10) : 1194-1210.
                                    </a>
                                </li>
                                <li id="70">


                                    <a id="bibliography_30" title=" Lu W M, Tan Y P. Adaptive color filter array demosaicking using directional spatial and spectral correlations[C]//Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint, December 15-18, 2003, Singapore, Singapore. New York: IEEE, 2003: 76-80." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive color filter array demosaicking using directional spatial and spectral correlations">
                                        <b>[30]</b>
                                         Lu W M, Tan Y P. Adaptive color filter array demosaicking using directional spatial and spectral correlations[C]//Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint, December 15-18, 2003, Singapore, Singapore. New York: IEEE, 2003: 76-80.
                                    </a>
                                </li>
                                <li id="72">


                                    <a id="bibliography_31" title=" Gunturk B K, Altunbasak Y, Mersereau R M. Color plane interpolation using alternating projections[J]. IEEE Transactions on Image Processing, 2002, 11 (9) : 997-1013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color plane interpolation using alternating projections">
                                        <b>[31]</b>
                                         Gunturk B K, Altunbasak Y, Mersereau R M. Color plane interpolation using alternating projections[J]. IEEE Transactions on Image Processing, 2002, 11 (9) : 997-1013.
                                    </a>
                                </li>
                                <li id="74">


                                    <a id="bibliography_32" title=" Wang Z, Bovik A C, Sheikh H R, &lt;i&gt;et al&lt;/i&gt;. Image quality assessment: from error visibility to structural similarity[J]. IEEE Transactions on Image Processing, 2004, 13 (4) : 600-612." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Quality Assessment:From Error Measurement to Structural Similarity">
                                        <b>[32]</b>
                                         Wang Z, Bovik A C, Sheikh H R, &lt;i&gt;et al&lt;/i&gt;. Image quality assessment: from error visibility to structural similarity[J]. IEEE Transactions on Image Processing, 2004, 13 (4) : 600-612.
                                    </a>
                                </li>
                                <li id="76">


                                    <a id="bibliography_33" title=" Sun F S, Han X, Ding J H, &lt;i&gt;et al&lt;/i&gt;. Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J]. Computer Engineering and Applications, 2018, 54 (13) : 175-180. 孙福盛, 韩燮, 丁江华, 等. LYTRO相机光场图像深度估计算法及重建的研究[J]. 计算机工程与应用, 2018, 54 (13) : 175-180." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813028&amp;v=MjE0NjFyQ1VSTE9lWmVWdUZ5SG1VNzNMTHo3TWFiRzRIOW5Ockk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[33]</b>
                                         Sun F S, Han X, Ding J H, &lt;i&gt;et al&lt;/i&gt;. Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J]. Computer Engineering and Applications, 2018, 54 (13) : 175-180. 孙福盛, 韩燮, 丁江华, 等. LYTRO相机光场图像深度估计算法及重建的研究[J]. 计算机工程与应用, 2018, 54 (13) : 175-180.
                                    </a>
                                </li>
                                <li id="78">


                                    <a id="bibliography_34" title=" Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A, 1989, 6 (11) : 1715-1726." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">
                                        <b>[34]</b>
                                         Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A, 1989, 6 (11) : 1715-1726.
                                    </a>
                                </li>
                                <li id="80">


                                    <a id="bibliography_35" title=" Tekalp A M, Ozkan M K, Sezan M I. High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration[C]∥[Proceedings]ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, March 23-26, 1992, San Francisco, CA, USA. New York: IEEE, 1992: 169-172." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration">
                                        <b>[35]</b>
                                         Tekalp A M, Ozkan M K, Sezan M I. High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration[C]∥[Proceedings]ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, March 23-26, 1992, San Francisco, CA, USA. New York: IEEE, 1992: 169-172.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-10-29 06:35</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(03),59-68 DOI:10.3788/AOS201939.0304001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>光场相机精确色彩矢量约束下的超分辨率算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E7%A6%8F%E7%9B%9B&amp;code=27517913&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙福盛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A9%E7%87%AE&amp;code=09479268&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">韩燮</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8C%97%E5%A4%A7%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E9%99%A2&amp;code=0036109&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中北大学大数据学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>以LYTRO相机为例, 提出一种精确色彩矢量约束下的光场图像超分辨率算法。根据相机内部微透镜阵列按六边形分布的特点, 结合点扩散函数, 及相机探测器阵列上滤光片的排列方式, 计算了每个单一像素点的RGB色彩分量值, 精确恢复出每一个像素的颜色信息;利用金字塔算法对色彩恢复的时效性进行了优化。提出一种基于相机子孔径图像序列颜色矢量约束下的超分辨率算法, 以提高图像质量。所提的色彩恢复方法可以用于多款光场相机, 同时以色彩矢量作为约束条件, 彩色超分辨率图像恢复的效果理想。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A2%E6%B5%8B%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">探测器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LYTRO%E7%9B%B8%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LYTRO相机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超分辨率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E9%80%8F%E9%95%9C%E9%98%B5%E5%88%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微透镜阵列;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%82%B9%E6%89%A9%E6%95%A3%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">点扩散函数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%89%B2%E5%BD%A9%E6%81%A2%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">色彩恢复;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *孙福盛 E-mail:sfs2699@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61672473);</span>
                    </p>
            </div>
                    <h1><b>Super-Resolution Algorithm Based on Precise Color Vector Constraint of Light Field Camera</b></h1>
                    <h2>
                    <span>Sun Fusheng</span>
                    <span>Han Xie</span>
            </h2>
                    <h2>
                    <span>School of Data Science and Technology, North University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Taking LYTRO camera as an example, we propose a super-resolution algorithm for light field image with precise color vector. According to the hexagonal distribution of the microlens array inside the camera, combining with the point spread function and the arrangement of the filters on the camera detector array, we calculate the RGB color component values of each single pixel point, and accurately recover the color information of each pixel. The timeliness of color restoration is optimized by using pyramid algorithm. In the second part, a super-resolution algorithm based on color vector constraint of camera sub-aperture image sequence is proposed to improve image quality. The proposed color restoration method can be applied to many kinds of light field cameras. At the same time, the color vector is used as the constraint condition, and the color super-resolution image restoration effect is ideal.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=detectors&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">detectors;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LYTRO%20camera&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LYTRO camera;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=super%20resolution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">super resolution;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=microlens%20array&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">microlens array;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=point%20spread%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">point spread function;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20restoration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color restoration;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-08-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="82" name="82" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="83">区别于普通相机, 光场相机能够捕捉光线的方向信息, 因此, 光场成像技术被广泛地应用于各个领域, 包括数码摄影、显微镜、机器人技术和机器视觉等。光场成像系统有多种不同的实现方式, 包括摄像机阵列<citation id="174" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 微透镜阵列 (MLA) <citation id="175" type="reference"><link href="18" rel="bibliography" /><link href="20" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 编码掩模<citation id="171" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 物镜阵列<citation id="172" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 及基于摄像系统<citation id="173" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等。其中, 基于MLA的光场相机能最大地符合成本效益, 被广泛地应用于学术研究及商业领域<citation id="176" type="reference"><link href="28" rel="bibliography" /><link href="30" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。但是, 基于MLA的光场相机的应用存在两个限制:低空间分辨率和窄基线。低空间分辨率限制了光场相机的通用性和适用性, 窄基线限制了深度估计的范围和精度。</p>
                </div>
                <div class="p1">
                    <p id="84">目前国内外相关学者提出了许多方法来解决基于MLA的光场相机的空间分辨率低的问题。一种主要的方法是将超分辨率图像恢复应用于光场子孔径图像, 通常是在贝叶斯框架下的超分辨率。例如, 文献<citation id="177" type="reference">[<a class="sup">11</a>]</citation>中的光场工具箱, 使用的是基于标准插值的方法;文献<citation id="178" type="reference">[<a class="sup">12</a>]</citation>中, 利用的是Lambertian定律和结构的先验;文献<citation id="179" type="reference">[<a class="sup">13</a>]</citation>中利用的是高斯混合模型;文献<citation id="180" type="reference">[<a class="sup">14</a>]</citation>中利用的是变分公式。基于学习的方法包括基于字典学习<citation id="181" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和深度卷积神经网络<citation id="183" type="reference"><link href="42" rel="bibliography" /><link href="44" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>。除了空间域超分辨率复原, 傅里叶域技术<citation id="184" type="reference"><link href="46" rel="bibliography" /><link href="48" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>和波动光学三维反卷积方法<citation id="185" type="reference"><link href="50" rel="bibliography" /><link href="52" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>也被用于超分辨率图像恢复。另一种提高分辨率的方法是使用混合式双摄像机系统, 包括光场照相机和高分辨率照相机两台相机, 通过合并图像以提高分辨率<citation id="186" type="reference"><link href="54" rel="bibliography" /><link href="56" rel="bibliography" /><link href="58" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>。文献<citation id="187" type="reference">[<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>]</citation>中使用字典学习技术, 从普通相机的高分辨率图像中提取图像, 并存储为一种高分辨率补丁字典。文献<citation id="182" type="reference">[<a class="sup">25</a>]</citation>通过一种直接的物理像素排列的方式, 实现了光场相机超分辨恢复。然而, 基于插值的方法虽然简便易行, 但是精度较低;而基于学习的方法又需要大量的前期学习与建库, 成本很高;混合方法需要借助于普通高分辨相机, 实验过程较为复杂;直接法虽然优于插值法, 但超分辨图像边缘抗锯齿效果不佳。鉴于此, 研究一种高精度且简单易行的超分辨算法很有必要。</p>
                </div>
                <div class="p1">
                    <p id="85">本文以第一代MLA光场相机——LYTRO相机为例, 根据相机内部微透镜阵列按六边形分布的特性, 结合点扩散函数及相机探测器阵列上滤光片的排列方式, 计算每个单一像素点的RGB色彩分量值, 精确恢复出每一个像素的颜色信息;并用一种方便简洁的金字塔算法对色彩恢复的时效性进行优化。同时, 提出一种基于相机子孔径图像序列颜色矢量约束下的超分辨处理算法, 用于解决相机分辨率低的问题。</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag">2 LYTRO相机像素分布特性与点扩散函数</h3>
                <h4 class="anchor-tag" id="87" name="87"><b>2.1 LYTRO相机的像素分布特性</b></h4>
                <div class="p1">
                    <p id="88">以LYTRO相机<citation id="188" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>为例, 成像结构<citation id="189" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>由三部分组成:前置光学系统、微透镜阵列和探测器。前置光学系统采用传统的光学成像系统原理, 其功能是对目标进行成像, 如图1所示, 用一个主镜代替前置光学系统。微透镜阵列放置在前置光学系统的对焦像面上, 其含有328×328个独立的微透镜, 每个微透镜下面覆盖着10×10个探测器像元。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 光场成像原理图" src="Detail/GetImg?filename=images/GXXB201903006_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 光场成像原理图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Principle diagram of optical field imaging</p>

                </div>
                <div class="p1">
                    <p id="90">LYTRO相机微透镜阵列采用六边形排列形式, 生成3280 pixel×3280 pixel、高12 bit的Bayer格式图像。其获取光线的R、G、B 3种颜色信号的方式是在CCD (charge coupled device) 传感器上覆盖一片拼贴有R、Gr、Gb、B 4种分量的马赛克滤镜。这一彩色滤波镜的R、G、B分量比值为1∶1∶1, 可以更好地还原图像的原始颜色, 而且每个像素只能感知一个颜色, LYTRO相机输出的数据按照“GRGR/BGBG”形式排列, 可以通过解析原始文件, 得到Bayer Pattern的原始数据, 这些原始数据以**.lfp (light field picture) 的文件格式存储。**.lfp文件是LYTRO相机独有的包含相机参数及照片参数的文件, 通过解析可获得光线数据。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>2.2 LYTRO相机点扩散函数测定</b></h4>
                <div class="p1">
                    <p id="92">光学系统处于理想状态是指物空间中的一点所发出的光能量在成像空间中聚集在一个点上。但在实际光学系统成像时, 物空间一点所发出的光在成像空间中总会在一定的区域内分散, 这种光点分散的现象为点扩散现象, 光点的扩散形式可以由点扩散函数 (PSF, point spread function) <citation id="190" type="reference"><link href="62" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>表示。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">2.2.1 测量原理</h4>
                <div class="p1">
                    <p id="94">根据文献<citation id="191" type="reference">[<a class="sup">26</a>]</citation>可知, 如果光学系统的输入是线光源, 则此时的系统输出为线响应函数, 用<i>g</i><sub><i>x</i></sub> (<i>x</i>) 表示, 即</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>δ</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd columnalign="left"><mi>g</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>S</mi><mo stretchy="false">[</mo><mi>δ</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">式中<i>i</i> (<i>x</i>, <i>y</i>) 为系统输入函数。若用未知的脉冲响应函数<i>h</i> (<i>x</i>, <i>y</i>) 表示线响应函数, 响应函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>δ</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>*</mo><mi>h</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msubsup><mo>∫</mo><mrow><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mi>h</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">即系统线响应函数是该系统的点扩散函数在线光源方向的积分。</p>
                </div>
                <div class="p1">
                    <p id="99">当输入为阶跃函数时, 其输出响应为边缘响应, 记为<i>e</i><sub><i>x</i></sub> (<i>x</i>) , 即</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>x</mi><mo>≥</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>x</mi><mo>≤</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><mo stretchy="false">[</mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mi>e</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtable columnalign="left"><mtr><mtd><mi>S</mi><mo>=</mo><mi>e</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>*</mo><mi>h</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>=</mo><msubsup><mstyle mathsize="140%" displaystyle="true"><mo>∬</mo></mstyle><mrow><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mi>h</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext>d</mtext><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mtext>d</mtext><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd><mo>=</mo><mstyle displaystyle="true"><mrow><munderover><mo>∫</mo><mrow><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></munderover><mi>g</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext>d</mtext><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd><mo>=</mo><mi>g</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mo>*</mo><mi>s</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><munderover><mo>∫</mo><mrow><mo>-</mo><mi>∞</mi></mrow><mi>x</mi></munderover><mi>g</mi></mrow></mstyle><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext>d</mtext><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo>。</mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">由 (5) 式可得</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mtext>d</mtext><mi>e</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mtext>d</mtext><mi>x</mi></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">由此可知, 可以采用测定系统的边缘响应的方法来测定一个光学系统的点扩散函数。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">2.2.2 测量方法</h4>
                <div class="p1">
                    <p id="105">对于绝大部分光学系统而言, 决定系统点扩散函数的因素有很多, 综合结果总是使其点扩散函数趋于Gauss型<citation id="192" type="reference"><link href="62" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>, 可以表达为</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>, </mo></mtd><mtd columnalign="left"><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>C</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext><mtext>s</mtext></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">式中:<i>σ</i>为标准偏差, 标准差越小说明光学系统成像质量越好;<i>C</i>为<i>h</i> (<i>x</i>, <i>y</i>) 的圆形支持域。根据 (2) 式, 其线响应函数可表示为</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msubsup><mo>∫</mo><mrow><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></msubsup><mi>h</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>σ</mi><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt></mrow></mfrac><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109">利用黑白跳变图像作为目标, CCD所获取的信号为光系统的边缘响应。对CCD获取的离散信号作一阶差分, 再按Gauss曲线进行最小二乘拟合, 即可求得标准偏差<i>σ</i>, 从而可以确定光学系统的点扩散函数。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>2.3 测量结果</b></h4>
                <div class="p1">
                    <p id="111">LYTRO相机每个微透镜的直径为13.99 μm, 因此可以确定采样间隔<i>δ</i><sub>d</sub>为1.399 μm。利用MATLAB对LYTRO相机的点扩散函数计算结果进行模拟, 得到的LYTRO相机点扩散函数实测结果如图2所示。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 LYTRO相机点扩散函数实测结果" src="Detail/GetImg?filename=images/GXXB201903006_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 LYTRO相机点扩散函数实测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Measured results of PSF of LYTRO camera</p>

                </div>
                <h3 id="113" name="113" class="anchor-tag">3 LYTRO相机像素点精确色彩恢复</h3>
                <h4 class="anchor-tag" id="114" name="114"><b>3.1 色彩恢复算法</b></h4>
                <h4 class="anchor-tag" id="115" name="115">3.1.1 建立六边形坐标系</h4>
                <div class="p1">
                    <p id="116">结合LYTRO相机微透镜阵列按照六边形排列的特性, 本研究算法建立了一个六边形<i>RST</i>坐标系, 如图3所示;该坐标系无需对坐标进行实际定义, 通过与直角坐标系的叠加使用能清晰地表达LYTRO相机点扩散函数的算法思路, 便于扩散函数点的描述与计算。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 六边形RST坐标系" src="Detail/GetImg?filename=images/GXXB201903006_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 六边形RST坐标系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Hexagonal RST coordinate system</p>

                </div>
                <div class="p1">
                    <p id="118">由于LYTRO相机微透镜阵列中的每个单独的微透镜所覆盖的像素点个数为10×10, 其显示的图像是物体发射或反射出的光线通过相机主透镜在传感器上形成的物像。依据点扩散函数的特性, 如图4所示, 中心透镜O所覆盖的像素点与其相邻区域内的6个微透镜所覆盖的像素点具有对应性;同时, 探测器上每一个像素点都会对应多个扩散函数点, 且扩散像素点与扩散函数点为同一坐标点。同理, 每一个透镜所覆盖的任意单个像素点都会有6的整数倍个对应像素点。为了减小计算量及计算误差, 取分布在中心透镜周围的相邻透镜内的6个像素点。</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 扩散函数点的分布位置示意图 (a) 和局部放大图 (b)" src="Detail/GetImg?filename=images/GXXB201903006_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 扩散函数点的分布位置示意图 (a) 和局部放大图 (b)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Distribution and location diagram of diffusion function points (a) and local magnification diagram (b) </p>

                </div>
                <div class="p1">
                    <p id="120">如图4 (a) 所示, 透镜A、B、C、D、E、F的中心点分别为<i>a</i>、<i>b</i>、<i>c</i>、<i>d</i>、<i>e</i>、<i>f</i>。中心透镜O的中心像素点<i>o</i> (目标点) 所对应的扩散像素点 (扩散函数点) 为六边形A、B、C、D、E、F中的点<i>a</i>′、<i>b</i>′、<i>c</i>′、<i>d</i>′、<i>e</i>′、<i>f</i>′, 如图4 (b) 所示。每一个扩散函数点与目标点<i>o</i>之间的距离相同, 这样就会在坐标区域内形成多个同心圆, 对应的扩散函数点均匀分布在这些同心圆上;每个圆上均有6个扩散函数点。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">3.1.2 扩散函数点位置计算</h4>
                <div class="p1">
                    <p id="122">利用给出的点扩散函数模型, 可以得到任意一个扩散函数点的位置坐标。在计算过程中, 将像素灰度值为0的点及位于彩色滤光片边界上的扩散函数点定义为噪声点, 进行剔除处理。令中心透镜O的中心像素点<i>o</i> (0, 0) 为坐标系原点, <i>o</i>点所对应的扩散函数点在直角坐标系下的坐标如表1所示。</p>
                </div>
                <div class="area_img" id="123">
                    <p class="img_tit">表1 不同层数的扩散函数点坐标 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Diffusion function point coordinates of different layers</p>
                    <p class="img_note"></p>
                    <table id="123" border="1"><tr><td><br />Point</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td><br /><i>a</i></td><td> (0, 11.671) </td><td> (0, 23.758) </td><td> (0, 35.239) </td><td> (0, 46.837) </td></tr><tr><td><br /><i>b</i></td><td> (10.107, 5.836) </td><td> (20.575, 11.879) </td><td> (30.518, 17.620) </td><td> (40.562, 23.419) </td></tr><tr><td><br /><i>c</i></td><td> (10.107, -5.836) </td><td> (20.575, -11.879) </td><td> (30.518, -17.620) </td><td> (40.562, -23.419) </td></tr><tr><td><br /><i>d</i></td><td> (0, -11.671) </td><td> (0, -23.758) </td><td> (0, -35.239) </td><td> (0, -46.837) </td></tr><tr><td><br /><i>e</i></td><td> (-10.701, -5.836) </td><td> (-20.575, -11.879) </td><td> (-30.518, -17.620) </td><td> (-40.562, -23.419) </td></tr><tr><td><br /><i>f</i></td><td> (-10.701, 5.836) </td><td> (-20.575, 11.879) </td><td> (-30.518, 17.620) </td><td> (-40.562, 23.419) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="124">在每个微透镜下所覆盖的100个像素点中, 有效像素点的个数约为78个;剩余的22个无效像素点 (像素灰度值为0的点) 为噪声点, 需要将其剔除。由于在实际计算过程中有些像素的对应扩散函数点的位置在无效范围内 (扩散函数点处于彩色滤光片边界) , 所以任意一个像素点都约有21个与之对应的扩散函数点。边缘位置的像素点对应的扩散函数点数目约为13, 4个角点所对应的扩散函数点数目约为6。</p>
                </div>
                <div class="p1">
                    <p id="125">图5为模拟中心点<i>o</i>及其对应的扩散函数点在彩色滤光片覆盖下的位置模型。由于<i>RST</i>三轴上每一个扩散像素点所处位置不同, 所以其上方所覆盖的彩色滤光片的颜色也各不相同。通过对存储图像文件**.lfp进行分析, 可得到感应器上覆盖的彩色滤波器的模式分布, 如表2所示。由此可以看出, LYTRO相机彩色滤光片中, 绿色信息更多, 失真更少。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 彩色滤波片与扩散函数点的分布" src="Detail/GetImg?filename=images/GXXB201903006_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 彩色滤波片与扩散函数点的分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Distribution of color filters and diffusion function points</p>

                </div>
                <div class="area_img" id="127">
                    <p class="img_tit">表2 彩色滤波片分布模式 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Color filter distribution mode</p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br />Column No.</td><td colspan="7">Mode</td></tr><tr><td>1</td><td>R</td><td>Gr</td><td>R</td><td>Gr</td><td>R</td><td>…</td><td>R</td></tr><tr><td><br />2</td><td>Gb</td><td>B</td><td>Gb</td><td>B</td><td>Gb</td><td>…</td><td>Gb</td></tr><tr><td><br />3</td><td>R</td><td>Gr</td><td>R</td><td>Gr</td><td>R</td><td>…</td><td>R</td></tr><tr><td><br />4</td><td>Gb</td><td>B</td><td>Gb</td><td>B</td><td>Gb</td><td>…</td><td>Gb</td></tr><tr><td><br />5</td><td>R</td><td>Gr</td><td>R</td><td>Gr</td><td>R</td><td>…</td><td>R</td></tr><tr><td><br />︙</td><td>︙</td><td>︙</td><td>︙</td><td>︙</td><td>︙</td><td>︙</td><td>︙</td></tr><tr><td><br /><i>N</i></td><td>Gb</td><td>B</td><td>Gb</td><td>B</td><td>Gb</td><td>…</td><td>Gb</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="128">综上, 便可直接将对应扩散像素点RGB的值与目标像素进行绑定, 从而达到精确赋值, 用以恢复图像的色彩。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>3.2 金字塔优化算法</b></h4>
                <h4 class="anchor-tag" id="130" name="130">3.2.1 算法介绍</h4>
                <div class="p1">
                    <p id="131">与矩形采样相比, 金字塔算法的六边形采样可减少13.4%的数据量。六边形具有各向等距的性质;同时, 由于六边形变换以7为倍率递减, 以此建立金字塔模型, 时效性更高。结合LYTRO相机微透镜阵列按六边形排列的特点, 使用六边形金字塔算法, 来收敛第2节所提出算法的时间复杂度, 提高算法的时效性。图6所示为金字塔模型, <i>n</i>为金字塔层数, 自顶向下分别为第一层至第<i>n</i>层。图7所示为LYTRO相机金字塔算法模型。</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 金字塔模型" src="Detail/GetImg?filename=images/GXXB201903006_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 金字塔模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Pyramid model</p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 LYTRO相机金字塔算法模型" src="Detail/GetImg?filename=images/GXXB201903006_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 LYTRO相机金字塔算法模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Pyramid algorithm model of LYTRO camera</p>

                </div>
                <h4 class="anchor-tag" id="134" name="134">3.2.2 算法流程</h4>
                <div class="p1">
                    <p id="135">利用金字塔算法对所提出的点扩散函数算法进行优化, 算法流程图如图8所示, 算法流程如下。</p>
                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 算法流程图" src="Detail/GetImg?filename=images/GXXB201903006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Algorithm flow chart</p>

                </div>
                <div class="p1">
                    <p id="137">1) 建立一个map, 记为map1, 其大小为3280×3280个像素, 将区域按10×10个像素进行划分, 形成328×328个区域, 用来对应相机的微透镜阵列。建立两个金字塔模型, 如图7所示:第一个模型对应的是328×328个微透镜的区域, 记为m<sub>1</sub>;第二个模型对应的是每个区域下的10×10个像素, 记为m<sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="138">2) 寻找map1中心微透镜的中心点<i>o</i>周围的4个像素点, 将其作为金字塔的顶层, 逐层向下搜索对应的扩散函数点。每一个区域下的10×10个像素都可分为5层, 每层个数分别为4、12、20、28、36。</p>
                </div>
                <div class="p1">
                    <p id="139">3) 在m<sub>1</sub>模型下, 按步骤2) 从顶层开始, 逐层向下进行搜索。</p>
                </div>
                <div class="p1">
                    <p id="140">4) 在map1中将已找到的点删除 (包括目标点及对应点) , 以减少计算数据量;同时, 生成一个新的map2, map2中的点为处理后的点的集合。</p>
                </div>
                <div class="p1">
                    <p id="141">5) 对map2进行显示, 即为处理结果。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>3.3 色彩恢复实验验证与结果分析</b></h4>
                <div class="p1">
                    <p id="143">LYTRO相机的色彩恢复是对LYTRO相机获取的原始图像 (**.raw图像) 进行曝光归一化、白平衡校正、Bayer模式解码、RGB运算及γ校正的过程<citation id="193" type="reference"><link href="64" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>。LYTRO相机色彩恢复算法的核心是RGB运算的过程, 即去马赛克的过程。</p>
                </div>
                <div class="p1">
                    <p id="144">LYTRO相机提供的**.json文件中包含像素格式、彩色滤波器排列方式、γ角度和传感器感光度等图像属性, 镜头焦距、光圈数值和传感器偏移量等拍摄参数, 以及相机固件版本信息等内容。利用上述文件参数, 结合所提算法, 即可对LYTRO相机采集的图像进行色彩恢复的实验验证及分析。本研究选取的实验相机为第一代LYTRO相机, 相机序列号为sn-A502390678, 运行环境为Windows 8、64位操作系统, 处理器为AMD Athlon (tm) ×4740 Quad Core Processor 3.20 GHz。本研究选取两张颜色丰富的图像作为实验目标。图9所示为LYTRO相机采集的原始图像信息。</p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 LYTRO相机采集的原始图像信息。" src="Detail/GetImg?filename=images/GXXB201903006_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 LYTRO相机采集的原始图像信息。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Original image information collected by LYTRO camera. </p>
                                <p class="img_note"> (a) 图像1; (b) 图像2</p>
                                <p class="img_note"> (a) Image 1; (b) image 2</p>

                </div>
                <div class="p1">
                    <p id="146">图10所示为双线性算法<citation id="194" type="reference"><link href="66" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>、Lu算法<citation id="196" type="reference"><link href="68" rel="bibliography" /><link href="70" rel="bibliography" /><sup>[<a class="sup">29</a>,<a class="sup">30</a>]</sup></citation>、自适应算法<citation id="195" type="reference"><link href="72" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>与所提算法的去马赛克实验效果对比及局部放大图。其中, 前三种算法需要对原始图像进行正交变换, 而所提算法不需要对原始图像进行预处理, 可直接对图像进行色彩恢复。在处理结果中可以看到, 所提算法效果优于文献算法。</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 4种算法实验结果及局部放大图" src="Detail/GetImg?filename=images/GXXB201903006_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 4种算法实验结果及局部放大图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Experimental results and local enlargement of 4 algorithms</p>

                </div>
                <div class="p1">
                    <p id="148">图11所示为两组图像色彩恢复结果。通过与文献算法进行对比发现:插值方法所恢复的图像颜色质量很低;而其他两种算法的颜色信息均是通过计算得到, 所提算法是直接将颜色信息进行精确赋值, 能够更加准确地恢复出物体的原始色彩且效果令人满意。</p>
                </div>
                <div class="p1">
                    <p id="149">为了证明所提算法的优越性, 利用均方误差和信噪比进行评价<citation id="197" type="reference"><link href="74" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>。表3和表4为两组图像评价数据对比。</p>
                </div>
                <h3 id="150" name="150" class="anchor-tag">4 精确颜色矢量约束下的超分辨率图像恢复</h3>
                <div class="p1">
                    <p id="151">超分辨率图像恢复的必要条件是获得同一个场景的图像序列, 即提高时间采样率;并且序列中各帧图像间需要存在子像素运动, 使各帧图像能从不同的观察角度得到同一个场景的互补信息。LYTRO相机一次拍照后, 可以通过提取子孔径图像得到单一场景下一组完整的图像序列。</p>
                </div>
                <h4 class="anchor-tag" id="152" name="152"><b>4.1 LYTRO相机子孔径图像序列获取</b></h4>
                <div class="p1">
                    <p id="153">如果已知低分辨率图像之间的位移关系, 或能以亚像素精度估计出这些运动参数, 将这些低分辨率图像的信息进行融合, 就可以恢复图像的超分辨率。LYTRO相机获取的子孔径图像不但包含水平方向的图像序列, 同时也包含垂直方向的图像序列。两个方向的图像序列可使超分辨效果更佳。</p>
                </div>
                <div class="p1">
                    <p id="154">图12 (a) 所示为LYTRO相机原始图像。利用文献<citation id="198" type="reference">[<a class="sup">33</a>]</citation>中方法对原始图像进行校正, 得到正交排列的宏像素。在本研究实验中, 宏像素共379×379个, 每个宏像素的大小为11 pixel×11 pixel;将所有宏像素中相同位置的子像素提取出来, 构成11×11幅子孔径图像, 如图12 (b) 所示, 边缘子孔径图像较暗, 这是由通过这些孔径的光线较少引起的, 若将其作为实验目标, 会引入大量噪声。因此只考虑位于中间的7×7幅图像, 如图12 (c) 所示。</p>
                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 两组图像色彩恢复结果。" src="Detail/GetImg?filename=images/GXXB201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 两组图像色彩恢复结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_155.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Color recovery results of two sets of images.</p>
                                <p class="img_note"> (a) 双线性算法; (b) Lu算法; (c) 自适应算法; (d) 本研究算法</p>
                                <p class="img_note"> (a) Bilinear algorithm; (b) Lu′s algorithm; (c) adaptive algorithm; (d) proposed algorithm</p>

                </div>
                <div class="area_img" id="156">
                    <p class="img_tit">表3 图像1评价数据 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Image 1 evaluation data</p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td>Image 1</td><td>Mean square error <i>E</i><sub>R</sub></td><td>Mean square error <i>E</i><sub>G</sub></td><td>Mean square error <i>E</i><sub>B</sub></td><td>Running time /s</td><td>Signal-to-noise ratio /dB</td></tr><tr><td>Bilinear method</td><td>326.3563</td><td>120.8871</td><td>335.1095</td><td>3.7823</td><td>25.6157</td></tr><tr><td><br />Adaptive method</td><td>36.2256</td><td>21.1565</td><td>30.3689</td><td>3.51776</td><td>35.4862</td></tr><tr><td><br />Lu′s method</td><td>23.3697</td><td>13.1639</td><td>20.3547</td><td>260.6953</td><td>40.5687</td></tr><tr><td><br />Proposed method</td><td>6.4154</td><td>10.4781</td><td>8.6971</td><td>4.31926</td><td>42.2369</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="157">
                    <p class="img_tit">表4 图像2评价数据 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Image 2 evaluation data</p>
                    <p class="img_note"></p>
                    <table id="157" border="1"><tr><td>Image 2</td><td>Mean square error <i>E</i><sub>R</sub></td><td>Mean square error <i>E</i><sub>G</sub></td><td>Mean square error <i>E</i><sub>B</sub></td><td>Running time /s</td><td>Signal-to-noise ratio /dB</td></tr><tr><td>Bilinear method</td><td>186.4771</td><td>83.9741</td><td>173.0163</td><td>2.0631</td><td>23.5872</td></tr><tr><td><br />Adaptive method</td><td>51.3588</td><td>21.3674</td><td>23.4856</td><td>1.696307</td><td>30.3547</td></tr><tr><td><br />Lu′s method</td><td>30.7681</td><td>11.4783</td><td>16.1031</td><td>109.5875</td><td>33.6971</td></tr><tr><td><br />Proposed method</td><td>19.3875</td><td>21.6833</td><td>14.3129</td><td>3.6327</td><td>36.3618</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 原始图像及子孔径图像。" src="Detail/GetImg?filename=images/GXXB201903006_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 原始图像及子孔径图像。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 Original image and sub-aperture images.</p>
                                <p class="img_note"> (a) 原始图像; (b) 子孔径图像; (c) 7×7幅子孔径图像</p>
                                <p class="img_note"> (a) Original image; (b) sub-aperture image; (c) 7×7 sub-aperture images</p>

                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>4.2 实验结果与对比分析</b></h4>
                <div class="p1">
                    <p id="160">利用本研究中的高精度颜色矢量信息作为后验知识, 对凸集投影 (POCS) 算法<citation id="199" type="reference"><link href="78" rel="bibliography" /><link href="80" rel="bibliography" /><sup>[<a class="sup">34</a>,<a class="sup">35</a>]</sup></citation>进行改进, 算法具体步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="161">1) 构造参考帧, 选择LYTRO相机全聚焦图像作为低分辨率参考帧, 作为初始估计;2) 运动估计, 对于观测序列中每个运动估计准确的像素, 在运动向量场中找到该像素映射到当前估计的高分辨率图像中的像素位置, 并找到第2节中计算出的点扩散函数作用范围内的像素;3) 修正参考帧, 模拟图像获取过程, 得到该像素的估计值, 并计算实际值与估计值之间的残差, 若残差超出预设的误差限, 则对当前高分辨率估计中的像素值进行修正, 使残差减小到误差限内;4) 迭代修正当前高分辨率估计, 直至达到一定的重建结果或循环次数。</p>
                </div>
                <div class="p1">
                    <p id="162">在上述修正过程中, 由于是对一个点扩散函数支撑域内所有像素进行修正, 而像素点在参考帧上的点扩散函数影响范围很可能重叠, 所以会出现前面修正过的像素点在后面的像素点修正之后又超出设定的范围的现象。在循环修正过程中加入颜色矢量的约束, 能充分保证超分辨处理质量。</p>
                </div>
                <div class="p1">
                    <p id="163">值得注意的是, 本研究所使用的误差限很低, 为亚像素级别<citation id="200" type="reference"><link href="76" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>。因此, 高分辨率估计的精确度有较大提高, 使得算法效果更为理想。图13所示为使用光场工具箱V3.0获取的LYTRO相机原始图像、局部放大图像及局部二次放大图像。</p>
                </div>
                <div class="area_img" id="164">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 原始图像及局部放大图像。" src="Detail/GetImg?filename=images/GXXB201903006_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 原始图像及局部放大图像。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 13 Original image and local magnified images. </p>
                                <p class="img_note"> (a) 原始图像; (b) 局部放大图像1; (c) 局部放大图像2; (d) 局部二次放大图像3</p>
                                <p class="img_note"> (a) Original image; (b) local magnification image 1; (c) local magnification image 2; (d) local two times enlarged image 3</p>

                </div>
                <div class="p1">
                    <p id="165">最后, 如图14所示, 对4种算法效果进行对比, 4种算法分别为a) 工具箱W/O校正+双三次上采样算法, b) 工具箱W/O校正+超分辨率算法, c) 文献<citation id="201" type="reference">[<a class="sup">25</a>]</citation>中的算法, d) 所提算法。显然, 方法a) 与方法b) 在分辨率效果上不尽如人意;方法c) 在边缘处理方面的效果低于所提算法。由此可知, 所提算法的超分辨结果优于其他三种算法的超分辨结果。</p>
                </div>
                <div class="area_img" id="166">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201903006_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图14 算法实验对比。" src="Detail/GetImg?filename=images/GXXB201903006_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图14 算法实验对比。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201903006_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 14 Experimental comparison of algorithms. </p>
                                <p class="img_note"> (a) 工具箱W/O校正+双三次上采样; (b) 工具箱W/O校正+超分辨率; (c) 文献算法<citation id="204" type="reference"><link href="60" rel="bibliography" /><sup>[25]</sup></citation>; (d) 本研究算法</p>
                                <p class="img_note"> (a) Toolbox W/O rectification+dual three-time on-sample; (b) toolbox W/O rectification+super-resolution; (c) document algorithm<citation id="205" type="reference"><link href="60" rel="bibliography" /><sup>[25]</sup></citation>; (d) proposed algorithm</p>

                </div>
                <h3 id="168" name="168" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="169">提出了一种基于LYTRO相机的色彩恢复算法, 利用LYTRO相机微透镜阵列按六边形分布的特点, 计算得到LYTRO相机的点扩散函数, 对每个像素的色彩信息进行了精确的指向性赋值;并用金字塔算法对色彩恢复的时效性进行了优化。将精确的颜色矢量信息作为后验知识, 对传统的POCS算法进行优化, 得到的超分辨图像恢复的效果理想。</p>
                </div>
                <div class="p1">
                    <p id="170">所提算法也存在不足之处, 由于边界位置的像素点所对应的扩散函数点数量较低, 颜色恢复效果不佳, 影响到超分辨算法对细小纹理的处理, 存在“失真”的问题。算法的优化将是以后的工作内容。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="12">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;#233;preuves r&amp;#233;versibles donnant la sensation du relief">

                                <b>[1]</b> Lippmann G. Épreuves réversibles donnant La sensation du relief[J]. Journal de Physique Théorique et Appliquée, 1908, 7 (1) : 821-825.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098252&amp;v=MTQ3NDJqbVViL0lLVjBVYUJFPU5pZklZN0s3SHRqTnI0OUZaT0lIRG5rN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Wilburn B, Joshi N, Vaish V, <i>et al</i>. High performance imaging using large camera arrays[J]. ACM Transactions on Graphics, 2005, 24 (3) : 765-776.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A real-time distributed light field camera">

                                <b>[3]</b> Yang J C, Everett M, <i>et al</i>. A real-time distributed light field camera[J]. Euro Graphics Workshop on Rendering, 2002: 77-86.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The focused plenoptic camera">

                                <b>[4]</b> Lumsdaine A, Georgiev T. The focused plenoptic camera[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-8.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098249&amp;v=MjAyODhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lLVjBVYUJFPU5pZklZN0s3SHRqTnI0OUZaT0lIRG5ndw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Ng R. Fourier slice photography[J]. ACM Transactions on Graphics, 2005, 24 (3) : 735-744.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098521&amp;v=MTI5NzN5am1VYi9JS1YwVWFCRT1OaWZJWTdLN0h0ak5yNDlGWk9JSENYNDRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Ashok V, Ramesh R Amit A, <i>et al</i>. Dappled photography: mask enhanced cameras for heterodyned light fields and coded aperture refocusing[J]. ACM Transactions on Graphics, 2007, 26 (3) : 69.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatio-Angular Resolution Tradeoffs in IntegralPhotography">

                                <b>[7]</b> Georgiev T, Zheng K C, <i>et al</i>. Spatio-angular resolution tradeoffs in integral photography[J]. Euro Graphics Conference on Rendering Techniques, 2006: 263-272.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Capturing and rendering with incident light fields">

                                <b>[8]</b> Unger J, Wenger A, <i>et al</i>. Capturing and rendering with incident light fields[J]. Euro Graphics Workshop on Rendering, 2003: 141-149.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lytro">

                                <b>[9]</b> Lytro, http://lytro.com/.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Raytrix">

                                <b>[10]</b> Raytrix, http: //www.raytrix.de/.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Decoding,calibration and rectification for lenselet-based plenoptic cameras">

                                <b>[11]</b> Dansereau D G, Pizarro O, Williams S B. Decoding, calibration and rectification for lenselet-based plenoptic cameras[C]∥2013 IEEE Conference on Computer Vision and Pattern Recognition, June 23-28, 2013, Portland, OR, USA. New York: IEEE, 2013: 1027-1034.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Light field superresolution">

                                <b>[12]</b> Bishop T E, Zanetti S, Favaro P. Light field superresolution[C]∥2009 IEEE International Conference on Computational Photography (ICCP) , April 16-17, 2009, San Francisco, CA, USA. New York: IEEE, 2009: 1-9.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Light field denoising,light field superresolution and stereo camera based refocussing using a GMM light field patch prior">

                                <b>[13]</b> Mitra K, Veeraraghavan A. Light field denoising, light field superresolution and stereo camera based refocussing using a GMM light field patch prior[C]//2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, June 16-21, 2012, Providence, RI, USA. New York: IEEE, 2012: 22-28.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial and angular variational super-resolution of4D light fields">

                                <b>[14]</b> Wanner S, Goldluecke B. Spatial and angular variational super-resolution of 4D light fields[M]//Fitzgibbon A, Lazebnik S, Perona P, <i>et al</i>. eds. Computer Vision-ECCV 2012. Berlin, Heidelberg: Springer, 2012: 608-621.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201809017&amp;v=Mjg1NjhIOW5NcG85RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5SG1VNzNMSWpYVGJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Qiu K, Yi B S, Xiang M, <i>et al</i>. Collaborative sparse dictionary learning for reconstruction of single image super resolution[J]. Acta Optica Sinica, 2018, 38 (9) : 0910002. 邱康, 易本顺, 向勉, 等. 协作稀疏字典学习实现单幅图像超分辨率重建[J]. 光学学报, 2018, 38 (9) : 0910002.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via deep recursive resid-ual network">

                                <b>[16]</b> Tai Y, Yang J, Liu X M. Image super-resolution via deep recursive residual network[C]∥2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA. New York: IEEE, 2017: 2790-2798.
                            </a>
                        </p>
                        <p id="44">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201712015&amp;v=MTc5MDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5SG1VNzNMSWpYVGJMRzRIOWJOclk5RVlZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Li S M, Lei G Q, Fan R. Depth map super-resolution reconstruction based on convolutional neural networks[J]. Acta Optica Sinica, 2017, 37 (12) : 1210002. 李素梅, 雷国庆, 范如. 基于卷积神经网络的深度图超分辨率重建[J]. 光学学报, 2017, 37 (12) : 1210002.
                            </a>
                        </p>
                        <p id="46">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fourier slice super-resolution in plenoptic cameras">

                                <b>[18]</b> Pérez F, Pérez A, Rodríguez M, <i>et al</i>. Fourier slice super-resolution in plenoptic cameras[C]∥2012 IEEE International Conference on Computational Photography (ICCP) , April 28-29, 2012, Seattle, WA, USA. New York: IEEE, 2012: 1-11.
                            </a>
                        </p>
                        <p id="48">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Light Field Reconstruction Using Sparsity in the ContinuousFourier Domain">

                                <b>[19]</b> Shi L X, Hassanieh H, Davis A, <i>et al</i>. Light field reconstruction using sparsity in the continuous Fourier domain[J]. ACM Transactions on Graphics, 2014, 34 (1) : 1-13.
                            </a>
                        </p>
                        <p id="50">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wave optics theory and 3-D deconvolution for the light field microscope">

                                <b>[20]</b> Broxton M, Grosenick L, Yang S, <i>et al</i>. Wave optics theory and 3-D deconvolution for the light field microscope[J]. Optics Express, 2013, 21 (21) : 25418-25439.
                            </a>
                        </p>
                        <p id="52">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High resolution imaging and wavefront aberration correction in plenoptic systems">

                                <b>[21]</b> Trujillo-Sevilla J M, Rodríguez-Ramos L F, Montilla I, <i>et al</i>. High resolution imaging and wavefront aberration correction in plenoptic systems[J]. Optics Letters, 2014, 39 (17) : 5030-5033.
                            </a>
                        </p>
                        <p id="54">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hybrid stereo imaging including a light field and a regular camera">

                                <b>[22]</b> Alam M Z, Gunturk B K. Hybrid stereo imaging including a light field and a regular camera[C]//2016 24th Signal Processing and Communication Application Conference (SIU) , May 16-19 2016, Zonguldak, Turkey. New York: IEEE, 2016: 1293-1296.
                            </a>
                        </p>
                        <p id="56">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-resolution light field reconstruction using a hybrid imaging system">

                                <b>[23]</b> Wang X, Li L, Hou G Q. High-resolution light field reconstruction using a hybrid imaging system[J]. Applied Optics, 2016, 55 (10) : 2580-2593.
                            </a>
                        </p>
                        <p id="58">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel light field super-resolution framework based on hybrid imaging system">

                                <b>[24]</b> Wu J D, Wang H Q, Wang X Z, <i>et al</i>. A novel light field super-resolution framework based on hybrid imaging system[C]∥2015 Visual Communications and Image Processing (VCIP) , December 13-16, 2015, Singapore, Singapore. New York: IEEE, 2015: 1-4.
                            </a>
                        </p>
                        <p id="60">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Super-resolution Image Synthesis Using the Physical Pixel Arrangemen to Light Field Camera">

                                <b>[25]</b> Ohashi K, Takahashi K, Tehrani M P, <i>et al</i>. Super-resolution image synthesis using the physical pixel arrangement of a light field camera[C]//2015 IEEE International Conference on Image Processing (ICIP) , September 27-30, 2015, Quebec City, QC, Canada. New York: IEEE, 2015: 2964-2968.
                            </a>
                        </p>
                        <p id="62">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810131133999&amp;v=MDQ5ODlGd1hWVjI3R2J1NUh0RFBybzVHWitJR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkNybFU3YkxJ&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> Li Z N. The principle of modern optical system[M]. Beijing: Beijing Polytechnic University Press, 1994: 155-160. 李志能. 现代光学系统原理[M]. 北京: 北京理工大学出版社, 1994: 155-160.
                            </a>
                        </p>
                        <p id="64">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201407003&amp;v=MDQ0MjBGckNVUkxPZVplVnVGeUhtVTczTFB5cmZiTEc0SDlYTXFJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b> Zhou W H, Lin L L. Light field image rectification and refocus method for Lytro camera[J]. Journal of Image and Graphics, 2014, 19 (7) : 1006-1011. 周文晖, 林丽莉. Lytro相机的光场图像校正与重对焦方法[J]. 中国图象图形学报, 2014, 19 (7) : 1006-1011.
                            </a>
                        </p>
                        <p id="66">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color imaging array">

                                <b>[28]</b> Bayer B E. Color imaging array: US3971065[P]. 1976-07-27.
                            </a>
                        </p>
                        <p id="68">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color filter array demosaicking: new method and performance measures">

                                <b>[29]</b> Lu W M, Tan Y P. Color filter array demosaicking: new method and performance measures[J]. IEEE Transactions on Image Processing, 2003, 12 (10) : 1194-1210.
                            </a>
                        </p>
                        <p id="70">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive color filter array demosaicking using directional spatial and spectral correlations">

                                <b>[30]</b> Lu W M, Tan Y P. Adaptive color filter array demosaicking using directional spatial and spectral correlations[C]//Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint, December 15-18, 2003, Singapore, Singapore. New York: IEEE, 2003: 76-80.
                            </a>
                        </p>
                        <p id="72">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color plane interpolation using alternating projections">

                                <b>[31]</b> Gunturk B K, Altunbasak Y, Mersereau R M. Color plane interpolation using alternating projections[J]. IEEE Transactions on Image Processing, 2002, 11 (9) : 997-1013.
                            </a>
                        </p>
                        <p id="74">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Quality Assessment:From Error Measurement to Structural Similarity">

                                <b>[32]</b> Wang Z, Bovik A C, Sheikh H R, <i>et al</i>. Image quality assessment: from error visibility to structural similarity[J]. IEEE Transactions on Image Processing, 2004, 13 (4) : 600-612.
                            </a>
                        </p>
                        <p id="76">
                            <a id="bibliography_33" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813028&amp;v=MDcyMTFOckk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5SG1VNzNMTHo3TWFiRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[33]</b> Sun F S, Han X, Ding J H, <i>et al</i>. Research on algorithm of image depth estimation and reconstruction based on LYTRO camera[J]. Computer Engineering and Applications, 2018, 54 (13) : 175-180. 孙福盛, 韩燮, 丁江华, 等. LYTRO相机光场图像深度估计算法及重建的研究[J]. 计算机工程与应用, 2018, 54 (13) : 175-180.
                            </a>
                        </p>
                        <p id="78">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">

                                <b>[34]</b> Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A, 1989, 6 (11) : 1715-1726.
                            </a>
                        </p>
                        <p id="80">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration">

                                <b>[35]</b> Tekalp A M, Ozkan M K, Sezan M I. High-resolution image reconstruction from lower-resolution image sequences and space-varying image restoration[C]∥[Proceedings]ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, March 23-26, 1992, San Francisco, CA, USA. New York: IEEE, 1992: 169-172.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201903006" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201903006&amp;v=MTQ2MzF1RnlIbVU3M0xJalhUYkxHNEg5ak1ySTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

