

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133863955596250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201907028%26RESULT%3d1%26SIGN%3dodbczjL7wZuzjvH70XuDX%252b4tgPM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201907028&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201907028&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201907028&amp;v=MTEwOTRuaFViL05JalhUYkxHNEg5ak1xSTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="2 YOLO V3网络介绍 ">2 YOLO V3网络介绍</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="3 改进的YOLO V3检测模型 ">3 改进的YOLO V3检测模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;3.1 数据集目标框的聚类分析&lt;/b&gt;"><b>3.1 数据集目标框的聚类分析</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;3.2 改进的YOLO V3检测模型&lt;/b&gt;"><b>3.2 改进的YOLO V3检测模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;4.1 网络的训练&lt;/b&gt;"><b>4.1 网络的训练</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;4.2 网络的测试&lt;/b&gt;"><b>4.2 网络的测试</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#106" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="图1 YOLO V3网络结构">图1 YOLO V3网络结构</a></li>
                                                <li><a href="#50" data-title="图2 Darknet53结构单元。">图2 Darknet53结构单元。</a></li>
                                                <li><a href="#59" data-title="图3 K-means聚类分析结果">图3 K-means聚类分析结果</a></li>
                                                <li><a href="#65" data-title="图4 各网络的输出结构。">图4 各网络的输出结构。</a></li>
                                                <li><a href="#66" data-title="图5 改进的YOLO V3网络结构">图5 改进的YOLO V3网络结构</a></li>
                                                <li><a href="#72" data-title="表1 VEDAI数据集中各类目标的数量">表1 VEDAI数据集中各类目标的数量</a></li>
                                                <li><a href="#78" data-title="图6 改进的YOLO V3损失值函数曲线和Avg IOU曲线。">图6 改进的YOLO V3损失值函数曲线和Avg IOU曲线。</a></li>
                                                <li><a href="#87" data-title="表2 不同算法目标检测结果的对比">表2 不同算法目标检测结果的对比</a></li>
                                                <li><a href="#91" data-title="图7 各网络的AP曲线。">图7 各网络的AP曲线。</a></li>
                                                <li><a href="#97" data-title="图8 改进的YOLO V3算法与原YOLO V3算法对小目标的检测结果对比">图8 改进的YOLO V3算法与原YOLO V3算法对小目标的检测结果对比</a></li>
                                                <li><a href="#98" data-title="图9 改进YOLO V3算法与原YOLO V3算法对小目标的检测结果对比">图9 改进YOLO V3算法与原YOLO V3算法对小目标的检测结果对比</a></li>
                                                <li><a href="#101" data-title="表3 不同算法目标检测结果的对比">表3 不同算法目标检测结果的对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" Zhang X Y, Ding Q H, Luo H B, &lt;i&gt;et al&lt;/i&gt;.Infrared dim target detection algorithm based on improved LCM[J].Infrared and Laser Engineering, 2017, 46 (7) :0726002.张祥越, 丁庆海, 罗海波, 等.基于改进LCM的红外小目标检测算法[J].红外与激光工程, 2017, 46 (7) :0726002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201707040&amp;v=MDAxMTdiL05MVHJTWkxHNEg5Yk1xSTlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnluaFU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Zhang X Y, Ding Q H, Luo H B, &lt;i&gt;et al&lt;/i&gt;.Infrared dim target detection algorithm based on improved LCM[J].Infrared and Laser Engineering, 2017, 46 (7) :0726002.张祥越, 丁庆海, 罗海波, 等.基于改进LCM的红外小目标检测算法[J].红外与激光工程, 2017, 46 (7) :0726002.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" Zhang R, Li W P, Mo T.Review of deep learning[J].Information and Control, 2018, 47 (4) :385-397, 410.张荣, 李伟平, 莫同.深度学习研究综述[J].信息与控制, 2018, 47 (4) :385-397, 410." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXYK201804002&amp;v=MDQwNjllVnVGeW5oVWIvTlBUWFNaYkc0SDluTXE0OUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Zhang R, Li W P, Mo T.Review of deep learning[J].Information and Control, 2018, 47 (4) :385-397, 410.张荣, 李伟平, 莫同.深度学习研究综述[J].信息与控制, 2018, 47 (4) :385-397, 410.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" Hua X, Wang X Q, Wang D, &lt;i&gt;et al&lt;/i&gt;.Multi-objective detection of traffic based on improved SSD[J].Acta Optica Sinica, 2018, 38 (12) :1215003.华夏, 王新晴, 王东, 等.基于改进SSD的交通大场景多目标检测[J].光学学报, 2018, 38 (12) :1215003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201812027&amp;v=MTQ1NTh0R0ZyQ1VSTE9lWmVWdUZ5bmhVYi9OSWpYVGJMRzRIOW5Oclk5SFk0UUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Hua X, Wang X Q, Wang D, &lt;i&gt;et al&lt;/i&gt;.Multi-objective detection of traffic based on improved SSD[J].Acta Optica Sinica, 2018, 38 (12) :1215003.华夏, 王新晴, 王东, 等.基于改进SSD的交通大场景多目标检测[J].光学学报, 2018, 38 (12) :1215003.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" Wang W X, Fu Y T, Dong F, &lt;i&gt;et al&lt;/i&gt;.Infrared ship target detection method based on deep convolution neural network[J].Acta Optica Sinica, 2018, 38 (7) :0712006.王文秀, 傅雨田, 董峰, 等.基于深度卷积神经网络的红外船只目标检测方法[J].光学学报, 2018, 38 (7) :0712006." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807020&amp;v=Mjc5MTQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmhVYi9OSWpYVGJMRzRIOW5NcUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Wang W X, Fu Y T, Dong F, &lt;i&gt;et al&lt;/i&gt;.Infrared ship target detection method based on deep convolution neural network[J].Acta Optica Sinica, 2018, 38 (7) :0712006.王文秀, 傅雨田, 董峰, 等.基于深度卷积神经网络的红外船只目标检测方法[J].光学学报, 2018, 38 (7) :0712006.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" Luo H B, Xu L Y, Hui B, &lt;i&gt;et al&lt;/i&gt;.Status and prospect of target tracking based on deep learning[J].Infrared and Laser Engineering, 2017, 46 (5) :0502002.罗海波, 许凌云, 惠斌, 等.基于深度学习的目标跟踪方法研究现状与展望[J].红外与激光工程, 2017, 46 (5) :0502002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201705002&amp;v=MjU3MTR6cXFCdEdGckNVUkxPZVplVnVGeW5oVWIvTkxUclNaTEc0SDliTXFvOUZab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Luo H B, Xu L Y, Hui B, &lt;i&gt;et al&lt;/i&gt;.Status and prospect of target tracking based on deep learning[J].Infrared and Laser Engineering, 2017, 46 (5) :0502002.罗海波, 许凌云, 惠斌, 等.基于深度学习的目标跟踪方法研究现状与展望[J].红外与激光工程, 2017, 46 (5) :0502002.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" title=" Girshick R.Fast R-CNN[C]//2015 IEEE International Conference on Computer Vision (ICCV) , December 7-13, 2015, Santiago, Chile.New York:IEEE, 2015:1440-1448." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">
                                        <b>[6]</b>
                                         Girshick R.Fast R-CNN[C]//2015 IEEE International Conference on Computer Vision (ICCV) , December 7-13, 2015, Santiago, Chile.New York:IEEE, 2015:1440-1448.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     Ren S Q, He K M, Girshick R, &lt;i&gt;et al&lt;/i&gt;.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) :1137-1149.</a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" He K M, Gkioxari G, Doll&#225;r P, &lt;i&gt;et al&lt;/i&gt;.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">
                                        <b>[8]</b>
                                         He K M, Gkioxari G, Doll&#225;r P, &lt;i&gt;et al&lt;/i&gt;.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" Liu W, Anguelov D, Erhan D, &lt;i&gt;et al&lt;/i&gt;.SSD:single shot multibox detector[M]//Leibe B, Matas J, SebeN, &lt;i&gt;et al&lt;/i&gt;.Lecture notes in computer science.Cham:Springer, 2016, 9905:21-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SSD:single shot multibox detector">
                                        <b>[9]</b>
                                         Liu W, Anguelov D, Erhan D, &lt;i&gt;et al&lt;/i&gt;.SSD:single shot multibox detector[M]//Leibe B, Matas J, SebeN, &lt;i&gt;et al&lt;/i&gt;.Lecture notes in computer science.Cham:Springer, 2016, 9905:21-37.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     Redmon J, Divvala S, Girshick R, &lt;i&gt;et al&lt;/i&gt;.You only look once:unified, real-time object detection[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:779-788.</a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     Redmon J, Farhadi A.YOLO9000:better, faster, stronger[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA.New York:IEEE, 2017:6517-6525.</a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" Redmon J, Farhadi A.YOLOv3:an incremental improvement[EB/OL]. (2018-04-08) [2018-12-25].https://arxiv.org/abs/1804.02767." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=YOLOv3 an incremental improvement">
                                        <b>[12]</b>
                                         Redmon J, Farhadi A.YOLOv3:an incremental improvement[EB/OL]. (2018-04-08) [2018-12-25].https://arxiv.org/abs/1804.02767.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" Razakarivony S, Jurie F.Vehicle detection in aerial imagery:a small target detection benchmark[J].Journal of Visual Communication and Image Representation, 2016, 34:187-203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8C3E45A38C465DF97AE8E1977B687CE1&amp;v=MDc5MDh3SzA9TmlmT2ZidkxIYVRJcXY1R2JKZ0xDbmxOdVI4VW0wcDFQWDdycXhWSGY3cVROcytlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGJ5OQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Razakarivony S, Jurie F.Vehicle detection in aerial imagery:a small target detection benchmark[J].Journal of Visual Communication and Image Representation, 2016, 34:187-203.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" He K M, Zhang X Y, Ren S Q, &lt;i&gt;et al&lt;/i&gt;.Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[14]</b>
                                         He K M, Zhang X Y, Ren S Q, &lt;i&gt;et al&lt;/i&gt;.Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:770-778.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" Fu C Y, Liu W, Ranga A, &lt;i&gt;et al&lt;/i&gt;.DSSD:deconvolutional single shot detector[EB/OL]. (2017-01-23) [2018-12-25].https://arxiv.org/abs/1701.06659." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dssd:Deconvolutional single shot detector">
                                        <b>[15]</b>
                                         Fu C Y, Liu W, Ranga A, &lt;i&gt;et al&lt;/i&gt;.DSSD:deconvolutional single shot detector[EB/OL]. (2017-01-23) [2018-12-25].https://arxiv.org/abs/1701.06659.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806034&amp;v=MTQzOTgvTklqWFRiTEc0SDluTXFZOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5oVWI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-02 14:28</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(07),253-260 DOI:10.3788/AOS201939.0715004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>改进的YOLO V3算法及其在小目标检测中的应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9E%A0%E9%BB%98%E7%84%B6&amp;code=42412970&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鞠默然</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E6%B5%B7%E6%B3%A2&amp;code=10356685&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗海波</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BB%B2%E5%8D%9A&amp;code=42412972&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王仲博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E6%B7%BC&amp;code=38721965&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何淼</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B8%B8%E9%93%AE&amp;code=26671826&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">常铮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%83%A0%E6%96%8C&amp;code=21685622&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">惠斌</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%B2%88%E9%98%B3%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=0183762&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院沈阳自动化研究所</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8E%E6%99%BA%E8%83%BD%E5%88%B6%E9%80%A0%E5%88%9B%E6%96%B0%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院机器人与智能制造创新研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院光电信息处理重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E7%9C%81%E5%9B%BE%E5%83%8F%E7%90%86%E8%A7%A3%E4%B8%8E%E8%A7%86%E8%A7%89%E8%AE%A1%E7%AE%97%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁省图像理解与视觉计算重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对图像中小目标检测率低、虚警率高等问题, 提出了一种YOLO V3的改进方法, 并将其应用于小目标的检测。由于小目标所占的像素少、特征不明显, 提出对原网络输出的8倍降采样特征图进行2倍上采样, 将2倍上采样特征图与第2个残差块输出的特征图进行拼接, 建立输出为4倍降采样的特征融合目标检测层。为了获取更多的小目标特征信息, 在YOLO V3网络结构Darknet53的第2个残差块中增加2个残差单元。利用K-means聚类算法对目标候选框的个数和宽高比维度进行聚类分析。用改进的YOLO V3算法和原YOLO V3算法在VEDAI数据集上进行对比实验, 结果表明改进后的YOLO V3算法能有效检测小目标, 对小目标的召回率和检测的平均准确率均值都有明显的提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">小目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=YOLO%20V3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">YOLO V3;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=VEDAI%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">VEDAI数据集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">K-means聚类算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *鞠默然, E-mail:jumoran@sia.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-11</p>

            </div>
                    <h1><b>Improved YOLO V3 Algorithm and Its Application in Small Target Detection</b></h1>
                    <h2>
                    <span>Ju Moran</span>
                    <span>Luo Haibo</span>
                    <span>Wang Zhongbo</span>
                    <span>He Miao</span>
                    <span>Chang Zheng</span>
                    <span>Hui Bin</span>
            </h2>
                    <h2>
                    <span>Shenyang Institute of Automation, Chinese Academy of Sciences</span>
                    <span>Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences</span>
                    <span>University of Chinese Academy of Sciences</span>
                    <span>Key Laboratory of Opt-Electronic Information Processing, Chinese Academy of Sciences</span>
                    <span>The Key Laboratory of Image Understanding and Computer Vision</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This study proposes an improved detection algorithm of YOLO V3 specially applied in small target detection to solve the problems of low detection and high false alarm rates of small targets in an image. The resolution of small targets is low, and their features are not obvious; thus, this study proposes 2× upsampling for the feature map down-sampled by 8× of the previous network, and the feature map upsampled by 2× is concatenated with the output of the second ResNet block unit. A feature fusion target detection layer, whose feature map is down-sampled by 4×, is established. Two ResNet units in the second ResNet block unit of Darknet53 in the YOLO V3 network structure are added to obtain more features of the small target. The K-means clustering algorithm is used to select the number of candidate anchor boxes and aspect ratio dimensions. A comparative experiment is performed based on the improved YOLO V3 algorithm on the VEDAI dataset and YOLO V3 algorithm. The results show that the improved YOLO V3 algorithm can efficiently detect small targets and improve the mean average precision and recall rate of small targets.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=small%20target%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">small target detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=YOLO%20V3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">YOLO V3;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=VEDAI%20dataset&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">VEDAI dataset;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=K-means%20clustering%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">K-means clustering algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-11</p>
                            </div>


        <!--brief start-->
                        <h3 id="42" name="42" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="43">目前, 目标检测已被广泛应用于军事和民用等领域中。小目标检测作为目标检测的一项关键技术, 近年来已成为研究热点。远距离目标通常会呈现小目标的特性。由于小目标像素少、特征不明显, 与大目标相比, 其检测率低、虚警率高, 因此小目标检测仍然是目标检测中的一个具有挑战性的研究课题<citation id="108" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">随着深度学习技术的不断发展<citation id="109" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 多种多样的基于深度学习的目标检测<citation id="118" type="reference"><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>和目标跟踪算法<citation id="110" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>被提出。深度卷积神经网络可以利用目标数据集对要检测的目标进行自主学习, 并完善自己的模型。目前基于深度学习且应用比较广泛的目标检测算法可以分为两类:1) 双步目标检测算法, 如Fast R-CNN (region-conventional neural network) <citation id="111" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Faster R-CNN<citation id="112" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、Mask R-CNN<citation id="113" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等, 这些算法都是将目标检测分为两个阶段, 即先使用区域候选网络 (RPN) 来提取候选目标信息, 再利用检测网络完成对候选目标的位置和类别的预测和识别;2) 单步目标检测算法, 如SSD (single shot Multibox detector) <citation id="114" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、YOLO (you only look once) <citation id="115" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、YOLO 9000<citation id="116" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、YOLO V3<citation id="117" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>等, 此类算法不需要使用RPN, 直接通过网络来产生目标的位置和类别信息, 是一种端到端的目标检测算法。因此, 单步目标检测算法具有更快的检测速度。</p>
                </div>
                <div class="p1">
                    <p id="45">为了提高网络对小目标的召回率和检测的准确率, 本文以单步目标检测算法的深度卷积神经网络YOLO V3为基础, 将航拍图像VEDAI (vehicle detection in aerial imagery) 数据集<citation id="119" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>中的车辆作为训练和检测的目标, 对YOLO V3的结构进行改进。首先, 对原网络输出的8倍降采样特征图进行2倍的上采样, 将2倍上采样特征图与第2个残差块的输出进行拼接, 以融合高层中的特征语义信息, 并在YOLO V3网络结构Darknet53的第2个残差块中增加2个残差单元, 以获取网络低层中准确的位置信息。最后, 为避免梯度消失, 将YOLO V3网络的目标检测输出层前的6个卷积变成2个卷积和2个残差单元。将改进后的网络结构与YOLO V3进行对比实验, 结果表明改进后的网络结构对小目标的召回率和检测的准确率都有明显的提升。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">2 YOLO V3网络介绍</h3>
                <div class="p1">
                    <p id="47">YOLO V3采用了Darknet53的网络结构, 共包含53个卷积层, 如图1所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 YOLO V3网络结构" src="Detail/GetImg?filename=images/GXXB201907028_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 YOLO V3网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 YOLO V3 network structure</p>

                </div>
                <div class="p1">
                    <p id="49">Darknet53由5个残差块构成, 借鉴了残差神经网络的思想<citation id="120" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。每个残差块由多个残差单元组成, 通过输入与两个数码累积造型 (DBL) 单元进行残差操作, 构建残差单元, 如图2 (a) 所示。其中, DBL单元包含卷积、批归一化和leaky ReLU激活函数, 如图2 (b) 所示。通过引入残差单元来增大网络深度, 避免梯度消失。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Darknet53结构单元。" src="Detail/GetImg?filename=images/GXXB201907028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Darknet53结构单元。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Structural unit of Darknet53.</p>
                                <p class="img_note"> (a) 残差单元; (b) DBL单元</p>
                                <p class="img_note"> (a) ResNet unit; (b) DBL unit</p>

                </div>
                <div class="p1">
                    <p id="51">YOLO V3对输入图片进行了5次降采样, 并分别在最后3次降采样中对目标进行预测。最后3次降采样中包含了3个尺度目标检测的特征图。小特征图提供深层次的语义信息, 大特征图则提供目标的位置信息, 小特征图经过上采样后与大特征图融合, 因此该模型既可以检测大目标, 也可以检测小目标。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">3 改进的YOLO V3检测模型</h3>
                <div class="p1">
                    <p id="53">本文主要研究小目标检测问题, 原网络定义的anchor boxes与网络的层级结构不适用于本文的研究对象。因此, 首先利用K-means聚类算法对数据集中的小目标进行聚类分析, 然后针对小目标检测, 修改网络的层级结构。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>3.1 数据集目标框的聚类分析</b></h4>
                <div class="p1">
                    <p id="55">YOLO V3引入了Faster R-CNN中所使用的anchor boxes的思想, anchor boxes是一组宽高固定的初始候选框, 对初始anchor boxes的选择会直接影响网络对目标的检测精度和速度。YOLO V3利用K-means聚类算法对COCO数据集中目标框的宽高进行聚类。采用平均重叠度 (Avg IOU) 作为目标聚类分析的量度, 对VEDAI数据集进行聚类分析。聚类的Avg IOU目标函数<i>f</i>可表示为</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo>=</mo><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munderover><mi>Ι</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mtext>Ι</mtext><mtext>Ο</mtext><mtext>U</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>B</mi><mo>, </mo><mi>C</mi><mo stretchy="false">) </mo></mrow><mi>n</mi></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">式中:<i>B</i>表示样本, 即ground truth中的目标;<i>C</i>表示簇的中心;<i>n</i><sub><i>k</i></sub>表示第<i>k</i>个聚类中心中样本的个数;<i>n</i>表示样本的总个数;<i>k</i>表示簇的个数;<i>I</i><sub>IOU</sub> (<i>B</i>, <i>C</i>) 表示簇的中心框和聚类框的交并比;<i>i</i>表示样本序号;<i>j</i>表示聚类中心中样本的序号。</p>
                </div>
                <div class="p1">
                    <p id="58">选取<i>k</i>=1～9, 分别对数据集中样本进行聚类分析, 得到<i>k</i>与Avg IOU之间的关系如图3所示。随着<i>k</i>值的增大, 目标函数变化越来越平稳, 变化的拐点可以认为是最佳的anchor boxes的个数。在<i>k</i>值大于3时, 曲线开始变得平稳, 所以选取anchor boxes的数量为3, 既可以加快损失函数的收敛, 又可以消除候选框带来的误差。对应预测框的大小设置为3个聚类中心, 其在VEDAI数据集上对应聚类中心的宽和高分别为 (22, 9) , (10, 21) , (20, 19) 。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 K-means聚类分析结果" src="Detail/GetImg?filename=images/GXXB201907028_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 K-means聚类分析结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 K-means clustering analysis result</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60"><b>3.2 改进的YOLO V3检测模型</b></h4>
                <div class="p1">
                    <p id="61">YOLO V3网络利用8倍降采样输出的特征图对小目标进行检测, 这意味着当目标小于8 pixel×8 pixel时, 网络对目标的预测就会出现困难, 并且特征图为8倍降采样的目标检测层对小目标位置信息的检测能力是有限的。为了使网络获取更多小目标的特征信息, 提高对小目标的检测率, 利用原网络中输出的4倍降采样特征图对目标进行检测, 因为它含有更多小目标的位置信息。对YOLO V3输出的8倍降采样特征图进行2倍上采样, 将2倍上采样特征图与Darknet53中第2个残差块输出的4倍降采样特征图进行拼接, 建立输出为4倍降采样的特征融合目标检测层, 以检测小目标。同时, 为了获取更多低层的小目标位置信息, 在原网络的第2个残差块中增加2个残差单元。</p>
                </div>
                <div class="p1">
                    <p id="62">YOLO V3采用了3个尺度对VOC和COCO数据集进行预测。在COCO数据集中尺度1对应的预测框是 (116, 90) , (156, 198) , (373, 326) , 尺度2对应的预测框是 (30, 61) , (62, 45) , (59, 119) , 尺度3对应的预测框是 (10, 13) , (16, 30) , (33, 23) 。为了提高网络对小目标的召回率和检测的准确率, 根据VEDAI数据集的聚类结果, 取消YOLO V3在原3个尺度上的输出检测, 直接利用输出的4倍降采样特征融合目标检测层对小目标进行检测。</p>
                </div>
                <div class="p1">
                    <p id="63">YOLO V3网络的目标检测输出层前包含6个DBL单元和一个1×1的卷积。受DSSD (deconvolutional single shot detector) 网络的启发<citation id="121" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 为了避免梯度消失并增强特征的复用, 将6个DBL单元变成2个DBL单元和2个ResNet单元, 如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="64">改进的YOLO V3网络结构如图5所示, 将第2个残差块输出的4倍降采样特征图与经过2倍上采样的8倍降采样特征图进行拼接, 建立输出为4倍降采样的特征融合目标检测层, 对小目标进行检测。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 各网络的输出结构。" src="Detail/GetImg?filename=images/GXXB201907028_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 各网络的输出结构。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Output structure of each network. </p>
                                <p class="img_note"> (a) YOLO V3网络; (b) 改进的YOLO V3网络</p>
                                <p class="img_note"> (a) YOLO V3 network; (b) improved YOLO V3 network</p>

                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 改进的YOLO V3网络结构" src="Detail/GetImg?filename=images/GXXB201907028_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 改进的YOLO V3网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Improved YOLO V3 network structure</p>

                </div>
                <div class="p1">
                    <p id="68">YOLO V3网络会对检测的图像进行缩放或裁剪, 无论输入的图像多大, 最后都会被缩放或裁剪成416 pixel×416 pixel的图像。采用512 pixel×512 pixel的VEDAI航拍数据集, 如果将图像进行缩放或裁剪, 原图像中小目标的分辨率会变得更低或视场变小, 直接影响网络对小目标的检测。因此, 改进的YOLO V3网络不对图像进行压缩或裁剪处理, 维持512 pixel×512 pixel的分辨率不变, 以使输入网络的图像分辨率保持不变, 从而提高网络对小目标的检测性能。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="70">YOLO V3在多个尺度下进行目标检测, 是目前能较好兼顾大、小目标的代表性算法, 对小目标具有较好的检测性能。因此, 将所提的改进YOLO V3算法与YOLO V3目标检测算法进行对比实验。</p>
                </div>
                <div class="p1">
                    <p id="71">利用VEDAI航拍图像作为数据集, 对YOLO V3算法和改进的YOLO V3算法进行对比实验。VEDAI数据集是将原始大视场卫星图像分割成1024 pixel×1024 pixel的图像, 包含各种各样的车辆, 背景和混淆对象。数据集中包含可见光和红外两种图像。所有的图像都采用了与地面相同的距离, 是典型应用于监视侦察的场景。此外, 数据集中还包含了对1024 pixel×1024pixel图像进行下采样得到的分辨率为512 pixel×512 pixel的图像, 为评估提供更小、更具挑战性的目标图像。VEDAI数据集中平均每张图像包含约5.5个车辆目标, 并且它们只占图像总像素的0.7%, 是典型的小目标检测数据集。数据集中共有9类对象, 包括:airplane, boat, car, truck, tractor, camping, pickup, vans, others。9类对象中每种类别的目标数量如表1所示。</p>
                </div>
                <div class="area_img" id="72">
                    <p class="img_tit">表1 VEDAI数据集中各类目标的数量 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Number of each target in VEDAI dataset</p>
                    <p class="img_note"></p>
                    <table id="72" border="1"><tr><td>Class name</td><td>Boat</td><td>Camping</td><td>Car</td><td>Others</td><td>Pickup</td><td>Tractors</td><td>Truck</td><td>Vans</td><td>Airplane</td></tr><tr><td><br />Total number</td><td>170</td><td>390</td><td>1340</td><td>200</td><td>950</td><td>190</td><td>300</td><td>100</td><td>47</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="73">采用两种方法来验证改进后的YOLO V3网络对小目标的检测性能:1) 采用分辨率为512 pixel×512 pixel的图像数据集, 将数据集中最小的3类目标car, vans, pickup归为一类car, 并随机选择80%的图像进行训练, 其余的20%图像用于测试;2) 采用分辨率为512 pixel×512 pixel的图像数据集, 对数据集中的9类目标进行检测。</p>
                </div>
                <div class="p1">
                    <p id="74">实验条件为:操作系统为Ubuntu 14.04, 深度学习框架为Darknet;CPU为i7-5930K, 内存为64 GB, GPU为NVIDIA GeForce GTX TITAN X。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>4.1 网络的训练</b></h4>
                <div class="p1">
                    <p id="76">对YOLO V3和改进的YOLO V3分别进行训练, 训练阶段初始学习率为0.001, 衰减系数为0.0005, 当训练迭代次数为20000次和25000次时, 分别将学习率降低为0.0001和0.00001, 使损失函数进一步收敛。利用旋转图像、增加对比度等方法对数据集中的图像进行增强和扩充。</p>
                </div>
                <div class="p1">
                    <p id="77">改进的YOLO V3网络训练过程中损失值的收敛曲线如图6 (a) 所示, 目标框与ground truth的Avg IOU曲线如图6 (b) 所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 改进的YOLO V3损失值函数曲线和Avg IOU曲线。" src="Detail/GetImg?filename=images/GXXB201907028_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 改进的YOLO V3损失值函数曲线和Avg IOU曲线。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Improved YOLO V3 loss curve and Avg IOU curve. </p>
                                <p class="img_note"> (a) 损失值函数曲线; (b) Avg IOU曲线</p>
                                <p class="img_note"> (a) Loss function curve; (b) Avg IOU curve</p>

                </div>
                <div class="p1">
                    <p id="79">大约经过30000次迭代之后, 各参数基本趋于稳定, 最后的损失值下降到0.2左右, Avg IOU逐渐接近1, 最终稳定在0.85左右。从此参数的收敛情况分析可知, 改进的YOLO V3网络的训练结果比较理想。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>4.2 网络的测试</b></h4>
                <h4 class="anchor-tag" id="81" name="81">4.2.1 实验1</h4>
                <div class="p1">
                    <p id="82">将数据集中最小的3类目标car、vans、pickup归为一类 (car) , 分别对2个网络进行测试, 计算其对目标的召回率和检测的准确率。</p>
                </div>
                <div class="p1">
                    <p id="83">目标召回率<i>R</i>和检测的准确率<i>P</i>可分别表示为</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mo>=</mo><mfrac><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>X</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>X</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ρ</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">式中:<i>X</i><sub>TP</sub>表示正确检测出来的目标数;<i>X</i><sub>FN</sub>表示没有被检测出来的目标数;<i>X</i><sub>FP</sub>表示被错误检出的目标数。</p>
                </div>
                <div class="p1">
                    <p id="86">测试的166幅图像中共有430个目标, 使用两种目标检测算法在VEDAI数据集上进行测试, 分别计算<i>R</i>和<i>P</i>, 结果如表2所示。</p>
                </div>
                <div class="area_img" id="87">
                    <p class="img_tit">表2 不同算法目标检测结果的对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Comparison of target recognition results with different algorithms</p>
                    <p class="img_note"></p>
                    <table id="87" border="1"><tr><td>Detection algorithm</td><td><i>X</i><sub>TP</sub></td><td><i>X</i><sub>FP</sub></td><td><i>X</i><sub>FN</sub></td><td><i>P</i> /%</td><td><i>R</i> /%</td></tr><tr><td><br />YOLO V3</td><td>373</td><td>69</td><td>57</td><td>84.3</td><td>86.7</td></tr><tr><td><br />Improved YOLO V3</td><td>392</td><td>56</td><td>37</td><td>87.5</td><td>91.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="88">与YOLO V3相比, 改进的YOLO V3算法对小目标的检测准确率由84.3%提高到87.5%, 召回率由86.7%提高到91.2%。</p>
                </div>
                <div class="p1">
                    <p id="89">在VEDAI数据集上, 分别利用两种网络计算小目标检测的平均精准度 (AP) , 平均精准度是从召回率和准确率两个角度来衡量检测算法的准确性, 是评价检测模型准确性的直观评价标准, 可以用来分析单个类别的检测效果<citation id="122" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。检测结果分别如图7所示, 改进的YOLO V3网络将目标检测的平均精准度由85.37%提高到90.38%。</p>
                </div>
                <div class="p1">
                    <p id="90">改进的YOLO V3网络和原YOLO V3网络在VEDAI数据集下的检测结果如图8所示。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 各网络的AP曲线。" src="Detail/GetImg?filename=images/GXXB201907028_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 各网络的AP曲线。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 AP curves of each network. </p>
                                <p class="img_note"> (a) YOLO V3网络的AP曲线; (b) 改进YOLO V3网络的AP曲线</p>
                                <p class="img_note"> (a) AP curve of YOLO V3; (b) AP curve of improved YOLO V3</p>

                </div>
                <div class="p1">
                    <p id="92">图8 (a) 、 (c) 是YOLO V3目标检测算法对小目标的检测结果, 图8 (b) 、 (d) 是改进YOLO V3目标检测算法对小目标的检测结果。对比图8 (a) 、 (b) , 可以发现YOLO V3对小目标的检测存在漏检的问题, 而改进的YOLO V3网络可以检测出原YOLO V3网络漏检的目标。对比图8 (c) 、 (d) , 可以发现图8 (c) 中的深色框代表错检的目标, YOLO V3对小目标检测存在错检的问题, 而改进的YOLO V3网络可以避免对小目标的错检。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">4.2.2 实验2</h4>
                <div class="p1">
                    <p id="94">分别利用YOLO V3和改进的YOLO V3对数据集中的9类目标进行检测, 分别计算各类目标的平均准确率, 并计算9类目标的平均准确率均值 (mAP) 。mAP值越高表示模型在全部类别中检测的综合性能越好。测试结果如表3所示, 改进的YOLO V3网络将目标检测的平均精准度由55.81%提高到62.36%。</p>
                </div>
                <div class="p1">
                    <p id="95">改进的YOLO V3网络和原YOLO V3网络在VEDAI数据集的9类目标的检测结果如图9所示。</p>
                </div>
                <div class="p1">
                    <p id="96">图9 (a) 、 (c) 是YOLO V3目标检测算法对小目标的检测结果, 图9 (b) 、 (d) 是改进YOLO V3目标检测算法对小目标的检测结果。对比图9 (a) 、 (b) , 可以发现图9中的深色框代表错检的目标, YOLO V3对小目标检测存在错检的问题, 而改进的YOLO V3网络可以避免对小目标的错检。对比图9 (c) 、 (d) , 可以发现 YOLO V3对小目标检测存在漏检的问题, 而改进的YOLO V3网络可以检测出原YOLO V3网络的漏检目标。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 改进的YOLO V3算法与原YOLO V3算法对小目标的检测结果对比" src="Detail/GetImg?filename=images/GXXB201907028_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 改进的YOLO V3算法与原YOLO V3算法对小目标的检测结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Comparison of detection results obtained by improved YOLO V3 algorithm and original YOLO V3 algorithm for small object</p>

                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 改进YOLO V3算法与原YOLO V3算法对小目标的检测结果对比" src="Detail/GetImg?filename=images/GXXB201907028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 改进YOLO V3算法与原YOLO V3算法对小目标的检测结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Comparison of detection results obtained by improved YOLO V3 algorithm and original YOLO V3 algorithm for small object</p>

                </div>
                <h4 class="anchor-tag" id="99" name="99">4.2.3 结果分析</h4>
                <div class="p1">
                    <p id="100">根据实验1和实验2的结果, 分别从定量和定性两个方面对改进的YOLO V3网络和原YOLO V3 网络进行性能对比。</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit">表3 不同算法目标检测结果的对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Comparison of target detection results with different algorithms</p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td rowspan="2"><br />Detection algorithm</td><td colspan="9"><br />AP /%</td><td rowspan="2">mAP /%</td></tr><tr><td>Boat</td><td>Camping</td><td>Car</td><td>Others</td><td>Pickup</td><td>Tractors</td><td>Truck</td><td>Vans</td><td>Plane</td></tr><tr><td>YOLO V3</td><td>21</td><td>61</td><td>78</td><td>22</td><td>70</td><td>43</td><td>55</td><td>52</td><td>100</td><td>55.81</td></tr><tr><td><br />Improved YOLO V3</td><td>42</td><td>61</td><td>81</td><td>34</td><td>76</td><td>66</td><td>31</td><td>70</td><td>100</td><td>62.36</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="102" name="102">1) 定量对比。</h4>
                <div class="p1">
                    <p id="103">在实验1中, 改进的YOLO V3网络对小目标检测的准确率较原YOLO V3网络提高了3.2%, 召回率提高了4.5%, 对小目标检测的mAP值提高了5.01%。在实验2中, 改进的YOLO V3网络对9类小目标检测的mAP值较原YOLO V3网络提高了6.55%。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">2) 定性对比。</h4>
                <div class="p1">
                    <p id="105">从图8和图9可以看出, 原YOLO V3对场景中的小目标存在漏检和错检的情况, 而改进的YOLO V3网络可以有效地检测出场景中的小目标, 并且可以避免对小目标的错检。</p>
                </div>
                <h3 id="106" name="106" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="107">提出了一种YOLO V3改进方法, 并将其用于小目标检测中。首先, 对数据集的样本进行聚类分析, 得到数据集上对应的聚类中心。然后对YOLO V3输出的8倍下采样特征图进行2倍上采样, 将2倍上采样特征图与Darknet53中的第2个残差块输出的4倍降采样特征图进行拼接, 建立输出为4倍降采样的特征融合目标检测层。最后, 为了获取更多的小目标特征信息, 在YOLO V3网络结构Darknet53的第2个残差块中增加2个残差单元, 并将YOLO V3网络的目标检测输出层前的6个DBL单元变成2个DBL单元和两个ResNet单元。实验结果表明, 改进后的YOLO V3算法对小目标的召回率、检测的平均准确率均有明显的提高。但是, 改进后的YOLO V3算法离实时性距离工程应用仍有差距。如何在不降低检测性能的条件下精简网络结构、降低计算量, 将是未来的主要研究方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201707040&amp;v=MjEwMDk5Yk1xSTlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnluaFViL05MVHJTWkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Zhang X Y, Ding Q H, Luo H B, <i>et al</i>.Infrared dim target detection algorithm based on improved LCM[J].Infrared and Laser Engineering, 2017, 46 (7) :0726002.张祥越, 丁庆海, 罗海波, 等.基于改进LCM的红外小目标检测算法[J].红外与激光工程, 2017, 46 (7) :0726002.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXYK201804002&amp;v=MjEyODJDVVJMT2VaZVZ1RnluaFViL05QVFhTWmJHNEg5bk1xNDlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Zhang R, Li W P, Mo T.Review of deep learning[J].Information and Control, 2018, 47 (4) :385-397, 410.张荣, 李伟平, 莫同.深度学习研究综述[J].信息与控制, 2018, 47 (4) :385-397, 410.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201812027&amp;v=MDkxNTR6cXFCdEdGckNVUkxPZVplVnVGeW5oVWIvTklqWFRiTEc0SDluTnJZOUhZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Hua X, Wang X Q, Wang D, <i>et al</i>.Multi-objective detection of traffic based on improved SSD[J].Acta Optica Sinica, 2018, 38 (12) :1215003.华夏, 王新晴, 王东, 等.基于改进SSD的交通大场景多目标检测[J].光学学报, 2018, 38 (12) :1215003.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807020&amp;v=MTQzNTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmhVYi9OSWpYVGJMRzRIOW5NcUk5SFo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Wang W X, Fu Y T, Dong F, <i>et al</i>.Infrared ship target detection method based on deep convolution neural network[J].Acta Optica Sinica, 2018, 38 (7) :0712006.王文秀, 傅雨田, 董峰, 等.基于深度卷积神经网络的红外船只目标检测方法[J].光学学报, 2018, 38 (7) :0712006.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201705002&amp;v=MDkwNzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmhVYi9OTFRyU1pMRzRIOWJNcW85Rlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Luo H B, Xu L Y, Hui B, <i>et al</i>.Status and prospect of target tracking based on deep learning[J].Infrared and Laser Engineering, 2017, 46 (5) :0502002.罗海波, 许凌云, 惠斌, 等.基于深度学习的目标跟踪方法研究现状与展望[J].红外与激光工程, 2017, 46 (5) :0502002.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">

                                <b>[6]</b> Girshick R.Fast R-CNN[C]//2015 IEEE International Conference on Computer Vision (ICCV) , December 7-13, 2015, Santiago, Chile.New York:IEEE, 2015:1440-1448.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 Ren S Q, He K M, Girshick R, <i>et al</i>.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) :1137-1149.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">

                                <b>[8]</b> He K M, Gkioxari G, Dollár P, <i>et al</i>.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SSD:single shot multibox detector">

                                <b>[9]</b> Liu W, Anguelov D, Erhan D, <i>et al</i>.SSD:single shot multibox detector[M]//Leibe B, Matas J, SebeN, <i>et al</i>.Lecture notes in computer science.Cham:Springer, 2016, 9905:21-37.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 Redmon J, Divvala S, Girshick R, <i>et al</i>.You only look once:unified, real-time object detection[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:779-788.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 Redmon J, Farhadi A.YOLO9000:better, faster, stronger[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA.New York:IEEE, 2017:6517-6525.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=YOLOv3 an incremental improvement">

                                <b>[12]</b> Redmon J, Farhadi A.YOLOv3:an incremental improvement[EB/OL]. (2018-04-08) [2018-12-25].https://arxiv.org/abs/1804.02767.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8C3E45A38C465DF97AE8E1977B687CE1&amp;v=MzA1ODNIZjdxVE5zK2VDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4Ynk5d0swPU5pZk9mYnZMSGFUSXF2NUdiSmdMQ25sTnVSOFVtMHAxUFg3cnF4Vg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Razakarivony S, Jurie F.Vehicle detection in aerial imagery:a small target detection benchmark[J].Journal of Visual Communication and Image Representation, 2016, 34:187-203.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[14]</b> He K M, Zhang X Y, Ren S Q, <i>et al</i>.Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:770-778.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dssd:Deconvolutional single shot detector">

                                <b>[15]</b> Fu C Y, Liu W, Ranga A, <i>et al</i>.DSSD:deconvolutional single shot detector[EB/OL]. (2017-01-23) [2018-12-25].https://arxiv.org/abs/1701.06659.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806034&amp;v=MTkzMjRiTEc0SDluTXFZOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5oVWIvTklqWFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201907028" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201907028&amp;v=MTEwOTRuaFViL05JalhUYkxHNEg5ak1xSTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

