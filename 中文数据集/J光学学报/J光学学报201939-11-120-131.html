

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133059799658750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dGXXB201911015%26RESULT%3d1%26SIGN%3dWiwK7jbWYlBg6AXxtQXpZSpDe7g%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201911015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201911015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201911015&amp;v=MTY2NTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5dm5VTHZBSWpYVGJMRzRIOWpOcm85RVlZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="2 大气散射模型 ">2 大气散射模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#65" data-title="3 本文算法 ">3 本文算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="&lt;b&gt;3.1 动态环境光估计&lt;/b&gt;"><b>3.1 动态环境光估计</b></a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;3.2 透射率估计&lt;/b&gt;"><b>3.2 透射率估计</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;3.3 图像去雾&lt;/b&gt;"><b>3.3 图像去雾</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#105" data-title="&lt;b&gt;4.1 训练集的合理性分析&lt;/b&gt;"><b>4.1 训练集的合理性分析</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;4.2 动态环境光的有效性验证&lt;/b&gt;"><b>4.2 动态环境光的有效性验证</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;4.3 不同算法的去雾效果对比&lt;/b&gt;"><b>4.3 不同算法的去雾效果对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#128" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="图1 算法框架">图1 算法框架</a></li>
                                                <li><a href="#76" data-title="图2 环境光图粗分割。">图2 环境光图粗分割。</a></li>
                                                <li><a href="#82" data-title="图3 动态环境光。">图3 动态环境光。</a></li>
                                                <li><a href="#87" data-title="图4 部分训练集示例。">图4 部分训练集示例。</a></li>
                                                <li><a href="#91" data-title="图5 TEN结构">图5 TEN结构</a></li>
                                                <li><a href="#99" data-title="图6 透射率的估计与细化。">图6 透射率的估计与细化。</a></li>
                                                <li><a href="#109" data-title="图7 透射率估计效果对比。">图7 透射率估计效果对比。</a></li>
                                                <li><a href="#111" data-title="表1 不同训练集训练网络的去雾图像客观指标均值比较">表1 不同训练集训练网络的去雾图像客观指标均值比较</a></li>
                                                <li><a href="#115" data-title="图8 全局大气光和动态环境光复原效果。">图8 全局大气光和动态环境光复原效果。</a></li>
                                                <li><a href="#121" data-title="图9 不同算法的去雾结果。">图9 不同算法的去雾结果。</a></li>
                                                <li><a href="#122" data-title="表2 不同去雾算法去雾图像客观指标均值比较">表2 不同去雾算法去雾图像客观指标均值比较</a></li>
                                                <li><a href="#126" data-title="表3 不同去雾算法的去雾图像客观指标比较">表3 不同去雾算法的去雾图像客观指标比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="11">


                                    <a id="bibliography_1" title=" Chen B H,Huang S C,Cheng F C.A high-efficiency and high-speed gain intervention refinement filter for haze removal[J].Journal of Display Technology,2016,12(7):753-759." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A high-efficiency and high-speed gain intervention refinement filter for haze removal">
                                        <b>[1]</b>
                                         Chen B H,Huang S C,Cheng F C.A high-efficiency and high-speed gain intervention refinement filter for haze removal[J].Journal of Display Technology,2016,12(7):753-759.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_2" title=" Lu H B,Zhao Y F,Zhao Y J,&lt;i&gt;et al&lt;/i&gt;.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811027&amp;v=MDEyODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QUlqWFRiTEc0SDluTnJvOUhZNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Lu H B,Zhao Y F,Zhao Y J,&lt;i&gt;et al&lt;/i&gt;.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_3" title=" Tang H Z,Zhang X G,Zhu L,&lt;i&gt;et al&lt;/i&gt;.Study of single image dehazing algorithm based on propagated filtering and minimum color channels[J].Journal on Communications,2017,38(1):26-34.汤红忠,张小刚,朱玲,等.结合最小颜色通道图与传播滤波的单幅图像去雾算法研究[J].通信学报,2017,38(1):26-34." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201701004&amp;v=MjY5OTJGeXZuVUx2QU1UWFRiTEc0SDliTXJvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Tang H Z,Zhang X G,Zhu L,&lt;i&gt;et al&lt;/i&gt;.Study of single image dehazing algorithm based on propagated filtering and minimum color channels[J].Journal on Communications,2017,38(1):26-34.汤红忠,张小刚,朱玲,等.结合最小颜色通道图与传播滤波的单幅图像去雾算法研究[J].通信学报,2017,38(1):26-34.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_4" title=" He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2341-2353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single Image Haze Removal Using Dark Channel Prior">
                                        <b>[4]</b>
                                         He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2341-2353.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_5" title=" He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">
                                        <b>[5]</b>
                                         He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_6" title=" Zhu Q S,Mai J M,Shao L.A fast single image haze removal algorithm using color attenuation prior[J].IEEE Transactions on Image Processing,2015,24(11):3522-3533." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fast single image haze removal algorithm using color attenuation prior">
                                        <b>[6]</b>
                                         Zhu Q S,Mai J M,Shao L.A fast single image haze removal algorithm using color attenuation prior[J].IEEE Transactions on Image Processing,2015,24(11):3522-3533.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_7" title=" Xiao J S,Gao W,Zou B Y,&lt;i&gt;et al&lt;/i&gt;.Image dehazing based on sky-constrained dark channel prior[J].Acta Electronica Sinica,2017,45(2):346-352.肖进胜,高威,邹白昱,等.基于天空约束暗通道先验的图像去雾[J].电子学报,2017,45(2):346-352." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201702012&amp;v=MDM0ODZHNEg5Yk1yWTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnl2blVMdkFJVGZUZTc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Xiao J S,Gao W,Zou B Y,&lt;i&gt;et al&lt;/i&gt;.Image dehazing based on sky-constrained dark channel prior[J].Acta Electronica Sinica,2017,45(2):346-352.肖进胜,高威,邹白昱,等.基于天空约束暗通道先验的图像去雾[J].电子学报,2017,45(2):346-352.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_8" title=" Ju M Y,Gu Z F,Zhang D Y.Single image haze removal based on the improved atmospheric scattering model[J].Neurocomputing,2017,260:180-191." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES21E7108C1B28852C54CA8CDF9CAAC3AC&amp;v=MTc3ODQ3a3dNUUF5VzJodEdDTVBuUnN2c0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRsaHg3cTh4S0E9TmlmT2ZiRzVhOWJOcjRjMlpaa05CSFE4eldVVw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Ju M Y,Gu Z F,Zhang D Y.Single image haze removal based on the improved atmospheric scattering model[J].Neurocomputing,2017,260:180-191.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_9" title=" Cai B L,Xu X M,Jia K,&lt;i&gt;et al&lt;/i&gt;.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An end-to-end system for single image haze removal">
                                        <b>[9]</b>
                                         Cai B L,Xu X M,Jia K,&lt;i&gt;et al&lt;/i&gt;.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_10" title=" Ren W Q,Liu S,Zhang H,&lt;i&gt;et al&lt;/i&gt;.Single image dehazing via multi-scale convolutional neural networks[M]∥Leibe B,Matas J,Sebe N,&lt;i&gt;et al&lt;/i&gt;.Computer vision-ECCV 2016.Lecture notes in computer science.Cham:Springer,2016,9906:154-169." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single image dehazing via multi-scale convolutional neural networks">
                                        <b>[10]</b>
                                         Ren W Q,Liu S,Zhang H,&lt;i&gt;et al&lt;/i&gt;.Single image dehazing via multi-scale convolutional neural networks[M]∥Leibe B,Matas J,Sebe N,&lt;i&gt;et al&lt;/i&gt;.Computer vision-ECCV 2016.Lecture notes in computer science.Cham:Springer,2016,9906:154-169.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_11" title=" Li J J,Li G H,Fan H.Image dehazing using residual-based deep CNN[J].IEEE Access,2018,6:26831-26842." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image dehazing using residual-based deep CNN">
                                        <b>[11]</b>
                                         Li J J,Li G H,Fan H.Image dehazing using residual-based deep CNN[J].IEEE Access,2018,6:26831-26842.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_12" title=" Narasimhan S G,Nayar S K.Vision and the atmosphere[J].International Journal of Computer Vision,2002,48(3):233-254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830759&amp;v=MDk4OThIN1I3cWVidWR0RlNubFVMM0xKRlk9Tmo3QmFyTzRIdEhPcDR4RlkrNEdZM2s1ekJkaDRqOTlTWHFScnhveGNN&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Narasimhan S G,Nayar S K.Vision and the atmosphere[J].International Journal of Computer Vision,2002,48(3):233-254.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_13" title=" Narasimhan S G,Nayar S K.Contrast restoration of weather degraded images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(6):713-724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast restoration of weather degraded images">
                                        <b>[13]</b>
                                         Narasimhan S G,Nayar S K.Contrast restoration of weather degraded images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(6):713-724.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_14" title=" Kim J H,Jang W D,Sim J Y,&lt;i&gt;et al&lt;/i&gt;.Optimized contrast enhancement for real-time image and video dehazing[J].Journal of Visual Communication and Image Representation,2013,24(3):410-425." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900021680&amp;v=MTgxNzZDblE1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSTF3WGJobz1OaWZPZmJLN0h0VE1wbzlGWk9rTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Kim J H,Jang W D,Sim J Y,&lt;i&gt;et al&lt;/i&gt;.Optimized contrast enhancement for real-time image and video dehazing[J].Journal of Visual Communication and Image Representation,2013,24(3):410-425.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_15" title=" Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Investigating Haze-relevant Features in A Learning Framework for Image Dehazing">
                                        <b>[15]</b>
                                         Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_16" title=" Luan Z,Shang Y Y,Zhou X Z,&lt;i&gt;et al&lt;/i&gt;.Fast single image dehazing based on a regression model[J].Neurocomputing,2017,245:10-22." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES96392F6B0B295F2978E19B81BD75FCD3&amp;v=MTYzMDFKa05CWGxQelI4VTRrcDhRUTNxcldCQmZyZmlOczZjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGxoeDdxOHhLQT1OaWZPZmJxK0hkak8yWWszWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Luan Z,Shang Y Y,Zhou X Z,&lt;i&gt;et al&lt;/i&gt;.Fast single image dehazing based on a regression model[J].Neurocomputing,2017,245:10-22.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_17" title=" Li B Y,Ren W Q,Fu D P,&lt;i&gt;et al&lt;/i&gt;.Benchmarking single-image dehazing and beyond[J].IEEE Transactions on Image Processing,2019,28(1):492-505." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Benchmarking single-image dehazing and beyond">
                                        <b>[17]</b>
                                         Li B Y,Ren W Q,Fu D P,&lt;i&gt;et al&lt;/i&gt;.Benchmarking single-image dehazing and beyond[J].IEEE Transactions on Image Processing,2019,28(1):492-505.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_18" title=" Liu J P,Huang B K,Wei G.A fast effective single image dehazing algorithm[J].Acta Electronica Sinica,2017,45(8):1896-1901.刘杰平,黄炳坤,韦岗.一种快速的单幅图像去雾算法[J].电子学报,2017,45(8):1896-1901." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201708013&amp;v=MDYyMTR6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QUlUZlRlN0c0SDliTXA0OUVaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Liu J P,Huang B K,Wei G.A fast effective single image dehazing algorithm[J].Acta Electronica Sinica,2017,45(8):1896-1901.刘杰平,黄炳坤,韦岗.一种快速的单幅图像去雾算法[J].电子学报,2017,45(8):1896-1901.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_19" title=" Krizhevsky A,Sutskever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]∥Advances in Neural Information Processing Systems 25 (NIPS 2012),December 3-8,2012,Harrahs and Harveys,Lake Tahoe.Canada:NIPS,2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[19]</b>
                                         Krizhevsky A,Sutskever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]∥Advances in Neural Information Processing Systems 25 (NIPS 2012),December 3-8,2012,Harrahs and Harveys,Lake Tahoe.Canada:NIPS,2012:1097-1105.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_20" title=" Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]∥Proceedings of the thirteenth international conference on artificial intelligence and statistics,May 13-15,2010,Chia Laguna Resort,Sardinia,Italy.[S.l.:s.n.],2010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">
                                        <b>[20]</b>
                                         Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]∥Proceedings of the thirteenth international conference on artificial intelligence and statistics,May 13-15,2010,Chia Laguna Resort,Sardinia,Italy.[S.l.:s.n.],2010.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_21" title=" Large scale visual recognition challenge 2012[OL].[2019-05-30].http://www.image-net.org/challenges/LSVRC/2012/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large scale visual recognition challenge 2012[OL]">
                                        <b>[21]</b>
                                         Large scale visual recognition challenge 2012[OL].[2019-05-30].http://www.image-net.org/challenges/LSVRC/2012/.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_22" title=" Tu C P,Xiao J S,Du K H,&lt;i&gt;et al&lt;/i&gt;.Multi-focus image fusion algorithm based on the anisotropic thermal diffusion equation[J].Acta Electronica Sinica,2015,43(6):1192-1199.涂超平,肖进胜,杜康华,等.基于各向异性热扩散方程的多聚焦图像融合算法[J].电子学报,2015,43(6):1192-1199." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201506023&amp;v=MDYwMjg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QUlUZlRlN0c0SDlUTXFZOUhaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         Tu C P,Xiao J S,Du K H,&lt;i&gt;et al&lt;/i&gt;.Multi-focus image fusion algorithm based on the anisotropic thermal diffusion equation[J].Acta Electronica Sinica,2015,43(6):1192-1199.涂超平,肖进胜,杜康华,等.基于各向异性热扩散方程的多聚焦图像融合算法[J].电子学报,2015,43(6):1192-1199.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-07-29 09:29</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(11),120-131 DOI:10.3788/AOS201939.1110002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合卷积神经网络与动态环境光的图像去雾算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%9D%B0%E5%B9%B3&amp;code=07555469&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘杰平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E4%B8%9A%E9%95%BF&amp;code=39493905&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨业长</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%95%8F%E5%9B%AD&amp;code=41713445&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈敏园</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E4%B8%BD%E7%BA%A2&amp;code=07556170&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马丽红</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E5%8D%97%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0122765&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华南理工大学电子与信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了有效估计雾霾图像的透射率并改善去雾图像偏暗的问题,提出一种结合卷积神经网络与动态环境光的图像去雾算法。设计了基于卷积神经网络的透射率估计网络,构建包含配对的真实雾霾图像与透射率图像库,对其进行随机块采样,得到配对的雾霾图像块与透射率图像块,并将其作为训练集用于训练透射率估计网络;使用训练好的网络估计雾霾图像的透射率,并进行平滑滤波。考虑到图像成像时光照不均的问题,使用动态环境光替代全局大气光。使用平滑滤波后的透射率和动态环境光进行图像去雾。实验结果表明,该算法不仅可以有效实现图像去雾,而且提高了去雾图像的亮度和饱和度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E9%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去雾;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%B0%94%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大气散射模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%80%8F%E5%B0%84%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">透射率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘杰平,E-mail:eeliujp@scut.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-31</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61471173,61701181);</span>
                                <span>广东省自然科学基金(2017A030325430);</span>
                    </p>
            </div>
                    <h1><b>Image Dehazing Algorithm Based on Convolutional Neural Network and Dynamic Ambient Light</b></h1>
                    <h2>
                    <span>Liu Jieping</span>
                    <span>Yang Yezhang</span>
                    <span>Chen Minyuan</span>
                    <span>Ma Lihong</span>
            </h2>
                    <h2>
                    <span>School of Electronic and Information Engineering, South China University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To effectively estimate the transmittance of the hazy images and improve the darkness of the fog removal image, an image dehazing algorithm is proposed based on convolutional neural network and dynamic ambient light. Firstly, a transmittance estimation network is designed based on convolutional neural network. Then, an image library containing paired real hazy images and transmittance images is constructed. And randomly block sampling is performed to obtain the paired hazy patches and transmittance patches which are used as training sets for training the transmittance estimation network. After that, the trained network is used to estimate the transmittance of hazy images and then smooth the acquired transmittance. At the same time, considering the problem of uneven illumination of images, dynamic ambient light is used to replace global atmospheric light. Finally, the smooth filtered transmittance and dynamic ambient light are used to restore the images. Experimental results show that the algorithm can not only effectively restore the images, but also significantly improve the brightness and saturation of the restored images.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dehazing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dehazing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=atmospheric%20scattering%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">atmospheric scattering model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=transmittance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">transmittance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-05-31</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="55" name="55" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="56">户外图像在获取的过程中常会因受到空气中悬浮粒子(如雾、霾等)的影响而出现成像后图像对比度降低、饱和度下降和色调偏移等退化现象,严重影响户外计算机视觉技术,如智能手机摄像、目标检测与识别、自动驾驶、视频监控与遥感成像等功能的发挥。</p>
                </div>
                <div class="p1">
                    <p id="57">近年来,单幅图像去雾研究取得较大进展<citation id="144" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。He等<citation id="136" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出基于暗通道先验的去雾算法,利用软抠图算法细化透射率,取得了较好的去雾效果;之后,He等<citation id="137" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>采用导向滤波细化透射率,提高了算法的运行效率,但是去雾图像整体偏暗且天空区域容易出现失真。Zhu等<citation id="138" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>对雾霾图像的场景深度进行建模,采用监督学习的方法学习模型参数,使用训练好的模型估计雾霾图像深度,进一步得到透射率,取得较好的去雾效果。肖进胜等<citation id="139" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出基于天空约束暗通道先验的去雾算法,针对天空区域进行透射率修正,改善了图像的去雾效果,但去雾图像前景区域偏暗。Ju等<citation id="140" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>改进了大气散射模型,使其同时包含全局大气光与局部大气光2种光照环境,其中:全局大气光是一个全局值;对于局部大气光,则采用聚类算法将图像分割为3个区域,分别计算各区域的灰度均值作为对应区域的大气光值,改善了去雾图像偏暗的问题。随着深度学习的不断发展和网络结构的不断更新,越来越多的深度学习方法被用于去雾算法研究。Cai等<citation id="141" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用卷积神经网络学习雾霾图像块与对应透射率之间的映射关系,网络训练完成后,只需将雾霾图像作为模型的输入,便可以在模型的输出端得到对应的透射率,随后利用大气光值与平滑滤波后的透射率得到去雾图像。Ren等<citation id="142" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出一种由粗到细的透射率生成网络,该网络包含两个子网络,其中一个子网络用于估计粗透射率,另一个子网络则用于细化粗透射率,但该算法需要根据雾霾浓度手动调整相应参数。Li等<citation id="143" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出基于残差图像学习的去雾算法,该算法对大气散射模型进行变形,定义同时包含透射率与大气光值的残差图像,用卷积神经网络估计参数并代入模型,得到去雾图像。</p>
                </div>
                <div class="p1">
                    <p id="58">上述算法都是基于大气散射模型,通过估计雾霾图像的透射率与大气光值得到去雾结果。因此,去雾图像的质量直接取决于透射率与大气光值估计方法的有效性与准确性。为了准确估计雾霾图像的透射率并改善去雾图像偏暗的问题,本文提出一种结合卷积神经网络与动态环境光的去雾算法。仿真结果验证了本文算法的有效性。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag">2 大气散射模型</h3>
                <div class="p1">
                    <p id="60">光经过空气中悬浮粒子发生散射的大气物理模型<citation id="145" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>可以描述为</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">式中:<i>x</i>为图像中像素点的位置;<i><b>I</b></i>(<i>x</i>)为传感器观测到的图像,当空气中有大量的雾、霾等粒子时,<i><b>I</b></i>(<i>x</i>)退化为雾霾图像;<i><b>J</b></i>(<i>x</i>)为对应的清晰无雾图像;<i><b>A</b></i>为大气光照强度;<i>t</i>(<i>x</i>)为透射率,可表示为</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo stretchy="false">[</mo><mo>-</mo><mi>β</mi><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><mspace width="0.25em" /><mn>0</mn><mo>&lt;</mo><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≤</mo><mn>1</mn><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中<i>β</i>是大气散射系数,<i>d</i>(<i>x</i>)是场景深度。</p>
                </div>
                <h3 id="65" name="65" class="anchor-tag">3 本文算法</h3>
                <div class="p1">
                    <p id="66">本文算法框架如图1所示。算法主要由两个部分组成:1)动态环境光估计,提出动态环境光的概念,通过阈值分割、闭运算与迭代细化操作得到雾霾图像的动态环境光图,代替全局大气光用于图像去雾;2)透射率估计,设计透射率估计网络估计雾霾图像的透射率,并使用中值滤波对透射率进行平滑滤波。最后,综合使用动态环境光与滤波后的透射率进行图像去雾。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 算法框架" src="Detail/GetImg?filename=images/GXXB201911015_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Framework of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>3.1 动态环境光估计</b></h4>
                <div class="p1">
                    <p id="69">若透射率<i>t</i>(<i>x</i>)和大气光照强度<i><b>A</b></i>已知,便可根据(1)式得到去雾图像<i><b>J</b></i>(<i>x</i>):</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo>]</mo></mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">]</mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">由于<i>t</i>(<i>x</i>)∈(0,1],因此<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo>]</mo></mrow><mo>≥</mo><mn>0</mn></mrow></math></mathml>。当大气光为一个全局值时,该值通常大于图像中绝大多数像素的亮度值,即<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>-</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">A</mi><mo>|</mo></mrow><mo>≤</mo><mn>0</mn></mrow></math></mathml>。结合(3)式可知,雾霾图像的去雾过程实际上是在雾霾图像的基础上减去一个偏移量。因此,使用全局大气光去雾时,会导致雾霾图像中原本偏暗的区域在去雾后更暗。另外,由于场景中地物环境复杂,图像成像过程中部分区域可能因处于其他物体的阴影之中,而出现光照不均的问题,即处于不同位置的景物会接收到不同强度的大气光。基于以上分析,使用全局大气光进行图像去雾是不合理的。为了改善使用全局大气光复原图像导致去雾图像偏暗的问题,对图像的不同区域使用不同的大气光值,并称这样的大气光为动态环境光,简称环境光。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">3.1.1 环境光</h4>
                <div class="p1">
                    <p id="73">为了得到雾霾图像的环境光,先使用四叉树搜索算法<citation id="146" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>求得全局大气光A<sub><i>G</i></sub>,再根据A<sub><i>G</i></sub>将图像分割为3个区域:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>1</mn></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi>ξ</mi><mi>A</mi><msub><mrow></mrow><mtext>G</mtext></msub><mo>&lt;</mo><mi>V</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>≤</mo><mn>2</mn><mn>5</mn><mn>5</mn><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>2</mn></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi>ξ</mi><mi>A</mi><msub><mrow></mrow><mtext>G</mtext></msub><mo>/</mo><mn>2</mn><mo>&lt;</mo><mi>V</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>ξ</mi><mi>A</mi><msub><mrow></mrow><mtext>G</mtext></msub><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>3</mn></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>ξ</mi><mi>A</mi><msub><mrow></mrow><mtext>G</mtext></msub><mo>/</mo><mn>2</mn><mo stretchy="false">}</mo></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">式中:A<sub><i>rea</i></sub><sub>1</sub>、A<sub><i>rea</i></sub><sub>2</sub>、A<sub><i>rea</i></sub><sub>3</sub>分别表示雾霾图像中的天空区域(或浓雾区域)、近景区域与阴影偏暗区域;V(i,j)表示图像在<i>HSV</i>空间中的亮度通道;ξ为图像天空区域的分割系数;i,j分别表示像素点的行、列。为了确定ξ的取值,通过观察雾霾图像[图2(<i>a</i>)]的V通道直方图[图2(<i>b</i>)]发现,若图像中存在大面积天空区域或浓雾区域,对应V通道直方图中处于较大灰度值的位置具有明显的波峰,因此只要有效地定位该波峰对应波谷所在位置,便可以较好地分割出天空区域(或浓雾区域)。对于除天空区域之外的区域,利用阈值ξA<sub><i>G</i></sub>/2将剩下的区域分割为前景区域与阴影偏暗区域。采用大津阈值算法可以将图像分割为2个区域,即天空区域和非天空区域,得到天空区域阈值(大津阈值);根据四叉树算法得到图像的全局大气光,用天空区域阈值与全局大气光的比值确定分割系数ξ。对1000幅雾霾图像进行实验,结果显示,绝大部分雾霾图像的大津阈值与全局大气光的比值在0.8～1.0范围内,因此取ξ=0.9。大量实验结果表明,ξ=0.9时可以较好地定位雾霾图像V通道直方图中的波谷位置[图2(<i>b</i>)虚线处]。图2(<i>c</i>)展示了ξ=0.9时的分割结果,可以看出,所设置的分割系数不仅有效分割出了雾霾图像中的天空区域或浓雾区域,而且还较好地分割出了图像中的阴影偏暗区域和近景区域。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 环境光图粗分割。" src="Detail/GetImg?filename=images/GXXB201911015_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 环境光图粗分割。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Coarse segmentation of ambient light images.</p>
                                <p class="img_note">(a)雾霾图像;(b) V通道直方图;(c)区域分割</p>
                                <p class="img_note"> (a) Hazy images; (b) histograms of V channel; 
(c) regional segmentation</p>

                </div>
                <div class="p1">
                    <p id="77">将雾霾图像的<i>V</i>通道图像分割为3个区域后,取各区域内像素点的亮度均值作为对应区域的大气光,最终得到对应的粗环境光图,即</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo></mtd><mtd columnalign="left"><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>k</mi><mi>A</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo></mtd><mtd columnalign="left"><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>A</mi><msub><mrow></mrow><mn>3</mn></msub><mo>,</mo></mtd><mtd columnalign="left"><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mn>3</mn></mrow></msub></mtd></mtr></mtable></mrow></mrow><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">式中:<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mi>l</mi></mrow></msub></mrow></munder><mi>V</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></mfrac><mo stretchy="false">(</mo><mi>l</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>表示第<i>l</i>个区域的大气光;<i>c</i><sub><i>l</i></sub>表示第<i>l</i>个区域中的像素点个数。实验结果表明,适度增大近景区域的大气光值有利于改善去雾图像的整体视觉效果。因此,在计算近景区域的大气光值时引入增益系数<i>k</i>,令<i>k</i>=1.2。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">3.1.2 环境光图细化</h4>
                <div class="p1">
                    <p id="81">根据(5)式得到的粗环境光图如图3(b)所示,从图中可以看出,环境光图被有效地分成了3个区域,且不同区域拥有不同的大气光值。但是,粗环境光图较为粗糙,存在不连续区域,且在不同区域交界处变化突兀。因此,先对粗环境光图采取闭运算操作,去除不连续区域,再使用均值滤波进行迭代细化(设置迭代次数为10次),均值滤波半径为min(<i>W</i>/30,<i>H</i>/30),<i>W</i>、<i>H</i>分别为环境光图的宽和高。迭代细化后的结果即为动态环境光[图3(c)],记作<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>。从图3(c)可以看出,细化之后的环境光图较为平滑,且原雾霾图像中处于阴影中或色彩偏暗的区域,对应在环境光图中的区域也都被赋予了较小的大气光值。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 动态环境光。" src="Detail/GetImg?filename=images/GXXB201911015_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 动态环境光。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Dynamic ambient light. </p>
                                <p class="img_note">(a)雾霾图像;(b)粗环境光图;(c)细化环境光图</p>
                                <p class="img_note">(a) Hazy images; (b) rough ambient light maps; (c) refined ambient light maps</p>

                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>3.2 透射率估计</b></h4>
                <div class="p1">
                    <p id="84">为了有效估计雾霾图像的透射率,利用卷积神经网络,在由配对的雾霾图像块与透射率图像块构成的训练集上进行训练,学习雾霾图像与对应透射率图像之间的映射关系,再将训练好的模型用于透射率估计。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">3.2.1 训练集构造</h4>
                <div class="p1">
                    <p id="86">目前,透射率估计方法使用的训练集基本上都是人工合成的训练集<citation id="149" type="reference"><link href="21" rel="bibliography" /><link href="27" rel="bibliography" /><link href="39" rel="bibliography" /><link href="41" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">9</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>,即对清晰图像块使用随机给定的透射率值与大气光值合成雾霾图像块,然后训练模型得到雾霾图像块到单一透射率值的映射关系。然而,图像块中往往包含一定的空间结构,对图像块所有像素使用相同透射率值的做法并不合理。因此,在构造训练集时,应将图像块的空间结构考虑在内。从百度搜索引擎和RESIDES<citation id="147" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>数据集中收集得到共2000幅真实雾霾图像,采用文献<citation id="148" type="reference">[<a class="sup">18</a>]</citation>的透射率估计方法得到对应的透射率图像,建立包含配对的雾霾图像和透射率图像的图像库,部分图像如图4(a)、(b)所示。在网络中进行每一步训练时,对图像库中配对的雾霾图像和透射率图像在相同位置上进行随机块采样,得到配对的雾霾图像块与透射率图像块作为训练样本[图4(c)],用于网络的训练。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 部分训练集示例。" src="Detail/GetImg?filename=images/GXXB201911015_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 部分训练集示例。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Examples of training set.</p>
                                <p class="img_note">(a)真实雾霾图像;(b)透射率图像;(c)配对训练样本</p>
                                <p class="img_note"> (a) Real hazy images; (b) transmittance images; (c) paired training samples</p>

                </div>
                <h4 class="anchor-tag" id="89" name="89">3.2.2 透射率估计网络</h4>
                <div class="p1">
                    <p id="90">从已有的透射率估计方法可以看出,雾霾图像对应的透射率可以通过图像的暗通道、亮度通道,以及饱和度通道等图像特征得到。这说明透射率可以通过图像的一些基本特征组合得到。因此,在设计网络时不需要将网络结构设计得太复杂。基于以上分析,设计仅包含3个卷积层的卷积神经网络用于透射率估计,将其称为透射率估计网络(TEN),网络结构如图5所示。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 TEN结构" src="Detail/GetImg?filename=images/GXXB201911015_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 TEN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Structure of TEN</p>

                </div>
                <div class="p1">
                    <p id="92">网络中3个卷积层依次为特征提取层、特征映射层与特征组合层。特征提取层使用尺寸为3×3×3×64的卷积核提取输入雾霾图像的特征;特征映射层采用尺寸为1×1×64×32的卷积核进行特征图的降维映射,在压缩模型的同时增加网络的非线性;特征组合层采用尺寸为3×3×32×1的卷积核组合特征,输出对应的透射率图像。每一次卷积(Conv)操作之后都使用激活函数进行特征的非线性转换,使用的激活函数为ReLU<citation id="150" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>函数。TEN的目标损失函数为网络预测结果与训练集中对应的透射率图像块之间的均方误差,表达式为</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mfrac><mn>1</mn><mrow><mi>s</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></mstyle><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">F</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式中:<i><b>H</b></i><sub><i>m</i></sub>、<i><b>T</b></i><sub><i>m</i></sub>分别表示来自训练集的雾霾图像块和对应的透射率图像块;<i>s</i>表示图像块的边长;<i><b>F</b></i>(<i><b>H</b></i><sub><i>m</i></sub>)表示当网络输入为雾霾图像块<i><b>H</b></i><sub><i>m</i></sub>时网络的透射率估计结果;<i>m</i>为图像块索引,<i>m</i>=1,2,3,…,<i>N</i>;<i>N</i>为网络训练一步所使用的图像块的数量;<i>θ</i>为网络参数。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">3.2.3 透射率估计与细化</h4>
                <div class="p1">
                    <p id="96">网络训练完成之后,将雾霾图像[见图6(a)]作为网络的输入,便可以在输出端得到对应的透射率图像。图6(b)展示了TEN的透射率估计结果。从图中可以看出,训练完成的TEN可以有效估计雾霾图像的透射率,但是结果中包含较多的纹理信息,且存在部分估计不准确的区域和噪声。透射率包含的信息应该是分段平滑的,因此需要对TEN估计的透射率图像进行细化。中值滤波能够有效消除噪点、平滑图像,并保留边缘信息,本研究使用中值滤波对TEN估计得到的粗透射率图像进行细化。</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo stretchy="false">{</mo><mi>min</mi><mo stretchy="false">{</mo><mtext>m</mtext><mtext>e</mtext><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>n</mtext><mo stretchy="false">[</mo><msup><mi>t</mi><mo>′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>,</mo><mi>r</mi><mo stretchy="false">]</mo><mo>,</mo><mn>1</mn><mo>.</mo><mn>0</mn><mo stretchy="false">}</mo><mo>,</mo><mi>t</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">}</mo><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">式中:<i>t</i>′(<i>x</i>)表示使用训练完成的TEN估计的粗透射率图像;median[<i>t</i>′(<i>x</i>),<i>r</i>]表示对<i>t</i>′(<i>x</i>)进行中值滤波,滤波半径<i>r</i>=31;<i>t</i><sub>s</sub>(<i>x</i>)表示滤波后的透射率图像;<i>t</i><sub>0</sub>为经验值,取0.4。滤波之后的透射率图像如图6(c)所示。可以看出,滤波之后的透射率图像基本符合透射率与场景深度的变化规律,在深度一致区域透射率变化较为平滑,同时有效保留了必要的边缘信息。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 透射率的估计与细化。" src="Detail/GetImg?filename=images/GXXB201911015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 透射率的估计与细化。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Estimation and refinement of transmittance. </p>
                                <p class="img_note">(a)雾霾图像;(b) TEN估计的透射率;(c)细化后的透射率</p>
                                <p class="img_note">(a) Hazy images; (b) transmittance estimated by TEN; 
(c) refined transimittance</p>

                </div>
                <h4 class="anchor-tag" id="100" name="100"><b>3.3 图像去雾</b></h4>
                <div class="p1">
                    <p id="101">将雾霾图像<i><b>I</b></i>(<i>x</i>)与对应的动态环境光<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>、透射率<i>t</i><sub>s</sub>(<i>x</i>)代入(3)式,可得到去雾图像<i><b>J</b></i>(<i>x</i>):</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo>]</mo></mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">]</mo><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="104">从3个方面验证本文算法的有效性:1)训练集的合理性分析;2)动态环境光的有效性验证;3)不同算法的去雾结果对比。实验测试集包含74幅雾霾图像(均未参与网络训练)。用于训练的图像块边长<i>s</i>=15,每一步网络训练使用的图像块数量<i>N</i>=128。TEN中所有卷积层的卷积核权值初始化满足Xavier分布<citation id="151" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,偏置均被初始化为0。目标损失函数采用初始学习率为0.05、衰减系数为0.05的随机梯度下降(SGD)优化器进行优化。网络训练使用的硬件设备为NVIDIA TITAN Xp GPUs,采用的深度学习框架为Keras框架。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>4.1 训练集的合理性分析</b></h4>
                <div class="p1">
                    <p id="106">为了验证训练集构造方法的合理性与有效性,在所有网络训练参数设置相同的情况下,分别使用所构造的训练集、人工合成训练集训练TEN,并将训练得到的模型分别命名为TEN1与TEN2。其中,用于构造人工合成训练集的清晰图像共1542幅,来自RESIDES<citation id="152" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>数据集和ImageNet ILSVRC 2012<citation id="153" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>数据集。根据大气散射模型合成雾霾图像块时,透射率<i>t</i>的取值范围为0.1≤<i>t</i>≤1,大气光的取值范围为<mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>0</mn><mo>.</mo><mn>8</mn><mo>≤</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">A</mi><mo>|</mo></mrow><mo>≤</mo><mn>1</mn></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="107">图7显示了分别由训练完成的TEN1与TEN2估计的透射率。从图7(b)、(c)可以看出,由TEN2估计得到的透射率图像的灰度值分布较为集中,处于不同场景深度的透射率变化不明显;而由TEN1估计得到的透射率图像的灰度值动态范围较大,比较符合雾霾图像中场景深度与透射率的变化规律。这可能是由于使用人工合成训练集进行训练时,随机采样可能会得到相似的图像块,但是合成雾霾图像块时使用的透射率值与大气光值均为随机值,因此可能会造成同一个雾霾图像块对应多个透射率值的情况,从而对网络的训练造成一定程度的影响。同时,图像块中可能包含部分空间结构,而人工合成训练集中雾霾图像块的合成过程并不考虑图像块的空间结构,对于图像块所有像素均赋予相同的透射率值,因此训练得到的TEN2对于图像中存在的空间结构判断能力较差,导致透射率图像中不同场景深度的透射率变化不明显。</p>
                </div>
                <div class="p1">
                    <p id="108">图7(d)、(e)分别为使用TEN2与TEN1估计的透射率得到的去雾图像。从图中可以看出,使用TEN1估计的透射率得到的去雾图像具有更好的主观视觉效果,图像更加清晰,纹理细节更加丰富,说明由TEN1估计得到的透射率可以更好地复原雾霾图像。即对于TEN而言,相比于人工合成训练集,使用所构造的训练集训练网络更加合理有效。</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 透射率估计效果对比。" src="Detail/GetImg?filename=images/GXXB201911015_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 透射率估计效果对比。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison of transmittance estimation effects. </p>
                                <p class="img_note">(a)雾霾图像;(b) TEN2透射率;(c) TEN1透射率;
(d) TEN2去雾结果;(e) TEN1去雾结果</p>
                                <p class="img_note">(a) Hazy images; (b) transmittance estimated by TEN2; 
(c) transmittance estimated by TEN1; (d) restored results of TEN2; (e) restored results of TEN1</p>

                </div>
                <div class="p1">
                    <p id="110">进一步地,验证采用文献<citation id="154" type="reference">[<a class="sup">18</a>]</citation>中估计的透射率图像构造训练集的合理性。首先,分别采用刘杰平等<citation id="155" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、Zhu等<citation id="156" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Cai等<citation id="157" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和肖进胜等<citation id="158" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>估计透射率的方法得到透射率图像,再用本文方法构造训练集,训练透射率估计网络,用训练好的网络估计透射率,对雾霾图像进行去雾处理,即只有构造训练集时所用的透射率图像不同,其他处理方法都是相同的,由此得到在4个训练集上训练的4个透射率估计网络。用训练好的这4个网络对测试集中的74幅雾霾图像进行去雾处理,去雾图像的质量采用标准差(standard deviation)、平均梯度(average gradient)、信息熵(information entropy)和边缘强度<citation id="159" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>(edge intensity)4个客观指标进行评价。表1给出了74幅去雾图像各项客观指标的平均值。从表1可以看出,相对用其他3种算法的透射率图像构造训练集,利用基于文献<citation id="160" type="reference">[<a class="sup">18</a>]</citation>的透射率图像构造的训练集最终得到的去雾图像的标准差、平均梯度和边缘强度的平均值都是最优的,4个训练集最终得到的去雾图像的信息熵平均值相当。实验结果表明,用文献<citation id="161" type="reference">[<a class="sup">18</a>]</citation>的透射率图像构造的训练集更好。</p>
                </div>
                <div class="area_img" id="111">
                    <p class="img_tit">表1 不同训练集训练网络的去雾图像客观指标均值比较 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Comparison of average objective indexes of dehazing images using the trained network with different training sets</p>
                    <p class="img_note"></p>
                    <table id="111" border="1"><tr><td>Training <br />set</td><td>Standard <br />deviation</td><td>Average <br />gradient</td><td>Information <br />entropy</td><td>Edge <br />intensity</td></tr><tr><td><br />Ref. [6]</td><td>60.21</td><td>8.22</td><td>7.21</td><td>59.26</td></tr><tr><td><br />Ref. [9]</td><td>59.23</td><td>8.05</td><td><b>7.22</b></td><td>58.07</td></tr><tr><td><br />Ref. [7]</td><td>62.59</td><td>8.17</td><td><b>7.22</b></td><td>58.80</td></tr><tr><td><br />Ref. [18]</td><td><b>64.02</b></td><td><b>9.55</b></td><td>7.21</td><td><b>69.03</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="112">综合上述人工合成训练集和用不同透射率估计方法的透射率图像构造训练集的实验结果,采用文献<citation id="162" type="reference">[<a class="sup">18</a>]</citation>的透射率图像构造训练集是相对合理的,有利于网络的训练。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>4.2 动态环境光的有效性验证</b></h4>
                <div class="p1">
                    <p id="114">为了验证本文算法中使用的动态环境光的有效性,首先使用由所构造的训练集训练好的TEN估计得到雾霾图像的透射率图像,然后分别使用全局大气光与动态环境光得到相应的去雾图像。图8展示了部分实验结果,从图中可以看出,使用全局大气光得到的去雾图像中,雾霾图像中原本存在的偏暗区域以及去雾图像对应的偏暗区域,导致去雾图像整体视觉效果偏暗;使用动态环境光得到的去雾图像则不存在这个问题,去雾图像的亮度和清晰度都较高,表明本文算法使用的动态环境光可以更好、更有效地复原图像。</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 全局大气光和动态环境光复原效果。" src="Detail/GetImg?filename=images/GXXB201911015_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 全局大气光和动态环境光复原效果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Restored effects of global and dynamic ambient light. </p>
                                <p class="img_note">(a)雾霾图像;(b)全局大气光去雾结果;(c)动态环境光去雾结果</p>
                                <p class="img_note">(a) Hazy images; (b) results restored by 
global atmospheric light; (c) results restored by dynamic ambient light</p>

                </div>
                <h4 class="anchor-tag" id="116" name="116"><b>4.3 不同算法的去雾效果对比</b></h4>
                <div class="p1">
                    <p id="117">在进行算法去雾效果对比时,将本文算法与文献<citation id="166" type="reference">[<a class="sup">4</a>,<a class="sup">5</a>]</citation>中算法、文献<citation id="163" type="reference">[<a class="sup">6</a>]</citation>中算法、文献<citation id="164" type="reference">[<a class="sup">9</a>]</citation>中算法,以及文献<citation id="165" type="reference">[<a class="sup">10</a>]</citation>中算法从主观效果和客观指标两个方面进行对比。</p>
                </div>
                <div class="p1">
                    <p id="118">在去雾图像的主观效果方面,从测试集图像的去雾效果来看,不同算法对于测试集中的雾霾图像均具有一定的去雾效果,图9显示了其中部分去雾图像(从上往下依次命名为Img1至Img6)。其中:文献<citation id="167" type="reference">[<a class="sup">6</a>]</citation>中算法、文献<citation id="168" type="reference">[<a class="sup">9</a>]</citation>中算法都存在去雾不彻底的问题,部分去雾图像在主观视觉上仍然具有一层薄雾,同时,文献<citation id="169" type="reference">[<a class="sup">9</a>]</citation>中算法得到的部分去雾图像整体偏暗,细节信息得不到突出;文献<citation id="171" type="reference">[<a class="sup">4</a>,<a class="sup">5</a>]</citation>中算法得到的部分去雾图像的天空区域出现较多纹理(如Img1、Img2、Img4),去雾效果较差;文献<citation id="170" type="reference">[<a class="sup">10</a>]</citation>中算法得到的部分去雾图像出现明显的颜色失真(如Img3、Img4);本文算法得到的去雾图像相比于其他4种算法,去雾效果更加明显,纹理更清晰,且无明显的色彩失真。</p>
                </div>
                <div class="p1">
                    <p id="119">在去雾图像的客观效果方面,采用标准差、平均梯度、信息熵和边缘强度4个客观指标进行评价。其中,标准差和信息熵都可以反映图像中包含的信息量,平均梯度和边缘强度可以反映图像的纹理与细节丰富程度。表2给出了利用不同算法处理测试集中74幅雾霾图像得到的去雾图像各项客观指标的平均值。从表2可以看出,本文算法去雾图像的各项客观指标的平均值都是最优的。本文算法的标准差和信息熵的平均值最大,表明与其他算法相比,本文算法去雾图像的灰度级分布更加分散,图像的色彩更加丰富、对比度更高;本文算法的平均梯度和边缘强度的平均值最大,说明与其他算法相比,本文算法去雾图像的边缘细节更加丰富,图像更加清晰。</p>
                </div>
                <div class="p1">
                    <p id="120">表1和表2是对相同测试集去雾的客观指标的平均值,两个表中都有Zhu等<citation id="172" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>算法、Cai等<citation id="173" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法,但含义不同:表1是用这2种算法先估计透射率图,再用本文方法构造训练集,最后训练设计的网络得到的图像去雾结果;表2是直接利用这2种算法的去雾结果。对比表1和表2中Zhu等<citation id="182" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、Cai等<citation id="183" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法的结果,可以看出表1中的指标明显好于表2的,说明本文算法比Zhu等<citation id="184" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>算法和Cai等<citation id="185" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法的去雾结果更好,具有较好的适应性。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201911015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同算法的去雾结果。" src="Detail/GetImg?filename=images/GXXB201911015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同算法的去雾结果。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201911015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Dehazing results of different algorithms. </p>
                                <p class="img_note">(a)雾霾图像;(b)文献[4-5]中算法;(c)文献[6]中算法;(d)文献[9]中算法;
(e)文献[10]中算法;(f)本文算法</p>
                                <p class="img_note">(a) Hazy images; (b) method in Ref. [4-5]; (c) method in Ref. [6]; 
(d) method in Ref. [9]; (e) method in Ref. [10]; (f) proposed algorithm</p>

                </div>
                <div class="area_img" id="122">
                    <p class="img_tit">表2 不同去雾算法去雾图像客观指标均值比较 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Comparison of average objective indexes of dehazing images with different algorithms</p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td>Algorithm</td><td>Standard deviation</td><td>Average gradient</td><td>Information entropy</td><td>Edge intensity</td></tr><tr><td><br />Method in Ref. [4-5]</td><td>45.12</td><td>7.82</td><td>7.02</td><td>57.07</td></tr><tr><td><br />Method in Ref. [6]</td><td>51.35</td><td>7.65</td><td>7.14</td><td>55.50</td></tr><tr><td><br />Method in Ref. [9]</td><td>51.41</td><td>7.13</td><td>7.16</td><td>51.34</td></tr><tr><td><br />Method in Ref. [10]</td><td>51.32</td><td>8.04</td><td>7.20</td><td>57.82</td></tr><tr><td><br />Proposed method</td><td><b>64.02</b></td><td><b>9.55</b></td><td><b>7.21</b></td><td><b>69.03</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="124">表3给出了图9所示去雾图像的客观指标。从表中可以看出,在5种算法中,本文算法的边缘强度、标准差、平均梯度均为最好,说明本文算法的去雾图像边缘细节信息更加丰富、对比度更高、图像更加清晰。此外,本文算法的信息熵大多优于其他4种算法,说明本文算法得到的去雾图像色彩更加丰富、信息量更大。对比Img3的信息熵可得,本文算法的信息熵小于其他4种算法,但是从Img3去雾图像的主观效果来看,He等<citation id="190" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>算法与Zhu等<citation id="186" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>算法的去雾图像都偏暗,Cai等<citation id="187" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法几乎没有去雾效果,Ren等<citation id="188" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>算法的去雾图像的部分区域出现了色彩失真,而本文算法的去雾效果明显优于其他4种算法。对于Img4,本文算法的信息熵略低于Ren等<citation id="189" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>算法,但是其去雾图像出现了明显的色调偏移,与原图色调不一致。</p>
                </div>
                <div class="p1">
                    <p id="125">综合上述训练集的合理性分析、动态环境光有效性验证,以及与其他去雾算法去雾图像的主客观效果对比,充分表明了本文算法的有效性。在进行去雾图像客观指标对比时,由于单一客观指标不能完全反映图像质量,采用了多项客观指标,并在对部分图像的客观指标进行分析时适当结合了主观效果。最终实验结果对比显示,所提出的结合卷积神经网络和动态环境光的图像去雾算法相对于其他4种算法在去雾图像的主客观效果上都较为理想,去雾图像的整体主观效果较好、图像色彩丰富、亮度较高、清晰度高。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit">表3 不同去雾算法的去雾图像客观指标比较 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Comparison of objective indicators of dehazing images with different algorithms</p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td>Image</td><td>Algorithm</td><td>Standard deviation</td><td>Average gradient</td><td>Information entropy</td><td>Edge intensity</td></tr><tr><td rowspan="5"><br />Img1</td><td>Method in Ref. [4-5]</td><td>52.95</td><td>7.47</td><td>7.40</td><td>58.53</td></tr><tr><td><br />Method in Ref. [6]</td><td>61.70</td><td>7.49</td><td>7.34</td><td>59.37</td></tr><tr><td><br />Method in Ref. [9]</td><td>66.51</td><td>6.95</td><td>7.19</td><td>55.70</td></tr><tr><td><br />Method in Ref. [10]</td><td>62.45</td><td>7.27</td><td>7.34</td><td>58.09</td></tr><tr><td><br />Proposed method</td><td><b>76.28</b></td><td><b>9.00</b></td><td><b>7.54</b></td><td><b>71.62</b></td></tr><tr><td rowspan="5"><br />Img2</td><td>Method in Ref. [4-5]</td><td>45.33</td><td>13.02</td><td>7.47</td><td>89.47</td></tr><tr><td><br />Method in Ref. [6]</td><td>49.40</td><td>11.29</td><td>7.33</td><td>76.85</td></tr><tr><td><br />Method in Ref. [9]</td><td>37.43</td><td>8.90</td><td>7.09</td><td>62.69</td></tr><tr><td><br />Method in Ref. [10]</td><td>57.02</td><td>13.05</td><td>7.53</td><td>88.99</td></tr><tr><td><br />Proposed method</td><td><b>70.11</b></td><td><b>15.25</b></td><td><b>7.63</b></td><td><b>104.10</b></td></tr><tr><td rowspan="5"><br />Img3</td><td>Method in Ref. [4-5]</td><td>55.74</td><td>12.98</td><td>7.41</td><td>86.35</td></tr><tr><td><br />Method in Ref. [6]</td><td>55.60</td><td>12.96</td><td>7.61</td><td>86.28</td></tr><tr><td><br />Method in Ref. [9]</td><td>52.08</td><td>10.85</td><td>7.52</td><td>74.17</td></tr><tr><td><br />Method in Ref. [10]</td><td>67.54</td><td>14.61</td><td><b>7.62</b></td><td>97.78</td></tr><tr><td><br />Proposed method</td><td><b>77.63</b></td><td><b>18.01</b></td><td>7.23</td><td><b>119.85</b></td></tr><tr><td rowspan="5"><br />Img4</td><td>Method in Ref. [4-5]</td><td>49.30</td><td>17.69</td><td>7.54</td><td>119.87</td></tr><tr><td><br />Method in Ref. [6]</td><td>49.96</td><td>15.82</td><td>7.56</td><td>107.62</td></tr><tr><td><br />Method in Ref. [9]</td><td>56.78</td><td>15.93</td><td>7.60</td><td>106.44</td></tr><tr><td><br />Method in Ref. [10]</td><td>59.89</td><td>18.47</td><td><b>7.75</b></td><td>120.96</td></tr><tr><td><br />Proposed method</td><td><b>76.47</b></td><td><b>22.08</b></td><td>7.60</td><td><b>149.85</b></td></tr><tr><td rowspan="5"><br />Img5</td><td>Method in Ref. [4-5]</td><td>49.67</td><td>9.81</td><td>7.27</td><td>65.23</td></tr><tr><td><br />Method in Ref. [6]</td><td>49.98</td><td>10.22</td><td>7.29</td><td>67.33</td></tr><tr><td><br />Method in Ref. [9]</td><td>50.89</td><td>9.40</td><td>7.29</td><td>65.60</td></tr><tr><td><br />Method in Ref. [10]</td><td>54.45</td><td>9.89</td><td>7.24</td><td>69.11</td></tr><tr><td><br />Proposed method</td><td><b>61.95</b></td><td><b>12.11</b></td><td><b>7.36</b></td><td><b>78.80</b></td></tr><tr><td rowspan="5"><br />Img6</td><td>Method in Ref. [4-5]</td><td>33.07</td><td>5.11</td><td>6.82</td><td>35.96</td></tr><tr><td><br />Method in Ref. [6]</td><td>51.43</td><td>5.45</td><td>7.35</td><td>38.38</td></tr><tr><td><br />Method in Ref. [9]</td><td>59.43</td><td>4.70</td><td>7.57</td><td>34.38</td></tr><tr><td><br />Method in Ref. [10]</td><td>50.14</td><td>5.03</td><td>7.40</td><td>36.77</td></tr><tr><td><br />Proposed method</td><td><b>72.29</b></td><td><b>6.75</b></td><td><b>7.63</b></td><td><b>46.94</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="128" name="128" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="129">提出一种结合卷积神经网络与动态环境光的去雾算法。设计了基于卷积神经网络的透射率估计网络,并使用真实雾霾图像构造训练集,训练设计的网络,学习雾霾图像与对应透射率图像的映射关系;使用训练完成的网络估计雾霾图像的透射率。考虑到雾霾图像成像过程中存在光照不均的问题,采用图像分割等方法得到雾霾图像的动态环境光。利用平滑滤波后的透射率与动态环境光进行去雾处理,得到去雾图像。实验结果表明,利用训练得到的透射率估计网络可以有效估计雾霾图像的透射率,而且,由于使用了动态环境光,雾霾图像中原本偏暗区域的大气光得到了有效修正,有效改善了去雾图像偏暗的问题,取得了较好的图像去雾效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="11">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A high-efficiency and high-speed gain intervention refinement filter for haze removal">

                                <b>[1]</b> Chen B H,Huang S C,Cheng F C.A high-efficiency and high-speed gain intervention refinement filter for haze removal[J].Journal of Display Technology,2016,12(7):753-759.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811027&amp;v=MTkzODFqWFRiTEc0SDluTnJvOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Lu H B,Zhao Y F,Zhao Y J,<i>et al</i>.Image defogging based on combination of image bright and dark channels[J].Acta Optica Sinica,2018,38(11):1115004.卢辉斌,赵燕芳,赵永杰,等.基于亮通道和暗通道结合的图像去雾[J].光学学报,2018,38(11):1115004.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201701004&amp;v=MjkxMTNvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QU1UWFRiTEc0SDliTXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Tang H Z,Zhang X G,Zhu L,<i>et al</i>.Study of single image dehazing algorithm based on propagated filtering and minimum color channels[J].Journal on Communications,2017,38(1):26-34.汤红忠,张小刚,朱玲,等.结合最小颜色通道图与传播滤波的单幅图像去雾算法研究[J].通信学报,2017,38(1):26-34.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single Image Haze Removal Using Dark Channel Prior">

                                <b>[4]</b> He K M,Sun J,Tang X O.Single image haze removal using dark channel prior[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(12):2341-2353.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">

                                <b>[5]</b> He K M,Sun J,Tang X O.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(6):1397-1409.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fast single image haze removal algorithm using color attenuation prior">

                                <b>[6]</b> Zhu Q S,Mai J M,Shao L.A fast single image haze removal algorithm using color attenuation prior[J].IEEE Transactions on Image Processing,2015,24(11):3522-3533.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201702012&amp;v=MjgzODhIOWJNclk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5dm5VTHZBSVRmVGU3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Xiao J S,Gao W,Zou B Y,<i>et al</i>.Image dehazing based on sky-constrained dark channel prior[J].Acta Electronica Sinica,2017,45(2):346-352.肖进胜,高威,邹白昱,等.基于天空约束暗通道先验的图像去雾[J].电子学报,2017,45(2):346-352.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES21E7108C1B28852C54CA8CDF9CAAC3AC&amp;v=MTc4MzloeDdxOHhLQT1OaWZPZmJHNWE5Yk5yNGMyWlprTkJIUTh6V1VXN2t3TVFBeVcyaHRHQ01QblJzdnNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Ju M Y,Gu Z F,Zhang D Y.Single image haze removal based on the improved atmospheric scattering model[J].Neurocomputing,2017,260:180-191.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An end-to-end system for single image haze removal">

                                <b>[9]</b> Cai B L,Xu X M,Jia K,<i>et al</i>.DehazeNet:an end-to-end system for single image haze removal[J].IEEE Transactions on Image Processing,2016,25(11):5187-5198.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single image dehazing via multi-scale convolutional neural networks">

                                <b>[10]</b> Ren W Q,Liu S,Zhang H,<i>et al</i>.Single image dehazing via multi-scale convolutional neural networks[M]∥Leibe B,Matas J,Sebe N,<i>et al</i>.Computer vision-ECCV 2016.Lecture notes in computer science.Cham:Springer,2016,9906:154-169.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image dehazing using residual-based deep CNN">

                                <b>[11]</b> Li J J,Li G H,Fan H.Image dehazing using residual-based deep CNN[J].IEEE Access,2018,6:26831-26842.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830759&amp;v=MTcwNDh6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RlNubFVMM0xKRlk9Tmo3QmFyTzRIdEhPcDR4RlkrNEdZM2s1&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Narasimhan S G,Nayar S K.Vision and the atmosphere[J].International Journal of Computer Vision,2002,48(3):233-254.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast restoration of weather degraded images">

                                <b>[13]</b> Narasimhan S G,Nayar S K.Contrast restoration of weather degraded images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2003,25(6):713-724.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900021680&amp;v=MTcyNjdYYmhvPU5pZk9mYks3SHRUTXBvOUZaT2tPQ25RNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUkxdw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Kim J H,Jang W D,Sim J Y,<i>et al</i>.Optimized contrast enhancement for real-time image and video dehazing[J].Journal of Visual Communication and Image Representation,2013,24(3):410-425.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Investigating Haze-relevant Features in A Learning Framework for Image Dehazing">

                                <b>[15]</b> Tang K T,Yang J C,Wang J.Investigating haze-relevant features in a learning framework for image dehazing[C]//2014 IEEE Conference on Computer Vision and Pattern Recognition,June 23-28,2014,Columbus,OH,USA.New York:IEEE,2014:2995-3002.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES96392F6B0B295F2978E19B81BD75FCD3&amp;v=MTAxODlmT0dRbGZDcGJRMzVkbGh4N3E4eEtBPU5pZk9mYnErSGRqTzJZazNaSmtOQlhsUHpSOFU0a3A4UVEzcXJXQkJmcmZpTnM2Y0NPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Luan Z,Shang Y Y,Zhou X Z,<i>et al</i>.Fast single image dehazing based on a regression model[J].Neurocomputing,2017,245:10-22.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Benchmarking single-image dehazing and beyond">

                                <b>[17]</b> Li B Y,Ren W Q,Fu D P,<i>et al</i>.Benchmarking single-image dehazing and beyond[J].IEEE Transactions on Image Processing,2019,28(1):492-505.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201708013&amp;v=MDc0MTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5dm5VTHZBSVRmVGU3RzRIOWJNcDQ5RVo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Liu J P,Huang B K,Wei G.A fast effective single image dehazing algorithm[J].Acta Electronica Sinica,2017,45(8):1896-1901.刘杰平,黄炳坤,韦岗.一种快速的单幅图像去雾算法[J].电子学报,2017,45(8):1896-1901.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[19]</b> Krizhevsky A,Sutskever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]∥Advances in Neural Information Processing Systems 25 (NIPS 2012),December 3-8,2012,Harrahs and Harveys,Lake Tahoe.Canada:NIPS,2012:1097-1105.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">

                                <b>[20]</b> Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]∥Proceedings of the thirteenth international conference on artificial intelligence and statistics,May 13-15,2010,Chia Laguna Resort,Sardinia,Italy.[S.l.:s.n.],2010.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large scale visual recognition challenge 2012[OL]">

                                <b>[21]</b> Large scale visual recognition challenge 2012[OL].[2019-05-30].http://www.image-net.org/challenges/LSVRC/2012/.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201506023&amp;v=MDQ2MjRlN0c0SDlUTXFZOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeXZuVUx2QUlUZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> Tu C P,Xiao J S,Du K H,<i>et al</i>.Multi-focus image fusion algorithm based on the anisotropic thermal diffusion equation[J].Acta Electronica Sinica,2015,43(6):1192-1199.涂超平,肖进胜,杜康华,等.基于各向异性热扩散方程的多聚焦图像融合算法[J].电子学报,2015,43(6):1192-1199.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201911015" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201911015&amp;v=MTY2NTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5dm5VTHZBSWpYVGJMRzRIOWpOcm85RVlZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01aTVQrV2x1a2h6OTd3KzRlTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

