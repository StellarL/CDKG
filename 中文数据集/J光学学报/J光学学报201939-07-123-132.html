

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133860739502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201907013%26RESULT%3d1%26SIGN%3d3qJ1pDnYpi7NMieYUvJPkHtd34o%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201907013&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201907013&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201907013&amp;v=MTQxMzZxQnRHRnJDVVJMT2VaZVZ1RnluZ1ZidkxJalhUYkxHNEg5ak1xSTlFWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#68" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="2 混合颗粒分类的基本方法 ">2 混合颗粒分类的基本方法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="3 基于&lt;i&gt;CNN&lt;/i&gt;的混合颗粒分类方法 ">3 基于<i>CNN</i>的混合颗粒分类方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="&lt;b&gt;3.1 网络结构&lt;/b&gt;"><b>3.1 网络结构</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;3.2 网络结构优化&lt;/b&gt;"><b>3.2 网络结构优化</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;3.3 RPN网络和FCN网络&lt;/b&gt;"><b>3.3 RPN网络和FCN网络</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;3.4 Loss函数&lt;/b&gt;"><b>3.4 Loss函数</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;3.5 算法流程及参数优化&lt;/b&gt;"><b>3.5 算法流程及参数优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="4 实验及结果分析 ">4 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#108" data-title="&lt;b&gt;4.1 实验装置&lt;/b&gt;"><b>4.1 实验装置</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;4.2 数据集预处理&lt;/b&gt;"><b>4.2 数据集预处理</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;4.3 结果分析&lt;/b&gt;"><b>4.3 结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="表1 颗粒的特征描述子">表1 颗粒的特征描述子</a></li>
                                                <li><a href="#79" data-title="图1 混合颗粒分类的CNN结构">图1 混合颗粒分类的CNN结构</a></li>
                                                <li><a href="#84" data-title="表2 conv3_x和conv4_x的结构配置">表2 conv3_x和conv4_x的结构配置</a></li>
                                                <li><a href="#88" data-title="图2 RPN网络结构。">图2 RPN网络结构。</a></li>
                                                <li><a href="#100" data-title="图3 混合颗粒的分类算法流程">图3 混合颗粒的分类算法流程</a></li>
                                                <li><a href="#107" data-title="图4 不同类型的颗粒。">图4 不同类型的颗粒。</a></li>
                                                <li><a href="#110" data-title="图5 混合颗粒测量系统">图5 混合颗粒测量系统</a></li>
                                                <li><a href="#113" data-title="图6 图像处理流程">图6 图像处理流程</a></li>
                                                <li><a href="#119" data-title="图7 不同方法处理后混合颗粒的图像。">图7 不同方法处理后混合颗粒的图像。</a></li>
                                                <li><a href="#122" data-title="图8 不同分类方法得到的颗粒计数结果">图8 不同分类方法得到的颗粒计数结果</a></li>
                                                <li><a href="#123" data-title="图9 不同分类方法的检测准确率">图9 不同分类方法的检测准确率</a></li>
                                                <li><a href="#125" data-title="图10 不同分类方法得到的颗粒的当量直径累积分布">图10 不同分类方法得到的颗粒的当量直径累积分布</a></li>
                                                <li><a href="#126" data-title="表3 不同分类方法得到的颗粒的测量尺寸">表3 不同分类方法得到的颗粒的测量尺寸</a></li>
                                                <li><a href="#128" data-title="图11 不同分类方法得到的长条形颗粒的长宽比累积分布">图11 不同分类方法得到的长条形颗粒的长宽比累积分布</a></li>
                                                <li><a href="#129" data-title="图12 不同分类方法得到的球形颗粒的长宽比累积分布">图12 不同分类方法得到的球形颗粒的长宽比累积分布</a></li>
                                                <li><a href="#130" data-title="图13 不同分类方法得到的非规则颗粒的长宽比累积分布">图13 不同分类方法得到的非规则颗粒的长宽比累积分布</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="152">


                                    <a id="bibliography_1" title=" Yuan W, Chin K S, Hua M, et al.Shape classification of wear particles by image boundary analysis using machine learning algorithms[J].Mechanical Systems and Signal Processing, 2016, 72/73:346-358." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9E6378840092EA9F2F3E3B639B90F922&amp;v=MjczNDZsSXhtQVJuRHdJU3cza3J4dEhjTExpVExpZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2Zick5HTkxMcDRkQlpPc0dEZw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Yuan W, Chin K S, Hua M, et al.Shape classification of wear particles by image boundary analysis using machine learning algorithms[J].Mechanical Systems and Signal Processing, 2016, 72/73:346-358.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_2" title=" Peng Y P, Wu T H, Cao G Z, et al.A hybrid search-tree discriminant technique for multivariate wear debris classification[J].Wear, 2017, 392/393:152-158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8F528596613B13CD61D468C2BDC88F35&amp;v=MjUzNjVCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJ2T0c5UEVxb1pEWXVvTWZuMDZ2R0lWNjB0NVRuZVJybUJCQ3JxY003bWFDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Peng Y P, Wu T H, Cao G Z, et al.A hybrid search-tree discriminant technique for multivariate wear debris classification[J].Wear, 2017, 392/393:152-158.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_3" title=" Stachowiak G P, Stachowiak G W, Podsiadlo P.Automated classification of wear particles based on their surface texture and shape features[J].Tribology International, 2008, 41 (1) :34-43." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101075799&amp;v=MDUwMDByUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVnNTYmhFPU5pZk9mYks3SHRET3JvOUVaT3dLQzNVd29CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Stachowiak G P, Stachowiak G W, Podsiadlo P.Automated classification of wear particles based on their surface texture and shape features[J].Tribology International, 2008, 41 (1) :34-43.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_4" title=" Hong W, Cai W J, Wang S P, et al.Mechanical wear debris feature, detection, and diagnosis:a review[J].Chinese Journal of Aeronautics, 2018, 31 (5) :867-882." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKXS201805001&amp;v=MzI1NTh0R0ZyQ1VSTE9lWmVWdUZ5bmdWYnZMTFNiVGZiRzRIOW5NcW85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Hong W, Cai W J, Wang S P, et al.Mechanical wear debris feature, detection, and diagnosis:a review[J].Chinese Journal of Aeronautics, 2018, 31 (5) :867-882.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_5" title=" Raadnui S.Wear particle analysis:utilization of quantitative computer image analysis:a review[J].Tribology International, 2005, 38 (10) :871-878." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101076293&amp;v=MTEwNDlIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVnNTYmhFPU5pZk9mYks3SHRET3JvOUVaT3dKRG5VNm9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Raadnui S.Wear particle analysis:utilization of quantitative computer image analysis:a review[J].Tribology International, 2005, 38 (10) :871-878.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_6" title=" Terdenge L M, Heisel S, Schembecker G, et al.Agglomeration degree distribution as quality criterion to evaluate crystalline products[J].Chemical Engineering Science, 2015, 133:157-169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15120600488839&amp;v=MjY3ODRJVnNTYmhFPU5pZk9mYks5SDlQTXFZOUZZT01IQkg4d29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Terdenge L M, Heisel S, Schembecker G, et al.Agglomeration degree distribution as quality criterion to evaluate crystalline products[J].Chemical Engineering Science, 2015, 133:157-169.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_7" title=" Heisel S, Kovaevi.Variable selection and training set design for particle classification using a linear and a non-linear classifier[J].Chemical Engineering Science, 2017, 173:131-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1452B57101C7A994C3C334A91F2B6CBD&amp;v=MDAzNzU4RzlPK3FvaEVaT3A4Q3cwd3hoSmc2VXgrUzN1VHBSTkRlOENTTnNqckNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Heisel S, Kovaevi.Variable selection and training set design for particle classification using a linear and a non-linear classifier[J].Chemical Engineering Science, 2017, 173:131-144.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_8" title=" Mehle A, Kitak D, Podrekar G, et al.In-line agglomeration degree estimation in fluidized bed pellet coating processes using visual imaging[J].International Journal of Pharmaceutics, 2018, 546 (1/2) :78-85." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES29637EAA7C5173375C13457529D1B3C4&amp;v=MTcxMzJEWHM2ekJFV21UNStUSHJscVJBOERiUG1Sc21iQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJHeEdOTEwydjQwWTVnSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Mehle A, Kitak D, Podrekar G, et al.In-line agglomeration degree estimation in fluidized bed pellet coating processes using visual imaging[J].International Journal of Pharmaceutics, 2018, 546 (1/2) :78-85.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_9" title=" Wang J D, Cao Y J, Jiang X J, et al.Agglomeration detection by acoustic emission (AE) sensors in fluidized beds[J].Industrial &amp;amp; Engineering Chemistry Research, 2009, 48 (7) :3466-3473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Agglomeration Detection by Acoustic Emission (AE) Sensors in Fluidized Beds">
                                        <b>[9]</b>
                                         Wang J D, Cao Y J, Jiang X J, et al.Agglomeration detection by acoustic emission (AE) sensors in fluidized beds[J].Industrial &amp;amp; Engineering Chemistry Research, 2009, 48 (7) :3466-3473.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_10" title=" Sheahan T, Briens L.Passive acoustic emissions monitoring of the coating of pellets in a fluidized bed:a feasibility analysis[J].Powder Technology, 2015, 283:373-379." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300224849&amp;v=MDcwNTF3WmVadUh5am1VYi9JSVZzU2JoRT1OaWZPZmJLOUg5UE9ySTlGWnVrTEJIZ3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Sheahan T, Briens L.Passive acoustic emissions monitoring of the coating of pellets in a fluidized bed:a feasibility analysis[J].Powder Technology, 2015, 283:373-379.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_11" title=" Iacoviello F, Iacoviello D, di Cocco V, et al.Classification of ductile cast iron specimens based on image analysis and support vector machine[J].Procedia Structural Integrity, 2017, 3:283-290." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES513B14B74B124F38F0DEECC2F52CB25C&amp;v=MTQzMTJGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2ZiYTVIYVBOcS8xQ1lKa09EbmhQekI1bDZrc0lQUXlScm1Rd2U4SG1SNy9zQ09Odg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Iacoviello F, Iacoviello D, di Cocco V, et al.Classification of ductile cast iron specimens based on image analysis and support vector machine[J].Procedia Structural Integrity, 2017, 3:283-290.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_12" title=" Ajdadi F R, Gilandeh Y A, Mollazade K, et al.Application of machine vision for classification of soil aggregate size[J].Soil and Tillage Research, 2016, 162:8-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Application of machine vision for classification of soil aggregate size">
                                        <b>[12]</b>
                                         Ajdadi F R, Gilandeh Y A, Mollazade K, et al.Application of machine vision for classification of soil aggregate size[J].Soil and Tillage Research, 2016, 162:8-17.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_13" title=" Stachowiak G W, Podsiadlo P.Towards the development of an automated wear particle classification system[J].Tribology International, 2006, 39 (12) :1615-1623." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101076057&amp;v=MTQ0OTBLN0h0RE9ybzlFWk93SkRIaytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVnNTYmhFPU5pZk9mYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Stachowiak G W, Podsiadlo P.Towards the development of an automated wear particle classification system[J].Tribology International, 2006, 39 (12) :1615-1623.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_14" title=" Zhang Y, Liu J J, Zhang L, et al.Particle shape characterisation and classification using automated microscopy and shape descriptors in batch manufacture of particulate solids[J].Particuology, 2016, 24:61-68." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7C81DAF3D6F7DB21D11543FC1E36FFE2&amp;v=MDcxMjVyVGlNOCtkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJUTEZ0QzQzdmxHRU8xNUN3aEx6UmRuNno1NFRIeVUzeE5BZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Zhang Y, Liu J J, Zhang L, et al.Particle shape characterisation and classification using automated microscopy and shape descriptors in batch manufacture of particulate solids[J].Particuology, 2016, 24:61-68.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_15" title=" Lee H, Chen Y P P.Cell morphology based classification for red cells in blood smear images[J].Pattern Recognition Letters, 2014, 49:155-161." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700171522&amp;v=MTk5OTdiSzhIOURNcUk5Rlpld09DWDQ3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSVZzU2JoRT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Lee H, Chen Y P P.Cell morphology based classification for red cells in blood smear images[J].Pattern Recognition Letters, 2014, 49:155-161.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_16" title=" Calderon C P, Daniels A L, Randolph T W.Deep convolutional neural network analysis of flow imaging microscopy data to classify subvisible particles in protein formulations[J].Journal of Pharmaceutical Sciences, 2018, 107 (4) :999-1008." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES540D466ABDC3F0EF30798A28A2660F22&amp;v=MTYyNjZmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJhOEhxWElxWWswRnA5OER3bzV1bUFRNmpoMFFBN2dwR00zZjdTVU03aWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Calderon C P, Daniels A L, Randolph T W.Deep convolutional neural network analysis of flow imaging microscopy data to classify subvisible particles in protein formulations[J].Journal of Pharmaceutical Sciences, 2018, 107 (4) :999-1008.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_17" title=" Chaves D, Fern&#225;ndez-Robles L, Bernal J, et al.Automatic characterisation of chars from the combustion of pulverised coals using machine vision[J].Powder Technology, 2018, 338:110-118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3D682109FD207436FF21076D3AF7EE75&amp;v=MTU4NDZzOXpCQmxuRDE4U0hqazJCRkVEN1hoTUwyYUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2ZiRE1HTm5Pcm85TUVwOE5ESA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Chaves D, Fern&#225;ndez-Robles L, Bernal J, et al.Automatic characterisation of chars from the combustion of pulverised coals using machine vision[J].Powder Technology, 2018, 338:110-118.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_18" title=" Vogado L H S, Veras R M S, Araujo F H D, et al.Leukemia diagnosis in blood slides using transfer learning in CNNs and SVM for classification[J].Engineering Applications of Artificial Intelligence, 2018, 72:415-422." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4CA015BECF2CC4750F6554B8BD8DC0E7&amp;v=MTg1ODJzPU5pZk9mYmZMYjlITnF2MHdGNTBOZnc4OXlCTVRuRGw0VFh1UXBHQkJjY2JuUmMrWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4Sw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Vogado L H S, Veras R M S, Araujo F H D, et al.Leukemia diagnosis in blood slides using transfer learning in CNNs and SVM for classification[J].Engineering Applications of Artificial Intelligence, 2018, 72:415-422.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_19" title=" Raitoharju J, Riabchenko E, Ahmad I, et al.Benchmark database for fine-grained image classification of benthic macroinvertebrates[J].Image and Vision Computing, 2018, 78:73-83." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES25626B23E743F7434F86D45B404FB4D3&amp;v=MjQxMDM9TmlmT2ZiRzlHTlBLM1kxR0Vld0xEd28reXhVWG5EZDdQSHZuM2hZMWZjVG1RYzZjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Raitoharju J, Riabchenko E, Ahmad I, et al.Benchmark database for fine-grained image classification of benthic macroinvertebrates[J].Image and Vision Computing, 2018, 78:73-83.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_20" title=" Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806034&amp;v=MjY1NjFyQ1VSTE9lWmVWdUZ5bmdWYnZMSWpYVGJMRzRIOW5NcVk5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_21" title=" Du J, Hu B L, Zhang Z F.Gastric carcinoma classification based on convolutional neural network and micro-hyperspectral imaging[J].Acta Optica Sinica, 2018, 38 (6) :0617001.杜剑, 胡炳樑, 张周锋.基于卷积神经网络与显微高光谱的胃癌组织分类方法研究[J].光学学报, 2018, 38 (6) :0617001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806036&amp;v=MjcyNjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5nVmJ2TElqWFRiTEc0SDluTXFZOUdZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Du J, Hu B L, Zhang Z F.Gastric carcinoma classification based on convolutional neural network and micro-hyperspectral imaging[J].Acta Optica Sinica, 2018, 38 (6) :0617001.杜剑, 胡炳樑, 张周锋.基于卷积神经网络与显微高光谱的胃癌组织分类方法研究[J].光学学报, 2018, 38 (6) :0617001.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     Ren S Q, He K M, Girshick R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) :1137-1149.</a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_23" title=" He K M, Gkioxari G, Doll&#225;r P, et al.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">
                                        <b>[23]</b>
                                         He K M, Gkioxari G, Doll&#225;r P, et al.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_24" >
                                        <b>[24]</b>
                                     He K M, Zhang X Y, Ren S Q, et al.Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:770-778.</a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_25" title=" Lin T Y, Doll&#225;r P, Girshick R, et al.Feature pyramid networks for object detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA.New York:IEEE, 2017:936-944" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature pyramid networks for object detection">
                                        <b>[25]</b>
                                         Lin T Y, Doll&#225;r P, Girshick R, et al.Feature pyramid networks for object detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA.New York:IEEE, 2017:936-944
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_26" title=" Shelhamer E, Long J, Darrell T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[26]</b>
                                         Shelhamer E, Long J, Darrell T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_27" title=" Vala H J, Baxi A.A review on Otsu image segmentation algorithm [J].International Journal of Advanced Research in Computer Engineering &amp;amp; Technology, 2013, 2 (2) :387-389." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Review on Otsu Image Segmentation Algorithm">
                                        <b>[27]</b>
                                         Vala H J, Baxi A.A review on Otsu image segmentation algorithm [J].International Journal of Advanced Research in Computer Engineering &amp;amp; Technology, 2013, 2 (2) :387-389.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_28" title=" Vincent L, Soille P.Watersheds in digital spaces:an efficient algorithm based on immersion simulations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1991, 13 (6) :583-598." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Watersheds in digital spaces: An efficient algorithm based on immersion simulations">
                                        <b>[28]</b>
                                         Vincent L, Soille P.Watersheds in digital spaces:an efficient algorithm based on immersion simulations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1991, 13 (6) :583-598.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-02 15:13</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(07),123-132 DOI:10.3788/AOS201939.0712002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的混合颗粒分类法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%94%A1%E6%9D%A8&amp;code=42141056&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蔡杨</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%8F%E6%98%8E%E6%97%AD&amp;code=00084059&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏明旭</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%94%A1%E5%B0%8F%E8%88%92&amp;code=14809743&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蔡小舒</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%83%BD%E6%BA%90%E4%B8%8E%E5%8A%A8%E5%8A%9B%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0256814&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学能源与动力工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对混合颗粒的分类问题, 传统算法多利用颗粒的二值化图像提取其特征, 并通过精细的特征设计结合BP神经网络、支持向量机 (SVM) 等分类器进行分类, 但颗粒粘连以及不精确的特征设计都会严重影响分类的准确率。利用卷积神经网络提取颗粒的特征, 通过区域建议网络 (RPN) 搜索颗粒的位置, 同时建立分类器, 并结合全卷积网络实现像素级的颗粒分割。对由球形、长条形及非规则形颗粒组成的混合流动颗粒体系进行实验研究, 结果表明:利用人工特征设计的SVM法可以达到87%的分类精确率和召回率, 而基于卷积神经网络的方法则可以达到97%的分类精确率和93%的召回率, 并且对于非规则颗粒的数目中位径, 该方法不仅可以将分析误差降低11%以上, 还避免了传统方法需要精确设计人工特征等的不足, 更易形成一个端对端的混合颗粒分类体系, 为流动混合颗粒的图像在线分析提供了更加有效的思路。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%8B%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">测量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%97%E7%B2%92%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颗粒分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *苏明旭, E-mail:sumx@usst.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (51776129);</span>
                    </p>
            </div>
                    <h1><b>Method for Mixed-Particle Classification Based on Convolutional Neural Network</b></h1>
                    <h2>
                    <span>Cai Yang</span>
                    <span>Su Mingxu</span>
                    <span>Cai Xiaoshu</span>
            </h2>
                    <h2>
                    <span>School of Energy and Power Engineering, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional methods for mixed-particle classification usually extract particle features from binary images. After designing appropriate features according to the particle type, particles can be classified using widely known classifiers, such as back-propagation neural network and support vector machine (SVM) . However, classifying touching particles is a challenging, and inappropriate feature design may further reduce the classification accuracy. Herein, a convolutional neural network (CNN) is utilized to extract the features for building mixed-particle image classifiers. In particular, particle locations in an image are determined using a region proposal network. Furthermore, a classifier is designed and combined with a fully convolutional network to achieve pixel-level particle segmentation. Experimental analysis is performed on some flowing-mixed-particle systems comprising spherical, elongated, and irregular particles. According to the analysis results, SVM method using manually designed features can achieve an average precision of 87% and recall of 87%, whereas those of the CNN-based method are up to 97% and 93%, respectively. The latter method can also reduce the analysis error by more than 11% for number median diameter (Dn<sub>50</sub>) of irregular particles. In addition, several shortcomings in traditional methods, such as the need for manually designed features are solved, making it easier to build an end-to-end system for effective real-time image analysis of flowing mixed particles.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=measurement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">measurement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=particle%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">particle classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20vector%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support vector machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="68" name="68" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="69">颗粒特性研究在工业生产及环境检测等方面具有非常重要的意义。混合颗粒系作为一种常见的颗粒存在体系, 其分析往往较单一颗粒系更为复杂, 对于具有一定形状或纹理特征的混合颗粒, 如何获取每种颗粒的粒径分布或形状信息至关重要。例如, 机械润滑系统中通常含有不同形状的磨损颗粒, 其特性可以间接反映机械运转状态, 对润滑油中的磨损颗粒进行分类可以更好地对机械进行摩擦诊断<citation id="208" type="reference"><link href="152" rel="bibliography" /><link href="154" rel="bibliography" /><link href="156" rel="bibliography" /><link href="158" rel="bibliography" /><link href="160" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。此外, 颗粒在团聚过程中会形成团聚颗粒和单个颗粒的混合颗粒系, 对其进行分类就可以得到颗粒系的团聚度, 进而对结晶过程中的晶体团聚和生长加以区分<citation id="209" type="reference"><link href="162" rel="bibliography" /><link href="164" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。在一些药品加工过程中, 可通过制作薄膜包衣来改善药物颗粒的性能, 而颗粒的团聚度会严重影响包衣的质量, 因此团聚度的获取具有重要意义<citation id="210" type="reference"><link href="166" rel="bibliography" /><link href="168" rel="bibliography" /><link href="170" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。在对颗粒系进行分析时, 经常会受到气泡和杂质颗粒的干扰, 从而严重影响了颗粒系特征分析的准确性。</p>
                </div>
                <div class="p1">
                    <p id="70">经典的混合颗粒分类问题依托于颗粒特征和分类器的设计, 而颗粒特征设计则建立在基本的图像处理算法上, 通过预处理去除图像噪声, 之后对图像进行二值化、图像形态学处理以及粘连颗粒分割, 进而提取颗粒特征, 形成一系列的特征描述子作为分类器的输入。通常分类器主要采用线性判别因子分析 (DFA) 或非线性神经网络以及支持向量机 (SVM) 等对不同类别的颗粒进行分类, 这种结合特征设计的混合颗粒分类过程作为先前主流的方法, 不少学者对此进行了研究<citation id="213" type="reference"><link href="172" rel="bibliography" /><link href="174" rel="bibliography" /><link href="176" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。Yuan等<citation id="211" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>根据颗粒的外轮廓建立了一种径向凹偏差特征描述子, 并结合线性判别分析 (LDA) 以及分类回归树 (CART) 等算法对磨损颗粒的分类问题进行了探究;Heisel等<citation id="212" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>通过建立颗粒的特征描述子, 并利用判别因子分析和人工神经网络方法对含有聚合晶体、单个晶体以及气泡的混合颗粒进行了对比研究。在其他的混合颗粒分类中, 同样有大量基于特征和分类器设计的研究方法<citation id="214" type="reference"><link href="178" rel="bibliography" /><link href="180" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>, 但此类方法的不足之处在于难以准确地提取颗粒特征。因为颗粒图像处理常常会受到光照、噪声、颗粒粘连等因素的影响。此外, 颗粒特征描述子也难以准确设计, 并会受到特征不足或特征冗余的干扰, 造成分类器欠拟合或过拟合, 大大降低了分类的准确率。卷积神经网络 (CNN) 是一种深度神经网络, 其完全自动的特征提取避免了人工特征设计的不确定性和繁杂性, 通过结合分类器以及与全卷积神经网络的融合, 可以实现分类和像素分割等任务<citation id="215" type="reference"><link href="182" rel="bibliography" /><link href="184" rel="bibliography" /><link href="186" rel="bibliography" /><link href="188" rel="bibliography" /><link href="190" rel="bibliography" /><link href="192" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>。目前, 鲜有对于混合颗粒的分类, 尤其是对颗粒进行像素级的分割应用的研究。</p>
                </div>
                <div class="p1">
                    <p id="71">本文首先介绍了混合颗粒分类的基本方法, 然后引入基于CNN的颗粒分类和分割方法, 对由球形、长条形颗粒以及非规则颗粒组成的三种混合颗粒样品进行循环流动实验, 同时对采集到的颗粒图像进行分类分析, 并结合颗粒的粒径分布以及长宽比特征对不同的分类方法进行对比研究。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag">2 混合颗粒分类的基本方法</h3>
                <div class="p1">
                    <p id="73">传统算法在对混合颗粒进行分析时, 主要考虑颗粒特征及分类器的设计, 常见分类器包括BP (back propagation) 神经网络以及SVM等。SVM是一种基于小样本学习的模式识别方法, 在保证正确分割正、负样本的前提下, 根据最大化支持向量到分割超平面的距离来分割正、负样本。对于颗粒特征设计, 则主要考虑如下两方面:选取不同类别间差距较大的特征, 以提高分类效果, 降低错分的概率;特征过多会增加计算的复杂度, 分类结果不易收敛, 分类效率降低。因此在保证正确分类的情况下, 应尽量减少特征数, 尤其是避免使用相似特征。两类特征描述子如表1所示, 类别1的颗粒尺寸有量纲, 当不同类别的颗粒尺寸相差较大时, 可考虑此类特征;当颗粒尺寸分布有交叉, 或涉及图像缩放等影响因素时, 可采用类别2的无量纲特征, 其主要描述颗粒的形状特征。</p>
                </div>
                <div class="area_img" id="74">
                                            <p class="img_tit">
                                                表1 颗粒的特征描述子
                                                    <br />
                                                Table 1 Feature descriptors of particles
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201907013_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 颗粒的特征描述子" src="Detail/GetImg?filename=images/GXXB201907013_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="76" name="76" class="anchor-tag">3 基于<i>CNN</i>的混合颗粒分类方法</h3>
                <h4 class="anchor-tag" id="77" name="77"><b>3.1 网络结构</b></h4>
                <div class="p1">
                    <p id="78">混合颗粒分类问题主要是指对图像中的每一颗粒进行定位、预测类别, 并提取每类颗粒的特征。利用Faster R-CNN<citation id="216" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>系列神经网络可以很好地完成目标的检测和识别, 但无法对目标进行分割。为了同时实现颗粒的精确分割, 笔者借鉴了Mask R-CNN<citation id="217" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>网络结构。混合颗粒分类的总体网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 混合颗粒分类的CNN结构" src="Detail/GetImg?filename=images/GXXB201907013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 混合颗粒分类的CNN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 CNN structure of mixed-particle classification</p>

                </div>
                <div class="p1">
                    <p id="80">采用ResNet-101<citation id="218" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>和FPN<citation id="219" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation> (feature pyramid network) 相结合的主干网络来提取混合颗粒的特征。ResNet-101是含有101个卷积层的深层网络结构, 可以更加准确地提取图像的特征, 而采用FPN结构则可提高对小目标的检测效果。一般顶部卷积层含有较大的感受野, 可以预测大目标, 而低层的卷积层含有较多的信息, 对小目标比较敏感。通过对顶层的卷积层进行上采样并与下层的卷积层进行融合, 就可以预测不同尺度的目标, 如图1的p2、p3、p4、p5和p6, 从而实现较大尺度范围的目标检测。此外, 用RPN网络搜索可能的目标区域, 然后在RPN预测的目标区域上, 利用ROIAlign<citation id="220" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>进行特征提取, 最终在特征图上展开3个分支, 分别用于颗粒二值图、类别和目标矩形框的预测。本实验使用了ROIAlign, 而非ROIPool<citation id="221" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, 这主要是因为后者会引入位置偏差, 从而影响颗粒的分割结果;而ROIAlign采用双线性插值的方法来消除位置偏差, 可使特征图更精确地对应原始图像的区域, 提高颗粒分割的准确度。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>3.2 网络结构优化</b></h4>
                <div class="p1">
                    <p id="82">考虑到混合颗粒的特征相对简单, 同时为了提高模型的预测效率, 对ResNet-101的conv3_x和conv4_x的结构配置进行调整, 如表2所示。</p>
                </div>
                <div class="p1">
                    <p id="83">Conv3_x中包含3个卷积块, 每块又有3个卷积层组成, 卷积核大小依次为1×1、3×3和1×1, 对应的卷积核数目分别128、128和512;类似地, conv4_x有20个卷积模块, 两者相对原始结构分别减少了1个和3个卷积块。为了防止模型出现过拟合, 笔者在最后的全连接层部分添加了dropout层来抑制颗粒的特征提取, 并选取阈值为0.5, 以防止模型训练时出现过拟合, 而在实际模型测试阶段则只保留全连接层。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit">表2 conv3_x和conv4_x的结构配置 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Structure configurations of conv3_x and conv4_x</p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td><br />Stage</td><td>Output size /<br /> (pixel×pixel) </td><td>Block structure</td><td>Block count</td></tr><tr><td><br />conv3_x</td><td>28×28</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd><mtd><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn></mtd><mtd><mn>1</mn><mn>2</mn><mn>8</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd><mtd><mn>5</mn><mn>1</mn><mn>2</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></td><td>3</td></tr><tr><td><br /><i>conv</i>4_<i>x</i></td><td>14×14</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd><mtd><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn></mtd><mtd><mn>2</mn><mn>5</mn><mn>6</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd><mtd><mn>1</mn><mn>0</mn><mn>2</mn><mn>4</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></td><td>20</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>3.3 RPN网络和FCN网络</b></h4>
                <div class="p1">
                    <p id="86">RPN网络主要用于生成目标建议框的集合, 通过定义不同尺寸的滑动窗, 在原图上映射得到不同的候选区域, 通过分类层输出候选区的得分来确定区域为目标还是背景, 并对锚框 (anchor) 的位置和尺寸进行精调, 最终获得目标建议框, 如图2所示。</p>
                </div>
                <div class="p1">
                    <p id="87">由于在主干网络上得到了不同尺度的特征层, 所以对不同层的特征图定义不同尺寸的锚框, 锚框有3种不同的比例:1\:1、1\:2和2\:1。此外, 如果最终的锚框互相重叠, 则保留前景分数最高者, 并通过非极大值抑制法过滤其余锚框。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 RPN网络结构。" src="Detail/GetImg?filename=images/GXXB201907013_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 RPN网络结构。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 RPN network structure. </p>
                                <p class="img_note"> (a) 锚框尺度设置; (b) 锚框比例设置</p>
                                <p class="img_note"> (a) Anchor frame scale setting; (b) anchor frame ratio setting</p>

                </div>
                <div class="p1">
                    <p id="89">通过RPN网络可初步确定目标框的位置, 但并不能判定物体的类别。为此, 在通过RPN获得感兴趣区域 (ROI) 的基础上, 利用分类器进一步判定ROI中的物体类别, 并通过回归器进一步精调边框的位置和尺寸。除了对ROI内目标进行分类和边界框回归外, 笔者将全卷积网络<citation id="222" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation> (FCN) 用于颗粒二值化图像的预测上。FCN主要对ROI分类器的前景目标进行反卷积, 使其恢复到原始尺寸, 进而获取颗粒的二值化图像。将主干网络划分为多个具有不同分辨率的特征层, 因此不同的ROI和特征层间存在一个对应关系:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mo>=</mo><mo stretchy="false">[</mo><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><msqrt><mrow><mi>w</mi><mi>h</mi></mrow></msqrt><mo>/</mo><mn>2</mn><mn>2</mn><mn>4</mn><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">式中:<i>K</i><sub>0</sub>为基准值;<i>w</i>和<i>h</i>分别为ROI区域的宽和高。由此可以通过ROI的尺寸决定所采用的特征层。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>3.4 Loss函数</b></h4>
                <div class="p1">
                    <p id="93">总体的损失函数<i>L</i>由3部分组成, 即分类损失 (<i>L</i><sub>cls</sub>) 、边界框的回归损失 (<i>L</i><sub>box</sub>) 和二值图的分割损失 (<i>L</i><sub>mask</sub>) :</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub><mo>+</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>x</mtext></mrow></msub><mo>+</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>a</mtext><mtext>s</mtext><mtext>k</mtext></mrow></msub><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中<i>L</i><sub>cls</sub>和<i>L</i><sub>box</sub>的定义与Faster R-CNN相同, 即</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>l</mtext><mtext>s</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">[</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>x</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>t</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>=</mo><mi>R</mi><mo stretchy="false"> (</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>t</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>0</mn><mo>.</mo><mn>5</mn><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo></mtd><mtd columnalign="left"><mtext>i</mtext><mtext>f</mtext><mspace width="0.25em" /><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">|</mo><mo>&lt;</mo><mn>1</mn></mtd></mtr><mtr><mtd columnalign="left"><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">|</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>, </mo></mtd><mtd columnalign="left"><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext><mtext>w</mtext><mtext>i</mtext><mtext>s</mtext><mtext>e</mtext></mtd></mtr></mtable></mrow></mrow><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">式中:<i>p</i><sub><i>i</i></sub>表示锚框为第<i>i</i>类的概率, 若锚框的标签为正, 则<i>p</i><sup>*</sup><sub>i</sub>=1, 否则置0;<i>t</i><sub><i>i</i></sub>为预测目标边界框的4个参数化坐标;<i>t</i><sup>*</sup><sub><i>i</i></sub>为真正目标区域边界框的坐标向量。对于二值图像预测的分支, 其在每个ROI上会输出<i>k</i>个分辨率为<i>m</i>×<i>m</i>的二值图像 (<i>k</i>为类别数) , 通过对每一个像素应用sigmoid函数, 然后取ROI上所有像素的交叉熵平均值为<i>L</i><sub>mask</sub>, 对于一个属于第<i>k</i>个类别的ROI, <i>L</i><sub>mask</sub>仅仅考虑第<i>k</i>个二值图, 所以允许对每个类别都生成二值图, 并且不会存在类间竞争。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>3.5 算法流程及参数优化</b></h4>
                <div class="p1">
                    <p id="99">混合颗粒分类的算法流程如图3所示, 训练集图像由修改后的ResNet-101和FPN进行特征提取, 通过RPN网络获取颗粒的目标框, 然后利用ROIAlign进行特征池化, 最后计算总体的损失, 训练至最大迭代次数时结束。考虑到相机采集的图像太大, 为了加快训练和测试速度, 在不影响颗粒分辨率的情况下, 统一将图像缩放至612 pixel×512 pixel, 同时每张图像中用于分类的锚框上限定为500 (一般情况下颗粒的分布密度均低于此数值) 。另外, 为了防止最终的目标候选框太多, 进行非极大值抑制, 并将阈值设为0.7。对学习率进行分析, 较小的学习率往往使得模型的收敛缓慢, 甚至难以收敛, 而当学习率过大时, 模型通常会陷入局部最优解, 或者出现无解的情况, 分别将学习率设为0.0001、0.001、0.01以及0.1进行了模型测试, 发现当学习率为0.001时模型的收敛效果最好。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 混合颗粒的分类算法流程" src="Detail/GetImg?filename=images/GXXB201907013_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 混合颗粒的分类算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Flow chart of mixed-particle classification algorithm</p>

                </div>
                <h3 id="102" name="102" class="anchor-tag">4 实验及结果分析</h3>
                <div class="p1">
                    <p id="103">为了探讨CNN混合颗粒分类法的效果, 设计了相应的混合颗粒循环流动系统, 并进行了实验研究。实验中采用的混合颗粒由球形颗粒、长条形颗粒和非规则颗粒组成, 如图4所示。</p>
                </div>
                <div class="p1">
                    <p id="104">为对后续的分类结果进行定量分析, 定义精确率 (<i>R</i><sub>precision</sub>) 和召回率 (<i>R</i><sub>recall</sub>) 为</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>u</mtext><mtext>e</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext><mtext>d</mtext><mtext>i</mtext><mtext>c</mtext><mtext>t</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>u</mtext><mtext>e</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">式中:<i>N</i><sub>true</sub>为预测正确的颗粒数;<i>N</i><sub>predict</sub>为所有检出的颗粒数;<i>N</i><sub>all</sub>为图像中的总颗粒数, 包括未检出的颗粒数。由 (6) 式和 (7) 式可知, 精确率反映了模型的分类效果, 而召回率则综合考虑了模型的分类效果和漏检情况。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同类型的颗粒。" src="Detail/GetImg?filename=images/GXXB201907013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同类型的颗粒。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Examples of different types of particles.</p>
                                <p class="img_note"> (a) 球形颗粒; (b) 长条形颗粒; (c) 非规则颗粒</p>
                                <p class="img_note"> (a) Spherical particles; (b) elongated particles; (c) irregular particles</p>

                </div>
                <h4 class="anchor-tag" id="108" name="108"><b>4.1 实验装置</b></h4>
                <div class="p1">
                    <p id="109">设计了如图5所示的实验装置来获得混合颗粒的动态图像, 硬件包括CCD相机、可调光强的卤素灯、光纤、蠕动泵, 以及用于流动观测的样品池和存储颗粒图像的计算机。采用GS3-U3-50S5M-C工业相机, 其传感器靶面的尺寸为8.8 mm×6.6 mm, 配置了2倍的放大镜头。实验中, 相机和光源均采用背光式布置, 即相机和光源位于同一水平轴的样品池两侧, 混合颗粒样品事先置于盛有蒸馏水的烧杯中, 并通过蠕动泵实现循环流动, CCD相机对样品池测量区进行实时拍摄, 混合颗粒图像保存于计算机中用于后续数据集处理。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 混合颗粒测量系统" src="Detail/GetImg?filename=images/GXXB201907013_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 混合颗粒测量系统  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Measuring system of mixed particles</p>

                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>4.2 数据集预处理</b></h4>
                <div class="p1">
                    <p id="112">通过上述实验装置实时采集混合颗粒的图像, 并根据模型参数测试需要, 选择400张用于后续的训练与分析, 其中训练集为300张图片, 测试集为100张图片。在CNN方法中, 需要获得颗粒的二值图像, 并标注每张图片中的颗粒类别。而在SVM法中, 要在二值图像的基础上提取颗粒特征, 并标注颗粒类别。为此, 对所有图片均作如图6所示的处理。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 图像处理流程" src="Detail/GetImg?filename=images/GXXB201907013_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 图像处理流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Flow chart of image processing</p>

                </div>
                <div class="p1">
                    <p id="114">如图6所示, 对于采集到的图像, 首先利用维纳滤波消除图像中的干扰噪声, 然后进行二值化处理。常用的二值化方法为最大类间方差 (OTSU) 法<citation id="223" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>, 它是基于全局最优阈值的方法, 但对于光照背景不均匀情形的处理效果很差, 因此本实验主要采用自适应阈值分割方法, 通过高斯滤波窗口获取每个窗口的背景阈值, 然后根据局部阈值实现颗粒图像的二值化, 即:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>W</mtext></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mtext>m</mtext></msub><mo>&lt;</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>a</mtext><mtext>u</mtext><mtext>s</mtext><mtext>s</mtext></mrow></msub><mo>×</mo><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mi>t</mi><mrow><mn>1</mn><mn>0</mn><mn>0</mn></mrow></mfrac></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">式中:<b><i>I</i></b><sub>BW</sub>为最终的二值矩阵;“&lt;”为图像矩阵对应元素的逻辑运算, 即逻辑为真对应于1, 相反则为0;<b><i>I</i></b><sub>m</sub>为颗粒图像的灰度矩阵;<i>t</i>为区分前景和背景的局部阈值, 可在-20和20之间取值, 根据实验, 本文取<i>t</i>=15;<b><i>I</i></b><sub>Gauss</sub>为对<b><i>I</i></b><sub>m</sub>进行高斯滤波后的图像矩阵。高斯滤波方形窗口的尺寸为</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>i</mtext><mtext>z</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mtext>f</mtext><mtext>l</mtext><mtext>o</mtext><mtext>o</mtext><mtext>r</mtext><mrow><mo>[</mo><mrow><mfrac><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>e</mtext><mtext>n</mtext><mtext>g</mtext><mtext>t</mtext><mtext>h</mtext></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mtext>m</mtext></msub><mo stretchy="false">) </mo></mrow><mrow><mn>2</mn><mn>0</mn></mrow></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">式中:<i>f</i><sub>size</sub>为滤波窗口的尺寸;<i>f</i><sub>length</sub> (<b><i>I</i></b><sub>m</sub>) 为求图像短边长度的函数式;floor (·) 为向下取整函数。还需要对获得的二值图像进行孔洞填充, 以及用分水岭 (watershed) 算法<citation id="224" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>对粘连颗粒进行分割等操作。由于分水岭算法并不能实现对颗粒的完全分割, 所以需要采用精细的手动分割操作, 以得到相对精确的颗粒二值图像。如图7所示, 二值图采用彩色标记图的形式表示, 在此基础上进行特征提取和颗粒类别标注, 鉴于实验中三类颗粒的尺寸分布较宽且有交叉, 这里主要选取表1中的类别2特征进行SVM的训练和测试。</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同方法处理后混合颗粒的图像。" src="Detail/GetImg?filename=images/GXXB201907013_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同方法处理后混合颗粒的图像。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Images of mixed particles processed by different methods. </p>
                                <p class="img_note"> (a) 混合颗粒; (b) 维纳滤波; (c) 二值化和孔洞填充; (d) watershed分割; (e) 手动精分割</p>
                                <p class="img_note"> (a) Mixed particles; (b) Wiener filtering; (c) binarization and hole filling; (d) watershed segmentation; (e) manually fine segmentation</p>

                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>4.3 结果分析</b></h4>
                <div class="p1">
                    <p id="121">根据训练集数据对模型进行训练, 分析基于SVM法和CNN的混合颗粒分类方法, 从颗粒分类准确度和颗粒特征分布两方面对结果进行评估。针对粘连颗粒, 同时探究分水岭法和手动分割方法对SVM法分类的影响。对测试集进行分析得到如图8所示的颗粒数目分布, 其中SVM_1表示特征提取时采用人工分割方式, SVM_2则表示利用分水岭算法分割粘连颗粒。对比三类颗粒总数后可知, CNN法得到的颗粒总数相对偏少, SVM_2则偏多, 这是因为CNN法需要搜索颗粒的位置, 存在漏检情况。此外, SVM_2存在过分割现象, 尤其是对于长条形颗粒, 会造成非规则颗粒数目增长。相比之下, CNN和SVM_1预测的三类颗粒数目的占比都比较接近实际值。此外, 对不同分类方法的精确率和召回率进行对比, 如图9所示, 其中纵坐标为小于当前准确率的图片数量占测试集图片数量的比例。对于SVM_1法, 由于其采用手动分割的二值图像, 所以<i>N</i><sub>predict</sub>和<i>N</i><sub>all</sub>相等, 精确率和召回率也相等。对于测试数据集, 通过计算不同分类方法下所有测试图片的精确率和召回率, 可以得到SVM_1法的平均精确率和召回率均为87%, 而CNN法则分别为97%和93%。从图9可以看出CNN法的精确率和召回率都高于SVM_1法, 而根据图8中预测的颗粒数分布, SVM_1法比CNN法更接近实际值, 表明SVM_1法存在较高的误检率。对比CNN法的精确率和召回率可以发现, 精确率明显高于召回率, 这是因为CNN法在保持较高分类精确率的同时, 也存在一定的漏检现象, 但从总体看, CNN法具有更高的测量准确率。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同分类方法得到的颗粒计数结果" src="Detail/GetImg?filename=images/GXXB201907013_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同分类方法得到的颗粒计数结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Particle counting results obtained by different classification methods</p>

                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同分类方法的检测准确率" src="Detail/GetImg?filename=images/GXXB201907013_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同分类方法的检测准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Detection accuracy of different classification methods</p>

                </div>
                <div class="p1">
                    <p id="124">除了混合颗粒的数目分布关系外, 颗粒的粒径分布也是描述混合颗粒的重要参数。通常混合颗粒的总体粒径分布难以反映每种颗粒的特性, 为此, 在分类基础上同时探究每种颗粒的粒径分布, 如图10所示, 采用CNN、SVM_1、SVM_2模型分别得到每种颗粒粒径的累积分布, 并与实际值进行对比。图10纵坐标为小于当前粒径的颗粒数量占测试颗粒总数的比例, 可见, 这三类颗粒的粒径分布曲线存在明显的交叉, 即仅仅通过粒径难以对混合颗粒的类别进行区分。对于球形颗粒, 三种模型预测的粒径分布类似, 大部分颗粒的粒径略小于实际值, 但是偏差均在5 μm以内, 如表3所示 (<i>D</i><sub>n10</sub>、<i>D</i><sub>n50</sub>、<i>D</i><sub>n90</sub>分别表示颗粒数目累积概率达到10%、50%、90%时对应的颗粒粒径) 。可见:虽然两种SVM法获得的<i>D</i><sub>n90</sub>都优于CNN法, 但由粒径分布可发现其远偏离实际情况;对于SVM_1和SVM_2法, 存在一部分超越实际最大值的颗粒粒径, 这是由其他两种形状的大颗粒被误检为球形颗粒导致的;相比于非规则颗粒和长条形颗粒, CNN法得到的粒径分布均与实际值比较吻合, 而SVM_1和SVM_2法得到的粒径都小于实际值, 尤其是非规则颗粒, 从表3可以发现, 这两种方法得到的<i>D</i><sub>n50</sub>和实际值的误差均超过11%, 由此可知其对非规则颗粒具有较大的误检率。对比SVM_1法和SVM_2法可以发现, SVM_2法对长条形和非规则颗粒分析得到的结果小于SVM_1, 主要表现在<i>D</i><sub>n50</sub>以下的粒径分布, 部分可达5 μm以上的差别。由于SVM_2采用分水岭法的颗粒分割方式, 与人工分割相比, 会存在一定的过分割误差, 部分非规则颗粒和长条形颗粒会被分割成小颗粒, 从而使得粒径较小的非规则颗粒和长条形颗粒增多, 进而使得<i>D</i><sub>n50</sub>以下的曲线向左偏移。此外, 表3中还列出了利用BP神经网络得到的粒径结果, 它采用与SVM_1相同的特征输入, 对比三类颗粒的特征粒径可以发现其准确率远不如SVM_1, 存在较大的分类误差。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同分类方法得到的颗粒的当量直径累积分布" src="Detail/GetImg?filename=images/GXXB201907013_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 不同分类方法得到的颗粒的当量直径累积分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Cumulative distributions of equivalent diameters of particles obtained by different classification methods</p>

                </div>
                <div class="area_img" id="126">
                                            <p class="img_tit">
                                                表3 不同分类方法得到的颗粒的测量尺寸
                                                    <br />
                                                Table 3 Particle sizes measured by different classification methods
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/GXXB201907013_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 不同分类方法得到的颗粒的测量尺寸" src="Detail/GetImg?filename=images/GXXB201907013_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="127">由上述的分析可以发现, 除了CNN法, 其他两种方法均存在较明显的粒径分析误差, 同时也会影响颗粒的形状参数, 如图11～13所示。CNN法得到的三种颗粒的长宽比分布都接近于实际分布。对于长条形颗粒, SVM_1法得到的长宽比偏大, 因为较小长宽比的长条形颗粒可能会被错分成非规则颗粒, 从而使得SVM_1法预测的长条形颗粒均保持在较高的长宽比水平。这实际也反映了基于特征设计法的颗粒分类模型的一个弊端, 即当不同类型的颗粒特征存在交叉时, 就容易产生一定的误差, 尤其是当颗粒的特征非常相似时。这同样体现在非规则颗粒的长宽比分布上, 由图13可以发现SVM_1法基本上没有得到长宽比大于2的颗粒, 因为长宽比较高的非规则颗粒会被误检为长条形颗粒。相比之下, SVM_2法受到颗粒过分割的影响, 长宽比分布会产生一个向左的偏移, 导致其更加接近实际分布, 但是根据前述得到的数目分布和粒径分布结果, SVM_2法的结果与实际值的偏离程度最大, 由此也可以发现混合颗粒的表征需要综合多方面的特征信息, 单一的特征表述会造成混合颗粒分析的偏差。值得注意的是, 实验中存在一些处于图像边界的球形颗粒, 所以其长宽比会比正常的球形颗粒大, 但这依然没有影响CNN法的检测效果, 反而在SVM_1法中, 其会被归为其他的类别, 从图12可以发现, SVM_1法未能检测出部分长宽比较大的球形颗粒。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 不同分类方法得到的长条形颗粒的长宽比累积分布" src="Detail/GetImg?filename=images/GXXB201907013_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 不同分类方法得到的长条形颗粒的长宽比累积分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Cumulative distributions of aspect ratios for elongated particles obtained by different classification methods</p>

                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 不同分类方法得到的球形颗粒的长宽比累积分布" src="Detail/GetImg?filename=images/GXXB201907013_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 不同分类方法得到的球形颗粒的长宽比累积分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 Cumulative distributions of aspect ratios for spherical particles obtained by different classification methods</p>

                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201907013_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 不同分类方法得到的非规则颗粒的长宽比累积分布" src="Detail/GetImg?filename=images/GXXB201907013_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 不同分类方法得到的非规则颗粒的长宽比累积分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201907013_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 13 Cumulative distributions of aspect ratios for irregular particles obtained by different classification methods</p>

                </div>
                <div class="p1">
                    <p id="131">综合上述分析可以发现, CNN法从颗粒分类的准确率、颗粒粒径分布和长宽比分布几个方面均表现出优于SVM_1法和SVM_2法的效果, 其中SVM_2法仅仅因为粘连分割的问题, 就出现了比SVM_1法更高的误检率, 而实际中SVM法还会受到光照和噪声等因素的干扰, 从而在连续分析中积累更多的误差。相比之下, CNN法对流动颗粒的分析上具有更多优势, 其优异的特征表达能力比人工特征设计更加准确, 并且受上述因素的干扰较小, 可以同时兼顾颗粒的局部和全局特征。</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="133">研究了图像法中混合颗粒的模式识别问题, 在传统的基于人工特征设计的SVM法基础上, 引入基于CNN法的混合颗粒分类方法, 通过实验得到了球形、非规则和长条形混合颗粒的流动图像, 建立了相应的训练数据集和测试数据集, 同时从数目分布、分类准确率以及颗粒的粒径、长宽比等方面进行了对比分析。</p>
                </div>
                <div class="p1">
                    <p id="134">首先建立了两类颗粒特征描述子, 并利用无量纲的描述子作为SVM法的特征向量, 同时根据粘连颗粒的分割方式建立了SVM_1法和SVM_2法, 结果发现SVM_1法比SVM_2法获得了更好的分类结果, 说明SVM法的准确率依赖于准确的特征提取, 而在分析混合颗粒时会受到光照和噪声的干扰, 分类误差甚至大于SVM_2法。混合颗粒的表征需要结合多方面特征, 对于分类模型评估也不能根据单一特征的分布决定其好坏, 综合颗粒数目分布、分类准确率、粒径分布和长宽比分布特征建立更加有效的分析模型, 形成了相对全面的混合颗粒特征, 避免了采用单一特征造成的偏差。此外, 基于CNN法的混合颗粒分析模型的各个特征分析结果均优于SVM法, 可更全面准确地分析混合颗粒;同时, CNN法无需进行人工特征设计, 并有效克服了图像中粘连颗粒等的干扰, 形成了相对准确的端对端混合颗粒分析系统。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="152">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9E6378840092EA9F2F3E3B639B90F922&amp;v=MTg1MjRTdzNrcnh0SGNMTGlUTGlkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJyTkdOTExwNGRCWk9zR0RnbEl4bUFSbkR3SQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Yuan W, Chin K S, Hua M, et al.Shape classification of wear particles by image boundary analysis using machine learning algorithms[J].Mechanical Systems and Signal Processing, 2016, 72/73:346-358.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8F528596613B13CD61D468C2BDC88F35&amp;v=MjgyNzlScm1CQkNycWNNN21hQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJ2T0c5UEVxb1pEWXVvTWZuMDZ2R0lWNjB0NVRuZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Peng Y P, Wu T H, Cao G Z, et al.A hybrid search-tree discriminant technique for multivariate wear debris classification[J].Wear, 2017, 392/393:152-158.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101075799&amp;v=MTAwMzlRVE1ud1plWnVIeWptVWIvSUlWc1NiaEU9TmlmT2ZiSzdIdERPcm85RVpPd0tDM1V3b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Stachowiak G P, Stachowiak G W, Podsiadlo P.Automated classification of wear particles based on their surface texture and shape features[J].Tribology International, 2008, 41 (1) :34-43.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HKXS201805001&amp;v=MzIwNDk5bk1xbzlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnluZ1ZidkxMU2JUZmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Hong W, Cai W J, Wang S P, et al.Mechanical wear debris feature, detection, and diagnosis:a review[J].Chinese Journal of Aeronautics, 2018, 31 (5) :867-882.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101076293&amp;v=MTM4OTFKRG5VNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWIvSUlWc1NiaEU9TmlmT2ZiSzdIdERPcm85RVpPdw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Raadnui S.Wear particle analysis:utilization of quantitative computer image analysis:a review[J].Tribology International, 2005, 38 (10) :871-878.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15120600488839&amp;v=MjYzNjhIeWptVWIvSUlWc1NiaEU9TmlmT2ZiSzlIOVBNcVk5RllPTUhCSDh3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Terdenge L M, Heisel S, Schembecker G, et al.Agglomeration degree distribution as quality criterion to evaluate crystalline products[J].Chemical Engineering Science, 2015, 133:157-169.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1452B57101C7A994C3C334A91F2B6CBD&amp;v=MjMwNjdIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2ZiSzhHOU8rcW9oRVpPcDhDdzB3eGhKZzZVeCtTM3VUcFJORGU4Q1NOc2pyQ09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Heisel S, Kovaevi.Variable selection and training set design for particle classification using a linear and a non-linear classifier[J].Chemical Engineering Science, 2017, 173:131-144.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES29637EAA7C5173375C13457529D1B3C4&amp;v=MjU5MjNHUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJHeEdOTEwydjQwWTVnS0RYczZ6QkVXbVQ1K1RIcmxxUkE4RGJQbVJzbWJDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Mehle A, Kitak D, Podrekar G, et al.In-line agglomeration degree estimation in fluidized bed pellet coating processes using visual imaging[J].International Journal of Pharmaceutics, 2018, 546 (1/2) :78-85.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Agglomeration Detection by Acoustic Emission (AE) Sensors in Fluidized Beds">

                                <b>[9]</b> Wang J D, Cao Y J, Jiang X J, et al.Agglomeration detection by acoustic emission (AE) sensors in fluidized beds[J].Industrial &amp; Engineering Chemistry Research, 2009, 48 (7) :3466-3473.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300224849&amp;v=MzA5OTN5am1VYi9JSVZzU2JoRT1OaWZPZmJLOUg5UE9ySTlGWnVrTEJIZ3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Sheahan T, Briens L.Passive acoustic emissions monitoring of the coating of pellets in a fluidized bed:a feasibility analysis[J].Powder Technology, 2015, 283:373-379.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES513B14B74B124F38F0DEECC2F52CB25C&amp;v=MTM3NjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJhNUhhUE5xLzFDWUprT0RuaFB6QjVsNmtzSVBReVJybVF3ZThIbVI3L3NDT052RlNpV1dyNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Iacoviello F, Iacoviello D, di Cocco V, et al.Classification of ductile cast iron specimens based on image analysis and support vector machine[J].Procedia Structural Integrity, 2017, 3:283-290.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Application of machine vision for classification of soil aggregate size">

                                <b>[12]</b> Ajdadi F R, Gilandeh Y A, Mollazade K, et al.Application of machine vision for classification of soil aggregate size[J].Soil and Tillage Research, 2016, 162:8-17.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012101076057&amp;v=MDM5NTZybzlFWk93SkRIaytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVnNTYmhFPU5pZk9mYks3SHRETw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Stachowiak G W, Podsiadlo P.Towards the development of an automated wear particle classification system[J].Tribology International, 2006, 39 (12) :1615-1623.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7C81DAF3D6F7DB21D11543FC1E36FFE2&amp;v=MTA4NjRGdEM0M3ZsR0VPMTVDd2hMelJkbjZ6NTRUSHlVM3hOQWVyVGlNOCtkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZmJUTA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Zhang Y, Liu J J, Zhang L, et al.Particle shape characterisation and classification using automated microscopy and shape descriptors in batch manufacture of particulate solids[J].Particuology, 2016, 24:61-68.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700171522&amp;v=MDY5NDhxSTlGWmV3T0NYNDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lJVnNTYmhFPU5pZk9mYks4SDlETQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Lee H, Chen Y P P.Cell morphology based classification for red cells in blood smear images[J].Pattern Recognition Letters, 2014, 49:155-161.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES540D466ABDC3F0EF30798A28A2660F22&amp;v=MDU4ODhOaWZPZmJhOEhxWElxWWswRnA5OER3bzV1bUFRNmpoMFFBN2dwR00zZjdTVU03aWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4YjI1eEtzPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Calderon C P, Daniels A L, Randolph T W.Deep convolutional neural network analysis of flow imaging microscopy data to classify subvisible particles in protein formulations[J].Journal of Pharmaceutical Sciences, 2018, 107 (4) :999-1008.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3D682109FD207436FF21076D3AF7EE75&amp;v=MTY1NjViRE1HTm5Pcm85TUVwOE5ESHM5ekJCbG5EMThTSGprMkJGRUQ3WGhNTDJhQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeGIyNXhLcz1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Chaves D, Fernández-Robles L, Bernal J, et al.Automatic characterisation of chars from the combustion of pulverised coals using machine vision[J].Powder Technology, 2018, 338:110-118.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4CA015BECF2CC4750F6554B8BD8DC0E7&amp;v=MDU2Nzh1SFlmT0dRbGZDcGJRMzVkaGh4YjI1eEtzPU5pZk9mYmZMYjlITnF2MHdGNTBOZnc4OXlCTVRuRGw0VFh1UXBHQkJjY2JuUmMrWUNPTnZGU2lXV3I3SklGcG1hQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Vogado L H S, Veras R M S, Araujo F H D, et al.Leukemia diagnosis in blood slides using transfer learning in CNNs and SVM for classification[J].Engineering Applications of Artificial Intelligence, 2018, 72:415-422.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES25626B23E743F7434F86D45B404FB4D3&amp;v=MjQyMzNoWTFmY1RtUWM2Y0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhiMjV4S3M9TmlmT2ZiRzlHTlBLM1kxR0Vld0xEd28reXhVWG5EZDdQSHZuMw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Raitoharju J, Riabchenko E, Ahmad I, et al.Benchmark database for fine-grained image classification of benthic macroinvertebrates[J].Image and Vision Computing, 2018, 78:73-83.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806034&amp;v=MTAzNTVxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmdWYnZMSWpYVGJMRzRIOW5NcVk5R1lJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> Feng X Y, Mei W, Hu D S.Aerial target detection based on improved faster R-CNN[J].Acta Optica Sinica, 2018, 38 (6) :0615004.冯小雨, 梅卫, 胡大帅.基于改进Faster R-CNN的空中目标检测[J].光学学报, 2018, 38 (6) :0615004.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201806036&amp;v=MTAxMjllVnVGeW5nVmJ2TElqWFRiTEc0SDluTXFZOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Du J, Hu B L, Zhang Z F.Gastric carcinoma classification based on convolutional neural network and micro-hyperspectral imaging[J].Acta Optica Sinica, 2018, 38 (6) :0617001.杜剑, 胡炳樑, 张周锋.基于卷积神经网络与显微高光谱的胃癌组织分类方法研究[J].光学学报, 2018, 38 (6) :0617001.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 Ren S Q, He K M, Girshick R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (6) :1137-1149.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mask R-CNN">

                                <b>[23]</b> He K M, Gkioxari G, Dollár P, et al.Mask R-CNN[C]//2017 IEEE International Conference on Computer Vision (ICCV) , October 22-29, 2017, Venice, Italy.New York:IEEE, 2017:2980-2988.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_24" >
                                    <b>[24]</b>
                                 He K M, Zhang X Y, Ren S Q, et al.Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 27-30, 2016, Las Vegas, NV, USA.New York:IEEE, 2016:770-778.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature pyramid networks for object detection">

                                <b>[25]</b> Lin T Y, Dollár P, Girshick R, et al.Feature pyramid networks for object detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 21-26, 2017, Honolulu, HI, USA.New York:IEEE, 2017:936-944
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[26]</b> Shelhamer E, Long J, Darrell T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (4) :640-651.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Review on Otsu Image Segmentation Algorithm">

                                <b>[27]</b> Vala H J, Baxi A.A review on Otsu image segmentation algorithm [J].International Journal of Advanced Research in Computer Engineering &amp; Technology, 2013, 2 (2) :387-389.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Watersheds in digital spaces: An efficient algorithm based on immersion simulations">

                                <b>[28]</b> Vincent L, Soille P.Watersheds in digital spaces:an efficient algorithm based on immersion simulations[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1991, 13 (6) :583-598.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201907013" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201907013&amp;v=MTQxMzZxQnRHRnJDVVJMT2VaZVZ1RnluZ1ZidkxJalhUYkxHNEg5ak1xSTlFWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

