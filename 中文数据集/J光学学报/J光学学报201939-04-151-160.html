

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134116300127500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201904018%26RESULT%3d1%26SIGN%3dIspqsZQXKWmofa9icgJxGaaKZTM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201904018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904018&amp;v=MjQxMDJDVVJMT2VaZVZ1Rnk3aFVickJJalhUYkxHNEg5ak1xNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="2 基本原理 ">2 基本原理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="&lt;b&gt;2.1 连通平面区域的提取&lt;/b&gt;"><b>2.1 连通平面区域的提取</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;2.2 平面区域的合并&lt;/b&gt;"><b>2.2 平面区域的合并</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.3 弱连接断裂修正&lt;/b&gt;"><b>2.3 弱连接断裂修正</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="&lt;b&gt;3.1 数据集介绍&lt;/b&gt;"><b>3.1 数据集介绍</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;3.2 算法参数设置&lt;/b&gt;"><b>3.2 算法参数设置</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;3.3 结果分析&lt;/b&gt;"><b>3.3 结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="4 结 论 ">4 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="图1 两种算法的分割结果。 (a) 三维点云 (俯视图) ; (b) 原始RANSAC算法分割结果; (c) 算法改进后的分割结果">图1 两种算法的分割结果。 (a) 三维点云 (俯视图) ; (b) 原始RANSAC算法分割结果;......</a></li>
                                                <li><a href="#66" data-title="图2 区域合并前后的结果。 (a) 连通平面区域; (b) “胶水”算法合并后的结果">图2 区域合并前后的结果。 (a) 连通平面区域; (b) “胶水”算法合并后的结果</a></li>
                                                <li><a href="#75" data-title="图3 所提算法处理的中间结果。 (a) 连通平面区域; (b) “胶水”算法的合并结果; (c) 红色连通区域对应的二值图像; (d) 腐蚀后的二值图像; (e) 最终的分割结果">图3 所提算法处理的中间结果。 (a) 连通平面区域; (b) “胶水”算法的合并结果; (c) 红......</a></li>
                                                <li><a href="#76" data-title="图4 板型物体与数据采集平台。 (a) 6种板型物体; (b) 简单型场景; (c) 复杂型场景">图4 板型物体与数据采集平台。 (a) 6种板型物体; (b) 简单型场景; (c) 复杂型场景</a></li>
                                                <li><a href="#77" data-title="图5 深度图与对应的三维点云示例。 (a) 深度图; (b) 三维点云 (俯视图) ; (c) 放大的三维点云">图5 深度图与对应的三维点云示例。 (a) 深度图; (b) 三维点云 (俯视图) ; (c) 放大......</a></li>
                                                <li><a href="#78" data-title="表1 所提算法的参数设置">表1 所提算法的参数设置</a></li>
                                                <li><a href="#81" data-title="图6 4种算法的分割结果。 (a) 深度图; (b) Canny边缘算法; (c) &lt;i&gt;K&lt;/i&gt;-均值聚类算法; (d) RANSAC算法; (e) 区域生长算法">图6 4种算法的分割结果。 (a) 深度图; (b) Canny边缘算法; (c) <i>K</i>-均值聚类算法; (d) RANSAC算法; (e) 区域生长算法</a></li>
                                                <li><a href="#84" data-title="图7 原始深度图与标签图的对比。 (a) 原始深度图; (b) 真实标签 (灰度图) ; (c) 真实标签 (彩色图) ">图7 原始深度图与标签图的对比。 (a) 原始深度图; (b) 真实标签 (灰度图) ; (c) 真......</a></li>
                                                <li><a href="#85" data-title="表2 所提算法与区域生长算法在20个简单型及10个复杂型场景上的分割准确率">表2 所提算法与区域生长算法在20个简单型及10个复杂型场景上的分割准确率</a></li>
                                                <li><a href="#86" data-title="表3 所提算法与区域生长算法在20个简单型及10个复杂型场景上的平均时间成本">表3 所提算法与区域生长算法在20个简单型及10个复杂型场景上的平均时间成本</a></li>
                                                <li><a href="#87" data-title="图8 所提算法在20个简单型场景上的分割结果">图8 所提算法在20个简单型场景上的分割结果</a></li>
                                                <li><a href="#88" data-title="图9 两种算法在S6、S8、S15场景上的分割结果。 (a) 所提算法; (b) 区域生长算法">图9 两种算法在S6、S8、S15场景上的分割结果。 (a) 所提算法; (b) 区域生长算法</a></li>
                                                <li><a href="#89" data-title="图10 两种算法在10个复杂型场景上的分割结果。 (a) 所提算法; (b) 区域生长算法">图10 两种算法在10个复杂型场景上的分割结果。 (a) 所提算法; (b) 区域生长算法</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="9">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Otsu N.A threshold selection method from gray-level histograms[J].IEEE Transactions on Systems, Man, and Cybernetics, 1979, 9 (1) :62-66.</a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_2" title=" Adams R, Bischof L.Seeded region growing[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (6) :641-647." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Seeded region growing">
                                        <b>[2]</b>
                                         Adams R, Bischof L.Seeded region growing[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (6) :641-647.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_3" title=" Comaniciu D, Meer P.Mean shift:a robust approach toward feature space analysis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (5) :603-619." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mean Shift: A Robust Approach Toward Feature Space Analysis">
                                        <b>[3]</b>
                                         Comaniciu D, Meer P.Mean shift:a robust approach toward feature space analysis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (5) :603-619.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_4" title=" Kass M, Witkin A, Terzopoulos D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830144&amp;v=MDU0NjEzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RlNqbFZidktKVmM9Tmo3QmFyTzRIdEhPcDR4RlplOExZ&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Kass M, Witkin A, Terzopoulos D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Shi J B, Malik J.Normalized cuts and image segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (8) :888-905.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_6" title=" Felzenszwalb P F, Huttenlocher D P.Efficient graph-based image segmentation[J].International Journal of Computer Vision, 2004, 59 (2) :167-181." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830890&amp;v=MTMxMDd0RlNqbFZidktKVmM9Tmo3QmFyTzRIdEhPcDR4RmJPSVBZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVk&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Felzenszwalb P F, Huttenlocher D P.Efficient graph-based image segmentation[J].International Journal of Computer Vision, 2004, 59 (2) :167-181.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_7" title=" Trevor A J B, Gedikli S, Rusu R B, &lt;i&gt;et al&lt;/i&gt;.Efficient organized point cloud segmentation with connected components[C].Semantic Perception Mapping and Exploration, 2013:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient organized point cloud segmentation with connectedcomponents">
                                        <b>[7]</b>
                                         Trevor A J B, Gedikli S, Rusu R B, &lt;i&gt;et al&lt;/i&gt;.Efficient organized point cloud segmentation with connected components[C].Semantic Perception Mapping and Exploration, 2013:1-6.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_8" title=" Tian Q H, Bai R L, Li D.Point cloud segmentation of scattered workpieces based on improved euclidean clustering[J].Laser &amp;amp; Optoelectronics Progress, 2017, 54 (12) :121503.田青华, 白瑞林, 李杜.基于改进欧氏聚类的散乱工件点云分割[J].激光与光电子学进展, 2017, 54 (12) :121503." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201712039&amp;v=Mjc1MzJGeTdoVWJyQkx5clBaTEc0SDliTnJZOUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Tian Q H, Bai R L, Li D.Point cloud segmentation of scattered workpieces based on improved euclidean clustering[J].Laser &amp;amp; Optoelectronics Progress, 2017, 54 (12) :121503.田青华, 白瑞林, 李杜.基于改进欧氏聚类的散乱工件点云分割[J].激光与光电子学进展, 2017, 54 (12) :121503.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_9" title=" Schnabel R, Wahl R, Klein R.Efficient RANSAC for point-cloud shape detection[J].Computer Graphics Forum, 2007, 26 (2) :214-226." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000017953&amp;v=MTQzNTZZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTamxWYnZLSlZjPU5pZmNhck80SHRITXI0NUNiZTRN&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Schnabel R, Wahl R, Klein R.Efficient RANSAC for point-cloud shape detection[J].Computer Graphics Forum, 2007, 26 (2) :214-226.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_10" title=" Rabbani T, van den Heuvel F, Vosselmann G.Segmentation of point clouds using smoothness constraint[J].International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, 2006, 36 (5) :248-253." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation of point clouds using smoothness constraint">
                                        <b>[10]</b>
                                         Rabbani T, van den Heuvel F, Vosselmann G.Segmentation of point clouds using smoothness constraint[J].International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, 2006, 36 (5) :248-253.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_11" title=" Li R Z, Liu Y Y, Yang M, &lt;i&gt;et al&lt;/i&gt;.Three-dimensional point cloud segmentation algorithm based on improved region growing[J].Laser &amp;amp; Optoelectronics Progress, 2018, 55 (5) :051502.李仁忠, 刘阳阳, 杨曼, 等.基于改进的区域生长三维点云分割[J].激光与光电子学进展, 2018, 55 (5) :051502." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805041&amp;v=MTIxNDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk3aFVickJMeXJQWkxHNEg5bk1xbzlCWllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Li R Z, Liu Y Y, Yang M, &lt;i&gt;et al&lt;/i&gt;.Three-dimensional point cloud segmentation algorithm based on improved region growing[J].Laser &amp;amp; Optoelectronics Progress, 2018, 55 (5) :051502.李仁忠, 刘阳阳, 杨曼, 等.基于改进的区域生长三维点云分割[J].激光与光电子学进展, 2018, 55 (5) :051502.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_12" title=" Stein S C, Schoeler M, Papon J, &lt;i&gt;et al&lt;/i&gt;.Object partitioning using local convexity[C].IEEE Conference on Computer Vision and Pattern Recognition, 2014:14632311." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Partitioning Using Local Convexity">
                                        <b>[12]</b>
                                         Stein S C, Schoeler M, Papon J, &lt;i&gt;et al&lt;/i&gt;.Object partitioning using local convexity[C].IEEE Conference on Computer Vision and Pattern Recognition, 2014:14632311.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_13" title=" Charles R Q, Su H, Mo K C, &lt;i&gt;et al&lt;/i&gt;.PointNet:deep learning on point sets for 3D classification and segmentation[C].IEEE Conference on Computer Vision and Pattern Recognition, 2017:17355473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Point Net:Deep Learning on Point Sets for 3D Classification and Segmentation">
                                        <b>[13]</b>
                                         Charles R Q, Su H, Mo K C, &lt;i&gt;et al&lt;/i&gt;.PointNet:deep learning on point sets for 3D classification and segmentation[C].IEEE Conference on Computer Vision and Pattern Recognition, 2017:17355473.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_14" title=" Qi C R, Yi L, Su H, &lt;i&gt;et al&lt;/i&gt;.Pointnet++:deep hierarchical feature learning on point sets in a metric space[C].Advances in Neural Information Processing Systems, 2017:5099-5108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PointNet++:Deep hierarchical feature learning on point sets in a metric space">
                                        <b>[14]</b>
                                         Qi C R, Yi L, Su H, &lt;i&gt;et al&lt;/i&gt;.Pointnet++:deep hierarchical feature learning on point sets in a metric space[C].Advances in Neural Information Processing Systems, 2017:5099-5108.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_15" title=" Jiang M, Wu Y, Lu C.PointSIFT:a SIFT-like network module for 3D point cloud semantic segmentation[EB/OL]. (2018-07-03) [2018-10-31].https://arxiv.org/abs/1807.00652." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PointSIFT:a SIFT-like network module for 3D point cloud semantic segmentation">
                                        <b>[15]</b>
                                         Jiang M, Wu Y, Lu C.PointSIFT:a SIFT-like network module for 3D point cloud semantic segmentation[EB/OL]. (2018-07-03) [2018-10-31].https://arxiv.org/abs/1807.00652.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_16" title=" Canny J.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Computational Approach to Edge Detection">
                                        <b>[16]</b>
                                         Canny J.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-17 10:58</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(04),151-160 DOI:10.3788/AOS201939.0412003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种板型物体混叠场景的快速分割算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%B2%81%E8%8D%A3%E8%8D%A3&amp;code=41392362&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁荣荣</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%9E%AB&amp;code=09588420&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱枫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E6%B8%85%E6%BD%87&amp;code=11224531&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴清潇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B4%94%E8%8A%B8%E9%98%81&amp;code=41736391&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">崔芸阁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%94%E7%A0%94%E8%87%AA&amp;code=41736393&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孔研自</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E4%BD%9B%E8%AE%A1&amp;code=41736395&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈佛计</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%B2%88%E9%98%B3%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=0183762&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院沈阳自动化研究所</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8E%E6%99%BA%E8%83%BD%E5%88%B6%E9%80%A0%E5%88%9B%E6%96%B0%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院机器人与智能制造创新研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院光电信息处理重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E7%9C%81%E5%9B%BE%E5%83%8F%E7%90%86%E8%A7%A3%E4%B8%8E%E8%A7%86%E8%A7%89%E8%AE%A1%E7%AE%97%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁省图像理解与视觉计算重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对多个板型物体混叠摆放的场景, 提出了一种快速有效的分割算法。该算法充分利用有序点云的特点, 将自顶向下以及自底向上的分割策略结合, 根据三维点的空间位置和法向量, 利用随机采样一致性 (RANSAC) 算法从三维点云数据中快速提取平面点集;然后将提取的平面点集所对应的图像坐标映射为二值图像, 通过连通区域分析将其分割为多个连通的平面区域;接着利用“胶水”算法对这些区域进行快速合并, 并对较大的弱连接连通区域进行断裂修正, 得到最终的分割结果。实验结果表明:与区域生长算法相比, 所提算法的分割结果更优, 且算法效率大幅提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">点云分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机采样一致性算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *朱枫, E-mail:fzhu@sia.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (U1713216);</span>
                                <span>机器人学国家重点实验室自主课题 (2017-Z21);</span>
                    </p>
            </div>
                    <h1><b>A Fast Segmenting Method for Scenes with Stacked Plate-Shaped Objects</b></h1>
                    <h2>
                    <span>Lu Rongrong</span>
                    <span>Zhu Feng</span>
                    <span>Wu Qingxiao</span>
                    <span>Cui Yunge</span>
                    <span>Kong Yanzi</span>
                    <span>Chen Foji</span>
            </h2>
                    <h2>
                    <span>Shenyang Institute of Automation, Chinese Academy of Sciences</span>
                    <span>Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences</span>
                    <span>University of Chinese Academy of Sciences</span>
                    <span>Key Laboratory of Opto-Electronic Information Processing</span>
                    <span>Key Laboratory of Image Understanding and Computer Vision</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A fast and efficient segmentation algorithm is proposed for scenes in which multiple plate-shaped objects are placed in an overlapping manner. The algorithm makes full use of the characteristics of the ordered point cloud, and combines the top-down and bottom-up segmentation strategies. The Random Sample Consensus (RANSAC) algorithm is used to quickly extract the three-dimensional planar point set according to the spatial position and normal vector of the three-dimensional point from the three-dimensional point cloud. The image coordinates corresponding to the extracted planar point set are mapped into a binary image, and are divided into a plurality of connected planar regions by the connected region analysis. Then, the glue algorithm is used to quickly merge these regions, and the larger weakly connected regions are subjected to the fracture correction, so as to obtain the final segmentation result. The experimental results show that compared with the region growing algorithm, the proposed algorithm can obtain better segmentation results, and the algorithm efficiency is greatly improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=point%20cloud%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">point cloud segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=depth%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">depth image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=random%20sample%20consensus%20(RANSAC)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">random sample consensus (RANSAC) algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="42">场景分割是计算机视觉领域重要的研究方向之一, 其目的是将场景数据划分为不相交且有意义的连通区域, 从而为后续的场景理解做铺垫。根据处理的场景数据不同, 可将其分为基于图像数据的二维场景分割以及基于点云数据的三维场景分割。常用的图像分割算法包括阈值分割算法<citation id="93" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、区域生长算法<citation id="94" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、均值飘移算法<citation id="95" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、主动轮廓线算法<citation id="96" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>以及图割法<citation id="97" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>, 这些方法本质上都是基于图像亮度、颜色、纹理等因素的不同对其进行分割的。对于纹理相近 (或无纹理) 、亮度差异不大且在图像中彼此靠近的物体的分割, 上述方法一般得不到理想的分割结果。与二维图像分割算法相比, 基于三维点云数据的方法有时仅根据物体之间相对位置的差异就能实现对场景的快速准确分割, 且点云数据对光照、亮度变化具有较强的稳健性。根据三维点云数据是否有序又可将点云分割分为有序点云分割与无序点云分割。其中有序点云是指点与点之间的近邻关系与存储相关的点云 (例如由深度相机采集的深度图, 或者由线结构光连续扫描拼接而成的深度图等) , 而无序点云则不具有这种相关性 (例如由三维重建得到的大规模点云数据等) 。有序点云的优势主要体现为近邻查询效率更高, 且具有类似图像连通性的属性。</p>
                </div>
                <div class="p1">
                    <p id="43">目前的三维场景分割算法主要有:基于属性聚类的方法<citation id="102" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>、基于模型拟合的方法<citation id="98" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、基于区域生长的算法<citation id="103" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>、基于局部凸连接的算法<citation id="99" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 以及基于深度神经网络的方法<citation id="104" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。这些方法都有各自的局限性。基于属性聚类的方法一般会将场景中具有相同属性特征的点聚为一类, 适合用于分割差异较为明显的物体。田青华等<citation id="100" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种改进的欧氏聚类分割方法, 可用于散乱工件点云的分割, 对圆柱体类型工件的分割具有较好的性能。基于模型拟合的方法只适用于具有显示几何模型的物体的分割, 例如:平面、球体等。基于区域生长的算法需要有连通性定义, 对于无序点云而言, 通常需要预先将点云数据进行体素化。李仁忠等<citation id="101" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了一种改进的区域生长算法, 通过选取曲率小的点作为种子点, 提高了点云分割的精确性与可靠性, 但文中采用的实验数据过少, 且对算法效率的分析不够充分。基于局部凸连接的算法建立在物体表面的凸性连接假设上, 而基于深度神经网络的方法通常需要预先标注大量的训练样本, 且运算量巨大, 对硬件要求较高。</p>
                </div>
                <div class="p1">
                    <p id="44">在实际的工程应用中, 对结构性物体的分割十分常见。例如:无人驾驶系统需要对道路进行分割;室内移动机器人需要实时检测墙面过道;工业自动化加工的原材料也多为几何结构鲜明的物体, 如板型物体。板型物体可以看成是将某种二维形状垂直拉伸一定高度后形成的立体模型, 其上下表面为平面。当厚度相同时, 不同类型的板型物体的区别就在于其二维形状的不同。针对多种类型的板型物体混叠摆放的场景, 自动分拣系统如果直接对它们进行目标识别定位, 将会面临以下难点:平面物体特征单一, 基于局部特征匹配的识别定位方法会形成大量误匹配, 而基于模板匹配的方法则容易被场景中的其他物体干扰, 且效率不高。为此, 本文提出了一种板型物体混叠场景的快速分割方法, 可为后续的识别定位以及机器人操作提供帮助。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">2 基本原理</h3>
                <div class="p1">
                    <p id="46">场景分割一般有两种思路:自顶向下与自底向上。自顶向下采用不断分裂的策略, 将场景数据当作一个整体, 然后将其逐渐划分为小的区域;自底向上则采用合并的策略, 将场景中的每个元素当作独立的个体, 然后根据某种约束将它们合并成较大的区域。本研究同时采用这两种策略, 实现对板型物体混叠场景的快速分割, 算法主要包含三个阶段:连通平面区域提取、平面区域合并以及弱连接断裂修正, 下面进行详细介绍。</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47"><b>2.1 连通平面区域的提取</b></h4>
                <div class="p1">
                    <p id="48">对于板型物体而言, 其主要结构为平面。因此, 可以采用随机采样一致性 (RANSAC) 算法进行平面提取。算法的流程如下:</p>
                </div>
                <div class="p1">
                    <p id="49">1) 从场景点云中随机选取3个不共线的点, 计算由这3个点确定的平面的方程;</p>
                </div>
                <div class="p1">
                    <p id="50">2) 计算场景中每个点到该平面的距离, 统计距离小于设定阈值<i>τ</i><sub>ransac</sub>的点的数量, 满足距离约束的点称为内点;</p>
                </div>
                <div class="p1">
                    <p id="51">3) 重复上述两个步骤<i>N</i><sub>r</sub>次, 找出内点数量最多的平面点集, 并返回相应内点的序号, 将其记为一个平面区域;</p>
                </div>
                <div class="p1">
                    <p id="52">4) 从场景点云中剔除已经得到的内点, 重复上述3个步骤, 直到场景中剩余的点数小于预先设定的阈值<i>N</i><sub>p</sub>, 或者最后一次得到的内点数量小于阈值<i>N</i><sub>p</sub>。</p>
                </div>
                <div class="p1">
                    <p id="53">图1 (b) 显示了基于上述算法对图1 (a) 中的场景点云分割后的结果, 可以看到:上述算法并不能以物体为单位进行平面提取, 而是每次从场景中找出一个最大的平面点集, 导致同一个物体由于倾斜放置而被划分到不同的平面点集。因此, 需要对该算法进行改进。</p>
                </div>
                <div class="area_img" id="54">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 两种算法的分割结果。 (a) 三维点云 (俯视图) ; (b) 原始RANSAC算法分割结果; (c) 算法改进后的分割结果" src="Detail/GetImg?filename=images/GXXB201904018_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 两种算法的分割结果。 (a) 三维点云 (俯视图) ; (b) 原始RANSAC算法分割结果; (c) 算法改进后的分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_054.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Segmentation results obtained with two algorithms. (a) 3D point cloud (top view) ; (b) segmentation result obtained with original RANSAC algorithm; (c) segmentation result obtained with modified algorithm</p>

                </div>
                <div class="p1">
                    <p id="56">由于本研究针对的场景点云数据是有序的, 即点云数据可以和图像数据相互转化。根据这一特点, 初始化一个与点云数据一一对应的类别标签图像<i>L</i><sub>s</sub>, <i>L</i><sub>s</sub>的每个像素设为0, 代表每个元素没有被分割到任何平面点集。因此, 对场景点云进行分割等价于给标签图像<i>L</i><sub>s</sub>的每个像素赋一个对应的类别编号。本课题组提出了一种新的平面区域提取策略, 与上述算法的区别主要在第3步。即:每次通过RANSAC算法找到当前场景点云中最大的平面点集后, 且不是直接将其作为一个类别, 而是通过连通区域分析对其进一步划分, 得到一个或多个连通的平面区域。具体的做法如下:首先初始化一个与类别标签图像<i>L</i><sub>s</sub>大小相同的二值图像<i>L</i><sub>b</sub> (全为0) , 将内点对应处的位置设为1;接下来并不是直接进行连通区域的提取, 而是对二者图像利用大小为3 pixel×3 pixel的十字形结构元进行腐蚀, 试图将一些弱连接的地方断开, 得到更合理的连通区域;最后进行连通区域的提取, 对于每个连通区域, 如果其元素个数小于设定的阈值<i>N</i><sub>e</sub>, 则剔除该区域, 否则, 将标签图像<i>L</i><sub>s</sub>的相应位置赋一个新的标签值。图1 (c) 展示了采用改进后的算法分割得到的结果, 可以看到, 原始点云数据被分割成了多个连通的平面区域。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>2.2 平面区域的合并</b></h4>
                <div class="p1">
                    <p id="58">上述的平面区域提取算法采用了自顶向下的分割策略, 可以将整个场景点云快速地分割为多个连通的平面区域, 得到的是过分割的结果。为了得到更好的分割结果, 需要对这些平面区域进行适当的合并。本课题组提出了一种“胶水”合并算法, 并采用该算法来执行这一过程。由2.1节连通平面区域的提取可知, 连通平面区域提取算法已经将整个场景分割为多个连通的区域, 接下来需要做的就是将属于同一个物体的平面区域合并到一起, 这一过程有点类似于用胶水粘连破碎的纸片, 故将其称为“胶水”合并算法。</p>
                </div>
                <div class="p1">
                    <p id="59">首先, 从标签图像<i>L</i><sub>s</sub>中提取所有像素值为0的点 (还没有被分类的点) 的坐标。如果这些点的总数小于阈值<i>N</i><sub>s</sub>, 则算法直接结束, 否则, 从中随机选取<i>N</i><sub>s</sub>个点作为种子点, 记种子点的集合为<i>S</i>。则“胶水”算法的步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="60">a) 如果<i>S</i>不为空, 从<i>S</i>中取出第一个元素作为当前的种子点, 并将其从<i>S</i>中剔除。初始化一个空的队列<i>Q</i>, 将当前的种子点加入到队列中。初始化一个空的标签列表<i>L</i>, 将当前种子点对应标签图像位置的值设为<i>l</i>, 并将其添加到该列表中。</p>
                </div>
                <div class="p1">
                    <p id="61">b) 如果<i>Q</i>不为空, 取出第一个元素作为当前的种子点, 并将其从<i>Q</i>中移除。根据该种子点的图像坐标, 获取它的八邻域图像坐标, 并对每个图像坐标进行越界判断。提取种子点以及它的邻域点对应的三维坐标, 并计算它们的法向量。</p>
                </div>
                <div class="p1">
                    <p id="62">c) 对于每个合理的邻域点<i>q</i>的向量<b><i>q</i></b>, 如果它与种子点<i>p</i>的向量<b><i>p</i></b>满足约束|<b><i>n</i></b><sub><i>p</i></sub>· (<b><i>p</i></b>-<b><i>q</i></b>) |≤cos <i>α</i>∧|<b><i>n</i></b><sub><i>q</i></sub>· (<b><i>p</i></b>-<b><i>q</i></b>) |≤cos <i>α</i> (<b><i>n</i></b><sub><i>p</i></sub>与<b><i>n</i></b><sub><i>q</i></sub>分别为种子点与邻域点的法向量, <i>α</i>为预先设定的夹角阈值) , 则继续进行如下判断, 如果<b><i>q</i></b>对应的标签图像位置的像素值为0, 则将该像素的坐标加入种子队列<i>Q</i>, 并将该点对应的像素值设置为<i>l</i>。否则, 直接将该点对应的标签值加入列表<i>L</i>。</p>
                </div>
                <div class="p1">
                    <p id="63">d) 重复步骤b) 与c) , 直到<i>Q</i>为空。移除标签列表<i>L</i>中重复的元素, 即重复出现的标签只保留一个。记<i>L</i>中最小的标签值为<i>L</i><sub>min</sub>, 依次遍历<i>L</i>中的每个元素, 将标签图像<i>L</i><sub>s</sub>中等于该元素值的地方都置为<i>L</i><sub>min</sub>, 即合并这些小的平面区域。</p>
                </div>
                <div class="p1">
                    <p id="64">e) 由于上述过程可能会将<i>S</i>中其他的种子点一同合并进去, 故将这些被合并的种子点从<i>S</i>中移除。如果<i>S</i>为空, 则算法结束, 输出最终的标签图像<i>L</i><sub>s</sub>。否则, 跳转到步骤a) 。</p>
                </div>
                <div class="p1">
                    <p id="65">图2 (b) 显示了将图2 (a) 中的连通平面区域通过“胶水”算法合并后的结果。可以看到, 属于同一个板型物体的平面区域基本被合并到一起, 除了一些被隔断的区域外。图中每种颜色代表一块连通的平面区域, 需要指出的是, 本文所有的分割结果都是以三维彩色点云的形式展示的, 而不是二维彩色图像。为了方便观察, 所有结果显示的是彩色点云的俯视图。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 区域合并前后的结果。 (a) 连通平面区域; (b) “胶水”算法合并后的结果" src="Detail/GetImg?filename=images/GXXB201904018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 区域合并前后的结果。 (a) 连通平面区域; (b) “胶水”算法合并后的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Results obtained before and after region merging. (a) Connected planar regions; (b) merged result obtained with glue algorithm</p>

                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.3 弱连接断裂修正</b></h4>
                <div class="p1">
                    <p id="68">对于两个并排弱接触的物体, 在平面区域合并时可能会将它们聚为一个类别, 如图3 (b) 所示。因此, 需要对“胶水”算法输出的标签图像<i>L</i><sub>s</sub>进行简单修正。具体做法如下:首先, 提取标签图像中所有的聚类, 并统计每个类别中元素的个数。对于元素个数不超过<i>N</i><sub>m</sub>的类别, 将该类别作为最终的分割结果直接输出。对于元素个数大于<i>N</i><sub>m</sub>的类别, 分别为它们创建一个与标签图像大小相同的全零二值图像, 并只将每个类别对应位置处的值设为1, 图3 (c) 显示了图3 (b) 中红色连通区域对应二值图像的局部放大图。可以看到, 这三个物体由于共面且部分接触, 最终被合并到了一起。为了将它们分开, 采用大小为7 pixel×7 pixel且全1的结构元对二值图像进行腐蚀, 腐蚀后的结果如图3 (d) 所示。然后从腐蚀后的二值图像中提取连通区域, 并统计每个连通区域中元素的个数。将元素个数小于<i>N</i><sub>c</sub>的区域忽略, 因为腐蚀操作可能会将同一个物体分为多个细小的部分, 故只保留其最主要的部分。如果剩余的连通区域的个数为1, 则说明原始的连通区域是一个物体, 故将被腐蚀前的类别直接输出。否则, 根据新的连通区域对该类别重新进行细分。由于腐蚀操作会剔除一部分原始类别的信息, 为此, 用腐蚀前的二值图像与腐蚀后的二值图像做异或运算, 提取被剔除的点的坐标, 并将这些点根据图像坐标距离分配给离它们最近的连通区域, 然后将每个连通区域当作一个新的类别进行输出。最终, 可以得到如图3 (e) 所示的分割结果。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="70">本研究涉及的算法全部基于MATLAB 2017b平台实现, 笔记本计算机的型号为联想Y430p, Intel i7-4710MQ 处理器, 主频2.5 GHz, 8 GB RAM。没有使用GPU等并行加速算法。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>3.1 数据集介绍</b></h4>
                <div class="p1">
                    <p id="72">为了验证算法的有效性, 利用实验室的线结构光扫描平台采集多幅板型物体随机混叠摆放的场景深度图像。根据场景中包含板型物体个数的不同, 将它们分为两类:1) 简单型场景, 共20个, 每个场景包含物体的个数为5～12;2) 复杂型场景, 共10个, 每个场景包含物体的个数为20～28。实验中共涉及6种不同形状的板型物体, 如图4 (a) 所示, 其厚度均为8 mm, 最小外接圆的直径为10～25 cm。线结构光扫描得到的深度图的尺寸为640 pixel×480 pixel, 其最小分辨率为0.1 mm, 如图5 (a) 所示。对应的三维点云如图5 (b) 、 (c) 所示。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>3.2 算法参数设置</b></h4>
                <div class="p1">
                    <p id="74">针对数据集的特点, 所提算法的相关参数设置如表1所示。RANSAC算法的距离阈值建议设定为不超过板型物体厚度的一半。由于实验中所涉及的物体的厚度均为8 mm, 故最终将阈值设为3.5 mm。将是否进行区域断裂修正的阈值<i>N</i><sub>m</sub>设为1.5<i>M</i><sub>min</sub>, 其中<i>M</i><sub>min</sub>是所有板型物体中主平面面积最小的物体水平放置后, 在采集的深度图中占据的像素数。如果深度图被降采样为新的尺寸, 则<i>M</i><sub>min</sub>为所有板型物体中主平面面积最小的物体水平放置后, 在降采样后的深度图中占据的像素数, 以保证算法能够自适应场景分辨率的变化。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 所提算法处理的中间结果。 (a) 连通平面区域; (b) “胶水”算法的合并结果; (c) 红色连通区域对应的二值图像; (d) 腐蚀后的二值图像; (e) 最终的分割结果" src="Detail/GetImg?filename=images/GXXB201904018_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 所提算法处理的中间结果。 (a) 连通平面区域; (b) “胶水”算法的合并结果; (c) 红色连通区域对应的二值图像; (d) 腐蚀后的二值图像; (e) 最终的分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Intermediate results obtained with proposed algorithm. (a) Connected planar regions; (b) merged result obtained with glue algorithm; (c) binary image corresponding to the red connected region; (d) binary image after erosion; (e) final segmentation result</p>

                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 板型物体与数据采集平台。 (a) 6种板型物体; (b) 简单型场景; (c) 复杂型场景" src="Detail/GetImg?filename=images/GXXB201904018_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 板型物体与数据采集平台。 (a) 6种板型物体; (b) 简单型场景; (c) 复杂型场景  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Plate-shaped objects and data acquisition platform. (a) Six types of plate-shaped objects; (b) simple scene; (c) complex scene</p>

                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 深度图与对应的三维点云示例。 (a) 深度图; (b) 三维点云 (俯视图) ; (c) 放大的三维点云" src="Detail/GetImg?filename=images/GXXB201904018_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 深度图与对应的三维点云示例。 (a) 深度图; (b) 三维点云 (俯视图) ; (c) 放大的三维点云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 An illustration of depth image and its corresponding three-dimensional point cloud. (a) Depth image; (b) three-dimensional point cloud (top view) ; (c) amplified three-dimensional point cloud</p>

                </div>
                <div class="area_img" id="78">
                    <p class="img_tit">表1 所提算法的参数设置 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Parameter setting of proposed algorithm</p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td><i>N</i><sub>r</sub></td><td><i>τ</i><sub>ransac</sub> /mm</td><td><i>N</i><sub>p</sub></td><td><i>N</i><sub>e</sub></td><td><i>N</i><sub>s</sub></td><td><i>α</i> / (°) </td><td><i>N</i><sub>m</sub></td><td><i>N</i><sub>c</sub></td></tr><tr><td><br />1000</td><td>3.5</td><td>300</td><td>50</td><td>500</td><td>80</td><td>1.5<i>M</i><sub>min</sub></td><td>100</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>3.3 结果分析</b></h4>
                <div class="p1">
                    <p id="80">为了客观评估所提算法的性能, 选取4种分割算法与之进行对比。这4种算法分别是:基于深度图的边缘提取分割算法——Canny边缘算法、基于RANSAC的平面提取算法——RANSAC算法、基于<i>K</i>-均值聚类的分割算法——<i>K</i>-均值聚类算法, 以及区域生长算法。为了快速检测上述4种算法在本研究所给数据集上的分割效果, 从简单型场景以及复杂型场景中各挑出一幅深度图进行测试。4种算法的分割结果如图6所示。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 4种算法的分割结果。 (a) 深度图; (b) Canny边缘算法; (c) K-均值聚类算法; (d) RANSAC算法; (e) 区域生长算法" src="Detail/GetImg?filename=images/GXXB201904018_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 4种算法的分割结果。 (a) 深度图; (b) Canny边缘算法; (c) <i>K</i>-均值聚类算法; (d) RANSAC算法; (e) 区域生长算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Segmentation results obtained with four algorithms. (a) Depth images; (b) Canny edge algorithm; (c) <i>K</i>-means algorithm; (d) RANSAC algorithm; (e) region growing algorithm</p>

                </div>
                <div class="p1">
                    <p id="82">图6 (b) 给出了直接在深度图上进行Canny边缘检测<citation id="105" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的结果, 可以看到, 对深度图直接进行边缘提取, 得不到以物体为单位的闭合轮廓, 因此不能基于该轮廓线进行分割。以每个点的三维坐标和法向量确定的平面方程的4个系数为特征进行<i>K</i>-均值聚类的结果如图6 (c) 所示, 不难发现, 由于场景中共面的点太多, 分割结果不理想, 且<i>K</i>-均值聚类算法需要预先指定类别数, 灵活性不够。基于RANSAC算法进行平面提取的结果如图6 (d) 所示, 由2.1节的分析可知, 在整个场景上直接提取到的平面点集并不会以物体为单位聚集, 而是会将一些倾斜放置的物体分割为多个区域, 从而得不到想要的分割结果。只有区域生长算法给出了正确的分割结果, 如图6 (e) 所示。由于Canny边缘算法、<i>K</i>-均值聚类算法和RANSAC算法基本上得不到正确的分割结果, 故最后只给出了所提算法与区域生长算法的对比结果。为了客观评价这两种算法的分割结果, 通过手动标注的方式获取上述30幅场景点云数据对应的真实分割标签图。图7 (b) 、 (c) 是图7 (a) 对应的真实分割标签图的两种显示形式。通过将算法得到的标签图与相应的真实标签图求交集, 统计正确分割的点数 (或像素数) , 然后除以总数 (不包括地面) , 即为该场景的分割准确率。两种算法在每个场景上的分割准确率如表2所示, 所花费的时间成本如表3所示。</p>
                </div>
                <div class="p1">
                    <p id="83">由表2可知, 所提算法与区域生长算法在20个简单型场景上的平均分割准确率基本相同。为了更直观地观察分割结果, 给出了所提算法在20个简单型场景上的分割结果, 如图8所示。由于区域生长算法也对大部分的场景进行了正确分割, 故图9只显示了区域生长算法没有正确分割的场景, 可以看到, 所提算法没有将S6场景中相连的物体完全分割开。主要原因是二者相连的部分较大, 在进行断裂修正时设置的腐蚀元结构不足以一次将它们完全分开, 从而导致它们仍然连通。但与区域生长算法相比, 所提算法的分割结果要更优一些。由表3可知, 区域生长算法分割大小为640 pixel×480 pixel深度图的平均耗时为11.02 s, 而所提算法的平均耗时只有2.14 s, 可见, 所提算法计算的效率明显优于前者。这是因为基于RANSAC与连通区域分析的平面提取算法可将原始场景快速分割为多个小的连通区域, 大大加快了后续合并的效率, 而区域生长算法只能根据选定的种子点慢慢生长, 导致合并效率不高。有些应用场景对实时性要求较高, 为了进一步提升算法的效率, 可以先对原始场景进行降采样, 缩减点云的规模。表3还给出了两种算法分割大小为320 pixel×240 pixel深度图的时间成本。显然, 两种算法的时间成本都有较大的缩减, 但所提算法的效率更高, 平均耗时为0.57 s, 约为区域生长算法时间开销的1/5。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 原始深度图与标签图的对比。 (a) 原始深度图; (b) 真实标签 (灰度图) ; (c) 真实标签 (彩色图)" src="Detail/GetImg?filename=images/GXXB201904018_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 原始深度图与标签图的对比。 (a) 原始深度图; (b) 真实标签 (灰度图) ; (c) 真实标签 (彩色图)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Comparison between original depth image and labeled images. (a) Original depth image; (b) ground truth (gray image) ; (c) ground truth (color image) </p>

                </div>
                <div class="area_img" id="85">
                    <p class="img_tit">表2 所提算法与区域生长算法在20个简单型及10个复杂型场景上的分割准确率 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Segmentation accuracy obtained with proposed algorithm and region growing algorithm on twenty simple scenes and ten complex scenes</p>
                    <p class="img_note"></p>
                    <table id="85" border="1"><tr><td rowspan="2"><br />Scene No.</td><td colspan="2"><br />Segmentation accuracy on simple scenes</td><td colspan="2">Segmentation accuracy on complex scenes</td><td rowspan="2" colspan="2"></td></tr><tr><td><br />Region growing algorithm</td><td>Proposed algorithm</td><td>Region growing algorithm</td><td>Proposed algorithm</td></tr><tr><td>S1</td><td>1</td><td>0.99</td><td>0.95</td><td>0.96</td></tr><tr><td><br />S2</td><td>0.94</td><td>0.94</td><td>0.85</td><td>0.93</td></tr><tr><td><br />S3</td><td>0.97</td><td>0.96</td><td>0.97</td><td>0.97</td></tr><tr><td><br />S4</td><td>0.91</td><td>0.94</td><td>0.92</td><td>0.89</td></tr><tr><td><br />S5</td><td>0.96</td><td>0.94</td><td>0.96</td><td>0.92</td></tr><tr><td><br />S6</td><td>0.82</td><td>0.89</td><td>0.96</td><td>0.96</td></tr><tr><td><br />S7</td><td>0.90</td><td>0.91</td><td>0.93</td><td>0.96</td></tr><tr><td><br />S8</td><td>0.84</td><td>0.99</td><td>0.84</td><td>0.95</td></tr><tr><td><br />S9</td><td>0.99</td><td>0.99</td><td>0.93</td><td>0.94</td></tr><tr><td><br />S10</td><td>1</td><td>0.99</td><td>0.92</td><td>0.95</td></tr><tr><td><br />S11</td><td>0.97</td><td>0.97</td><td></td><td></td></tr><tr><td><br />S12</td><td>1</td><td>0.99</td><td></td><td></td></tr><tr><td><br />S13</td><td>1</td><td>0.99</td><td></td><td></td></tr><tr><td><br />S14</td><td>1</td><td>1</td><td></td><td></td></tr><tr><td><br />S15</td><td>0.94</td><td>0.95</td><td></td><td></td></tr><tr><td><br />S16</td><td>1</td><td>0.95</td><td></td><td></td></tr><tr><td><br />S17</td><td>1</td><td>1</td><td></td><td></td></tr><tr><td><br />S18</td><td>1</td><td>1</td><td></td><td></td></tr><tr><td><br />S19</td><td>1</td><td>1</td><td></td><td></td></tr><tr><td><br />S20</td><td>0.98</td><td>0.98</td><td></td><td></td></tr><tr><td><br />Average</td><td>0.961</td><td>0.968</td><td>0.923</td><td>0.943</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit">表3 所提算法与区域生长算法在20个简单型及10个复杂型场景上的平均时间成本 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Average time cost obtained with proposed algorithm and region growing algorithm on twenty simple scenes and ten complex scenes</p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td rowspan="2"><br />Image size /<br /> (pixel×pixel) </td><td colspan="2"><br />Average time cost on simple scenes /s</td><td colspan="2">Average time cost on complex scenes /s</td><td rowspan="2" colspan="2"></td></tr><tr><td><br />Region growing algorithm</td><td>Proposed algorithm</td><td>Region growing algorithm</td><td>Proposed algorithm</td></tr><tr><td>640×480</td><td>11.02</td><td>2.14</td><td>11.89</td><td>3.14</td></tr><tr><td><br />320×240</td><td>2.65</td><td>0.57</td><td>2.59</td><td>1.02</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 所提算法在20个简单型场景上的分割结果" src="Detail/GetImg?filename=images/GXXB201904018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 所提算法在20个简单型场景上的分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Segmentation results obtained with proposed algorithm on twenty simple scenes</p>

                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 两种算法在S6、S8、S15场景上的分割结果。 (a) 所提算法; (b) 区域生长算法" src="Detail/GetImg?filename=images/GXXB201904018_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 两种算法在S6、S8、S15场景上的分割结果。 (a) 所提算法; (b) 区域生长算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Segmentation results obtained with two algorithms on S6, S8 and S15 scenes. (a) Proposed method; (b) region growing algorithm</p>

                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201904018_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 两种算法在10个复杂型场景上的分割结果。 (a) 所提算法; (b) 区域生长算法" src="Detail/GetImg?filename=images/GXXB201904018_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 两种算法在10个复杂型场景上的分割结果。 (a) 所提算法; (b) 区域生长算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201904018_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Segmentation results obtained with two algorithms on ten complex scenes. (a) Proposed method; (b) region growing algorithm</p>

                </div>
                <div class="p1">
                    <p id="90">由表2可知, 所提算法在10个复杂型场景上的平均分割准确率优于区域生长算法。同样, 在图10中给出了两种算法在10个复杂型场景上的分割结果。结合表2可以看出, 所提算法在S2、S7以及S8场景中较好地处理了弱连接物体的分割, 因此得到了较高的分割准确率。同样, 表3中给出了两种算法分割每个场景花费的时间成本。与简单型场景的分割时间相比, 两种算法的时间开销都有一定的提升。这是因为随着场景中板型物体的增多, 连通平面区域的数量也随之增加, 这意味着需要合并的区域数较简单型场景更多, 所以时间成本会相应增加。在同等条件下, 所提算法的计算效率优于区域生长算法, 且分割效果更好。上述实验结果说明了所提算法的有效性与实用性。</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">4 结 论</h3>
                <div class="p1">
                    <p id="92">介绍了一种快速有效的板型物体混叠场景分割算法。首先利用自顶向下的分割策略将原始场景分割为多个连通的平面区域, 然后通过自底向上的策略将它们快速合并。最后对合并后的结果进行弱连接断裂修正, 从而得到更优的分割结果。为了验证算法的有效性, 采集了多组测试数据集进行实验, 实验结果表明:无论是分割结果还是算法的时间开销, 所提算法都优于区域生长算法。在实际应用中, 如果对实时性要求较高, 建议将原始场景进行适当降采样, 这样可以更快地完成场景分割。通常, 分割只是为了更好地理解场景。在接下来的研究中, 可以对分割出来的物体进行识别与定位, 以实现自动化抓取等操作。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="9">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Otsu N.A threshold selection method from gray-level histograms[J].IEEE Transactions on Systems, Man, and Cybernetics, 1979, 9 (1) :62-66.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Seeded region growing">

                                <b>[2]</b> Adams R, Bischof L.Seeded region growing[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (6) :641-647.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mean Shift: A Robust Approach Toward Feature Space Analysis">

                                <b>[3]</b> Comaniciu D, Meer P.Mean shift:a robust approach toward feature space analysis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (5) :603-619.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830144&amp;v=MTQ3MDJxZWJ1ZHRGU2psVmJ2S0pWYz1OajdCYXJPNEh0SE9wNHhGWmU4TFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Kass M, Witkin A, Terzopoulos D.Snakes:active contour models[J].International Journal of Computer Vision, 1988, 1 (4) :321-331.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Shi J B, Malik J.Normalized cuts and image segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (8) :888-905.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830890&amp;v=MzAzMjJkdEZTamxWYnZLSlZjPU5qN0Jhck80SHRIT3A0eEZiT0lQWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Felzenszwalb P F, Huttenlocher D P.Efficient graph-based image segmentation[J].International Journal of Computer Vision, 2004, 59 (2) :167-181.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient organized point cloud segmentation with connectedcomponents">

                                <b>[7]</b> Trevor A J B, Gedikli S, Rusu R B, <i>et al</i>.Efficient organized point cloud segmentation with connected components[C].Semantic Perception Mapping and Exploration, 2013:1-6.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201712039&amp;v=Mjc4NzE0TzN6cXFCdEdGckNVUkxPZVplVnVGeTdoVWJyQkx5clBaTEc0SDliTnJZOUdiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Tian Q H, Bai R L, Li D.Point cloud segmentation of scattered workpieces based on improved euclidean clustering[J].Laser &amp; Optoelectronics Progress, 2017, 54 (12) :121503.田青华, 白瑞林, 李杜.基于改进欧氏聚类的散乱工件点云分割[J].激光与光电子学进展, 2017, 54 (12) :121503.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000017953&amp;v=MDE1MDFqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTamxWYnZLSlZjPU5pZmNhck80SHRITXI0NUNiZTRNWTNrNXpCZGg0&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Schnabel R, Wahl R, Klein R.Efficient RANSAC for point-cloud shape detection[J].Computer Graphics Forum, 2007, 26 (2) :214-226.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation of point clouds using smoothness constraint">

                                <b>[10]</b> Rabbani T, van den Heuvel F, Vosselmann G.Segmentation of point clouds using smoothness constraint[J].International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, 2006, 36 (5) :248-253.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805041&amp;v=MzA3MjZHNEg5bk1xbzlCWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk3aFVickJMeXJQWkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Li R Z, Liu Y Y, Yang M, <i>et al</i>.Three-dimensional point cloud segmentation algorithm based on improved region growing[J].Laser &amp; Optoelectronics Progress, 2018, 55 (5) :051502.李仁忠, 刘阳阳, 杨曼, 等.基于改进的区域生长三维点云分割[J].激光与光电子学进展, 2018, 55 (5) :051502.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Partitioning Using Local Convexity">

                                <b>[12]</b> Stein S C, Schoeler M, Papon J, <i>et al</i>.Object partitioning using local convexity[C].IEEE Conference on Computer Vision and Pattern Recognition, 2014:14632311.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Point Net:Deep Learning on Point Sets for 3D Classification and Segmentation">

                                <b>[13]</b> Charles R Q, Su H, Mo K C, <i>et al</i>.PointNet:deep learning on point sets for 3D classification and segmentation[C].IEEE Conference on Computer Vision and Pattern Recognition, 2017:17355473.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PointNet++:Deep hierarchical feature learning on point sets in a metric space">

                                <b>[14]</b> Qi C R, Yi L, Su H, <i>et al</i>.Pointnet++:deep hierarchical feature learning on point sets in a metric space[C].Advances in Neural Information Processing Systems, 2017:5099-5108.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PointSIFT:a SIFT-like network module for 3D point cloud semantic segmentation">

                                <b>[15]</b> Jiang M, Wu Y, Lu C.PointSIFT:a SIFT-like network module for 3D point cloud semantic segmentation[EB/OL]. (2018-07-03) [2018-10-31].https://arxiv.org/abs/1807.00652.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Computational Approach to Edge Detection">

                                <b>[16]</b> Canny J.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201904018" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201904018&amp;v=MjQxMDJDVVJMT2VaZVZ1Rnk3aFVickJJalhUYkxHNEg5ak1xNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNDOE1qZHpnTnRFYXZMeWZFaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

