

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135525390256250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201902012%26RESULT%3d1%26SIGN%3dZ%252bnG%252bar9aIZ41gF7vts4dvtBNy0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201902012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201902012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201902012&amp;v=MjkwMDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURrVUx6TElqWFRiTEc0SDlqTXJZOUVab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#73" data-title="1 引 言 ">1 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="2 理论模型 ">2 理论模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="&lt;b&gt;2.1&lt;/b&gt;&lt;b&gt;Retinex模型&lt;/b&gt;"><b>2.1</b><b>Retinex模型</b></a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;2.2&lt;/b&gt;&lt;b&gt;HSI颜色模型&lt;/b&gt;"><b>2.2</b><b>HSI颜色模型</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;2.3&lt;/b&gt;&lt;b&gt;卷积神经网络&lt;/b&gt;"><b>2.3</b><b>卷积神经网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#93" data-title="3 基于DCNN的图像增强 ">3 基于DCNN的图像增强</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;3.1&lt;/b&gt;&lt;b&gt;图像增强算法模型&lt;/b&gt;"><b>3.1</b><b>图像增强算法模型</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;3.2&lt;/b&gt;&lt;b&gt;亮度增强&lt;/b&gt;"><b>3.2</b><b>亮度增强</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="4 实验结果分析 ">4 实验结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#128" data-title="&lt;b&gt;4.1&lt;/b&gt;&lt;b&gt;样本制作&lt;/b&gt;"><b>4.1</b><b>样本制作</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;4.2&lt;/b&gt;&lt;b&gt;实验设置&lt;/b&gt;"><b>4.2</b><b>实验设置</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;4.3&lt;/b&gt;&lt;b&gt;实验参数的选取&lt;/b&gt;"><b>4.3</b><b>实验参数的选取</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;4.4&lt;/b&gt;&lt;b&gt;实验分析&lt;/b&gt;"><b>4.4</b><b>实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#159" data-title="5 结 论 ">5 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="图1 CNN的典型结构">图1 CNN的典型结构</a></li>
                                                <li><a href="#96" data-title="图2 所提算法流程">图2 所提算法流程</a></li>
                                                <li><a href="#106" data-title="图3 DCNN模型的网络结构">图3 DCNN模型的网络结构</a></li>
                                                <li><a href="#137" data-title="表1 不同网络层数和卷积核数目下的测试PSNR值">表1 不同网络层数和卷积核数目下的测试PSNR值</a></li>
                                                <li><a href="#143" data-title="图4 不同算法在合成低照度图像上的主观视觉对比。 (a) 图像“caps”; (b) 图像“carnivaldolls”; (c) 图像“cemetry”; (d) 图像“building 2”">图4 不同算法在合成低照度图像上的主观视觉对比。 (a) 图像“caps”; (b) 图像“carn......</a></li>
                                                <li><a href="#144" data-title="表2 不同算法在合成低照度图像上的客观评价指标">表2 不同算法在合成低照度图像上的客观评价指标</a></li>
                                                <li><a href="#149" data-title="图5 有/无BN条件下HSI和RGB增强方法的收敛速度。 (a) 50个训练周期的平均SSIM; (b) 50个训练周期的平均PSNR">图5 有/无BN条件下HSI和RGB增强方法的收敛速度。 (a) 50个训练周期的平均SSIM; (......</a></li>
                                                <li><a href="#154" data-title="图6 不同算法在真实低照度图像上的主观视觉对比。 (a) 图像来自数据库DICM; (b) 图像来自数据库VV; (c) ～ (d) 图像来自数据库NASA; (e) 图6 (d) 中蓝框区域放大图">图6 不同算法在真实低照度图像上的主观视觉对比。 (a) 图像来自数据库DICM; (b) 图像来自......</a></li>
                                                <li><a href="#155" data-title="表3 不同算法在真实低照度图像上的客观评价指标">表3 不同算法在真实低照度图像上的客观评价指标</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="11">


                                    <a id="bibliography_1" title=" Li Q Z, Liu Q. Adaptive enhancement algorithm for low illumination images based on wavelet transform[J]. Chinese Journal of Lasers, 2015, 42 (2) : 0209001.  李庆忠, 刘清. 基于小波变换的低照度图像自适应增强算法[J]. 中国激光, 2015, 42 (2) : 0209001" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201502040&amp;v=MjY3MjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMekxMeWZSZExHNEg5VE1yWTlCWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Li Q Z, Liu Q. Adaptive enhancement algorithm for low illumination images based on wavelet transform[J]. Chinese Journal of Lasers, 2015, 42 (2) : 0209001.  李庆忠, 刘清. 基于小波变换的低照度图像自适应增强算法[J]. 中国激光, 2015, 42 (2) : 0209001
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_2" title=" Fei Y J, Shao F. Contrast adjustment based on image retrieval[J]. Laser &amp;amp; Optoelectronics Progress, 2018, 55 (5) : 051002. 费延佳, 邵枫. 基于图像检索的对比度调整[J]. 激光与光电子学进展, 2018, 55 (5) : 051002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805013&amp;v=MjIyMDVMRzRIOW5NcW85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGtVTHpMTHlyUFo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Fei Y J, Shao F. Contrast adjustment based on image retrieval[J]. Laser &amp;amp; Optoelectronics Progress, 2018, 55 (5) : 051002. 费延佳, 邵枫. 基于图像检索的对比度调整[J]. 激光与光电子学进展, 2018, 55 (5) : 051002.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_3" title=" Land E H. The retinex theory of color vision[J]. Scientific American, 1977, 237 (6) : 108-128." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The retinex theory of color vision">
                                        <b>[3]</b>
                                         Land E H. The retinex theory of color vision[J]. Scientific American, 1977, 237 (6) : 108-128.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_4" title=" Zhang J, Zhou P C, Zhang Q. Low-light image enhancement based on iterative multi-scale guided filter Retinex[J]. Journal of Graphics, 2018, 39 (1) : 1-11. 张杰, 周浦城, 张谦. 基于迭代多尺度引导滤波Retinex的低照度图像增强[J]. 图学学报, 2018, 39 (1) : 1-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201801001&amp;v=MjU1MDk5bk1ybzlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMekxJaTdmZHJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Zhang J, Zhou P C, Zhang Q. Low-light image enhancement based on iterative multi-scale guided filter Retinex[J]. Journal of Graphics, 2018, 39 (1) : 1-11. 张杰, 周浦城, 张谦. 基于迭代多尺度引导滤波Retinex的低照度图像增强[J]. 图学学报, 2018, 39 (1) : 1-11.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_5" title=" Jobson D J, Rahman Z, Woodell G A. Properties and performance of a center/surround retinex[J]. IEEE Transactions on Image Processing, 1997, 6 (3) : 451-462." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Properties and performance of a center/surround retinex">
                                        <b>[5]</b>
                                         Jobson D J, Rahman Z, Woodell G A. Properties and performance of a center/surround retinex[J]. IEEE Transactions on Image Processing, 1997, 6 (3) : 451-462.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_6" title=" Lin H, Shi Z.Multi-scale retinex improvement for nighttime image enhancement[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (24) : 7143-7148." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700100098&amp;v=MzIwMDllWnRGaW5sVXJ6SktGOFhhUkU9TmlmT2ZiSzhIOURNcUk5Rlplc1BESFV4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Lin H, Shi Z.Multi-scale retinex improvement for nighttime image enhancement[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (24) : 7143-7148.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_7" title=" Chen Y, Zhan D, Liu H L. Enhancement algorithm for low-lighting images based on physical model and boundary constraint[J]. Journal of Electronics &amp;amp; Information Technology, 2017, 39 (12) : 2962-2969. 陈勇, 詹帝, 刘焕淋. 基于物理模型与边界约束的低照度图像增强算法[J]. 电子与信息学报, 2017, 39 (12) : 2962-2969." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201712022&amp;v=MjI3MTA1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMekxJVGZTZHJHNEg5Yk5yWTlIWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Chen Y, Zhan D, Liu H L. Enhancement algorithm for low-lighting images based on physical model and boundary constraint[J]. Journal of Electronics &amp;amp; Information Technology, 2017, 39 (12) : 2962-2969. 陈勇, 詹帝, 刘焕淋. 基于物理模型与边界约束的低照度图像增强算法[J]. 电子与信息学报, 2017, 39 (12) : 2962-2969.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_8" title=" Fu X Y, Zeng D L, Huang Y, &lt;i&gt;et al&lt;/i&gt;. A weighted variational model for simultaneous reflectance and illumination estimation[C]. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 2782-2790." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A weighted variational model for simultaneous reflectanceand illumination estimation">
                                        <b>[8]</b>
                                         Fu X Y, Zeng D L, Huang Y, &lt;i&gt;et al&lt;/i&gt;. A weighted variational model for simultaneous reflectance and illumination estimation[C]. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 2782-2790.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_9" title=" Guo X J, Li Y, Ling H B. LIME: low-light image enhancement via illumination map estimation[J]. IEEE Transactions on Image Processing, 2017, 26 (2) : 982-993." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LIME:Low-light image enhancement via illumination map estimation">
                                        <b>[9]</b>
                                         Guo X J, Li Y, Ling H B. LIME: low-light image enhancement via illumination map estimation[J]. IEEE Transactions on Image Processing, 2017, 26 (2) : 982-993.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_10" title=" Dong X, Wang G, Pang Y, &lt;i&gt;et al&lt;/i&gt;. Fast efficient algorithm for enhancement of low lighting video[C]. IEEE International Conference on Multimedia and Expo (ICME) , 2011: 1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast efficient algorithm for enhancement of low lighting video">
                                        <b>[10]</b>
                                         Dong X, Wang G, Pang Y, &lt;i&gt;et al&lt;/i&gt;. Fast efficient algorithm for enhancement of low lighting video[C]. IEEE International Conference on Multimedia and Expo (ICME) , 2011: 1-6.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_11" title=" Li L, Wang R G, Wang W M, &lt;i&gt;et al&lt;/i&gt;. A low-light image enhancement method for both denoising and contrast enlarging[C]. IEEE International Conference on Image Processing (ICIP) , 2015: 3730-3734." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A low-light image enhancement method for both denoising and contrast enlarging">
                                        <b>[11]</b>
                                         Li L, Wang R G, Wang W M, &lt;i&gt;et al&lt;/i&gt;. A low-light image enhancement method for both denoising and contrast enlarging[C]. IEEE International Conference on Image Processing (ICIP) , 2015: 3730-3734.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_12" title=" Yang J, Jiang X W, Pan C H, &lt;i&gt;et al&lt;/i&gt;. Enhancement of low light level images with coupled dictionary learning[C].International Conference on Pattern Recognition (ICPR) , 2016: 751-756." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancement of low light level images with coupled dictionary learning">
                                        <b>[12]</b>
                                         Yang J, Jiang X W, Pan C H, &lt;i&gt;et al&lt;/i&gt;. Enhancement of low light level images with coupled dictionary learning[C].International Conference on Pattern Recognition (ICPR) , 2016: 751-756.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_13" title=" Song R X, Li D, Wang X C. Low illumination image enhancement algorithm based on HSI color space[J]. Journal of Graphics, 2017, 38 (2) : 217-223. 宋瑞霞, 李达, 王小春. 基于HSI色彩空间的低照度图像增强算法[J]. 图学学报, 2017, 38 (2) : 217-223." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201702013&amp;v=MjE5MDI3ZmRyRzRIOWJNclk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGtVTHpMSWk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Song R X, Li D, Wang X C. Low illumination image enhancement algorithm based on HSI color space[J]. Journal of Graphics, 2017, 38 (2) : 217-223. 宋瑞霞, 李达, 王小春. 基于HSI色彩空间的低照度图像增强算法[J]. 图学学报, 2017, 38 (2) : 217-223.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_14" title=" Wu F, Kintak U. Low-light image enhancement algorithm based on HSI color space[C]. International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI) , 2017: 1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low-light image enhancement algorithm based on HSI color space">
                                        <b>[14]</b>
                                         Wu F, Kintak U. Low-light image enhancement algorithm based on HSI color space[C]. International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI) , 2017: 1-6.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_15" title=" Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[J]. Communications of the ACM, 2017, 60 (6) : 84-90." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[15]</b>
                                         Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[J]. Communications of the ACM, 2017, 60 (6) : 84-90.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_16" title=" Xin P, Xu Y L, Tang H, &lt;i&gt;et al&lt;/i&gt;. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MjI4MTJySTlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMekxJalhUYkxHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Xin P, Xu Y L, Tang H, &lt;i&gt;et al&lt;/i&gt;. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_17" title=" Zhu M M, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;. Airport detection method with improved region-based convolutional neural network[J]. Acta Optica Sinica, 2018, 38 (7) : 0728001. 朱明明, 许悦雷, 马时平, 等. 改进区域卷积神经网络的机场检测方法[J]. 光学学报, 2018, 38 (7) : 0728001." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807042&amp;v=MDg5OTZVTHpMSWpYVGJMRzRIOW5NcUk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Zhu M M, Xu Y L, Ma S P, &lt;i&gt;et al&lt;/i&gt;. Airport detection method with improved region-based convolutional neural network[J]. Acta Optica Sinica, 2018, 38 (7) : 0728001. 朱明明, 许悦雷, 马时平, 等. 改进区域卷积神经网络的机场检测方法[J]. 光学学报, 2018, 38 (7) : 0728001.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     Lore K G, Akintayo A, Sarkar S. LLNet: a deep autoencoder approach to natural low-light image enhancement[J]. Pattern Recognition, 2017, 61: 650-662.</a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_19" title=" Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]. Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, 2011: 315-323." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Sparse Rectifier Neural Networks">
                                        <b>[19]</b>
                                         Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]. Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, 2011: 315-323.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_20" title=" Ioffe S, Szegedy C. Batch normalization: accelerating deep network training by reducing internal covariate shift[C]. Proceedings of the 32nd International Conference on International Conference on Machine Learning, 2015: 448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:accelerating deep network training by reducing internal covariate shift">
                                        <b>[20]</b>
                                         Ioffe S, Szegedy C. Batch normalization: accelerating deep network training by reducing internal covariate shift[C]. Proceedings of the 32nd International Conference on International Conference on Machine Learning, 2015: 448-456.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_21" title=" Chen X Y, Wang S A. Superpixel segmentation based on Delaunay triangulation[C]. International Conference on Mechatronics and Machine Vision in Practice (M2VIP) , 2016: 1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Superpixel segmentation based on Delaunay triangulation">
                                        <b>[21]</b>
                                         Chen X Y, Wang S A. Superpixel segmentation based on Delaunay triangulation[C]. International Conference on Mechatronics and Machine Vision in Practice (M2VIP) , 2016: 1-6.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_22" title=" Zhang K, Zuo W, Chen Y, &lt;i&gt;et al&lt;/i&gt;. Beyond a Gaussian denoiser: residual learning of deep CNN for image denoisin[J]. IEEE Transactions on Image Processing, 2017, 26 (7) : 3142-3155." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond a Gaussian Denoiser:Residual Learning of Deep CNN for Image Denoising">
                                        <b>[22]</b>
                                         Zhang K, Zuo W, Chen Y, &lt;i&gt;et al&lt;/i&gt;. Beyond a Gaussian denoiser: residual learning of deep CNN for image denoisin[J]. IEEE Transactions on Image Processing, 2017, 26 (7) : 3142-3155.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_23" title=" He K M, Zhang X Y, Ren S Q, &lt;i&gt;et al&lt;/i&gt;. Delving deep into rectifiers: surpassing human-level performance on ImageNet classification[C]. IEEE International Conference on Computer Vision (ICCV) , 2015: 1026-1034." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Delving Deep into Rectifiers:Surpassing Human-Level Performance on ImageNet Classification">
                                        <b>[23]</b>
                                         He K M, Zhang X Y, Ren S Q, &lt;i&gt;et al&lt;/i&gt;. Delving deep into rectifiers: surpassing human-level performance on ImageNet classification[C]. IEEE International Conference on Computer Vision (ICCV) , 2015: 1026-1034.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_24" title=" Dong C, Loy C C, He K M, &lt;i&gt;et al&lt;/i&gt;. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) : 295-307." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">
                                        <b>[24]</b>
                                         Dong C, Loy C C, He K M, &lt;i&gt;et al&lt;/i&gt;. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) : 295-307.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_25" title=" Cheng H D, Shi X J. A simple and effective histogram equalization approach to image enhancement[J]. Digital Signal Processing, 2004, 14 (2) : 158-170." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501235178&amp;v=MTU5MDRLRjhYYVJFPU5pZk9mYks3SHRETnFvOUVadWdLRFhzeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6Sg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         Cheng H D, Shi X J. A simple and effective histogram equalization approach to image enhancement[J]. Digital Signal Processing, 2004, 14 (2) : 158-170.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_26" title=" Sheikh H R, Sabir M F, Bovik A C. A statistical evaluation of recent full reference image quality assessment algorithm[J]. IEEE Transactions on Image Processing, 2006, 15 (11) : 3440-3451." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Statistical Evaluation of Recent Full Reference Image Quality Assessment Algorithms">
                                        <b>[26]</b>
                                         Sheikh H R, Sabir M F, Bovik A C. A statistical evaluation of recent full reference image quality assessment algorithm[J]. IEEE Transactions on Image Processing, 2006, 15 (11) : 3440-3451.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_27" title=" Wang S H, Zheng J, Hu H M, &lt;i&gt;et al&lt;/i&gt;. Naturalness preserved enhancement algorithm for non-uniform illumination images[J]. IEEE Transactions on Image Processing, 2013, 22 (9) : 3538-3548." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Naturalness preserved enhancement algorithm for non-uniform illumination images">
                                        <b>[27]</b>
                                         Wang S H, Zheng J, Hu H M, &lt;i&gt;et al&lt;/i&gt;. Naturalness preserved enhancement algorithm for non-uniform illumination images[J]. IEEE Transactions on Image Processing, 2013, 22 (9) : 3538-3548.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_28" title=" Rahman Z U, Jobson D J, Woodell G A. Investigating the relationship between image enhancement and image compression in the context of the multi-scale retinex[J]. Journal of Visual Communication and Image Representation, 2011, 22 (3) : 237-250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263401&amp;v=MjM2NTBubFVyekpLRjhYYVJFPU5pZk9mYks3SHRETnFvOUVadTBNQ0h3NG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[28]</b>
                                         Rahman Z U, Jobson D J, Woodell G A. Investigating the relationship between image enhancement and image compression in the context of the multi-scale retinex[J]. Journal of Visual Communication and Image Representation, 2011, 22 (3) : 237-250.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_29" title=" Lee C, Lee C, Kim C S. Contrast enhancement based on layered difference representation[C]. IEEE International Conference on Image Processing, 2012: 965-968." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement based on layered differencerepresentation">
                                        <b>[29]</b>
                                         Lee C, Lee C, Kim C S. Contrast enhancement based on layered difference representation[C]. IEEE International Conference on Image Processing, 2012: 965-968.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_30" title=" Vonikakis V, Andreadis I. Fast automatic compensation of under/over- exposured image regions[C]. IEEE Pacific Rim Symposium on Image Video and Technology (PSIVT) , 2007: 510-521." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast automatic compensation of under/over exposured image regions">
                                        <b>[30]</b>
                                         Vonikakis V, Andreadis I. Fast automatic compensation of under/over- exposured image regions[C]. IEEE Pacific Rim Symposium on Image Video and Technology (PSIVT) , 2007: 510-521.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_31" title=" Chow L S, Rajagopal H, Paramesran R. Correlation between subjective and objective assessment of magnetic resonance (MR) images[J]. Magnetic Resonance Imaging, 2016, 34 (6) : 820-831." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Correlation between subjective and objective assessment of magnetic resonance (MR)images">
                                        <b>[31]</b>
                                         Chow L S, Rajagopal H, Paramesran R. Correlation between subjective and objective assessment of magnetic resonance (MR) images[J]. Magnetic Resonance Imaging, 2016, 34 (6) : 820-831.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-10-07 14:16</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(02),99-108 DOI:10.3788/AOS201939.0210004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于深度卷积神经网络的低照度图像增强</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E7%BA%A2%E5%BC%BA&amp;code=38613075&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马红强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E6%97%B6%E5%B9%B3&amp;code=20940682&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马时平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%AE%B8%E6%82%A6%E9%9B%B7&amp;code=21114973&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">许悦雷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%98%8E%E6%98%8E&amp;code=38559959&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱明明</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A9%BA%E5%86%9B%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E8%88%AA%E7%A9%BA%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0274788&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空军工程大学航空工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E6%97%A0%E4%BA%BA%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=0085569&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学无人系统技术研究院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对低照度条件下图像降质严重的问题, 提出了一种基于深度卷积神经网络 (DCNN) 的低照度图像增强算法。该算法根据Retinex模型合成训练样本, 将原始低照度图像从RGB (Red Green Blue) 空间转换到HSI (Hue Saturation Intensity) 颜色空间, 保持色度分量和饱和度分量不变, 利用DCNN对亮度分量进行增强, 最后将HSI颜色空间转换到RGB空间, 得到最终的增强图像。实验结果表明, 与现有主流的图像增强算法相比, 所提算法不仅能够有效提升亮度和对比度, 改善过增强现象, 而且能够避免色彩失真, 主观视觉和客观评价指标均得到了进一步提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Retinex%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Retinex模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">批归一化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *马红强, E-mail:18049025189@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61372167, 61379104);</span>
                    </p>
            </div>
                    <h1>Low-Light Image Enhancement Based on Deep Convolutional Neural Network</h1>
                    <h2>
                    <span>Ma Hongqiang</span>
                    <span>Ma Shiping</span>
                    <span>Xu Yuelei</span>
                    <span>Zhu Mingming</span>
            </h2>
                    <h2>
                    <span>Aeronautics Engineering College, Air Force Engineering University</span>
                    <span>Unmanned System Research Institute, Northwestern Polytechnical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of the severe image degradation under a low-light condition, a low-light image enhancement algorithm based on deep convolutional neural network (DCNN) is proposed. The training sample is synthesized by this algorithm according to the Retinex model. Then, the original low-light image is converted from RGB (Red Green Blue) space to HSI (Hue Saturation Intensity) color space. The luminance component is enhanced by using the DCNN while keeping the chrominance component and the saturation component unchanged. Finally, the image is turned back to the RGB space from HSI color space to get the finally enhanced image. The experimental results show that, compared with the existing excellent image enhancement algorithms, the proposed algorithm can not only effectively enhance the brightness and the contrast, but also can avoid the color distortion and the over-enhancement, and both the subjective vision and objective evaluation index are further improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Retinex%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Retinex model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=batch%20normalization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">batch normalization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="73" name="73" class="anchor-tag">1 引 言</h3>
                <div class="p1">
                    <p id="74">在夜间等低照度环境下拍摄的图像, 由于其亮度、对比度较低且含有噪声, 不仅肉眼难以分辨, 也给后续图像处理 (如目标检测、视频监控等) 带来了严峻挑战<citation id="161" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。因此, 低照度图像增强一直是计算机领域的热点之一, 具有十分重要的理论意义和应用价值。</p>
                </div>
                <div class="p1">
                    <p id="75">目前, 国内外已有很多低照度图像增强算法相继被提出, 广泛使用的有三类:1) 基于直方图均衡化 (HE) 的方法。HE的基本思想是保持像素值之间的相对关系并使其服从均匀分布。对比度受限的自适应HE法通过限制局部直方图的高度来限制局部对比度的增强幅度, 从而限制局部对比度的过增强<citation id="162" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。这类方法能有效提高对比度且处理速度快, 但易出现色偏现象, 同时由于灰度级合并而丢失细节信息。2) 基于Retinex理论的方法<citation id="163" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 此类方法是一种目前比较流行的低照度图像增强算法。该理论认为:人眼观察到的图像可以表示为光照分量与反射分量的乘积, 光照分量反映的是光照的情况, 而反射分量才是图像的固有属性。通过原始图像估计出光照分量并将其去除, 从而可获得反射分量, 实现图像增强<citation id="164" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。因此, 如何准确估计出光照分量是Retinex算法的核心步骤之一, 研究人员先后采用不同的光照分量估计方法提出了不同的Retinex算法。其中最经典的有单尺度Retinex (SSR) 算法<citation id="165" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、多尺度Retinex (MSR) 算法<citation id="166" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和带色彩恢复的MSR (MSRCR) 算法。SSR算法只对图像做了高斯滤波估计, MSR算法则可以看成多个不同尺度的SSR线性加权求和<citation id="167" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 能够较好地提高图像的对比度和亮度, 但也会使图像边缘锐化不足, 部分颜色发生扭曲。MSRCR算法在MSR算法基础上引入了颜色恢复, 使得增强后的图像不会出现失真的现象, 但图像的颜色会偏离原始色彩, 整体颜色偏白<citation id="168" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。近年来, 也有一些基于Retinex理论的新算法被提出, 如Fu等<citation id="169" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种加权变分模型, 即SRIE (Simultaneous Reflectance and Illumination Estimation) , 同时估计光照分量和反射分量;Guo等<citation id="170" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了LIME (Low-light Image Enhancement via Illumination Map Estimation) 算法, 即先在原始低照度图像红 (R) 、绿 (G) 、蓝 (B) 三个通道中取最大值得到光照图, 再通过结构先验不断修正原始光照图, 从而得到最终的光照图像。3) 基于去雾模型的方法。Dong等<citation id="171" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>于2011年发现低照度图像反转后与雾天图像有很高的相似性, 提出采用去雾方法实现低照度图像增强, 取得了较好的增强效果, 给后续此类方法<citation id="172" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>提供了重要理论支撑。此类方法虽能够在一定程度上提高视觉质量, 但增强后的图像往往不符合实际场景, 且容易在边缘出现伪影。</p>
                </div>
                <div class="p1">
                    <p id="76">此外, 也有一些算法是将图像RGB (Red Green Blue) 色彩空间转换到其他色彩空间实现图像增强<citation id="175" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>, 可有效保持图像的色彩, 防止增强后图像色彩严重失真, 但亮度和对比度仍有待提高。最近, 深度学习技术在图像分类<citation id="173" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、检测与跟踪<citation id="176" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>等领域取得了巨大成功, 引发了学术界和工业界研究的热潮。深度学习是通过建立类似人脑信息处理机制的网络模型, 采取高效的学习策略逐级提取数据特征, 拟合复杂的非线性函数。文献<citation id="174" type="reference">[<a class="sup">18</a>]</citation>尝试利用深度神经网络栈式稀疏降噪自编码器对灰度图像进行了增强, 证实了深度学习方法的可行性。而卷积神经网络 (CNN) 作为深度学习中的代表性模型, 其局部感受野、权值共享和池化三大结构的优势不仅减少了训练参数、降低了训练难度, 还对缩放、旋转和平移等各种扭曲不变性图像具有良好的稳健性, 使提取到的深层次特征具有更强的泛化能力。</p>
                </div>
                <div class="p1">
                    <p id="77">鉴于以上分析, 本文提出了一种有效的低照度图像增强算法, 该方法首先将原始低照度图像由RGB空间转换到HSI (Hue Saturation Intensity) 颜色空间, 利用深度CNN (DCNN) 对亮度分量进行增强。实验结果表明, 所提算法相比于其他主流算法, 不仅能够明显增强亮度和对比度, 还能够保持图像色彩信息不变, 在视觉感知和客观评价指标上均得到了进一步提高。</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag">2 理论模型</h3>
                <h4 class="anchor-tag" id="79" name="79"><b>2.1</b><b>Retinex模型</b></h4>
                <div class="p1">
                    <p id="80">Retinex理论是由Land<citation id="177" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>在20世纪70年代提出, 该模型认为物体的颜色是由物体表面的反射属性决定的, 而与光照情况无关。Retinex模型可以用函数描述为</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">R</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">式中:<b><i>S</i></b> (<i>x</i>, <i>y</i>) 为人眼观察到的低照度图像, <b><i>L</i></b> (<i>x</i>, <i>y</i>) 为反映外界光照环境的光照分量, <b><i>R</i></b> (<i>x</i>, <i>y</i>) 为反映物体本质属性的反射分量。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>2.2</b><b>HSI颜色模型</b></h4>
                <div class="p1">
                    <p id="84">目前, 绝大部分彩色图像增强算法是基于RGB三基色模型, 对R、G、B三个颜色通道分别进行处理, 再合成彩色图像。然而<i>R</i>、<i>G</i>、<i>B</i>三个分量具有很强的相关性, 若三者比例发生变化, 会造成色彩失真。HSI颜色空间采用色度 (H) 、饱和度 (S) 和亮度 (I) 来表征色彩, 色度是色彩属性, 饱和度给出一种纯色被白光稀释程度的度量, 亮度即颜色的明亮程度。HSI颜色空间有两个重要特性:1) <i>I</i>分量的改变不会影响图像的颜色信息;2) <i>H</i>和<i>S</i>分量与人感受彩色的方式紧密相连, 更符合人类视觉感受外界的知觉特性。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.3</b><b>卷积神经网络</b></h4>
                <div class="p1">
                    <p id="86">如图1所示, 典型的CNN一般由输入层、卷积层 (Conv) 、池化层、全连接层 (FC) 和输出层组成。</p>
                </div>
                <div class="p1">
                    <p id="87">为提取输入数据的不同特征, 往往采用多个卷积核与输入图像进行卷积, 得到若干个特征图, 卷积层的产生过程可描述为</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>j</mi><mi>l</mi></msubsup><mo>=</mo><mi>f</mi><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mi mathvariant="bold-italic">x</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo>*</mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>+</mo><mi mathvariant="bold-italic">b</mi><msubsup><mrow></mrow><mi>j</mi><mi>l</mi></msubsup></mrow><mo>) </mo></mrow><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">式中:<b><i>x</i></b><sup><i>l</i></sup><sub><i>j</i></sub>和<b><i>x</i></b><sup><i>l</i>-1</sup><sub><i>i</i></sub>分别为卷积层<i>l</i>的第<i>j</i>个输出特征图和卷积层<i>l</i>-1的第<i>i</i>个输出特征图, <b><i>W</i></b><sup><i>l</i></sup><sub><i>ij</i></sub>为卷积层<i>l</i>的第<i>i</i>个特征图与卷积层<i>l</i>-1的第<i>j</i>个特征图相连的卷积核, <b><i>b</i></b><sup><i>l</i></sup><sub><i>j</i></sub>为卷积层<i>l</i>的第<i>j</i>个特征图的偏置, <b><i>M</i></b><sub><i>j</i></sub>为当前任意一个输入特征图子集, *表示卷积运算, <i>f</i>为激活函数。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CNN的典型结构" src="Detail/GetImg?filename=images/GXXB201902012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 CNN的典型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Typical structure of CNN</p>

                </div>
                <div class="p1">
                    <p id="92">卷积层后面通常为池化层, 依据一定的下采样规则对特征图进行下采样, 目的是实现特征图降维并保持特征的尺度不变性。经过多个卷积层和池化层的交替传递, 最后通过FC输出用于识别图像的特征。</p>
                </div>
                <h3 id="93" name="93" class="anchor-tag">3 基于DCNN的图像增强</h3>
                <h4 class="anchor-tag" id="94" name="94"><b>3.1</b><b>图像增强算法模型</b></h4>
                <div class="p1">
                    <p id="95">针对当前低照度图像增强算法的缺陷, 结合色彩模型变换算法和CNN的优势, 对低照度图像进行增强。首先将低照度图像从RGB空间变换到HSI颜色空间, 然后保持色度分量<i>H</i>和饱和度分量<i>S</i>不变, 利用DCNN对亮度分量<i>I</i>进行增强, 最后再转换到RGB空间, 得到最终的增强图像。所提算法流程如图2所示。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 所提算法流程" src="Detail/GetImg?filename=images/GXXB201902012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 所提算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Flow chart of proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>3.2</b><b>亮度增强</b></h4>
                <div class="p1">
                    <p id="98">与一般深度学习方法不同, 所提方法并非直接利用DCNN在RGB空间通过训练学习低照度图像和正常光照图像之间的端到端的映射关系, 而是在HSI颜色空间只对亮度分量进行增强, 这是由于前者在训练中还需考虑色彩的变化, 而所提算法很好地避免了这一问题, 从而更有利于网络训练。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">3.2.1 网络结构</h4>
                <div class="p1">
                    <p id="100">提出的DCNN与一般CNN结构不同, 没有池化层和FC。网络模型如图3所示, 主要由输入、特征提取、非线性映射、重建和输出5部分组成。</p>
                </div>
                <div class="p1">
                    <p id="101">由于本文网络模型学习的是低照度图像与正常光照图像之间的映射关系, 要求网络输出与输入图像尺寸大小一致。而采样层会使采样前后图像大小不一致, 不利于图像增强任务的实现;另外, 卷积层也会使图像在卷积操作前后大小不一致, 丢失边界信息。因此, 在所有卷积层前先进行零填充操作, 这样就保证了图像在网络的传递过程中大小始终保持不变。</p>
                </div>
                <div class="p1">
                    <p id="102">1) 输入和输出。为便于网络更好地训练, 所提网络输入和输出并非整幅图像, 而是随机选取低照度图像块和与之相对应的正常光照图像块作为训练样本;同时, 该模型只对亮度分量进行增强, 因此输入的是低照度图像的亮度分量, 输出的是增强后的亮度分量。</p>
                </div>
                <div class="p1">
                    <p id="103">2) 特征提取。该网络第一部分的作用为特征提取, 由卷积层组成。卷积层往往通过多个可学习的卷积核与输入层图像或者上一层特征图进行卷积运算, 提取出多个不同局部区域的特征, 并经过非线性激活函数作用得以实现。用<b><i>H</i></b><sub><i>d</i></sub>表示CNN第<i>d</i>层特征图, 设网络输入图像块为<b><i>X</i></b>, 特征提取用函数表示为</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>max</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>1</mn></msub><mo>*</mo><mi mathvariant="bold-italic">X</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">式中:<b><i>W</i></b><sub>1</sub>为卷积核, <b><i>b</i></b><sub>1</sub>∈<b>R</b><sup><i>n</i><sub>1</sub></sup>表示神经元偏置向量。<b><i>X</i></b>尺寸大小为<i>n</i>×<i>n</i>, 设<i>f</i><sub>1</sub>为单个卷积核的尺寸, <i>c</i>为输入图像的通道数 (只对亮度分量进行处理, 因此<i>c</i>=1) , max (·) 表示取最大值。如果有<i>n</i><sub>1</sub>个卷积核, 则<b><i>W</i></b><sub>1</sub>的尺寸大小为<i>f</i><sub>1</sub><i>f</i><sub>1</sub><i>n</i><sub>1</sub><i>c</i>。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 DCNN模型的网络结构" src="Detail/GetImg?filename=images/GXXB201902012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 DCNN模型的网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Network structure of DCNN model</p>

                </div>
                <div class="p1">
                    <p id="108">经过网络模型第一层卷积运算和非线性函数激励, 便可以从低照度图像亮度分量中提取出数据不同方面的特征。</p>
                </div>
                <div class="p1">
                    <p id="109">3) 非线性映射。非线性映射记作convolutional module, 由卷积层、批归一化 (BN) 层和ReLu (Rectified Linear Units) <citation id="178" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>激励层组成。2015年, Ioffe等<citation id="179" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出使用BN算法对CNN中所有中间层的输出数据进行BN处理, 可以减小网络中间数据分布的改变对神经网络参数训练的影响, 从而加快神经网络的收敛速度和稳定性。</p>
                </div>
                <div class="p1">
                    <p id="110">设网络某隐藏层输入数据集合为{<i>μ</i><sub>1</sub>, …, <i>μ</i><sub><i>m</i></sub>}, 该批样本个数为<i>m</i>, 首先分别求得输入样本的均值<i>E</i> (<i>μ</i>) 和方差<i>D</i> (<i>μ</i>) 为</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi mathvariant="bold-italic">μ</mi></mstyle><msub><mrow></mrow><mi>h</mi></msub><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>D</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mi>h</mi></msub><mo>-</mo><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">然后对批样本数据进行归一化处理, 得到服从均值为0、方差为1的数据分布<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">μ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>h</mi></msub></mrow></math></mathml>, 即</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">μ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mi>h</mi></msub><mo>-</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>μ</mi><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">ε</mi></mrow></msqrt></mrow></mfrac><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">式中:为避免分式分母为0, 通常取<i>ε</i>为一个接近于0的正数。</p>
                </div>
                <div class="p1">
                    <p id="116">最后引入重构参数<i>α</i>和<i>β</i>对BN后的数据进行重构变换, 得到最终的输出数据<b><i>z</i></b><sub><i>h</i></sub>为</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mi>B</mi><mi>Ν</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">α</mi><mo>, </mo><mi mathvariant="bold-italic">β</mi></mrow></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">μ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">α</mi><mover accent="true"><mi mathvariant="bold-italic">μ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>h</mi></msub><mo>+</mo><mi mathvariant="bold-italic">β</mi><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">经过非线性映射, 能够将由所提网络第一层提取出来的低照度图像的亮度分量特征由低维空间映射到高维空间, 使底层特征更加抽象。这一过程用函数表示为</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Η</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>max</mi><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mi>B</mi><mi>Ν</mi><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>*</mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>k</mi><mo>≥</mo><mn>3</mn><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">式中:<i>k</i>为所提网络的深度, 即第<i>k</i>-1层为非线性映射部分的最后一层。在此需说明, 在所提网络中进行BN操作是以特征图为单位, 而并非单个神经元, 这样可以大大减少重构变换引入的<i>α</i>和<i>β</i>。</p>
                </div>
                <div class="p1">
                    <p id="121">4) 重建。对低照度图像进行增强是基于重建的思想。重建是指通过训练使模型输出与正常光照图像的亮度分量误差最小, 从而实现图像增强。在本层中, 只用一个卷积层便能够实现重建, 用函数描述为</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>k</mi></msub><mo>*</mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>k</mi></msub><mo>。</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">为了通过训练自动学习网络模型参数<i>θ</i>={<b><i>W</i></b><sub>1</sub>, …, <b><i>W</i></b><sub>k</sub>;<b><i>b</i></b><sub>1</sub>, …, <b><i>b</i></b><sub>k</sub>}, 假设给定训练样本集<i>D</i>={ (<b><i>X</i></b><sub>1</sub>, <b><i>Y</i></b><sub>1</sub>) , …, (<b><i>X</i></b><sub><i>η</i></sub>, <b><i>Y</i></b><sub><i>η</i></sub>) }, 其中<b><i>X</i></b><sub><i>η</i></sub>和<b><i>Y</i></b><sub><i>η</i></sub>分别为第<i>η</i>个输入的低照度图像亮度分量和与之相对应的正常光照图像亮度分量 (即Ground truth) 样本, 利用反向传播算法和随机梯度下降法最小化如下目标函数</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>η</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>Η</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>η</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>η</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>‚</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">式中:<i>N</i>为训练样本的数目;<i>λ</i>为权重约束项, 可以防止过拟合。</p>
                </div>
                <div class="p1">
                    <p id="126">一旦训练学习得到最优参数<i>θ</i>, 网络便训练结束, 在测试时只需要输入一幅低照度图像的亮度分量, 网络模型即可根据<i>θ</i>计算得到一幅增强后的亮度分量。</p>
                </div>
                <h3 id="127" name="127" class="anchor-tag">4 实验结果分析</h3>
                <h4 class="anchor-tag" id="128" name="128"><b>4.1</b><b>样本制作</b></h4>
                <div class="p1">
                    <p id="129">目前基于深度学习的低照度图像增强仍处于起步阶段, 其中一个很重要的原因是深度学习方法需要大量的训练样本, 而拍摄低照度图像和与之属于同一场景的正常光照图像非常困难, 严重制约了深度学习技术在图像增强方面的研究和应用。为此, 本文提出了一种易于操作且耗时较少的训练样本产生方法。</p>
                </div>
                <div class="p1">
                    <p id="130">由 (1) 式可以看出, 低照度图像是光照分量与反射分量 (正常光照图像) 的乘积。然而真实低照度图像场景更加复杂, 有光照均匀和不均匀之分。为了尽可能涵盖大多数场景的低照度图像, 训练样本图像块的选取也很关键。如果图像块过小, 这些图像块拼接而成的整幅图像边缘部分过于突出, 与真实低照度图像不符;如果图像块太大, 又忽略了真实低照度图像中光照不均匀的情况, 鉴于此, 实验从计算机视觉领域的公开数据集Berkeley Segmentation Dataset<citation id="180" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>中收藏了总计500幅光照条件较好的图像作为反射分量 (即Ground truth) , 并从中随机选取总共256000个尺寸为40 pixel×40 pixel的图像块, 然后让光照分量<b><i>L</i></b>服从均匀分布<b><i>L</i></b>～<i>U</i> (0, 1) , 则合成的低照度图像块可表示为<b><i>S</i></b> (<i>x</i>, <i>y</i>) =<b><i>LR</i></b> (<i>x</i>, <i>y</i>) 。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131"><b>4.2</b><b>实验设置</b></h4>
                <div class="p1">
                    <p id="132">算法训练是以Matlab R2014为仿真平台, 采用MatConvNet<citation id="181" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>深度学习开源框架, 计算机的CPU (Central Processing Unit) 为美国Intel Core i7-7700, 主频为3.6 GHz, 内存为16 G, GPU (Graphics Processing Unit) 为NVIDIA GTX1070。</p>
                </div>
                <div class="p1">
                    <p id="133">网络深度为7层, 单个卷积核的尺寸为3 pixel×3 pixel, 其网络框架中特征提取部分卷积核的个数为64, 尺寸为3 pixel×3 pixel×64 pixel;非线性映射部分中所有卷积核的个数均为64, 尺寸为3 pixel×3 pixel×64 pixel×64 pixel;重建部分只有1个卷积核, 尺寸为3 pixel×3 pixel×64 pixel。网络所有层的卷积核均采用文献<citation id="182" type="reference">[<a class="sup">23</a>]</citation>中的初始化方法, 偏置项初始化为0;采用Adam算法训练模型, 批训练样本为128, 学习率的初始值设为0.1, 并且每经过10个训练周期将会减小1/10, 总计训练50个训练周期。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"><b>4.3</b><b>实验参数的选取</b></h4>
                <div class="p1">
                    <p id="135">由于本文提出的网络结构不含池化层, 因此不同的网络层数以及卷积层中卷积核的尺寸、数目直接影响模型性能的好坏。依据牛津大学VGG (Visual Geometry Group) 小组对深度卷积网络的实验结果和经验, 对于VGG_ILSVRC_16_layers模型, 第一层使用3 pixel×3 pixel大小的卷积核, 能够有效减少参数数目<citation id="183" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。在超分辨率CNN (SRCNN) 算法中, 第二层卷积核尺寸越大, 超分辨率效果越好, 但同时会增大运算量。在重建部分卷积层中, 缩小卷积核的尺寸可能会影响重建图像的质量。鉴于此, 除重建部分卷积层以外, 还将所有的卷积核的尺寸设置为3 pixel×3 pixel, 这样既能够提升增强效果, 也不会造成运算量大幅增加。为验证最后一层卷积核尺寸对网络性能的影响, 实验设定网络层数为3层, 分别对以下3种模型3-3-1、3-3-3和3-3-5 (其中末尾数字1表示最后一层卷积核尺寸为1 pixel×1 pixel, 3和5同理) 进行训练和测试, 实验结果表明, 在经过10个训练周期后, 3-3-3模型在测试过程中比3-3-5模型总计少耗时62.59 s, 输出图像的平均峰值信噪比 (PSNR) 较3-3-5网络模型提高了0.35 dB;3-3-3模型在测试过程中比3-3-1模型总计多耗时约30 s, 而输出图像的平均PSNR较3-3-1网络模型提高了0.29 dB。</p>
                </div>
                <div class="p1">
                    <p id="136">为综合考虑处理效果和运算速率, 本文所有卷积核尺寸均选择3 pixel×3 pixel, 这样即能缩短训练时间, 也不会对输出图像的质量造成较大的影响。在学习速率和卷积核尺寸不变的条件下, 本文还对卷积核的数目以及网络层数进行了实验分析, 训练50个训练周期后对图4 (a) 进行测试, 得到增强后输出图像的PSNR, 实验结果见表1, 其中<i>n</i><sub>1</sub>为第一个卷积层中卷积核的数目, <i>n</i><sub><i>p</i>-1</sub> (<i>p</i>≥3) 为后面所有卷积层中卷积核的数目。</p>
                </div>
                <div class="area_img" id="137">
                    <p class="img_tit">表1 不同网络层数和卷积核数目下的测试PSNR值 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Tested PSNR under different network layers and convolution kernel numbers</p>
                    <p class="img_note"></p>
                    <table id="137" border="1"><tr><td><br />Number of <br />layers</td><td>Number of convolution <br />kernels</td><td>PSNR /dB</td></tr><tr><td><br />5</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=32</td><td>21.74</td></tr><tr><td><br />5</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=64</td><td>21.87</td></tr><tr><td><br />7</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=32</td><td>22.23</td></tr><tr><td><br />7</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=64</td><td>22.31</td></tr><tr><td><br />9</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=32</td><td>22.04</td></tr><tr><td><br />9</td><td><i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=64</td><td>22.17</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="138">借鉴文献<citation id="184" type="reference">[<a class="sup">24</a>]</citation>中SRCNN结构中不同层卷积核数目的设置方法, 实验选取<i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=32和<i>n</i><sub>1</sub>=64, <i>n</i><sub><i>p</i>-1</sub>=64进行对比分析, 网络层数有3, 5, 7, 9层。由表1可知, 随着卷积核数目的增加, 模型性能也会提高, 但是增加卷积核的数目无疑增加了计算量;还可以发现当网络层数为7层时, 模型输出的图像PSNR值最高, 网络层数的增加并不一定会提高模型性能, 这是因为对原始网络结构进行简单堆积可能致使其结构不合理, 同样梯度弥散现象也会随着层数的增加而越发严重。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139"><b>4.4</b><b>实验分析</b></h4>
                <div class="p1">
                    <p id="140">为验证所提算法的有效性, 将对合成的低照度图像和实际低照度图像分别进行实验, 从客观和主观两方面进行对比分析, 对比经典算法HE<citation id="185" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>和近几年增强效果好的Dong、SRIE和LIME算法。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141">4.4.1 合成低照度图像实验</h4>
                <div class="p1">
                    <p id="142">首先对人工合成的低照度图像进行实验, 测试样本选取计算机视觉领域公开数据集LIVE1<citation id="186" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>进行人工合成低照度图像, 总计29幅图片, 实验结果如图4和表2所示。</p>
                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同算法在合成低照度图像上的主观视觉对比。 (a) 图像“caps”; (b) 图像“carnivaldolls”; (c) 图像“cemetry”; (d) 图像“building 2”" src="Detail/GetImg?filename=images/GXXB201902012_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同算法在合成低照度图像上的主观视觉对比。 (a) 图像“caps”; (b) 图像“carnivaldolls”; (c) 图像“cemetry”; (d) 图像“building 2”  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Subjective visual comparison of different methods for synthetic low-light images. (a) Image “caps”; (b) image “carnivaldolls”; (c) image “cemetry”; (d) image “building 2”</p>

                </div>
                <div class="area_img" id="144">
                    <p class="img_tit">表2 不同算法在合成低照度图像上的客观评价指标 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Objective evaluation index of different methods for synthetic low-light images</p>
                    <p class="img_note"></p>
                    <table id="144" border="1"><tr><td><br />Method</td><td>PSNR /dB</td><td>SSIM</td><td>MSE</td><td>LOE</td></tr><tr><td><br />HE<sup>[25]</sup></td><td>16.19</td><td>0.7985</td><td>1928.3</td><td>505</td></tr><tr><td><br />Dong<sup>[10]</sup></td><td>16.29</td><td>0.7947</td><td>1699.6</td><td>2040</td></tr><tr><td><br />SRIE<sup>[8]</sup></td><td>21.08</td><td>0.9579</td><td>686.4</td><td>776</td></tr><tr><td><br />LIME<sup>[9]</sup></td><td>13.47</td><td>0.8097</td><td>3230.7</td><td>1277</td></tr><tr><td><br />Proposed method</td><td>22.23</td><td>0.9204</td><td>389.0</td><td>402</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="145">在主观评价中, 选取LIVE1数据集中4幅图像为例来进行说明, 从上到下分别记作图4 (a) ～ (d) 。其中图4 (a) 、 (b) 均为光照均匀的低照度图像, 图4 (c) 、 (d) 为光照不均匀的图像。由图4可以看出, Dong、SRIE、LIME算法和所提算法均能够对合成的低照度图像进行增强, 改善了人的主观感受。通过观察图4 (a) 、 (c) 和 (d) , 可以发现Dong算法得到的图像在边缘处有明显的轮廓, 如图4 (a) 中帽子下方原本是阴影, 但增强后出现了严重的轮廓线, 图4 (c) 、 (d) 中树枝也变得不太符合实际场景, 像雕刻在上面一样。SRIE算法能够很好地保持图像色彩, 且不会出现轮廓现象, 但提高亮度能力有限。图4 (b) 中Ground truth大片白色区域经暗化操作后, 增强效果不明显, 图像亮度仍较暗。LIME算法处理后图像整体偏亮, 且会出现程度不等的色彩失真。图4 (c) 、 (d) 中花草颜色泛黄, 而Ground truth中为绿色, 与原始光照较好的图像有一定的差距。所提算法不仅能够提高图像的亮度和对比度, 还能够保持图像色彩信息基本不变, 更加接近正常光照下的原始图像。但所提算法仍然与其他算法一样, 并不能有效增强实际场景是大片白色区域的黑暗部分。此外, 所提算法对光照均匀的低照度图像增强效果最好, 但对于非均匀光照图像, 整体亮度稍暗, 这是由于Retinex模型仍相对简单, 不足以描述复杂的低照度场景, 且由于利用深度学习算法的这类任务大多采取的损失函数为均方误差 (MSE) , 因此并不能涵盖所有图像像素点。</p>
                </div>
                <div class="p1">
                    <p id="146">在对合成低照度图像进行客观评价时, 由于Ground truth已知, 因此可以比较采用不同算法增强后的图像与参考图像Ground truth之间的差异来说明算法的性能优劣。实验选取PSNR、结构相似度 (SSIM) 、MSE和LOE (Lightness Order Error) <citation id="187" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>作为客观评价指标。其中, PSNR反映图像的失真程度, 其值越高, 表示失真程度越小。SSIM表征图像结构信息的完整性, 其值越高, 表明增强后图像与Ground truth的结构特征越相似。MSE反映了增强后图像与Ground truth之间的差距, 其值越小说明增强后图像越接近原始正常光照图像。LOE主要评价增强后图像的自然度保持能力, 数值越小则图像的亮度顺序保护得越好, 图像越自然。表2给出了采用不同增强算法时在LIVE1数据集上获得的一些评价指标的平均值。</p>
                </div>
                <div class="p1">
                    <p id="147">由表2可知, 本文所提算法除了SSIM低于SRIE算法外, PSNR、MSE和LOE三个评价指标均高于其他算法, 说明本文所提算法更加接近原始图像, 失真程度较小, 同时增强后的图像更加真实自然, 验证了所提算法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="148">此外, 为进一步验证所提算法和直接对RGB图像增强这两种算法的性能优劣, 本文在有BN和无BN的情况下分别训练网络总计达50个训练周期, 在测试集LIVE1上进行了两组对照实验, 记录了每个训练周期下网络测试获得的平均PSNR和SSIM, 实验结果如图5所示。</p>
                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 有/无BN条件下HSI和RGB增强方法的收敛速度。 (a) 50个训练周期的平均SSIM; (b) 50个训练周期的平均PSNR" src="Detail/GetImg?filename=images/GXXB201902012_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 有/无BN条件下HSI和RGB增强方法的收敛速度。 (a) 50个训练周期的平均SSIM; (b) 50个训练周期的平均PSNR  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Convergence performance of HSI and RGB enhancement methods with BN and without BN. (a) Average SSIM within 50 epochs; (b) average PSNR within 50 epochs</p>

                </div>
                <div class="p1">
                    <p id="150">通过图5可以看出, 在有BN和无BN时, 采用HIS训练方法比直接对RGB图像进行增强更加容易收敛且获得的平均PSNR和SSIM值更高;同时也能看出, BN能够有效提高网络训练的收敛速度, 获得更好的效果。</p>
                </div>
                <h4 class="anchor-tag" id="151" name="151">4.4.2 实际低照度图像实验</h4>
                <div class="p1">
                    <p id="152">为了验证本文增强算法不仅对人工合成的低照度图像有效, 还能够增强实际拍摄的低照度图像, 具有更好的稳健性, 实验从低照度图像数据库NASA<citation id="188" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>、DICM<citation id="189" type="reference"><link href="67" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>和VV<citation id="190" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>中选取了17幅典型图像进行测试, 实验结果如图6和表3所示。</p>
                </div>
                <div class="p1">
                    <p id="153">在主观评价中, 以5幅图为例来对实验结果进行对比和分析, 从上到下依次记为图6 (a) ～ (e) 。从图6 (a) 、 (c) 和 (d) 中可以看出, HE算法虽然能够扩大图像的动态范围, 提高图像的整体亮度和对比度, 但过饱和会导致严重的色偏现象。从图6 (a) 中可明显观察到天空颜色泛白, 而原始图像为蓝色, 同时树木颜色也不再是绿色, 整体泛黄;此外, 图6 (c) 、 (d) 中同样出现了类似的色彩失真现象。Dong算法增强后图像色彩保持较好, 但是出现了严重的边缘效应。从图6 (a) 中的树木、石碑和图6 (c) 中的人脸图像中均可以看到在这些要素的边缘处有明显的黑色线条, 图像十分不自然。这是由于Dong算法将去雾的方法用于图像增强, 而低照度图像反转后与雾天图像并不完全相同, 且不能准确估计伪雾图的大气光值。而SRIE算法只对亮度较暗的区域有效, 但是对黑暗区域并不能提高其亮度, 细节信息很难分辨清楚, 图6 (a) 中树木和图6 (b) 中的人脸图像在增强后亮度仍然较暗。LIME算法很好地改善了黑暗区域的亮度, 图像整体亮度提高, 色彩也更加鲜艳, 然而该算法会很容易出现过增强现象, 同时也会造成一定的色彩失真。如图6 (a) 中树叶颜色与原始图像不符, 颜色泛黄, 且石碑有明显的黄色伪影。此外, 图6 (e) 中的小女孩右半部分脸由于原本就处于曝光情况下, 而LIME算法不管区域是否黑暗, 均会对图像进行增强, 因此, 可以看到小女孩右半部分脸被过度增强, 不符合人眼视觉感知。而所提算法可以很好地保持色彩并改善过增强现像, 但对黑暗区域亮度提升程度低于LIME算法。</p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201902012_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法在真实低照度图像上的主观视觉对比。 (a) 图像来自数据库DICM; (b) 图像来自数据库VV; (c) ～ (d) 图像来自数据库NASA; (e) 图6 (d) 中蓝框区域放大图" src="Detail/GetImg?filename=images/GXXB201902012_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法在真实低照度图像上的主观视觉对比。 (a) 图像来自数据库DICM; (b) 图像来自数据库VV; (c) ～ (d) 图像来自数据库NASA; (e) 图6 (d) 中蓝框区域放大图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201902012_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Subjective visual comparison of different methods for real low-light images. (a) Image from DICM dataset; (b) image from VV dataset; (c) - (d) image from NASA dataset; (e) enlarged result of part shown in blue box of Fig. 6 (d) </p>

                </div>
                <div class="area_img" id="155">
                    <p class="img_tit">表3 不同算法在真实低照度图像上的客观评价指标 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Objective evaluation index of differentmethods for real low-light images</p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />Method</td><td>Entropy of <br />information</td><td>Degree of <br />chromaticity <br />change</td><td>LOE</td><td>VIF</td></tr><tr><td><br />HE<sup>[25]</sup></td><td>7.1412</td><td>0.2474</td><td>571</td><td>0.4782</td></tr><tr><td><br />Dong<sup>[10]</sup></td><td>6.9541</td><td>0.0313</td><td>1484</td><td>0.4262</td></tr><tr><td><br />SRIE<sup>[8]</sup></td><td>6.9542</td><td>0.0045</td><td>972</td><td>0.6153</td></tr><tr><td><br />LIME<sup>[9]</sup></td><td>7.2612</td><td>0.0124</td><td>1390</td><td>0.3444</td></tr><tr><td><br />Proposed method</td><td>7.1425</td><td>0.0032</td><td>378</td><td>0.7356</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">在对真实低照度图像进行客观评价时, 由于没有相同场景的光照较好的图像作为参考, 属于无参考客观质量评价范畴。选用信息熵、色度改变程度、LOE和视觉信息保真度 (VIF) 对增强图像进行客观评价。其中, 信息熵表征图像信息量的大小, 其值越大则图像信息越丰富, 细节保持越好;色度改变程度反映了增强后图像色彩保持情况, 其值越小说明色彩失真越小;VIF是结合自然图像统计模型、图像失真模型和人眼视觉系统模型提出的图像质量评价指标, 其值越大, 表明图像质量越好<citation id="191" type="reference"><link href="71" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>。表3给出了使用不同算法对17幅低照度图像进行增强后的各种客观评价指标的平均值。</p>
                </div>
                <div class="p1">
                    <p id="158">从表3中可知, HE算法和Dong算法具有更高的色度改变值, 表明增强图像的色彩保持能力最差, 这是因为它们分别在R、G、B三个通道直接进行处理使得各颜色通道增幅不一, 引起颜色失真。LIME算法具有更高的信息熵, 说明该算法得到的图像包含的信息更多, 但是其LOE值较大, 说明图像的亮度顺序遭到破坏, 自然度保持较差。而SRIE算法的信息熵最低, 对低照度图像进行增强后, 细节信息不明显。所提算法除了信息熵低于LIME算法, 在其他三个评价指标上均优于其他算法的, 说明利用所提算法增强后的图像色彩保持较好, 具有更好的自然度。</p>
                </div>
                <h3 id="159" name="159" class="anchor-tag">5 结 论</h3>
                <div class="p1">
                    <p id="160">针对当前主流低照度图像增强算法在提高亮度、对比度时易产生色彩失真现象, 本文首先从人眼视觉特性出发, 将低照度图像从RGB空间转换到HSI颜色空间, 然后充分利用类似人脑信息处理机制的DCNN所具有从海量数据中提取数据本质特征并拟合复杂函数的强大学习能力, 保持色度分量和饱和度分量不变, 基于一种端到端的思想学习低照度图像亮度分量与理想照度图像的亮度分量之间的映射关系, 从而得到增强的亮度分量, 最后再由HSI颜色空间转换到RGB空间。实验结果表明, 所提算法在提高亮度和对比度的同时, 也很好地避免了色彩失真现象, 增强效果优于目前主流的低照度图像增强算法, 具有一定的理论借鉴意义。今后将继续优化网络模型, 进一步提高黑暗区域的亮度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="11">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201502040&amp;v=MjU3NzVxcUJ0R0ZyQ1VSN3FmWnVadEZpRGtVTHpLTHlmUmRMRzRIOVRNclk5QlpJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Li Q Z, Liu Q. Adaptive enhancement algorithm for low illumination images based on wavelet transform[J]. Chinese Journal of Lasers, 2015, 42 (2) : 0209001.  李庆忠, 刘清. 基于小波变换的低照度图像自适应增强算法[J]. 中国激光, 2015, 42 (2) : 0209001
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805013&amp;v=MjA2MDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMektMeXJQWkxHNEg5bk1xbzlFWjRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Fei Y J, Shao F. Contrast adjustment based on image retrieval[J]. Laser &amp; Optoelectronics Progress, 2018, 55 (5) : 051002. 费延佳, 邵枫. 基于图像检索的对比度调整[J]. 激光与光电子学进展, 2018, 55 (5) : 051002.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The retinex theory of color vision">

                                <b>[3]</b> Land E H. The retinex theory of color vision[J]. Scientific American, 1977, 237 (6) : 108-128.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201801001&amp;v=MTM1OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGtVTHpLSWk3ZmRyRzRIOW5Ncm85RlpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Zhang J, Zhou P C, Zhang Q. Low-light image enhancement based on iterative multi-scale guided filter Retinex[J]. Journal of Graphics, 2018, 39 (1) : 1-11. 张杰, 周浦城, 张谦. 基于迭代多尺度引导滤波Retinex的低照度图像增强[J]. 图学学报, 2018, 39 (1) : 1-11.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Properties and performance of a center/surround retinex">

                                <b>[5]</b> Jobson D J, Rahman Z, Woodell G A. Properties and performance of a center/surround retinex[J]. IEEE Transactions on Image Processing, 1997, 6 (3) : 451-462.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700100098&amp;v=MTE0MjdPZmJLOEg5RE1xSTlGWmVzUERIVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyekpLRjhYYVJBPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Lin H, Shi Z.Multi-scale retinex improvement for nighttime image enhancement[J]. Optik-International Journal for Light and Electron Optics, 2014, 125 (24) : 7143-7148.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201712022&amp;v=MTU3OTJyWTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMektJVGZTZHJHNEg5Yk4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Chen Y, Zhan D, Liu H L. Enhancement algorithm for low-lighting images based on physical model and boundary constraint[J]. Journal of Electronics &amp; Information Technology, 2017, 39 (12) : 2962-2969. 陈勇, 詹帝, 刘焕淋. 基于物理模型与边界约束的低照度图像增强算法[J]. 电子与信息学报, 2017, 39 (12) : 2962-2969.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A weighted variational model for simultaneous reflectanceand illumination estimation">

                                <b>[8]</b> Fu X Y, Zeng D L, Huang Y, <i>et al</i>. A weighted variational model for simultaneous reflectance and illumination estimation[C]. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 2782-2790.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LIME:Low-light image enhancement via illumination map estimation">

                                <b>[9]</b> Guo X J, Li Y, Ling H B. LIME: low-light image enhancement via illumination map estimation[J]. IEEE Transactions on Image Processing, 2017, 26 (2) : 982-993.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast efficient algorithm for enhancement of low lighting video">

                                <b>[10]</b> Dong X, Wang G, Pang Y, <i>et al</i>. Fast efficient algorithm for enhancement of low lighting video[C]. IEEE International Conference on Multimedia and Expo (ICME) , 2011: 1-6.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A low-light image enhancement method for both denoising and contrast enlarging">

                                <b>[11]</b> Li L, Wang R G, Wang W M, <i>et al</i>. A low-light image enhancement method for both denoising and contrast enlarging[C]. IEEE International Conference on Image Processing (ICIP) , 2015: 3730-3734.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancement of low light level images with coupled dictionary learning">

                                <b>[12]</b> Yang J, Jiang X W, Pan C H, <i>et al</i>. Enhancement of low light level images with coupled dictionary learning[C].International Conference on Pattern Recognition (ICPR) , 2016: 751-756.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201702013&amp;v=MTEzNzVxcUJ0R0ZyQ1VSN3FmWnVadEZpRGtVTHpLSWk3ZmRyRzRIOWJNclk5RVo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Song R X, Li D, Wang X C. Low illumination image enhancement algorithm based on HSI color space[J]. Journal of Graphics, 2017, 38 (2) : 217-223. 宋瑞霞, 李达, 王小春. 基于HSI色彩空间的低照度图像增强算法[J]. 图学学报, 2017, 38 (2) : 217-223.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low-light image enhancement algorithm based on HSI color space">

                                <b>[14]</b> Wu F, Kintak U. Low-light image enhancement algorithm based on HSI color space[C]. International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI) , 2017: 1-6.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[15]</b> Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[J]. Communications of the ACM, 2017, 60 (6) : 84-90.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201803036&amp;v=MDgxMDZHNEg5bk1ySTlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEa1VMektJalhUYkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Xin P, Xu Y L, Tang H, <i>et al</i>. Fast airplane detection based on multi-layer feature fusion of fully convolutional networks[J]. Acta Optica Sinica, 2018, 38 (3) : 0315003. 辛鹏, 许悦雷, 唐红, 等. 全卷积网络多层特征融合的飞机快速检测[J]. 光学学报, 2018, 38 (3) : 0315003.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201807042&amp;v=MjI1MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURrVUx6S0lqWFRiTEc0SDluTXFJOUJab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Zhu M M, Xu Y L, Ma S P, <i>et al</i>. Airport detection method with improved region-based convolutional neural network[J]. Acta Optica Sinica, 2018, 38 (7) : 0728001. 朱明明, 许悦雷, 马时平, 等. 改进区域卷积神经网络的机场检测方法[J]. 光学学报, 2018, 38 (7) : 0728001.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 Lore K G, Akintayo A, Sarkar S. LLNet: a deep autoencoder approach to natural low-light image enhancement[J]. Pattern Recognition, 2017, 61: 650-662.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Sparse Rectifier Neural Networks">

                                <b>[19]</b> Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]. Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, 2011: 315-323.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:accelerating deep network training by reducing internal covariate shift">

                                <b>[20]</b> Ioffe S, Szegedy C. Batch normalization: accelerating deep network training by reducing internal covariate shift[C]. Proceedings of the 32nd International Conference on International Conference on Machine Learning, 2015: 448-456.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Superpixel segmentation based on Delaunay triangulation">

                                <b>[21]</b> Chen X Y, Wang S A. Superpixel segmentation based on Delaunay triangulation[C]. International Conference on Mechatronics and Machine Vision in Practice (M2VIP) , 2016: 1-6.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond a Gaussian Denoiser:Residual Learning of Deep CNN for Image Denoising">

                                <b>[22]</b> Zhang K, Zuo W, Chen Y, <i>et al</i>. Beyond a Gaussian denoiser: residual learning of deep CNN for image denoisin[J]. IEEE Transactions on Image Processing, 2017, 26 (7) : 3142-3155.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Delving Deep into Rectifiers:Surpassing Human-Level Performance on ImageNet Classification">

                                <b>[23]</b> He K M, Zhang X Y, Ren S Q, <i>et al</i>. Delving deep into rectifiers: surpassing human-level performance on ImageNet classification[C]. IEEE International Conference on Computer Vision (ICCV) , 2015: 1026-1034.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">

                                <b>[24]</b> Dong C, Loy C C, He K M, <i>et al</i>. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) : 295-307.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501235178&amp;v=MTgzNDVpbmxVcnpKS0Y4WGFSQT1OaWZPZmJLN0h0RE5xbzlFWnVnS0RYc3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> Cheng H D, Shi X J. A simple and effective histogram equalization approach to image enhancement[J]. Digital Signal Processing, 2004, 14 (2) : 158-170.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Statistical Evaluation of Recent Full Reference Image Quality Assessment Algorithms">

                                <b>[26]</b> Sheikh H R, Sabir M F, Bovik A C. A statistical evaluation of recent full reference image quality assessment algorithm[J]. IEEE Transactions on Image Processing, 2006, 15 (11) : 3440-3451.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Naturalness preserved enhancement algorithm for non-uniform illumination images">

                                <b>[27]</b> Wang S H, Zheng J, Hu H M, <i>et al</i>. Naturalness preserved enhancement algorithm for non-uniform illumination images[J]. IEEE Transactions on Image Processing, 2013, 22 (9) : 3538-3548.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_28" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263401&amp;v=MDA2ODJmT2ZiSzdIdEROcW85RVp1ME1DSHc0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpKS0Y4WGFSQT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[28]</b> Rahman Z U, Jobson D J, Woodell G A. Investigating the relationship between image enhancement and image compression in the context of the multi-scale retinex[J]. Journal of Visual Communication and Image Representation, 2011, 22 (3) : 237-250.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement based on layered differencerepresentation">

                                <b>[29]</b> Lee C, Lee C, Kim C S. Contrast enhancement based on layered difference representation[C]. IEEE International Conference on Image Processing, 2012: 965-968.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast automatic compensation of under/over exposured image regions">

                                <b>[30]</b> Vonikakis V, Andreadis I. Fast automatic compensation of under/over- exposured image regions[C]. IEEE Pacific Rim Symposium on Image Video and Technology (PSIVT) , 2007: 510-521.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Correlation between subjective and objective assessment of magnetic resonance (MR)images">

                                <b>[31]</b> Chow L S, Rajagopal H, Paramesran R. Correlation between subjective and objective assessment of magnetic resonance (MR) images[J]. Magnetic Resonance Imaging, 2016, 34 (6) : 820-831.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201902012" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201902012&amp;v=MjkwMDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURrVUx6TElqWFRiTEc0SDlqTXJZOUVab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dFFaNjNMSWtaUGZ1aW9HelVZVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

