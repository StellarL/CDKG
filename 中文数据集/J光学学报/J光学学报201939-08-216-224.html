

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133843657783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGXXB201908026%26RESULT%3d1%26SIGN%3dC%252bbMCUuX7Bbj1zTQ077x%252bxy0UXU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908026&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GXXB201908026&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908026&amp;v=MjQ0NjJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg5ak1wNDlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#44" data-title="1 引  言 ">1 引  言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="2 改进Census变换 ">2 改进Census变换</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="3 基于改进Census变换的多特征背景建模方法 ">3 基于改进Census变换的多特征背景建模方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;3.1 背景模型原理&lt;/b&gt;"><b>3.1 背景模型原理</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;3.2 模型的初始化&lt;/b&gt;"><b>3.2 模型的初始化</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;3.3 模型更新策略&lt;/b&gt;"><b>3.3 模型更新策略</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#123" data-title="&lt;b&gt;4.1 光线突变场景实验及分析&lt;/b&gt;"><b>4.1 光线突变场景实验及分析</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;4.2 普通背景和复杂背景实验及分析&lt;/b&gt;"><b>4.2 普通背景和复杂背景实验及分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="5 结  论 ">5 结  论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="图1 3&#215;3窗口像素值。">图1 3×3窗口像素值。</a></li>
                                                <li><a href="#61" data-title="图2 邻域像素值抖动。">图2 邻域像素值抖动。</a></li>
                                                <li><a href="#68" data-title="图3 Census模板。">图3 Census模板。</a></li>
                                                <li><a href="#94" data-title="图4 视频不同动态区域。">图4 视频不同动态区域。</a></li>
                                                <li><a href="#129" data-title="图5 光线突变场景">图5 光线突变场景</a></li>
                                                <li><a href="#131" data-title="表1 光线突变场景准确性验证">表1 光线突变场景准确性验证</a></li>
                                                <li><a href="#138" data-title="图6 5种算法处理结果对比">图6 5种算法处理结果对比</a></li>
                                                <li><a href="#139" data-title="表2 5种算法处理速度对比">表2 5种算法处理速度对比</a></li>
                                                <li><a href="#140" data-title="表3 普通场景对比实验">表3 普通场景对比实验</a></li>
                                                <li><a href="#141" data-title="表4 复杂背景对比实验">表4 复杂背景对比实验</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" Wang H Y, Wang L, Yin W R, &lt;i&gt;et al&lt;/i&gt;.Multi-scale correlation filtering visual tracking algorithm combined with target detection[J].Acta Optica Sinica, 2019, 39 (1) :0115004.王红雨, 汪梁, 尹午荣, 等.结合目标检测的多尺度相关滤波视觉跟踪算法[J].光学学报, 2019, 39 (1) :0115004." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201901035&amp;v=MzE1MzdCdEdGckNVUkxPZVplVnVGeW5sVzd6TklqWFRiTEc0SDlqTXJvOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Wang H Y, Wang L, Yin W R, &lt;i&gt;et al&lt;/i&gt;.Multi-scale correlation filtering visual tracking algorithm combined with target detection[J].Acta Optica Sinica, 2019, 39 (1) :0115004.王红雨, 汪梁, 尹午荣, 等.结合目标检测的多尺度相关滤波视觉跟踪算法[J].光学学报, 2019, 39 (1) :0115004.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" Ge B Y, Zuo X Z, Hu Y J.Long-term object tracking based on feature fusion[J].Acta Optica Sinica, 2018, 38 (11) :1115002.葛宝义, 左宪章, 胡永江.基于特征融合的长时目标跟踪算法[J].光学学报, 2018, 38 (11) :1115002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811025&amp;v=MTU2NjVMRzRIOW5Ocm85SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXN3pOSWpYVGI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Ge B Y, Zuo X Z, Hu Y J.Long-term object tracking based on feature fusion[J].Acta Optica Sinica, 2018, 38 (11) :1115002.葛宝义, 左宪章, 胡永江.基于特征融合的长时目标跟踪算法[J].光学学报, 2018, 38 (11) :1115002.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" Yang C Y, Li C, Liang Y C, &lt;i&gt;et al&lt;/i&gt;.Blurred object detection based on improved particle filter in coal mine underground surveilance[J].Journal of Jilin University (Engineering and Technology Edition) , 2017, 47 (6) :1976-1985.杨超宇, 李策, 梁胤程, 等.基于改进粒子滤波的煤矿视频监控模糊目标检测[J].吉林大学学报 (工学版) , 2017, 47 (6) :1976-1985." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201706041&amp;v=MjgwMDdlWmVWdUZ5bmxXN3pOTHlITWQ3RzRIOWJNcVk5QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Yang C Y, Li C, Liang Y C, &lt;i&gt;et al&lt;/i&gt;.Blurred object detection based on improved particle filter in coal mine underground surveilance[J].Journal of Jilin University (Engineering and Technology Edition) , 2017, 47 (6) :1976-1985.杨超宇, 李策, 梁胤程, 等.基于改进粒子滤波的煤矿视频监控模糊目标检测[J].吉林大学学报 (工学版) , 2017, 47 (6) :1976-1985.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" Sun X W, Xu Q S, Cai Y, &lt;i&gt;et al&lt;/i&gt;.Sea sky line detection based on edge phase encoding in complicated background[J].Acta Optica Sinica, 2017, 37 (11) :1110002.孙熊伟, 徐青山, 蔡熠, 等.基于边缘相位编码的复杂背景下海天线检测[J].光学学报, 2017, 37 (11) :1110002." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201711011&amp;v=MDY5OTMzenFxQnRHRnJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg5Yk5ybzlFWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Sun X W, Xu Q S, Cai Y, &lt;i&gt;et al&lt;/i&gt;.Sea sky line detection based on edge phase encoding in complicated background[J].Acta Optica Sinica, 2017, 37 (11) :1110002.孙熊伟, 徐青山, 蔡熠, 等.基于边缘相位编码的复杂背景下海天线检测[J].光学学报, 2017, 37 (11) :1110002.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" Sui Z S, Li J S, Zhang J, &lt;i&gt;et al&lt;/i&gt;.Video foreground detection of tensor low-rank representation and spatial-temporal sparsity decomposition[J].Optics and Precision Engineering, 2017, 25 (2) :529-536.隋中山, 李俊山, 张姣, 等.张量低秩表示和时空稀疏分解的视频前景检测[J].光学精密工程, 2017, 25 (2) :529-536." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201702031&amp;v=MTI4OTRubFc3ek5JalhCWTdHNEg5Yk1yWTlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Sui Z S, Li J S, Zhang J, &lt;i&gt;et al&lt;/i&gt;.Video foreground detection of tensor low-rank representation and spatial-temporal sparsity decomposition[J].Optics and Precision Engineering, 2017, 25 (2) :529-536.隋中山, 李俊山, 张姣, 等.张量低秩表示和时空稀疏分解的视频前景检测[J].光学精密工程, 2017, 25 (2) :529-536.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" title=" Ma J J, Pan Q, Liang Y, &lt;i&gt;et al&lt;/i&gt;.Object detection based on improved Grassberger entropy random forest classifier[J].Chinese Journal of Lasers, 2019, 46 (7) :0704011.马娟娟, 潘泉, 梁彦, 等.基于改进Grassberger熵随机森林分类器的目标检测[J].中国激光, 2019, 46 (7) :0704011." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201907031&amp;v=MTM3MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXN3pOTHlmUmRMRzRIOWpNcUk5R1pZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Ma J J, Pan Q, Liang Y, &lt;i&gt;et al&lt;/i&gt;.Object detection based on improved Grassberger entropy random forest classifier[J].Chinese Journal of Lasers, 2019, 46 (7) :0704011.马娟娟, 潘泉, 梁彦, 等.基于改进Grassberger熵随机森林分类器的目标检测[J].中国激光, 2019, 46 (7) :0704011.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" Wren C R, Azarbayejani A, Darrell T, &lt;i&gt;et al&lt;/i&gt;.Pfinder:real-time tracking of the human body[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997, 19 (7) :780-785." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pfinder: Real-time tracking of the human body">
                                        <b>[7]</b>
                                         Wren C R, Azarbayejani A, Darrell T, &lt;i&gt;et al&lt;/i&gt;.Pfinder:real-time tracking of the human body[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997, 19 (7) :780-785.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" Stauffer C, Grimson W E L.Adaptive background mixture models for real-time tracking[C]∥1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 23-25, 1999, Fort Collins, CO, USA.New York:IEEE, 1999:246-252." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Background Mixture Models for Real-time Tracking">
                                        <b>[8]</b>
                                         Stauffer C, Grimson W E L.Adaptive background mixture models for real-time tracking[C]∥1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 23-25, 1999, Fort Collins, CO, USA.New York:IEEE, 1999:246-252.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" Huo D H, Yang D, Zhang X H, &lt;i&gt;et al&lt;/i&gt;.Principal component analysis based codebook background modeling algorithm[J].Acta Automatica Sinica, 2012, 38 (4) :591-600.霍东海, 杨丹, 张小洪, 等.一种基于主成分分析的Codebook背景建模算法[J].自动化学报, 2012, 38 (4) :591-600." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201204011&amp;v=MDQ4ODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXN3pOS0NMZlliRzRIOVBNcTQ5RVpZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Huo D H, Yang D, Zhang X H, &lt;i&gt;et al&lt;/i&gt;.Principal component analysis based codebook background modeling algorithm[J].Acta Automatica Sinica, 2012, 38 (4) :591-600.霍东海, 杨丹, 张小洪, 等.一种基于主成分分析的Codebook背景建模算法[J].自动化学报, 2012, 38 (4) :591-600.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" Barnich O, van Droogenbroeck M.ViBe:a universal background subtraction algorithm for video sequences[J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ViBe: A Universal Background Subtraction Algorithm for Video Sequences">
                                        <b>[10]</b>
                                         Barnich O, van Droogenbroeck M.ViBe:a universal background subtraction algorithm for video sequences[J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" Bi G L, Xu Z J, Chen T, &lt;i&gt;et al&lt;/i&gt;.Complex background model and foreground detection based on random aggregation[J].Acta Physica Sinica, 2015, 64 (15) :150701.毕国玲, 续志军, 陈涛, 等.基于随机聚类的复杂背景建模与前景检测算法[J].物理学报, 2015, 64 (15) :150701." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201515005&amp;v=MTc4MjFpSFRiTEc0SDlUTnFvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzd6Tk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Bi G L, Xu Z J, Chen T, &lt;i&gt;et al&lt;/i&gt;.Complex background model and foreground detection based on random aggregation[J].Acta Physica Sinica, 2015, 64 (15) :150701.毕国玲, 续志军, 陈涛, 等.基于随机聚类的复杂背景建模与前景检测算法[J].物理学报, 2015, 64 (15) :150701.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" Zhang Z B, Yuan X B.An improved PBAS algorithm for dynamic background[J].Electronic Design Engineering, 2017, 25 (3) :35-40.张泽斌, 袁哓兵.一种改进反馈机制的PBAS运动目标检测算法[J].电子设计工程, 2017, 25 (3) :35-40." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201703009&amp;v=MDMwNDllVnVGeW5sVzd6TklqclBkTEc0SDliTXJJOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Zhang Z B, Yuan X B.An improved PBAS algorithm for dynamic background[J].Electronic Design Engineering, 2017, 25 (3) :35-40.张泽斌, 袁哓兵.一种改进反馈机制的PBAS运动目标检测算法[J].电子设计工程, 2017, 25 (3) :35-40.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_13" title=" Stein F.Efficient computation of optical flow using the census transform[M]//Rasmussen C E, B&#252;lthoff H H, Sch&#246;lkopf B, &lt;i&gt;et al&lt;/i&gt;.Pattern recognition.Lecture notes in computer science.Berlin, Heidelberg:Springer, 2004, 3175:79-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient computation of optical flow using the census transform">
                                        <b>[13]</b>
                                         Stein F.Efficient computation of optical flow using the census transform[M]//Rasmussen C E, B&#252;lthoff H H, Sch&#246;lkopf B, &lt;i&gt;et al&lt;/i&gt;.Pattern recognition.Lecture notes in computer science.Berlin, Heidelberg:Springer, 2004, 3175:79-86.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_14" title=" Yan L, Wang R, Liu H, &lt;i&gt;et al&lt;/i&gt;.Stereo matching method based on improved cost computation and adaptive guided filter[J].Acta Optica Sinica, 2018, 38 (11) :1115007.闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :1115007." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811030&amp;v=MDg0MDk5bk5ybzlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Yan L, Wang R, Liu H, &lt;i&gt;et al&lt;/i&gt;.Stereo matching method based on improved cost computation and adaptive guided filter[J].Acta Optica Sinica, 2018, 38 (11) :1115007.闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :1115007.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_15" title=" Guo Z C, Dang J W, Wang Y P, &lt;i&gt;et al&lt;/i&gt;.Background modeling method based on multi-feature fusion[J].Opto-Electronic Engineering, 2018, 45 (12) :180206.郭治成, 党建武, 王阳萍, 等.基于多特征融合的背景建模方法[J].光电工程, 2018, 45 (12) :180206." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201812006&amp;v=MjU5ODhIOW5Oclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXN3pOSWluTWJiRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Guo Z C, Dang J W, Wang Y P, &lt;i&gt;et al&lt;/i&gt;.Background modeling method based on multi-feature fusion[J].Opto-Electronic Engineering, 2018, 45 (12) :180206.郭治成, 党建武, 王阳萍, 等.基于多特征融合的背景建模方法[J].光电工程, 2018, 45 (12) :180206.
                                    </a>
                                </li>
                                <li id="40">


                                    <a id="bibliography_16" title=" Liao S C, Zhao G Y, Kellokumpu V, &lt;i&gt;et al&lt;/i&gt;.Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes[C]//2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 13-18, 2010, San Francisco, CA, USA.New York:IEEE, 2010:1301-1306." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modeling Pixel Process with ScaleInvariant Local Patterns for Background Subtraction in Complex Scenes">
                                        <b>[16]</b>
                                         Liao S C, Zhao G Y, Kellokumpu V, &lt;i&gt;et al&lt;/i&gt;.Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes[C]//2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 13-18, 2010, San Francisco, CA, USA.New York:IEEE, 2010:1301-1306.
                                    </a>
                                </li>
                                <li id="42">


                                    <a id="bibliography_17" title=" Wang Y, Jodoin P M, Porikli F, &lt;i&gt;et al&lt;/i&gt;.CDnet 2014:an expanded change detection benchmark dataset[C]∥2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, June 23-28, 2014, Columbus, OH, USA.New York:IEEE, 2014:393-400." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CDnet 2014:An expanded change detection benchmark dataset">
                                        <b>[17]</b>
                                         Wang Y, Jodoin P M, Porikli F, &lt;i&gt;et al&lt;/i&gt;.CDnet 2014:an expanded change detection benchmark dataset[C]∥2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, June 23-28, 2014, Columbus, OH, USA.New York:IEEE, 2014:393-400.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-16 17:45</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GXXB" target="_blank">光学学报</a>
                2019,39(08),216-224 DOI:10.3788/AOS201939.0815003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进Census变换的多特征背景建模算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%B2%BB%E6%88%90&amp;code=14256708&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭治成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%85%9A%E5%BB%BA%E6%AD%A6&amp;code=08547028&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">党建武</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E9%98%B3%E8%90%8D&amp;code=07918279&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王阳萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%87%91%E9%9D%99&amp;code=11716296&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金静</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%85%B0%E5%B7%9E%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0231149&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">兰州交通大学电子与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%98%E8%82%83%E7%9C%81%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%B7%A5%E7%A8%8B%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">甘肃省人工智能与图形图像处理工程研究中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对视频图像易受噪声干扰和背景变化复杂的特点, 改进传统Census变换特征值对中心像素的依赖问题, 建立Census模板以保持Census变换对光线变化的稳健性。将改进后的Census变换特征值、图像像素值、更新频数、最近更新时间和动态指数等多种特征融合, 建立了一种新的背景建模算法。利用帧间亮度差, 自适应选择融合多种特征更新背景模型, 依据动态指数衡量背景变化复杂程度, 建立不同的更新规则, 提升模型对光线突变和复杂场景处理的稳定性。经测试多组标准视频序列, 本算法检测精度优于其他算法, 有效改善了光线突变对前景目标提取的影响, 提高了对光线突变和复杂场景的稳健性, 减少了运动目标的孔洞和像素漂移产生的假前景。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Census%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Census变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E6%99%AF%E5%BB%BA%E6%A8%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背景建模;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *党建武 E-mail:lzjdgr@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-06</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61661026, 61841303);</span>
                                <span>甘肃省科技计划项目 (18JR3RA104);</span>
                                <span>甘肃省教育厅 (2017D-08);</span>
                                <span>兰州交通大学青年基金 (2016005);</span>
                    </p>
            </div>
                    <h1><b>Multi-Feature Background Modeling Algorithm Based on Improved Census Transform</b></h1>
                    <h2>
                    <span>Guo Zhicheng</span>
                    <span>Dang Jianwu</span>
                    <span>Wang Yangping</span>
                    <span>Jin Jing</span>
            </h2>
                    <h2>
                    <span>School of Electronic and Information Engineering, Lanzhou Jiaotong University</span>
                    <span>Gansu Provincial Engineering Research Center for Artificial Intelligence and Graphics & Image Processing</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In view of the noise interference to video images and the complexity of background change, the traditional Census transform eigenvalue dependence on the central pixel is improved, and the Census template is established to maintain the robustness of the Census transform to light changes. A new background modeling method is established by combining the improved Census transform eigenvalue, image pixel value, update frequency, latest update time and dynamic index. The background texture difference is adaptively selected and fused with multiple features to update the background model. According to the dynamic index, the background change complexity is established, and different update rules are established to improve the stability of the model for light mutation and complex scene processing. After testing multiple sets of standard video sequences, the detection accuracy of this algorithm is better than that of other algorithms, which effectively improves the influence of light mutation on foreground target extraction, increases the robustness to light mutations and complex scenes, and reduces the false foreground caused by holes and pixel shift of the moving target.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=video%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">video processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Census%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Census transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=motion%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">motion detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=background%20modeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">background modeling;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-06</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="44" name="44" class="anchor-tag">1 引  言</h3>
                <div class="p1">
                    <p id="45">背景建模技术是机器视觉和视频处理的一个重要研究方向, 目标是将感兴趣区域从视频序列中标识出来, 为目标检测<citation id="144" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、目标跟踪<citation id="145" type="reference"><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>和行为分析理解等算法提供重要依据。稳健背景模型的建立和更新算法直接决定前景目标的检测效果。国内外很多学者对背景建模方法进行了深入的研究<citation id="146" type="reference"><link href="16" rel="bibliography" /><link href="18" rel="bibliography" /><link href="20" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>, 这些模型主要分为两类:一类是参数化方法, 为每个像素点建立带参数的模型;另一类是非参数方法, 用已获取样本像素的关系建立模型。</p>
                </div>
                <div class="p1">
                    <p id="46">Wren等<citation id="147" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出为每个像素值时域信息建立带参单高斯背景模型, 该方法适用于变化缓慢及单一的背景, 当背景像素发生扰动变化且较为复杂时, 会产生大量假前景, 检测效果较差。对于单高斯背景模型处理复杂背景效果差的问题, Stauffer等<citation id="148" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出为每个像素值建立多个高斯分布的混合高斯背景模型, 模型对复杂背景处理效果较好, 但由于多个高斯分布参数调整困难, 易造成前景目标丢失, 计算复杂度高, 处理速度慢。CodeBook (码本模型) 为视频帧中每个像素建立一个码本结构<citation id="149" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 每个码本结构由多个码字组成, 计算量小, 处理时间起伏较好, 但背景动态变化程度较高时易造成码字更新错误, 适应能力差, 内存消耗大。ViBe (Visual Background Extractor) 用单帧视频建立初始背景模型<citation id="151" type="reference"><link href="28" rel="bibliography" /><link href="30" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 依据邻域像素点空间分布特性更新背景模型, 采用随机替换策略使模型能够快速适应场景的简单变化, 但在光线突变的场景下, 会产生大量的假前景。PBAS (Pixel-Based Adaptive Segmenter) 引入控制论思想, 结合SACON (Sample Consensus) 背景建模方法和ViBe随机替换策略<citation id="150" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 在检测性能上优于SACON和ViBe, 具有建模速度快、准确率较高的优点, 但更新率计算和判断阈值复杂度较高, 实时性较差。</p>
                </div>
                <div class="p1">
                    <p id="47">目前大多数背景建模算法对光线亮度变化较为敏感, 尤其在光线突变场景中目标获取效果较差, Census变换<citation id="152" type="reference"><link href="34" rel="bibliography" /><link href="36" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>能够减少光线差异引起的误匹配, 对亮度偏差较为稳健, 同时计算量小, 满足视频处理实时性。本文提出一种基于改进Census变换的多特征背景建模算法, 改进传统Census变换特征值对中心像素的依赖问题, 引入Census模板, 提高了Census变换对视频图像处理的稳健性, 将改进后的Census变换特征值、图像像素值、更新频数、最近更新时间和动态指数等多种特征融合, 建立了一种新的背景建模方法。该方法能够依据光线对视频序列的影响自适应地选择有效的特征值, 改善了光线突变对目标提取的影响, 在复杂场景中提取运动目标具有较强的适应性和稳健性。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">2 改进Census变换</h3>
                <div class="p1">
                    <p id="49">Census变换是一种基于图像局部信息的非参数变换方法, 其基本原理是在图像中选取一个像素点<i>p</i>, 以<i>p</i>为中心建立一个矩形窗口, 将窗口内中心像素的邻域像素<i>p</i>′与<i>p</i>进行比较, 并将结果用0和1来表示。Census变换的实质是通过邻域像素与中心像素的大小关系, 将图像像素值编码成二进制码流, 公式为</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>C</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mo>⊗</mo></mstyle><mrow><msup><mi>p</mi><mo>′</mo></msup><mo>∈</mo><mi>W</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow></munder><mi>ζ</mi><mo stretchy="false">[</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">式中:<i>W</i> (<i>p</i>) 为中心像素<i>p</i>对应的Census变换窗口;<i>I</i> (<i>p</i>) 为<i>p</i>的像素值;<i>I</i> (<i>p</i>′) 为<i>p</i>周边像素的像素值;⨂符号表示按位连接<i>ζ</i>[<i>I</i> (<i>p</i>) , <i>I</i> (<i>p</i>′) ], 满足</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ζ</mi><mo stretchy="false">[</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>, </mo></mtd><mtd><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo></mtd><mtd><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">中心像素灰度值经过Census变换后被替换为<i>C</i><sub>Cen</sub> (<i>p</i>) , 利用Hamming距计算<i>C</i><sub>Cen</sub> (<i>p</i>) 之间的差异程度, 测量两点之间的距离。<i>C</i><sub>Cen</sub> (<i>p</i>) 与变换窗口中心像素和其他各个像素灰度大小有关, 因此, Census变换对于幅度失真与光线突然变换有着较强的稳健性。</p>
                </div>
                <div class="p1">
                    <p id="54">传统的Census变换对中心像素依赖性较强, 如图1 (a) 和 (b) 所示, 窗口内邻域像素值不变, 中心像素值变化, Census变换波动较大, 容易引起误配。</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3&#215;3窗口像素值。" src="Detail/GetImg?filename=images/GXXB201908026_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 3×3窗口像素值。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Pixel value in 3×3 window.</p>
                                <p class="img_note"> (a) 窗口内邻域像素相同, 中心像素不同; (b) 中心像素为原始灰度值; (c) 中心像素为窗口各像素值的平均灰度值; (d) 中心像素为窗口内各像素值的中位数</p>
                                <p class="img_note"> (a) Fields in the window with the same pixels and the different center pixels; (b) center pixel is the original gray value; (c) center pixel is the average gray value of each pixel value of the window; (d) center pixel is the median value of each pixel value in the window</p>

                </div>
                <div class="p1">
                    <p id="56">为改变视频序列图像受噪声干扰和背景变化复杂带来Census变换误配的问题, 本文提出一种改进Census变换算法, 其核心思想是取窗口内各像素值的中位数替代中心像素灰度值<i>I</i> (<i>p</i>) :</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ζ</mi><mo stretchy="false">[</mo><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>, </mo></mtd><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo></mtd><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mi>m</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">[</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">式中:<i>M</i> (<i>p</i>) 为窗口内所有像素值的中位数;<i>m</i><sub>median</sub> ( ) 为求中位数的函数。</p>
                </div>
                <div class="p1">
                    <p id="59">将窗口中邻域各像素的灰度值与参考值进行比较, 如图1 (b) ～ (d) 所示, 分别取窗口内中心像素值、所有像素平均值、所有像素中位数为中心像素参考值, 以中位数取代中心像素的Census变换明显降低了对中心像素的依赖, 提高了算法的稳健性。</p>
                </div>
                <div class="p1">
                    <p id="60">采集视频信息设备硬件缺陷和外界电磁波干扰, 易引起视频图像在同一坐标位置不同帧之间像素值的抖动。图2 (a) 矩形区域中心像素<i>p</i> (坐标为 (185, 122) ) , 连续140帧内像素值在146～152之间的抖动如图2 (b) 所示, Census变换结果如图2 (c) ～ (e) 所示, 中心像素<i>M</i> (<i>p</i>) 不变, 邻域像素值抖动, Census变换状态稳定性较差。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 邻域像素值抖动。" src="Detail/GetImg?filename=images/GXXB201908026_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 邻域像素值抖动。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Neighborhood pixel value change.</p>
                                <p class="img_note"> (a) 视频序列; (b) 矩形区域像素值变化; (c) 中心像素为153第t帧Census变换; (d) 中心像素为153第t+1帧Census变换; (e) 中心像素为153第t+2帧Census变换</p>
                                <p class="img_note"> (a) Video sequence; (b) rectangular area pixel value change; (c) center pixel is 153, the t-th frame Census transform; (d) center pixel is 153, the (t+1) th frame Census transform; (e) center pixel is 153, the (t+2) th frame Census transform</p>

                </div>
                <div class="p1">
                    <p id="62">为改进Census变换的稳定性, 本文提出Census模板, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi>C</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd><mtd><mi>max</mi><mo stretchy="false">[</mo><mrow><mo>|</mo><mrow><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>, </mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo stretchy="false">]</mo><mo>&lt;</mo><mi>ε</mi></mtd></mtr><mtr><mtd><mi>C</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo></mtd><mtd><mi>max</mi><mo stretchy="false">[</mo><mrow><mo>|</mo><mrow><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>, </mo><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo stretchy="false">]</mo><mo>≥</mo><mi>ε</mi></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">式中:<i>C</i><sub>cen</sub> (<i>p</i><sub><i>t</i></sub>) 为第<i>t</i>帧像素<i>p</i>的Census变换值;<i>M</i> (<i>p</i><sub><i>t</i></sub>) 为<i>t</i>帧像素窗口内所有像素值的中位数;<i>I</i> (<i>p</i>′<sub><i>t</i></sub>) 为<i>t</i>帧<i>p</i>周边像素的像素值;<i>ε</i>为常数, 取5～8;max () 为求最大值函数。</p>
                </div>
                <div class="p1">
                    <p id="65">Census模板更新规则为</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>p</mi><mo>′</mo></msup><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mo>。</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">处理结果如图3所示, 因为差异小于<i>ε</i>, 所以图3 (a) ～ (c) 公用一个census模板, 减少了像素抖动对前景目标提取的影响, 增强了Census变换的稳定性。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Census模板。" src="Detail/GetImg?filename=images/GXXB201908026_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Census模板。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Census template. </p>
                                <p class="img_note">（a）Census模板像素值；（b）t<sub>1</sub>帧像素值；（c）t<sub>2</sub>帧像素值；（d）Census模板变换值；（e）I（p′）-I（p′<sub>t</sub><sub>1</sub>）；（f）I（p′）-I（p′<sub>t</sub><sub>2</sub>）</p>
                                <p class="img_note"> (a) Census template pixel value; (b) t<sub>1</sub> frame pixel value; (c) t<sub>2</sub> frame pixel value; (d) Census template transform value; (e) I (p′) -I (p′t<sub>1</sub>) ; (f) I (p′) -I (p′t<sub>2</sub>) </p>

                </div>
                <h3 id="69" name="69" class="anchor-tag">3 基于改进Census变换的多特征背景建模方法</h3>
                <h4 class="anchor-tag" id="70" name="70"><b>3.1 背景模型原理</b></h4>
                <div class="p1">
                    <p id="71">背景模型常用像素值、梯度、目标表象等信息为特征建立模型<citation id="153" type="reference"><link href="38" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 如Liao等<citation id="154" type="reference"><link href="40" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>以纹理为特征建立背景模型, Barnich等<citation id="155" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>利用像素邻域空间关系更新背景模型等。这些算法用短时间内场景变化的统计特性来增强背景模型的适应性, 却忽略了长时间内场景变化呈现周期性和受光线突变引起的场景变化。这些复杂场景变化导致背景模型退化, 误检率上升, 算法性能下降。为解决以上问题, 本文将改进后的Census变换特征和视频多种特征融合, 提出了一种新的背景建模算法。</p>
                </div>
                <div class="p1">
                    <p id="72">视频是由多幅图像组成的序列, 这些图像称为帧, 连续帧在同一位置上的像素值在时间轴上构成了一个集合<i>V</i> (<i>x</i><sub><i>t</i></sub>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>t</i></sub>|<i>t</i>=1, …, <i>A</i>}, 其中<i>V</i> (<i>x</i><sub><i>t</i></sub>) 为像素<i>x</i><sub><i>t</i></sub>的值, <i>x</i><sub><i>t</i></sub>为图像中的一个像素, <i>t</i>为视频序列中第<i>t</i>帧, <i>A</i>为视频序列帧数。模型为视频图像中的每一个<i>x</i><sub><i>i</i></sub>建立一个样本集<i>M</i> (<i>x</i><sub><i>i</i></sub>) ={<i>C</i> (<i>x</i><sub><i>i</i></sub>) , <i>P</i> (<i>x</i><sub><i>i</i></sub>) , <i>F</i> (<i>x</i><sub><i>i</i></sub>) , <i>T</i> (<i>x</i><sub><i>i</i></sub>) , <i>S</i> (<i>x</i><sub><i>i</i></sub>) }, 其中:</p>
                </div>
                <div class="p1">
                    <p id="73"><i>C</i> (<i>x</i><sub><i>i</i></sub>) ={<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>N</i></sub>}为<i>x</i><sub><i>i</i></sub>处背景样本集中每个样本的Census变换特征值, <i>N</i>为样本集大小;</p>
                </div>
                <div class="p1">
                    <p id="74"><i>P</i> (<i>x</i><sub><i>i</i></sub>) ={<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>N</i></sub>}为<i>x</i><sub><i>i</i></sub>处背景样本集中每个样本的像素值;</p>
                </div>
                <div class="p1">
                    <p id="75"><i>F</i> (<i>x</i><sub><i>i</i></sub>) ={<i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>, …, <i>f</i><sub><i>N</i></sub>}为<i>x</i><sub><i>i</i></sub>处背景样本集中每个样本的频数;</p>
                </div>
                <div class="p1">
                    <p id="76"><i>T</i> (<i>x</i><sub><i>i</i></sub>) ={<i>t</i><sub>1</sub>, <i>t</i><sub>2</sub>, …, <i>t</i><sub><i>N</i></sub>}为<i>x</i><sub><i>i</i></sub>处背景样本集中每个样本最近更新时间;</p>
                </div>
                <div class="p1">
                    <p id="77"><i>S</i> (<i>x</i><sub><i>i</i></sub>) ={<i>s</i>}为<i>x</i><sub><i>i</i></sub>像素的动态指数。</p>
                </div>
                <div class="p1">
                    <p id="78">模型假设像素值在<i>M</i> (<i>x</i><sub><i>i</i></sub>) 外分布的为前景像素, 在<i>M</i> (<i>x</i><sub><i>i</i></sub>) 内分布的为背景像素, 前景、背景像素的判定边界由<i>M</i> (<i>x</i><sub><i>i</i></sub>) 构成, <i>t</i>帧输入的像素<i>V</i> (<i>x</i><sub><i>t</i></sub>) 通过下式来判断是否为背景像素, </p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi>G</mi><msub><mrow></mrow><mtext>F</mtext></msub><mo>, </mo><mo stretchy="false">{</mo><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>Μ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mo>&lt;</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>G</mi><msub><mrow></mrow><mtext>B</mtext></msub><mo>, </mo><mo stretchy="false">{</mo><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>Μ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mo>≥</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">式中:<i>G</i><sub>F</sub>为前景像素;<i>G</i><sub>B</sub>为背景像素。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>3.2 模型的初始化</b></h4>
                <div class="p1">
                    <p id="82">初始化背景模型用视频序列的第1帧图像, 取以像素<i>x</i><sub><i>i</i></sub>为中心的3×3窗口内所有像素初始化<i>x</i><sub><i>i</i></sub>, Census变换特征值<i>C</i> (<i>x</i><sub><i>i</i></sub>) ={<i>C</i><sub>cen</sub> (<i>x</i><sub><i>i</i></sub>) , <i>C</i><sub>cen</sub> (<i>x</i><sub><i>j</i></sub>) |<i>j</i>=1, …, 8}, 其中<i>i</i>为1帧中第<i>i</i>个像素, 其中<i>j</i>为<i>x</i><sub><i>i</i></sub>第<i>j</i>个邻域像素, <i>C</i><sub>cen</sub> (<i>x</i><sub><i>i</i></sub>) 为<i>x</i><sub><i>i</i></sub>的Census变换特征值。取像素<i>x</i><sub><i>i</i></sub>为中心的5×5窗口中满足</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">的像素值初始化<i>P</i> (<i>x</i><sub><i>i</i></sub>) , <i>F</i> (<i>x</i><sub><i>i</i></sub>) ={<i>f</i><sub><i>i</i></sub>=1|<i>i</i>=1, …, <i>N</i>}, <i>T</i> (<i>x</i><sub><i>i</i></sub>) ={<i>t</i><sub><i>i</i></sub>=1|<i>i</i>=1, …, <i>N</i>}, <i>N</i>为样本集大小, 满足</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>∈</mo><mo stretchy="false">{</mo><mrow><mo>|</mo><mrow><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>&lt;</mo><mi>ε</mi><mo>, </mo><mi>k</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>2</mn><mn>4</mn><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">的<i>x</i><sub><i>i</i></sub>元素个数, 动态指数满足</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>|</mo><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow><mi>Ν</mi></mfrac><mo>, </mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><mo>, </mo><mtext> </mtext><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">式中:<i>V</i>′<sub><i>k</i></sub> (<i>x</i><sub><i>i</i></sub>) 为像素<i>x</i><sub><i>i</i></sub>的5×5邻域像素;<i>S</i> (<i>s</i><sub><i>i</i></sub>) 为<i>x</i><sub><i>i</i></sub>像素的动态指数;<i>j</i>为第<i>j</i>个满足 (10) 式的邻域像素;<i>k</i>为第<i>k</i>个邻域像素, <i>V</i> (<i>x</i><sub><i>i</i></sub>) 为窗口中心像素的像素值;<i>V</i>′<sub><i>j</i></sub> (<i>x</i><sub><i>i</i></sub>) 为满足 (10) 式的邻域像素;<i>ε</i>为常数, 取值同 (5) 式。</p>
                </div>
                <div class="p1">
                    <p id="89">为减少背景中复杂动态变化, 如:水波、光线和树叶晃动等因素产生的大量错误前景目标, 建立衡量背景动态变化程度的标准<i>D</i> (<i>x</i><sub><i>i</i></sub>) , 满足</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle></mrow><mi>Ν</mi></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91"> (12) 式为当前图像像素值与背景模型的样本值先差分求和, 得到欧氏距离和后的均值。式中<i>p</i><sub><i>k</i></sub>为背景模型<i>P</i> (<i>x</i><sub><i>i</i></sub>) 的样本值。</p>
                </div>
                <div class="p1">
                    <p id="92">动态指数<i>S</i> (<i>x</i><sub><i>i</i></sub>) 利用不同复杂度区域中像素反馈的信息来衡量背景动态变化程度。动态变化程度低, 如图4 (a) 中区域<i>A</i> (左下方框标记, 中心坐标为 (166, 36) ) , 动态指数<i>S</i> (<i>x</i><sub><i>i</i></sub>) 应较小, 降低误识别背景点;动态变化程度高, 如图4 (a) 中区域<i>B</i> (左上方框标记, 中心坐标为 (187, 95) ) , 动态指数<i>S</i> (<i>x</i><sub><i>i</i></sub>) 应较大, 避免产生错误的前景点, <i>S</i> (<i>x</i><sub><i>i</i></sub>) 满足</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd><mtd><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>≤</mo><mi>a</mi><mo>⋅</mo><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd><mtd><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>&gt;</mo><mi>a</mi><mo>⋅</mo><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 视频不同动态区域。" src="Detail/GetImg?filename=images/GXXB201908026_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 视频不同动态区域。  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Different dynamic areas in the video.</p>
                                <p class="img_note"> (a) 连续100帧; (b) 区域A、B的复杂度</p>
                                <p class="img_note"> (a) Continuous 100 frames; (b) complexity of areas A and B</p>

                </div>
                <div class="p1">
                    <p id="95">式中:<i>a</i>为固定系数。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>3.3 模型更新策略</b></h4>
                <div class="p1">
                    <p id="97">前景目标的提取质量主要取决于背景模型的更新策略, 模型更新慢会引起停滞物体和运动目标ghost现象, 模型更新快会出现大量假前景和运动目标内孔洞现象。算法利用亮度差来衡量视频序列图像中是否发生光线突变, 调整建模特征更新模型, 有效去除了光线突变造成的大量假前景, 提升了前景目标识别率;利用动态指数<i>S</i> (<i>x</i><sub><i>i</i></sub>) 来衡量不同区域动态程度, 结合样本频数<i>F</i> (<i>x</i><sub><i>i</i></sub>) 、最近更新时间<i>T</i> (<i>x</i><sub><i>i</i></sub>) 控制背景模型在不同区域的更新速度, 有效地减少了ghost和运动目标内孔洞现象。</p>
                </div>
                <div class="p1">
                    <p id="98">模型更新策略如下:</p>
                </div>
                <div class="p1">
                    <p id="99">步骤1:设<i>d</i><sub><i>t</i></sub> (<i>h</i>, <i>w</i>) 为第<i>t</i>帧和第<i>t</i>-1帧第<i>h</i>行第<i>w</i>列像素差异, <i>x</i><sub><i>t</i></sub>为第<i>t</i>帧第<i>h</i>行第<i>w</i>列像素的像素值, 有</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>w</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>, </mo></mtd><mtd><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>≠</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo></mtd><mtd><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mn>1</mn><mo>≤</mo><mi>h</mi><mo>≤</mo><mi>Η</mi><mo>, </mo><mspace width="0.25em" /><mn>1</mn><mo>≤</mo><mi>w</mi><mo>≤</mo><mi>W</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">式中:<i>W</i>为图像宽度;<i>H</i>为图像高度。通过</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>w</mi><mo stretchy="false">) </mo></mrow><mrow><mi>W</mi><mo>×</mo><mi>Η</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">计算输入图像与上一帧的亮度差<i>L</i> (<i>x</i><sub><i>t</i></sub>) , 衡量是否有光线突变发生, 如<i>L</i> (<i>x</i><sub><i>t</i></sub>) 满足</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>&lt;</mo><mi>η</mi><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">执行步骤2, 否则执行步骤4。<i>η</i>为固定常数, 一般设为0.4～0.6之间。</p>
                </div>
                <div class="p1">
                    <p id="106">步骤2:<i>x</i><sub><i>t</i></sub>像素点未被分类。</p>
                </div>
                <div class="p1">
                    <p id="107">像素<i>V</i> (<i>x</i><sub><i>t</i></sub>) 满足</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mn>8</mn></munderover><mo stretchy="false"> (</mo></mstyle><mrow><mo>|</mo><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>-</mo><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>&lt;</mo><mi>δ</mi><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109"><i>x</i><sub><i>t</i></sub>为噪声会干扰像素分类, <i>V</i> (<i>x</i><sub><i>t</i></sub>) 表示为</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>m</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>e</mtext><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">[</mo><msup><mi>V</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>8</mn><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">式中:<i>V</i>′<sub><i>j</i></sub> (<i>x</i><sub><i>t</i></sub>) 为像素<i>x</i><sub><i>t</i></sub>3×3窗口内的邻域像素值;<i>δ</i>为固定常数。</p>
                </div>
                <div class="p1">
                    <p id="112">步骤3:<i>x</i><sub><i>t</i></sub>在<i>M</i> (<i>x</i><sub><i>t</i></sub>) 中找到满足</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>V</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>&lt;</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">的值, 则<i>x</i><sub><i>t</i></sub>为背景像素, 样本集中第<i>i</i>个样本频数自增1, 更新时间清零, 其他样本的频数自减1, 更新时间自增1, 式中<i>p</i><sub><i>i</i></sub> (<i>x</i><sub><i>t</i></sub>) 为<i>P</i> (<i>x</i><sub><i>t</i></sub>) 中第<i>i</i>个样本的像素值。</p>
                </div>
                <div class="p1">
                    <p id="115">如果<i>x</i><sub><i>t</i></sub>在<i>M</i> (<i>x</i><sub><i>t</i></sub>) 中未找到满足 (19) 式的值, 则<i>x</i><sub><i>t</i></sub>为前景像素, <i>x</i><sub><i>t</i></sub>的3×3邻域元素<i>x</i><sub><i>j</i></sub>满足</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>∈</mo><mi>C</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">的值设置为前景像素, <i>F</i> (<i>x</i><sub><i>t</i></sub>) 所有元素自减1, <i>T</i> (<i>x</i><sub><i>t</i></sub>) 所有元素自增1, 执行步骤5。</p>
                </div>
                <div class="p1">
                    <p id="118">步骤4:<i>x</i><sub><i>t</i></sub>在<i>M</i> (<i>x</i><sub><i>t</i></sub>) 中找到满足 (20) 式的值, <i>x</i><sub><i>t</i></sub>为背景, 否则为前景, 初始化<i>P</i> (<i>x</i><sub><i>t</i></sub>) 、<i>F</i> (<i>x</i><sub><i>t</i></sub>) 、<i>T</i> (<i>x</i><sub><i>t</i></sub>) 、<i>S</i> (<i>x</i><sub><i>t</i></sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="119">步骤5:更新<i>M</i> (<i>x</i><sub><i>t</i></sub>) 。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">4 实验与结果分析</h3>
                <div class="p1">
                    <p id="121">为验证本文所提背景建模算法的性能, 将该算法在多组数据上进行实验, LightSwitch、Bootstrap、TimeOfDay、WavingTrees来源于Microsoft Wallflower paper数据集, Highway、Canoe、Fountain02来源于CDNet2014<citation id="156" type="reference"><link href="42" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>数据集。LightSwitch、Bootstrap、TimeOfDay为室内场景, 分辨率为160 pixel×120 pixel, WavingTrees、Highway为室外场景, 分辨率为160 pixel×120 pixel和320 pixel×240 pixel, Canoe、Fountain02为复杂场景, 分辨率为320 pixel×240 pixel和432 pixel×288 pixel。</p>
                </div>
                <div class="p1">
                    <p id="122">实验在酷睿i3 3.2 GHz 6.0 GB的计算机上, VS2010、C++和OpenCV3.3.0环境实现算法, 与文献<citation id="157" type="reference">[<a class="sup">9</a>]</citation>中的CodeBook、文献<citation id="158" type="reference">[<a class="sup">8</a>]</citation>的混合高斯模型MOG、文献<citation id="159" type="reference">[<a class="sup">12</a>]</citation>的PBAS和文献<citation id="160" type="reference">[<a class="sup">10</a>]</citation>的ViBe 4种算法作对比实验, CodeBook和MOG建模帧数为15帧, PBAS和ViBe维持原文献中的参数。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>4.1 光线突变场景实验及分析</b></h4>
                <div class="p1">
                    <p id="124">光线突变场景实验中本文选取LightSwitch的闪烁显示器 (755帧) 、开关灯 (801帧) 和摄像头遮挡 (827帧) 3个场景, 结果如图5所示。</p>
                </div>
                <div class="p1">
                    <p id="125">定量分析采用3个信息检索邻域内反映检索效果的重要指标对5种背景建模进行评估, 包括:准确率 (<i>P</i>) , 表示检测出前景目标的正确率;召回率 (<i>R</i>) , 表示所有前景目标有多少被检测出来;误检百分比 (<i>P</i><sub>PWC</sub>) , 表示前景和背景点的错误率。</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>p</mtext></mrow></msub></mrow><mrow><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>p</mtext></mrow></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>p</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><mo>=</mo><mfrac><mrow><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>p</mtext></mrow></msub></mrow><mrow><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>p</mtext></mrow></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>n</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>W</mtext><mtext>C</mtext></mrow></msub><mo>=</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>×</mo><mfrac><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>n</mtext></mrow></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>p</mtext></mrow></msub></mrow><mrow><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>p</mtext></mrow></msub><mo>+</mo><mi>t</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>n</mtext></mrow></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>p</mtext></mrow></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>n</mtext></mrow></msub></mrow></mfrac><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">式中:<i>t</i><sub>tp</sub>为检测正确前景点数;<i>t</i><sub>tn</sub>为检测错误前景点数;<i>f</i><sub>fp</sub>为检测正确背景点数;<i>f</i><sub>fn</sub>为检测错误背景点数。</p>
                </div>
                <div class="p1">
                    <p id="128">CodeBook、MOG、PBAS和ViBe 4种背景建模算法以像素值为主要特征识别前景目标。从图5可以看出, 在光线突变场景下, 由光线突变引起当前背景图像内大量像素的像素值大幅度变化, 导致应为背景的像素无法在模型中正确匹配, 产生大量假前景, 无法正确识别前景目标, 召回率较低, 误检百分比较高。本文算法利用Census变换对光线变化不敏感的特点融合多种特征, 能够在光线突变场景中正确识别前景目标, 从图5和表1可以看出, 本文算法召回率较高、误检百分比较低, 明显优于其他4种算法, 对光线突变场景具有较强的稳健性。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 光线突变场景" src="Detail/GetImg?filename=images/GXXB201908026_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 光线突变场景  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Light mutation scenes</p>

                </div>
                <div class="area_img" id="131">
                    <p class="img_tit">表1 光线突变场景准确性验证 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Light mutation scene accuracy verification</p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td rowspan="2"><br />Method</td><td colspan="3"><br />755th frames</td><td colspan="3"><br />801st frames</td><td colspan="3"><br />827th frames</td></tr><tr><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td></tr><tr><td><br />CodeBook</td><td>0</td><td>0</td><td>0</td><td>0.89</td><td>0.34</td><td>51</td><td>0.78</td><td>0.5</td><td>55</td></tr><tr><td><br />MOG</td><td>0</td><td>0</td><td>0.35</td><td>0.82</td><td>0.38</td><td>41</td><td>0.71</td><td>0.47</td><td>59</td></tr><tr><td><br />PBAS</td><td>0</td><td>0</td><td>0.042</td><td>0.97</td><td>0.33</td><td>55</td><td>0.92</td><td>0.53</td><td>48</td></tr><tr><td><br />ViBe</td><td>0</td><td>0</td><td>0.22</td><td>0.79</td><td>0.33</td><td>48</td><td>0.68</td><td>0.47</td><td>59</td></tr><tr><td><br />Proposed</td><td>0</td><td>0</td><td>0</td><td>0.25</td><td>0.9</td><td>21</td><td>0.32</td><td>0.95</td><td>38</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>4.2 普通背景和复杂背景实验及分析</b></h4>
                <div class="p1">
                    <p id="133">普通和复杂背景实验数据选取Bootstrap共3054张, TimeOfDay共5889张, WavingTrees共286张, Highway共1700张, Canoe共1189张和Fountain02共1499张, 结果如图6所示。</p>
                </div>
                <div class="p1">
                    <p id="134">将初始化模型耗费时间 (<i>M</i><sub>MT</sub>) 和模型对单帧的处理时间 (<i>H</i><sub>HT</sub>) 进行对比, 本文算法初始化模型耗费时间较短, 处理单帧速度较快。结果如表2所示。</p>
                </div>
                <div class="p1">
                    <p id="135">Bootstrap、TimeOfDay、WavingTrees和Highway 4组普通场景的视频序列实验结果如表3所示。Canoe、Fountain02出现不平静的水面、喷泉等复杂背景的实验结果如表4所示。由图6可以看出, 本文算法前景目标提取较为完整, 背景识别错误率较低, 假前景较少, 在复杂背景环境下前景目标识别程度也较高。对表3和表4的定量分析也显示本文算法的准确率、召回率和误检百分比优于其他算法。</p>
                </div>
                <h3 id="136" name="136" class="anchor-tag">5 结  论</h3>
                <div class="p1">
                    <p id="137">提出一种基于改进Census变换的多特征背景建模算法, 用3×3窗口中位数取代中心像素值降低了Census变换特征值对中心像素的依赖, 针对处理对象为连续多幅图像序列, 建立Census模板和模板更新规则, 提高了Census变换对视频图像处理的稳健性, 将改进后的Census变换特征值、图像的像素值、频数、更新时间和动态指数等多种特征融合, 建立了一种新的背景建模方法。该方法能够依据光线变化对视频序列的影响程度自适应地选择融合有效的特征值, 更新背景模型并识别前景目标, 改善了光线突变对目标提取的影响, 利用动态指数来衡量视频不同区域的复杂度, 为不同复杂度的区域设置不同的更新规则, 实验结果表明, 该算法提高了在光线突变和动态复杂场景中提取运动目标的适应性和稳健性。因此, 本文算法可为视频检测系统的背景建模提供有力的技术支持和参考。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GXXB201908026_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 5种算法处理结果对比" src="Detail/GetImg?filename=images/GXXB201908026_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 5种算法处理结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GXXB201908026_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Processing results comparison of five algorithms</p>

                </div>
                <div class="area_img" id="139">
                    <p class="img_tit">表2 5种算法处理速度对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Processing speed comparison of five algorithms</p>
                    <p class="img_note"></p>
                    <table id="139" border="1"><tr><td rowspan="2"><br />Method</td><td colspan="2"><br />WavingTrees</td><td colspan="2"><br />Bootstrap</td><td colspan="2"><br />Highway</td><td colspan="2"><br />Fountain02</td></tr><tr><td><br /><i>M</i><sub>MT</sub></td><td><i>H</i><sub>HT</sub></td><td><br /><i>M</i><sub>MT</sub></td><td><i>H</i><sub>HT</sub></td><td><br /><i>M</i><sub>MT</sub></td><td><i>H</i><sub>HT</sub></td><td><br /><i>M</i><sub>MT</sub></td><td><i>H</i><sub>HT</sub></td></tr><tr><td><br />CodeBook</td><td>0.59</td><td>0.05</td><td>0.62</td><td>0.05</td><td>1.25</td><td>0.08</td><td>1.39</td><td>0.10</td></tr><tr><td><br />MOG</td><td>2.31</td><td>0.29</td><td>2.30</td><td>0.26</td><td>8.50</td><td>1.30</td><td>8.98</td><td>1.63</td></tr><tr><td><br />ViBe</td><td>0.09</td><td>0.03</td><td>0.11</td><td>0.03</td><td>0.45</td><td>0.14</td><td>0.49</td><td>0.18</td></tr><tr><td><br />PBAS</td><td>0.08</td><td>0.37</td><td>0.09</td><td>0.36</td><td>0.31</td><td>0.58</td><td>0.46</td><td>0.61</td></tr><tr><td><br />Proposed</td><td>0.07</td><td>0.08</td><td>0.06</td><td>0.08</td><td>0.36</td><td>0.28</td><td>0.35</td><td>0.39</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="140">
                    <p class="img_tit">表3 普通场景对比实验 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Common scene comparison experiment</p>
                    <p class="img_note"></p>
                    <table id="140" border="1"><tr><td rowspan="2"><br />Method</td><td colspan="3"><br />Bootstrap</td><td colspan="3"><br />TimeOfDay</td><td colspan="3"><br />WavingTrees</td><td colspan="3"><br />Highway</td></tr><tr><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td></tr><tr><td><br />CodeBook</td><td>0.374</td><td>0.626</td><td>11.3</td><td>0.366</td><td>0.998</td><td>4.32</td><td>0.766</td><td>0.727</td><td>16.00</td><td>0.703</td><td>0.891</td><td>4.81</td></tr><tr><td><br />MOG</td><td>0.290</td><td>0.626</td><td>11.7</td><td>0.494</td><td>0.310</td><td>11.00</td><td>0.695</td><td>0.693</td><td>18.70</td><td>0.748</td><td>0.962</td><td>3.55</td></tr><tr><td><br />PBAS</td><td>0.386</td><td>0.568</td><td>12.0</td><td>0.404</td><td>0.981</td><td>4.11</td><td>0.997</td><td>0.677</td><td>14.60</td><td>0.807</td><td>0.98</td><td>2.63</td></tr><tr><td><br />ViBe</td><td>0.397</td><td>0.525</td><td>12.8</td><td>0.315</td><td>0.998</td><td>4.67</td><td>0.654</td><td>0.688</td><td>19.70</td><td>0.706</td><td>0.937</td><td>4.29</td></tr><tr><td><br />Proposed</td><td>0.588</td><td>0.576</td><td>11.2</td><td>0.435</td><td>0.981</td><td>3.90</td><td>0.962</td><td>0.878</td><td>5.25</td><td>0.845</td><td>0.972</td><td>2.25</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit">表4 复杂背景对比实验 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Complex scene comparison experiment</p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td rowspan="2"><br />Method</td><td colspan="3"><br />Canoe</td><td colspan="3"><br />Fountain02</td></tr><tr><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td><td><br /><i>R</i></td><td><i>P</i></td><td><i>P</i><sub>PWC</sub></td></tr><tr><td><br />CodeBook</td><td>0.530</td><td>0.341</td><td>15.90</td><td>0.926</td><td>0.577</td><td>1.570</td></tr><tr><td><br />MOG</td><td>0.295</td><td>0.495</td><td>10.70</td><td>0.609</td><td>0.707</td><td>1.340</td></tr><tr><td><br />PBAS</td><td>0.949</td><td>0.410</td><td>15.10</td><td>0.582</td><td>0.589</td><td>1.720</td></tr><tr><td><br />ViBe</td><td>0.711</td><td>0.663</td><td>6.91</td><td>0.608</td><td>0.684</td><td>1.400</td></tr><tr><td><br />Proposed</td><td>0.833</td><td>0.729</td><td>5.070</td><td>0.809</td><td>0.755</td><td>0.944</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="143">由于本文主要针对较为理想的场景, 在雾霾、沙尘或雨雪等极端气候下, 需要考虑恶劣的室外环境对前景目标提取的影响, 探索适用程度更高的背景建模算法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201901035&amp;v=MDcyMzZxQnRHRnJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg5ak1ybzlHWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Wang H Y, Wang L, Yin W R, <i>et al</i>.Multi-scale correlation filtering visual tracking algorithm combined with target detection[J].Acta Optica Sinica, 2019, 39 (1) :0115004.王红雨, 汪梁, 尹午荣, 等.结合目标检测的多尺度相关滤波视觉跟踪算法[J].光学学报, 2019, 39 (1) :0115004.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811025&amp;v=MzE3OTBWdUZ5bmxXN3pOSWpYVGJMRzRIOW5Ocm85SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Ge B Y, Zuo X Z, Hu Y J.Long-term object tracking based on feature fusion[J].Acta Optica Sinica, 2018, 38 (11) :1115002.葛宝义, 左宪章, 胡永江.基于特征融合的长时目标跟踪算法[J].光学学报, 2018, 38 (11) :1115002.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201706041&amp;v=MjI2OTBiTXFZOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzd6Tkx5SE1kN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Yang C Y, Li C, Liang Y C, <i>et al</i>.Blurred object detection based on improved particle filter in coal mine underground surveilance[J].Journal of Jilin University (Engineering and Technology Edition) , 2017, 47 (6) :1976-1985.杨超宇, 李策, 梁胤程, 等.基于改进粒子滤波的煤矿视频监控模糊目标检测[J].吉林大学学报 (工学版) , 2017, 47 (6) :1976-1985.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201711011&amp;v=Mjk4NTlHRnJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg5Yk5ybzlFWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Sun X W, Xu Q S, Cai Y, <i>et al</i>.Sea sky line detection based on edge phase encoding in complicated background[J].Acta Optica Sinica, 2017, 37 (11) :1110002.孙熊伟, 徐青山, 蔡熠, 等.基于边缘相位编码的复杂背景下海天线检测[J].光学学报, 2017, 37 (11) :1110002.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201702031&amp;v=MjMyMjJYQlk3RzRIOWJNclk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5bmxXN3pOSWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Sui Z S, Li J S, Zhang J, <i>et al</i>.Video foreground detection of tensor low-rank representation and spatial-temporal sparsity decomposition[J].Optics and Precision Engineering, 2017, 25 (2) :529-536.隋中山, 李俊山, 张姣, 等.张量低秩表示和时空稀疏分解的视频前景检测[J].光学精密工程, 2017, 25 (2) :529-536.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JJZZ201907031&amp;v=MjAzOTJGeW5sVzd6Tkx5ZlJkTEc0SDlqTXFJOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Ma J J, Pan Q, Liang Y, <i>et al</i>.Object detection based on improved Grassberger entropy random forest classifier[J].Chinese Journal of Lasers, 2019, 46 (7) :0704011.马娟娟, 潘泉, 梁彦, 等.基于改进Grassberger熵随机森林分类器的目标检测[J].中国激光, 2019, 46 (7) :0704011.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pfinder: Real-time tracking of the human body">

                                <b>[7]</b> Wren C R, Azarbayejani A, Darrell T, <i>et al</i>.Pfinder:real-time tracking of the human body[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997, 19 (7) :780-785.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Background Mixture Models for Real-time Tracking">

                                <b>[8]</b> Stauffer C, Grimson W E L.Adaptive background mixture models for real-time tracking[C]∥1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 23-25, 1999, Fort Collins, CO, USA.New York:IEEE, 1999:246-252.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201204011&amp;v=MTUxMDNVUkxPZVplVnVGeW5sVzd6TktDTGZZYkc0SDlQTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Huo D H, Yang D, Zhang X H, <i>et al</i>.Principal component analysis based codebook background modeling algorithm[J].Acta Automatica Sinica, 2012, 38 (4) :591-600.霍东海, 杨丹, 张小洪, 等.一种基于主成分分析的Codebook背景建模算法[J].自动化学报, 2012, 38 (4) :591-600.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ViBe: A Universal Background Subtraction Algorithm for Video Sequences">

                                <b>[10]</b> Barnich O, van Droogenbroeck M.ViBe:a universal background subtraction algorithm for video sequences[J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201515005&amp;v=MDcwMTRubFc3ek5NaUhUYkxHNEg5VE5xbzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Bi G L, Xu Z J, Chen T, <i>et al</i>.Complex background model and foreground detection based on random aggregation[J].Acta Physica Sinica, 2015, 64 (15) :150701.毕国玲, 续志军, 陈涛, 等.基于随机聚类的复杂背景建模与前景检测算法[J].物理学报, 2015, 64 (15) :150701.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201703009&amp;v=MjA1MDZPZVplVnVGeW5sVzd6TklqclBkTEc0SDliTXJJOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Zhang Z B, Yuan X B.An improved PBAS algorithm for dynamic background[J].Electronic Design Engineering, 2017, 25 (3) :35-40.张泽斌, 袁哓兵.一种改进反馈机制的PBAS运动目标检测算法[J].电子设计工程, 2017, 25 (3) :35-40.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient computation of optical flow using the census transform">

                                <b>[13]</b> Stein F.Efficient computation of optical flow using the census transform[M]//Rasmussen C E, Bülthoff H H, Schölkopf B, <i>et al</i>.Pattern recognition.Lecture notes in computer science.Berlin, Heidelberg:Springer, 2004, 3175:79-86.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811030&amp;v=MTQ1MTh6TklqWFRiTEc0SDluTnJvOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Yan L, Wang R, Liu H, <i>et al</i>.Stereo matching method based on improved cost computation and adaptive guided filter[J].Acta Optica Sinica, 2018, 38 (11) :1115007.闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :1115007.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDGC201812006&amp;v=MDQ0NTNZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5sVzd6Tklpbk1iYkc0SDluTnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Guo Z C, Dang J W, Wang Y P, <i>et al</i>.Background modeling method based on multi-feature fusion[J].Opto-Electronic Engineering, 2018, 45 (12) :180206.郭治成, 党建武, 王阳萍, 等.基于多特征融合的背景建模方法[J].光电工程, 2018, 45 (12) :180206.
                            </a>
                        </p>
                        <p id="40">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modeling Pixel Process with ScaleInvariant Local Patterns for Background Subtraction in Complex Scenes">

                                <b>[16]</b> Liao S C, Zhao G Y, Kellokumpu V, <i>et al</i>.Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes[C]//2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 13-18, 2010, San Francisco, CA, USA.New York:IEEE, 2010:1301-1306.
                            </a>
                        </p>
                        <p id="42">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CDnet 2014:An expanded change detection benchmark dataset">

                                <b>[17]</b> Wang Y, Jodoin P M, Porikli F, <i>et al</i>.CDnet 2014:an expanded change detection benchmark dataset[C]∥2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, June 23-28, 2014, Columbus, OH, USA.New York:IEEE, 2014:393-400.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GXXB201908026" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201908026&amp;v=MjQ0NjJDVVJMT2VaZVZ1RnlubFc3ek5JalhUYkxHNEg5ak1wNDlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9rakVxV3hmUTNNTFVERjZkUE9iUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

