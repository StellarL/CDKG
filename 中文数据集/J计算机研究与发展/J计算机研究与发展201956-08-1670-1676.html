

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127884117931250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201908010%26RESULT%3d1%26SIGN%3dS%252fD2pYTLGE%252fmnY%252fHJ7r9DUd%252b%252fbo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201908010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201908010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201908010&amp;v=MjAzNTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXZnVkx2Skx5dlNkTEc0SDlqTXA0OUVaSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 背景知识&lt;/b&gt; "><b>1 背景知识</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#92" data-title="&lt;b&gt;2 多示例深度森林&lt;/b&gt; "><b>2 多示例深度森林</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;2.1 多示例森林&lt;/b&gt;"><b>2.1 多示例森林</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;2.2 多示例深度森林&lt;/b&gt;"><b>2.2 多示例深度森林</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;3 实验测试&lt;/b&gt; "><b>3 实验测试</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#111" data-title="&lt;b&gt;3.1 任务及其数据集&lt;/b&gt;"><b>3.1 任务及其数据集</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;3.2 实验设计&lt;/b&gt;"><b>3.2 实验设计</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;3.3 实验结果&lt;/b&gt;"><b>3.3 实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#95" data-title="图1 类向量生成示意图">图1 类向量生成示意图</a></li>
                                                <li><a href="#107" data-title="图2 多示例深度森林级联示意图">图2 多示例深度森林级联示意图</a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;表1 数据集的具体信息&lt;/b&gt;"><b>表1 数据集的具体信息</b></a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表2 药物和图片标注数据集上不同算法的平均预测准确率&lt;/b&gt;"><b>表2 药物和图片标注数据集上不同算法的平均预测准确率</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表3 文本分类数据集上不同算法的平均预测准确率&lt;/b&gt;"><b>表3 文本分类数据集上不同算法的平均预测准确率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="150">


                                    <a id="bibliography_1" title="Dietterich T G, Lathrop R H, Lozano-P&#233;rez T.Solving the multiple instance problem with axis-parallel rectangles[J].Artificial Intelligence, 1997, 89 (1/2) :31- 71" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702007540&amp;v=MDQ4NDFJOUhaT3NJQ1hnNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxySUkxc1RiaE09TmlmT2ZiSzdIdEROcQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Dietterich T G, Lathrop R H, Lozano-P&#233;rez T.Solving the multiple instance problem with axis-parallel rectangles[J].Artificial Intelligence, 1997, 89 (1/2) :31- 71
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_2" title="Amores J.Multiple instance classification:Review, taxonomy and comparative study[J].Artificial Intelligence, 2013, 201:81- 105" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080200174321&amp;v=MTYyMjNHZXJxUVRNbndaZVp1SHlqbVVMcklJMXNUYmhNPU5pZk9mYks3SHRuTXJZOUZaZXdMRDM0NG9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Amores J.Multiple instance classification:Review, taxonomy and comparative study[J].Artificial Intelligence, 2013, 201:81- 105
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_3" title="Andrews S, Tsochantaridis I, Hofmann T.Support vector machines for multiple-instance learning[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2003:577- 584" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Support Vector Machines for Multiple-Instance Learning">
                                        <b>[3]</b>
                                        Andrews S, Tsochantaridis I, Hofmann T.Support vector machines for multiple-instance learning[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2003:577- 584
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_4" title="Zhou Zhihua, Sun Yuyin, Li Yufeng.Multi-instance learning by treating instances as non-iid samples[C] //Proc of the 26th Annual Int Conf on Machine Learning.New York:ACM, 2009:1249- 1256" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-instance learning by treating instances as non-I.I.D.samples">
                                        <b>[4]</b>
                                        Zhou Zhihua, Sun Yuyin, Li Yufeng.Multi-instance learning by treating instances as non-iid samples[C] //Proc of the 26th Annual Int Conf on Machine Learning.New York:ACM, 2009:1249- 1256
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_5" title="Chen Yinxin, Bi Jinbo, Wang J Z.MILES:Multiple-instance learning via embedded instance selection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :1931- 1947" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MILES: Multiple-Instance Learning via Embedded Instance Selection">
                                        <b>[5]</b>
                                        Chen Yinxin, Bi Jinbo, Wang J Z.MILES:Multiple-instance learning via embedded instance selection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :1931- 1947
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_6" title="Krizhevsky A, Sutskever I, Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2012:1097- 1105" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[6]</b>
                                        Krizhevsky A, Sutskever I, Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2012:1097- 1105
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_7" title="Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of the 2015 Conf on Empirical Methods in Natural Language Processing.Stroudsburg, PA:ACL, 2015:1753- 1762" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks">
                                        <b>[7]</b>
                                        Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of the 2015 Conf on Empirical Methods in Natural Language Processing.Stroudsburg, PA:ACL, 2015:1753- 1762
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_8" title="Goodfellow I, Bengio Y, Courville A.Deep Learning[M].Cambridge, MA:MIT Press, 2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Learning">
                                        <b>[8]</b>
                                        Goodfellow I, Bengio Y, Courville A.Deep Learning[M].Cambridge, MA:MIT Press, 2016
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_9" title="Wang Xinggang, Yan Yongluan, Tang Peng, et al.Revisiting multiple instance neural networks[J].Pattern Recognition, 2018, 74 (C) :15- 24" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9B047D00494268C33E75A09156148386&amp;v=MDI1ODV0WEwyNDlGWU9JTERub3h2QlVRbnpoNE9YL3JyUmN6ZUxhY1JyS1pDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOMWh4NzI0eEtrPU5pZk9mYnJLSA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Wang Xinggang, Yan Yongluan, Tang Peng, et al.Revisiting multiple instance neural networks[J].Pattern Recognition, 2018, 74 (C) :15- 24
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_10" title="Zhou Zhihua, Feng Ji.Deep forest:Towards an alternative to deep neural networks[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.San Francisco, CA:Morgan Kaufmann, 2017:3553- 3559" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Forest:Towards an alternative to Deep Neural Networks">
                                        <b>[10]</b>
                                        Zhou Zhihua, Feng Ji.Deep forest:Towards an alternative to deep neural networks[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.San Francisco, CA:Morgan Kaufmann, 2017:3553- 3559
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_11" title="Chevaleyre Y, Zucker J D.Solving multiple-instance and multiple-part learning problems with decision trees and rule sets.Application to the mutagenesis problem[C] //Proc of the Conf of the Canadian Society for Computational Studies of Intelligence.Berlin:Springer, 2001:204- 214" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Solving multiple-instance and multiple-part learning problems with decision trees and decision rules">
                                        <b>[11]</b>
                                        Chevaleyre Y, Zucker J D.Solving multiple-instance and multiple-part learning problems with decision trees and rule sets.Application to the mutagenesis problem[C] //Proc of the Conf of the Canadian Society for Computational Studies of Intelligence.Berlin:Springer, 2001:204- 214
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_12" title="Kom&#225;rek T, Somol P.Multiple instance learning with bag-level randomized trees[C] //Proc of the Joint European Conf on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer, 2018:259- 272" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple instance learning with bag-level randomized trees">
                                        <b>[12]</b>
                                        Kom&#225;rek T, Somol P.Multiple instance learning with bag-level randomized trees[C] //Proc of the Joint European Conf on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer, 2018:259- 272
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_13" title="Amit Y, Geman D.Shape quantization and recognition with randomized trees[J].Neural Computation, 1997, 9 (7) :1545- 1588" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014189&amp;v=MjQwMTBLOUh0ak1xbzlGWk9vTERYUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklJMXNUYmhNPU5pZkpaYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Amit Y, Geman D.Shape quantization and recognition with randomized trees[J].Neural Computation, 1997, 9 (7) :1545- 1588
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_14" title="Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5- 32" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDY3OTdJdEZadXdPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQzNsVUxyUEpGOD1OajdCYXJPNEh0SE5y&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5- 32
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_15" title="Geurts P, Ernst D, Wehenkel L.Extremely randomized trees[J].Machine Learning, 2006, 63 (1) :3- 42" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001341091&amp;v=MDA2MjZkdEZDM2xVTHJQSkY4PU5qN0Jhck80SHRITnJJdEVaT0lPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Geurts P, Ernst D, Wehenkel L.Extremely randomized trees[J].Machine Learning, 2006, 63 (1) :3- 42
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(08),1670-1676 DOI:10.7544/issn1000-1239.2019.20190332            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>多示例学习下的深度森林架构</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">任婕</a>
                                <a href="javascript:;">侯博建</a>
                                <a href="javascript:;">姜远</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8D%97%E4%BA%AC%E5%A4%A7%E5%AD%A6)&amp;code=0069758&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机软件新技术国家重点实验室(南京大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%A7%E4%B8%9A%E5%8C%96%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83(%E5%8D%97%E4%BA%AC%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">软件新技术与产业化协同创新中心(南京大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>多示例学习已经广泛地应用到各个领域, 如图像检索、文本分类、人脸识别等.而近年来深度神经网络也成功地运用到各个任务和问题上, MI-Nets是深度神经网络在多示例学习领域一个成功的应用.虽然MI-Nets很成功, 但其主要在图像相关的任务上表现突出, 而在非图像任务比如文本分类任务上的性能并不令人满意.而最近2年兴起的深度森林在非图像任务上取得了较好的成绩, 并因为其相对于深度神经网络有较少的参数和较稳定的性能而受到青睐.所以用深度森林来提升多示例学习性能具有可行性.但由于深度森林结构的限制, 并不能把组成深度森林的每一个森林都直接替换成包级别的森林, 需要修改深度森林的结构来达到目的.提出了一种新的深度森林架构MIDF.在该架构下, 为了使得中间层的输出分布可以和包中的示例拼接成功, 拼接时把包里的每个示例都看作是一个包, 从而使得级联结构依然有效.另外, 还能自动确认深度森林的层数.实验结果表明:该方法在图像任务上的性能与擅长处理图像任务的MI-Nets相当;而在文本数据上, 该方法取得了比MI-Nets和其他基线算法更好的效果.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多示例学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E6%A3%AE%E6%9E%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度森林;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">监督学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非图像分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *姜远, jiangy@lamda.nju.edu.cn;
                                </span>
                                <span>
                                    任婕, renj@lamda.nju.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61673201);</span>
                    </p>
            </div>
                    <h1><b>Deep Forest for Multiple Instance Learning</b></h1>
                    <h2>
                    <span>Ren Jie</span>
                    <span>Hou Bojian</span>
                    <span>Jiang Yuan</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Multi-instance learning has been applied to various tasks, such as image retrieval, text classification, face recognition, etc. Deep neural network has also been successfully applied to plenty of tasks and problems. MI-Nets are one of the successful applications to multi-instance learning of deep neural network. Although MI-Nets have obtained achievements and the main task they are good at is image task, while on non-image tasks, they show mediocre performance. Over the last two years, deep forest has achieved good performance on non-image tasks and is favored for its less parameters and steady performance compared with deep neural network. Thus it is urgent and necessary to apply deep forest to multi-instance learning. However, due to the limitation of the structure of deep forest, we cannot simply substitute the bag-level forest for each forest of deep forest. Therefore, we need to change the structure of deep forest to achieve our purpose. In this paper, we provide a new structure of deep forest, that is multiple instance deep forest (MIDF) . We regard each instance from a bag as a new bag, and thus the distribution output from the middle level can concatenate the original bag to make the cascade structure valid. We can also assure the number of layers of MIDF. Experimental results show that our method has comparable performance with MI-Nets on image task, while on non-image tasks, our method outperforms MI-Nets and other baseline methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-instance%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-instance learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20forest&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep forest;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=supervised%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">supervised learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-image%20categorization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-image categorization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Ren Jie, born in 1995.Master in Nanjing University.Her main research interests include artificial intelligence, machine learning and data mining. <image id="144" type="" href="images/JFYZ201908010_14400.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Hou Bojian, born in 1992.PhD candidate in Nanjing University.His main research interests include artificial intelligence, machine learning and data mining. (houbj @lamda.nju.edu.cn) <image id="146" type="" href="images/JFYZ201908010_14600.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Jiang Yuan, born in 1976.PhD, professor in the Department of Computer Science and Technology at Nanjing University.Her main research interests include artificial intelligence, machine learning, and data mining. (jiangy@lamda.nju.edu.cn) <image id="148" type="" href="images/JFYZ201908010_14800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-03</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61673201);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="36">多示例学习 (multiple instance learning, MIL) 在药物活性预测调查期间被首次提出<citation id="180" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.与传统的单示例学习不同, 多示例学习的输入是一组标签为正或负的包, 而不是一组标签为正或负的示例.在多示例学习中我们不会得到任何示例的标签信息.如今, 多示例学习已经广泛地应用于各种领域, 如图像分类检索、人脸识别、文本分类、计算机辅助医疗诊断等<citation id="181" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.在过去的时间里, 已经提出了很多有效的MIL算法<citation id="182" type="reference"><link href="154" rel="bibliography" /><link href="156" rel="bibliography" /><link href="158" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="37">而近年来, 深度神经网络也在各个领域都取得了很好的效果<citation id="184" type="reference"><link href="160" rel="bibliography" /><link href="162" rel="bibliography" /><link href="164" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>.其中MI-Net with DS和MI-Net with RC<citation id="183" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>是深度神经网络在多示例学习领域的成功应用, 它使用了深度学习的技巧:深度监督和剩余连接, 在图像领域的数据上取得了优异的成绩.然而在非图像任务上的性能并不像在图像任务上那么优秀.与大部分的深度神经网络模型一样, 它也需要人工针对不同的数据集进行结构调整和参数选择.</p>
                </div>
                <div class="p1">
                    <p id="38">最近几年, 深度森林<citation id="185" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>进入了人们的视野.这是一种基于非可微模块构建的深度模型, 具有比深度神经网络少得多的超参数, 同时其模型复杂性可以通过数据相关的方式自动确定.实验表明, 其性能对于超参数设置非常稳健, 因此在大多数情况下, 即使面对来自不同领域的不同数据, 也可以通过使用相同的默认设置获得出色的性能.此外由于决策树的特性, 深度森林在非图像的领域上也有着不错的效果.</p>
                </div>
                <div class="p1">
                    <p id="39">因此在非图像任务上利用深度森林架构来解决多示例学习问题或许是一种更好的选择.Amores<sup></sup><citation id="186" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>指出包级别的算法通常比示例级的算法效果要好.但由于深度森林结构的限制, 组成深度森林的每一个森林并不能直接被替换成包级别的森林, 所以并不能把包级别的思想直接套用到深度森林框架上.这就使得我们需要提出一种新的深度森林结构来解决多示例学习问题.</p>
                </div>
                <div class="p1">
                    <p id="40">本文提出了一种新的深度森林架构 (multiple instance deep forest, MIDF) , 使用了包级的算法思想.在拼接时我们把包里的每个示例都看做是一个包, 从而使得中间层的输出分布可以和包中的示例拼接成功, 让级联结构依然有效.此外我们的架构由2个级联结构组成, 一个使用<i>k</i>折交叉验证来帮助自动确定深度森林的层数, 另一个根据所求的层数来计算最终的结果.实验结果表明:我们的方法在图像任务上的性能与擅长处理图像任务的MI-Net with DS和MI-Net with RC相当;而在文本数据上, 我们的算法取得了比它们和其他基线算法更好的效果.</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag"><b>1 背景知识</b></h3>
                <div class="p1">
                    <p id="42">本节主要介绍多示例学习问题的定义, 并回顾一个经典的基于包级别的多示例决策树算法ID3-MI<citation id="187" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="43">多示例学习 (MIL) 问题最初在药物活性预测中提出.现在多示例学习已经被广泛应用于许多领域, 并成为机器学习中的一个重要问题.在大量的多媒体数据中都包含着多示例 (multiple instance, MI) 结构, 例如文本数据中的文章可以被分为多个段落, 图像数据可以被划分成多个局部区域, 基因表达数据包含着多个基因.多示例学习能够有效地处理这些多示例 (MI) 数据.</p>
                </div>
                <div class="p1">
                    <p id="44">多示例学习 (MIL) 是一种弱监督学习 (weakly supervised learning, WSL) .在MIL中, 每一个训练样本都是一个由许多示例组成的包.对于二分类问题, 如果一个包中存在至少一个标签为正的示例, 那么我们称这样的包是一个正包.如果一个包中的示例标签都为负, 那么我们称这样的包是一个负包.尽管我们可以得到包的标签, 但是所有示例的标签都是未知的.多示例学习的目标就是要在这样的假设下, 训练出一个学习器能够很好地预测出包的标签.用形式化的语言来说:假设X是一个示例空间, Y是一个类别标签的集合.给定一个数据集{ (<i>X</i><sub>1</sub>, <i>y</i><sub>1</sub>) , (<i>X</i><sub>2</sub>, <i>y</i><sub>2</sub>) , …, (<i>X</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) , …, (<i>X</i><sub><i>N</i></sub>, <i>y</i><sub><i>N</i></sub>) }, 其中<i>X</i><sub><i>i</i></sub>={<b><i>x</i></b><mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, <b><i>x</i></b><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, …, <i>x</i><mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, …, <i>x</i><mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>}⊆X表示一个包, <i>y</i><sub><i>i</i></sub>∈Y={-1, +1}表示<i>X</i><sub><i>i</i></sub>的标签, 多示例学习的任务就是去寻找一个能够分类未知标签包的函数<i>f</i>:2<sup>X</sup>→{-1, +1}.</p>
                </div>
                <div class="p1">
                    <p id="49">目前已经有许多算法被用来解决MIL问题.根据Amores的调查, MIL算法可以分为3个种类:示例空间 (instance space, IS) 范式、包空间 (bag space, BS) 范式和嵌入空间 (embedded space, ES) 范式.简而言之, 对于IS范式, 判别信息被认为是在示例级别上的, 而在BS范式中, 判别信息是在包级别上的.ES范式中的多示例学习算法明确或隐含地将每个包映射到单个特征向量上, 该特征向量总结了关于整个包的相关信息.</p>
                </div>
                <div class="p1">
                    <p id="50">ID3-MI算法就是一种包级多实例学习的算法, 它遵循的是一种常见的分而治之的决策树方式.众所周知, 决策树算法有着2个重要组成部分:1) 如何选择分割树节点的属性;2) 如何使用树进行预测.因此ID3-MI算法使用与标准决策树相同的方法来进行预测, 也就是使用未知标签的包所落入的叶子节点的标签来确定该包的标签.显然ID3-MI算法的关键是如何定义一种衡量标准用来选择决策树的划分点.</p>
                </div>
                <div class="p1">
                    <p id="51">对于传统的熵 (entropy) , 不妨假设数据集<i>D</i>包含<i>p</i>个正例和<i>n</i>个负例, 那么依据类别得到的<i>D</i>的熵可以写作:</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mfrac><mi>p</mi><mrow><mi>p</mi><mo>+</mo><mi>n</mi></mrow></mfrac><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mfrac><mi>p</mi><mrow><mi>p</mi><mo>+</mo><mi>n</mi></mrow></mfrac><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mfrac><mi>n</mi><mrow><mi>p</mi><mo>+</mo><mi>n</mi></mrow></mfrac><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mfrac><mi>n</mi><mrow><mi>p</mi><mo>+</mo><mi>n</mi></mrow></mfrac><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">如果选择在属性<i>V</i>上划分, 并将<i>D</i>划分为{<i>D</i><sub>1</sub>, <i>D</i><sub>2</sub>, …, <i>D</i><sub><i>l</i></sub>}, 那么此时的熵可以写作:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mrow><mfrac><mrow><mrow><mo>|</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">此时的信息增益可以写作:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mrow><mfrac><mrow><mrow><mo>|</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></mfrac></mrow></mstyle><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">对于多示例学习, 我们只需要考虑如何把计算正负例的个数转换成计算正负包的个数.假设<i>π</i> (X) 和<i>ν</i> (X) 分别表示在数据集X中出现的正包和负包的个数.那么使用<i>V</i>来划分数据集<i>D</i>所得到的熵可以写作:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mo>-</mo><mfrac><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mfrac><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mfrac><mrow><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mrow><mfrac><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></mstyle><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">使用相同思路可以得到多示例学习下的信息增益:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mrow><mfrac><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></mstyle><mi>Ι</mi><mi>n</mi><mi>f</mi><mi>o</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>u</mtext><mtext>l</mtext><mtext>t</mtext><mtext>i</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">算法1通过伪代码的形式给出了包级多实例决策树ID3-MI生成决策树过程的详细描述:</p>
                </div>
                <div class="area_img" id="149">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201908010_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="149">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201908010_14901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="92" name="92" class="anchor-tag"><b>2 多示例深度森林</b></h3>
                <div class="p1">
                    <p id="93">多示例深度森林同时具有多示例森林和深度森林的优势.但是简单地将两者结合起来并不可行, 我们需要更有效的结合方式.</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>2.1 多示例森林</b></h4>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201908010_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 类向量生成示意图" src="Detail/GetImg?filename=images/JFYZ201908010_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 类向量生成示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201908010_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The illustration of class vector generation</p>

                </div>
                <div class="p1">
                    <p id="96">本节介绍2种多示例森林算法MIRF和BLRT<citation id="188" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation> , 它们分别受到随机森林算法和极根随机树算法的启发.</p>
                </div>
                <div class="p1">
                    <p id="97">随机森林 (random forests, RFs) 最初由Amit等人提出<citation id="189" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>并由Breiman<citation id="190" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>扩展.在随机森林中, 每一棵树的训练集都是通过对原始训练集的有放回采样 (自助采样法bootstrap) 得到的.除此之外, 在建树时对每个节点划分的选择也不再是对所有的属性计算一个最优化分, 而是在属性集的一个随机子集中选择最优化分属性.如果我们假设所有的样本属性总数都是<i>d</i>, 那么随机森林通常会挑出<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mi>d</mi></msqrt></mrow></math></mathml>个属性用于选择最优化分.多示例随机森林 (<i>MIRF</i>) 使用了和随机森林类似的集成方法, 它们之间的区别是<i>MIRF</i>集成的是包级多示例决策树<i>ID</i>3-<i>MI</i>而非传统的决策树.</p>
                </div>
                <div class="p1">
                    <p id="99">在极根随机树算法 (<i>ExtraTrees</i>) <citation id="191" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>中, 使用了更进一步的随机化步骤.与随机森林一样, 极根随机树也是在候选特征的随机子集上来寻找划分, 但不同的是极根随机树并非在每个属性上计算最优划分点, 而是在这些属性上随机选择划分点.换言之这个值是在属性的经验范围内均匀随机选取的.在所有的随机划分点中, 极根随机树会选择其中最优的作为该节点的划分点.<i>BLRT</i>受到了极根随机树的影响, 并将传统的<i>ExtraTree</i>像<i>ID</i>3-<i>MI</i>那样推广成了包级多示例<i>ExtraTree</i>.</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"><b>2.2 多示例深度森林</b></h4>
                <div class="p1">
                    <p id="101">多示例深森林 (MIDF) 受到了深度森林的启发, 它也具有级联结构, 级联的每一层都是从其前一层接收特征, 并将结果发送给下一层作为输入.MIDF的每一层都是MIRF和BLRT这2种不同多示例森林的集成, 使用不同种类的森林集成可以增加MIDF算法的多样性.</p>
                </div>
                <div class="p1">
                    <p id="102">在深度森林中, 如果将示例提供给级联结构的某一层, 则这一层中所有的森林都会预测出一个类别分布的估计值, 并将这个分布估计值转化为类别向量, 如图1所示.之后我们将类别向量与原始特征向量拼接起来, 作为输入传递给下一层.但在MIDF中, 得到该层中的每个森林所给出的包级预测后, 我们不能简单地将长度为2的类别向量与大小为<i>n</i><sub><i>i</i></sub>×<i>d</i>的原始特征矩阵直接拼接起来, 因为他们在维度上并不相同.</p>
                </div>
                <div class="p1">
                    <p id="103">为了解决拼接问题, 我们将所有的森林都按包级进行训练 (不妨假设每层由2个MIDF和2个BLRT组成) .之后对于任意包<i>X</i><sub><i>i</i></sub>⊆X, 将其中的每个示例<b><i>x</i></b><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>∈<i>X</i><sub><i>i</i></sub>都看作一个包, 这样会得到一个新的包集合X ′, 并把它提供给当前层的森林.森林会给出一个大小为2×<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>n</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>的类别向量的集合.此时训练集中的每个示例都可以与一个长度为2的类别向量进行拼接.在做好拼接之后, 我们重新按照X将所有的示例划分成包, 得到新的集合X ″, 并把它作为输入传递给下一层.X ″中的每个示例<b><i>x</i></b><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>∈<i>X</i><sub><i>i</i></sub>都有个<i>d</i>+8个属性.图2的级联结构中详细地给出了具体的拼接过程.</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201908010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 多示例深度森林级联示意图" src="Detail/GetImg?filename=images/JFYZ201908010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 多示例深度森林级联示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201908010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The illustration of the cascade structure of multiple instance deep forest</p>

                </div>
                <div class="p1">
                    <p id="108">本文算法由2个级联结构组成:1) 用于确定MIDF的层数;2) 用于计算最终预测结果.第1个级联中的每个森林所预测出的类别向量都是通过<i>k</i>折交叉验证得到的, 这里我们通常取<i>k</i>=3.详细地, 每个示例都会被用作训练数据<i>k</i>-1次, 产生<i>k</i>-1个类别向量, 然后对其取平均值以产生用于传递给下一层的增强特征.此外, 在扩展一个新层之后, 整个级联的性能将在验证集上进行评估, 如果没有显著的性能增益, 那么训练过程将会终止.因此, 我们可以通过第1个级联结构来自动地确定级联的层数.第2个级联的每一层则使用了完整的训练数据, 其训练的层数由第1个级联结构计算给出, 并得到最终的预测结果.</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>3 实验测试</b></h3>
                <div class="p1">
                    <p id="110">在本节中, 我们分别在多个多示例学习基准数据集上进行实验, 包括分子活动、图像识别以及文本分类数据集.并在这些数据集上对比多示例深度森林算法 (MIDF) 、Wang等人提出的多示例神经网络算法 (MI-Net with DS和MI-Net with RC) 以及MILES, miGraph, ID3-MI, MIRF等多示例学习算法的效果.</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.1 任务及其数据集</b></h4>
                <div class="p1">
                    <p id="112">我们分别在3类任务上进行实验:</p>
                </div>
                <div class="p1">
                    <p id="113">1) 药物激活预测.Musk数据集是1997年由Dietterich等人发布的关于预测分子是否具有麝香味的数据集.由于每个分子都可以被描述为它能够折叠成的不同形状 (构象异构体) , 我们将每个分子对应为一个包, 而包中的每一个示例则对应该分子的不同构象.其中, 不同构象负责分子的不同性质, 也就是它的气味.在实验里, 如果至少包含一种能够让分子产生麝香味的构象, 我们就将这个分子 (包) 标为正类, 如果没有任何一种构象具有这种性质, 我们就把这个分子标为负类.</p>
                </div>
                <div class="p1">
                    <p id="114">2) 自动图像标注.在这一类任务中有3个比较有名的数据集, 分别是Andrews等人于2002年提出的Fox, Tiger和Elephant数据集<citation id="192" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.在这类任务中, 我们把图像本身作为包, 图像的不同区域作为包中的示例.对于每个类别, 如果图像包含该类动物, 我们就把这个图像看作为正包, 如果图像仅包含其他动物 (来自其他类别的动物, 不仅仅是Fox, Tiger和Elephant) , 那我们将其看作为负包.</p>
                </div>
                <div class="p1">
                    <p id="115">3) 文本分类.我们从一个名为20 Newsgroups的语料库中生成了20个文本分类数据集, 对于20个新闻类别中的每一个都生成了50个正包和50个负包.其中每个正包都包含了从目标类别中随机抽取的3%的示例, 并从其他类别中随机均匀采样剩余示例, 每个负包则只包含从其他类别中均匀采样的示例, 并不包含本类别的数据.在所生成的包中的每个示例均拥有80维的特征.</p>
                </div>
                <h4 class="anchor-tag" id="116" name="116"><b>3.2 实验设计</b></h4>
                <div class="p1">
                    <p id="117">我们设计实验用来验证本文的多示例深度森林算法能够与深度神经网络以及其他算法在多个数据集上效果相当, 并且在某些数据集上会取得更好的效果, 同时我们的算法还能够更加容易地进行超参数的调整.在实验中, 对于所有的数据集, 我们都使用相同的级联结构 (参数) :每一层由2个包级多示例极跟随机树 (BLRT) 和2个包级多示例随机森林 (MIRF) 构成, 其中每个森林均包含50棵树.</p>
                </div>
                <div class="p1">
                    <p id="118">对于深度神经网络, 我们使用Wang等人在2018年提出的MI-Net with DS和MI-Net with RC算法, 这些算法都需要设定不同的学习率、权重衰减和动量值来获得在不同数据集上的高性能.因此, 我们进行实验时在验证集上验证不同参数的效果, 选择最佳的参数, 并在训练集上重新训练得到最终的预测结果.</p>
                </div>
                <div class="p1">
                    <p id="119">对于其余的多示例算法我们也使用了和MI-Net with DS和MI-Net with RC一样的方法来确定它们在不同数据集上的最优参数, 并使用该参数得到最终的预测结果.</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>3.3 实验结果</b></h4>
                <div class="p1">
                    <p id="121">我们通过10次10折交叉验证来比较ID3-MI、MIRF以及MIDF算法的性能 (运行10次10折交叉验证, 每次采取不同的随机数据划分) .表1和表2展示了测试准确率的比较.</p>
                </div>
                <div class="p1">
                    <p id="122">表1给出了在药物激活预测以及自动图像标注任务上的实验结果, 表2给出了在文本分类任务上的实验结果, 其中用黑体加粗来标注得到的最好结果.</p>
                </div>
                <div class="area_img" id="123">
                    <p class="img_tit"><b>表1 数据集的具体信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Detailed Characteristics of Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="123" border="1"><tr><td rowspan="2"><br />Datasets</td><td rowspan="2">Attribute</td><td colspan="3"><br />Bag</td><td rowspan="2">Instance</td></tr><tr><td><br />Positive</td><td>Negative</td><td>Total</td></tr><tr><td>Musk1</td><td>166</td><td>47</td><td>45</td><td>92</td><td>476</td></tr><tr><td><br />Musk2</td><td>166</td><td>39</td><td>63</td><td>102</td><td>6 598</td></tr><tr><td><br />Elephant</td><td>230</td><td>100</td><td>100</td><td>200</td><td>1 220</td></tr><tr><td><br />Tiger</td><td>230</td><td>100</td><td>100</td><td>200</td><td>1 391</td></tr><tr><td><br />Fox</td><td>230</td><td>100</td><td>100</td><td>200</td><td>1 320</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表2 药物和图片标注数据集上不同算法的平均预测准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Average Prediction Accuracy of Different Methods for Drug and Image Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td>Algorithms</td><td>Musk1</td><td>MUSK2</td><td>Elephant</td><td>Fox</td><td>Tiger</td></tr><tr><td><br />MILES</td><td>0.84</td><td>0.80</td><td>0.82</td><td><b>0.61</b></td><td>0.80</td></tr><tr><td><br />miGraph</td><td>0.88</td><td>0.84</td><td>0.80</td><td>0.60</td><td>0.79</td></tr><tr><td><br />MI-Net with RC</td><td>0.88</td><td><b>0.85</b></td><td>0.84</td><td>0.60</td><td><b>0.81</b></td></tr><tr><td><br />MI-Net with DS</td><td><b>0.89</b></td><td>0.84</td><td><b>0.85</b></td><td>0.59</td><td><b>0.81</b></td></tr><tr><td><br />ID3-MI</td><td>0.77</td><td>0.71</td><td>0.67</td><td>0.56</td><td>0.69</td></tr><tr><td><br />MIRF</td><td>0.87</td><td>0.80</td><td>0.76</td><td>0.54</td><td>0.72</td></tr><tr><td><br />MIDF</td><td><b>0.89</b></td><td>0.81</td><td>0.84</td><td>0.58</td><td>0.79</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best results are in bold.</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表3 文本分类数据集上不同算法的平均预测准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Average Prediction Accuracy of Different Methods for Text Categorization Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td>Datasets</td><td>MILES</td><td>miGraph</td><td>MI-Net with RC</td><td>MI-Net with Ds</td><td>ID3-MI</td><td>MIRF</td><td>MIDF</td></tr><tr><td><br />alt.atheism</td><td>0.65</td><td>0.74</td><td>0.77</td><td>0.68</td><td>0.67</td><td>0.75</td><td><b>0.79</b></td></tr><tr><td><br />comp.graphics</td><td>0.64</td><td>0.80</td><td>0.79</td><td>0.74</td><td>0.73</td><td><b>0.81</b></td><td>0.81</td></tr><tr><td><br />comp.os.ms-windows.misc</td><td>0.57</td><td>0.57</td><td><b>0.64</b></td><td>0.58</td><td>0.56</td><td>0.60</td><td>0.61</td></tr><tr><td><br />comp.sys.ibm.pc.hardware</td><td>0.63</td><td>0.57</td><td>0.58</td><td>0.55</td><td>0.66</td><td><b>0.74</b></td><td>0.73</td></tr><tr><td><br />comp.sys.mac.hardware</td><td>0.59</td><td>0.73</td><td>0.74</td><td>0.68</td><td>0.67</td><td>0.75</td><td><b>0.79</b></td></tr><tr><td><br />comp.windows.x</td><td>0.74</td><td>0.77</td><td>0.70</td><td>0.56</td><td>0.73</td><td><b>0.78</b></td><td>0.77</td></tr><tr><td><br />misc.forsale</td><td>0.54</td><td><b>0.65</b></td><td>0.58</td><td>0.57</td><td>0.53</td><td>0.60</td><td>0.64</td></tr><tr><td><br />rec.autos</td><td>0.61</td><td>0.71</td><td>0.62</td><td>0.66</td><td>0.67</td><td>0.70</td><td><b>0.72</b></td></tr><tr><td><br />rec.motorcycles</td><td>0.65</td><td>0.78</td><td><b>0.84</b></td><td>0.80</td><td>0.76</td><td>0.79</td><td>0.81</td></tr><tr><td><br />rec.sport.baseball</td><td>0.71</td><td>0.74</td><td>0.79</td><td>0.70</td><td>0.69</td><td>0.78</td><td><b>0.82</b></td></tr><tr><td><br />rec.sport.hockey</td><td>0.78</td><td>0.79</td><td>0.74</td><td>0.60</td><td>0.71</td><td>0.77</td><td><b>0.80</b></td></tr><tr><td><br />sci.crypt</td><td>0.74</td><td>0.66</td><td>0.70</td><td>0.66</td><td>0.67</td><td>0.74</td><td><b>0.76</b></td></tr><tr><td><br />sci.electronics.mat</td><td>0.70</td><td>0.86</td><td>0.84</td><td>0.78</td><td>0.84</td><td>0.90</td><td><b>0.91</b></td></tr><tr><td><br />sci.med</td><td>070</td><td><b>0.81</b></td><td>0.77</td><td>0.69</td><td>0.64</td><td>0.71</td><td>0.71</td></tr><tr><td><br />sci.space</td><td>0.61</td><td>0.67</td><td>0.73</td><td>0.67</td><td>0.63</td><td>0.69</td><td><b>0.74</b></td></tr><tr><td><br />soc.religion.christian</td><td>0.61</td><td>0.71</td><td>0.71</td><td>0.65</td><td>0.61</td><td>0.74</td><td><b>0.74</b></td></tr><tr><td><br />talk.politics.guns</td><td>0.70</td><td>0.62</td><td><b>0.72</b></td><td>0.63</td><td>0.65</td><td>0.69</td><td>0.71</td></tr><tr><td><br />talk.politics.mideast</td><td>0.71</td><td>0.62</td><td>0.64</td><td>0.64</td><td>0.73</td><td>0.79</td><td><b>0.80</b></td></tr><tr><td><br />talk.politics.misc</td><td>0.56</td><td>0.61</td><td>0.62</td><td><b>0.64</b></td><td>0.58</td><td>0.60</td><td><b>0.64</b></td></tr><tr><td><br />talk.religion.misc</td><td>0.60</td><td>0.64</td><td>0.63</td><td>0.62</td><td>0.59</td><td>0.67</td><td><b>0.68</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best results are in bold.</p>
                </div>
                <div class="p1">
                    <p id="126">MIDF在这些数据集上均展现了较好的效果, 尤其是在处理文本分类任务时, 我们在20个数据集中的12个数据集上取得了最优效果, 并在其他8个数据集上同最优结果相当.同时在图像数据上我们同示例级的神经网络算法效果也相差不大.此外尽管其他算法在某些数据集上也展现了不错的效果, 但他们往往需要针对不同数据集使用不同的超参数, 这类超参数的选择十分困难且耗时.而我们的算法只需要使用相同的超参就可以得到很好的结果.</p>
                </div>
                <h3 id="127" name="127" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="128">本文提出了一个新的深度森林框架MIDF来解决多示例学习问题.在这种新的框架下, 拼接时会把包中的每个示例都看做是一个包, 从而使得中间层的输出分布可以和包中的示例拼接成功, 进而使得级联结构依然有效.另外, 我们的架构由2个级联结构组成, 其中一个使用<i>k</i>折交叉验证来帮助自动确定深度森林的层数, 另一个根据所求的层数来计算最终的结果.实验结果表明:我们的方法在图像任务上的性能并不比擅长处理图像任务的MI-Nets差, 而在在文本数据上, 本文方法取得了比MI-Nets更好的效果.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="150">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702007540&amp;v=MjQzNTlIWk9zSUNYZzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklJMXNUYmhNPU5pZk9mYks3SHRETnFJOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Dietterich T G, Lathrop R H, Lozano-Pérez T.Solving the multiple instance problem with axis-parallel rectangles[J].Artificial Intelligence, 1997, 89 (1/2) :31- 71
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13080200174321&amp;v=MzI1Mjc0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHJJSTFzVGJoTT1OaWZPZmJLN0h0bk1yWTlGWmV3TEQzNA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Amores J.Multiple instance classification:Review, taxonomy and comparative study[J].Artificial Intelligence, 2013, 201:81- 105
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Support Vector Machines for Multiple-Instance Learning">

                                <b>[3]</b>Andrews S, Tsochantaridis I, Hofmann T.Support vector machines for multiple-instance learning[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2003:577- 584
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-instance learning by treating instances as non-I.I.D.samples">

                                <b>[4]</b>Zhou Zhihua, Sun Yuyin, Li Yufeng.Multi-instance learning by treating instances as non-iid samples[C] //Proc of the 26th Annual Int Conf on Machine Learning.New York:ACM, 2009:1249- 1256
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MILES: Multiple-Instance Learning via Embedded Instance Selection">

                                <b>[5]</b>Chen Yinxin, Bi Jinbo, Wang J Z.MILES:Multiple-instance learning via embedded instance selection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :1931- 1947
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[6]</b>Krizhevsky A, Sutskever I, Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of the Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2012:1097- 1105
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks">

                                <b>[7]</b>Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of the 2015 Conf on Empirical Methods in Natural Language Processing.Stroudsburg, PA:ACL, 2015:1753- 1762
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Learning">

                                <b>[8]</b>Goodfellow I, Bengio Y, Courville A.Deep Learning[M].Cambridge, MA:MIT Press, 2016
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9B047D00494268C33E75A09156148386&amp;v=MjU1MjFSY3plTGFjUnJLWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU4xaHg3MjR4S2s9TmlmT2ZicktIdFhMMjQ5RllPSUxEbm94dkJVUW56aDRPWC9ycg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Wang Xinggang, Yan Yongluan, Tang Peng, et al.Revisiting multiple instance neural networks[J].Pattern Recognition, 2018, 74 (C) :15- 24
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Forest:Towards an alternative to Deep Neural Networks">

                                <b>[10]</b>Zhou Zhihua, Feng Ji.Deep forest:Towards an alternative to deep neural networks[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.San Francisco, CA:Morgan Kaufmann, 2017:3553- 3559
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Solving multiple-instance and multiple-part learning problems with decision trees and decision rules">

                                <b>[11]</b>Chevaleyre Y, Zucker J D.Solving multiple-instance and multiple-part learning problems with decision trees and rule sets.Application to the mutagenesis problem[C] //Proc of the Conf of the Canadian Society for Computational Studies of Intelligence.Berlin:Springer, 2001:204- 214
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple instance learning with bag-level randomized trees">

                                <b>[12]</b>Komárek T, Somol P.Multiple instance learning with bag-level randomized trees[C] //Proc of the Joint European Conf on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer, 2018:259- 272
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014189&amp;v=MzAwNThmSlpiSzlIdGpNcW85RlpPb0xEWFF3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHJJSTFzVGJoTT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Amit Y, Geman D.Shape quantization and recognition with randomized trees[J].Neural Computation, 1997, 9 (7) :1545- 1588
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDY5OTczazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkMzbFVMclBKRjg9Tmo3QmFyTzRIdEhOckl0Rlp1d09Z&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5- 32
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001341091&amp;v=MDI2ODhOajdCYXJPNEh0SE5ySXRFWk9JT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkMzbFVMclBKRjg9&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Geurts P, Ernst D, Wehenkel L.Extremely randomized trees[J].Machine Learning, 2006, 63 (1) :3- 42
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201908010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201908010&amp;v=MjAzNTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXZnVkx2Skx5dlNkTEc0SDlqTXA0OUVaSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVIR29TaXBTZWtoNExMVEtXMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

