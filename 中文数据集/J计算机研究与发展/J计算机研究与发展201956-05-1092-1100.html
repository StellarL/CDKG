

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128656037931250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201905019%26RESULT%3d1%26SIGN%3d1IQHJSzRVffhMPCbTbtPEjk3CKc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905019&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905019&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905019&amp;v=MTU4MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHl2U2RMRzRIOWpNcW85RWJZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="&lt;b&gt;2 动量随机梯度下降算法&lt;/b&gt; "><b>2 动量随机梯度下降算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;3 静态重启随机梯度下降算法&lt;/b&gt; "><b>3 静态重启随机梯度下降算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="&lt;b&gt;4 基于堆叠注意力网络的图片问答模型&lt;/b&gt; "><b>4 基于堆叠注意力网络的图片问答模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#117" data-title="&lt;b&gt;4.1 图片模型&lt;/b&gt;"><b>4.1 图片模型</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;4.2 问题模型&lt;/b&gt;"><b>4.2 问题模型</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;4.3 堆叠注意力模型&lt;/b&gt;"><b>4.3 堆叠注意力模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;5 实验结果与分析&lt;/b&gt; "><b>5 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#134" data-title="&lt;b&gt;5.1 数据集&lt;/b&gt;"><b>5.1 数据集</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;5.2 图片问答评估算法&lt;/b&gt;"><b>5.2 图片问答评估算法</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;5.3 模型配置&lt;/b&gt;"><b>5.3 模型配置</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;5.4 实验结果&lt;/b&gt;"><b>5.4 实验结果</b></a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;5.5 实验分析&lt;/b&gt;"><b>5.5 实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="&lt;b&gt;6 结 论&lt;/b&gt; "><b>6 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="图1 模型定位到错误区域而导致错误">图1 模型定位到错误区域而导致错误</a></li>
                                                <li><a href="#147" data-title="图2 基准算法的实验结果">图2 基准算法的实验结果</a></li>
                                                <li><a href="#148" data-title="图3 静态重启随机梯度下降算法的实验结果">图3 静态重启随机梯度下降算法的实验结果</a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;表1 全局最优实验结果&lt;/b&gt;"><b>表1 全局最优实验结果</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;表2 T检验结果&lt;/b&gt;"><b>表2 T检验结果</b></a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表3 优化算法的全局最优实验结果&lt;/b&gt;"><b>表3 优化算法的全局最优实验结果</b></a></li>
                                                <li><a href="#162" data-title="图4 泛化性能和推广价值的实验结果">图4 泛化性能和推广价值的实验结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="221">


                                    <a id="bibliography_1" title="Yang Zichao, He Xiaodong, Gao Jianfeng, et al.Stacked attention networks for image question answering[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:21- 29" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked attention networks for image question answering">
                                        <b>[1]</b>
                                        Yang Zichao, He Xiaodong, Gao Jianfeng, et al.Stacked attention networks for image question answering[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:21- 29
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_2" title="Yang Yuan.Why is stochastic steepest descent (SGD) a good method?[OL]. (2017-08-27) [2018-01-22].https://zhuanlan.zhihu.com/p/27609238" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Why is stochastic steepest descent (SGD) a good method?[OL]">
                                        <b>[2]</b>
                                        Yang Yuan.Why is stochastic steepest descent (SGD) a good method?[OL]. (2017-08-27) [2018-01-22].https://zhuanlan.zhihu.com/p/27609238
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_3" title="Wu Qi, Wang Peng, Shen Chunhua, et al.Ask me anything:Free-form visual question answering based on knowledge from external sources[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4622- 4630" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ask Me Anything:Free-form Visual Question Answering Based on Knowledge from External Sources">
                                        <b>[3]</b>
                                        Wu Qi, Wang Peng, Shen Chunhua, et al.Ask me anything:Free-form visual question answering based on knowledge from external sources[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4622- 4630
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_4" title="Yu Dongfei, Fu Jianlong, Mei Tao, et al.Multi-level attention networks for visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:4187- 4195" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-level Attention Networks for Visual Question Answering">
                                        <b>[4]</b>
                                        Yu Dongfei, Fu Jianlong, Mei Tao, et al.Multi-level attention networks for visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:4187- 4195
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_5" title="Gu G, Kim S T, Yong M R.Adaptive attention fusion network for visual question answering[C] //Proc of the 2017 IEEE Int Conf on Multimedia and Expo.Piscataway, NJ:IEEE, 2017:997- 1002" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive attention fusion network for visual question answering">
                                        <b>[5]</b>
                                        Gu G, Kim S T, Yong M R.Adaptive attention fusion network for visual question answering[C] //Proc of the 2017 IEEE Int Conf on Multimedia and Expo.Piscataway, NJ:IEEE, 2017:997- 1002
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_6" title="Lu Jiasen, Yang Jianwei, Batra D, et al.Hierarchical question-image co-attention for visual question answering[C/OL] //Proc of the 2016 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2016 (2016-05-31) [2018-03-01].https://arxiv.org/abs/1606.00061v5" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Hierarchical question-image coattention for visual question answering,&amp;quot;">
                                        <b>[6]</b>
                                        Lu Jiasen, Yang Jianwei, Batra D, et al.Hierarchical question-image co-attention for visual question answering[C/OL] //Proc of the 2016 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2016 (2016-05-31) [2018-03-01].https://arxiv.org/abs/1606.00061v5
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_7" title="Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bottom-up and top-down attention for image captioning and visual question answering">
                                        <b>[7]</b>
                                        Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_8" title="Loshchilov I, Hutter F.SGDR:Stochastic gradient descent with warm restarts[C/OL] //Proc of the 5th Int Conf on Learning Representations.2017 [2018-03-06].https://arxiv.org/abs/1608.03983" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SGDR:Stochastic gradient descent with warm restarts[C/OL]">
                                        <b>[8]</b>
                                        Loshchilov I, Hutter F.SGDR:Stochastic gradient descent with warm restarts[C/OL] //Proc of the 5th Int Conf on Learning Representations.2017 [2018-03-06].https://arxiv.org/abs/1608.03983
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_9" title="Bianchi P, Jakubowicz J.Convergence of a multi-agent projected stochastic gradient algorithm for non-convex optimization[J].IEEE Transactions on Automatic Control, 2013, 58 (2) :391- 405" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convergence of a Multi-Agent Projected Stochastic Gradient Algorithm for Non-Convex Optimization">
                                        <b>[9]</b>
                                        Bianchi P, Jakubowicz J.Convergence of a multi-agent projected stochastic gradient algorithm for non-convex optimization[J].IEEE Transactions on Automatic Control, 2013, 58 (2) :391- 405
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_10" title="Jiang Jiyuan, Xia Liang, Zhang Xian, et al.A sparse stochastic algorithm with O (1/T) convergence rate[J].Journal of Computer Research and Development, 2014, 51 (9) :1901- 1910 (in Chinese) (姜纪远, 夏良, 章显, 等.一种具有O (1/T) 收敛速率的稀疏随机算法[J].计算机研究与发展, 2014, 51 (9) :1901- 1910) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201409003&amp;v=MzExNjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGeW5sVWJ6S0x5dlNkTEc0SDlYTXBvOUZaNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Jiang Jiyuan, Xia Liang, Zhang Xian, et al.A sparse stochastic algorithm with O (1/T) convergence rate[J].Journal of Computer Research and Development, 2014, 51 (9) :1901- 1910 (in Chinese) (姜纪远, 夏良, 章显, 等.一种具有O (1/T) 收敛速率的稀疏随机算法[J].计算机研究与发展, 2014, 51 (9) :1901- 1910) 
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_11" title="Yang Shuangtao, Ma Zhiqiang, Dou Baoyuan, et al.Asynchronous double stochastic gradient descent algorithm in yarn framework[J].Journal of Chinese Computer Systems, 2017, 38 (5) :1070- 1075 (in Chinese) (杨双涛, 马志强, 窦保媛, 等.一种Yarn框架下的异步双随机梯度下降算法[J].小型微型计算机系统, 2017, 38 (5) :1070- 1075) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201705031&amp;v=MDc4OTdCdEdGckNVUkxPZVplUnFGeW5sVWJ6S1BUWGNkckc0SDliTXFvOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Yang Shuangtao, Ma Zhiqiang, Dou Baoyuan, et al.Asynchronous double stochastic gradient descent algorithm in yarn framework[J].Journal of Chinese Computer Systems, 2017, 38 (5) :1070- 1075 (in Chinese) (杨双涛, 马志强, 窦保媛, 等.一种Yarn框架下的异步双随机梯度下降算法[J].小型微型计算机系统, 2017, 38 (5) :1070- 1075) 
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_12" title="Chen Zhenhong, Lan Yanyan, Guo Jiafeng, et al.Distributed stochastic gradient descent with discriminative aggregating[J].Chinese Journal of Computers, 2015, 38 (10) :2054- 2063 (in Chinese) (陈振宏, 兰艳艳, 郭嘉丰, 等.基于差异合并的分布式随机梯度下降算法[J].计算机学报, 2015, 38 (10) :2054- 2063) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201510010&amp;v=MzA1NTQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHo3QmRyRzRIOVROcjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Chen Zhenhong, Lan Yanyan, Guo Jiafeng, et al.Distributed stochastic gradient descent with discriminative aggregating[J].Chinese Journal of Computers, 2015, 38 (10) :2054- 2063 (in Chinese) (陈振宏, 兰艳艳, 郭嘉丰, 等.基于差异合并的分布式随机梯度下降算法[J].计算机学报, 2015, 38 (10) :2054- 2063) 
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_13" title="Li Ping, Dai Yueming, Wang Yan.Text sentiment analysis based on hybrid chi-square statistic and logistic regression[J].Computer Engineering, 2017, 43 (12) :192- 196 (in Chinese) (李平, 戴月明, 王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程, 2017, 43 (12) :192- 196) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712035&amp;v=MjM3MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHo3QmJiRzRIOWJOclk5R1lZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Li Ping, Dai Yueming, Wang Yan.Text sentiment analysis based on hybrid chi-square statistic and logistic regression[J].Computer Engineering, 2017, 43 (12) :192- 196 (in Chinese) (李平, 戴月明, 王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程, 2017, 43 (12) :192- 196) 
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_14" title="Wang Gongpeng, Duan Meng, Niu Changyong.Stochastic gradient descent algorithm based on convolution neural network[J].Computer Engineering and Design, 2018, 39 (2) :441- 445 (in Chinese) (王功鹏, 段萌, 牛常勇.基于卷积神经网络的随机梯度下降算法[J].计算机工程与设计, 2018, 39 (2) :441- 445) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201802026&amp;v=MTk2OTQ5SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTmlmWVpMRzRIOW5Nclk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Wang Gongpeng, Duan Meng, Niu Changyong.Stochastic gradient descent algorithm based on convolution neural network[J].Computer Engineering and Design, 2018, 39 (2) :441- 445 (in Chinese) (王功鹏, 段萌, 牛常勇.基于卷积神经网络的随机梯度下降算法[J].计算机工程与设计, 2018, 39 (2) :441- 445) 
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_15" title="Wang Chen.Seven common random gradient descent algorithms[OL].2017 [2018-02-01].http://wangpan.loan/post/54.html" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Seven common random gradient descent algorithms[OL]">
                                        <b>[15]</b>
                                        Wang Chen.Seven common random gradient descent algorithms[OL].2017 [2018-02-01].http://wangpan.loan/post/54.html
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_16" title="Kafle K, Kanan C.Visual question answering:Datasets, algorithms, and future challenges[J].Computer Vision and Image Understanding, 2017, 163:3- 20" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3E2747A8B911A469B998E7C73FD7AEE8&amp;v=MDU0OTBwbWFCdUhZZk9HUWxmQ3BiUTM1TnhoeGJpOXc2bz1OaWZPZmJETkhOYklxUDVORnVJT0RRMDl5UjloNHpaMVBYaVJxeEZERGJYbE1NK1hDT052RlNpV1dyN0pJRg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Kafle K, Kanan C.Visual question answering:Datasets, algorithms, and future challenges[J].Computer Vision and Image Understanding, 2017, 163:3- 20
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_17" title="Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bottom-up and top-down attention for image captioning and visual question answering">
                                        <b>[17]</b>
                                        Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_18" title="Lin Xiao, Parikh D.Active learning for visual question answering:An empirical study[C/OL] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017 (2017-11-06) [2018-03-20].https://arxiv.org/abs/1711.01732" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Active learning for visual question answering:An empirical study[C/OL]">
                                        <b>[18]</b>
                                        Lin Xiao, Parikh D.Active learning for visual question answering:An empirical study[C/OL] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017 (2017-11-06) [2018-03-20].https://arxiv.org/abs/1711.01732
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_19" title="Wu Qi, Teney D, Wang Peng, et al.Visual question answering:A survey of methods and datasets[J].Computer Vision and Image Understanding, 2017, 163:21- 41" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3C84822FD024CB340672A116F38C75E2&amp;v=MTY5MzhYRXJZMHpFT3NOQ0E5THpCSVQ3RGgvT1g3anFtUTJjY0dUUU0rZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54aHhiaTl3Nm89TmlmT2ZiRExGdA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Wu Qi, Teney D, Wang Peng, et al.Visual question answering:A survey of methods and datasets[J].Computer Vision and Image Understanding, 2017, 163:21- 41
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_20" title="Agrawal A, Lu Jiasen, Antol S, et al.VQA:Visual question answering[J].International Journal of Computer Vision, 2015, 123 (1) :4- 31" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD06E7D905CC65C690282027F9DA2BE66F&amp;v=MjkzNTNyTythOWE0cG85QUY1Z0pDUTgveGhZUjRqMTlTbmlVcFdaRWU4RGhRN3pwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnhoeGJpOXc2bz1OajdCYQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Agrawal A, Lu Jiasen, Antol S, et al.VQA:Visual question answering[J].International Journal of Computer Vision, 2015, 123 (1) :4- 31
                                    </a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_21" >
                                        <b>[21]</b>
                                    Ren M, Kiros R, Zemel R S.Exploring models and data for image question answering[C] //Proc of the 2015 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:2953- 2961</a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_22" title="Noh H, Seo P H, Han B.Image question answering using convolutional neural network with dynamic parameter prediction[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:30- 38" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image question answering using convolutional neural network with dynamic parameter prediction">
                                        <b>[22]</b>
                                        Noh H, Seo P H, Han B.Image question answering using convolutional neural network with dynamic parameter prediction[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:30- 38
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_23" title="Teney D, Hengel A V D.Zero-shot visual question answering[C/OL] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016 (2016-11-20) [2018-03-16].http://arxiv.org/pdf/1611.05546" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Zero-shot visual question answering[C/OL]">
                                        <b>[23]</b>
                                        Teney D, Hengel A V D.Zero-shot visual question answering[C/OL] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016 (2016-11-20) [2018-03-16].http://arxiv.org/pdf/1611.05546
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_24" title="Lin Yuetan, Pang Zhangyang, Li Yanan, et al.Simple and effective visual question answering in a single modality[C] //Proc of the 23rd IEEE Int Conf on Image Processing.Recognition.Piscataway, NJ:IEEE, 2016:2276- 2280" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simple and effective visual question answering in a single modality">
                                        <b>[24]</b>
                                        Lin Yuetan, Pang Zhangyang, Li Yanan, et al.Simple and effective visual question answering in a single modality[C] //Proc of the 23rd IEEE Int Conf on Image Processing.Recognition.Piscataway, NJ:IEEE, 2016:2276- 2280
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_25" title="Malinowski M, Fritz M.A multi-world approach to question answering about real-world scenes based on uncertain input[C] //Proc of the 2014 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2014:1682- 1690" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input">
                                        <b>[25]</b>
                                        Malinowski M, Fritz M.A multi-world approach to question answering about real-world scenes based on uncertain input[C] //Proc of the 2014 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2014:1682- 1690
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_26" title="Ren M, Kiros R, Zemel R S.Exploring models and data for image question answering[C] //Proc of the 2015 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:2953- 2961" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploring models and data for image question answering">
                                        <b>[26]</b>
                                        Ren M, Kiros R, Zemel R S.Exploring models and data for image question answering[C] //Proc of the 2015 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:2953- 2961
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_27" title="Zhu Yuke, Groth O, Bernstein M, et al.Visual7W:Grounded question answering in images[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4995- 5004" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual7W:Grounded question answering in images">
                                        <b>[27]</b>
                                        Zhu Yuke, Groth O, Bernstein M, et al.Visual7W:Grounded question answering in images[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4995- 5004
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_28" title="Teney D, Wu Qi, Hengel A V D.Visual question answering:A tutorial[J].IEEE Signal Processing Magazine, 2017, 34 (6) :63- 76" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual question answering:A tutorial">
                                        <b>[28]</b>
                                        Teney D, Wu Qi, Hengel A V D.Visual question answering:A tutorial[J].IEEE Signal Processing Magazine, 2017, 34 (6) :63- 76
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_29" title="Yu Jun, Wang Liang, Yu Zhou.Research on visual question answering techniques[J].Journal of Computer Research and Development, 2018, 55 (9) :1946- 1958 (in Chinese) (俞俊, 汪亮, 余宙.视觉问答技术研究[J].计算机研究与发展, 2018, 55 (9) :1946- 1958) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201809010&amp;v=MDg0MjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnlubFViektMeXZTZExHNEg5bk1wbzlFWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                        Yu Jun, Wang Liang, Yu Zhou.Research on visual question answering techniques[J].Journal of Computer Research and Development, 2018, 55 (9) :1946- 1958 (in Chinese) (俞俊, 汪亮, 余宙.视觉问答技术研究[J].计算机研究与发展, 2018, 55 (9) :1946- 1958) 
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_30" title="Agrawal A.VQA evaluation method[OL]. (2017-10-03) [2018-01-08].http://www.visualqa.org/evaluation.html" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VQA evaluation method[OL]">
                                        <b>[30]</b>
                                        Agrawal A.VQA evaluation method[OL]. (2017-10-03) [2018-01-08].http://www.visualqa.org/evaluation.html
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_31" title="Tiaaaaa.T test[OL]. (2017-02-27) [2018-04-15].https://blog.csdn.net/tiaaaaa/article/details/58130363" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=T test[OL]">
                                        <b>[31]</b>
                                        Tiaaaaa.T test[OL]. (2017-02-27) [2018-04-15].https://blog.csdn.net/tiaaaaa/article/details/58130363
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_32" title="Multiangle.Summary of optimization methods[OL]. (2016-11-01) [2018-06-12].https://blog.csdn.net/u014595019/article/details/52989301" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Summary of optimization methods[OL]">
                                        <b>[32]</b>
                                        Multiangle.Summary of optimization methods[OL]. (2016-11-01) [2018-06-12].https://blog.csdn.net/u014595019/article/details/52989301
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_33" title="Yazan E, Talu M F.Comparison of the stochastic gradient descent based optimization techniques[C] //Proc of the Int Artificial Intelligence and Data Processing Symp.Piscataway, NJ:IEEE, 2017:1- 6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparison of the stochastic gradient descent based optimization techniques">
                                        <b>[33]</b>
                                        Yazan E, Talu M F.Comparison of the stochastic gradient descent based optimization techniques[C] //Proc of the Int Artificial Intelligence and Data Processing Symp.Piscataway, NJ:IEEE, 2017:1- 6
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_34" title="Zeiler M D.ADADELTA:An adaptive learning rate method[OL]. (2012-12-22) [2018-03-12].https://arxiv.org/pdf/1212.5701v1.pdf" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ADADELTA:An adaptive learning rate method">
                                        <b>[34]</b>
                                        Zeiler M D.ADADELTA:An adaptive learning rate method[OL]. (2012-12-22) [2018-03-12].https://arxiv.org/pdf/1212.5701v1.pdf
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_35" title="Krizhevsky A.The CIFAR-10 dataset[OL]. (2009-03-31) [2018-04-20].http://www.cs.toronto.edu/～kriz/cifar.html" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The CIFAR-10 dataset">
                                        <b>[35]</b>
                                        Krizhevsky A.The CIFAR-10 dataset[OL]. (2009-03-31) [2018-04-20].http://www.cs.toronto.edu/～kriz/cifar.html
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_36" title="He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[36]</b>
                                        He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(05),1092-1100 DOI:10.7544/issn1000-1239.2019.20180472            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于图片问答的静态重启随机梯度下降算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E8%83%9C%E4%B8%9C&amp;code=41873591&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李胜东</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%95%E5%AD%A6%E5%BC%BA&amp;code=10724564&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕学强</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0198015&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民大学信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%BB%8A%E5%9D%8A%E7%87%95%E4%BA%AC%E8%81%8C%E4%B8%9A%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B%E7%B3%BB&amp;code=1694644&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">廊坊燕京职业技术学院计算机工程系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%BD%91%E7%BB%9C%E6%96%87%E5%8C%96%E4%B8%8E%E6%95%B0%E5%AD%97%E4%BC%A0%E6%92%AD%E5%8C%97%E4%BA%AC%E5%B8%82%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8C%97%E4%BA%AC%E4%BF%A1%E6%81%AF%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6)&amp;code=0251832&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">网络文化与数字传播北京市重点实验室(北京信息科技大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>图片问答是计算机视觉与自然语言处理交叉的多模态学习任务.为了解决该任务, 研究人员提出堆叠注意力网络 (stacked attention networks, SANs) .研究发现该模型易陷入不好的局部最优解, 引发较高的问答错误率.为了解决该问题, 提出基于图片问答的静态重启随机梯度下降算法.实验结果和分析表明:它的准确率比基准算法提高0.29%, 但其收敛速度慢于基准算法.为了验证改善性能的显著性, 对实验结果进行统计假设检验.T检验结果证明它的改善性能是极其显著的.为了验证它在同类算法中的有效性, 将该算法和当前最好的一阶优化算法进行有效性实验, 实验结果和分析证明它更有效.为了验证它的泛化性能和推广价值, 在经典的Cifar-10数据集上进行图像识别实验.实验结果和T检验结果证明:它具有良好的泛化性能和较好的推广价值.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E7%89%87%E9%97%AE%E7%AD%94&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图片问答;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A0%86%E5%8F%A0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">堆叠的注意力网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%99%E6%80%81%E9%87%8D%E5%90%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">静态重启;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机梯度下降;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *吕学强, lxq@bistu.edu.cn;
                                </span>
                                <span>
                                    李胜东, lsd@ruc.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-06-27</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61671070);</span>
                                <span>国家语委十三五科研规划2017年度重点项目 (ZDI135-53);</span>
                                <span>网络文化与数字传播北京市重点实验室开放课题 (ICDD201505) This work was;</span>
                    </p>
            </div>
                    <h1><b>Static Restart Stochastic Gradient Descent Algorithm Based on Image Question Answering</b></h1>
                    <h2>
                    <span>Li Shengdong</span>
                    <span>Lü Xueqiang</span>
            </h2>
                    <h2>
                    <span>School of Information, Renmin University of China</span>
                    <span>Department of Computer Engineering, Langfang Yanjing Vocational Technical College</span>
                    <span>Beijing Key Laboratory of Internet Culture and Digital Dissemination Research (Beijing Information Science and Technology University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Image question answering is a multimodal learning task intersecting computer vision and natural language processing. With the breakthroughs in the deep neural networks, it has been the hotspot and focus of many researchers' attention. To solve the task, researchers put forward numerous excellent models. Stacked attention networks (SANs) is one of the most typical models, and gets the state-of-the-art results in the test of four public visual question answering datasets. Although it has the excellent performance, because of the diversity of question and the sparsity of answer, it cannot fully learn the universal law of the corpus, and easily fall into the poor local optimal solution, which leads to the higher question answering error rate. By analyzing the causes of the error and observing the details of the model processing image question answering, we find that stochastic gradient descent based on momentum (baseline) has some defects in the optimization of SANs. To solve it, we propose static restart stochastic gradient descent based on image question answering. The experimental results show that its accuracy is 0.29% higher than baseline, but its convergence rate is slower than baseline. To verify the significance of the improved performance, we conduct statistical hypothesis test on the experimental results. The results of T test prove that its improved performance is extremely significant in the process of converging to the global optimal solution. To verify its effectiveness in the same kind of algorithm, we conduct effectiveness experiments with it and the state-of-the-art first-order optimization algorithms. The experimental results and analysis prove that it is more effective in solving image question answering. To verify its generalization performance and promotion value, we conduct the image recognition experiment on the classic Cifar-10 for the image recognition task. The experimental results and the results of T test prove that it has good generalization performance and promotion value in the process of converging to the global optimal solution.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20question%20answering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image question answering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=stacked%20attention%20networks%20(SANs)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">stacked attention networks (SANs) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=momentum&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">momentum;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=static%20restart&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">static restart;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=stochastic%20gradient%20descent%20(SGD)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">stochastic gradient descent (SGD) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Li Shengdong, born in 1984.PhD candidate, lecturer. His main research interests include visual question answering, statistical machine learning and deep learning.<image id="218" type="formula" href="images/JFYZ201905019_21800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Lü Xueqiang, born in 1970.PhD, professor. Member of CCF. His main research interests include multimedia information processing.<image id="220" type="formula" href="images/JFYZ201905019_22000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-06-27</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61671070);</span>
                                <span>the 2017 Key Project of State Language Commission 13th Five-Year Scientific Research Plan (ZDI135-53);</span>
                                <span>the Opening Project of Beijing Key Laboratory of Internet Culture and Digital Dissemination Research (ICDD201505);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="77">图片问答是让机器根据图片回答自然语言问题.通用的模型采用卷积神经网络 (convoltional neural networks, CNN) 抽取全局图片特征, 采用长短期记忆网络 (long short-term memory, LSTM) 抽取问题特征, 然后将这2种特征融合后以推断问题答案.对于简单问题, 这种模型能够得到较好的结果.但当问题比较复杂时, 为了过滤掉噪声信息, 需要对问题进行多步推理才能准确定位答案相关的局部图片区域.此时, 该模型往往不能得到准确答案.为了解决该问题, 文献<citation id="293" type="reference">[<a class="sup">1</a>]</citation>提出堆叠注意力网络 (stacked attention networks, SANs) .该模型在4个公开的视觉问答数据集上进行综合评估, 其性能都显著超过当时最好的结果.</p>
                </div>
                <div class="p1">
                    <p id="78">虽然SANs模型在解决图片问答问题时取得良好的效果, 但问题的复杂多样性和答案的稀疏性导致该模型不能完全学习到语料的普遍规律.这容易使该模型因陷入不好的局部最优解而引发模型定位到错误区域, 从而导致问答错误.统计表明, 该类错误占测试错误总数的22%<citation id="294" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 如图1所示:</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905019_079.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型定位到错误区域而导致错误" src="Detail/GetImg?filename=images/JFYZ201905019_079.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型定位到错误区域而导致错误  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905019_079.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Model locates the wrong area and causes errors</p>

                </div>
                <div class="p1">
                    <p id="80">图1中的问题是What swim in the ocean near two large ferries?.该问题是What类型, 答案应该为object.图1 (a) 中的object有clouds, sky, boats, ducks, ocean.根据图1 (b) , 第1步推理定位的答案为object (boats, ducks) 和概念 (swim in the ocean, near two large ferries) .根据图1 (c) , 模型在第1步推理的基础上进行第2步推理, 初步定位到boats和ducks.由于它们的形状相似, 而boats更大且更容易识别, 模型最终定位到boats.这导致模型预测错误答案 (boats) , 而不是正确答案 (ducks) .</p>
                </div>
                <div class="p1">
                    <p id="81">为了解决该问题, 对随机梯度下降算法进行调研和分析, 提出基于图片问答的静态重启随机梯度下降算法.本文的主要贡献有4个方面:</p>
                </div>
                <div class="p1">
                    <p id="82">1) 重启的思想与随机梯度下降算法融合, 提出基于静态重启的随机梯度下降算法.该算法优化SANs模型, 提出基于图片问答的静态重启随机梯度下降算法.实验结果和分析表明它的准确率比基于图片问答的动量随机梯度下降算法提高0.29%, 但其收敛速度慢于基于图片问答的动量随机梯度下降算法.</p>
                </div>
                <div class="p1">
                    <p id="83">2) 为了验证改善的显著性, 对实验结果进行统计假设检验.T检验结果证明在收敛到全局最优解的过程中它的改善性能在统计意义上是极其显著的.</p>
                </div>
                <div class="p1">
                    <p id="84">3) 为了验证它在同类算法中的有效性, 本文将它和当前最好的一阶优化算法RmsProp, Adam, AdaDelta进行有效性实验.实验结果和分析证明它在解决图片问答问题时更有效.</p>
                </div>
                <div class="p1">
                    <p id="85">4) 算法的泛化性能与数据集的选取有关.算法的推广价值与任务的选择有关.为了验证它的泛化性能和推广价值, 针对图像识别任务, 在经典的Cifar-10数据集上进行图像识别实验.实验结果和T检验结果证明它在收敛到全局最优解的过程中具有良好的泛化性能和较好的推广价值.</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="87">若求解机器学习算法中的模型参数, 并对算法中的目标函数进行优化以找到它的最小值, 梯度下降是最常用的方法之一.该算法沿着导数的方向逐步收敛到函数的最优解.</p>
                </div>
                <div class="p1">
                    <p id="88">设<i>z</i>表示当前时刻, <i>x</i><sub><i>z</i></sub>表示当前目标函数值, <i>η</i><sub><i>z</i></sub>表示当前学习率, <image href="images/JFYZ201905019_089.jpg" type="" display="inline" placement="inline"><alt></alt></image><i>F</i> (<i>x</i><sub><i>z</i></sub>) 表示当前导数.该算法的数学表达形式<citation id="295" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>为</p>
                </div>
                <div class="p1">
                    <p id="90"><i>x</i><sub><i>z</i>+1</sub>=<i>x</i><sub><i>z</i></sub>-<i>η</i><sub><i>z</i></sub>×<image href="images/JFYZ201905019_091.jpg" type="" display="inline" placement="inline"><alt></alt></image><i>F</i> (<i>x</i><sub><i>z</i></sub>) . (1) </p>
                </div>
                <div class="p1">
                    <p id="92">梯度下降算法简单、可操作性强, 在深度学习和机器学习领域得到广泛的应用.但该算法收敛速度极慢且容易陷入局部最优解.为了解决这2个缺点, 研究人员提出随机梯度下降算法.</p>
                </div>
                <div class="p1">
                    <p id="93">设<i>g</i><sub><i>z</i></sub>表示随机梯度, 满足<i>E</i> (<i>g</i><sub><i>z</i></sub>) =<image href="images/JFYZ201905019_094.jpg" type="" display="inline" placement="inline"><alt></alt></image><i>F</i> (<i>x</i><sub><i>z</i></sub>) , 该算法的数学表达形式<citation id="296" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>为</p>
                </div>
                <div class="p1">
                    <p id="95"><i>x</i><sub><i>z</i>+1</sub>=<i>x</i><sub><i>z</i></sub>-<i>η</i><sub><i>z</i></sub>×<i>g</i><sub><i>z</i></sub>. (2) </p>
                </div>
                <div class="p1">
                    <p id="96">虽然随机梯度下降算法在不同程度上解决梯度下降算法的2个缺陷, 但为了使它能够针对具体问题获得最佳的处理效果, 众多研究人员针对具体问题特性对它优化深度学习和机器学习问题进行大量研究, 提出它的很多变种, 取得较满意的效果.Yang等人<citation id="297" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>采用基于动量的随机梯度下降算法优化图片问答模型, 提出SANs模型, 解决图片问答问题;Wu等人<citation id="298" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>采用基于最小批的随机梯度下降算法优化图片问答模型, 提出将图片内容与外部知识库提取的信息级联在一起进行多元输入的模型, 解决自由形式的视觉问答问题;Yu等人<citation id="299" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>采用基于动量和最小批的随机梯度下降算法优化图片问答模型, 提出多层注意力网络 (multi-level attention network, MLAN) , 解决图片问答问题;Gu等人<citation id="300" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和Lu等人<citation id="301" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>采用Rmsprop算法优化图片问答模型, 较好地解决图片问答问题;Anderson等人<citation id="302" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>采用基于最小批的AdaDelta算法优化图片问答模型, 提出自下而上和自上而下相结合的注意力机制, 解决图片问答问题;Loshchilov 等人<citation id="303" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>将重启的思想应用到多模态学习问题中, 提出基于重启的随机梯度算法, 解决分类问题;Bianchi 等人<citation id="304" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在随机梯度下降算法基础上提出一种新的多机系统的分布式约束的非凸优化算法的收敛性分析框架;姜纪远等人<citation id="305" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>针对随机梯度下降算法在求解强凸优化中的正则优化问题时的收敛速度过慢的问题, 将COMID算法和α-suffix平均技巧结合, 提出LIMD -α算法;杨双涛等人<citation id="306" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出异步双随机梯度算法, 解决异步单随机梯度算法在集群环境中的通信冲突问题;陈振宏等人<citation id="307" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>针对基于模型合并的大规模随机梯度下降算法忽略参与合并模型的内在差异性而导致模型收敛速度慢和性能较差的问题, 提出基于模型差异的合并策略;李平等人<citation id="308" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>采用基于随机梯度下降的逻辑回归方法进行文本情感分类, 并利用模拟退火原理自适应选择步长, 解决随机梯度下降算法中步长难以确定的问题;王功鹏等人<citation id="309" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出自适应更新学习率的随机梯度下降算法, 解决学习率参数设置不当对随机梯度下降算法造成的不利影响.</p>
                </div>
                <div class="p1">
                    <p id="97">总之, 随机梯度下降算法在一定程度上解决梯度下降算法的2个明显缺陷, 具有广泛的应用场景和良好的应用效果.在具体应用场景中, 需要针对具体问题对随机梯度下降算法进行改进, 得到随机梯度下降算法的变种.常用的改进方法有设置最小批、在算法中加入动量、调整学习率等.改进后的随机梯度下降算法与其他算法相结合, 使目标函数逐步收敛到最小值点, 从而达到算法优化的目的.</p>
                </div>
                <div class="p1">
                    <p id="98">本文借鉴随机梯度下降算法改进的常规思路, 分析随机梯度下降算法的工作原理和工作机制, 同时考虑数据集的特点, 在SANs模型的基础上提出基于图片问答的静态重启随机梯度下降算法.</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag"><b>2 动量随机梯度下降算法</b></h3>
                <div class="p1">
                    <p id="100">若初始学习率设置不当, 随机梯度下降算法在优化深度神经网络时易陷入局部最优解.在算法中引入动量后, 可以帮助深度神经网络跳出局部最优解的限制.基于动量的随机梯度下降算法通过多次迭代在目标函数值递减的方向上累积1个速度矢量以加速梯度下降<citation id="310" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="101">设<b><i>v</i></b><sub><i>z</i></sub>表示当前的速度矢量, <i>γ</i>表示动量系数.该算法的数学表达形式<citation id="311" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>为</p>
                </div>
                <div class="p1">
                    <p id="102"><b><i>v</i></b><sub><i>z</i>+1</sub>=<b><i>v</i></b><sub><i>z</i></sub>×<i>γ</i>-<i>η</i><sub><i>z</i></sub>×<i>g</i><sub><i>z</i></sub>, (3) </p>
                </div>
                <div class="p1">
                    <p id="103"><i>x</i><sub><i>z</i>+1</sub>=<i>x</i><sub><i>z</i></sub>+<b><i>v</i></b><sub><i>z</i>+1</sub>. (4) </p>
                </div>
                <div class="p1">
                    <p id="104">该算法仅仅增加一部分之前的速度矢量.当梯度下降保持原来的方向时, 它能增加下降的步幅, 从而更快地到达最小值点;当梯度下降改变方向时, 它能使改变量平滑一点, 这对于不好的网络初始值具有重要的弥补作用<citation id="312" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.因此, 它能使深度神经网络较快地达到最小值点而没有太多震荡.它优化SANs模型, 在4个公开的视觉问答数据集中获得当时最好的结果, 本文将其作为评估基准.</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>3 静态重启随机梯度下降算法</b></h3>
                <div class="p1">
                    <p id="106">随机梯度下降算法常用于解决机器学习算法中的参数优化问题.如果考虑随机性, 重启的思想能够用于随机梯度下降算法<citation id="313" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.在深度神经网络中, 梯度和目标函数值可以从一个最小批到下一个最小批的范围内变化, 故重启算法也能够用于深度神经网络.深度神经网络的解空间类似于无边无际、高低起伏、绵延不绝的高山组成的峡谷, 随机梯度下降算法优化的目标是找到峡谷的最低点, 即目标函数值最小的点.目前的方法采用海量数据训练深度神经网络, 通过随机梯度下降算法优化该网络, 尽可能地在解空间中找到这个全局最低点.但随机梯度下降算法在优化深度神经网络时, 若设置较大的学习率, 算法收敛速度快, 容易跳过最低点;若设置较小的学习率, 算法收敛速度慢, 且容易陷入不好的局部最低点.为了在图片问答任务中解决该问题, 提出基于图片问答的静态重启随机梯度下降算法.该算法在搜索局部最优解的过程中采用退火策略, 使学习率由大到小逐步减小, 解决学习率过大造成算法跳过最优解的问题, 同时使收敛速度适中;当最优解不是全局最优解或算法陷入不好的局部最优解时, 采用静态重启策略给算法一个较大的重启学习率, 使算法能跳出局部最优解, 并继续寻找全局最优解.在理论上, 该算法能够找到全局最优解, 提高深度神经网络的性能.</p>
                </div>
                <div class="p1">
                    <p id="107">设<i>ω</i>表示当前最小批数, <i>e</i>表示训练次数, <i>β</i>表示重启周期的最小批数, <i>φ</i>表示重启缩放因子, <i>η</i><sub>max</sub>表示学习率变化的上界, <i>η</i><sub>min</sub>表示学习率变化的下界, <i>σ</i>表示学习率变化率.</p>
                </div>
                <div class="p1">
                    <p id="108">若<i>ω</i>%<i>β</i>=0, <i>η</i><sub><i>z</i></sub>≥<i>η</i><sub>min</sub>, 则更新学习率:</p>
                </div>
                <div class="p1">
                    <p id="109"><i>η</i><sub><i>z</i>+1</sub>=<i>η</i><sub><i>z</i></sub>×<i>σ</i>. (5) </p>
                </div>
                <div class="p1">
                    <p id="110">若<i>ω</i>%<i>β</i>≠0, <i>η</i><sub><i>z</i></sub>≥<i>η</i><sub>min</sub>, 则更新学习率:</p>
                </div>
                <div class="p1">
                    <p id="111"><i>η</i><sub><i>z</i>+1</sub>=<i>η</i><sub><i>z</i></sub>. (6) </p>
                </div>
                <div class="p1">
                    <p id="112">若<i>ω</i>%<i>β</i>=0, <i>η</i><sub><i>z</i></sub>&lt;<i>η</i><sub>min</sub>, 则更新学习率:</p>
                </div>
                <div class="p1">
                    <p id="113"><i>η</i><sub><i>z</i>+1</sub>=<i>η</i><sub>max</sub>×<i>φ</i> . (7) </p>
                </div>
                <div class="p1">
                    <p id="114">静态重启算法中的学习率更新随机梯度下降算法中的学习率, 提出基于静态重启的随机梯度下降算法.该算法优化SANs模型, 提出基于图片问答的静态重启随机梯度下降算法.它通过自适应地调节学习率寻求图片问答的全局最优解.若SANs模型接近极值点时, 它缓慢地给予模型一个较小的学习率, 便于模型逐步收敛到局部最优解;若该最优解不是全局最优解时, 通过重启算法给予模型一个较大的学习率, 便于模型跳出不好的局部最优解, 并试探性地找到全局最优解.为了防止通过重启而获得的学习率太大, 导致模型跳到下一个不好的局部最优解的附近, 在重启时通过重启缩放因子调节重启学习率, 使它在合理的范围内变化.</p>
                </div>
                <h3 id="115" name="115" class="anchor-tag"><b>4 基于堆叠注意力网络的图片问答模型</b></h3>
                <div class="p1">
                    <p id="116">基于堆叠注意力网络的图片问答模型由基于CNN的图片模型、基于CNN的问题模型、基于attention的堆叠注意力模型组成.</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117"><b>4.1 图片模型</b></h4>
                <div class="p1">
                    <p id="118">图片模型用于抽取图片特征, 一般采用CNN<citation id="314" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>模型, 很少一部分采用Faster R-CNN<citation id="315" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>框架.CNN模型可以采用VGGNet<citation id="316" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, ResNet<citation id="317" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, GoogLeNet<citation id="318" type="reference"><link href="259" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>实现.</p>
                </div>
                <div class="p1">
                    <p id="119">本文采用基于VGGNet的CNN模型抽取图片特征<citation id="319" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.经过VGGNet处理, 维度为448×448的原始图片抽取维度为14×14的图片特征.每个维度的图片特征是一个1×512维的局部图片特征向量.这些特征向量不是来自最后的全连接层, 而是来自最后的池化层.因为这一层保留原始图片的空间信息, 故采用这一层的图片特征能够收到更好的效果.最后, 1×512维的局部图片特征向量通过单层感知机转换成与问题向量同维度的新特征向量<b><i>I</i></b><sub><i>i</i></sub> (<i>i</i>=0, 2, …, 195) .196个新特征向量形成图片特征矩阵<b><i>I</i></b>, 用于在堆叠注意力模型中与问题特征进行特征融合.</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>4.2 问题模型</b></h4>
                <div class="p1">
                    <p id="121">问题模型用于抽取问题特征, 常采用BOW (bag of words) <citation id="320" type="reference"><link href="261" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, GRU (gated recurrent unit) <citation id="321" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>, LSTM<citation id="322" type="reference"><link href="265" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, RNN (recurrent neural network) <citation id="323" type="reference"><link href="267" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>, CNN<citation id="324" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>实现.</p>
                </div>
                <div class="p1">
                    <p id="122">本文采用基于CNN的问题模型抽取问题的语义信息<citation id="325" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.基于CNN的问题模型由embedding层、卷积层、最大池化层构成.在embedding层中, 每个单词的embedding向量由embedding矩阵乘以每个单词的one hot向量得到, 然后顺次级联问题中每个单词的embedding向量, 得到问题的embedding向量.在卷积层中, 每个单词的embedding向量作为卷积层的输入.卷积层有一元、二元、三元的过滤器.设过滤器的尺寸为<i>j</i> (<i>j</i>=1, 2, 3) , 则尺寸为<i>j</i>的第<i>s</i>个卷积特征为<b><i>Q</i></b><sub><i>sj</i></sub>.所有<b><i>Q</i></b><sub><i>sj</i></sub>级联在一起, 形成卷积特征<b><i>Q</i></b><sub><i>j</i></sub>.在最大池化层中, 对<b><i>Q</i></b><sub><i>j</i></sub>进行最大池化处理, 得到相应的池化特征<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Q</mi><mo>˜</mo></mover></math></mathml><sub><i>j</i></sub>.所有的<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>级联在一起, 得到问题的特征向量<b><i>Q</i></b>, 用于在堆叠注意力模型中与图片特征进行特征融合.</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>4.3 堆叠注意力模型</b></h4>
                <div class="p1">
                    <p id="126">堆叠注意力模型用于把图片特征和问题特征融合后推断问题答案<citation id="326" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.经过图片模型和问题模型的处理, 得到图片特征矩阵<b><i>I</i></b>和问题特征向量<b><i>Q</i></b>.它们作为单层神经网络的输入, 得到其输出结果<b><i>h</i></b>, 再把<b><i>h</i></b>作为softmax层的输入, 得到问题相关的局部图片区域的attention分布<b><i>p</i></b>.<b><i>p</i></b>由196个局部图片attention分布<i>p</i><sub><i>i</i></sub>组成.<i>p</i><sub><i>i</i></sub>乘以相应的局部图片特征向量<b><i>I</i></b><sub><i>i</i></sub>, 得到一维向量<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover></math></mathml><sub><i>i</i></sub>.所有<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover></math></mathml><sub><i>i</i></sub>累加求和后, 得到一维向量<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover></math></mathml>.该向量不仅包含问答相关的视觉信息, 而且有利于问题特征向量融合.<b><i>Q</i></b>与基于attention的图片特征向量<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover></math></mathml>融合, 得到1个经过改良的查询向量<b><i>q</i></b>.<b><i>q</i></b>不仅含有答案相关的局部图片区域, 而且排除答案不相关的局部图片区域.</p>
                </div>
                <div class="p1">
                    <p id="131">对于简单问题, 单层模型足以准确定位答案相关的局部图片区域.但对于复杂问题, 需要多层模型进行多步推理才能准确定位答案相关的局部图片区域.多层模型与单层模型类似, 唯一的区别是输入层中用前一层的查询向量替代<b><i>Q</i></b>, 其他都不变.如果需要<i>k</i>层模型才能准确定位答案相关的局部图片区域, 那么采用<b><i>q</i></b><sub><i>k</i></sub>作为查询向量推断最终答案<citation id="327" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.本文采用2层模型, 因为3层或者更多层模型不能进一步改进问答性能<citation id="328" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>5 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="133">本文在基于SANs的图片问答模型上评估基于图片问答的静态重启随机梯度下降算法.基准算法为基于图片问答的动量随机梯度下降算法.评估方法为视觉问答评估算法, 根据问答评估结果评估算法性能.评估数据为最复杂的VQAv1数据集.</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"><b>5.1 数据集</b></h4>
                <div class="p1">
                    <p id="135">常用的图片问答数据集有DAQUAR<citation id="329" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>, COCO-QA<citation id="330" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>, Visual7W<citation id="331" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>, VQA<citation id="332" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>, FM-IQA<citation id="333" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="136">本文采用最复杂的VQAv1数据集.该数据集包含82 783个训练集图片和40 504个验证集图片.每个图片有3个问题, 每个问题有10个答案.答案由10个不同人进行标注, 故这10个答案可能相同, 也可能不相同.问题类型较多, 答案长度也不同, 最长为17个单词.</p>
                </div>
                <div class="p1">
                    <p id="137">在对数据集进行预处理时, 统计答案出现的频次, 根据频次对答案进行降序排列, 然后抽取前1 000个高频答案 (占答案总数的82.67%<citation id="334" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>) 作为对问题进行分类的类标签.训练集用于训练模型;验证集一分为二<citation id="335" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 分别作为验证集和测试集, 用于验证训练的模型和测试训练的模型.</p>
                </div>
                <h4 class="anchor-tag" id="138" name="138"><b>5.2 图片问答评估算法</b></h4>
                <div class="p1">
                    <p id="139">根据VQAv1数据集的特点, 每个问题有10个答案, 它们可能相同, 也可能不同, 故图片问答模型对该数据集的评估方法不能采用机器学习和深度学习中常用的评估算法, 只能采用文献<citation id="336" type="reference">[<a class="sup">30</a>]</citation>中的视觉问答度量方法, 该方法的数学表达形式为</p>
                </div>
                <div class="p1">
                    <p id="140"><i>acc</i> (<i>a</i>) =min ( (#humans that said <i>a</i>) /3, 1) . (8) </p>
                </div>
                <div class="p1">
                    <p id="141">它是一个全新的评估指标.只要人工标注的10个答案中有3个或3个以上的答案跟机器给予的答案匹配, 就评估机器对该问题的回答完全正确;否则, 评估机器对该问题的回答部分正确.除此之外, 在评估之前, 对机器产生的答案和人工标注的答案进行预处理, 仅仅保留答案中的核心词.因此, 该评估算法对不同人对同一个答案的不同表达形式具有较强的鲁棒性, 能够产生比较客观且准确的评估结果, 从而保证该算法评估图片问答结果的有效性和可靠性.</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>5.3 模型配置</b></h4>
                <div class="p1">
                    <p id="143">在基准算法实验中, <i>γ</i>=0.9, <i>β</i>=1 000, <i>e</i>=50, <i>η</i><sub>0</sub>=0.1.根据训练数据量和训练次数, 最小批的总数为145 400.算法每经过<i>β</i>个最小批的训练更新一次学习率.在更新学习率时, 测试集测试训练的模型, 并输出1个测试结果.因此, 算法共得到146个测试结果, 从中获得全局最优结果作为算法的实验结果.</p>
                </div>
                <div class="p1">
                    <p id="144">在基于图片问答的静态重启随机梯度下降算法实验中, <i>σ</i>=0.9, <i>η</i><sub>max</sub>=0.1, <i>η</i><sub>min</sub>=0.000 5, <i>φ</i>=0.5, 其他模型配置与基准算法一致.</p>
                </div>
                <h4 class="anchor-tag" id="145" name="145"><b>5.4 实验结果</b></h4>
                <div class="p1">
                    <p id="146">根据上述实验配置, 得到实验结果.为了便于在同一数量级下比较实验结果中的各个参数之间的变化趋势, 学习率值放大到原来的30倍, 最小批数缩小到原来的1/50 000, 得到图片问答结果<i>acc</i> (<i>a</i>) 随当前最小批数<i>ω</i>、学习率<i>η</i>、目标函数值<i>loss</i>变化的实验结果, 如图2和图3所示:</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905019_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基准算法的实验结果" src="Detail/GetImg?filename=images/JFYZ201905019_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基准算法的实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905019_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The experimental results of baseline</p>

                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905019_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 静态重启随机梯度下降算法的实验结果" src="Detail/GetImg?filename=images/JFYZ201905019_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 静态重启随机梯度下降算法的实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905019_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The experimental results of static restart stochastic gradient descent</p>

                </div>
                <div class="p1">
                    <p id="149">为了全面评估算法特性, 本文抽取图2和图3中的全局最优实验结果和高性能算法在达到低性能算法的全局最优实验结果时的结果, 如表1所示.在表1中, M和R分别表示基准算法和基于图片问答的静态重启随机梯度下降算法;符号=的左侧是高性能算法, 其右侧是低性能算法.</p>
                </div>
                <div class="area_img" id="150">
                    <p class="img_tit"><b>表1 全局最优实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 The Global Optimal Experimental Results</b></p>
                    <p class="img_note"></p>
                    <table id="150" border="1"><tr><td><br />Model</td><td><i>ω</i></td><td><i>η</i></td><td><i>loss</i></td><td><i>acc</i> (<i>a</i>) </td></tr><tr><td><br />M</td><td>78 000</td><td>0.100 0</td><td>1.670 57</td><td>0.521 8</td></tr><tr><td><br />R</td><td>137 000</td><td>0.000 7</td><td>1.698 22</td><td>0.524 7</td></tr><tr><td><br />R=M</td><td>114 000</td><td>0.007 5</td><td>1.707 77</td><td>0.522 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="151" name="151"><b>5.5 实验分析</b></h4>
                <div class="p1">
                    <p id="152">根据图2所示, 在学习率不变的条件下, 基准算法在优化图片问答模型时, 随着最小批数增加, 目标函数值沿着比较平滑的单调曲线方向逐渐减小, 图片问答评估结果沿着比较平滑的单调曲线方向逐渐增加.对于局部异常点, 比如第25个结果, 目标函数值骤然上升, 相应的图片问答结果也急剧下降.因此, 基准算法在优化图片问答模型时, 各个参数与结果之间的变化是合理的, 说明它的实验结果是可信的和有效的.</p>
                </div>
                <div class="p1">
                    <p id="153">根据图3所示, 基于图片问答的静态重启随机梯度下降算法在优化图片问答模型时, 随着最小批数增加, 学习率在0.1和0.000 5或者0.05和0.000 5之间上下波动, 目标函数值也相应地比较平缓地上下变化, 图片问答评估结果沿着目标函数值曲线的单调性相反的方向变化.因此, 基于图片问答的静态重启随机梯度下降算法在优化图片问答模型时, 各个参数与结果之间的变化是合理的, 没有发现异常情况, 说明它的实验结果是可信的和有效的.</p>
                </div>
                <div class="p1">
                    <p id="154">根据表1所示, 基准算法在<i>ω</i>=78 000时获得全局最优实验结果, 其值为52.18%;基于图片问答的静态重启随机梯度下降算法在<i>ω</i>=137 000时获得全局最优实验结果, 其值为52.47%;基于图片问答的静态重启随机梯度下降算法在<i>ω</i>=114 000时能够收敛到与基准算法的全局最优实验结果相同的结果, 其值为52.2%.因此, 基于图片问答的静态重启随机梯度下降算法的全局最优实验结果比基准算法高0.29%, 但基于图片问答的静态重启随机梯度下降算法在收敛到基准算法的全局最优实验结果的过程中, 其收敛速度慢46.15%.收敛速度变慢的原因是重启学习率.每次重启学习率时, 算法都跳出不好的局部最优解而重新尝试找到较好的局部最优解, 并尽可能找到全局最优解.算法不断重启、迭代、探索, 这个过程导致算法收敛速度变慢.</p>
                </div>
                <div class="p1">
                    <p id="155">根据实验评估方法和性能度量标准, 实验结果和分析表明基于图片问答的静态重启随机梯度下降算法的问答准确率高于基准算法.但它的性能改善是否显著呢?为了回答这个问题, 本文对表1中的实验结果进行统计假设检验.</p>
                </div>
                <div class="p1">
                    <p id="156">为了对表1中的结果进行统计假设检验, 本文分别从2个算法的全局最优实验结果附近连续抽取21个样本.根据抽样结果, 采用T检验法<citation id="337" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>对样本做统计假设检验, 检验结果 (显著度<i>α</i>=0.05) 如表2所示:</p>
                </div>
                <div class="area_img" id="157">
                    <p class="img_tit"><b>表2 T检验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 The Results of T Test</b></p>
                    <p class="img_note"></p>
                    <table id="157" border="1"><tr><td><br /><i>t</i></td><td><i>P</i></td></tr><tr><td><br />4.596</td><td>4.584E-05</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="158">根据表2所示, <i>t</i>=4.596, <i>P</i>=4.584E-05.因此, T检验结果中的<i>P</i>&lt;0.0001, 即<i>P</i>≪0.05, 说明在收敛到全局最优解的过程中它的性能改善在统计意义上是极其显著的.</p>
                </div>
                <div class="p1">
                    <p id="159">基于图片问答的静态重启随机梯度下降算法属于一阶优化算法.当前最好的同类算法有RmsProp<citation id="338" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>, Adam<citation id="339" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>, AdaDelta<citation id="340" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>.为了验证它在同类算法中的有效性, 在图片问答任务上进行优化算法实验, 实验结果如表3所示:</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表3 优化算法的全局最优实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 The Global Optimal Experimental Results of Optimization Algorithm</b></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />Model</td><td><i>ω</i></td><td><i>η</i></td><td><i>loss</i></td><td><i>acc</i> (<i>a</i>) </td></tr><tr><td><br />R</td><td>137 000</td><td>0.000 7</td><td>1.698 22</td><td>0.524 7</td></tr><tr><td><br />M</td><td>78 000</td><td>0.100 0</td><td>1.670 57</td><td>0.521 8</td></tr><tr><td><br />RmsProp</td><td>145 000</td><td>0.100 0</td><td>1.930 07</td><td>0.482 2</td></tr><tr><td><br />Adam</td><td>119 000</td><td>0.100 0</td><td>1.709 42</td><td>0.519 4</td></tr><tr><td><br />AdaDelta</td><td>125 000</td><td>0.100 0</td><td>1.771 28</td><td>0.500 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="161">根据表3所示, 在解决图片问答任务时, 基于图片问答的静态重启随机梯度下降算法的准确率高于其他优化算法.因此, 它在解决图片问答问题时更有效.</p>
                </div>
                <div class="area_img" id="162">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905019_162.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 泛化性能和推广价值的实验结果" src="Detail/GetImg?filename=images/JFYZ201905019_162.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 泛化性能和推广价值的实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905019_162.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The experimental results of generalization  performance and promotion value</p>

                </div>
                <div class="p1">
                    <p id="163">算法结果与数据集的选取有关.如果换一个数据集, 基于图片问答的静态重启随机梯度下降算法是否有效呢?即它是否具有良好的泛化性能呢?算法结果与任务的选择有关.如果换一个任务, 它是否有效呢?即它是否具有良好的推广价值呢?为了回答这2个问题, 针对图像识别任务, 在经典的Cifar-10数据集<citation id="341" type="reference"><link href="289" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>上采用5层深度残差网络<citation id="342" type="reference"><link href="291" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>进行图像识别实验.在基准算法为动量随机梯度下降算法的图像识别实验中, <i>η</i><sub>0</sub>=0.1.在基于图片问答的静态重启随机梯度下降算法的图像识别实验中, <i>e</i>=16, <i>β</i>=3, <i>η</i><sub>max</sub>=0.1, <i>η</i><sub>min</sub>=0.000 5, <i>σ</i>=0.69.算法每被训练集训练3次更新1次学习率, 每被训练集训练1次, 测试集测试训练的模型1次, 并输出测试结果.根据模型配置, 得到图像识别结果, 如图4所示:</p>
                </div>
                <div class="p1">
                    <p id="164">根据图4所示, 基于图片问答的静态重启随机梯度下降算法的全局最优实验结果为88.83%, 基准算法的全局最优实验结果为85.00%.除了训练初期的个别结果外, 基于图片问答的静态重启随机梯度下降算法的大部分结果都比基准算法好.但性能改善是否显著呢?从图4中的算法全局最优实验结果附近连续抽取6个样本进行T检验.<i>t</i>=9.655 8, <i>P</i>=3.207E-05.<i>P</i>&lt;0.000 1, 说明在收敛到全局最优解的过程中性能改善在统计意义上是极其显著的.因此, 基于图片问答的静态重启随机梯度下降算法在收敛到全局最优解的过程中具有良好的泛化性能和较好的推广价值.</p>
                </div>
                <h3 id="165" name="165" class="anchor-tag"><b>6 结 论</b></h3>
                <div class="p1">
                    <p id="166">针对SANs模型解决图片问答过程中的问题, 观察模型处理的细节, 分析数据集的特点, 发现基于动量的随机梯度下降算法在优化SANs模型时存在一定的缺陷是导致问题发生的重要原因.为了解决该问题, 调研随机梯度下降算法, 结合SANs模型的特点, 提出基于图片问答的静态重启随机梯度下降算法.在VQAv1数据集、Cifar-10数据集、同类优化算法上进行量化对比实验.实验结果和T检验结果证明它的显著性、有效性、泛化性、推广价值.因此, 它在一定程度上解决基于图片问答的动量随机梯度下降算法中的问题, 具有良好的性能和较高的应用前景.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="221">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked attention networks for image question answering">

                                <b>[1]</b>Yang Zichao, He Xiaodong, Gao Jianfeng, et al.Stacked attention networks for image question answering[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:21- 29
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Why is stochastic steepest descent (SGD) a good method?[OL]">

                                <b>[2]</b>Yang Yuan.Why is stochastic steepest descent (SGD) a good method?[OL]. (2017-08-27) [2018-01-22].https://zhuanlan.zhihu.com/p/27609238
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ask Me Anything:Free-form Visual Question Answering Based on Knowledge from External Sources">

                                <b>[3]</b>Wu Qi, Wang Peng, Shen Chunhua, et al.Ask me anything:Free-form visual question answering based on knowledge from external sources[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4622- 4630
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-level Attention Networks for Visual Question Answering">

                                <b>[4]</b>Yu Dongfei, Fu Jianlong, Mei Tao, et al.Multi-level attention networks for visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:4187- 4195
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive attention fusion network for visual question answering">

                                <b>[5]</b>Gu G, Kim S T, Yong M R.Adaptive attention fusion network for visual question answering[C] //Proc of the 2017 IEEE Int Conf on Multimedia and Expo.Piscataway, NJ:IEEE, 2017:997- 1002
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Hierarchical question-image coattention for visual question answering,&amp;quot;">

                                <b>[6]</b>Lu Jiasen, Yang Jianwei, Batra D, et al.Hierarchical question-image co-attention for visual question answering[C/OL] //Proc of the 2016 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2016 (2016-05-31) [2018-03-01].https://arxiv.org/abs/1606.00061v5
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bottom-up and top-down attention for image captioning and visual question answering">

                                <b>[7]</b>Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SGDR:Stochastic gradient descent with warm restarts[C/OL]">

                                <b>[8]</b>Loshchilov I, Hutter F.SGDR:Stochastic gradient descent with warm restarts[C/OL] //Proc of the 5th Int Conf on Learning Representations.2017 [2018-03-06].https://arxiv.org/abs/1608.03983
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convergence of a Multi-Agent Projected Stochastic Gradient Algorithm for Non-Convex Optimization">

                                <b>[9]</b>Bianchi P, Jakubowicz J.Convergence of a multi-agent projected stochastic gradient algorithm for non-convex optimization[J].IEEE Transactions on Automatic Control, 2013, 58 (2) :391- 405
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201409003&amp;v=Mjc2MDRkTEc0SDlYTXBvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGeW5sVWJ6S0x5dlM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Jiang Jiyuan, Xia Liang, Zhang Xian, et al.A sparse stochastic algorithm with O (1/T) convergence rate[J].Journal of Computer Research and Development, 2014, 51 (9) :1901- 1910 (in Chinese) (姜纪远, 夏良, 章显, 等.一种具有O (1/T) 收敛速率的稀疏随机算法[J].计算机研究与发展, 2014, 51 (9) :1901- 1910) 
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201705031&amp;v=MDI4NzZVYnpLUFRYY2RyRzRIOWJNcW85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Yang Shuangtao, Ma Zhiqiang, Dou Baoyuan, et al.Asynchronous double stochastic gradient descent algorithm in yarn framework[J].Journal of Chinese Computer Systems, 2017, 38 (5) :1070- 1075 (in Chinese) (杨双涛, 马志强, 窦保媛, 等.一种Yarn框架下的异步双随机梯度下降算法[J].小型微型计算机系统, 2017, 38 (5) :1070- 1075) 
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201510010&amp;v=MjY4ODhIOVROcjQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHo3QmRyRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Chen Zhenhong, Lan Yanyan, Guo Jiafeng, et al.Distributed stochastic gradient descent with discriminative aggregating[J].Chinese Journal of Computers, 2015, 38 (10) :2054- 2063 (in Chinese) (陈振宏, 兰艳艳, 郭嘉丰, 等.基于差异合并的分布式随机梯度下降算法[J].计算机学报, 2015, 38 (10) :2054- 2063) 
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712035&amp;v=MDk4MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGeW5sVWJ6S0x6N0JiYkc0SDliTnJZOUdZWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Li Ping, Dai Yueming, Wang Yan.Text sentiment analysis based on hybrid chi-square statistic and logistic regression[J].Computer Engineering, 2017, 43 (12) :192- 196 (in Chinese) (李平, 戴月明, 王艳.基于混合卡方统计量与逻辑回归的文本情感分析[J].计算机工程, 2017, 43 (12) :192- 196) 
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201802026&amp;v=MDI2ODhaZVJxRnlubFViektOaWZZWkxHNEg5bk1yWTlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Wang Gongpeng, Duan Meng, Niu Changyong.Stochastic gradient descent algorithm based on convolution neural network[J].Computer Engineering and Design, 2018, 39 (2) :441- 445 (in Chinese) (王功鹏, 段萌, 牛常勇.基于卷积神经网络的随机梯度下降算法[J].计算机工程与设计, 2018, 39 (2) :441- 445) 
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Seven common random gradient descent algorithms[OL]">

                                <b>[15]</b>Wang Chen.Seven common random gradient descent algorithms[OL].2017 [2018-02-01].http://wangpan.loan/post/54.html
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3E2747A8B911A469B998E7C73FD7AEE8&amp;v=MjcxNjY5aDR6WjFQWGlScXhGRERiWGxNTStYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnhoeGJpOXc2bz1OaWZPZmJETkhOYklxUDVORnVJT0RRMDl5Ug==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Kafle K, Kanan C.Visual question answering:Datasets, algorithms, and future challenges[J].Computer Vision and Image Understanding, 2017, 163:3- 20
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bottom-up and top-down attention for image captioning and visual question answering">

                                <b>[17]</b>Anderson P, He Xiaodong, Buehler C, et al.Bottom-up and top-down attention for image captioning and visual question answering[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017:6077- 6086
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Active learning for visual question answering:An empirical study[C/OL]">

                                <b>[18]</b>Lin Xiao, Parikh D.Active learning for visual question answering:An empirical study[C/OL] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2017 (2017-11-06) [2018-03-20].https://arxiv.org/abs/1711.01732
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3C84822FD024CB340672A116F38C75E2&amp;v=MTc5MDY3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54aHhiaTl3Nm89TmlmT2ZiRExGdFhFclkwekVPc05DQTlMekJJVDdEaC9PWDdqcW1RMmNjR1RRTStkQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Wu Qi, Teney D, Wang Peng, et al.Visual question answering:A survey of methods and datasets[J].Computer Vision and Image Understanding, 2017, 163:21- 41
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD06E7D905CC65C690282027F9DA2BE66F&amp;v=MDkyNDhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGh4Ymk5dzZvPU5qN0Jhck8rYTlhNHBvOUFGNWdKQ1E4L3hoWVI0ajE5U25pVXBXWkVlOERoUTd6cA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Agrawal A, Lu Jiasen, Antol S, et al.VQA:Visual question answering[J].International Journal of Computer Vision, 2015, 123 (1) :4- 31
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_21" >
                                    <b>[21]</b>
                                Ren M, Kiros R, Zemel R S.Exploring models and data for image question answering[C] //Proc of the 2015 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:2953- 2961
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image question answering using convolutional neural network with dynamic parameter prediction">

                                <b>[22]</b>Noh H, Seo P H, Han B.Image question answering using convolutional neural network with dynamic parameter prediction[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:30- 38
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Zero-shot visual question answering[C/OL]">

                                <b>[23]</b>Teney D, Hengel A V D.Zero-shot visual question answering[C/OL] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016 (2016-11-20) [2018-03-16].http://arxiv.org/pdf/1611.05546
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simple and effective visual question answering in a single modality">

                                <b>[24]</b>Lin Yuetan, Pang Zhangyang, Li Yanan, et al.Simple and effective visual question answering in a single modality[C] //Proc of the 23rd IEEE Int Conf on Image Processing.Recognition.Piscataway, NJ:IEEE, 2016:2276- 2280
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input">

                                <b>[25]</b>Malinowski M, Fritz M.A multi-world approach to question answering about real-world scenes based on uncertain input[C] //Proc of the 2014 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2014:1682- 1690
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploring models and data for image question answering">

                                <b>[26]</b>Ren M, Kiros R, Zemel R S.Exploring models and data for image question answering[C] //Proc of the 2015 Int Conf on Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:2953- 2961
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual7W:Grounded question answering in images">

                                <b>[27]</b>Zhu Yuke, Groth O, Bernstein M, et al.Visual7W:Grounded question answering in images[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:4995- 5004
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual question answering:A tutorial">

                                <b>[28]</b>Teney D, Wu Qi, Hengel A V D.Visual question answering:A tutorial[J].IEEE Signal Processing Magazine, 2017, 34 (6) :63- 76
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201809010&amp;v=MjAzNjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHl2U2RMRzRIOW5NcG85RVpJUUs=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b>Yu Jun, Wang Liang, Yu Zhou.Research on visual question answering techniques[J].Journal of Computer Research and Development, 2018, 55 (9) :1946- 1958 (in Chinese) (俞俊, 汪亮, 余宙.视觉问答技术研究[J].计算机研究与发展, 2018, 55 (9) :1946- 1958) 
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VQA evaluation method[OL]">

                                <b>[30]</b>Agrawal A.VQA evaluation method[OL]. (2017-10-03) [2018-01-08].http://www.visualqa.org/evaluation.html
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=T test[OL]">

                                <b>[31]</b>Tiaaaaa.T test[OL]. (2017-02-27) [2018-04-15].https://blog.csdn.net/tiaaaaa/article/details/58130363
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Summary of optimization methods[OL]">

                                <b>[32]</b>Multiangle.Summary of optimization methods[OL]. (2016-11-01) [2018-06-12].https://blog.csdn.net/u014595019/article/details/52989301
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparison of the stochastic gradient descent based optimization techniques">

                                <b>[33]</b>Yazan E, Talu M F.Comparison of the stochastic gradient descent based optimization techniques[C] //Proc of the Int Artificial Intelligence and Data Processing Symp.Piscataway, NJ:IEEE, 2017:1- 6
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ADADELTA:An adaptive learning rate method">

                                <b>[34]</b>Zeiler M D.ADADELTA:An adaptive learning rate method[OL]. (2012-12-22) [2018-03-12].https://arxiv.org/pdf/1212.5701v1.pdf
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The CIFAR-10 dataset">

                                <b>[35]</b>Krizhevsky A.The CIFAR-10 dataset[OL]. (2009-03-31) [2018-04-20].http://www.cs.toronto.edu/～kriz/cifar.html
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[36]</b>He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the 2016 IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201905019" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905019&amp;v=MTU4MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5bmxVYnpLTHl2U2RMRzRIOWpNcW85RWJZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMlkzU0Nubk5wUEphSXhhb2tTaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

