

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127891956368750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201907003%26RESULT%3d1%26SIGN%3drbhYzsBBnoe22B%252fmQAf8a1eG0pk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201907003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201907003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201907003&amp;v=MDg5NTNJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXZoVzd2Tkx5dlNkTEc0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;1 合作者潜力预测模型设计思路&lt;/b&gt; "><b>1 合作者潜力预测模型设计思路</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="&lt;b&gt;2 合作者潜力预测模型构建过程&lt;/b&gt; "><b>2 合作者潜力预测模型构建过程</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="&lt;b&gt;2.1 特征分析&lt;/b&gt;"><b>2.1 特征分析</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;2.2 样本特征构造&lt;/b&gt;"><b>2.2 样本特征构造</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;2.3 集成学习方法&lt;/b&gt;"><b>2.3 集成学习方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#139" data-title="&lt;b&gt;3 实验设计&lt;/b&gt; "><b>3 实验设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#140" data-title="&lt;b&gt;3.1 数据描述与实验设置&lt;/b&gt;"><b>3.1 数据描述与实验设置</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;3.2 评价指标&lt;/b&gt;"><b>3.2 评价指标</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;3.3 实验结果及分析&lt;/b&gt;"><b>3.3 实验结果及分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图2 科研合作网络">图2 科研合作网络</a></li>
                                                <li><a href="#61" data-title="图1 模型流程图">图1 模型流程图</a></li>
                                                <li><a href="#77" data-title="图3 发表篇数与对应人数">图3 发表篇数与对应人数</a></li>
                                                <li><a href="#79" data-title="图4 发表篇数与对应人数取对数">图4 发表篇数与对应人数取对数</a></li>
                                                <li><a href="#83" data-title="图5 文章题目前3词汇时间分布">图5 文章题目前3词汇时间分布</a></li>
                                                <li><a href="#84" data-title="图6 各等级前50位发文等级分布">图6 各等级前50位发文等级分布</a></li>
                                                <li><a href="#86" data-title="图7 各等级前3位发文等级年份分布">图7 各等级前3位发文等级年份分布</a></li>
                                                <li><a href="#86" data-title="图7 各等级前3位发文等级年份分布">图7 各等级前3位发文等级年份分布</a></li>
                                                <li><a href="#91" data-title="图8 优化后的基本特征">图8 优化后的基本特征</a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表1 文章基本特征组合&lt;/b&gt;"><b>表1 文章基本特征组合</b></a></li>
                                                <li><a href="#134" data-title="图9 集成分类器">图9 集成分类器</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表2 混淆矩阵&lt;/b&gt;"><b>表2 混淆矩阵</b></a></li>
                                                <li><a href="#161" data-title="图10 训练集增加的实验效果">图10 训练集增加的实验效果</a></li>
                                                <li><a href="#163" data-title="图11 基分类器增加的实验效果">图11 基分类器增加的实验效果</a></li>
                                                <li><a href="#163" data-title="图11 基分类器增加的实验效果">图11 基分类器增加的实验效果</a></li>
                                                <li><a href="#164" data-title="图12 训练集和基分类器增加时RF的实验效果">图12 训练集和基分类器增加时RF的实验效果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="271">


                                    <a id="bibliography_1" title="Fortunato S, Bergstrom C T, B9rner K, et al.Science of science[J].Science, 2018, 359 (6379) :185-185" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS8879A5601D3FDCD3567CFE1F33004FFB&amp;v=MTAyMTdidXdHZGk5cW9sRlpaOE1lZ2hLdXhVVzdEZ09QZ3JqMmhFMmViS1FNOHp0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjFoeDd5M3hLMD1OaWZaZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Fortunato S, Bergstrom C T, B9rner K, et al.Science of science[J].Science, 2018, 359 (6379) :185-185
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                    Lee S, Bozeman B.The impact of research collaboration on scientific productivity[J].Social Studies of Science, 2005, 35 (5) :673-702</a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_3" title="Newman M E.The structure of scientific collaboration networks[J].Proceedings of the National Academy of Sciences of the United States of America, 2001, 98 (2) :404-409" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The structure of scientific collaboration networks">
                                        <b>[3]</b>
                                        Newman M E.The structure of scientific collaboration networks[J].Proceedings of the National Academy of Sciences of the United States of America, 2001, 98 (2) :404-409
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_4" title="Michele A, Moro M, Lopes G R.Using link semantics to recommend collaborations in academic social networks[C]//Proc of the 5th Workshop on Simplifying Complex Networks for Practitioners-Simplex.New York:ACM, 2013:833-840" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using LinkSemantics to Recommend Collaborations in Academic Social Networks">
                                        <b>[4]</b>
                                        Michele A, Moro M, Lopes G R.Using link semantics to recommend collaborations in academic social networks[C]//Proc of the 5th Workshop on Simplifying Complex Networks for Practitioners-Simplex.New York:ACM, 2013:833-840
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_5" title="Xia Feng, Chen Zhen, Wang Wei, et al.MVCWalker:Random walk-based most valuable collaborators recommendation exploiting academic factors[J].IEEE Transactions on Emerging Topics in Computing, 2014, 2 (3) :364-375" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MVCWalker:Random Walk-Based Most Valuable Collaborators Recommendation Exploiting Academic Factors">
                                        <b>[5]</b>
                                        Xia Feng, Chen Zhen, Wang Wei, et al.MVCWalker:Random walk-based most valuable collaborators recommendation exploiting academic factors[J].IEEE Transactions on Emerging Topics in Computing, 2014, 2 (3) :364-375
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_6" title="Tang Jie, Wu Sen, Sun Jimeng, et al.Cross-domain collaboration recommendation[C]//Proc of the 18th ACMSIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2012:1285-1293" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cross-domain collaboration recommendation">
                                        <b>[6]</b>
                                        Tang Jie, Wu Sen, Sun Jimeng, et al.Cross-domain collaboration recommendation[C]//Proc of the 18th ACMSIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2012:1285-1293
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_7" title="Su Xiaoyan, Wang Wei, Yu Shuo, et al.Can academic conferences promote research collaboration[C]Proc of the16th ACM?IEEE-CS on Joint Conf on Digital Libraries.New York:ACM, 2016:231-232" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Can academic conferences promote research collaboration">
                                        <b>[7]</b>
                                        Su Xiaoyan, Wang Wei, Yu Shuo, et al.Can academic conferences promote research collaboration[C]Proc of the16th ACM?IEEE-CS on Joint Conf on Digital Libraries.New York:ACM, 2016:231-232
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_8" title="Lopes G R, Moro M M, Wives L K, et al.Collaboration recommendation on academic social networks[C]//Proc of the 29th Int Conf on Conceptual Modeling.Berlin:Springer, 2010:190-199" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaboration recommendation on academic social networks">
                                        <b>[8]</b>
                                        Lopes G R, Moro M M, Wives L K, et al.Collaboration recommendation on academic social networks[C]//Proc of the 29th Int Conf on Conceptual Modeling.Berlin:Springer, 2010:190-199
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_9" title="Wang Wei, Liu Jiaying, Xia Feng, et al.Shifu:Deep learning based advisor-advisee relationship mining in scholarly big data[C]//Proc of the 26th Int Conf on World Wide Web Companion.Lyon, France:International World Wide Web Conferences Committee (IW3C2) , 2017:303-310" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shifu Deep learning based advisor-advisee relationship mining in schol-arly big data">
                                        <b>[9]</b>
                                        Wang Wei, Liu Jiaying, Xia Feng, et al.Shifu:Deep learning based advisor-advisee relationship mining in scholarly big data[C]//Proc of the 26th Int Conf on World Wide Web Companion.Lyon, France:International World Wide Web Conferences Committee (IW3C2) , 2017:303-310
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_10" title="Sagiroglu S, Sinanc D.Big data:A review[C]//Proc of the9th Int Conf on Collaboration Technologies and Systems.Piscataway, NJ:IEEE, 2013:42-47" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Big data:A review">
                                        <b>[10]</b>
                                        Sagiroglu S, Sinanc D.Big data:A review[C]//Proc of the9th Int Conf on Collaboration Technologies and Systems.Piscataway, NJ:IEEE, 2013:42-47
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_11" title="Xia Feng, Wang Wei, Bekele T M, et al.Big scholarly data:A survey[J].IEEE Transactions on Big Data, 2017, 3 (1) :18-35" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Big Scholarly Data:A Survey">
                                        <b>[11]</b>
                                        Xia Feng, Wang Wei, Bekele T M, et al.Big scholarly data:A survey[J].IEEE Transactions on Big Data, 2017, 3 (1) :18-35
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_12" title="Williams K, Wu Jian, Choudhury S R, et al.Scholarly big data information extraction and integration in the CiteSeerXdigital library[C]//Proc of the 33rd Int Conf on Data Engineering Workshops.Piscataway, NJ:IEEE, 2017:68-73" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scholarly big data information extraction and integration in the CiteSeerXdigital library">
                                        <b>[12]</b>
                                        Williams K, Wu Jian, Choudhury S R, et al.Scholarly big data information extraction and integration in the CiteSeerXdigital library[C]//Proc of the 33rd Int Conf on Data Engineering Workshops.Piscataway, NJ:IEEE, 2017:68-73
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_13" title="Ditterrich T G.Machine learning research:Four current direction[J].Artificial Intelligence Magazine, 1997, 18 (4) :97-136" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Machine learning research: Four current directions">
                                        <b>[13]</b>
                                        Ditterrich T G.Machine learning research:Four current direction[J].Artificial Intelligence Magazine, 1997, 18 (4) :97-136
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_14" title="Freund Y, Schapire R E.A decision-theoretic generalization of on-line learning and an application to boosting[J].Journal of Computer and System Sciences, 1997, 55 (1) :119-139" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601258112&amp;v=MDAxMTZaZVp1SHlqbVVMcklJMW9jYmhjPU5pZk9mYks3SHRETnFZOUVadTRIRFgwN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Freund Y, Schapire R E.A decision-theoretic generalization of on-line learning and an application to boosting[J].Journal of Computer and System Sciences, 1997, 55 (1) :119-139
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_15" title="Breiman L.Bagging predictors[J].Machine Learning, 1996, 24 (2) :123-140" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MzE4NTZidWR0RkMzbFVMdkFKRnM9Tmo3QmFyTzRIdEhOckl4TVlPTU5ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3Fl&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Breiman L.Bagging predictors[J].Machine Learning, 1996, 24 (2) :123-140
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_16" title="Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDExNjl1d09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDM2xVTHZBSkZzPU5qN0Jhck80SHRITnJJdEZa&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32
                                    </a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_17" title="Qian Suchi, Peng Furong, Li Xiang, et al.The hierarchical model to Ali mobile recommendation competition[C]//Proc of the 15th Int Conf on Data Mining Workshop.Piscataway, NJ:IEEE, 2015:1070-1077" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The hierarchical model to Ali mobile recommendation competition">
                                        <b>[17]</b>
                                        Qian Suchi, Peng Furong, Li Xiang, et al.The hierarchical model to Ali mobile recommendation competition[C]//Proc of the 15th Int Conf on Data Mining Workshop.Piscataway, NJ:IEEE, 2015:1070-1077
                                    </a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_18" title="Hu Kaixian, Liang Ying, Xu Hongbo, et al.Amethod for social network user identify feature recognition[J].Journal of Computer Research and Development, 2016, 53 (11) :2630-2644 (in Chinese) (胡开先, 梁英, 许洪波, 等.一种社会网络用户身份特征识别方法[J].计算机研究与发展, 2016, 53 (11) :2630-2644) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201611020&amp;v=MDQzODZHNEg5Zk5ybzlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnl2aFc3dk5MeXZTZEw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Hu Kaixian, Liang Ying, Xu Hongbo, et al.Amethod for social network user identify feature recognition[J].Journal of Computer Research and Development, 2016, 53 (11) :2630-2644 (in Chinese) (胡开先, 梁英, 许洪波, 等.一种社会网络用户身份特征识别方法[J].计算机研究与发展, 2016, 53 (11) :2630-2644) 
                                    </a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_19" title="Tang Jie, Zhang Jing, Yao Limin, et al.ArnetMiner:Extraction and mining of academic social networks[C]//Proc of the 12th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2008:990-998" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ArnetMiner:Extraction and Mining of Academic Social Networks">
                                        <b>[19]</b>
                                        Tang Jie, Zhang Jing, Yao Limin, et al.ArnetMiner:Extraction and mining of academic social networks[C]//Proc of the 12th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2008:990-998
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_20" title="Deerwester S.Indexing by latent semantic analysis[J].Journal of the Association for Information Science&amp;amp;Technology, 2010, 41 (6) :391-407" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Indexing by latent semantic analysis">
                                        <b>[20]</b>
                                        Deerwester S.Indexing by latent semantic analysis[J].Journal of the Association for Information Science&amp;amp;Technology, 2010, 41 (6) :391-407
                                    </a>
                                </li>
                                <li id="311">


                                    <a id="bibliography_21" title="Sonnenwald D H.Scientific collaboration[J].Annual Review of Information Science and Technology, 2007, 41 (1) :643-681" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scientific collaboration">
                                        <b>[21]</b>
                                        Sonnenwald D H.Scientific collaboration[J].Annual Review of Information Science and Technology, 2007, 41 (1) :643-681
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-04-03 16:57</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(07),1383-1395 DOI:10.7544/issn1000-1239.2019.20180641            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于集成学习的科研合作者潜力预测分类方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">艾科</a>
                                <a href="javascript:;">马国帅</a>
                                <a href="javascript:;">杨凯凯</a>
                                <a href="javascript:;">钱宇华</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E8%A5%BF%E5%A4%A7%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E4%B8%8E%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=0176514&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山西大学大数据科学与产业研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E4%B8%8E%E4%B8%AD%E6%96%87%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%B1%B1%E8%A5%BF%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算智能与中文信息处理教育部重点实验室(山西大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E8%A5%BF%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山西大学计算机与信息技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>科研合作是学术成果非常重要的实现形式, 很多高水平的研究成果通过合作实现.研究合作潜力可以为学者选择合作者提供指导, 最大化科研效率.然而当前大数据爆发阻碍了合作者的有效选择.为了解决这个问题, 基于学者-文章大数据, 经过特征分析和优化, 综合考虑学者的文章、机构、研究兴趣等个人属性和相关属性, 分别从文章标题、文章等级、文章数量、时间及署名序多维度构造样本特征, 以文章所发表的期刊会议等级作为合作者序列对的样本标签, 表示当前合作者的潜力高低, 利用集成方法的强学习特性, 提出了基于集成学习分类方法的科研合作者潜力预测模型.分析并构造对应于科研合作者潜力预测问题的特征集后, 采用分类方法解决这一问题.实验中准确率、召回率、F1分数都远高于传统机器学习方法, 并能以较少的样本和时间收敛于较高值 (80%以上) , 说明了模型的优越性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A7%91%E7%A0%94%E5%90%88%E4%BD%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">科研合作;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BD%9C%E5%8A%9B%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潜力预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征构造;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%A6%E6%9C%AF%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">学术大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    Ai Ke, born in 1992.Master.His main research interests include data mining and complex networks. aike0229@163.com;
                                </span>
                                <span>
                                    Ma Guoshuai, born in 1992.PhD.His main research interests include data mining and link prediction.;
                                </span>
                                <span>
                                    Yang Kaikai, born in 1993.Master.Her main research interests include data mining and complex networks.;
                                </span>
                                <span>
                                    *Qian Yuhua, born in 1976.Professor and PhD supervisor.Member of CCF.His main research interests include granular computing, social computing and machine learning. jinchengqyh@sxu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61672332, 61432011, U1435212);</span>
                                <span>山西省海外归国人员研究项目 (2017023);</span>
                    </p>
            </div>
                    <h1><b>A Classification Method of Scientific Collaborator Potential Prediction Based on Ensemble Learning</b></h1>
                    <h2>
                    <span>Ai Ke</span>
                    <span>Ma Guoshuai</span>
                    <span>Yang Kaikai</span>
                    <span>Qian Yuhua</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Scientific cooperation is a very important form of academic achievement. Many high-level researches are achieved through cooperation. Researching the collaboration potential can provide guidance for scholars to choose collaborators and maximize the efficiency of scientific research. However, the current outbursts of big data have hindered the effective choice of collaborators. In order to solve the problem, based on scholar-paper big data, after features analysis and optimization and comprehensively considering individual attributes and related attributes of scholars' papers, institutions, research interests, etc., sample features from various dimensions such as paper title, paper rank, paper number, time and coauthor order are constructed. Taking journal or conference level of papers as the sample tags of collaborators sequence pairs, which indicates the potential of current cooperators and make use of the strong learning characteristics of the ensemble methods, a scientific collaborator potential prediction model based on ensemble learning classification method is proposed. After analyzing and constructing the feature set that corresponds to the problem of scientific collaborator potential prediction, classification method is adopted to solve the problem. In experiments, the accuracy, recall rate, and F1 score are much higher than those of traditional machine learning methods and can converge to high values (above 80%) with few samples and little time, indicating the superiority of the proposed model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=scientific%20cooperation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">scientific cooperation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=potential%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">potential prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20construction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature construction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=big%20scholar%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">big scholar data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ensemble%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ensemble learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61672332, 61432011, U1435212);</span>
                                <span>the Overseas Returnee Research Project of Shanxi Scholarship Council of China (2017023);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="49">科学学<citation id="313" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation> (science of science) 旨在发掘学科的发展动力, 构造模型反映学科演化过程, 进而推动科学事业发展, 科研合作就是其研究内容之一.合作和产出之间有强相关性<citation id="314" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 越来越多的高水平研究成果通过合作实现, 这正凸显了合作者选择的重要性.优秀的合作关系能够充分发挥各合作者的潜力, 最大化科研效益.通过科研合作模式指导, 预先甄别合作者的潜力有助于学者平衡投入与产出, 选择潜在收益最大的合作者, 最大化科研效率.</p>
                </div>
                <div class="p1">
                    <p id="50">合作关系所形成的合作数据反映了学者间的相互关系, 是科研网络和学者行为的重要研究对象.基于合作数据的科研合作模式研究是当前的热点内容.科研合作模式对于研究学者行为有着非常重要的意义.以科研合作模式为载体的合作者推荐问题研究, 多基于复杂网络理论<citation id="315" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>;以点和边的拓扑分析为基础, 把合作者推荐问题作为链路预测问题<citation id="316" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>处理, 如基于随机游走的最有价值合作者MVCWalker (most valuable collaborator) <citation id="317" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>方法预测二者之间产生合作的可能性;Tang等人<citation id="318" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>则致力于解决交叉学科的合作者推荐和预测问题;一些其他方法也得到了较好的效果, 如把共同参加同一会议作为影响合作产生的因素<citation id="319" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 以统计概率的形式描述新合作的产生;以及通过量化学者间的局部相关性和全局相似性<citation id="320" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>进行合作者推荐;模式识别方面, Xia等人<citation id="321" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用高维度多角度的学术大数据, 结合数据特征构造Shifu模型, 对导师-学生关系进行挖掘.</p>
                </div>
                <div class="p1">
                    <p id="51">然而以上的工作多以合作产生的可能性为研究目的, 并没有对合作的结果给出预判性指导.为了达到最好的合作效果, 需要对学者的合作潜力进行研究.但是仅仅依靠传统的拓扑关系已经无法满足问题需求, 需要质量更高、信息量更大的数据来支撑.然而学术大数据 (big scholar data, BSD) <citation id="322" type="reference"><link href="289" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>的“爆发”性质<citation id="323" type="reference"><link href="291" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>使得合作者潜力预测问题成为挑战.首先, 数据量巨大使模式挖掘更加困难;其次, 数据形式多样, 不局限于现有方法中使用的结构化数据, 学术大数据包含许多异构信息, 如作者、文章、机构、期刊会议等, 以及合作者合著关系等复杂网络关系<citation id="324" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>;同时, 数据具有动态性, 学者个人、文章的影响力以及学者之间的合作强度都是与时间相关的, 时间不同效果也不同.来自问题和数据的多重挑战迫切需要提出更有效的解决方法.</p>
                </div>
                <div class="p1">
                    <p id="52">集成学习算法<citation id="325" type="reference"><link href="295" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>是机器学习的一种新学习思想, 该学习算法把同一个问题分解到多个不同模块中, 由多个学习器参与学习, 共同解决目标问题, 最终通过平均或投票选用分类器, 从而提高分类器泛化能力.根据个体学习器的生成方式, 目前的集成学习方法大致可分为两大类, 即个体学习器间存在强依赖关系、必须串行生成的序列化方法 (以Boosting<citation id="326" type="reference"><link href="297" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>为代表) , 以及个体学习器间不存在强依赖关系、可同时生成的并行化方法 (Bagging<citation id="327" type="reference"><link href="299" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和随机森林<citation id="328" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation> (random forest, RF) 为代表) .</p>
                </div>
                <div class="p1">
                    <p id="53">因此, 本文把集成学习分类方法应用于真实学者-文章大数据, 构造面向合作者潜力预测问题的样本集.样本特征综合考虑学者的个人属性以及合作者之间的相关性, 分别从文章标题、文章等级、文章数量、时间、署名序等多维度进行特征构造<citation id="329" type="reference"><link href="303" rel="bibliography" /><link href="305" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>, 进而提出了基于集成学习分类方法的科研合作者潜力预测模型.该模型旨在通过学者的属性集, 对当前合作者的潜力进行预测.</p>
                </div>
                <div class="p1">
                    <p id="54">本文的主要贡献有2个方面:</p>
                </div>
                <div class="p1">
                    <p id="55">1) 构造了面向合作者潜力预测模型的样本集.将学术大数据中的文章、作者与文章等级进行对应, 处理成含等级的文章和含等级的作者数据作为基准数据集.同时定义了一系列学术背景下的学者个人特征描述以及学者间相关性特征描述.</p>
                </div>
                <div class="p1">
                    <p id="56">2) 提出合作者潜力预测的挖掘模型.将分类方法应用于以上特征集来解决合作者的潜力预测问题且实验效果显著.</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>1 合作者潜力预测模型设计思路</b></h3>
                <div class="p1">
                    <p id="58">本文提出的合作者潜力预测模型基于假设:合作者潜力通过合作成果的等级高低表现, 而成果等级高低与合作者各自的单一属性和合作者之间的相关属性密切相关——作为个体每个学者都有一系列学术属性和社会属性, 一定存在某种潜在模式使合作者的属性合集达到特定的形式时会产出特定等级的合作成果, 这正是模型构建的出发点.本文通过对真实学术大数据进行分析并构建样本, 利用集成学习算法在样本集挖掘合作者潜力预测模型.模型整体流程如图1所示:</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 科研合作网络" src="Detail/GetImg?filename=images/JFYZ201907003_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 科研合作网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Scientific coauthor network</p>

                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型流程图" src="Detail/GetImg?filename=images/JFYZ201907003_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow chart of the model</p>

                </div>
                <div class="p1">
                    <p id="62">① 以ArnetMiner<citation id="330" type="reference"><link href="307" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提供的学术社会网络数据集为数据源提取特征, 其中包括学者数据集和文章数据集.</p>
                </div>
                <div class="p1">
                    <p id="63">② 以《中国计算机学会推荐国际学术会议和期刊目录》 (简称《CCF推荐目录》) 中的类别A, B, C (其中A代表高水平的期刊和会议) 作为评价合作成果等级的标签.</p>
                </div>
                <div class="p1">
                    <p id="64">③ 以作者为唯一标识符构建作者数据集, 以文章为唯一标识符结合《CCF推荐目录》构建包含等级的文章数据集.</p>
                </div>
                <div class="p1">
                    <p id="65">④ 基于格式化的作者和文章数据集抽取和构建作者包含等级的作者特征集.考虑文章标题、等级、发表年份、作者列表属性, 从时间、数量、文本相似性等角度综合度量不同特征对结果产生的偏差.</p>
                </div>
                <div class="p1">
                    <p id="66">作者属性如题目、研究兴趣等都是文本形式, 为了分析这些文本特征之间的关系, 本文利用了自然语言处理中的潜在语义索引 (latent semantic indexing, LSI) 模型<citation id="331" type="reference"><link href="309" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.LSI基于奇异值分解 (singular value decomposition, SVD) 的方法得到文本主题, 通过1次SVD过程得到文档和主题的相关度、词和词义的相关度以及词义和主题的相关度索引.</p>
                </div>
                <div class="p1">
                    <p id="67">⑤ 科研合作是由合著关系表示的一种强社会关系.不同模式的合作关系隐藏在广泛的科研合作关系中.在共著关系基础上可以构建1个科研合作网络<citation id="332" type="reference"><link href="311" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 如图2所示.在科研合作网络中, 2位学者如果共同撰写文章就会被认为是相互联系的.基于科研合作网络的结构和社会规律对合作模式挖掘非常重要.</p>
                </div>
                <div class="p1">
                    <p id="68">类似于网络图中对边的定义和研究, 模型构建中只考虑合作成果作为1条边的情况, 即只考虑2个人而非多个人之间产生合作的模型构建.</p>
                </div>
                <div class="p1">
                    <p id="69">⑥ 构造基于当前合作双方的基准特征集, 包含作者各自的特征以及二者之间相关性的特征.若合作样本 (文章) 的等级为A, 则样本标签记为“1”, 否则为“0”, 进而将特征和样本整合为样本集.</p>
                </div>
                <div class="p1">
                    <p id="70">⑦ 分别采用Boosting, Bagging, RF这3种基分类器对以上样本集进行集成学习.分别改变训练集比例以及基分类器个数以测试所构造样本集在当前研究中的有效性.</p>
                </div>
                <div class="p1">
                    <p id="71">⑧ 得到学术大数据下的科研合作者潜力预测模型.</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag"><b>2 合作者潜力预测模型构建过程</b></h3>
                <div class="p1">
                    <p id="73">本文构建合作者潜力预测模型的过程主要包含2部分:1) 基于科研合作大数据的分析, 提取可用特征;2) 基于学者基本数据构造特征样本, 采用集成学习算法构建模型, 完成合作者潜力预测的任务.</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>2.1 特征分析</b></h4>
                <div class="p1">
                    <p id="75">考虑与合作者潜力相关的因素, 以统计图表形式分别对4个特征进行分析:1) 文章标题;2) 不同等级中的文章数量;3) 文章发表年份;4) 署名序.</p>
                </div>
                <div class="p1">
                    <p id="76">首先, 图3以发表篇数为横坐标、发表该篇数的人数为纵坐标初步刻画了数据内容, 这里以S表示所有文章, 即不考虑文章分级进行数量统计.图3中不论级别都基本服从长尾的幂率分布, 这一表现与直观认知一致, 少量学者占据了多数发文量, 这个不平衡数据问题需要充分利用数据构建特征以反映内在模式.</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 发表篇数与对应人数" src="Detail/GetImg?filename=images/JFYZ201907003_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 发表篇数与对应人数  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Publication number and corresponding  authors number</p>

                </div>
                <div class="p1">
                    <p id="78">将图3中发表篇数与对应人数分别取对数得到图4.</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 发表篇数与对应人数取对数" src="Detail/GetImg?filename=images/JFYZ201907003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 发表篇数与对应人数取对数  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Logarithms for publication number and  corresponding authors number</p>

                </div>
                <div class="p1">
                    <p id="80">1) 文章标题.利用文本数据挖掘方法提取各级别所有文章标题中的高频词根.以2000—2010年为例, 图5表示每年前3位高频词根随时间变化情况.某些年份词频较为接近, 会出现一定程度重叠.图5中点的纵坐标与轴对应, 表示数值大小, 而点右侧词的高低不具有坐标意义, 只与相对高低的点对应表示此点的词根.图5中不论A, B, C类每年高频词根数量持续增长, 数量变化趋势基本一致, 内容虽大致相同但有少量变化, 说明文章标题是一个较为敏感的因素.因此作者文章标题可以作为合作者潜力预测的基本特征.</p>
                </div>
                <div class="p1">
                    <p id="81">2) 不同等级中的文章数量.图6展示了各等级中, 以学者发表文章数量为排序依据, 各学者发表不同级别文章数量的分布情况, 为了便于表示这里选取排名前50位作图.如图6 (a) 表示以各学者发表A类文章数量为排序依据, 前50位发表A, B, C类文章的分布情况.由图6可得, 不同排序标准下的排序分布不同, 不计级别意义下 (图6 (d) ) 的文章数量并不能准确反映作者在各个等级下单独的能力, 每个作者在不同等级中都有一定的能力体现, 因此文章等级及文章数量可以作为合作者潜力预测的基本特征.</p>
                </div>
                <div class="p1">
                    <p id="82">3) 文章发表年份.分别取不同等级中累积发表该类文章数量前3位的学者, 分析他们发表文章数量的等级分布随时间变化, 如图7所示.虽然各等级中学者发表文章以该类为主, 但仍有其他类的文章发表.学者科研生涯发表文章数量和等级不断变化, 考虑年份特征更能反映学者在当下的科研潜力, 因此文章的发表年份可以作为合作者潜力预测的基本特征.</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 文章题目前3词汇时间分布" src="Detail/GetImg?filename=images/JFYZ201907003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 文章题目前3词汇时间分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Top 3 words in titles by year</p>

                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 各等级前50位发文等级分布" src="Detail/GetImg?filename=images/JFYZ201907003_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 各等级前50位发文等级分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Level distribution of top 50 authors in each level</p>

                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 各等级前3位发文等级年份分布" src="Detail/GetImg?filename=images/JFYZ201907003_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 各等级前3位发文等级年份分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Level distribution by year of top 3 authors in each level</p>

                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_08601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 各等级前3位发文等级年份分布" src="Detail/GetImg?filename=images/JFYZ201907003_08601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 各等级前3位发文等级年份分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_08601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Level distribution by year of top 3 authors in each level</p>

                </div>
                <div class="p1">
                    <p id="87">4) 署名序.每篇文章的作者常以合作者列表的形式呈现, 每位作者对文章的贡献程度是不一样的, 最直观的就是通过学者在作者列表中的位置来反映.例如1篇A类文章的第1作者和第2作者比第2作者之后的作者对文章的贡献更大, 即前2位作者较之后的作者有更多A类潜力.因此署名序可以作为合作者潜力预测的基本特征.</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>2.2 样本特征构造</b></h4>
                <div class="p1">
                    <p id="89">经2.1节对学术大数据的分析, 提取可用特征:文章标题、文章等级、文章数量、文章发表年份以及署名序.</p>
                </div>
                <div class="p1">
                    <p id="90">基于以上基本特征因素进行规范和优化.首先年份特征作为时间因素可以衍生出相关特征:文章发表时间为<i>t</i>, 发表第1篇文章距今的时间间隔定义为其学术年龄<i>AA</i> (academic age) <citation id="333" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>;第1篇文章的发表时间为<i>t</i><sub>0</sub>;最近1篇文章的发表时间<i>t</i><sub>l</sub>.对于署名序, 由于1篇文章的作者列表可能包含多人, 进行特征组合会产生大量冗余特征, 因此这里只用署名第2作者之内的<i>O</i><sub>0</sub> (包括第2作者) 的和第2作者之外的<i>O</i><sub>1</sub>加以区分.而文章级别分为A, B, C这3类, 文章数目计数器记为<i>N</i>, 则优化后的基本特征如图8所示:</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 优化后的基本特征" src="Detail/GetImg?filename=images/JFYZ201907003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 优化后的基本特征  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Basic features after optimizing</p>

                </div>
                <div class="p1">
                    <p id="92">基本特征从简单维度反映了合作者的潜力表现, 是预测模型最直接的量化和外在形式.但是仅依据直观意义下的单一统计量不足以适应多样化的合作模式, 难以挖掘合作者潜力.因此, 对于数字类数据和文本类数据, 本文分别采用了不同的特征构造策略:1) 以特征工程处理数字类数据, 对基本特征进行1次组合及2次组合, 得到较小粒度的可用特征;2) 文本类数据特征利用语义信息计算语义相似度构造特征.</p>
                </div>
                <div class="p1">
                    <p id="93">1) 数字类数据特征构造.以基本特征为基元扩展特征维度.首先对基本特征进行1次组合如表1所示, 得到特征:<i>NL</i>特征、<i>OL</i>特征、<i>YL</i>特征、<i>NO</i>特征、<i>NY</i>特征、<i>YO</i>特征 (所有特征都基于当前合作时间点<i>t</i><sub>c</sub>得出) .</p>
                </div>
                <div class="p1">
                    <p id="94">① <i>NL</i>特征.不同等级<i>l</i><sub><i>i</i></sub>中文章的数量<i>N</i><sub><i>l</i><sub><i>i</i></sub></sub> (<i>l</i><sub><i>i</i></sub>表示文章等级:<i>l</i><sub>A</sub>表示A级别、<i>l</i><sub>B</sub>表示B级别、<i>l</i><sub>C</sub>表示C级别) :</p>
                </div>
                <div class="p1">
                    <p id="95"><i>NL</i>={<i>N</i><sub><i>l</i><sub><i>i</i></sub></sub>|<i>l</i><sub><i>i</i></sub>∈{<i>l</i><sub>A</sub>, <i>l</i><sub>B</sub>, <i>l</i><sub>C</sub>}}. (1) </p>
                </div>
                <div class="p1">
                    <p id="96">② <i>OL</i>特征.不同等级<i>l</i><sub><i>i</i></sub>中文章的署名序<i>O</i><sub><i>l</i><sub><i>i</i></sub></sub>:</p>
                </div>
                <div class="p1">
                    <p id="97"><i>OL</i>={<i>O</i><sub><i>l</i><sub><i>i</i></sub></sub>|<i>l</i><sub><i>i</i></sub>∈{<i>l</i><sub>A</sub>, <i>l</i><sub>B</sub>, <i>l</i><sub>C</sub>}}. (2) </p>
                </div>
                <div class="p1">
                    <p id="98">③ <i>YL</i>特征.不同时序位置<i>t</i><sub><i>i</i></sub>和不同等级<i>l</i><sub><i>i</i></sub>的文章发表时间<i>year</i><sub><i>t</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>或学术年龄<i>AA</i><sub><i>t</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub> (<i>t</i><sub><i>i</i></sub>表示文章的时序位置:<i>t</i><sub>0</sub>表示当前学者生涯第1篇, <i>t</i><sub>l</sub>表示当前学者最近1篇) :</p>
                </div>
                <div class="p1">
                    <p id="99"><i>YL</i>={ (<i>year</i>, <i>AA</i>) <sub><i>t</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>|<i>t</i><sub><i>i</i></sub>∈{<i>t</i><sub>0, </sub><i>t</i><sub>l</sub>}, <i>l</i><sub><i>i</i></sub>∈{<i>l</i><sub>A</sub>, <i>l</i><sub>B</sub>, <i>l</i><sub>C</sub>}}. (3) </p>
                </div>
                <div class="p1">
                    <p id="101">④ <i>NO</i>特征.不同署名序<i>o</i><sub><i>i</i></sub>时的文章数<i>N</i><sub><i>O</i><sub><i>i</i></sub></sub> (<i>o</i><sub><i>i</i></sub>表示署名序:当作者在文章中署名前2位作者时<i>o</i><sub><i>i</i></sub>=1, 否则<i>o</i><sub><i>i</i></sub>=0) :</p>
                </div>
                <div class="p1">
                    <p id="102"><i>NO</i>={<i>N</i><sub><i>O</i><sub><i>i</i></sub></sub>|<i>o</i><sub><i>i</i></sub>∈{0, 1}}. (4) </p>
                </div>
                <div class="p1">
                    <p id="103">⑤ <i>NY</i>特征.不同时间区间<i>T</i><sub><i>i</i></sub>中的文章数量<i>N</i><sub><i>T</i><sub><i>i</i></sub></sub> (<i>T</i><sub><i>i</i></sub>表示文章时间区间的时序位置:[<i>t</i><sub>0</sub>, <i>t</i><sub>0</sub>+Δ<i>T</i>) 表示学者学术生涯中第1个时间区间、[<i>t</i><sub>l</sub>-Δ<i>T</i>, <i>t</i><sub>l</sub>) 表示最近1个时间区间, 其中Δ<i>T</i>表示时间区间长度, 如Δ<i>T</i>=5, 则统计学术生涯前5年和最近5年中的文章数量) :</p>
                </div>
                <div class="p1">
                    <p id="104"><i>NY</i>={<i>N</i><sub><i>T</i><sub><i>i</i></sub></sub>|<i>T</i><sub><i>i</i></sub>∈{[<i>t</i><sub>0</sub>, <i>t</i><sub>0</sub>+Δ<i>T</i>) , [<i>t</i><sub>l</sub>-Δ<i>T</i>, <i>t</i><sub>l</sub>) }}. (5) </p>
                </div>
                <div class="p1">
                    <p id="106">⑥ <i>YO</i>特征.不同时序位置<i>t</i><sub><i>i</i></sub>和不同署名序<i>o</i><sub><i>i</i></sub>的文章发表时间<i>year</i><sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub></sub>或学术年龄<i>AA</i><sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub></sub>:</p>
                </div>
                <div class="p1">
                    <p id="107"><i>YO</i>={ (<i>year</i>, <i>AA</i>) <sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub></sub>|<i>t</i><sub><i>i</i></sub>∈{<i>t</i><sub>0</sub>, <i>t</i><sub>l</sub>}, <i>o</i><sub><i>i</i></sub>∈{0, 1}}. (6) </p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表1 文章基本特征组合</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Combining Basic Features of Papers</b></p>
                    <p class="img_note"></p>
                    <table id="109" border="1"><tr><td rowspan="2"><br />Basic<br />Features</td><td colspan="4"><br />Basic Features</td></tr><tr><td><br /><i>L</i></td><td><i>N</i></td><td><i>O</i></td><td><i>Y</i></td></tr><tr><td><br /><i>L</i></td><td></td><td><i>NL</i></td><td><i>OL</i></td><td><i>YL</i></td></tr><tr><td><br /><i>N</i></td><td><i>NL</i></td><td></td><td><i>NO</i></td><td><i>NY</i></td></tr><tr><td><br /><i>O</i></td><td><i>OL</i></td><td><i>NO</i></td><td></td><td><i>YO</i></td></tr><tr><td><br /><i>Y</i></td><td><i>YL</i></td><td><i>NY</i></td><td><i>YO</i></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="110">细化特征粒度, 排除意义重复特征, 对以上特征二次组合得到<i>YL</i>&amp;<i>O</i>特征和<i>NO</i>&amp;<i>YL</i>特征.</p>
                </div>
                <div class="p1">
                    <p id="111">⑦ <i>YL</i>&amp;<i>O</i>特征.不同时序位置<i>t</i><sub><i>i</i></sub>、不同署名序<i>o</i><sub><i>i</i></sub>、不同等级<i>l</i><sub><i>i</i></sub>的文章发表年份<i>year</i><sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>或学术年龄<i>AA</i><sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>:</p>
                </div>
                <div class="p1">
                    <p id="112"><i>YL</i>&amp;<i>O</i>={ (<i>year</i>, <i>AA</i>) <sub><i>t</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>|<i>t</i><sub><i>i</i></sub>∈{<i>t</i><sub>0, </sub><i>t</i><sub>l</sub>}, <i>o</i><sub><i>i</i></sub>∈{0, 1}, <i>l</i><sub><i>i</i></sub>∈{<i>l</i><sub>A</sub>, <i>l</i><sub>B</sub>, <i>l</i><sub>C</sub>}}. (7) </p>
                </div>
                <div class="p1">
                    <p id="114">⑧ <i>NO</i>&amp;<i>YL</i>特征.不同时间区间<i>T</i><sub><i>i</i></sub>、不同署名序<i>o</i><sub><i>i</i></sub>、不同等级<i>l</i><sub><i>i</i></sub>的文章数量<i>N</i><sub><i>T</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>:</p>
                </div>
                <div class="p1">
                    <p id="115"><i>NO</i>&amp;<i>YL</i>={<i>N</i><sub><i>T</i><sub><i>i</i></sub>, <i>o</i><sub><i>i</i></sub>, <i>l</i><sub><i>i</i></sub></sub>|<i>T</i><sub><i>i</i></sub>∈{[<i>t</i><sub>0</sub>, <i>t</i><sub>0</sub>+Δ<i>T</i>) , </p>
                </div>
                <div class="p1">
                    <p id="116">[<i>t</i><sub>l</sub>-Δ<i>T</i>) }, <i>o</i><sub><i>i</i></sub>∈{0, 1}, <i>l</i><sub><i>i</i></sub>∈{<i>l</i><sub>A</sub>, <i>l</i><sub>B</sub>, <i>l</i><sub>C</sub>}}. (8) </p>
                </div>
                <div class="p1">
                    <p id="117">2) 文本类数据特征构造.文本数据不同于数字类数据.每个文本在形式上由包括标点在内的字符组成, 由词到句, 由句到篇.不论是在文本的自底向上或自顶向下的层次解析中, 形式相同的一段字符串在不同的语境下可得到不同的含义.文本的一致性和多义性决定了其独特的处理方式.因此本文利用潜在语义索引<citation id="334" type="reference"><link href="309" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>方法, 计算基于集成语料库子空间的标题特征值以及标题间相似度.</p>
                </div>
                <div class="p1">
                    <p id="118">首先给出3个定义:</p>
                </div>
                <div class="p1">
                    <p id="119"><b>定义1</b>. 文章标题全集<i>sumTitle</i> (<i>T</i><sup>*</sup>, <i>L</i><sup>*</sup>) .</p>
                </div>
                <div class="p1">
                    <p id="120"><i>sumTitle</i> (<i>T</i><sup>*</sup>, <i>L</i><sup>*</sup>) =∪{<i>title</i><sub><i>p</i><sub><i>i</i></sub></sub>|<i>year</i><sub><i>p</i><sub><i>i</i></sub></sub>∈<i>T</i><sup>*</sup>, <i>l</i><sub><i>p</i><sub><i>i</i></sub></sub>=<i>L</i><sup>*</sup>}, (9) </p>
                </div>
                <div class="p1">
                    <p id="122">其中, <i>T</i><sup>*</sup>表示发表年份区间, <i>L</i><sup>*</sup>表示文章等级 (标题<i>title</i><sub><i>p</i><sub><i>i</i></sub></sub>、年<i>year</i><sub><i>p</i><sub><i>i</i></sub></sub>、级别<i>l</i><sub><i>p</i><sub><i>i</i></sub></sub>对应于同一篇文章<i>p</i><sub><i>i</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="123"><b>定义2</b>. 文本特征值计算函数<i>Cal</i> (<i>x</i>, <i>X</i>) .其中, <i>x</i>为待计算的文本样本, <i>X</i>为对应的计算子空间.</p>
                </div>
                <div class="p1">
                    <p id="124"><b>定义3</b>. 文本相似度运算函数<i>dis</i> (<i>y</i><sub><i>i</i></sub>, <i>y</i><sub><i>j</i></sub>) .其中<i>y</i><sub><i>i</i></sub>, <i>y</i><sub><i>j</i></sub>分别为文本合集.</p>
                </div>
                <div class="p1">
                    <p id="125">基于文本定义可得2个文本特征:</p>
                </div>
                <div class="p1">
                    <p id="126">1) <i>TIT</i>特征.分别以作者<i>au</i>第1篇<i>t</i><sub>0</sub>、最近1篇<i>t</i><sub>l</sub>及到当前时间<i>t</i><sub>c</sub>为止累积发表文章标题合集作为计算样本<i>x</i>, 以样本<i>x</i>中文章在当时年份<i>t</i><sub>p</sub>、当时年份之前1个时间区间[<i>t</i><sub>p</sub>-Δ<i>T</i>, <i>t</i><sub>p</sub>) 及到当时年份为止[0, <i>t</i><sub>p</sub>) 时间段的文章标题全集分别为计算子空间<i>X</i> (计算子空间<i>X</i>中所有文章等级与计算样本<i>x</i>的等级<i>l</i><sub>p</sub>一致) , 将样本和子空间代入特征值函数得出标题特征:</p>
                </div>
                <div class="area_img" id="127">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201907003_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="129">2) <i>SIM</i><sub>title</sub> (<i>au</i><sub><i>i</i></sub>, <i>au</i><sub><i>j</i></sub>) 相似度.合作者<i>au</i><sub><i>i</i></sub>和<i>au</i><sub><i>j</i></sub>到当时年份为止[0, <i>t</i><sub>p</sub>) 在各等级上文章标题全集之间的文本相似度:</p>
                </div>
                <div class="area_img" id="130">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201907003_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>2.3 集成学习方法</b></h4>
                <div class="p1">
                    <p id="133">集成分类器如图9所示, 利用多个基学习器参与学习, 通过投票或平均选择最适应当前任务的分类器, 提高泛化性能.</p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 集成分类器" src="Detail/GetImg?filename=images/JFYZ201907003_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 集成分类器  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Ensemble estimators</p>

                </div>
                <div class="p1">
                    <p id="135">所用集成学习方法简述:</p>
                </div>
                <div class="p1">
                    <p id="136">1) AdaBoost<citation id="335" type="reference"><link href="297" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>.该方法先从初始训练集训练出1个基学习器, 再根据基学习器的表现对训练样本进行调整, 使得先前基学习器的错分样本能够在后续中得到更多的训练, 基于调整后的样本分布进行下一个基学习器的训练.如此重复直到基学习器数量达到预先指定的值, 最终将这些基学习器进行加权结合.</p>
                </div>
                <div class="p1">
                    <p id="137">2) Bagging<citation id="336" type="reference"><link href="299" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.该方法首先经过多次随机有放回采样, 得到多个采样集.使得有的样本多次出现, 有的样本则从未出现.进而个体学习器之间既有差异又能进行有效学习.之后从每个采样集中训练出1个基学习器, 最终将这些基学习器进行结合.</p>
                </div>
                <div class="p1">
                    <p id="138">3) 随机森林<citation id="337" type="reference"><link href="301" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation> (random forest, RF) .在以决策树为基学习器的Bagging集成的基础上, 在训练过程中引入随机属性选择, 不同于传统的决策树在当前的属性全集中选择1个最优属性, 而是从属性集合中随机选择1个属性的子集, 再从子集中选1个最优属性用于划分.</p>
                </div>
                <h3 id="139" name="139" class="anchor-tag"><b>3 实验设计</b></h3>
                <h4 class="anchor-tag" id="140" name="140"><b>3.1 数据描述与实验设置</b></h4>
                <div class="p1">
                    <p id="141">ArnetMiner 数据集上有丰富的文章和作者信息, 包含文章数据2 092 356条、作者数据1 712 433条、文章作者匹配数据5 192 998条.每条文章数据包括ID、题目、作者、年份、所发机构、期刊等;每条作者数据包括ID、姓名、机构、研究兴趣等;文章作者匹配数据通过各自的ID把文章和作者联系起来.ArnetMiner 数据的优势在于给每个作者赋予了唯一的ID, 使重名消歧的问题从数据源头得以解决.《CCF推荐目录》中包含计算机10个领域的600多个各类期刊会议.本文将ArnetMiner 中《CCF推荐目录》的全部数据抽出, 根据《CCF推荐目录》的论文分级从ArnetMiner 中抽取计算机领域整个数据集作为研究对象, 以期刊和会议的等级高低作为文章的级别标签 (其中A类文章100 324篇, B类文章162 634篇, C类文章208 422篇, 总计471 380篇) , 得到计算机领域的全部数据进行实验.</p>
                </div>
                <div class="p1">
                    <p id="142">从以上真实数据中抽取合作边, 根据第2节所述合作者潜力预测模型中的式 (1) ～ (11) 构建样本特征, 结果等级为A类文章样本标签记为“1”, 否则样本标签记为“0”.依流程图1把每个合作边样本构造为&lt;特征, 标签&gt;样本, 得到样本数据集.为了兼顾模型的准确率和运行的时间开销, 本文的实验以当前年份之前10年数据为训练集, 当前年份之后3年数据为测试集进行验证.如当前年份为2010年时, 训练集为2000—2010年的样本, 测试集为2001—2003年的样本.</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>3.2 评价指标</b></h4>
                <div class="p1">
                    <p id="144">本文选用机器学习分类常用的准确率、召回率、F1分数和模型学习时间作为评价模型的指标.假定某类标签的预测集合为<i>PS</i>.根据预测标签和真实标签可以将<i>PS</i>分为表2混淆矩阵中的4组.</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表2 混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Confused Matrix</b></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td rowspan="2"><br />Labels</td><td colspan="2"><br />Labels</td></tr><tr><td><br />Actual is True</td><td>Actual is False</td></tr><tr><td><br />Predicted is True</td><td>True Positive (<i>TP</i>) </td><td>False Positive (<i>FP</i>) </td></tr><tr><td><br />Predicted is False</td><td>False Negative (<i>FN</i>) </td><td>True Negative (<i>TN</i>) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="146"><i>TP</i>:真实标签为正例被正确判定为正例;</p>
                </div>
                <div class="p1">
                    <p id="147"><i>FN</i>:真实标签为正例未被正确判定为正例;</p>
                </div>
                <div class="p1">
                    <p id="148"><i>FP</i>:真实标签为负例的被错误判定为正例;</p>
                </div>
                <div class="p1">
                    <p id="149"><i>TN</i>:真实标签为负例的未被判定为正例.</p>
                </div>
                <div class="p1">
                    <p id="150">由混淆矩阵得到准确率 (precision, <i>P</i>) 、召回率 (recall, <i>R</i>) 、F1分数 (F1-score, <i>F</i>) 计算为</p>
                </div>
                <div class="p1">
                    <p id="151"><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>, (12) </p>
                </div>
                <div class="p1">
                    <p id="153"><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>, (13) </p>
                </div>
                <div class="p1">
                    <p id="155"><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mo>×</mo><mi>R</mi></mrow><mrow><mi>Ρ</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow></math></mathml>. (14) </p>
                </div>
                <h4 class="anchor-tag" id="157" name="157"><b>3.3 实验结果及分析</b></h4>
                <div class="p1">
                    <p id="158">为了验证本文构造模型在合作者潜力预测问题中的适应性, 设置实验对<i>TP</i>, <i>FN</i>, <i>FP</i>, <i>TN</i>四个指标进行测试比较.同时引入决策树 (decision tree, DT) 、<i>K</i>-近邻 (<i>K</i>-nearest neighbor, KNN) 、逻辑回归 (logistic regression, LR) 和支持向量机 (support vector machine, SVM) 多种传统学习算法作为基于集成学习的科研合作者潜力预测模型的对比方法, 进一步验证其有效性.</p>
                </div>
                <div class="p1">
                    <p id="159">图10以10年全部数据中不同百分比的样本作为训练集, 集成学习方法基分类器个数为300时, Adaboost, Bagging, RF, DT, KNN, LR, SVM多种类型的算法在4个指标的实验性能 (其中SVM时间开销巨大, 因此图10 (d) 只展示了除SVM外的6种算法运行时间, 同时DT和LR运行较快, 曲线基本重叠) .结果显示, 集成学习算法虽然时间开销较高, 但是准确率、召回率和F1分数都远高于对照算法.同时, 本文基于集成学习算法的模型在较小的训练集时就已经能取得较好的效果, 即以较少的数据量快速收敛于较高的性能.其中Bagging对模型的适应性最好, 但是运行时间更长.运行时间、性能参数与数据量正相关, 但是使用20%的训练集样本就基本接近性能最优值, 此时的运算时间较低, 因此时间开销并不大.</p>
                </div>
                <div class="p1">
                    <p id="160">图11为以10年中全部数据作为训练集, 增加集成学习中基分类器个数时Adaboost, Bagging, RF这3种算法在4个指标的实验性能.与增加训练集数据时类似, 本文模型在较少的基训练器时基本接近大量基训练器的效果.而运行时间主要取决于集成学习方法自身的复杂度, 基本呈线性分布.</p>
                </div>
                <div class="area_img" id="161">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 训练集增加的实验效果" src="Detail/GetImg?filename=images/JFYZ201907003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 训练集增加的实验效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Experimental results with training dataset increasing</p>

                </div>
                <div class="area_img" id="163">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_16300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 基分类器增加的实验效果" src="Detail/GetImg?filename=images/JFYZ201907003_16300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 基分类器增加的实验效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_16300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Experimental results with estimator number increasing</p>

                </div>
                <div class="area_img" id="163">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_16301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 基分类器增加的实验效果" src="Detail/GetImg?filename=images/JFYZ201907003_16301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 基分类器增加的实验效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_16301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Experimental results with estimator number increasing</p>

                </div>
                <div class="area_img" id="164">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907003_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 训练集和基分类器增加时RF的实验效果" src="Detail/GetImg?filename=images/JFYZ201907003_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 训练集和基分类器增加时RF的实验效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907003_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.12 Experimental results with training dataset and estimators number increasing</p>

                </div>
                <div class="p1">
                    <p id="166">3种集成学习算法的性能表现趋势大致相同, 因此图12以RF为代表, 用三维散点图的形式表示训练集和基分类器同时增加时的实验效果.更直观地说明了增加训练集和基分类器个数对实验性能的影响.</p>
                </div>
                <div class="p1">
                    <p id="167">综合上述实验结果可得:1) 3种经典集成学习方法的准确率、召回率和F1分数都超过了0.8, 较好地完成了合作者的潜力预测问题.Bagging算法最能适应本文所提模型, 准确率、召回率、F1分数分别达到87%, 82%, 82%.RF虽然性能略差, 但是运行时间最快;2) 模型的样本收敛较快, 少量训练集时性能参数基本达到最优;3) 基分类器数量较少时性能参数基本达到最优;4) 以上2点保证了模型较低的时间开销.</p>
                </div>
                <h3 id="168" name="168" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="169">基于文章等级与合作者属性相关这一假设, 本文研究了大数据背景下的合作者潜力预测问题, 从大量合作关系中挖掘不同等级的合作表现, 指导学者进行合作者选择.为了训练和评估模型, 本文从学术大数据中抽取并构造了一系列特征来描述合作者潜力, 把ArnetMiner 的文章和学者信息与《CCF推荐目录》匹配构造包含等级的文章数据集和包含等级的学者数据集作为样本集.同时定义了一系列学术背景下的学者个人特征描述及学者间相关性特征描述, 并将经典集成学习方法应用于所构造的样本.实验结果说明了本文所提模型的实用性和优越性, 从而可以为学者选择有潜力合作者提供参考性意见, 有助于个人科研效率最大化.</p>
                </div>
                <div class="p1">
                    <p id="170">本文未来的工作将继续拓展特征的丰富性来更全面地刻画合作者潜力, 以《CCF推荐目录》中的不同分级为标准, 向多维数据扩展, 如期刊、会议、作者主页, 爬取完整数据, 提升模型性能, 进一步挖掘合作模式.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="342" type="formula" href="images/JFYZ201907003_34200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">艾科</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="343" type="formula" href="images/JFYZ201907003_34300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">马国帅</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="344" type="formula" href="images/JFYZ201907003_34400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杨凯凯</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="345" type="formula" href="images/JFYZ201907003_34500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">钱宇华</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="271">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS8879A5601D3FDCD3567CFE1F33004FFB&amp;v=Mjg5MzZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOMWh4N3kzeEswPU5pZlpmYnV3R2RpOXFvbEZaWjhNZWdoS3V4VVc3RGdPUGdyajJoRTJlYktRTTh6dA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Fortunato S, Bergstrom C T, B9rner K, et al.Science of science[J].Science, 2018, 359 (6379) :185-185
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                Lee S, Bozeman B.The impact of research collaboration on scientific productivity[J].Social Studies of Science, 2005, 35 (5) :673-702
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The structure of scientific collaboration networks">

                                <b>[3]</b>Newman M E.The structure of scientific collaboration networks[J].Proceedings of the National Academy of Sciences of the United States of America, 2001, 98 (2) :404-409
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using LinkSemantics to Recommend Collaborations in Academic Social Networks">

                                <b>[4]</b>Michele A, Moro M, Lopes G R.Using link semantics to recommend collaborations in academic social networks[C]//Proc of the 5th Workshop on Simplifying Complex Networks for Practitioners-Simplex.New York:ACM, 2013:833-840
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MVCWalker:Random Walk-Based Most Valuable Collaborators Recommendation Exploiting Academic Factors">

                                <b>[5]</b>Xia Feng, Chen Zhen, Wang Wei, et al.MVCWalker:Random walk-based most valuable collaborators recommendation exploiting academic factors[J].IEEE Transactions on Emerging Topics in Computing, 2014, 2 (3) :364-375
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cross-domain collaboration recommendation">

                                <b>[6]</b>Tang Jie, Wu Sen, Sun Jimeng, et al.Cross-domain collaboration recommendation[C]//Proc of the 18th ACMSIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2012:1285-1293
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Can academic conferences promote research collaboration">

                                <b>[7]</b>Su Xiaoyan, Wang Wei, Yu Shuo, et al.Can academic conferences promote research collaboration[C]Proc of the16th ACM?IEEE-CS on Joint Conf on Digital Libraries.New York:ACM, 2016:231-232
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaboration recommendation on academic social networks">

                                <b>[8]</b>Lopes G R, Moro M M, Wives L K, et al.Collaboration recommendation on academic social networks[C]//Proc of the 29th Int Conf on Conceptual Modeling.Berlin:Springer, 2010:190-199
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shifu Deep learning based advisor-advisee relationship mining in schol-arly big data">

                                <b>[9]</b>Wang Wei, Liu Jiaying, Xia Feng, et al.Shifu:Deep learning based advisor-advisee relationship mining in scholarly big data[C]//Proc of the 26th Int Conf on World Wide Web Companion.Lyon, France:International World Wide Web Conferences Committee (IW3C2) , 2017:303-310
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Big data:A review">

                                <b>[10]</b>Sagiroglu S, Sinanc D.Big data:A review[C]//Proc of the9th Int Conf on Collaboration Technologies and Systems.Piscataway, NJ:IEEE, 2013:42-47
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Big Scholarly Data:A Survey">

                                <b>[11]</b>Xia Feng, Wang Wei, Bekele T M, et al.Big scholarly data:A survey[J].IEEE Transactions on Big Data, 2017, 3 (1) :18-35
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scholarly big data information extraction and integration in the CiteSeerXdigital library">

                                <b>[12]</b>Williams K, Wu Jian, Choudhury S R, et al.Scholarly big data information extraction and integration in the CiteSeerXdigital library[C]//Proc of the 33rd Int Conf on Data Engineering Workshops.Piscataway, NJ:IEEE, 2017:68-73
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Machine learning research: Four current directions">

                                <b>[13]</b>Ditterrich T G.Machine learning research:Four current direction[J].Artificial Intelligence Magazine, 1997, 18 (4) :97-136
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601258112&amp;v=MDkwMThxUVRNbndaZVp1SHlqbVVMcklJMW9jYmhjPU5pZk9mYks3SHRETnFZOUVadTRIRFgwN29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Freund Y, Schapire R E.A decision-theoretic generalization of on-line learning and an application to boosting[J].Journal of Computer and System Sciences, 1997, 55 (1) :119-139
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MTIwMDRyeG94Y01IN1I3cWVidWR0RkMzbFVMdkFKRnM9Tmo3QmFyTzRIdEhOckl4TVlPTU5ZM2s1ekJkaDRqOTlTWHFS&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Breiman L.Bagging predictors[J].Machine Learning, 1996, 24 (2) :123-140
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDc1MDkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkMzbFVMdkFKRnM9Tmo3QmFyTzRIdEhOckl0Rlp1d09Z&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The hierarchical model to Ali mobile recommendation competition">

                                <b>[17]</b>Qian Suchi, Peng Furong, Li Xiang, et al.The hierarchical model to Ali mobile recommendation competition[C]//Proc of the 15th Int Conf on Data Mining Workshop.Piscataway, NJ:IEEE, 2015:1070-1077
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201611020&amp;v=Mjk5ODhaZVJyRnl2aFc3dk5MeXZTZExHNEg5Zk5ybzlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Hu Kaixian, Liang Ying, Xu Hongbo, et al.Amethod for social network user identify feature recognition[J].Journal of Computer Research and Development, 2016, 53 (11) :2630-2644 (in Chinese) (胡开先, 梁英, 许洪波, 等.一种社会网络用户身份特征识别方法[J].计算机研究与发展, 2016, 53 (11) :2630-2644) 
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ArnetMiner:Extraction and Mining of Academic Social Networks">

                                <b>[19]</b>Tang Jie, Zhang Jing, Yao Limin, et al.ArnetMiner:Extraction and mining of academic social networks[C]//Proc of the 12th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM, 2008:990-998
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Indexing by latent semantic analysis">

                                <b>[20]</b>Deerwester S.Indexing by latent semantic analysis[J].Journal of the Association for Information Science&amp;Technology, 2010, 41 (6) :391-407
                            </a>
                        </p>
                        <p id="311">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scientific collaboration">

                                <b>[21]</b>Sonnenwald D H.Scientific collaboration[J].Annual Review of Information Science and Technology, 2007, 41 (1) :643-681
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201907003" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201907003&amp;v=MDg5NTNJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXZoVzd2Tkx5dlNkTEc0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVISFZ1RFQveTJET3hHdmFFbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

