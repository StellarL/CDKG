

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128647255275000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201905012%26RESULT%3d1%26SIGN%3dJaTXS2rXjjXyGUSM7GimelyWh3k%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905012&amp;v=MzAzNDhaZVJxRmlEaFdyck1MeXZTZExHNEg5ak1xbzlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="&lt;b&gt;2 基于布尔矩阵分解的蛋白质功能预测框架&lt;/b&gt; "><b>2 基于布尔矩阵分解的蛋白质功能预测框架</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="&lt;b&gt;2.1 蛋白质功能预测及相关符号定义&lt;/b&gt;"><b>2.1 蛋白质功能预测及相关符号定义</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;2.2 框架描述&lt;/b&gt;"><b>2.2 框架描述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#110" data-title="&lt;b&gt;3 精确布尔矩阵分解算法&lt;/b&gt; "><b>3 精确布尔矩阵分解算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#112" data-title="&lt;b&gt;3.1 精确布尔矩阵分解算法基础&lt;/b&gt;"><b>3.1 精确布尔矩阵分解算法基础</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;3.2 功能标签关联矩阵&lt;/b&gt;"><b>3.2 功能标签关联矩阵</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;3.3 基于标签簇的布尔矩阵分解算法&lt;/b&gt;"><b>3.3 基于标签簇的布尔矩阵分解算法</b></a></li>
                                                <li><a href="#167" data-title="&lt;b&gt;3.4 Label-Cluster算法的相关推论及证明&lt;/b&gt;"><b>3.4 Label-Cluster算法的相关推论及证明</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="&lt;b&gt;4 蛋白质功能预测实验&lt;/b&gt; "><b>4 蛋白质功能预测实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#199" data-title="&lt;b&gt;4.1 数据集&lt;/b&gt;"><b>4.1 数据集</b></a></li>
                                                <li><a href="#204" data-title="&lt;b&gt;4.2 Label-Cluster实验分析&lt;/b&gt;"><b>4.2 Label-Cluster实验分析</b></a></li>
                                                <li><a href="#230" data-title="&lt;b&gt;4.3 PFP-BMD实验分析&lt;/b&gt;"><b>4.3 PFP-BMD实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#262" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="图1 蛋白质功能注释数据集中标签注释样本频率示意图">图1 蛋白质功能注释数据集中标签注释样本频率示意图</a></li>
                                                <li><a href="#105" data-title="图2 基于布尔矩阵的蛋白质功能预测框架">图2 基于布尔矩阵的蛋白质功能预测框架</a></li>
                                                <li><a href="#135" data-title="图3 标签关联示意图">图3 标签关联示意图</a></li>
                                                <li><a href="#203" data-title="&lt;b&gt;表1 S.C数据集统计&lt;/b&gt;"><b>表1 S.C数据集统计</b></a></li>
                                                <li><a href="#224" data-title="图4 Label-Cluster算法在3个数据集上的降维效果对比">图4 Label-Cluster算法在3个数据集上的降维效果对比</a></li>
                                                <li><a href="#227" data-title="&lt;b&gt;表2 实验环境&lt;/b&gt;"><b>表2 实验环境</b></a></li>
                                                <li><a href="#229" data-title="图5 Remove-Smallest算法和Label-Cluster算法运行时间对比">图5 Remove-Smallest算法和Label-Cluster算法运行时间对比</a></li>
                                                <li><a href="#254" data-title="图 6 PFP-BMD与MLC-BMAD实验结果对比">图 6 PFP-BMD与MLC-BMAD实验结果对比</a></li>
                                                <li><a href="#259" data-title="图7 PFP-BMD与CLUS-HMC/HSC/SC实验结果对比">图7 PFP-BMD与CLUS-HMC/HSC/SC实验结果对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="378">


                                    <a id="bibliography_1" title="Ruepp A, Zollner A, Maier D, et al.The FunCat, a functional annotation scheme for systematic classification of proteins from whole genomes[J].Nucleic Acids Research, 2004, 32 (18) :5539- 5545" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The FunCat, a functional annotation scheme for systematic classification of proteins from whole genomes">
                                        <b>[1]</b>
                                        Ruepp A, Zollner A, Maier D, et al.The FunCat, a functional annotation scheme for systematic classification of proteins from whole genomes[J].Nucleic Acids Research, 2004, 32 (18) :5539- 5545
                                    </a>
                                </li>
                                <li id="380">


                                    <a id="bibliography_2" title="Harris M A, Clark J, Ireland A, et al.The gene ontology (GO) database and informatics resource[J].Nucleic Acids Research, 2004, 32 (Suppl1) :258- 261" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The gene ontology( GO) database and informatics resource">
                                        <b>[2]</b>
                                        Harris M A, Clark J, Ireland A, et al.The gene ontology (GO) database and informatics resource[J].Nucleic Acids Research, 2004, 32 (Suppl1) :258- 261
                                    </a>
                                </li>
                                <li id="382">


                                    <a id="bibliography_3" title="Cao Renzhi, Cheng Jianlin.Integrated protein function prediction by mining function associations, sequences, and protein-protein and gene-gene interaction networks[J].Methods, 2016, 93:84- 91" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1EF9ECC5AF2B4DAC8C7635B03C6818D3&amp;v=MTg5MDlPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Z3pMeTJ4YTg9TmlmT2ZiTE5hTmk1M1B4QUZaME5mbmhOdm1VYm1UaDdTM3FRckJGR2Y3cVZUYzZjQw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Cao Renzhi, Cheng Jianlin.Integrated protein function prediction by mining function associations, sequences, and protein-protein and gene-gene interaction networks[J].Methods, 2016, 93:84- 91
                                    </a>
                                </li>
                                <li id="384">


                                    <a id="bibliography_4" title="Saha S, Chatterjee P, Basu S, et al.Gene ontology based function prediction of human protein using protein sequence and neighborhood property of PPI network[C]//Proc of the 5th Int Conf on Frontiers in Intelligent Computing:Theory and Applications.Berlin:Springer, 2017:109- 118" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gene Ontology Based Function Prediction of Human Protein Using Protein Sequence and Neighborhood Property of PPI Network">
                                        <b>[4]</b>
                                        Saha S, Chatterjee P, Basu S, et al.Gene ontology based function prediction of human protein using protein sequence and neighborhood property of PPI network[C]//Proc of the 5th Int Conf on Frontiers in Intelligent Computing:Theory and Applications.Berlin:Springer, 2017:109- 118
                                    </a>
                                </li>
                                <li id="386">


                                    <a id="bibliography_5" title="Fu Guangyuan, Yu Guoxian, Wang Jun, et al.Protein function prediction using positive and negative examples [J].Journal of Computer Research and Development, 2016, 53 (8) :1753- 1765 (in Chinese) (傅广垣, 余国先, 王峻, 等 .基于正负样例的蛋白质功能预测[J].计算机研究与发展, 2016, 53 (8) :1753- 1765) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201608010&amp;v=MzE4ODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGhXcnJQTHl2U2RMRzRIOWZNcDQ5RVpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Fu Guangyuan, Yu Guoxian, Wang Jun, et al.Protein function prediction using positive and negative examples [J].Journal of Computer Research and Development, 2016, 53 (8) :1753- 1765 (in Chinese) (傅广垣, 余国先, 王峻, 等 .基于正负样例的蛋白质功能预测[J].计算机研究与发展, 2016, 53 (8) :1753- 1765) 
                                    </a>
                                </li>
                                <li id="388">


                                    <a id="bibliography_6" title="Yu Guoxian, Rangwala H, Domeniconi C, et al.Predicting protein function using multiple kernels[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2015, 12 (1) :219- 233" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM3CB89900D62181EC8AB73885E590A446&amp;v=MTQ5MTJiTm5GcG85RkVPME5EWFE0dW1VYm0wMTZTM2ZxcVdjd2NMTGxRYjZaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx5MnhhOD1OaWZJWTdETA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        Yu Guoxian, Rangwala H, Domeniconi C, et al.Predicting protein function using multiple kernels[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2015, 12 (1) :219- 233
                                    </a>
                                </li>
                                <li id="390">


                                    <a id="bibliography_7" title="Mohana P G, Chitra S.Design and development of an efficient hierarchical approach for multi-label protein function prediction[J].Biomedical Research, 2017 (Special Issue) :S370- S379" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Design and development of an efficient hierarchical approach for multi-label protein function prediction">
                                        <b>[7]</b>
                                        Mohana P G, Chitra S.Design and development of an efficient hierarchical approach for multi-label protein function prediction[J].Biomedical Research, 2017 (Special Issue) :S370- S379
                                    </a>
                                </li>
                                <li id="392">


                                    <a id="bibliography_8" title="Vens C, Struyf J, Schietgat L, et al.Decision trees for hierarchical multi-label classification[J].Machine Learning, 2008, 73 (2) :185- 214" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15103100184024&amp;v=MTE0NjJkR2VycVFUTW53WmVadUh5am1VTHZKS0ZvZGJ4VT1OajdCYXJLOUg5SFBybzlGWmVNTERINDlvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Vens C, Struyf J, Schietgat L, et al.Decision trees for hierarchical multi-label classification[J].Machine Learning, 2008, 73 (2) :185- 214
                                    </a>
                                </li>
                                <li id="394">


                                    <a id="bibliography_9" title="Cerri R, Barros R C, de Carvalho, et al.A genetic algorithm for hierarchical multi-Label classification[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:250- 255" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A genetic algorithm for hierarchical multi-Label classification">
                                        <b>[9]</b>
                                        Cerri R, Barros R C, de Carvalho, et al.A genetic algorithm for hierarchical multi-Label classification[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:250- 255
                                    </a>
                                </li>
                                <li id="396">


                                    <a id="bibliography_10" title="Otero F, Freitas A, Johnson C.A hierarchical multi-label classification ant colony algorithm for protein function prediction[J].Memetic Computing, 2010, 2 (3) :165- 181" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hierarchical multi-label classification ant colony algorithm for protein function prediction">
                                        <b>[10]</b>
                                        Otero F, Freitas A, Johnson C.A hierarchical multi-label classification ant colony algorithm for protein function prediction[J].Memetic Computing, 2010, 2 (3) :165- 181
                                    </a>
                                </li>
                                <li id="398">


                                    <a id="bibliography_11" title="Rubin T, Chambers A, Smyth P, et al.Statistical topic models for multi-label document classification[J].Machine Learning, 2012, 88 (1) :157- 208" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120619001574&amp;v=MDI5NTlGWmU0SUNCTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2aFVyZk1LVnNUTmo3QmFySzZIdGZOcG85&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Rubin T, Chambers A, Smyth P, et al.Statistical topic models for multi-label document classification[J].Machine Learning, 2012, 88 (1) :157- 208
                                    </a>
                                </li>
                                <li id="400">


                                    <a id="bibliography_12" title="Mostafavi S, Morris Q.Fast integration of heterogeneous data sources for predicting gene function with limited annotation[J].Bioinformatics, 2010, 26 (14) :1759- 1765" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast integration of heterogeneous data sources for predicting gene function with limited annotation">
                                        <b>[12]</b>
                                        Mostafavi S, Morris Q.Fast integration of heterogeneous data sources for predicting gene function with limited annotation[J].Bioinformatics, 2010, 26 (14) :1759- 1765
                                    </a>
                                </li>
                                <li id="402">


                                    <a id="bibliography_13" title="Xiong Wei, Liu Hiu, Guan Jihong, et al.Protein function prediction by collective classification with explicit and implicit edges in protein-protein interaction networks[J].BMC Bioinformatics, 2013, 14 (Suppl 12) :S4" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Protein function prediction by collective classification with explicit and implicit edges in protein-protein interaction networks">
                                        <b>[13]</b>
                                        Xiong Wei, Liu Hiu, Guan Jihong, et al.Protein function prediction by collective classification with explicit and implicit edges in protein-protein interaction networks[J].BMC Bioinformatics, 2013, 14 (Suppl 12) :S4
                                    </a>
                                </li>
                                <li id="404">


                                    <a id="bibliography_14" title="Chua H, Sung W, Wong L.Exploiting indirect neighbours and topological weight to predict protein function from protein-protein interactions[J].Bioinformatics, 2008, 22 (3) :1623- 1630" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting indirect neighbours and topological weight to predict protein function from protein--protein interactions">
                                        <b>[14]</b>
                                        Chua H, Sung W, Wong L.Exploiting indirect neighbours and topological weight to predict protein function from protein-protein interactions[J].Bioinformatics, 2008, 22 (3) :1623- 1630
                                    </a>
                                </li>
                                <li id="406">


                                    <a id="bibliography_15" title="Hsu D, Kakade S, Langford J, et al.Multi-label prediction via compressed sensing[C] //Proc of Int Conf on Neural Information Processing Systems.New York:Curran Associates Inc, 2009:772- 780" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-label prediction via compressed sensing">
                                        <b>[15]</b>
                                        Hsu D, Kakade S, Langford J, et al.Multi-label prediction via compressed sensing[C] //Proc of Int Conf on Neural Information Processing Systems.New York:Curran Associates Inc, 2009:772- 780
                                    </a>
                                </li>
                                <li id="408">


                                    <a id="bibliography_16" title="Tai F, Lin H.Multi-label classification with principal label space transformation[J].Neural Computation, 2012, 24 (9) :2508- 2542" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500013325&amp;v=MjQ3MjVycVFUTW53WmVadUh5am1VTHZKS0ZvZGJ4VT1OaWZKWmJLOUh0ak1xbzlGWk9vTUQzNDhvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Tai F, Lin H.Multi-label classification with principal label space transformation[J].Neural Computation, 2012, 24 (9) :2508- 2542
                                    </a>
                                </li>
                                <li id="410">


                                    <a id="bibliography_17" title="Zhang Yi, Schneider J.Multi-label output codes using canonical correlation analysis[J].Journal of Machine Learning Research, 2012, 15 (1) :873- 882" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-label output codes using canonical correlation analysis">
                                        <b>[17]</b>
                                        Zhang Yi, Schneider J.Multi-label output codes using canonical correlation analysis[J].Journal of Machine Learning Research, 2012, 15 (1) :873- 882
                                    </a>
                                </li>
                                <li id="412">


                                    <a id="bibliography_18" title="Li Li, Zhang Longkai, Wang Houfeng.Muli-label text categorization with hidden components[C]//Proc of Conf on Empirical Methods in Natural Language Processing.New York:ACM, 2014:1816- 1821" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Muli-label text categorization with hidden components">
                                        <b>[18]</b>
                                        Li Li, Zhang Longkai, Wang Houfeng.Muli-label text categorization with hidden components[C]//Proc of Conf on Empirical Methods in Natural Language Processing.New York:ACM, 2014:1816- 1821
                                    </a>
                                </li>
                                <li id="414">


                                    <a id="bibliography_19" title="Balasubramanian K, Lebanon G.The landmark selection method for multiple output prediction[C] //Proc of the 29th Int Conf on Machine Learning.Madison, Wisconsin:Omnipress, 2012:283- 290" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The landmark selection method for multiple output prediction">
                                        <b>[19]</b>
                                        Balasubramanian K, Lebanon G.The landmark selection method for multiple output prediction[C] //Proc of the 29th Int Conf on Machine Learning.Madison, Wisconsin:Omnipress, 2012:283- 290
                                    </a>
                                </li>
                                <li id="416">


                                    <a id="bibliography_20" title="Bi Wei, Kwok J T.Efficient multi-label classification with many labels[C/OL].//Proc of Int Conf on Machine Learning.2013 [2017-05-20].http://www.jmlr.org/" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient multi-label classification with many labels">
                                        <b>[20]</b>
                                        Bi Wei, Kwok J T.Efficient multi-label classification with many labels[C/OL].//Proc of Int Conf on Machine Learning.2013 [2017-05-20].http://www.jmlr.org/
                                    </a>
                                </li>
                                <li id="418">


                                    <a id="bibliography_21" title="Miettinen P.The Boolean column and column-row matrix decompositions[J].Data Mining and Knowledge Discovery, 2008, 17 (1) :39- 56" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15103100094712&amp;v=MDQxMTQvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGb2RieFU9Tmo3QmFySzlIOUhQcm85RlpPSUxDMzA3b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Miettinen P.The Boolean column and column-row matrix decompositions[J].Data Mining and Knowledge Discovery, 2008, 17 (1) :39- 56
                                    </a>
                                </li>
                                <li id="420">


                                    <a id="bibliography_22" title="Lubiw A.The Boolean basis problem and how to cover some polygons by rectangles[J].SIAM Journal on Discrete Mathematics, 1990, 3 (1) :98- 115" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The boolean basis problem and how to cover some polygons by rectangles">
                                        <b>[22]</b>
                                        Lubiw A.The Boolean basis problem and how to cover some polygons by rectangles[J].SIAM Journal on Discrete Mathematics, 1990, 3 (1) :98- 115
                                    </a>
                                </li>
                                <li id="422">


                                    <a id="bibliography_23" title="Miettinen P.Matrix decomposition methods for data mining:Computational complexity and algorithms[D].Helsinki:University of Helsinki, 2009" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Matrix decomposition methods for data mining:Computational complexity and algorithms">
                                        <b>[23]</b>
                                        Miettinen P.Matrix decomposition methods for data mining:Computational complexity and algorithms[D].Helsinki:University of Helsinki, 2009
                                    </a>
                                </li>
                                <li id="424">


                                    <a id="bibliography_24" title="Belohlavek R, Trnecka M.From-below approximations in Boolean matrix factorization:Geometry and new algorithm[J].Journal of Computer &amp;amp; System Sciences, 2013, 81 (8) :45- 52" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15121200311178&amp;v=MTE3NDd1SHlqbVVMdkpLRm9kYnhVPU5pZk9mYks5SDlQTnJZOUZaK29PRFhzeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Belohlavek R, Trnecka M.From-below approximations in Boolean matrix factorization:Geometry and new algorithm[J].Journal of Computer &amp;amp; System Sciences, 2013, 81 (8) :45- 52
                                    </a>
                                </li>
                                <li id="426">


                                    <a id="bibliography_25" title="Drineas P, Mahoney M W, Muthukrishnan S.Relative-error $CUR$ matrix decompositions[J].SIAM Journal on Matrix Analysis &amp;amp; Applications, 2007, 30 (2) :844- 881" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relative-error cur matrix decompositions">
                                        <b>[25]</b>
                                        Drineas P, Mahoney M W, Muthukrishnan S.Relative-error $CUR$ matrix decompositions[J].SIAM Journal on Matrix Analysis &amp;amp; Applications, 2007, 30 (2) :844- 881
                                    </a>
                                </li>
                                <li id="428">


                                    <a id="bibliography_26" title="Wicker J, Pfahringer B, Kramer S.Multi-label classification using Boolean matrix decomposition[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:179- 186" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-label classification using boolean matrix decomposition">
                                        <b>[26]</b>
                                        Wicker J, Pfahringer B, Kramer S.Multi-label classification using Boolean matrix decomposition[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:179- 186
                                    </a>
                                </li>
                                <li id="430">


                                    <a id="bibliography_27" title="Sun Yuan, Ye Shiwei, Sun Yi, et al.Improved algorithms for exact and approximate Boolean matrix decomposition[C]//Proc of the 2nd IEEE Int Conf on Data Science and Advanced Analytics.Piscataway, NJ:IEEE, 2015:1- 10" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved algorithms for exact and approximate Boolean matrix decomposition">
                                        <b>[27]</b>
                                        Sun Yuan, Ye Shiwei, Sun Yi, et al.Improved algorithms for exact and approximate Boolean matrix decomposition[C]//Proc of the 2nd IEEE Int Conf on Data Science and Advanced Analytics.Piscataway, NJ:IEEE, 2015:1- 10
                                    </a>
                                </li>
                                <li id="432">


                                    <a id="bibliography_28" title="Gregory D A, Pullman N J.Semiring rank:Boolean rank and nonnegative rank factorizations[J].Journal of Combinatorics, Information &amp;amp; System Sciences, 1983, 8 (3) :223- 233" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semiring rank: Boolean rank and nonnegative rank factorizations">
                                        <b>[28]</b>
                                        Gregory D A, Pullman N J.Semiring rank:Boolean rank and nonnegative rank factorizations[J].Journal of Combinatorics, Information &amp;amp; System Sciences, 1983, 8 (3) :223- 233
                                    </a>
                                </li>
                                <li id="434">


                                    <a id="bibliography_29" title="Zhang Minling, Zhou Zhihua.ML-KNN:A lazy learning approach to multi-label learning[J].Pattern Recognition, 2007, 40 (7) :2038- 2048" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739502&amp;v=MjY1NjZud1plWnVIeWptVUx2SktGb2RieFU9TmlmT2ZiSzdIdEROcVk5RlkrZ0dDWHc3b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                        Zhang Minling, Zhou Zhihua.ML-KNN:A lazy learning approach to multi-label learning[J].Pattern Recognition, 2007, 40 (7) :2038- 2048
                                    </a>
                                </li>
                                <li id="436">


                                    <a id="bibliography_30" title="Zheng Wei, Wang Chaokun, Liu Zhang, et al.A multi-label classification algorithm based on random walk model[J].Chinese Journal of Computers, 2010, 33 (8) :1418- 1426 (in Chinese) (郑伟, 王朝坤, 刘璋, 等.一种基于随机游走模型的多标签分类算法[J].计算机学报, 2010, 33 (8) :1418- 1426) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201008012&amp;v=MzA1OTlQTHo3QmRyRzRIOUhNcDQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGhXcnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[30]</b>
                                        Zheng Wei, Wang Chaokun, Liu Zhang, et al.A multi-label classification algorithm based on random walk model[J].Chinese Journal of Computers, 2010, 33 (8) :1418- 1426 (in Chinese) (郑伟, 王朝坤, 刘璋, 等.一种基于随机游走模型的多标签分类算法[J].计算机学报, 2010, 33 (8) :1418- 1426) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(05),1020-1033 DOI:10.7544/issn1000-1239.2019.20180274            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于布尔矩阵分解的蛋白质功能预测框架</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E7%90%B3&amp;code=23252918&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘琳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%94%90%E9%BA%9F&amp;code=38091023&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐麟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%94%90%E6%98%8E%E9%9D%96&amp;code=25519084&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐明靖</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E7%BB%B4&amp;code=24215774&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周维</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0008093&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南师范大学信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B0%91%E6%97%8F%E6%95%99%E8%82%B2%E4%BF%A1%E6%81%AF%E5%8C%96%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E4%BA%91%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6)&amp;code=0233984&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">民族教育信息化教育部重点实验室(云南师范大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E6%A0%A1%E9%95%BF%E5%8A%9E%E5%85%AC%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南师范大学校长办公室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E5%A4%A7%E5%AD%A6%E5%9B%BD%E5%AE%B6%E7%A4%BA%E8%8C%83%E6%80%A7%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南大学国家示范性软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>蛋白质是细胞生命活动中最重要和最多样的一种大分子物质.因此, 研究蛋白质功能对于破解生命密码具有重要的意义.以往的研究表明蛋白质功能预测问题本质上是一个多标签分类问题, 但庞大的功能标签数量使得各种多标签分类器在蛋白质功能预测中的应用面临巨大挑战.针对蛋白质功能标签数量庞大且标签关联性较高的特点, 提出了一种基于布尔矩阵分解的蛋白质功能预测框架 (protein function prediction based on Boolean matrix decomposition, PFP-BMD) .同时, 针对目前布尔矩阵分解算法中精确分解和列利用条件难以同时满足的问题, 提出一种基于标签簇的精确布尔矩阵分解算法, 使其通过标签关联矩阵实现标签的层次扩展聚簇, 并通过相关推论证明了该算法可实现最优的精确布尔矩阵分解.实验结果表明:提出的布尔矩阵分解算法在计算复杂度上具有较大优势, 且应用了该算法的蛋白质功能预测框架可有效提升蛋白质功能预测的准确率, 为各种多标签分类器在蛋白质功能预测中的高效应用奠定了基础.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多标签分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%8A%9F%E8%83%BD%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蛋白质功能预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%87%E7%AD%BE%E7%A9%BA%E9%97%B4%E9%99%8D%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">标签空间降维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%87%E7%AD%BE%E5%85%B3%E8%81%94%E7%9F%A9%E9%98%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">标签关联矩阵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B8%83%E5%B0%94%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">布尔矩阵分解;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *唐麟, maitanweng2@163.com;
                                </span>
                                <span>
                                    刘琳, liulinrachel@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61862067, 61762089);</span>
                                <span>云南师范大学博士启动项目 (2016zb009);</span>
                                <span>云南大学数据驱动的软件工程省科技创新团队项目 (2017HC012);</span>
                    </p>
            </div>
                    <h1><b>The Framework of Protein Function Prediction Based on Boolean Matrix Decomposition</b></h1>
                    <h2>
                    <span>Liu Lin</span>
                    <span>Tang Lin</span>
                    <span>Tang Mingjing</span>
                    <span>Zhou Wei</span>
            </h2>
                    <h2>
                    <span>School of Information, Yunnan Normal University</span>
                    <span>Key Laboratory of Educational Informatization for Nationalities (Yunnan Normal University ) , Ministry of Education</span>
                    <span>President Office, Yunnan Normal University</span>
                    <span>National Pilot School of Software, Yunnan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Protein is the most essential and versatile macromolecule of living cells, and thus the research on protein functions is of great significance in decoding the secret of life. Previous researches have suggested that prediction of protein function is essentially a multi-label classification problem. Nonetheless, the large number of protein functional annotation labels brings the huge challenge to various kinds of multi-label classifiers applied to protein function prediction. To achieve more accuracy prediction of protein function by multi-label classifiers, we consider the characteristics of high correlation between protein functional labels, and propose a framework of protein function prediction based on Boolean matrix decomposition (PFP-BMD) . Meanwhile, considering the problem of hardly satisfying exact decomposition and column in condition simultaneously of current Boolean matrix decomposition algorithms, an exact Boolean matrix decomposition algorithm based on label clusters is proposed, which realizes the hierarchical extended clustering of labels by the label-associated matrix. What's more, we prove its ability of optimal Boolean matrix decomposition based on related deductions. The experimental results show that this exact Boolean matrix decomposition algorithm possesses considerable advantage in reducing the computational complexity in comparison with existing algorithms. In addition, the application of the proposed algorithm in PFP-BMD can effectively improve the accuracy of protein function prediction, and more importantly, reducing and restoring dimensions in the functional label space of proteins using this algorithm lays the foundation of a more efficient classification of various multi-label classifiers.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-label%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-label classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=protein%20function%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">protein function prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=label%20space%20dimension%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">label space dimension reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=label-associated%20matrix&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">label-associated matrix;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Boolean%20matrix%20decomposition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Boolean matrix decomposition;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Liu Lin, born in 1982.PhD, lecturer. Member of CCF. Her main research interests include bioinformatics and machine learning.<image id="308" type="formula" href="images/JFYZ201905012_30800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Tang Lin, born in 1981.PhD, senior engineer. His main research interests include video mining and probabilistic graphical models.<image id="310" type="formula" href="images/JFYZ201905012_31000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Tang Mingjing, born in 1978. PhD candidate, lecturer. His main research interests include software engineering, process mining and machine learning.<image id="312" type="formula" href="images/JFYZ201905012_31200.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhou Wei, born in 1974.PhD, professor. His main research interests include distributed computing, cloud computing and bioinformatics. (zwei@ynu.edu.cn) <image id="314" type="formula" href="images/JFYZ201905012_31400.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-04-09</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61862067, 61762089);</span>
                                <span>the PhD Startup Foundation of Yunnan Normal University (2016zb009);</span>
                                <span>the Yunnan Province Science and Technology Innovation Team Project of Yunnan University Data-Driven Software Engineering (2017HC012);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="67">蛋白质 (protein) 是组成生命体一切细胞、组织的基本有机物, 是生命活动的主要承担者.根据遗传学中心法则, 基因在经过转录和翻译之后才能由蛋白质在各种生命活动中执行其功能.因此, 在大规模水平上对蛋白质的结构及功能进行研究的蛋白质组学对于阐明生命现象的本质和活动规律具有重要的意义, 也是后基因组时代生命科学研究的核心内容之一.当前, 蛋白质组学研究的一个重要内容就是对蛋白质进行功能注释.然而传统基于生物实验的蛋白质功能注释方法费时费力, 无力填补基因组测序技术所获得的大量蛋白质与其功能之间的鸿沟.近年来, 越来越多的生物信息学研究者利用蛋白质序列数据、基因表达数据、系统发生谱等各种类型的生物数据, 针对数据特点建立相应的计算模型以完成蛋白质功能的自动注释.这类基于计算模型的蛋白质功能预测方法可以大大节省蛋白质功能注释的时间和人力消耗, 因此已成为目前蛋白质组学中的一个研究热点.</p>
                </div>
                <div class="p1">
                    <p id="68">从计算模型的角度看, 该领域的研究大致可分为两大类:基于分类的方法和基于网络的方法.1) 基于分类的蛋白质功能预测方法是将蛋白质看作需要分类的实例, 而将注释蛋白质的功能术语看作类别标签, 功能术语可由FunCat (funcat category) <citation id="438" type="reference"><link href="378" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>和基因本体 (gene ontology, GO) <citation id="439" type="reference"><link href="380" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>所定义, 与功能相关的各种生物数据转换为蛋白质的特征, 最后利用各种多标签分类器的训练和测试来完成蛋白质功能标签预测.2) 基于网络的蛋白质功能预测方法是通过网络中节点的距离来衡量蛋白质功能的相似度, 可以基于蛋白质的功能关联性或蛋白质相互作用网络构建出以蛋白质为节点的网络表达<citation id="440" type="reference"><link href="382" rel="bibliography" /><link href="384" rel="bibliography" /><link href="386" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="69">在基于分类的蛋白质功能预测研究中, 很多传统的多标签分类方法如支持向量机 (support vector machine, SVM) 、神经网络和决策树等<citation id="443" type="reference"><link href="388" rel="bibliography" /><link href="390" rel="bibliography" /><link href="392" rel="bibliography" /><link href="394" rel="bibliography" /><link href="396" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>已取得较好的预测效果.但同时, 我们的大量前期研究表明:与普通的分类场景相比, 蛋白质功能预测中功能注释标签数量非常庞大, 如仅在文献<citation id="441" type="reference">[<a class="sup">8</a>]</citation>的D1数据集中就包含了4 133个GO术语.换句话说, 处理蛋白质功能预测数据集的算法所面对的不再是几个或几十个标签, 而是成百上千的大规模标签, 这会直接导致计算模型的训练时间非常长.特别是对于一些传统的多标签分类算法, 根本无法处理大规模标签分类问题, 例如BR (binary relevance) 方法不可用在具有10<sup>4</sup>个标签的多标签分类问题中, 因为这意味着它需要训练10<sup>4</sup>个二值分类器.同时, 已有研究表明:面对这种大量标签的多标签分类数据集, SVMs等判别式模型的分类性能会急剧下降<citation id="442" type="reference"><link href="398" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="70">此外, 由于蛋白质功能标签之间均具有层次结构, 显然被低层功能标签注释的蛋白质数量会比高层功能标签注释的蛋白质数量少很多, 这种标签的标注样本频率极度不平衡的情况会直接导致分类效果不佳.图1展示了对D1数据集<citation id="444" type="reference"><link href="392" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>中功能标签标注频率的统计结果.从图1中可以看出, 大量的功能标签注释了非常少的蛋白质, 仅仅有较少的功能标签注释了超过30个蛋白质.</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 蛋白质功能注释数据集中标签注释样本频率示意图" src="Detail/GetImg?filename=images/JFYZ201905012_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 蛋白质功能注释数据集中标签注释样本频率示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The number statistics of function labels annotated  protein in protein function annotation dataset</p>

                </div>
                <div class="p1">
                    <p id="72">面对蛋白质功能标签数据的这一特点, 目前蛋白质功能预测方法的研究是采取一种只对低维标签空间分类的策略.这些研究通过一定的规则首先从标签集中选择出一个小规模的标签子集, 然后算法仅针对小规模性的标签子集进行训练和预测, 而并不是直接面对高维标签空间进行分类.如Yu等人<citation id="445" type="reference"><link href="388" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>使用文献<citation id="446" type="reference">[<a class="sup">12</a>]</citation>中的标准蛋白质数据集, 这一数据集是通过GO进行生物功能注释, 研究者对其中的酵母数据过滤出注释了至少100个蛋白质且最多300个蛋白质的GO功能标签, 对人类和小鼠数据过滤出注释了至少30个蛋白质且最多100个蛋白质的GO功能标签.最后, 酵母数据中保留的功能标签数量为57个, 人类数据保留了254个功能标签, 小鼠数据保留了239个标签, 继而预测模型只对这些少量的标签进行处理.Xiong等人<citation id="447" type="reference"><link href="402" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>使用有益功能类<citation id="448" type="reference"><link href="404" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>的概念来选择GO标签, 一个有益GO标签是指:1) 至少注释了30个蛋白质;2) 没有任何孩子标签注释至少30个蛋白质.最后, 该研究在酵母数据集中获得了66个有益的GO标签, 并且在小鼠注释数据集中获得了130个有益GO term, 同样预测模型也仅对有益GO标签进行预测.显然, 以上这些方式可以大大减少分类器所面对的标签数量, 但同时预测结果也仅限于小规模的标签子集内.因此, 目前蛋白质功能预测方法的研究其实并没有真正解决大量标签分类问题.</p>
                </div>
                <div class="p1">
                    <p id="73">基于以上考虑, 本文针对蛋白质功能注释标签数量庞大的问题, 提出一种基于布尔矩阵分解的蛋白质功能预测框架 (protein function prediction based on Boolean matrix decomposition, PFP-BMD) , 并特别针对框架中的精确布尔矩阵分解 (Boolean matrix decomposition, BMD) 模块进行具体研究, 提出一种基于标签簇的精确BMD算法Label-Cluster.本文的研究也是首次基于布尔矩阵分解针对蛋白质功能预测问题开展的研究, 可为各种多标签分类器在蛋白质功能预测中的高效应用奠定基础.</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="75">除了在蛋白质功能注释数据中, 在文本和图片分类场景中也会存在标签数量过于庞大的问题.针对这一问题, 一种称为标签空间降维 (label space dimension reduction, LSDR) 的方法被研究者们提出, 其基本思想就是利用矩阵降维技术将标签空间矩阵投影到低维标签空间, 多标签分类器的训练和测试都只对低维标签空间进行.</p>
                </div>
                <div class="p1">
                    <p id="76">Hsu等人<citation id="449" type="reference"><link href="406" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>在2009年利用压缩感知技术首次实现了该类方法.此后研究者们相继利用主成分分析<citation id="450" type="reference"><link href="408" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、典型相关分析<citation id="451" type="reference"><link href="410" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和奇异值分解<citation id="452" type="reference"><link href="412" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>等手段对LSDR进行了研究.尽管主成分分析和奇异值分解等矩阵降维技术可以很好地将大规模标签降维一个低维空间, 但是降维后的空间也失去了原始标签的含义.为了解决这一问题, Balasubramanian等人<citation id="453" type="reference"><link href="414" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出了标签子集选择的思想, 即低维标签选择自原标签空间.此后, Bi等人<citation id="454" type="reference"><link href="416" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出了多标签分类的列子集选择方法 (column subset selection for multi-label, CSS-ML) , 该方法基于一个随机采样过程选择出<i>k</i>个标签以尽可能覆盖所有的标签, 并且在选择好的标签上学习了<i>k</i>个分类器.总的来说, 以上方法都只是将标签矩阵看作一个普通的矩阵来进行维度降低.从多标签分类的角度看, 蛋白质功能标签矩阵显然是一个布尔矩阵 (只有2种值0和1) .文献<citation id="455" type="reference">[<a class="sup">21</a>]</citation>已证明:某些能够进行精确BMD的矩阵却不一定能进行普通的矩阵分解, 因此BMD对标签的降维效果要好于普通矩阵分解.</p>
                </div>
                <div class="p1">
                    <p id="77">BMD问题已被证明是一个等价于二分图中最小二分团覆盖的NP困难问题<citation id="456" type="reference"><link href="420" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.因此, 对于一个最小的<i>k</i>来发现矩阵的BMD并不是一个可直接实现的问题, 特别当待分解矩阵的规模很大时.最早对于BMD问题的研究是基于组合数学的理论, 之后Miettinen<citation id="457" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>对于BMD开创性的工作启发了大量研究将其应用于数据挖掘领域<citation id="458" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.Drineas等人<citation id="459" type="reference"><link href="426" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出了CX分解:一个给定的矩阵<b><i>M</i></b>被分解为2个矩阵<b><i>C</i></b>和<b><i>X</i></b>, 使得<b><i>M</i></b>与<b><i>C</i></b>·<b><i>X</i></b>之间的差别最小, 即<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Μ</mi><mo>-</mo><mi mathvariant="bold-italic">C</mi><mo>⋅</mo><mi mathvariant="bold-italic">X</mi></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>L</mtext></msub></mrow></math></mathml>最小, 并且规定<b><i>C</i></b>中的列必须是<b><i>M</i></b>的一个列子集, 这一约束也被称为“列利用条件”.若满足<b><i>M</i></b>=<b><i>C</i></b>·<b><i>X</i></b>, 则称精确分解.基于这一研究, Miettinen<citation id="460" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>设计了贪婪算法Asso, 用于对于给定的布尔矩阵找到能最好地近似它的布尔矩阵分解, 显然Asso并不是一个精确BMD算法.此后, Wicker等人<citation id="461" type="reference"><link href="428" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>基于Asso提出了一种多标签分类器, 并考虑了标签间的关联关系以提高分类性能, 然而由于其使用的是Asso算法, 因此分类结果并不是基于精确BMD进行还原.文献<citation id="462" type="reference">[<a class="sup">24</a>]</citation>利用晶格理论的思想提出了2个启发式算法GreConD和GreEss, 但这2个算法并不满足“列利用条件”约束. Sun等人<citation id="463" type="reference"><link href="430" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>首次为精确BMD问题提出了一个布尔矩阵<b><i>J</i></b>, 使其满足<b><i>M</i></b>=<b><i>M</i></b>。<b><i>J</i></b><sup>T</sup>, 并且基于矩阵<b><i>J</i></b>提出了2个启发式算法.在多个真实数据集中的实验表明:该研究与多个代表性的BMD算法相比, 在运行速度和精度上具有明显优势, 且满足“列利用条件”约束.</p>
                </div>
                <div class="p1">
                    <p id="79">通过以上分析可知, 数量庞大的蛋白质功能注释标签已成为提高各类多标签分类器预测效果的一大障碍.本文采用BMD方法实现蛋白质功能预测过程中功能标签的维度降低, 即可保留功能标签的生物意义亦可完成更精确的降维.同时, 本文在PFP-BMD中使用精确BMD算法, 能够使降维后的分类及还原最大程度地保留分类器的分类精度, 而“列利用条件”则可使降维后的标签空间仍然具有原标签的意义.</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag"><b>2 基于布尔矩阵分解的蛋白质功能预测框架</b></h3>
                <div class="p1">
                    <p id="81">在本节中, 我们详细介绍PFP-BMD的基本思想.</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82"><b>2.1 蛋白质功能预测及相关符号定义</b></h4>
                <div class="p1">
                    <p id="83">基于多标签分类的思想, 本文首先对蛋白质功能预测问题进行形式化定义:</p>
                </div>
                <div class="p1">
                    <p id="84">给定包含<i>D</i>个蛋白质的集合<i>D</i>={<b><i>X</i></b><sub>1</sub>, <b><i>X</i></b><sub>2</sub>, …, <b><i>X</i></b><sub><i>D</i></sub>}以及<i>S</i>个功能标签的标签空间<i>S</i>={1, 2, …, <i>S</i>}, 每个蛋白质<b><i>X</i></b><sub><i>d</i></sub>, <i>d</i>∈[1, <i>D</i>]具有在特征空间<i>W</i>={1, 2, …, <i>W</i>}中的<i>W</i>个特征属性, 则每个蛋白质<b><i>X</i></b><sub><i>d</i></sub>可通过一个<i>W</i>维的特征向量<b><i>F</i></b><sub><i>d</i></sub>和一个<i>S</i>维的功能向量<b><i>Y</i></b><sub><i>d</i></sub>进行描述, 即<b><i>X</i></b><sub><i>d</i></sub>= (<b><i>F</i></b><sub><i>d</i></sub>, <b><i>Y</i></b><sub><i>d</i></sub>) , <b><i>F</i></b><sub><i>d</i></sub>= (<i>f</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>d</mi></msubsup></mrow></math></mathml>, <i>f</i><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>d</mi></msubsup></mrow></math></mathml>, …, <i>f</i><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>W</mi><mi>d</mi></msubsup></mrow></math></mathml>) , <b><i>Y</i></b><sub><i>d</i></sub>= (<i>y</i><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>d</mi></msubsup></mrow></math></mathml>, <i>y</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>d</mi></msubsup></mrow></math></mathml>, …, <i>y</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mi>d</mi></msubsup></mrow></math></mathml>) , 其中<i>f</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>d</mi></msubsup></mrow></math></mathml>∈R, <i>y</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>d</mi></msubsup></mrow></math></mathml>∈{0, 1}, <i>d</i>∈[1, <i>D</i>], <i>t</i>∈[1, <i>W</i>], <i>s</i>∈[1, <i>S</i>].<i>f</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>d</mi></msubsup></mrow></math></mathml>表示蛋白质<b><i>X</i></b><sub><i>d</i></sub>第<i>t</i>个特征属性的值, <i>y</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>d</mi></msubsup></mrow></math></mathml>表示蛋白质<b><i>X</i></b><sub><i>d</i></sub>第<i>s</i>个功能标签的值, 如果蛋白质<b><i>X</i></b><sub><i>d</i></sub>被第<i>s</i>个功能标签所注释, 则<i>y</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>d</mi></msubsup></mrow></math></mathml>=1, 否则<i>y</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>d</mi></msubsup></mrow></math></mathml>=0.在蛋白质功能数据中, 1个蛋白质可以被多个功能标签注释, 即允许<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>y</mi></mstyle><msubsup><mrow></mrow><mi>s</mi><mi>d</mi></msubsup><mo>&gt;</mo><mn>1</mn><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="98">蛋白质功能预测的任务就是从已知特征向量和功能标签向量的训练数据集<i>D</i><sub>train</sub>={<b><i>X</i></b><sub>1</sub>, <b><i>X</i></b><sub>2</sub>, …, <b><i>X</i></b><sub><i>m</i></sub>|<b><i>X</i></b><sub><i>d</i></sub>= (<b><i>F</i></b><sub><i>d</i></sub>, <b><i>Y</i></b><sub><i>d</i></sub>) , <i>d</i>∈[1, <i>m</i>]}中, 对多标签分类模型进行训练, 然后使用训练好的模型对已知特征向量但未知功能注释标签向量的新蛋白质<i>D</i><sub>test</sub>={<b><i>X</i></b><sub>1</sub>, <b><i>X</i></b><sub>2</sub>, …, <b><i>X</i></b><sub><i>n</i></sub>|<b><i>X</i></b><sub><i>d</i></sub>= (<b><i>F</i></b><sub><i>d</i></sub>, ) , <i>d</i>∈[1, <i>n</i>]}, 预测出其功能标签<b><i>Y</i></b><sub><i>d</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="99">在本文中, <i>D</i>表示训练集中蛋白质数量, <i>S</i>表示功能标签的数量, 蛋白质功能标签矩阵<b><i>Y</i></b>= (<i>Y</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>D</i>×<i>S</i></sup>.布尔值间的关系满足:1&gt;0且1-0=1, 1-1=0-0=0.本文使用<b><i>Y</i></b><sub><i>i</i></sub>来表示矩阵<b><i>Y</i></b>中第<i>i</i>行的行向量, 使用<b><i>Y</i></b><sup>T</sup><sub><i>j</i></sub>来表示矩阵<b><i>Y</i></b>中第<i>j</i>列的列向量.特别地, <b><i>Y</i></b><sup>T</sup><sub>≠<i>i</i>, <i>j</i></sub> (或<b><i>Y</i></b><sub><i>i</i>, ≠<i>j</i></sub>) 表示第<i>j</i>列 (或第<i>i</i>行) 中去除第<i>i</i>行 (或第<i>j</i>列) 元素后的向量.矩阵的补表示为<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><mo>=</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>D</mi><mo>×</mo><mi>S</mi></mrow></msup></mrow></math></mathml>, 其中, <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mn>0</mn><mo stretchy="true">¯</mo></mover><mo>=</mo><mn>1</mn></mrow></math></mathml>且<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mn>1</mn><mo stretchy="true">¯</mo></mover><mo>=</mo><mn>0</mn></mrow></math></mathml>, 转置矩阵表示为<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>.</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow></mrow></math></mathml>表示矩阵<b><i>Y</i></b>中非0元素的个数.R表示所有实数的集合.符号“·”表示普通的矩阵乘法.</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>2.2 框架描述</b></h4>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于布尔矩阵的蛋白质功能预测框架" src="Detail/GetImg?filename=images/JFYZ201905012_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于布尔矩阵的蛋白质功能预测框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The framework of protein function prediction  based on Boolean matrix decomposition</p>

                </div>
                <div class="p1">
                    <p id="106">为了解决蛋白质功能预测中数量庞大的功能标签问题, 本文采用LSDR的思想, 在预测过程中加入精确布尔矩阵模块以实现蛋白质功能标签矩阵的降维和还原, 精确BMD模块与多标签分类器一起构成了本文的PFP-BMD.PFP-BMD的流程描述如图 2所示:</p>
                </div>
                <div class="p1">
                    <p id="107">PFP-BMD的基本思想为:</p>
                </div>
                <div class="p1">
                    <p id="108">首先输入蛋白质训练数据集矩阵<b><i>D</i></b><sub>train</sub>, 其由特征矩阵<b><i>F</i></b><sub>train</sub>= (<i>F</i><sub><i>i j</i></sub>) ∈R<sup><i>D</i>×<i>F</i></sup>和标签矩阵<b><i>Y</i></b><sub>train</sub>= (<i>Y</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>D</i>×<i>S</i></sup>构成;然后利用BMD方法对标签矩阵<b><i>Y</i></b><sub>train</sub>进行精确布尔矩阵分解以得到分解后的2个矩阵<b><i>C</i></b><sub>train</sub>= (<i>C</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>D</i>×<i>k</i></sup>和<b><i>B</i></b><sub>train</sub>= (<i>B</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>k</i>×<i>S</i></sup>;接着将<b><i>F</i></b><sub>train</sub>和<b><i>C</i></b><sub>train</sub>组合到一个矩阵<b><i>G</i></b><sub>train</sub>中以创建训练数据集, 并对多标签分类器进行训练;然后利用训练好的分类器对未知功能的蛋白质特征向量<b><i>p</i></b>进行分类预测, 以得到预测标签向量<b><i>q</i></b>= (<i>q</i><sub>1</sub>, <i>q</i><sub>2</sub>, …, <i>q</i><sub><i>k</i></sub>) , <i>q</i><sub><i>s</i></sub>∈{0, 1}, <i>s</i>∈[1, <i>k</i>];最后, 利用矩阵<b><i>B</i></b><sub>train</sub>将预测向量<b><i>q</i></b>还原回原标签空间<b><i>q</i></b>′= (<i>q</i>′<sub>1</sub>, <i>q</i>′<sub>2</sub>, …, <i>q</i>′<sub><i>S</i></sub>) , <i>q</i>′<sub><i>s</i></sub>∈{0, 1}, <i>s</i>∈[1, <i>S</i>]:<b><i>q</i></b>′=<b><i>q</i></b>。<b><i>B</i></b><sub>train</sub>.</p>
                </div>
                <div class="p1">
                    <p id="109">由图2可看出, 基于布尔矩阵分解的蛋白质功能预测框架的优势在于:利用精确的布尔矩阵分解得到的矩阵能够一定程度上减轻多标签分类器的训练及预测任务, 而多标签分类器的输出结果只需要和矩阵<b><i>B</i></b>进行简单的布尔乘即可还原回原标签空间.在框架中, 精确BMD模块和多标签分类器模块是2个相对独立的部件, 因此该框架可适用于多种多标签分类器, 其中精确BMD模块既能保留在分类时标签的生物意义, 同时在还原回原标签时并不降低分类精度.</p>
                </div>
                <h3 id="110" name="110" class="anchor-tag"><b>3 精确布尔矩阵分解算法</b></h3>
                <div class="p1">
                    <p id="111">在本节中, 我们针对PFP-BMD中的精确BMD模块进行具体研究, 提出一个改进的精确布尔矩阵分解算法Label-Cluster.</p>
                </div>
                <h4 class="anchor-tag" id="112" name="112"><b>3.1 精确布尔矩阵分解算法基础</b></h4>
                <div class="p1">
                    <p id="113">本节首先给出布尔矩阵分解的定义及文献<citation id="464" type="reference">[<a class="sup">27</a>]</citation>中的相关定义、命题和定理.</p>
                </div>
                <div class="p1">
                    <p id="114">蛋白质功能标签矩阵<b><i>Y</i></b>是一个<i>D</i>×<i>S</i>维的布尔矩阵, 即<b><i>Y</i></b>= (<i>Y</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>D</i>×<i>S</i></sup>.布尔矩阵分解的目的是找到2个矩阵<b><i>C</i></b>= (<i>C</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>D</i>×<i>k</i></sup>和<b><i>B</i></b>= (<i>B</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>k</i>×<i>S</i></sup>, 使得对于给定的<i>k</i>或使<i>k</i>尽量小的情况下<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">C</mi><mtext> </mtext><mo>˚</mo><mi mathvariant="bold-italic">B</mi></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>L</mtext></msub></mrow></math></mathml>最小.其中符号“。”表示布尔矩阵乘, 它是布尔域上的普通矩阵乘法, 定义为</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><mo>=</mo><mi mathvariant="bold-italic">C</mi><mtext> </mtext><mo>˚</mo><mi mathvariant="bold-italic">B</mi><mo>=</mo><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>D</mi><mo>×</mo><mi>S</mi></mrow></msup><mo>, </mo></mtd></mtr><mtr><mtd><mi>Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>=</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mo>∨</mo></mstyle><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>s</mi></mrow></msub><mo>∧</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>s</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">换句话说, 布尔矩阵乘法就是在普通矩阵乘法中加一条额外的定义1+1=1, 最小的<i>k</i>通常被称为<b><i>Y</i></b>的布尔轶, 且已有研究表明一个布尔矩阵的布尔轶可能大于或小于它的实数轶<citation id="465" type="reference"><link href="432" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>.对于可以找到最小<i>k</i>的布尔矩阵分解算法, 则称其为最优布尔矩阵分解.</p>
                </div>
                <div class="p1">
                    <p id="118">本文使用的是精确BMD, 即在任意的L范数下满足<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Μ</mi><mo>-</mo><mi mathvariant="bold-italic">U</mi><mo>˚</mo><mi mathvariant="bold-italic">V</mi></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>L</mtext></msub><mo>=</mo><mn>0</mn></mrow></math></mathml>.一个精确BMD的例子:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">C</mi><mo>˚</mo><mi mathvariant="bold-italic">B</mi><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>˚</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">即<b><i>Y</i></b>=<b><i>C</i></b> 。<b><i>B</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="122"><b>定义1</b>. 给定2个布尔矩阵<b><i>U</i></b>= (<i>U</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>m</i>×<i>n</i></sup>和<b><i>V</i></b>= (<i>V</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>m</i>×<i>n</i></sup>, 如果对于所有的<i>i</i>=1, 2, …, <i>m</i>和<i>j</i>=1, 2, …, <i>n</i>都满足<i>U</i><sub><i>i j</i></sub>≥<i>V</i><sub><i>i j</i></sub>, 则称<b><i>U</i></b>≥<b><i>V</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="123"><b>命题1</b>. 布尔乘法满足扩展:</p>
                </div>
                <div class="p1">
                    <p id="124"><b><i>Y</i></b>=<b><i>C</i></b> 。<b><i>B</i></b>=<b><i>C</i></b><sup>T</sup><sub>1</sub>。<b><i>B</i></b><sub>1</sub>∨<b><i>C</i></b><sup>T</sup><sub>2</sub>。<b><i>B</i></b><sub>2</sub>∨…∨<b><i>C</i></b><sup>T</sup><sub><i>k</i></sub>。<b><i>B</i></b><sub><i>k</i></sub>=</p>
                </div>
                <div class="p1">
                    <p id="125">∨<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup></mrow></math></mathml>{<b><i>C</i></b><sup>T</sup><sub><i>t</i></sub>。<b><i>B</i></b><sub><i>t</i></sub>}.</p>
                </div>
                <div class="p1">
                    <p id="127">在文献<citation id="466" type="reference">[<a class="sup">27</a>]</citation>所提出的BMD方法中, 首先证明了存在一个布尔矩阵<b><i>J</i></b>, 使得<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>J</i></b><sup>T</sup>成立, 并且当<b><i>J</i></b>中的任意元素从0改变为1时等式就不再成立, 即<b><i>J</i></b>是使等式成立的最大矩阵.文献中所提出的启发式算法Remove-Smallest基于2个定理:</p>
                </div>
                <div class="p1">
                    <p id="128"><b>定理1</b>. 给定任意矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, 定义矩阵<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo>=</mo><mover accent="true"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>˚</mo><mi mathvariant="bold-italic">Y</mi></mrow><mo stretchy="true">¯</mo></mover><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>S</mi><mo>×</mo><mi>S</mi></mrow></msup></mrow></math></mathml>, 那么对于任意满足等式<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>B</i></b><sup>T</sup>的矩阵<b><i>B</i></b>∈{0, 1}<sup><i>S</i>×<i>S</i></sup>, 都有<b><i>B</i></b>≤<b><i>J</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="130"><b>定理2</b>. 令<b><i>Y</i></b>=<b><i>C</i></b>。<b><i>B</i></b>是矩阵<b><i>Y</i></b>的布尔矩阵分解, 且满足“列利用条件”约束, 其中<b><i>C</i></b>∈{0, 1}<sup><i>D</i>×<i>k</i></sup>, <b><i>B</i></b>∈{0, 1}<sup><i>k</i>×<i>S</i></sup>并且令<i>k</i>尽可能小.那么对于每个<i>i</i>=1, 2, …, <i>k</i>, 一定有<b><i>C</i></b><sup>T</sup><sub><i>i</i></sub>。<b><i>B</i></b><sub><i>i</i></sub>∈ {<b><i>Y</i></b><sup>T</sup><sub><i>t</i></sub>。 <b><i>J</i></b><sub><i>t</i></sub>|<i>t</i>=1, 2, …, <i>S</i>}.</p>
                </div>
                <div class="p1">
                    <p id="131">定理2说明:在“列利用条件”下对于矩阵<b><i>Y</i></b>的一个最优布尔矩阵分解的搜索空间可以限制在{<b><i>Y</i></b><sup>T</sup><sub><i>t</i></sub><b><i>J</i></b><sub><i>t</i></sub>|<i>t</i>=1, 2, …, <i>S</i>}中.文献<citation id="467" type="reference">[<a class="sup">27</a>]</citation>即基于这一定理提出了精确布尔矩阵分解算法Remove-Smallest, 该算法也将在4.2节中与本文所提的改进算法进行实验对比讨论.</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>3.2 功能标签关联矩阵</b></h4>
                <div class="p1">
                    <p id="133">矩阵<b><i>J</i></b>在文献<citation id="468" type="reference">[<a class="sup">27</a>]</citation>中与原矩阵<b><i>Y</i></b>一起构成了最优布尔矩阵分解的搜索空间.在对矩阵<b><i>J</i></b>的深入研究中, 本文发现:矩阵<b><i>J</i></b>本质上是对原矩阵<b><i>Y</i></b>各列关联关系的一种表示.我们将在本节对蛋白质功能预测中的功能标签关联矩阵<b><i>A</i></b>进行定义, 以及通过推论1证明其与矩阵<b><i>J</i></b>的关系.</p>
                </div>
                <div class="p1">
                    <p id="134">在蛋白质功能注释命名方案GO和FunCat中, 蛋白质的功能标签之间具有层次关系, FunCat中是树形结构, 而GO中是有向无环图 (directed acyclic graph, DAG) 结构.也就是说, 不论是在FunCat还是在GO中, 用于蛋白质功能预测的多标签分类器必须满足层次约束, 即被一些功能注释的蛋白质一定会被这些功能的父节点功能注释.本文使用符号<i>parent</i> (<i>c</i><sub><i>i</i></sub>) 表示功能标签<i>c</i><sub><i>i</i></sub>的父标签集, 使用<i>des</i> (<i>c</i><sub><i>i</i></sub>) 表示功能标签<i>c</i><sub><i>i</i></sub>的祖先标签集.如图3所示<i>c</i><sub>1</sub>到<i>c</i><sub>8</sub>共8个功能标签的层次关联, 其中<i>des</i> (<i>c</i><sub>7</sub>) ={<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, <i>c</i><sub>3</sub>, <i>c</i><sub>4</sub>}.</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 标签关联示意图" src="Detail/GetImg?filename=images/JFYZ201905012_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 标签关联示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The diagram of associated labels</p>

                </div>
                <div class="p1">
                    <p id="136">对于功能标签间的DAG层次关联关系, 本文使用了一个矩阵<b><i>A</i></b>= (<i>A</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>S</i>×<i>S</i></sup>来描述, <b><i>A</i></b>中的元素<i>A</i><sub><i>i j</i></sub>满足:若功能标签<i>c</i><sub><i>i</i></sub>∈<i>des</i> (<i>c</i><sub><i>j</i></sub>) 则<i>A</i><sub><i>i j</i></sub>=1, 否则为0.显然, 矩阵<b><i>A</i></b>可通过功能标签间固有的DAG关系计算得出图3的矩阵<b><i>A</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>.</mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">下面通过推论1来证明矩阵<b><i>A</i></b>和矩阵<b><i>J</i></b>之间的关系.</p>
                </div>
                <div class="p1">
                    <p id="139"><b>推论1</b>. 对于功能标签矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, 其标签列的DAG关联矩阵<b><i>A</i></b>= (<i>A</i><sub><i>i j</i></sub>) ∈{0, 1}<sup><i>S</i>×<i>S</i></sup>和矩阵<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo>=</mo><mover accent="true"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>˚</mo><mi mathvariant="bold-italic">Y</mi></mrow><mo stretchy="true">¯</mo></mover><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>S</mi><mo>×</mo><mi>S</mi></mrow></msup></mrow></math></mathml>之间满足<b><i>J</i></b>≥<b><i>A</i></b>的关系.</p>
                </div>
                <div class="p1">
                    <p id="141">证明. 从定理1可得只要证明<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>, 则有<b><i>J</i></b>≥<b><i>A</i></b>.在<b><i>A</i></b>中, <i>A</i><sub><i>i j</i></sub>=1表示第<i>i</i>个标签是第<i>j</i>个标签的祖先;在<b><i>A</i></b><sup>T</sup>中, (<b><i>A</i></b><sup>T</sup>) <sub><i>i j</i></sub>=1说明第<i>i</i>个标签是第<i>j</i>个标签的子孙;显然对于<b><i>A</i></b>和<b><i>A</i></b><sup>T</sup>, <i>A</i><sub><i>i i</i></sub>=1以及 (<b><i>A</i></b><sup>T</sup>) <sub><i>j j</i></sub>=1成立.下面分2种情况进行证明:当矩阵<b><i>Y</i></b>中的元素<i>Y</i><sub><i>i j</i></sub>=1时, 由于有 (<b><i>A</i></b><sup>T</sup>) <sub><i>j j</i></sub>=1, 则<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>中的元素 (<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>) <sub><i>i j</i></sub>=1;当矩阵<b><i>Y</i></b>中的元素<i>Y</i><sub><i>i j</i></sub>=0时, 由于矩阵<b><i>Y</i></b>中的第<i>i</i>行不可能存在一个元素<i>Y</i><sub><i>i k</i></sub>=1且<b><i>A</i></b><sup>T</sup>中的 (<b><i>A</i></b><sup>T</sup>) <sub><i>k j</i></sub>=1, 因为 (<b><i>A</i></b><sup>T</sup>) <sub><i>k j</i></sub>=1说明标签<i>k</i>是标签<i>j</i>的子孙, 如果<i>Y</i><sub><i>i k</i></sub>=1则一定有<i>Y</i><sub><i>i j</i></sub>=1, 这与假设相背, 因此<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>中的元素 (<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>) <sub><i>i j</i></sub>=0.综上2种情况, <b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>A</i></b><sup>T</sup>均成立, 则由定理1可得<b><i>J</i></b>≥<b><i>A</i></b>成立. 证毕.</p>
                </div>
                <div class="p1">
                    <p id="142">从推论1可以看出, 矩阵<b><i>J</i></b>不仅覆盖了原始标签集的一个DAG关联, 并且还反映了由矩阵<b><i>Y</i></b>中的值隐含的列之间的关联关系.因此, 矩阵<b><i>J</i></b>本质上是一个标签关联矩阵.</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>3.3 基于标签簇的布尔矩阵分解算法</b></h4>
                <div class="p1">
                    <p id="144">由3.2节讨论可知, 对于矩阵<b><i>Y</i></b>, 矩阵<b><i>A</i></b>反映的是标签间固有的层次约束关系, 即<b><i>Y</i></b>中的元素必须满足:如果矩阵<b><i>A</i></b>中的元素<i>A</i><sub><i>i j</i></sub>=1, 且<i>Y</i><sub><i>d j</i></sub>=1, 则<i>Y</i><sub><i>d i</i></sub>=1.换句话说, 当子孙标签<i>c</i><sub><i>j</i></sub>注释了某蛋白质<i>d</i>时, 它会使得<i>c</i><sub><i>j</i></sub>所有的祖先标签<i>des</i> (<i>c</i><sub><i>j</i></sub>) 均注释该蛋白质.如图3中的功能标签<i>c</i><sub>7</sub>, 其所注释的蛋白质也一定被其祖先标签集<i>des</i> (<i>c</i><sub>7</sub>) ={<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, <i>c</i><sub>3</sub>, <i>c</i><sub>4</sub>}所注释.</p>
                </div>
                <div class="p1">
                    <p id="145">基于以上这种层次约束关系, 如果将矩阵<b><i>Y</i></b>中所有祖先标签这种因其子孙扩展而来的注释关系去掉, 那么可能会出现大量祖先标签注释蛋白质的数量为0, 当将这些不再注释蛋白质的祖先标签从标签集中去掉时, 并不会影响其他标签对蛋白质的注释关系, 而通过祖先标签与保留的子孙标签的层次关联关系, 又可以很容易地恢复祖先标签对蛋白质的标准.显然, 只需保留最下层的叶子标签即可最大程度地删除不再注释蛋白质的祖先标签.本文将这种保留下的子孙标签称为一个标签簇, 因为尽管保留下来的仅仅是一个单独的子孙标签列, 但是它却包含了从它开始向上扩展一直到根标签的一个标签子集.</p>
                </div>
                <div class="p1">
                    <p id="146">如图3中的功能标签<i>c</i><sub>7</sub>可与其祖先标签集构成一个标签簇{<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, <i>c</i><sub>3</sub>, <i>c</i><sub>4</sub>, <i>c</i><sub>7</sub>}, 而<i>c</i><sub>7</sub>对蛋白质的注释数据同时也可反映出<i>c</i><sub>1</sub>～<i>c</i><sub>4</sub>是否注释了某些蛋白质.如果对矩阵<b><i>Y</i></b>找出所有这样的标签簇, 保留下标签簇中的最下层标签, 那么相当于实现了标签空间的降维, 而标签簇对蛋白质的注释矩阵与标签簇与标签的对应关系矩阵相乘则可得到对原标签空间的还原, 这一过程实际就是一个精确的BMD.</p>
                </div>
                <div class="p1">
                    <p id="147">由推论1可知, 矩阵<b><i>J</i></b>本质上是一个标签的关联矩阵且<b><i>J</i></b>≥<b><i>A</i></b>, 即矩阵<b><i>J</i></b>描述功能标签间关联关系最完整的矩阵, 不仅包含功能标签间固有的DAG关系, 同时还包含了矩阵<b><i>Y</i></b>中的值之间反映的关联关系.因此, 按照以上标签聚簇思想同样可基于矩阵<b><i>J</i></b>来构造标签簇集, 以完成<b><i>Y</i></b>的精确BMD.基于以上分析, 本文提出了基于标签簇的精确BMD算法, 如算法1所示:</p>
                </div>
                <div class="p1">
                    <p id="148"><b>算法1</b>. Label-Cluster算法.</p>
                </div>
                <div class="area_img" id="315">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905012_31500.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="165">在Label-Cluster算法中, 矩阵<b><i>C</i></b>成为了蛋白质功能的“标签”矩阵, 其中每一个新的功能“标签” (即<b><i>C</i></b>中的每一列) 既是一个原始标签也代表了原始标签集的一个子集 (标签簇:一个原始标签的所有祖先标签及其本身的一个集合) , 即满足“列利用条件”约束.对于每个蛋白质, 矩阵<b><i>C</i></b>以一个更低的维度表现了蛋白质所有的原始功能标签, 而矩阵<b><i>B</i></b>中的每一行是一个标签簇到原始标签的一个对应关系, 如果<i>B</i><sub><i>i j</i></sub>=1, 那么标签簇<i>i</i>中包含了原始标签<i>j</i>, 否则为0.矩阵<b><i>B</i></b>所描述的这种标签簇与标签间的对应关系, 可以很自然地用于标签簇矩阵到原始标签矩阵的还原.</p>
                </div>
                <div class="p1">
                    <p id="166">同时, 需要注意的是:不是所有的祖先标签都能在被聚簇后而在矩阵<b><i>C</i></b>中被消去, 除非它对所有蛋白质的注释都能被其标签簇所表示.因此, 在算法1中, 步骤2首先是将对矩阵<b><i>Y</i></b>中的每一个元素进行更新, 如果<i>Y</i><sub><i>i j</i></sub>=1, 且存在<i>j</i>的某孩子标签<i>m</i>有<i>Y</i><sub><i>i m</i></sub>=1, 那么将<i>Y</i><sub><i>i j</i></sub>更新为0, 在对<b><i>Y</i></b>中的每个元素进行更新后, 如果某标签可以被其标签簇完全表示, 那么该列将全部为0, 即可删除.在步骤3删除全0列得到矩阵<b><i>C</i></b>之后, 还需要步骤5对步骤2中更新为0但没有被随列删除的元素进行恢复, 进而使得矩阵<b><i>C</i></b>满足“列利用条件”.因此算法1是对聚簇操作的一种程序实现的具体表示, 与本节所阐述的聚簇思想相对应.</p>
                </div>
                <h4 class="anchor-tag" id="167" name="167"><b>3.4 Label-Cluster算法的相关推论及证明</b></h4>
                <div class="p1">
                    <p id="168">为了证明Label-Cluster算法可得到矩阵<b><i>Y</i></b>的最优精确布尔矩阵分解, 我们在本节中通过4个推论对其进行证明.</p>
                </div>
                <div class="p1">
                    <p id="169"><b>推论2</b>. 给定一个布尔矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, (<b><i>C</i></b>, <b><i>B</i></b>) =<i>Label</i>_<i>Cluster</i> (<b><i>Y</i></b>) , <b><i>C</i></b>∈{0, 1}<sup><i>D</i>×<i>k</i></sup>且<b><i>B</i></b>∈{0, 1}<sup><i>k</i>×<i>S</i></sup>.那么通过算法Label-Cluster′ (将Label-Cluster中的矩阵<b><i>J</i></b>替换为任意满足式<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>H</i></b><sup>T</sup>的矩阵<b><i>H</i></b>) 可得到 (<b><i>C</i></b>′, <b><i>B</i></b>′) =<i>Label</i>_<i>Cluster</i>′ (<b><i>Y</i></b>) , <b><i>C</i></b>′∈{0, 1}<sup><i>D</i>×<i>k</i>′</sup> 且<b><i>B</i></b>∈{0, 1}<sup><i>k</i>′×<i>S</i></sup>, 则<i>k</i>≤<i>k</i>′成立.</p>
                </div>
                <div class="p1">
                    <p id="170">证明. 由定理1可知, 对于任意满足<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>H</i></b><sup>T</sup>的矩阵<b><i>H</i></b>都有<b><i>H</i></b>≤<b><i>J</i></b>, 显然<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">J</mi><msub><mrow></mrow><mrow><mo>≠</mo><mi>j</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>≤</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mo>≠</mo><mi>j</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>也成立, 因此满足<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mo>≠</mo><mi>j</mi></mrow></msub><mo>∧</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">J</mi><msub><mrow></mrow><mrow><mo>≠</mo><mi>j</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>≤</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mo>≠</mo><mi>j</mi></mrow></msub><mo>∧</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mo>≠</mo><mi>j</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>.换句话说, 通过矩阵<b><i>J</i></b>更新得到的矩阵<i>Label</i>_<i>Cluster</i> (<b><i>Y</i></b>) 一定小于等于通过矩阵<b><i>H</i></b>更新得到的矩阵<i>Label</i>_<i>Cluster</i>′ (<b><i>Y</i></b>) , 即<i>Label</i>_<i>Cluster</i> (<b><i>Y</i></b>) 中非0列的个数<i>k</i>小于等于<i>Label</i>_<i>Cluster</i>′ (<b><i>Y</i></b>) 中的非0列个数<i>k</i>′, 即<i>k</i>≤<i>k</i>′成立. 证毕.</p>
                </div>
                <div class="p1">
                    <p id="173">通过推论2可得, 在算法Label-Cluster中基于矩阵<b><i>J</i></b>所得到的矩阵<b><i>C</i></b>的列数<i>k</i>是最小的, 若在Label-Cluster算法中基于其他关联标签关联矩阵所得到的矩阵<b><i>C</i></b>的列数<i>k</i>′均大于<i>k</i>.</p>
                </div>
                <div class="p1">
                    <p id="174"><b>推论3</b>. 给定一个布尔矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, (<b><i>C</i></b>, <b><i>B</i></b>) =<i>Label</i>_<i>Cluster</i> (<b><i>Y</i></b>) , <b><i>C</i></b>∈{0, 1}<sup><i>D</i>×<i>k</i></sup>且<b><i>B</i></b>∈{0, 1}<sup><i>k</i>×<i>S</i></sup>, 则<b><i>Y</i></b>=<b><i>C</i></b>。<b><i>B</i></b>成立.</p>
                </div>
                <div class="p1">
                    <p id="175">证明. 假定<i>Y</i><sub><i>i j</i></sub>=0, 当<b><i>C</i></b>中第<i>i</i>行的任意元素<i>C</i><sub><i>i m</i></sub>=1, 说明第<i>i</i>个实例被第<i>m</i>个标签簇所标注, 如果有<i>B</i><sub><i>m j</i></sub>=1, 说明第<i>m</i>个标签簇包含了第<i>j</i>个标签, 则第<i>i</i>个实例一定也被第<i>j</i>个标签所标注, 即<i>Y</i><sub><i>i j</i></sub>=1, 但这与假设相悖.因此当<i>C</i><sub><i>i m</i></sub>=1时, 一定不存在<i>B</i><sub><i>m j</i></sub>=1, 则 (<b><i>C</i></b> 。<b><i>B</i></b>) <sub><i>i j</i></sub>=0.假定<i>Y</i><sub><i>i j</i></sub>=1, 因为<b><i>C</i></b>中不存在全0列, 因此一定有一个<i>C</i><sub><i>i m</i></sub>=1, 同样, 如果<i>B</i><sub><i>m j</i></sub>=0, 说明第<i>m</i>个标签簇不包含第<i>j</i>个标签, 那么第<i>i</i>个实例一定不被第<i>j</i>个标签所标注, 即<i>Y</i><sub><i>i j</i></sub>=0, 这与假设相悖.因此当<i>C</i><sub><i>i m</i></sub>=1时, 一定有<i>B</i><sub><i>m j</i></sub>=1, 则 (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>i j</i></sub>=1.综上所述, 2种情况下<i>Y</i><sub><i>i j</i></sub>= (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>i j</i></sub>, 即<b><i>Y</i></b>=<b><i>C</i></b>。<b><i>B</i></b>成立. 证毕.</p>
                </div>
                <div class="p1">
                    <p id="176">通过推论3可得, 算法Label-Cluster所得到的矩阵<b><i>C</i></b>和<b><i>B</i></b>是<b><i>Y</i></b>的精确BMD.</p>
                </div>
                <div class="p1">
                    <p id="177"><b>推论4</b>. 给定一个布尔矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, 令<b><i>C</i></b>=<b><i>Y</i></b>及<b><i>B</i></b>=<b><i>J</i></b><sup>T</sup>, 对于任意的<i>j</i>=1, 2, …, <i>S</i>, 如果<mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">C</mi><mo>⋅</mo><mi mathvariant="bold-italic">B</mi></mrow><mo>|</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">C</mi><mo>⋅</mo><mi mathvariant="bold-italic">B</mi><mo>-</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><mi>j</mi><mtext>Τ</mtext></msubsup><mo>˚</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>成立, 那么在删除了<b><i>C</i></b>中的第<i>j</i>列和<b><i>B</i></b>中的第<i>j</i>行后, 得到矩阵<b><i>P</i></b>∈{0, 1}<sup><i>D</i>× (<i>S</i>-1) </sup>和<b><i>R</i></b>∈{0, 1}<sup> (<i>S</i>-1) ×<i>S</i></sup>, 则<b><i>Y</i></b>=<b><i>P</i></b>。<b><i>R</i></b>同样成立.</p>
                </div>
                <div class="p1">
                    <p id="179">证明. 令<b><i>T</i></b>=<b><i>C</i></b>·<b><i>B</i></b>. 当<b><i>T</i></b>中的某个元素<i>T</i><sub><i>a b</i></sub>≥1时, 由于<i>T</i><sub><i>a b</i></sub>=<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>a</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>×</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub></mrow></math></mathml>, 因此<mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>a</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>×</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub></mrow></math></mathml>≥1, 可得∨<mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup></mrow></math></mathml><i>C</i><sub><i>a i</i></sub>×<i>B</i><sub><i>i b</i></sub>=1, 即 (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>a b</i></sub>=1.如果<mathml id="183"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">Τ</mi><mo>|</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Τ</mi><mo>-</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><mi>j</mi><mtext>Τ</mtext></msubsup><mo>˚</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>成立, 则说明<mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>a</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>×</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub></mrow></math></mathml>-<i>C</i><sub><i>a j</i></sub>×<i>B</i><sub><i>j b</i></sub>≥1成立.则将<b><i>C</i></b>中的第<i>j</i>列删除得到<b><i>P</i></b>∈{0, 1}<sup><i>D</i>× (<i>S</i>-1) </sup>, 将<b><i>B</i></b>中的第<i>j</i>行删除得到<b><i>R</i></b>∈{0, 1}<sup> (<i>S</i>-1) ×<i>S</i></sup>后, 得到 (<b><i>P</i></b>。<b><i>R</i></b>) <sub><i>a b</i></sub>=∨<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>S</mi></msubsup></mrow></math></mathml><i>C</i><sub><i>a i</i></sub>×<i>B</i><sub><i>i b</i></sub>=1.同时由于<b><i>Y</i></b>=<b><i>Y</i></b>。<b><i>J</i></b><sup>T</sup> (已由文献<citation id="469" type="reference">[<a class="sup">27</a>]</citation>证明) , 则<b><i>Y</i></b>=<b><i>C</i></b>。<b><i>B</i></b>, 且 (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>a b</i></sub>=1, 则最终可得<i>Y</i><sub><i>a b</i></sub>= (<b><i>P</i></b>。<b><i>R</i></b>) <sub><i>a b</i></sub>=1成立.当<i>T</i><sub><i>a b</i></sub>=0时, 即<mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>a</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>×</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub></mrow></math></mathml>=0, 同样可得∨<mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup></mrow></math></mathml><i>C</i><sub><i>a i</i></sub>×<i>B</i><sub><i>i b</i></sub>=0, 即 (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>a b</i></sub>=0.将<b><i>C</i></b>中的第<i>j</i>列删除得到<b><i>P</i></b>∈{0, 1}<sup><i>D</i>× (<i>S</i>-1) </sup>, 将<b><i>B</i></b>中的第<i>j</i>行删除得到<b><i>R</i></b>∈{0, 1}<sup> (<i>S</i>-1) ×<i>S</i></sup>后有 (<b><i>P</i></b>。<b><i>R</i></b>) <sub><i>a b</i></sub>=∨<mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>S</mi></msubsup></mrow></math></mathml><i>C</i><sub><i>a i</i></sub>×<i>B</i><sub><i>i b</i></sub>=0.由于有 (<b><i>C</i></b>。<b><i>B</i></b>) <sub><i>a b</i></sub>=<i>Y</i><sub><i>a b</i></sub>=0, 则<i>Y</i><sub><i>a b</i></sub>= (<b><i>P</i></b>。<b><i>R</i></b>) <sub><i>a b</i></sub>成立.综上2种情况下, <i>Y</i><sub><i>a b</i></sub>= (<b><i>P</i></b>。<b><i>R</i></b>) <sub><i>a b</i></sub>均成立, 即推论成立. 证毕.</p>
                </div>
                <div class="p1">
                    <p id="189">通过推论4可得, 在<i>j</i>=1, 2, …, <i>S</i>中可以找到多个<i>j</i>满足<mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">C</mi><mo>⋅</mo><mi mathvariant="bold-italic">B</mi></mrow><mo>|</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">C</mi><mo>⋅</mo><mi mathvariant="bold-italic">B</mi><mo>-</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><mi>j</mi><mtext>Τ</mtext></msubsup><mo>˚</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>.在<b><i>C</i></b>和<b><i>B</i></b>中迭代删除列和行的过程 (即更新和) , 直到没有再满足上式, 最终得到的矩阵即为矩阵<b><i>Y</i></b>的布尔矩阵分解.</p>
                </div>
                <div class="p1">
                    <p id="191"><b>推论5</b>. 给定一个布尔矩阵<b><i>Y</i></b>∈{0, 1}<sup><i>D</i>×<i>S</i></sup>, (<b><i>C</i></b>, <b><i>B</i></b>) =<i>Label</i>_<i>Cluster</i> (<b><i>Y</i></b>) , <b><i>C</i></b>∈{0, 1}<sup><i>D</i>×<i>k</i></sup>且<b><i>B</i></b>∈{0, 1}<sup><i>k</i>×<i>S</i></sup>, 初始化<b><i>P</i></b>=<b><i>C</i></b>及<mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">R</mi><mo>=</mo><mover accent="true"><mrow><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>˚</mo><mi mathvariant="bold-italic">C</mi></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>, 对于任意<b><i>j</i></b>=1, 2, …, <b><i>k</i></b>, 不存在<b><i>j</i></b>满足<mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>⋅</mo><mi mathvariant="bold-italic">R</mi></mrow><mo>|</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>⋅</mo><mi mathvariant="bold-italic">R</mi><mo>-</mo><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mi>j</mi><mtext>Τ</mtext></msubsup><mo>˚</mo><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="194">证明. 从算法Label-Cluster中对<b><i>Y</i></b>的更新式可得, <b><i>Y</i></b>′是对矩阵<b><i>Y</i></b>中的每一行的元素进行如下更新得到的矩阵, 如果标签<i>j</i>属于某一簇<i>k</i>, 即<i>J</i><sub><i>j k</i></sub>=1, 且<i>Y</i><sub><i>i k</i></sub>=1, 则<i>Y</i>′<sub><i>i j</i></sub>=0.更新完成后, 对于标签<i>j</i>, 如果它没有标注任意实例<i>i</i>, 或对所有实例都存在一个或多个其所属的簇<i>k</i>有<i>Y</i><sub><i>i k</i></sub>=1, 那么<b><i>Y</i></b>中的第<i>j</i>列会被更新为全0值, 继而在算法的下一步会被删除.换句话说, 那些保留下来的簇实际上也是表现为一个列标签<i>t</i>, 这个列标签所代表的簇包含了其所有子孙标签.而保留下的这个列<i>t</i>一定是标注了某个实例<i>d</i>, 即<i>Y</i><sub><i>d t</i></sub>=1, 但不存在任何列 (或簇) <i>j</i>=1, 2, …, <i>S</i>满足<i>Y</i><sub><i>d j</i></sub>=1, 且<i>J</i><sub><i>t j</i></sub>=1.令<b><i>T</i></b>=<b><i>P</i></b>·<b><i>R</i></b>, 则<i>T</i><sub><i>i j</i></sub>表示标注实例<i>i</i>的标签中包含了<i>j</i>的簇的次数 (标签簇<i>j</i>包含了它本身) .在经过Label-Cluster算法之后, 如前所述, 保留下来的列 (或簇) <i>t</i>, 对于某个实例<i>d</i>来说, 不存在包含<i>t</i>的簇也标注了<i>d</i>, 即在<i>T</i><sub><i>d t</i></sub>=<i>P</i><sub><i>d</i>, <i>s</i><sub>1</sub></sub>×<i>R</i><sub><i>s</i><sub>1</sub>, <i>t</i></sub>+<i>P</i><sub><i>d</i>, <i>s</i><sub>2</sub></sub>×<i>R</i><sub><i>s</i><sub>2</sub>, <i>t</i></sub>+…+<i>P</i><sub><i>d</i>, <i>S</i></sub>×<i>R</i><sub><i>S</i>, <i>t</i></sub>中, 只有当<i>s</i><sub><i>i</i></sub>=<i>t</i>时, 才有<i>P</i><sub><i>d</i>, <i>s</i><sub><i>i</i></sub></sub>×<i>R</i><sub><i>s</i><sub><i>i</i></sub>, <i>t</i></sub>=1, 而其余项均为0, 如果删除<i>t</i>列, 那么<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>⋅</mo><mi mathvariant="bold-italic">R</mi></mrow><mo>|</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>⋅</mo><mi mathvariant="bold-italic">R</mi><mo>-</mo><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mi>t</mi><mtext>Τ</mtext></msubsup><mo>˚</mo><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>就无法满足, 因此<i>t</i>列不可删除.同理, 每一个被保留下来的列均不可删除. 证毕.</p>
                </div>
                <div class="p1">
                    <p id="196">由推论4和推论5可得, 算法Label-Cluster得到的矩阵<b><i>C</i></b>和<b><i>B</i></b>满足:如果再从矩阵<b><i>C</i></b>和<b><i>B</i></b>中删除列和行, 则所得到的矩阵不再能满足<b><i>Y</i></b>的精确分解.即证明了矩阵<b><i>C</i></b>和<b><i>B</i></b>是<b><i>Y</i></b>的最优布尔矩阵分解.</p>
                </div>
                <h3 id="197" name="197" class="anchor-tag"><b>4 蛋白质功能预测实验</b></h3>
                <div class="p1">
                    <p id="198">在本节中, 我们分别对Label-Cluster算法和PFP-BMD在3个数据集进行了实验验证, 并选用针对大规模标签的分类模型与本文所提方法进行对比.</p>
                </div>
                <h4 class="anchor-tag" id="199" name="199"><b>4.1 数据集</b></h4>
                <div class="p1">
                    <p id="200">为验证Label-Cluster算法和PFP-BMD的有效性及优势, 本文采用了一个被广泛使用的标准蛋白质功能预测数据集酵母数据集 (s.cerevisiae dataset, S.C) <citation id="470" type="reference"><link href="394" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>进行实验分析.该数据集的蛋白质特征数据包含酵母基因的多个方面, 如序列统计特征、表型特征、基因表达特征、二级结构特征和同源特征等, 其包含了S.C-1到 S.C-12共12个数据集, 并且每个数据集都使用了FunCat和GO这2种功能注释方案, 本文主要使用了S.C中GO功能注释方案的S.C-1到S.C-3数据集.该数据集的数据格式都是Weka (waikato environment for knowledge analysis) 的arff文件, 以便于更多的Weka中的基准多标签分类算法应用到该数据集上.由于S.C数据集均已根据GO功能标签间的DAG结构对标签注释数据进行了扩展, 因此本文无需再做此预处理.</p>
                </div>
                <div class="p1">
                    <p id="201">表1中蛋白质平均标签数量为<mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mi>D</mi></mrow></math></mathml>, 在多标签分类中也称其为cardinality, <i>c</i><sub><i>i</i></sub>表示注释了第<i>i</i>个蛋白质的功能标签数量, <i>D</i>为蛋白质数量.蛋白质的平均标签数可以反映功能标签间的关联程度, 当cardinality接近于1时, 说明功能标签间基本没有依赖关系.</p>
                </div>
                <div class="area_img" id="203">
                    <p class="img_tit"><b>表1 S.C数据集统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 The Statistics of S.C Dataset</b></p>
                    <p class="img_note"></p>
                    <table id="203" border="1"><tr><td><br />Datasets</td><td>Feature</td><td>Label Number</td><td>Cardinality</td></tr><tr><td><br />S.C-1</td><td>Sequence</td><td>4 133</td><td>34</td></tr><tr><td><br />S.C-2</td><td>Phenotype</td><td>3 127</td><td>38</td></tr><tr><td><br />S.C-3</td><td>Secondary Structure</td><td>4 132</td><td>34</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="204" name="204"><b>4.2 Label-Cluster实验分析</b></h4>
                <h4 class="anchor-tag" id="205" name="205">4.2.1 对比算法及时间复杂度分析</h4>
                <div class="p1">
                    <p id="206">本节将Label-Cluster算法与文献<citation id="471" type="reference">[<a class="sup">27</a>]</citation>中的Remove-Smallest算法进行蛋白质功能标签矩阵降维实验对比.由于Remove-Smallest和Label-Cluster算法都是属于精确BMD方法, 均能完整地还原回原矩阵空间, 因此2个算法在文献<citation id="472" type="reference">[<a class="sup">27</a>]</citation>中使用的BMD算法评价标准覆盖率值均为100%.下面对2个算法的时间复杂度进行分析.</p>
                </div>
                <div class="p1">
                    <p id="207">1) Remove-Smallest算法.由命题1可知, 计算<mathml id="208"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover></math></mathml><sup>T</sup>。<b><i>Y</i></b>的时间可以分解为<mathml id="209"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mrow><mrow><mo>|</mo><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><mo>×</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><mo>≤</mo><mi>S</mi><mo>×</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><mo>=</mo></mrow></math></mathml><mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow></mrow></math></mathml>.因此, Remove-Smallest算法中计算式<mathml id="211"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo>=</mo><mover accent="true"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>˚</mo><mi mathvariant="bold-italic">Y</mi></mrow><mo stretchy="true">¯</mo></mover><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>S</mi><mo>×</mo><mi>S</mi></mrow></msup></mrow></math></mathml>的时间复杂度为<mathml id="212"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">S</mi><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>, 而计算式<b><i>T</i></b>=<b><i>C</i></b>·<b><i>B</i></b>的时间复杂度为<mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mi>D</mi><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>.因此, 当<i>D</i>&gt;<i>S</i>时, Remove-Smallest算法的时间复杂度为<image id="316" type="formula" href="images/JFYZ201905012_31600.jpg" display="inline" placement="inline"><alt></alt></image>.</p>
                </div>
                <div class="p1">
                    <p id="317">2) Label-Cluster算法.算法第1步同样需要通过式<mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">J</mi><mo>=</mo><mover accent="true"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>˚</mo><mi mathvariant="bold-italic">Y</mi></mrow><mo stretchy="true">¯</mo></mover><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo><msup><mrow></mrow><mrow><mi>S</mi><mo>×</mo><mi>S</mi></mrow></msup></mrow></math></mathml>计算出矩阵<b><i>J</i></b>, 但是不需要计算<b><i>T</i></b>=<b><i>C</i></b>·<b><i>B</i></b>, 而只需要利用式<mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi mathvariant="bold-italic">Y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mo>≠</mo><mi>j</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mo>≠</mo><mi>j</mi></mrow></msub><mo>∧</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">J</mi><msub><mrow></mrow><mrow><mo>≠</mo><mi>j</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>更新矩阵<b><i>Y</i></b>以得到<b><i>Y</i></b>′, 此更新步骤的时间复杂度为<mathml id="218"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>.同时, 通过步骤5对矩阵<b><i>C</i></b>进行关联标签扩展, 此步骤的时间复杂度为<mathml id="219"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>¯</mo></mover><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>, 显然<mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>¯</mo></mover><mo>|</mo></mrow><mo>≪</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow></mrow></math></mathml>.因此, 当<i>D</i>&gt;<i>S</i>时, 算法Label-Cluster总的时间复杂度为<mathml id="221"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mo stretchy="false"> (</mo><mi>S</mi><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Y</mi><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></math></mathml>, 其较Remove-Smallest算法的时间复杂度具有一定优势.4.2.2节将通过实验对Label-Cluster算法的性能进行评估.</p>
                </div>
                <h4 class="anchor-tag" id="222" name="222">4.2.2 实验结果</h4>
                <div class="p1">
                    <p id="223">Label-Cluster算法分别在上述3个数据集中进行布尔矩阵分解, 实验结果如图4所示, 图4中降维率= (原标签数量-降维后的标签数量) /原标签数量, 降维率可以反映了精确BMD算法对不同数据集的降维效果差异, 其值越大说明对高维标签的降维程度越高.</p>
                </div>
                <div class="area_img" id="224">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_224.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Label-Cluster算法在3个数据集上的降维效果对比" src="Detail/GetImg?filename=images/JFYZ201905012_224.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 Label-Cluster算法在3个数据集上的降维效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_224.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The dimension deduction comparisons of  Label-Cluster algorithm in three dataset</p>

                </div>
                <div class="p1">
                    <p id="225">由图4可以看出, 对于不同的数据集, Label-Cluster算法的降维率不尽相同, 其中对S.C-2数据集的降维程度最高.这主要是各数据集中标签的关联程度不同导致的, 如图4中的虚线所示, S.C-2数据集的样本平均标签数量要高于S.C-1和S.C-3数据集.换句话说, Label-Cluster算法对于标签关联度更大的数据趋向于得到更高的降维率.</p>
                </div>
                <div class="p1">
                    <p id="226">由于Remove-Smallest和Label-Cluster算法都是属于精确BMD算法, 因此在不同的数据集上在降维效果上是完全相同的.但由4.2.1节的分析可知, Label-Cluster较Remove-Smallest算法在时间复杂度上有较大优势, 表2和图5展示了2个算法运行的实验环境及在不同数据集中的运行时间对比.</p>
                </div>
                <div class="area_img" id="227">
                    <p class="img_tit"><b>表2 实验环境</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 The Experimental Environment</b></p>
                    <p class="img_note"></p>
                    <table id="227" border="1"><tr><td><br />Software/Hardware</td><td>Configuration</td></tr><tr><td><br />CPU</td><td>Intel Core i7-4790 (3.6 GHz) </td></tr><tr><td><br />Memory Size/GB</td><td>8</td></tr><tr><td><br />OS</td><td>Windows 7 professinal</td></tr><tr><td><br />Programing Platform</td><td>JDK1.8.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="228">从图5可知:本文提出的Label-Cluster相比Remove-Smallest算法在计算速度上有较大提高, 运行时间能减少90%左右, 且能完成标签矩阵的精确布尔分解, 并遵循“列利用条件”.特别是算法中引入了标签簇的思想, 对分解后的保留的标签看作是原有标签的一个聚类, 更利于解释后续分类的结果.</p>
                </div>
                <div class="area_img" id="229">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_229.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 Remove-Smallest算法和Label-Cluster算法运行时间对比" src="Detail/GetImg?filename=images/JFYZ201905012_229.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 Remove-Smallest算法和Label-Cluster算法运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_229.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The run time comparisons of Label-Cluster  and Remove-Smallest algorithm</p>

                </div>
                <h4 class="anchor-tag" id="230" name="230"><b>4.3 PFP-BMD实验分析</b></h4>
                <h4 class="anchor-tag" id="231" name="231">4.3.1 评价标准</h4>
                <div class="p1">
                    <p id="232">蛋白质功能预测作为一个多标签分类问题, 可以使用通用的多标签分类评价指标对模型的分类性能进行评估.如引言所述, 目前常用的蛋白质功能预测算法主要是针对小规模的功能标签子集进行训练和预测.文献<citation id="473" type="reference">[<a class="sup">9</a>]</citation>是一个针对大规模蛋白质功能标签集的多标签分类方法研究, 为了与此类方法进行对比, 本文亦采用了相同的评价标准, 即精确率-召回率曲线下面积 (area under the precision-recall curve, AUPRC) .AUPRC的值越接近于1, 则模型性能越好.</p>
                </div>
                <div class="p1">
                    <p id="233">在蛋白质功能预测数据集中大部分的功能标签注释的蛋白质数量很少, 这也就意味着对于大部分功能标签来说负例的数量会大大超过正例的数量.而本文更加关心的是正确预测出的正例 (蛋白质被某个功能标签所注释) , 而不是正确预测出负例 (蛋白质不被某个功能标签所注释) .据此, 本文采用PR (precision-recall) 曲线进行评价是合理的.</p>
                </div>
                <div class="p1">
                    <p id="234">当然, PR曲线仅仅是针对单个的标签来计算, 而对于蛋白质功能预测则要同时面对多个功能标签.因此, 为了评价蛋白质功能预测方法的整体性能, 文献<citation id="474" type="reference">[<a class="sup">9</a>]</citation>采用了2种AUPRC评价指标.</p>
                </div>
                <h4 class="anchor-tag" id="235" name="235">1) 平均PR曲线下的面积 (area under the average PR curve, <i>R</i><sub>MicroAUPRC</sub>) </h4>
                <div class="p1">
                    <p id="236">第1种获得多标签分类模型整体性能分数的方法就是通过将多标签分类问题转化为一个二值问题以构造出整体的PR曲线.假设一个二值分类器的输入是一个 (样本, 类别) 对, 输出是预测出该样本是否输入该类别, 一个排序分类器可以通过选择一个阈值而转化为一个二值分类器, 并且通过变化阈值则可得到一条PR曲线.</p>
                </div>
                <div class="p1">
                    <p id="237">对于给定的阈值, 对应的是PR空间中的一个点的坐标值为 (<i>prec</i>, <i>rec</i>) , 其定义为</p>
                </div>
                <div class="p1">
                    <p id="238" class="code-formula">
                        <mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Τ</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Τ</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>F</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>r</mi><mi>e</mi><mi>c</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Τ</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Τ</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>F</mi></mstyle><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="239">其中, <i>i</i>表示第<i>i</i>个标签, 通过变化阈值就可以得到1根平均PR曲线, 并将其曲线下的面积表示为<i>R</i><sub>MicroAUPRC</sub>.</p>
                </div>
                <h4 class="anchor-tag" id="240" name="240">2) PR曲线下的平均面积 (average area under the PR curves, <i>R</i><sub>MacroAUPRC</sub>) </h4>
                <div class="p1">
                    <p id="241">第2类方法是求单根PR曲线 (一个标签) 下面积的权值平均, 计算方法如下:</p>
                </div>
                <div class="p1">
                    <p id="242" class="code-formula">
                        <mathml id="242"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mrow><mtext>Μ</mtext><mtext>a</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext><mtext>A</mtext><mtext>U</mtext><mtext>Ρ</mtext><mtext>R</mtext><mtext>C</mtext></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>×</mo><mi>R</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="243">其中, <i>R</i><sub><i>i</i></sub>表示第<i>i</i>个标签的AUPRC值.当将所有<i>w</i><sub><i>i</i></sub>设置为1时, 计算结果表示为<i>R</i><sub>MacroAUPRC</sub>. 若对<i>w</i><sub><i>i</i></sub>以不同的策略取值, 计算结果表示为<i>R</i><sub>MacroWAUPRC</sub>. 在<i>R</i><sub>MacroWAUPRC</sub>的计算过程中, 对于权值<i>w</i><sub><i>i</i></sub>最直观的想法就是设置为1/|<i>S</i>|, 其中<i>S</i>是标签的数量.对于权值<i>w</i><sub><i>i</i></sub>第2种最自然的取值就是<i>w</i><sub><i>i</i></sub>=<mathml id="244"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>v</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>, 其中<i>v</i><sub><i>i</i></sub>表示类别<i>s</i><sub><i>i</i></sub>在数据集中出现的频率.第2种权值设置方法反映出标注样本越多的标签越重要.</p>
                </div>
                <div class="p1">
                    <p id="245">总的来说, 上述2种针对多标签分类的AUPRC值计算方法, <i>R</i><sub>MicroAUPRC</sub>实际是对AUPRC值求微平均, 因此可称其为PR曲线下面积微平均值 (micro average of AUPRC, <i>MICRO</i>-<i>AUPRC</i>) , 换句话说<i>R</i><sub>MicroAUPRC</sub>是在所有标签的混合中来评价模型.而<i>R</i><sub>MacroAUPRC</sub>实际是对AUPRC求宏平均, 可称其为PR曲线下面积宏平均值 (macro average of AUPRC, <i>MACRO</i>-<i>AUPRC</i>) , <i>R</i><sub>MacroWAUPRC</sub>则称为PR曲线下面积带权重宏平均值 (macro average of AUPRC with weight, <i>MACRO</i>-<i>WAUPRC</i>) , 它们可在一定程度上反映出各个独立标签的预测准确率.</p>
                </div>
                <h4 class="anchor-tag" id="246" name="246">4.3.2 对比算法及实验设置</h4>
                <div class="p1">
                    <p id="247">本节在蛋白质功能预测框架PFP-BMD中的精确BMD模块采用Label-Cluster算法, 多标签分类器模块采用多标签最近邻算法 (multi-label K-nearest neighbor, MLKNN) <citation id="477" type="reference"><link href="434" rel="bibliography" /><link href="436" rel="bibliography" /><sup>[<a class="sup">29</a>,<a class="sup">30</a>]</sup></citation>.对比算法使用文献<citation id="475" type="reference">[<a class="sup">26</a>]</citation>中的MLC-BMAD (multi-label classification using Boolean matrix decomposition) , 以及文献<citation id="476" type="reference">[<a class="sup">9</a>]</citation>中的3个层次多标签分类算法CLUS-HMC, CLUS-SC, CLUS-HSC.</p>
                </div>
                <div class="p1">
                    <p id="248">MLKNN是对传统<i>K</i>近邻算法在多标签分类中的一种改进, 本文在实验中设置MLKNN的邻居数目为10, 平滑因子为1.</p>
                </div>
                <div class="p1">
                    <p id="249">MLC-BMAD是一个专门针对大规模标签的多标签分类的方法.其思想与PFP-BMD非常类似, 也是先通过BMD对原标签进行降维, 预测之后再还原回原标签空间, 但MLC-BMaD中使用的是近似BMD算法, 因此需预先设定降维后的标签数量, 同时本文将MLC-BMAD在3个数据集上的标签关联阈值均设置为0.5.</p>
                </div>
                <div class="p1">
                    <p id="250">CLUS-HMC, CLUS-SC, CLUS-HSC是3个基于决策树的层次多标签分类器, 其中CLUS-HMC可同时学习所有的层次标签, CLUS-SC是为每个标签学习一棵独立的决策树, CLUS-HSC在CLUS-SC的基础上考虑了标签间的层次依赖.这一个算法在多篇对蛋白质功能预测的研究论文中被证明是一类性能较佳的算法, 特别是CLUS-HMC在数据集S.C中的实验结果均优于多个层次多标签分类器及CLUS-SC和CLUS-HSC.本文CLUS-HMC/HSC/SC算法的实验结果来自于文献<citation id="478" type="reference">[<a class="sup">9</a>]</citation>中.在文献<citation id="479" type="reference">[<a class="sup">9</a>]</citation>的实验中, CLUS-HMC/HSC/SC算法是在完整的S.C数据集中进行, 保留了功能标签间的层次关系, 且无需经过标签降维.尽管PFP-BMD需要经过标签降维, 但降维后的标签还能还原回原始标签, 因此它和CLUS-HMC/HSC/SC算法在预测结果的标签空间上是相同的.</p>
                </div>
                <div class="p1">
                    <p id="251">本文的多标签分类实验采用十折交叉验证, 实验评价指标使用了4.3.1节所述的<i>R</i><sub>MicroAUPRC</sub>, <i>R</i><sub>MacroAUPRC</sub>, <i>R</i><sub>MacroWAUPRC</sub> 3种PRC曲线下面积, 对于这3种评价标准, 评价标准的值越大, 预测准确率越高.</p>
                </div>
                <h4 class="anchor-tag" id="252" name="252">4.3.3 PFP-BMD与MLC-BMAD对比实验结果</h4>
                <div class="p1">
                    <p id="253">由于MLC-BMAD采用的是近似布尔矩阵分解算法进行降维, 因此本文分别在3个数据集中为其设置一个降维标签数量的范围, 最后与PFP-BMD在固定的降维标签数下进行对比.图 6展示了对比结果:</p>
                </div>
                <div class="area_img" id="254">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_254.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图 6 PFP-BMD与MLC-BMAD实验结果对比" src="Detail/GetImg?filename=images/JFYZ201905012_254.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图 6 PFP-BMD与MLC-BMAD实验结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_254.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 The experimental comparisons of PFP-BMD  and MLC-BMAD</p>

                </div>
                <div class="p1">
                    <p id="255">由图6可以看出, 随着设置的标签数量的增加, MLC-BMAD的3个评价标准值均在降低, 这是由于较小的降维后标签数量可使分类器获得更高的分类准确率.同时, 由于MLC-BMAD所使用的近似布尔矩阵分解算法不能够在分类后将标签矩阵精确还原, 这会大大损失还原后的分类准确率.因此对于S.C-1, S.C-2, S.C-3数据集, 尽管MLC-BMAD方法可设置较大范围的降维后标签数量, 但与PFP-BMD固定数量的降维标签相比, MLC-BMAD在3个评价标准<i>R</i><sub>MicroAUPRC</sub>, <i>R</i><sub>MacroAUPRC</sub>, <i>R</i><sub>MacroWAUPRC</sub>上所获得的值显著低于PFP-BMD.在数据集S.C-1上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值高于MLC- BMAD在各降维标签数量范围内平均值的31%, <i>R</i><sub>MacroAUPRC</sub>值高于MLC-BMAD的46%, <i>R</i><sub>MicroAUPRC</sub>值高于MLC-BMAD的20.4%;在数据集S.C-2上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值高于MLC-BMAD在各降维标签数量范围内平均值的1.2%, <i>R</i><sub>MacroAUPRC</sub>值高于MLC-BMAD的2.5%, <i>R</i><sub>MicroAUPRC</sub>值高于MLC- BMAD的50%;在数据集S.C-3上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值高于MLC-BMAD在各降维标签数量范围内平均值的4%, <i>R</i><sub>MacroAUPRC</sub>值高于MLC-BMAD的0.1%, <i>R</i><sub>MicroAUPRC</sub>值高于MLC-BMAD的34%.</p>
                </div>
                <h4 class="anchor-tag" id="256" name="256">4.3.4 PFP-BMD与CLUS-HMC/HSC/SC对比实验结果</h4>
                <div class="p1">
                    <p id="257">图7显示了PFP-BMD和CLUS-HMC /HSC/SC在3个数据集中的实验结果对比.</p>
                </div>
                <div class="p1">
                    <p id="258">由图7所示, 在将所有标签看作同等重要的评价指标<i>R</i><sub>MacroAUPRC</sub>上, PFP-BMD具有显著优势.分别与CLUS-HMC, CLUS-HSC, CLUS-SC相比:PFP-BMD在数据集S.C-1上的<i>R</i><sub>MacroAUPRC</sub>值提高了86.5%, 86.9%, 86.9%;在数据集S.C-2上的<i>R</i><sub>MacroAUPRC</sub>值提高了92.7%, 93.4%, 92.7%;在数据集S.C-3上的<i>R</i><sub>MacroAUPRC</sub>值提高了90.2%, 90%, 90%.这是由于<i>R</i><sub>MacroAUPRC</sub>的计算并不偏重于反映注释较多蛋白质的功能标签预测准确率, 而是针对所有标签预测准确性的平均.在PFP-BMD中, 注释蛋白质较少的功能标签在BMD之后更趋向于被降维删除, 但矩阵<b><i>B</i></b>表示了它和保留标签的关联关系, 可以通过矩阵还原较准确的得到它的预测结果, 以此提高了所有标签的平均预测准确率.同时, 由图7也可以看出, CLUS-HMC, CLUS-HS, CLUS-SC这3个算法在数据集S.C-1到S.C-3上获得了相似的<i>R</i><sub>MacroAUPRC</sub>值.PFP-BMD在<i>R</i><sub>MacroAUPRC</sub>上的优势说明PFP-BMD较CLUS-HMC/HSC/SC更有利于提高标注蛋白质少的标签的分类结果.</p>
                </div>
                <div class="area_img" id="259">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905012_259.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 PFP-BMD与CLUS-HMC/HSC/SC实验结果对比" src="Detail/GetImg?filename=images/JFYZ201905012_259.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 PFP-BMD与CLUS-HMC/HSC/SC实验结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905012_259.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 The experimental comparisons of PFP-BMD  and CLUS-HMC/HSC/SC</p>

                </div>
                <div class="p1">
                    <p id="260">同时, 对于考虑了标签标注频率的评价指标<i>R</i><sub>MicroAUPRC</sub>, PFP-BMD在3个数据集上的值略低于CLUS-HMC, 但在<i>R</i><sub>MacroWAUPRC</sub>评价标准上获得了和CLUS-HMC基本一致的结果, 且显著优于CLUS-HSC和CLUS-SC.在数据集S.C-1上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值和CLUS-HMC相比提高了1.3%, 和 CLUS-HSC相比提高了25%, 和CLUS-SC相比提高了26%;在数据集S.C-2上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值和CLUS-HMC相比降低了1.3%, 和CLUS-HSC相比提高了19%, 和CLUS-SC相比提高了19%;在数据集S.C-3上, PFP-BMD的<i>R</i><sub>MacroWAUPRC</sub>值和CLUS-HMC相比降低了1.5%, 而和CLUS-HSC相比提高了17.6%, 和CLUS-SC相比提高了 18.9%.CLUS-HMC在考虑了标签标注频率评价标准上的优势是由于这类层次多标签分类算法在分类过程中考虑了标签间的层次关系, 因此对于处于底层的标注频率较高的标签具有更好的预测准确率, 而标注频率较高的标签预测结果对<i>R</i><sub>MicroAUPRC</sub>和<i>R</i><sub>MacroWAUPRC</sub>的贡献较大.</p>
                </div>
                <div class="p1">
                    <p id="261">总结:从以上实验结果可以看出, 本文PFP-BMD的首先利用Label-Cluster算法完成对蛋白质功能标签矩阵的精确布尔矩阵分解, 能有效地降低后续多标签分类器的负担并提高多标签分类器的分类准确率, 最后再通过Label-Cluster算法得到的矩阵<b><i>B</i></b>可完整地将预测结果还原回原标签空间.这类LSDR的思想与直接对大规模功能标签进行分类的方法相比 (如CLUS-HMC/HSC/SC) , 由于在降维过程中趋向于舍去标注蛋白质少的功能标签, 但最后在还原过程可以对其进行完整的还原, 因此对于提高这一类功能标签的预测准确率具有明显优势.而与近似布尔矩阵分解的多标签分类方法相比 (如MLC-BMAD) , 尽管近似布尔矩阵可以任意指定降维数以获得更低的标签维数, 但近似还原同时也会一定程度地降低功能标签的预测准确率, 而Label-Cluster算法可以在不降低预测准确率的条件下对标签矩阵进行精确还原, 因此本文提出的方法在与MLC-BMAD的对比实验中仍取得了较好的结果.</p>
                </div>
                <h3 id="262" name="262" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="263">蛋白质功能注释是蛋白质组学最重要的研究内容, 通过各种可计算模型实现蛋白质功能的自动注释是当前生物信息学的一个研究热点.本文将蛋白质功能预测作为一个多标签分类问题进行研究, 针对蛋白质功能标签数量庞大的问题, 提出了一种基于布尔矩阵分解的蛋白质功能预测框架.并针对框架中的布尔矩阵分解模块, 提出了一种基于标签簇的精确布尔矩阵分解算法Label-Cluster.该算法利用标签关联矩阵<b><i>J</i></b>对标签矩阵进行标签簇构造, 每一个标签簇代表了一个原始标签的所有祖先标签及其本身的集合, 因此满足“列利用条件”约束.实验结果表明:Label-Cluster算法能够有效地完成大规模标签降维任务并且在运行速度上具有明显优势, 且应用该算法的蛋白质功能与PFP-BMD能够有效提高大规模功能标签的整体预测准确率, 特别对于提高注释蛋白质数量较少的功能标签预测准确率具有较大优势.</p>
                </div>
                <div class="p1">
                    <p id="264">同时, PFP-BMD中多标签分类器的选用对分类结果有较大影响, 尽管本文的实验部分仅选用了MLKNN一种分类器, 但PFP-BMD可支持多种分类器的应用, 因此PFP-BMD的实验效果还具有较大的提升潜力.目前, 随着网络应用的蓬勃发展, 使得更多的多标签分类场景中的实例倾向于与大量的标签相关联, 而本文所提出的PFP-BMD和Label-Cluster算法将蛋白质功能预测的过程作为一种通用的多标签分类场景进行处理, 因此本文的研究对于各领域中的大规模多标签分类问题也具有广泛的应用价值.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="378">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The FunCat, a functional annotation scheme for systematic classification of proteins from whole genomes">

                                <b>[1]</b>Ruepp A, Zollner A, Maier D, et al.The FunCat, a functional annotation scheme for systematic classification of proteins from whole genomes[J].Nucleic Acids Research, 2004, 32 (18) :5539- 5545
                            </a>
                        </p>
                        <p id="380">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The gene ontology( GO) database and informatics resource">

                                <b>[2]</b>Harris M A, Clark J, Ireland A, et al.The gene ontology (GO) database and informatics resource[J].Nucleic Acids Research, 2004, 32 (Suppl1) :258- 261
                            </a>
                        </p>
                        <p id="382">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1EF9ECC5AF2B4DAC8C7635B03C6818D3&amp;v=MjcwNjAzUHhBRlowTmZuaE52bVVibVRoN1MzcVFyQkZHZjdxVlRjNmNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6THkyeGE4PU5pZk9mYkxOYU5pNQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Cao Renzhi, Cheng Jianlin.Integrated protein function prediction by mining function associations, sequences, and protein-protein and gene-gene interaction networks[J].Methods, 2016, 93:84- 91
                            </a>
                        </p>
                        <p id="384">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gene Ontology Based Function Prediction of Human Protein Using Protein Sequence and Neighborhood Property of PPI Network">

                                <b>[4]</b>Saha S, Chatterjee P, Basu S, et al.Gene ontology based function prediction of human protein using protein sequence and neighborhood property of PPI network[C]//Proc of the 5th Int Conf on Frontiers in Intelligent Computing:Theory and Applications.Berlin:Springer, 2017:109- 118
                            </a>
                        </p>
                        <p id="386">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201608010&amp;v=MjUwMzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURoV3JyUEx5dlNkTEc0SDlmTXA0OUVaSVE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Fu Guangyuan, Yu Guoxian, Wang Jun, et al.Protein function prediction using positive and negative examples [J].Journal of Computer Research and Development, 2016, 53 (8) :1753- 1765 (in Chinese) (傅广垣, 余国先, 王峻, 等 .基于正负样例的蛋白质功能预测[J].计算机研究与发展, 2016, 53 (8) :1753- 1765) 
                            </a>
                        </p>
                        <p id="388">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM3CB89900D62181EC8AB73885E590A446&amp;v=MTM1MTZ6THkyeGE4PU5pZklZN0RMYk5uRnBvOUZFTzBORFhRNHVtVWJtMDE2UzNmcXFXY3djTExsUWI2WkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Zw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>Yu Guoxian, Rangwala H, Domeniconi C, et al.Predicting protein function using multiple kernels[J].IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2015, 12 (1) :219- 233
                            </a>
                        </p>
                        <p id="390">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Design and development of an efficient hierarchical approach for multi-label protein function prediction">

                                <b>[7]</b>Mohana P G, Chitra S.Design and development of an efficient hierarchical approach for multi-label protein function prediction[J].Biomedical Research, 2017 (Special Issue) :S370- S379
                            </a>
                        </p>
                        <p id="392">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15103100184024&amp;v=MjE1ODlIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRm9kYnhVPU5qN0Jhcks5SDlIUHJvOUZaZU1MREg0OW9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Vens C, Struyf J, Schietgat L, et al.Decision trees for hierarchical multi-label classification[J].Machine Learning, 2008, 73 (2) :185- 214
                            </a>
                        </p>
                        <p id="394">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A genetic algorithm for hierarchical multi-Label classification">

                                <b>[9]</b>Cerri R, Barros R C, de Carvalho, et al.A genetic algorithm for hierarchical multi-Label classification[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:250- 255
                            </a>
                        </p>
                        <p id="396">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hierarchical multi-label classification ant colony algorithm for protein function prediction">

                                <b>[10]</b>Otero F, Freitas A, Johnson C.A hierarchical multi-label classification ant colony algorithm for protein function prediction[J].Memetic Computing, 2010, 2 (3) :165- 181
                            </a>
                        </p>
                        <p id="398">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD120619001574&amp;v=MDMzMDduS3JpZlp1OXVGQ3ZoVXJmTUtWc1ROajdCYXJLNkh0Zk5wbzlGWmU0SUNCTTh6eFVTbURkOVNIN24zeEU5ZmJ2&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Rubin T, Chambers A, Smyth P, et al.Statistical topic models for multi-label document classification[J].Machine Learning, 2012, 88 (1) :157- 208
                            </a>
                        </p>
                        <p id="400">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast integration of heterogeneous data sources for predicting gene function with limited annotation">

                                <b>[12]</b>Mostafavi S, Morris Q.Fast integration of heterogeneous data sources for predicting gene function with limited annotation[J].Bioinformatics, 2010, 26 (14) :1759- 1765
                            </a>
                        </p>
                        <p id="402">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Protein function prediction by collective classification with explicit and implicit edges in protein-protein interaction networks">

                                <b>[13]</b>Xiong Wei, Liu Hiu, Guan Jihong, et al.Protein function prediction by collective classification with explicit and implicit edges in protein-protein interaction networks[J].BMC Bioinformatics, 2013, 14 (Suppl 12) :S4
                            </a>
                        </p>
                        <p id="404">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting indirect neighbours and topological weight to predict protein function from protein--protein interactions">

                                <b>[14]</b>Chua H, Sung W, Wong L.Exploiting indirect neighbours and topological weight to predict protein function from protein-protein interactions[J].Bioinformatics, 2008, 22 (3) :1623- 1630
                            </a>
                        </p>
                        <p id="406">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-label prediction via compressed sensing">

                                <b>[15]</b>Hsu D, Kakade S, Langford J, et al.Multi-label prediction via compressed sensing[C] //Proc of Int Conf on Neural Information Processing Systems.New York:Curran Associates Inc, 2009:772- 780
                            </a>
                        </p>
                        <p id="408">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500013325&amp;v=MTUyNDRxbzlGWk9vTUQzNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRm9kYnhVPU5pZkpaYks5SHRqTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Tai F, Lin H.Multi-label classification with principal label space transformation[J].Neural Computation, 2012, 24 (9) :2508- 2542
                            </a>
                        </p>
                        <p id="410">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-label output codes using canonical correlation analysis">

                                <b>[17]</b>Zhang Yi, Schneider J.Multi-label output codes using canonical correlation analysis[J].Journal of Machine Learning Research, 2012, 15 (1) :873- 882
                            </a>
                        </p>
                        <p id="412">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Muli-label text categorization with hidden components">

                                <b>[18]</b>Li Li, Zhang Longkai, Wang Houfeng.Muli-label text categorization with hidden components[C]//Proc of Conf on Empirical Methods in Natural Language Processing.New York:ACM, 2014:1816- 1821
                            </a>
                        </p>
                        <p id="414">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The landmark selection method for multiple output prediction">

                                <b>[19]</b>Balasubramanian K, Lebanon G.The landmark selection method for multiple output prediction[C] //Proc of the 29th Int Conf on Machine Learning.Madison, Wisconsin:Omnipress, 2012:283- 290
                            </a>
                        </p>
                        <p id="416">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient multi-label classification with many labels">

                                <b>[20]</b>Bi Wei, Kwok J T.Efficient multi-label classification with many labels[C/OL].//Proc of Int Conf on Machine Learning.2013 [2017-05-20].http://www.jmlr.org/
                            </a>
                        </p>
                        <p id="418">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15103100094712&amp;v=MDMyNDZadUh5am1VTHZKS0ZvZGJ4VT1OajdCYXJLOUg5SFBybzlGWk9JTEMzMDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Miettinen P.The Boolean column and column-row matrix decompositions[J].Data Mining and Knowledge Discovery, 2008, 17 (1) :39- 56
                            </a>
                        </p>
                        <p id="420">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The boolean basis problem and how to cover some polygons by rectangles">

                                <b>[22]</b>Lubiw A.The Boolean basis problem and how to cover some polygons by rectangles[J].SIAM Journal on Discrete Mathematics, 1990, 3 (1) :98- 115
                            </a>
                        </p>
                        <p id="422">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Matrix decomposition methods for data mining:Computational complexity and algorithms">

                                <b>[23]</b>Miettinen P.Matrix decomposition methods for data mining:Computational complexity and algorithms[D].Helsinki:University of Helsinki, 2009
                            </a>
                        </p>
                        <p id="424">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15121200311178&amp;v=MDQwMTBVPU5pZk9mYks5SDlQTnJZOUZaK29PRFhzeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGb2RieA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Belohlavek R, Trnecka M.From-below approximations in Boolean matrix factorization:Geometry and new algorithm[J].Journal of Computer &amp; System Sciences, 2013, 81 (8) :45- 52
                            </a>
                        </p>
                        <p id="426">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relative-error cur matrix decompositions">

                                <b>[25]</b>Drineas P, Mahoney M W, Muthukrishnan S.Relative-error $CUR$ matrix decompositions[J].SIAM Journal on Matrix Analysis &amp; Applications, 2007, 30 (2) :844- 881
                            </a>
                        </p>
                        <p id="428">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-label classification using boolean matrix decomposition">

                                <b>[26]</b>Wicker J, Pfahringer B, Kramer S.Multi-label classification using Boolean matrix decomposition[C]//Proc of the 27th Annual ACM Symp on Applied Computing.New York:ACM, 2012:179- 186
                            </a>
                        </p>
                        <p id="430">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved algorithms for exact and approximate Boolean matrix decomposition">

                                <b>[27]</b>Sun Yuan, Ye Shiwei, Sun Yi, et al.Improved algorithms for exact and approximate Boolean matrix decomposition[C]//Proc of the 2nd IEEE Int Conf on Data Science and Advanced Analytics.Piscataway, NJ:IEEE, 2015:1- 10
                            </a>
                        </p>
                        <p id="432">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semiring rank: Boolean rank and nonnegative rank factorizations">

                                <b>[28]</b>Gregory D A, Pullman N J.Semiring rank:Boolean rank and nonnegative rank factorizations[J].Journal of Combinatorics, Information &amp; System Sciences, 1983, 8 (3) :223- 233
                            </a>
                        </p>
                        <p id="434">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739502&amp;v=MTUxNjdPZmJLN0h0RE5xWTlGWStnR0NYdzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRm9kYnhVPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b>Zhang Minling, Zhou Zhihua.ML-KNN:A lazy learning approach to multi-label learning[J].Pattern Recognition, 2007, 40 (7) :2038- 2048
                            </a>
                        </p>
                        <p id="436">
                            <a id="bibliography_30" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201008012&amp;v=MDUwNzZxQnRHRnJDVVJMT2VaZVJxRmlEaFdyclBMejdCZHJHNEg5SE1wNDlFWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[30]</b>Zheng Wei, Wang Chaokun, Liu Zhang, et al.A multi-label classification algorithm based on random walk model[J].Chinese Journal of Computers, 2010, 33 (8) :1418- 1426 (in Chinese) (郑伟, 王朝坤, 刘璋, 等.一种基于随机游走模型的多标签分类算法[J].计算机学报, 2010, 33 (8) :1418- 1426) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201905012" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905012&amp;v=MzAzNDhaZVJxRmlEaFdyck1MeXZTZExHNEg5ak1xbzlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4aWR1NEQvRWNKQjZRNFJOdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

