

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127116006863750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJFYZ201911009%26RESULT%3d1%26SIGN%3diFLTpvahN5fjDY%252f7pmE2B9xQOa0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911009&amp;v=MTMxODFyQ1VSTE9lWmVSc0Z5em1WTHJKTHl2U2RMRzRIOWpOcm85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#73" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="&lt;b&gt;1.1 特定方面情感分析&lt;/b&gt;"><b>1.1 特定方面情感分析</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;1.2 注意力机制&lt;/b&gt;"><b>1.2 注意力机制</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;2 问题描述与方法概论&lt;/b&gt; "><b>2 问题描述与方法概论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="&lt;b&gt;2.1 任务定义&lt;/b&gt;"><b>2.1 任务定义</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;2.2 方法概述&lt;/b&gt;"><b>2.2 方法概述</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;2.3 特定方面注意力机制&lt;/b&gt;"><b>2.3 特定方面注意力机制</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;2.4 上下文自注意力机制&lt;/b&gt;"><b>2.4 上下文自注意力机制</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;2.5 多头注意力机制下的双注意力&lt;/b&gt;"><b>2.5 多头注意力机制下的双注意力</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="&lt;b&gt;3 面向双注意力网络的特定方面情感分析模型(DANSA&lt;/b&gt;) "><b>3 面向双注意力网络的特定方面情感分析模型(DANSA</b>)</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#123" data-title="&lt;b&gt;3.1 模型构建&lt;/b&gt;"><b>3.1 模型构建</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;3.2 模型训练&lt;/b&gt;"><b>3.2 模型训练</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="&lt;b&gt;4 实  验&lt;/b&gt; "><b>4 实  验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#142" data-title="&lt;b&gt;4.1 实验数据&lt;/b&gt;"><b>4.1 实验数据</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;4.2 超参数&lt;/b&gt;"><b>4.2 超参数</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;4.3 对比实验&lt;/b&gt;"><b>4.3 对比实验</b></a></li>
                                                <li><a href="#162" data-title="&lt;b&gt;4.4 DANSA模型分析&lt;/b&gt;"><b>4.4 DANSA模型分析</b></a></li>
                                                <li><a href="#177" data-title="&lt;b&gt;4.5 注意力可视化&lt;/b&gt;"><b>4.5 注意力可视化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#184" data-title="&lt;b&gt;5 总  结&lt;/b&gt; "><b>5 总  结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="&lt;b&gt;表1 分句形式&lt;/b&gt;"><b>表1 分句形式</b></a></li>
                                                <li><a href="#105" data-title="图1 特定方面注意力机制">图1 特定方面注意力机制</a></li>
                                                <li><a href="#109" data-title="图2 上下文自注意力机制">图2 上下文自注意力机制</a></li>
                                                <li><a href="#113" data-title="图3 线性变换例子">图3 线性变换例子</a></li>
                                                <li><a href="#117" data-title="图4 DANSA模型框架">图4 DANSA模型框架</a></li>
                                                <li><a href="#125" data-title="图5 线性变换过程">图5 线性变换过程</a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;表2 实验使用数据统计&lt;/b&gt;"><b>表2 实验使用数据统计</b></a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;表3 不同模型的准确率&lt;/b&gt;"><b>表3 不同模型的准确率</b></a></li>
                                                <li><a href="#165" data-title="&lt;b&gt;表4 不同模型完成1次迭代的训练时间&lt;/b&gt;"><b>表4 不同模型完成1次迭代的训练时间</b></a></li>
                                                <li><a href="#170" data-title="图6 不同线性映射次数的准确率">图6 不同线性映射次数的准确率</a></li>
                                                <li><a href="#174" data-title="图7 不同注意力类型的准确率">图7 不同注意力类型的准确率</a></li>
                                                <li><a href="#175" data-title="图8 不同注意力类型的训练时间">图8 不同注意力类型的训练时间</a></li>
                                                <li><a href="#179" data-title="图9 上下文自注意力权重">图9 上下文自注意力权重</a></li>
                                                <li><a href="#182" data-title="&lt;b&gt;表5 特定方面注意力权重&lt;/b&gt;"><b>表5 特定方面注意力权重</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="222">


                                    <a id="bibliography_1" title="Medhat W,Hassan A,Korashay H.Sentiment analysis algorithms and applications:A survey[J].Ain Shams Engineering Journal,2014,5(4):1093- 1113" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700305623&amp;v=MDAxMjBIeWptVUwzSUpGMFRieE09TmlmT2ZiSzhIdGZOcUk5Rlorc0tDbjQ2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Medhat W,Hassan A,Korashay H.Sentiment analysis algorithms and applications:A survey[J].Ain Shams Engineering Journal,2014,5(4):1093- 1113
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_2" title="Wang Zhongyuan,Cheng Jianpeng,Wang Haixun,et al.Short text understanding:A survey[J].Journal of Computer Research and Development,2016,53(2):262- 269 (in Chinese)(王仲远,程健鹏,王海勋,等.短文本理解研究[J].计算机研究与发展,2016,53(2):262- 269)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MDM4NDJ2U2RMRzRIOWZNclk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em1WTHJKTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Wang Zhongyuan,Cheng Jianpeng,Wang Haixun,et al.Short text understanding:A survey[J].Journal of Computer Research and Development,2016,53(2):262- 269 (in Chinese)(王仲远,程健鹏,王海勋,等.短文本理解研究[J].计算机研究与发展,2016,53(2):262- 269)
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_3" title="Liang Bin,Liu Quan,Xu Jin,et al.Aspect-based sentiment analysis based on multi-attention CNN[J].Journal of Computer Research and Development,2017,54(8):1724- 1735 (in Chinese)(梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分[J].计算机研究与发展,2017,54(8):1724- 1735)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MDkzMTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXptVkxySkx5dlNkTEc0SDliTXA0OUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Liang Bin,Liu Quan,Xu Jin,et al.Aspect-based sentiment analysis based on multi-attention CNN[J].Journal of Computer Research and Development,2017,54(8):1724- 1735 (in Chinese)(梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分[J].计算机研究与发展,2017,54(8):1724- 1735)
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_4" title="Zhu Yonghua,Gao Xun,Zhang Weilin,et al.A bi-directional LSTM-CNN model with attention for aspect-level text classification[J].Future Internet,2018,10(12):116- 127" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A bi-directional LSTM-CNN model with attention for aspect-level text classification">
                                        <b>[4]</b>
                                        Zhu Yonghua,Gao Xun,Zhang Weilin,et al.A bi-directional LSTM-CNN model with attention for aspect-level text classification[J].Future Internet,2018,10(12):116- 127
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_5" title="Quan Wei,Chen Zheng,Gao Jianliang,et al.Comparative study of CNN and LSTM based attention neural networks for aspect-level opinion mining[C] //Proc of IEEE Int Conf on Big Data 2018.Piscataway,NJ:IEEE,2018:2141- 2150" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparative study of CNN and LSTM based attention neural networks for aspect-level opinion mining">
                                        <b>[5]</b>
                                        Quan Wei,Chen Zheng,Gao Jianliang,et al.Comparative study of CNN and LSTM based attention neural networks for aspect-level opinion mining[C] //Proc of IEEE Int Conf on Big Data 2018.Piscataway,NJ:IEEE,2018:2141- 2150
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_6" title="Lin Chenghua,He Yulan,Everson R,et al.Weakly supervised joint sentiment-topic detection from text[J].IEEE Transactions on Knowledge and Data Engineering,2012,24(6):1134- 1145" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weakly supervised joint sentiment-topic detection from text">
                                        <b>[6]</b>
                                        Lin Chenghua,He Yulan,Everson R,et al.Weakly supervised joint sentiment-topic detection from text[J].IEEE Transactions on Knowledge and Data Engineering,2012,24(6):1134- 1145
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_7" title="Kiritchenko S,Zhu Xiaodan,Cherry C,et al.Detecting aspects and sentiment in customer reviews[C] //Proc of the 8th Int Workshop on Semantic Evaluation.Stroudsburg,PA:ACL,2014:437- 442" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting aspects and sentiment in customer reviews">
                                        <b>[7]</b>
                                        Kiritchenko S,Zhu Xiaodan,Cherry C,et al.Detecting aspects and sentiment in customer reviews[C] //Proc of the 8th Int Workshop on Semantic Evaluation.Stroudsburg,PA:ACL,2014:437- 442
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_8" title="Chen Long,Guan Ziyu,He Jinhong,et al.A survey on sentiment classification[J].Journal of Computer Research and Development,2017,54(6):1150- 1170 (in Chinese)(陈龙,管子玉,何金红,等.情感分类研究进展[J].计算机研究与发展,2017,54(6):1150- 1170)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201706003&amp;v=MzE5NjdlWmVSc0Z5em1WTHJKTHl2U2RMRzRIOWJNcVk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Chen Long,Guan Ziyu,He Jinhong,et al.A survey on sentiment classification[J].Journal of Computer Research and Development,2017,54(6):1150- 1170 (in Chinese)(陈龙,管子玉,何金红,等.情感分类研究进展[J].计算机研究与发展,2017,54(6):1150- 1170)
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_9" title="Xue Wei,Li Tao.Aspect based sentiment analysis with gated convolutional networks[C] //Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2018:2514- 2523" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aspect Based Sentiment Analysis with Gated Convolutional Networks">
                                        <b>[9]</b>
                                        Xue Wei,Li Tao.Aspect based sentiment analysis with gated convolutional networks[C] //Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2018:2514- 2523
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_10" title="Piao Guangyuan,Breslin J.Financial aspect and sentiment predictions with deep neural networks[C] //Proc of the 2018 World Wide Web Conf.New York:ACM,2018:1973- 1977" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Financial aspect and sentiment predictions with deep neural networks">
                                        <b>[10]</b>
                                        Piao Guangyuan,Breslin J.Financial aspect and sentiment predictions with deep neural networks[C] //Proc of the 2018 World Wide Web Conf.New York:ACM,2018:1973- 1977
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_11" title="Ma Yukun,Peng Haiyun,Cambria E.Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:5876- 5883" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM">
                                        <b>[11]</b>
                                        Ma Yukun,Peng Haiyun,Cambria E.Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:5876- 5883
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_12" title="Cai Guoyong,Li Hongyu.Joint attention LSTM network for aspect-level sentiment analysis[C] //Proc of the 24th China Conf on Information Retrieval (CCIR 2018).Los Alamitos,CA:IEEE Computer Society,2018:147- 157" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint attention LSTM network for aspect-level sentiment analysis">
                                        <b>[12]</b>
                                        Cai Guoyong,Li Hongyu.Joint attention LSTM network for aspect-level sentiment analysis[C] //Proc of the 24th China Conf on Information Retrieval (CCIR 2018).Los Alamitos,CA:IEEE Computer Society,2018:147- 157
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_13" title="Gu Shuqin,Zhang Lipeng,Hou Yuexian,et al.A position-aware bidirectional attention network for aspect-level sentiment analysis[C] //Proc of the 27th Int Conf on Computation Linguistics.Stroudsburg,PA:ACL,2018:774- 784" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A position-aware bidirectional attention network for aspect-level sentiment analysis">
                                        <b>[13]</b>
                                        Gu Shuqin,Zhang Lipeng,Hou Yuexian,et al.A position-aware bidirectional attention network for aspect-level sentiment analysis[C] //Proc of the 27th Int Conf on Computation Linguistics.Stroudsburg,PA:ACL,2018:774- 784
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_14" title="He Ruidan,Lee W S,Ng H T,et al.Effective attention modeling for aspect-level sentiment classification[C] //Proc of the 27th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2018:1121- 1131" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Effective attention modeling for aspect-level sentiment classification">
                                        <b>[14]</b>
                                        He Ruidan,Lee W S,Ng H T,et al.Effective attention modeling for aspect-level sentiment classification[C] //Proc of the 27th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2018:1121- 1131
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_15" title="Yi Qian,Liu Jie,Zhang Guixuan,et al.Aspect-level sentiment classification with conv-attention mechanism[C] //Proc of the 25th Int Conf.Los Alamitos,CA:IEEE Computer Society,2018:231- 243" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aspect-level sentiment classification with conv-attention mechanism">
                                        <b>[15]</b>
                                        Yi Qian,Liu Jie,Zhang Guixuan,et al.Aspect-level sentiment classification with conv-attention mechanism[C] //Proc of the 25th Int Conf.Los Alamitos,CA:IEEE Computer Society,2018:231- 243
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_16" title="Mnih V,Heess N,Graves A,et al.Recurrent models of visual attention[C] //Proc of the 28th Conf on Neural Information Processing Systems(NIPS2014).Cambridge,MA:MIT Press,2014:2204- 2212" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent models of visual attention">
                                        <b>[16]</b>
                                        Mnih V,Heess N,Graves A,et al.Recurrent models of visual attention[C] //Proc of the 28th Conf on Neural Information Processing Systems(NIPS2014).Cambridge,MA:MIT Press,2014:2204- 2212
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_17" title="Cheng Yong,Shen Shiqi,He Zhongjun,et,al.Agreement-based joint training for bidirectional attention-based neural machine translation[C] //Proc of the 25th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2016:2761- 2767" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Agreement-based joint training for bidirectional attention-based neural machine translation">
                                        <b>[17]</b>
                                        Cheng Yong,Shen Shiqi,He Zhongjun,et,al.Agreement-based joint training for bidirectional attention-based neural machine translation[C] //Proc of the 25th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2016:2761- 2767
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_18" title="Yin Wenpeng,Sch&#252;tze H,Xiang Bing,et al.ABCNN:Attention-based convolutional neural network for modeling sentence pairs[J].Association for Computational Linguistics,2016,4:259- 272" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-based convolutional neural network for modeling sentence pairs">
                                        <b>[18]</b>
                                        Yin Wenpeng,Sch&#252;tze H,Xiang Bing,et al.ABCNN:Attention-based convolutional neural network for modeling sentence pairs[J].Association for Computational Linguistics,2016,4:259- 272
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_19" title="Vaswani A,Shazeer N,Parmar N,et al.Attention is all you need[C] //Proc of the 31st Conf on Neural Information Processing Systems(NIPS2017).Cambridge,MA:MIT Press,2017:6000- 6010" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">
                                        <b>[19]</b>
                                        Vaswani A,Shazeer N,Parmar N,et al.Attention is all you need[C] //Proc of the 31st Conf on Neural Information Processing Systems(NIPS2017).Cambridge,MA:MIT Press,2017:6000- 6010
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_20" title="Fan Feifan,Feng Yansong,Zhao Dongyan.Multi-grained attention network for aspect-level sentiment classification[C] //Proc of the 2018 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2018:3433- 3442" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-grained attention network for aspect-level sentiment classification">
                                        <b>[20]</b>
                                        Fan Feifan,Feng Yansong,Zhao Dongyan.Multi-grained attention network for aspect-level sentiment classification[C] //Proc of the 2018 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2018:3433- 3442
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_21" title="Wang Xinyi,Xu Guangluan,Zhang Jingyuan,et al.Syntax-directed hybrid attention network for aspect-level sentiment analysis[J].IEEE Access,2019,7:5014- 5025" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Syntax-directed hybrid attention network for aspect-level sentiment analysis">
                                        <b>[21]</b>
                                        Wang Xinyi,Xu Guangluan,Zhang Jingyuan,et al.Syntax-directed hybrid attention network for aspect-level sentiment analysis[J].IEEE Access,2019,7:5014- 5025
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_22" title="Pennington J,Socher R,Manning C D.Glove:Global vectors for word representation[C] //Proc of the 2014 Conf on Empircal Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1532- 1543" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global vectors for word representation">
                                        <b>[22]</b>
                                        Pennington J,Socher R,Manning C D.Glove:Global vectors for word representation[C] //Proc of the 2014 Conf on Empircal Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1532- 1543
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_23" title="Kim Y.Convolutional neural networks for sentence classification[C] //Proc of the 2014 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1746- 1751" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[23]</b>
                                        Kim Y.Convolutional neural networks for sentence classification[C] //Proc of the 2014 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1746- 1751
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_24" title="Wang Linlin,Cao Zhu,de Melo G,et al.Relation classification via multi-level attention CNNs[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2016:1298- 1307" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relation classification via multi-level attention cnns">
                                        <b>[24]</b>
                                        Wang Linlin,Cao Zhu,de Melo G,et al.Relation classification via multi-level attention CNNs[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2016:1298- 1307
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_25" title="Tang Duyu,Qin Bing,Feng Xiaocheng,et al.Effective LSTMs for target-dependent sentiment classification[C] //Proc of the 26th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2016:3298- 3307" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Effective LSTMs for target-dependent sentiment classification">
                                        <b>[25]</b>
                                        Tang Duyu,Qin Bing,Feng Xiaocheng,et al.Effective LSTMs for target-dependent sentiment classification[C] //Proc of the 26th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2016:3298- 3307
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_26" title="Wang Yequan,Huang Minlie,Zhu Xiaoyan,et al.Attention-based LSTM for aspect-level sentiment classification[C] //Proc of the 2016 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2016:606- 615" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attentionbased LSTM for aspect-level sentiment classification">
                                        <b>[26]</b>
                                        Wang Yequan,Huang Minlie,Zhu Xiaoyan,et al.Attention-based LSTM for aspect-level sentiment classification[C] //Proc of the 2016 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2016:606- 615
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_27" title="Ma Dehong,Li Sujian,Zhang Xiaodong,et al.Interactive attention networks for aspect-level sentiment classification[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017:4068- 4074" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive attention networks for aspect-level sentiment classification">
                                        <b>[27]</b>
                                        Ma Dehong,Li Sujian,Zhang Xiaodong,et al.Interactive attention networks for aspect-level sentiment classification[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017:4068- 4074
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(11),2384-2395 DOI:10.7544/issn1000-1239.2019.20180823            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向双注意力网络的特定方面情感分析模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E5%B0%8F%E5%A9%89&amp;code=35523278&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙小婉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%8B%B1&amp;code=07668928&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王英</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E9%91%AB&amp;code=07668880&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王鑫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E7%8E%89%E4%B8%9C&amp;code=42454985&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙玉东</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%89%E6%9E%97%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=1046463&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吉林大学软件学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%AC%A6%E5%8F%B7%E8%AE%A1%E7%AE%97%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%B7%A5%E7%A8%8B%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%90%89%E6%9E%97%E5%A4%A7%E5%AD%A6)&amp;code=0205988&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">符号计算与知识工程教育部重点实验室(吉林大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%89%E6%9E%97%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吉林大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%98%A5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长春工程学院计算机技术与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>特定方面情感分析已经成为自然语言处理领域的研究热点,其通过学习文本上下文的信息判别文本中特定方面的情感极性,可以更加有效地帮助人们了解用户对不同方面的情感表达.当前,将注意力机制和神经网络相结合的模型在解决特定方面情感分析任务时大多仅考虑单一层面的注意力信息,并且卷积神经网络无法获取全局结构信息、循环神经网络训练时间过长且单词间的依赖程度随着距离增加而逐渐减弱.针对上述问题,提出一种面向双注意力网络的特定方面情感分析(dual-attention networks for aspect-level sentiment analysis, DANSA)模型.首先,引入多头注意力机制,通过对输入进行多次不同的线性变换操作,获取更全面的注意力信息,同时,多头注意力机制可以实现并行化计算,保证了DANSA的训练速度.其次,DANSA引入自注意力机制,通过计算输入中每个单词与其他所有单词的注意力得分获取全局结构信息,并且单词间的依赖程度不会受到时间和句子长度的影响.最后,融合上下文自注意力信息与特定方面单词注意力信息,共同作为特定方面情感预测的依据,最终实现特定方面情感极性的预测.相比结合注意力机制的神经网络,DANSA弥补了注意力信息单一问题,不仅可以有效获取全局结构信息,还能够实现并行化计算,大大降低了训练时间.在SemEval2014数据集和Twitter数据集上进行实验,DANSA获得了更好的分类效果,进一步证明了DANSA的有效性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%AE%9A%E6%96%B9%E9%9D%A2%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特定方面情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多头注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双注意力网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自然语言处理;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *王英（wangying2010@jlu.edu.cn);
                                </span>
                                <span>
                                    孙小婉,sunxw17@mails.jlu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目（61872161,61602057,61976103）;</span>
                                <span>吉林省科技发展计划项目（2018101328JC）;</span>
                                <span>吉林省科技厅优秀青年人才基金项目（20170520059JH）;</span>
                                <span>吉林省技术攻关项目（20190302029GX）;</span>
                                <span>吉林省发改委项目（2019C053-8）;</span>
                                <span>吉林省教育厅科研项目（JJKH20191257KJ);</span>
                    </p>
            </div>
                    <h1><b>Aspect-Based Sentiment Analysis Model Based on Dual-Attention Networks</b></h1>
                    <h2>
                    <span>Sun Xiaowan</span>
                    <span>Wang Ying</span>
                    <span>Wang Xin</span>
                    <span>Sun Yudong</span>
            </h2>
                    <h2>
                    <span>College of Software, Jilin University</span>
                    <span>Key Laboratory of Symbol Computation and Knowledge Engineering(Jilin University), Ministry of Education</span>
                    <span>College of Computer Science and Technology, Jilin University</span>
                    <span>College of Computer Technology and Engineering, Changchun Institute of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aspect-based sentiment analysis has become one of the hottest research issues in the field of natural language processing. It identifies the aspect sentiment polarity of texts by learning from context information, which can effectively help people understand the sentiment expression on different aspects. Currently, the most models with combining attention mechanism and neural network only consider a single level of attention information. When solving aspect-based sentiment analysis tasks, theses models have a lot of limitations. The convolutional neural network cannot capture the global structural information. For the recurrent neural network, the training time-consuming is too long, and the degree of dependence between words gradually decreases as the distance increases. To solve the above problems, we propose the dual-attention networks for aspect-level sentiment analysis(DANSA) model. Firstly, by introducing the multi-head attention mechanism, the model performs multiple linear transformation on the input to obtain more comprehensive attention information, which can realize parallel computing and enhance the training speed. Secondly, the self-attention mechanism is introduced to obtain global structural information by calculating the attention scores between each word and all other words in the input, and the degree of dependence between words is not affected by time and sentence length. Finally, the model makes a prediction of aspects sentiment polarity by combining the context self-attention information and the aspect of the word attention information. The extensive experiments on the SemEval2014 datasets and the Twitter datasets show that the DANSA achieves better classification performance, which further demonstrates the validity of DANSA.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=aspect-based%20sentiment%20analysis(ABSA)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">aspect-based sentiment analysis(ABSA);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=self-attention&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">self-attention;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-head%20attention&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-head attention;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dual-attention%20networks&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dual-attention networks;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=natural%20language%20processing(NLP)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">natural language processing(NLP);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Sun Xiaowan,born in 1989.Master candidate.Her main research interests include sentiment analysis,machine learning,and natural language processing.<image id="308" type="formula" href="images/JFYZ201911009_30800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Ying,born in 1981.PhD,associate professor.Senior member of CCF.Her main research interests include machine learning,social network,data mining and search engine.<image id="309" type="formula" href="images/JFYZ201911009_30900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Xin,born in 1981.PhD,associate professor.Senior member of CCF.His main research interests include machine learning,information retrieval and social computing.<image id="310" type="formula" href="images/JFYZ201911009_31000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Sun Yudong,born in 1994.Master candidate.His main research interests include recommendation system and network representation learning.<image id="311" type="formula" href="images/JFYZ201911009_31100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-11</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61872161,61602057,61976103);</span>
                                <span>the Project of Science and Technology Development Plan of Jilin Province(2018101328JC);</span>
                                <span>the Science and Technology Department Excellent Youth Talent Foundation of Jilin Province(20170520059JH);</span>
                                <span>the Project of Technical Tackle-Key-Problem of Jilin Province(20190302029GX);</span>
                                <span>the Project of Development and Reform of Jilin Province(2019C053-8);</span>
                                <span>the Scientific Research Item of Jilin Provincial Education Department(JJKH20191257KJ);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="65">社交网络的迅猛发展为人们提供了发表和分享个人言论的广阔平台,各种网络数据迅速膨胀,越来越多的人在网络上发表意见和表达情感.如何利用自然语言处理(natural language processing, NLP)技术分析社交网络短文本的情感倾向,已经成为研究人员关注的热点<citation id="276" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="66">用户在针对某实体发表观点时,除了在评论中给出总体评价外,通常也会针对该实体的多个方面发表观点评论.特定方面情感分析(aspect-based sentiment analysis, ABSA)作为情感分析的重要子任务之一,可以针对不同的方面挖掘用户更细腻更具体的情感表述<citation id="277" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.例如句子“The design of space is good but the service is horrible”,对于特定方面“space”是积极情感,而对于特定方面“service”是消极情感.与普通情感分析不同,特定方面情感分析需要判断句子中不同方面的情感极性,这不仅依赖于文本的上下文信息,同时也要考虑不同方面的情感信息.因此,在同一句子中针对不同特定方面可能会出现完全相反的情感极性,可见特定方面情感极性的分析可以更加有效地帮助人们了解用户对不同方面的情感表达.</p>
                </div>
                <div class="p1">
                    <p id="67">近年来,深度学习已在NLP领域取得了令人瞩目的成功.同时,结合注意力机制(attention mech-anism)的神经网络模型在特定方面情感分析任务中取得了比以往方法更好的效果.梁斌等人<citation id="278" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出一种基于多注意力的卷积神经网络(convolutional neural network, CNN),利用词向量注意力机制、词性注意力机制和位置注意力机制与卷积神经网络结合,使模型在不需要依存句法分析等外部知识的情况下,有效识别特定方面的情感极性.Zhu等人<citation id="279" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出使用双向长短期记忆网络(long short-term memory, LSTM)构建句子的长期记忆,然后使用CNN从记忆中提取注意力以获得更具体的句子表示,该方法使用特定方面嵌入表示目标信息,取得较好的分类效果.结合注意力机制的神经网络可以在训练过程中高度关注特定方面的特征,并可以有效针对不同特定方面调整神经网络的参数,进而挖掘更多的隐藏特征.</p>
                </div>
                <div class="p1">
                    <p id="68">目前,结合注意力机制的神经网络主要包括基于注意力机制的卷积神经网络(CNN)和基于注意力机制的循环神经网络(recurrent neural network, RNN)<citation id="280" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.CNN在卷积层使用滤波器抽取文本特征,只能获取滤波器窗口内单词间的依赖关系,无法获取句子中所有单词间的依赖关系,进而无法获取整体结构信息.在图像处理领域,相邻像素点之间往往存在很大的相关程度,但在NLP领域,由于修饰词、语法规则和表达习惯的影响,使得相邻单词的相关程度并不高.RNN及其衍生网络,例如LSTM,GRU(gated recurrent unit)在NLP领域应用广泛,RNN的原理是基于“人的认知是基于过往经验和记忆”这一观点提出,与CNN不同,RNN不仅考虑前一时刻的输入,而且赋予网络对前面内容的记忆功能,但RNN及其衍生网络这类序列模型,难以实现并行计算,训练时间过慢,并且句子中单词间的依赖程度会随着距离增加而减弱.此外,CNN和RNN这2种结合注意力机制的神经网络模型,都使用单一注意力模式,即模型只进行单次注意力计算,导致模型无法对句中单词间的依赖关系实现深层次抽取.</p>
                </div>
                <div class="p1">
                    <p id="69">针对上述问题,本文提出面向双注意力网络的特定方面情感分析模型(dual-attention networks for aspect-level sentiment analysis, DANSA),主要贡献有3方面:</p>
                </div>
                <div class="p1">
                    <p id="70">1) 提出融合上下文自注意力机制和特定方面注意力机制的多头双注意力网络模型,不仅实现了大规模并行计算,大大降低了模型的训练时间,而且能够抽取文本全局结构信息和特定方面与文本的依赖关系.</p>
                </div>
                <div class="p1">
                    <p id="71">2) 提出将多头注意力机制应用在特定方面情感分析任务中,学习文本在不同线性变换下的注意力表示,能够更全面、更深层次地理解句中单词之间的依赖关系,更好地解决特定方面情感分析问题.</p>
                </div>
                <div class="p1">
                    <p id="72">3) 在SemEva2014数据集和Twitter数据集上进行实验,相比于传统神经网络和基于注意力机制的神经网络,DANSA取得了更好的情感分类效果,进一步验证了DANSA的有效性.</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag"><b>1 相关工作</b></h3>
                <h4 class="anchor-tag" id="74" name="74"><b>1.1 特定方面情感分析</b></h4>
                <div class="p1">
                    <p id="75">特定方面情感分析是细粒度的情感分析,对特定方面情感极性的挖掘能够帮助人们做出更正确的决策<citation id="281" type="reference"><link href="232" rel="bibliography" /><link href="234" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="76">在过去的研究中,特定方面情感分析方法主要是基于情感字典和机器学习的传统方法<citation id="282" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.这些方法需要对输入文本进行大量的预处理和复杂的特征工程,以及例如依存关系分析等外部知识.模型的优劣,很大程度上取决于人工设计和先验知识,耗时耗力且模型推广能力差.</p>
                </div>
                <div class="p1">
                    <p id="77">近年来,深度学习技术在NLP各类任务中取得了重大突破,在特定方面情感分析领域也取得了比传统机器学习方法更好的效果.Xue等人<citation id="283" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出基于卷积神经网络和门控制的模型,利用Gated Tanh-ReLU单元根据给定的特定方面或实体选择性地输出情感极性,在训练速度和分类准确度上都取得了较好的效果.Piao等人<citation id="284" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出使用CNN和RNN联合解决金融领域中的特定方面情感极性预测问题,利用Rigde回归和特定方面预测投票策略,不依赖任何的手工标注.Ma等人<citation id="285" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出在使用Senti-LSTM模型解决特定方面情感分析问题时,联合情感常识共同对模型进行训练并得到更好的分类效果.这类基于深度神经网络的模型与传统机器学习方法相比,大大降低了预处理和特征工程的工作量,但仍需要结合一些如依存句法分析、依存关系树等外部知识.</p>
                </div>
                <div class="p1">
                    <p id="78">目前,将注意力机制与神经网络相结合的方法,已经成为特定方面情感分析问题的主流方法.Cai等人<citation id="286" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出将注意力机制与LSTM结合进行特定方面情感的层次提取,同时关注情感术语和特定方面的潜在联系.Gu等人<citation id="287" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>认为现有的工作大多忽略特定情感词与句子之间的关系,提出基于双向门控循环单元(gated recurrent unit, GRU)的位置感知双向注意力网络,认为当特定方面术语出现在某一句子中时,其邻近的单词应该比其他长距离单词给予更多的关注.He等人<citation id="288" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出将语法信息融入到注意力机制中,再与LSTM相结合,可以更好地预测特定方面的情感极性.Yi等人<citation id="289" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出conv-attention机制,将CNN的卷积操作与注意力结合,通过卷积运算生成特定方面的注意力,对上下文单词的时序信息进行建模.这些结合注意力机制的神经网络在无需额外的语义分析等外部知识的情况下,取得了比仅使用神经网络模型更好的效果.但此类方法,多数使用单一层面注意力机制,没有对注意力信息进行更深层次的挖掘,且使用的神经网络存在训练速度慢、无法获得全局结构信息等缺点.</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>1.2 注意力机制</b></h4>
                <div class="p1">
                    <p id="80">注意力机制最早在图像处理领域提出<citation id="290" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>,目的是让网络模型在训练过程中高度关注指定的目标.近年来,注意力机制在NLP领域也发挥着越来越重要的作用.Cheng等人<citation id="291" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>将注意力机制应用到机器翻译任务中,提出全局注意力和局部注意力2种机制,为注意力机制在NLP中的应用奠定了基础.Yin等人<citation id="292" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出将注意力机制与CNN结合解决句子对的建模问题,该方法使用在卷积时进行注意力计算、在池化时进行注意力计算以及在卷积和池化时同时进行注意力计算这3种方式进行建模,提供了在CNN中使用注意力机制的基础思路.短短几年内,如何利用注意力机制解决NLP领域问题已经成为研究人员关注的热点.谷歌翻译团队<citation id="293" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出仅使用注意力机制的Transformer网络,该网络使用大量自注意力机制获取单词间的依赖关系,并提出多头注意力的概念,即不再使用单一注意力信息,而是将输入经过不同的线性变化获取更全面的注意力表示.</p>
                </div>
                <div class="p1">
                    <p id="81">注意力机制的特性使得其可以很好地解决句子中特定方面情感极性判别问题.Fan等人<citation id="294" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出利用细粒度注意力机制和粗粒度注意力机制组成多粒度注意力网络,并设计特定方面对齐损失来描述具有相同上下文的特定方面之间的方面级别交互.Wang等人<citation id="295" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出面向语法导向的混合注意力网络,使用全局注意力来捕获特定目标的粗略信息,利用语法指导的局部注意力查看在语法上接近特定方面的单词,利用信息门来合成全局注意力和局部注意力信息,并自适应生成较少噪声和更多情绪导向的表示,解决了全局注意力将高注意力得分分配给不相关的情感单词的困扰.这些方法不仅证明了注意力机制在特定方面情感分析领域的有效性,还为今后的研究提供了新的思路.</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>2 问题描述与方法概论</b></h3>
                <h4 class="anchor-tag" id="83" name="83"><b>2.1 任务定义</b></h4>
                <div class="p1">
                    <p id="84">给定长度为<i>n</i>的句子,即<i>s</i>={<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub>,…,<i>w</i><sub><i>n</i></sub>}每个句子由一系列的词语<i>w</i><sub><i>i</i></sub>组成,其中<i>a</i><sub>1</sub>和<i>a</i><sub>2</sub>是句子<i>s</i>中特定方面的目标词,每个句子有一个或多个目标词.本文的任务是根据输入的句子判断句子中特定方面的情感极性(积极、消极、中立),例如句子“a group of friendly staff,the pizza is not bad,but the beef cubes are not worth the money”,该句中特定方面“staff”,“pizza”,“beef cubes”的情感极性分别为积极、中立和消极.本文将句子以词为单位形成1个词序列,然后通过词嵌入层将每一个词映射成低维空间中的连续值词向量,得到上下文词向量矩阵<i><b>E</b></i><sup>c</sup>∈R<sup><i>k</i></sup><sup>×</sup><sup><i>c</i></sup><sup>′</sup>和特定方面词向量矩阵<i><b>E</b></i><sup>a</sup>∈R<sup><i>k</i></sup><sup>×</sup><sup><i>a</i></sup><sup>′</sup>,其中<i>k</i>为词向量维度,<i>c</i>′为上下文词向量数量,<i>a</i>′为特定方面词向量数量.</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.2 方法概述</b></h4>
                <div class="p1">
                    <p id="86">为了更好地识别同一句子中不同特定方面的情感极性,本文针对不同的特定方面将句子表示为多个分句,分句的个数取决于不同特定方面的数量,例如句子“Good food but dreadful service at that restaurant”表示成表1所示形式.本文采用多头注意力机制来构建DANSA模型的2种注意力机制:</p>
                </div>
                <div class="p1">
                    <p id="87">1) 特定方面注意力机制.将特定方面词向量矩阵与上下文词向量矩阵做注意力运算,获取对特定方面的注意力信息,从而加强模型对特定方面的关注程度.</p>
                </div>
                <div class="p1">
                    <p id="88">2) 上下文自注意力机制.对上下文词向量矩阵中每一个词向量进行自注意力操作,以获得每一个单词与其他单词的依赖关系,进而获取输入句子的全局结构信息.</p>
                </div>
                <div class="area_img" id="89">
                    <p class="img_tit"><b>表1 分句形式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Form of Sentences</b></p>
                    <p class="img_note"></p>
                    <table id="89" border="1"><tr><td><br />Sentence</td><td>Aspect</td></tr><tr><td><br />Good food but dreadful service at that restaurant</td><td>food</td></tr><tr><td><br />Good food but dreadful service at that restaurant</td><td>service</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>2.3 特定方面注意力机制</b></h4>
                <div class="p1">
                    <p id="91">注意力机制的目的是在训练过程中,让模型了解输入数据中哪一部分信息是重要的,从而使模型高度关注这些信息.对于特定方面情感分析而言,可以通过分析文本内容得到哪些词与句子中特定方面目标词的相关度更高.例如句子“The appetizers are ok,but the service is slow”,词语“ok”是用来形容目标词“appetizers”的,而词语“slow”是用来形容目标词“service”的,因此在该句中,词语“ok”相比“slow”与目标词“appetizers”相关程度更高.同理,词语“slow”相比“ok”,与目标词“service”的相关度更高.</p>
                </div>
                <div class="p1">
                    <p id="92">特定方面注意力机制如图1所示,对于句子“The appetizers are ok,but the service is slow”,通过词嵌入操作可以得到上下文词向量矩阵<i><b>E</b></i><sup>c</sup>=(<i><b>x</b></i><sub>1</sub>,<i><b>x</b></i><sub>2</sub>,…,<i><b>x</b></i><sub>9</sub>)和特定方面词向量矩阵<i><b>E</b></i><sup>a</sup>=(<i><b>t</b></i><sub>1</sub>,<i><b>t</b></i><sub>2</sub>),其中<i><b>t</b></i><sub>1</sub>为特定方面“appetizers”,<i><b>t</b></i><sub>2</sub>为特定方面“service”.首先,将特定方面词向量矩阵中的每一个词与上下文词向量矩阵进行相似度计算,得到相似度向量<i><b>e</b></i>,<i><b>e</b></i>中的值表示相应位置词向量间的相似程度,形式为</p>
                </div>
                <div class="p1">
                    <p id="93"><i>e</i><sub><i>ij</i></sub>=<i>f</i>(<i><b>t</b></i><sub><i>i</i></sub>,<i><b>x</b></i><sub><i>j</i></sub>).(1)</p>
                </div>
                <div class="p1">
                    <p id="94">常用相似度计算函数主要有加性相似度函数和点积相似度函数,加性相似度函数使用神经网络来计算2部分的相似度,形式为</p>
                </div>
                <div class="p1">
                    <p id="95"><i>e</i><sub><i>ij</i></sub>=<i><b>w</b></i><sup>T</sup>σ(<i><b>t</b></i><sub><i>i</i></sub>+<i><b>x</b></i><sub><i>j</i></sub>),(2)</p>
                </div>
                <div class="p1">
                    <p id="96">其中,<i>σ</i>(·)表示激活函数,<i><b>w</b></i><sup>T</sup>为训练参数.点积注意力通过点积运算计算2部分的相似度,形式为</p>
                </div>
                <div class="p1">
                    <p id="97"><i>e</i><sub><i>ij</i></sub>=&lt;<i><b>t</b></i><sub><i>i</i></sub>,<i><b>x</b></i><sub><i>j</i></sub>&gt;,(3)</p>
                </div>
                <div class="p1">
                    <p id="98">其中,符号“&lt;&gt;”表示点积运算.点积注意力与加性注意力相比,计算更加快且节省空间,特别地,Vaswani等人<citation id="296" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>使用缩放点积注意力来代替点积注意力,可以减少高维度计算中带来的损失,形式为</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mo>&lt;</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>&gt;</mo></mrow><mrow><msqrt><mrow><mi>d</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msqrt></mrow></mfrac></mrow></math></mathml>,(4)</p>
                </div>
                <div class="p1">
                    <p id="100">其中,<i>d</i><sub><i>x</i></sub>表示词向量<i><b>x</b></i><sub><i>j</i></sub>的维度.</p>
                </div>
                <div class="p1">
                    <p id="101">向量<i><b>e</b></i>通过归一化操作得到注意力权重向量<i><b>e</b></i><sup>a</sup>,<i><b>e</b></i><sup>a</sup>中的元素代表相应位置上特定方面单词与上下文中单词的相关程度:</p>
                </div>
                <div class="p1">
                    <p id="102"><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mtext>a</mtext></msubsup><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false">(</mo><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false">(</mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>.(5)</p>
                </div>
                <div class="p1">
                    <p id="103">最后,特定方面词向量可以用权重矩阵中对应的权重与原来的词向量加权求和表示:</p>
                </div>
                <div class="p1">
                    <p id="104"><mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mtext>a</mtext></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>e</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mtext>a</mtext></msubsup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>.(6)</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 特定方面注意力机制" src="Detail/GetImg?filename=images/JFYZ201911009_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 特定方面注意力机制  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The aspect attention mechanism</p>

                </div>
                <h4 class="anchor-tag" id="106" name="106"><b>2.4 上下文自注意力机制</b></h4>
                <div class="p1">
                    <p id="107">自注意力机制是注意力机制的一种特殊形式,通过计算句子中每一个单词与其他所有单词的注意力得分,获取每一对单词间的依赖关系,对于远程和局部依赖都具有良好的灵活性.本文采用自注意力机制获取输入文本上下文中单词的依赖关系,以获取全局结构信息.例如句子“Great food but the service was dreadful”,上下文自注意力机制的任务是要分别计算句子中7个单词与其他单词的注意力得分.</p>
                </div>
                <div class="p1">
                    <p id="108">对于经过词嵌入的上下文词向量矩<i><b>E</b></i><sup>c</sup>经过上下文自注意力机制操作后得到相同维度的自注意力矩阵<i><b>B</b></i><sup>c</sup>,如图2所示:</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 上下文自注意力机制" src="Detail/GetImg?filename=images/JFYZ201911009_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 上下文自注意力机制  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The context self-attention mechanism</p>

                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>2.5 多头注意力机制下的双注意力</b></h4>
                <div class="p1">
                    <p id="111">传统的注意力机制只考虑单词之间单一层面的注意力信息,多头注意力通过计算句子在不同线性变换下的表示来获取更全面的注意力信息.</p>
                </div>
                <div class="p1">
                    <p id="112">如图3所示,以句子“The food is great”为例,句中单词经过词嵌入后得到相应的词向量<i><b>x</b></i><sub>1</sub>,<i><b>x</b></i><sub>2</sub>,<i><b>x</b></i><sub>3</sub>,<i><b>x</b></i><sub>4</sub>,分别与线性变换矩阵<i><b>W</b></i><sup>(1)</sup>,<i><b>W</b></i><sup>(2)</sup>,<i><b>W</b></i><sup>(3)</sup>进行点乘得到相对应的线性变换后的向量.特定方面“food”经过词嵌入后得到相应的词向量,与线性变换矩阵<i><b>W</b></i><sup>p</sup>点乘后得到对应的向量<i><b>p</b></i><sub>1</sub>.</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 线性变换例子" src="Detail/GetImg?filename=images/JFYZ201911009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 线性变换例子  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The examples of linear transformations</p>

                </div>
                <div class="p1">
                    <p id="114">特定方面“food”注意力计算过程有3个:1)计算<i><b>p</b></i><sub>1</sub>与<i><b>k</b></i><sub>1</sub>,<i><b>k</b></i><sub>2</sub>,<i><b>k</b></i><sub>3</sub>,<i><b>k</b></i><sub>4</sub>的相似度得分;2)对相似度得分进行归一化操作;3)用归一化后得到的权重分别与对应位置的<i><b>v</b></i><sub>1</sub>,<i><b>v</b></i><sub>2</sub>,<i><b>v</b></i><sub>3</sub>,<i><b>v</b></i><sub>4</sub>相乘求和,进而得到最终的注意力向量.</p>
                </div>
                <div class="p1">
                    <p id="115">同理,上下文“The food is great”自注意力计算过程就是将<i><b>p</b></i><sub>1</sub>替换成上下文词向量线性变换后的表示<i><b>q</b></i><sub>1</sub>,<i><b>q</b></i><sub>2</sub>,<i><b>q</b></i><sub>3</sub>,<i><b>q</b></i><sub>4</sub>.多头注意力机制就是在多次不同组线性变换下,重复上述操作.</p>
                </div>
                <h3 id="116" name="116" class="anchor-tag"><b>3 面向双注意力网络的特定方面情感分析模型(DANSA</b>)</h3>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 DANSA模型框架" src="Detail/GetImg?filename=images/JFYZ201911009_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 DANSA模型框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Framework of DANSA</p>

                </div>
                <div class="p1">
                    <p id="118">面向特定方面细粒度情感分析的双注意力网络(DANSA)如图4所示,文本上下文与特定方面目标词首先通过嵌入层将每个单词映射成1个多维连续值词向量进而得到上下文词向量矩阵与特定方面词向量矩阵,然后通过线性变换层得到2个矩阵在多次不同线性变换下的映射矩阵,再通过双注意力层对不同映射矩阵进行特定方面和文本上下文双注意力操作得到注意力表示矩阵,最后经过输出层得到最终的情感分类结果,DANSA由4部分组成:</p>
                </div>
                <div class="p1">
                    <p id="119">1) 词嵌入层.将输入看作以词为单位的词序列,通过本层将输入文本上下文序列和特定方面序列中的每一个词映射为1个多维的连续值词向量,从而得到2部分的词向量矩阵.</p>
                </div>
                <div class="p1">
                    <p id="120">2) 线性变换层.通过对上下文和特定方面2部分词向量矩阵进行多次不同线性变换,得到2部分词向量矩阵在不同线性变换条件下的表示,从而使模型能够从多方面捕获上下文和特定方面的特征信息.</p>
                </div>
                <div class="p1">
                    <p id="121">3) 双注意力层.通过计算上下文部分的多头自注意力,捕获词与词间的依赖关系,获取文本的整体结构信息.然后,计算特定方面对于文本的注意力得分,以获取文本与特定方面间的依赖关系.将2部分注意力进行拼接并再次进行线性映射操作,利用池化操作获得不同线性变换条件下最重要的情感特征.</p>
                </div>
                <div class="p1">
                    <p id="122">4) 输出层.使用<i>softmax</i>函数得到输出结果,最终获取特定方面的情感极性.</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>3.1 模型构建</b></h4>
                <div class="p1">
                    <p id="124">给定句子在经过词嵌入层后得到上下文词向量矩阵<i><b>E</b></i><sup>c</sup>=(<i><b>x</b></i><sub>1</sub>,<i><b>x</b></i><sub>2</sub>,…,<i><b>x</b></i><sub><i>n</i></sub>)和特定方面词向量矩阵<i><b>E</b></i><sup>a</sup>=(<i><b>t</b></i><sub>1</sub>,<i><b>t</b></i><sub>2</sub>,…,<i><b>t</b></i><sub><i>m</i></sub>),在线性变换层,通过对2个矩阵进行不同的线性变换,得到2个矩阵在不同线性变换下的表示,图5描述了1次线性变换的过程,线性变换层的工作就是重复此过程<i>n</i>次.</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 线性变换过程" src="Detail/GetImg?filename=images/JFYZ201911009_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 线性变换过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Process of linear transformation</p>

                </div>
                <div class="p1">
                    <p id="126">上下文词向量矩阵<i><b>E</b></i><sup>c</sup>经过不同的3组线性变换得到矩阵<i><b>Q</b></i><sup>c</sup>,<i><b>K</b></i><sup>c</sup>,<i><b>V</b></i><sup>c</sup>,特定方面词向量矩阵<i><b>E</b></i><sup>a</sup>经过线性变换得到矩阵<i><b>P</b></i><sup>a</sup>.其中<i><b>W</b></i><sup><i>Q</i></sup>,<i><b>W</b></i><sup><i>K</i></sup>,<i><b>W</b></i><sup><i>V</i></sup>,<i><b>W</b></i><sup><i>P</i></sup>为线性变换参数矩阵.</p>
                </div>
                <div class="p1">
                    <p id="127">在双注意力层,上下文自注意力矩阵<i><b>S</b></i><sup>c</sup>的计算方式为</p>
                </div>
                <div class="p1">
                    <p id="128"><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mtext>c</mtext></msup><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mo>&lt;</mo><mi mathvariant="bold-italic">Q</mi><msup><mrow></mrow><mtext>c</mtext></msup><mo>,</mo><mi mathvariant="bold-italic">Κ</mi><msup><mrow></mrow><mtext>c</mtext></msup><mo>&gt;</mo></mrow><mrow><msqrt><mrow><mi>d</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msqrt></mrow></mfrac></mrow><mo>)</mo></mrow><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>c</mtext></msup></mrow></math></mathml>,(7)</p>
                </div>
                <div class="p1">
                    <p id="129">其中,<i>d</i><sub><i>k</i></sub>为矩阵<i><b>K</b></i><sup>c</sup>列向量的维度.使用线性变换后的矩阵<i><b>Q</b></i><sup>c</sup>,<i><b>K</b></i><sup>c</sup>,<i><b>V</b></i><sup>c</sup>通过缩放点积注意力函数得出.</p>
                </div>
                <div class="p1">
                    <p id="130">同理,特定方面注意力矩阵<i><b>D</b></i><sup>a</sup>为</p>
                </div>
                <div class="p1">
                    <p id="131"><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><msup><mrow></mrow><mtext>a</mtext></msup><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mo>&lt;</mo><mi mathvariant="bold-italic">Ρ</mi><msup><mrow></mrow><mtext>a</mtext></msup><mo>,</mo><mi mathvariant="bold-italic">Κ</mi><msup><mrow></mrow><mtext>c</mtext></msup><mo>&gt;</mo></mrow><mrow><msqrt><mrow><mi>d</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msqrt></mrow></mfrac></mrow><mo>)</mo></mrow><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>c</mtext></msup></mrow></math></mathml>.(8)</p>
                </div>
                <div class="p1">
                    <p id="132">将每次线性变换下得到的上下文自注意力矩阵与特定方面注意力矩阵进行拼接,得到双注意力矩阵<i><b>U</b></i><sub><i>i</i></sub>,然后将每次线性变换后的双注意力矩阵<i><b>U</b></i><sub>1</sub>,<i><b>U</b></i><sub>2</sub>,…,<i><b>U</b></i><sub><i>n</i></sub>进行拼接,再次进行线性变换得到最终的注意力表达矩阵<i><b>Z</b></i>:</p>
                </div>
                <div class="p1">
                    <p id="133"><i><b>Z</b></i>=<i>concat</i>(<i><b>U</b></i><sub>1</sub>,<i><b>U</b></i><sub>2</sub>,…,<i><b>U</b></i><sub><i>n</i></sub>).(9)</p>
                </div>
                <div class="p1">
                    <p id="134">在模型的最后一层,将上层输出矩阵进行平均池化操作得到特征向量<i><b>z</b></i><sub>avg</sub>,然后像传统的神经网络一样,将池化后的结果经过全连接层后输入到最终的<i>softmax</i>分类器中,从而得到最终的情感极性.</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135"><b>3.2 模型训练</b></h4>
                <div class="p1">
                    <p id="136">本文使用双注意力层输出作为全连接层输入,通过一个<i>softmax</i>函数输出最终情感极性,即:</p>
                </div>
                <div class="p1">
                    <p id="137"><i>y</i>=<i>softmax</i>(<i><b>Wz</b></i><sub>avg</sub>+<i><b>B</b></i>),(10)</p>
                </div>
                <div class="p1">
                    <p id="138">其中,<i><b>z</b></i><sub>avg</sub>为双注意力层输出,<i><b>W</b></i>为全连接层权重矩阵,<i><b>B</b></i>为全连接层偏置项矩阵.本文使用反向传播法来优化模型,交叉熵为</p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>D</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>C</mi></mrow></munder><mover accent="true"><mi>y</mi><mo>^</mo></mover></mstyle></mrow></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mspace width="0.25em" /><mrow><mi>ln</mi></mrow><mtext> </mtext><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mi>θ</mi><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>,(11)</p>
                </div>
                <div class="p1">
                    <p id="140">其中,<i>D</i>为训练集数据量,即训练集合大小;<i>C</i>为数据的类别数;<i>y</i>为待分类句子的预测类别;<mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml>为实际类别;<mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><mrow><mo>|</mo><mi>θ</mi><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>为交叉熵正则项.</p>
                </div>
                <h3 id="141" name="141" class="anchor-tag"><b>4 实  验</b></h3>
                <h4 class="anchor-tag" id="142" name="142"><b>4.1 实验数据</b></h4>
                <div class="p1">
                    <p id="143">本文采用SemEval2014数据集<citation id="316" type="note"><link href="312" rel="footnote" /><sup>①</sup></citation>和Twitter数据集进行对比实验,数据样本的情感极性分为积极、消极和中性.其中,SemEval2014数据集是语义测评比赛任务的数据集,包括laptop和restaurant 2个领域的用户评论.通过对比实验,验证了本文提出的DANSA在不同领域数据集上都取得了较好的情感分类性能,表2给出本文实验使用数据统计:</p>
                </div>
                <div class="area_img" id="144">
                    <p class="img_tit"><b>表2 实验使用数据统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Statistic of the Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="144" border="1"><tr><td><br />Dateset</td><td>Positive</td><td>Negative</td><td>Neutral</td></tr><tr><td><br />Laptop-train</td><td>994</td><td>870</td><td>464</td></tr><tr><td><br />Laptop-test</td><td>341</td><td>128</td><td>168</td></tr><tr><td><br />Restaurant-train</td><td>2 164</td><td>807</td><td>637</td></tr><tr><td><br />Restaurant-test</td><td>728</td><td>196</td><td>196</td></tr><tr><td><br />Twitter-train</td><td>2 586</td><td>2 379</td><td>1 283</td></tr><tr><td><br />Twitter-test</td><td>281</td><td>228</td><td>183</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="145" name="145"><b>4.2 超参数</b></h4>
                <div class="p1">
                    <p id="146">在本文的实验中,词向量采用Pennington等人<citation id="297" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出的Glove词向量<citation id="317" type="note"><link href="314" rel="footnote" /><sup>①</sup></citation>,其中每个词向量维度为300维,词典大小为1.9 MB.对于未登录词,采用均匀分布<i>U</i>(-0.01,0.01)随机初始化词向量.<i>L</i><sub>2</sub>正则项系数设置为10<sup>-4</sup>,随机失活率(dropout rate)设置为0.5,Adam优化器初始学习率为0.01,模型迭代次数(epoch)为10.在线性变换层,线性变换次数设置为8,注意力函数采用缩放点积注意力.</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147"><b>4.3 对比实验</b></h4>
                <div class="p1">
                    <p id="148">将本文提出的DANSA同8种方法在2个不同数据集上进行实验:</p>
                </div>
                <div class="p1">
                    <p id="149">1) SVM.基于特征的SVM分类方法,是传统机器学习的常用方法.</p>
                </div>
                <div class="p1">
                    <p id="150">2) CNN.基于Kim<citation id="298" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>提出的卷积神经网络模型,是最基础的卷积神经网络.</p>
                </div>
                <div class="p1">
                    <p id="151">3) ATT-CNN.基于Wang等人<citation id="299" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提出的基于注意力机制的卷积神经网络.</p>
                </div>
                <div class="p1">
                    <p id="152">4) LSTM.基础LSTM网络,使用最后隐藏状态作为句子表示,输入到最终分类器中.</p>
                </div>
                <div class="p1">
                    <p id="153">5) TD-LSTM.基于Tang等人<citation id="300" type="reference"><link href="270" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出的使用2个LSTM网络,分别作用于特定方面之前的文本和之后的文本,然后使用2个LSTM网络的最后隐藏状态的拼接预测情感极性.</p>
                </div>
                <div class="p1">
                    <p id="154">6) AT-LSTM.基于Wang等人<citation id="301" type="reference"><link href="272" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>提出的通过LSTM网络对文本上下文建模,然后将隐状态与特定方面联合嵌入监督注意力向量的生成,再由生成的注意力向量产生最后的特定方面情感极性.</p>
                </div>
                <div class="p1">
                    <p id="155">7) ATAE-LSTM.是在AT-LSTM基础上的拓展,它将特定方面嵌入向量与每个单词嵌入向量相加表示上下文.</p>
                </div>
                <div class="p1">
                    <p id="156">8) IAN.基于Ma等人<citation id="302" type="reference"><link href="274" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>提出的使用2个LSTM网络分别对句子和特定方面进行建模,交互生成2部分的注意力向量用于情感分类.</p>
                </div>
                <div class="p1">
                    <p id="157">不同模型在SemEval2014和Twitter数据集上经过10次迭代后的准确率如表3所示,对于实验结果的分析为:</p>
                </div>
                <div class="p1">
                    <p id="158">1) 在前4种没有使用注意力机制的模型中,普通CNN网络的情感分析模型准确率偏低.CNN在图像处理领域的有效性是有目共睹的,这是因为在图像上相邻像素点通常是相关的,而在自然语言处理中,句子中相邻的词语未必相关,相关词语之间可能存在若干的修饰词语,这导致CNN卷积操作所获取的信息不完整,不能有效地利用数据信息.传统SVM分类器准确率虽然略高于普通CNN,但分类效果仍不理想,这是因为本文在实验过程中没有做过多特征工程的工作,而传统机器学习方法的优劣很大程度上取决于特征工程的质量.基础LSTM模型的结果优于前2种模型,这是因为LSTM善于处理序列问题并通过门机制来实现长时依赖,但基础LSTM并没有特别关注句子中的特定方面目标词.TD-LSTM相比普通LSTM在3个数据集上的准确率分别提升了2.8%,1.29%,1.56%,原因是TD-LSTM开始对特定方面进行关注,它通过在文本中特定方面的左右分别建模,利用2个LSTM网络来学习特定方面的表示,这种方法虽然取得了一定的效果,但对于模型来说,文本中每个词对特定方面的影响都是相同的,没有对更重要的部分重点学习.</p>
                </div>
                <div class="p1">
                    <p id="159">2) 在另外4种将注意力机制与神经网络相结合的模型中,其准确率相比没有使用注意力的模型,都有明显提升,证明了注意力机制在特定方面情感分析任务中的有效性.由于CNN在NLP中的局限性,ATT-CNN的结果相比于将注意力与LSTM相结合的模型,结果并不理想.AT-LSTM,ATAE-LSTM,IAN都是将注意力机制与LSTM相结合的方法,在准确率上相比4种方法都有所提升.AT-LSTM和ATAE-LSTM通过注意力机制来监督特定方面上下文中的重要信息,并且将特定方面与文本进行联合嵌入,这为特定方面情感分类生成更合理的表示.IAN对文本和特定方面进行单独建模,交互的生成注意力,不仅学习文本中对特定方面相对重要的信息,也学习了特定方面中对文本更重要的信息,再次证明了注意力机制的有效性.</p>
                </div>
                <div class="p1">
                    <p id="160">3) 本文提出的DANSA在对比实验中取得了最好的效果,证明了模型的有效性.在将注意力与神经网络相结合的模型中,都使用了单一的注意力机制,都是从单一层面获取注意力信息,而DANSA使用多头注意力机制来搭建注意力网络,它将文本和特定方面进行多次不同的线性变换,学习两者在不同线性变换下的注意力表示,能够更深层次地学习和表示文本.不同于基于CNN的模型,DANSA通过自注意力计算,获取了文本全局的依赖信息;与基于LSTM网络的模型相比,模型首先通过自注意力来获取文本中每一个词向量与其他词向量的相关度,实现了词向量之间的长距离依赖,再通过特定方面注意力的计算,获取了文本中对特定方面的重要信息,从而得到更好的分类效果,同时DANSA能够实现大规模并行化计算,大大提升了模型训练速度.</p>
                </div>
                <div class="area_img" id="161">
                    <p class="img_tit"><b>表3 不同模型的准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Accuracy of Different Models</b></p>
                    <p class="img_note">%</p>
                    <table id="161" border="1"><tr><td><br />Model</td><td>Laptop</td><td>Restaurant</td><td>Twitter</td></tr><tr><td><br />SVM</td><td>61.71</td><td>69.54</td><td>71.12</td></tr><tr><td><br />CNN</td><td>59.32</td><td>67.23</td><td>70.03</td></tr><tr><td><br />LSTM</td><td>65.42</td><td>74.33</td><td>75.56</td></tr><tr><td><br />TD-LSTM</td><td>68.22</td><td>75.62</td><td>77.12</td></tr><tr><td><br />ATT-CNN</td><td>62.11</td><td>68.19</td><td>72.18</td></tr><tr><td><br />AT-LSTM</td><td>70.96</td><td>77.28</td><td>79.07</td></tr><tr><td><br />ATAE-LSTM</td><td>73.88</td><td>79.61</td><td>81.51</td></tr><tr><td><br />IAN</td><td>75.27</td><td>81.24</td><td>84.63</td></tr><tr><td><br />DANSA</td><td>76.86</td><td>82.37</td><td>86.08</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="162" name="162"><b>4.4 DANSA模型分析</b></h4>
                <h4 class="anchor-tag" id="163" name="163">4.4.1 运行时间分析</h4>
                <div class="p1">
                    <p id="164">本文使用相同的词向量矩阵和相同的数据集,在相同的CPU,GPU和网络框架下完成训练时间对比实验,表4给出了不同模型在Restaurant领域数据集上完成1次迭代的训练时间对比结果.</p>
                </div>
                <div class="area_img" id="165">
                    <p class="img_tit"><b>表4 不同模型完成1次迭代的训练时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Runtime of Each Training Epoch</b></p>
                    <p class="img_note"></p>
                    <table id="165" border="1"><tr><td><br />Model</td><td>Training Time/s</td></tr><tr><td><br />CNN</td><td>8</td></tr><tr><td><br />ATT-CNN</td><td>17</td></tr><tr><td><br />LSTM</td><td>417</td></tr><tr><td><br />TD-LSTM</td><td>490</td></tr><tr><td><br />AT-LSTM</td><td>520</td></tr><tr><td><br />ATAE-LSTM</td><td>548</td></tr><tr><td><br />IAN</td><td>560</td></tr><tr><td><br />DANSA</td><td>58</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="166">从表4可以看出, 在基于LSTM的模型中,普通的LSTM模型训练时间需要417 s,加入注意力机制的AT-LSTM和ATAE-LSTM的训练时间都超过了500 s.训练时间过长是LSTM网络最大的弱点,由于网络接收序列形数据,导致无法实现并行计算,并且LSTM的每一个单元都需要相当复杂的运算操作,这些原因都大大增加了LSTM的训练时间.</p>
                </div>
                <div class="p1">
                    <p id="167">普通的CNN模型训练时间是最短的,完成1次迭代的训练时间只需要8 s,加入注意力机制的ATT-CNN模型的训练时间也只需17 s,训练时间远远优于LSTM网络.DANSA模型完成1次迭代时间为58 s,虽然高于基于CNN的模型,但是却远远优于基于LSTM网络的模型.模型中文本自注意力和特定方面注意力的计算必然会消耗一定时间,但不同线性变换下的注意力是可以并行计算的,这与普通注意力在时间复杂度上是相同的.在保证了准确率的基础上,DANSA模型的训练时间相比基于LSTM的模型平均减少了449 s.</p>
                </div>
                <h4 class="anchor-tag" id="168" name="168">4.4.2 线性变换次数分析</h4>
                <div class="p1">
                    <p id="169">对DANSA采用的多头注意力机制在不同线性变换次数下的准确率进行对比分析,实验对比结果如图6所示:</p>
                </div>
                <div class="area_img" id="170">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同线性映射次数的准确率" src="Detail/GetImg?filename=images/JFYZ201911009_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同线性映射次数的准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Accuracy of different transformation times</p>

                </div>
                <div class="p1">
                    <p id="171">实验对比了线性变换次数为2,4,6,8,10时在数据集Restaurant上经过10次迭代的准确率情况.从图6可以看出,模型的准确率大体随着线性变换次数(<i>k</i>)的增加而增加,但当<i>k</i>=10时的准确率相比<i>k</i>=8时有所下降,这说明在此数据集上,当<i>k</i>=10时,可能存在模型的过拟合现象,所以本文在对比实验中将线性变换次数设置为8.</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172">4.4.3 注意力类型分析</h4>
                <div class="p1">
                    <p id="173">将采用缩放点积注意力的DANSA和采用加性注意力的DANSA在Restaurant数据集上进行准确率对比实验,在Laptop,Restaurant,Twitter数据集上进行训练时间对比实验,实验结果如图7与图8所示.</p>
                </div>
                <div class="area_img" id="174">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_174.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同注意力类型的准确率" src="Detail/GetImg?filename=images/JFYZ201911009_174.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同注意力类型的准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_174.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Accuracy of different attention types</p>

                </div>
                <div class="area_img" id="175">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_175.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同注意力类型的训练时间" src="Detail/GetImg?filename=images/JFYZ201911009_175.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同注意力类型的训练时间  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_175.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 The runtime of different attention types</p>

                </div>
                <div class="p1">
                    <p id="176">从图7可以看到,经过10次迭代之后,使用加性注意力的DANSA模型准确率略高于使用缩放点积注意力的模型.加性注意力使用神经网络来计算2个元素的相似度或相关度,可以更深层次地学习元素之间的依赖关系,实验证明在准确率上使用加性注意力的DANSA确实可以取得更好的效果.但从图8可以明显地看出,在3个数据集上,使用加性注意力的模型在训练时间上是使用点积注意力模型的3倍,加性注意力使用神经网络作为相似度函数,需要训练更多的参数,需要付出更高的时间成本.考虑到模型的综合性能,在对比实验中,本文采用缩放点积注意力来构造DANSA模型.</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177"><b>4.5 注意力可视化</b></h4>
                <div class="p1">
                    <p id="178">从Restaurant-test数据集中选取句子“Great food but the service was dreadful!”用作自注意力可视化说明,如图9所示,区域颜色越深,代表注意力权重越大.</p>
                </div>
                <div class="area_img" id="179">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911009_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 上下文自注意力权重" src="Detail/GetImg?filename=images/JFYZ201911009_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 上下文自注意力权重  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911009_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 The context self-attention weights</p>

                </div>
                <div class="p1">
                    <p id="180">从图9可以看出,名词、动词和形容词等在语义上重要的词,通常会受到很大的关注,比如句子中的“great”,“food”,“service”,“dreadful”都受到更高的关注,但是一些停用词则不会受到过高的关注.全局中重要的词,比如“food”和“service”,由于句子主要是针对这2个词进行描述,所以它们获得其他单词更多的关注.如果一个单词仅与某些词有关,那么它会获得相关词的更高的关注,例如“food”与“great”相关度极高,“service”只与“dreadful”相关度极高.</p>
                </div>
                <div class="p1">
                    <p id="181">选取句子“The appetizers are ok,but the service is slow”用作特定方面注意力可视化说明,如表5所示,表5中句子区域颜色越深,代表该词注意力权重越大.</p>
                </div>
                <div class="area_img" id="182">
                    <p class="img_tit"><b>表5 特定方面注意力权重</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 The Weight of Aspect Attention</b></p>
                    <p class="img_note"></p>
                    <table id="182" border="1"><tr><td><br />Aspect</td><td>Sentence</td></tr><tr><td><br />appetizers</td><td><img src="images\JFYZ201911009_318.jpg" /></td></tr><tr><td><br />service</td><td><img src="images\JFYZ201911009_319.jpg" /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="183">从表5可以清楚地看到,对于特定方面“appetizers”,代表“ok”的区域颜色极深,说明词“ok”与“appetizers”这个特定方面相关度极大,而其他区域都为较浅的颜色.在特定方面为“service”也有同样的情况,代表“slow”的区域为深红色,说明“service”与“slow”极为相关.这说明注意力机制可以有效地捕捉与特定方面相关的信息,可以使模型更充分地获取有效信息.</p>
                </div>
                <h3 id="184" name="184" class="anchor-tag"><b>5 总  结</b></h3>
                <div class="p1">
                    <p id="185">在以往的工作中,大部分针对特定方面情感分析的研究都是将注意力机制与CNN或LSTM网络相结合.然而基于CNN的模型无法获取全局信息,而基于LSTM网络的模型则需要很高的时间代价且元素间的依赖关系会受到距离的影响,因此本文提出一种面向双注意力网络的特定方面情感分析模型(DANSA),将多头注意力机制应用到细粒度情感分析问题中,主要思想是通过双注意力网络学习文本向量之间在不同线性映射下的依赖关系和特定方面与文本之间的依赖关系,并且所获取的依赖关系不会因为距离而减弱,同时,模型可以实现大规模并行化计算,极大地降低了训练时间.实验结果表明,DANSA可以合理有效地解决特定方面情感分析问题.</p>
                </div>
                <div class="p1">
                    <p id="186">DANSA目前没有考虑文本的时序性问题,在未来的研究中,我们将就文本的时序问题和位置关系进行研究,以提升模型的性能.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="222">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700305623&amp;v=MjIxMzA0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKRjBUYnhNPU5pZk9mYks4SHRmTnFJOUZaK3NLQ240Nm9CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Medhat W,Hassan A,Korashay H.Sentiment analysis algorithms and applications:A survey[J].Ain Shams Engineering Journal,2014,5(4):1093- 1113
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MjMwMjhaZVJzRnl6bVZMckpMeXZTZExHNEg5Zk1yWTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Wang Zhongyuan,Cheng Jianpeng,Wang Haixun,et al.Short text understanding:A survey[J].Journal of Computer Research and Development,2016,53(2):262- 269 (in Chinese)(王仲远,程健鹏,王海勋,等.短文本理解研究[J].计算机研究与发展,2016,53(2):262- 269)
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MTMxMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXptVkxySkx5dlNkTEc0SDliTXA0OUZiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Liang Bin,Liu Quan,Xu Jin,et al.Aspect-based sentiment analysis based on multi-attention CNN[J].Journal of Computer Research and Development,2017,54(8):1724- 1735 (in Chinese)(梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分[J].计算机研究与发展,2017,54(8):1724- 1735)
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A bi-directional LSTM-CNN model with attention for aspect-level text classification">

                                <b>[4]</b>Zhu Yonghua,Gao Xun,Zhang Weilin,et al.A bi-directional LSTM-CNN model with attention for aspect-level text classification[J].Future Internet,2018,10(12):116- 127
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparative study of CNN and LSTM based attention neural networks for aspect-level opinion mining">

                                <b>[5]</b>Quan Wei,Chen Zheng,Gao Jianliang,et al.Comparative study of CNN and LSTM based attention neural networks for aspect-level opinion mining[C] //Proc of IEEE Int Conf on Big Data 2018.Piscataway,NJ:IEEE,2018:2141- 2150
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weakly supervised joint sentiment-topic detection from text">

                                <b>[6]</b>Lin Chenghua,He Yulan,Everson R,et al.Weakly supervised joint sentiment-topic detection from text[J].IEEE Transactions on Knowledge and Data Engineering,2012,24(6):1134- 1145
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting aspects and sentiment in customer reviews">

                                <b>[7]</b>Kiritchenko S,Zhu Xiaodan,Cherry C,et al.Detecting aspects and sentiment in customer reviews[C] //Proc of the 8th Int Workshop on Semantic Evaluation.Stroudsburg,PA:ACL,2014:437- 442
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201706003&amp;v=MzI0OTMzenFxQnRHRnJDVVJMT2VaZVJzRnl6bVZMckpMeXZTZExHNEg5Yk1xWTlGWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Chen Long,Guan Ziyu,He Jinhong,et al.A survey on sentiment classification[J].Journal of Computer Research and Development,2017,54(6):1150- 1170 (in Chinese)(陈龙,管子玉,何金红,等.情感分类研究进展[J].计算机研究与发展,2017,54(6):1150- 1170)
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aspect Based Sentiment Analysis with Gated Convolutional Networks">

                                <b>[9]</b>Xue Wei,Li Tao.Aspect based sentiment analysis with gated convolutional networks[C] //Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2018:2514- 2523
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Financial aspect and sentiment predictions with deep neural networks">

                                <b>[10]</b>Piao Guangyuan,Breslin J.Financial aspect and sentiment predictions with deep neural networks[C] //Proc of the 2018 World Wide Web Conf.New York:ACM,2018:1973- 1977
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM">

                                <b>[11]</b>Ma Yukun,Peng Haiyun,Cambria E.Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:5876- 5883
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint attention LSTM network for aspect-level sentiment analysis">

                                <b>[12]</b>Cai Guoyong,Li Hongyu.Joint attention LSTM network for aspect-level sentiment analysis[C] //Proc of the 24th China Conf on Information Retrieval (CCIR 2018).Los Alamitos,CA:IEEE Computer Society,2018:147- 157
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A position-aware bidirectional attention network for aspect-level sentiment analysis">

                                <b>[13]</b>Gu Shuqin,Zhang Lipeng,Hou Yuexian,et al.A position-aware bidirectional attention network for aspect-level sentiment analysis[C] //Proc of the 27th Int Conf on Computation Linguistics.Stroudsburg,PA:ACL,2018:774- 784
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Effective attention modeling for aspect-level sentiment classification">

                                <b>[14]</b>He Ruidan,Lee W S,Ng H T,et al.Effective attention modeling for aspect-level sentiment classification[C] //Proc of the 27th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2018:1121- 1131
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aspect-level sentiment classification with conv-attention mechanism">

                                <b>[15]</b>Yi Qian,Liu Jie,Zhang Guixuan,et al.Aspect-level sentiment classification with conv-attention mechanism[C] //Proc of the 25th Int Conf.Los Alamitos,CA:IEEE Computer Society,2018:231- 243
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent models of visual attention">

                                <b>[16]</b>Mnih V,Heess N,Graves A,et al.Recurrent models of visual attention[C] //Proc of the 28th Conf on Neural Information Processing Systems(NIPS2014).Cambridge,MA:MIT Press,2014:2204- 2212
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Agreement-based joint training for bidirectional attention-based neural machine translation">

                                <b>[17]</b>Cheng Yong,Shen Shiqi,He Zhongjun,et,al.Agreement-based joint training for bidirectional attention-based neural machine translation[C] //Proc of the 25th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2016:2761- 2767
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-based convolutional neural network for modeling sentence pairs">

                                <b>[18]</b>Yin Wenpeng,Schütze H,Xiang Bing,et al.ABCNN:Attention-based convolutional neural network for modeling sentence pairs[J].Association for Computational Linguistics,2016,4:259- 272
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">

                                <b>[19]</b>Vaswani A,Shazeer N,Parmar N,et al.Attention is all you need[C] //Proc of the 31st Conf on Neural Information Processing Systems(NIPS2017).Cambridge,MA:MIT Press,2017:6000- 6010
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-grained attention network for aspect-level sentiment classification">

                                <b>[20]</b>Fan Feifan,Feng Yansong,Zhao Dongyan.Multi-grained attention network for aspect-level sentiment classification[C] //Proc of the 2018 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2018:3433- 3442
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Syntax-directed hybrid attention network for aspect-level sentiment analysis">

                                <b>[21]</b>Wang Xinyi,Xu Guangluan,Zhang Jingyuan,et al.Syntax-directed hybrid attention network for aspect-level sentiment analysis[J].IEEE Access,2019,7:5014- 5025
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global vectors for word representation">

                                <b>[22]</b>Pennington J,Socher R,Manning C D.Glove:Global vectors for word representation[C] //Proc of the 2014 Conf on Empircal Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1532- 1543
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[23]</b>Kim Y.Convolutional neural networks for sentence classification[C] //Proc of the 2014 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2014:1746- 1751
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relation classification via multi-level attention cnns">

                                <b>[24]</b>Wang Linlin,Cao Zhu,de Melo G,et al.Relation classification via multi-level attention CNNs[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,PA:ACL,2016:1298- 1307
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Effective LSTMs for target-dependent sentiment classification">

                                <b>[25]</b>Tang Duyu,Qin Bing,Feng Xiaocheng,et al.Effective LSTMs for target-dependent sentiment classification[C] //Proc of the 26th Int Conf on Computational Linguistics.Stroudsburg,PA:ACL,2016:3298- 3307
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attentionbased LSTM for aspect-level sentiment classification">

                                <b>[26]</b>Wang Yequan,Huang Minlie,Zhu Xiaoyan,et al.Attention-based LSTM for aspect-level sentiment classification[C] //Proc of the 2016 Conf on Empirical Methods in Natural Language Processing.Stroudsburg,PA:ACL,2016:606- 615
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive attention networks for aspect-level sentiment classification">

                                <b>[27]</b>Ma Dehong,Li Sujian,Zhang Xiaodong,et al.Interactive attention networks for aspect-level sentiment classification[C] //Proc of the 26th Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017:4068- 4074
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="312" href="javascript:void(0)">
                            <b>1</b> http://alt.qcri.org/semeval2014/
                        </span>
                    </p>
                    <p>
                        <span id="314" href="javascript:void(0)">
                            <b>2</b> http://nlp.stanford.edu/projects/glove/
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201911009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911009&amp;v=MTMxODFyQ1VSTE9lWmVSc0Z5em1WTHJKTHl2U2RMRzRIOWpOcm85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZVYyL2sreXo2dzFqcVVxWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

