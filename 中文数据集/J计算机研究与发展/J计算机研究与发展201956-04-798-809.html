

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129043731837500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201904013%26RESULT%3d1%26SIGN%3duRIX4abnD3c2qmd9DRmidfcEMPA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201904013&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201904013&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201904013&amp;v=MTM3NTVFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNuaFc3M0tMeXZTZExHNEg5ak1xNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="&lt;b&gt;1 基于斯格明子介质的存内计算框架&lt;/b&gt; "><b>1 基于斯格明子介质的存内计算框架</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="&lt;b&gt;1.1 斯格明子-赛道型存储器件&lt;/b&gt;"><b>1.1 斯格明子-赛道型存储器件</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;1.2 基于斯格明子介质的存内计算框架&lt;/b&gt;"><b>1.2 基于斯格明子介质的存内计算框架</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="&lt;b&gt;2 基于斯格明子介质的计算单元设计&lt;/b&gt; "><b>2 基于斯格明子介质的计算单元设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="&lt;b&gt;2.1 基于斯格明子逻辑门的加法逻辑&lt;/b&gt;"><b>2.1 基于斯格明子逻辑门的加法逻辑</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;2.2 基于斯格明子逻辑门的进位逻辑&lt;/b&gt;"><b>2.2 基于斯格明子逻辑门的进位逻辑</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;2.3 基于斯格明子逻辑门的全加器&lt;/b&gt;"><b>2.3 基于斯格明子逻辑门的全加器</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;2.4 基于斯格明子逻辑门的乘法器&lt;/b&gt;"><b>2.4 基于斯格明子逻辑门的乘法器</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;3 基于斯格明子介质的存储单元设计&lt;/b&gt; "><b>3 基于斯格明子介质的存储单元设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#108" data-title="&lt;b&gt;3.1 斯格明子存储单元底层硬件设计&lt;/b&gt;"><b>3.1 斯格明子存储单元底层硬件设计</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;3.2 斯格明子存储单元系统优化&lt;/b&gt;"><b>3.2 斯格明子存储单元系统优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="&lt;b&gt;4 实验与结果分析&lt;/b&gt; "><b>4 实验与结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="&lt;b&gt;4.1 基于斯格明子的计算单元性能评估&lt;/b&gt;"><b>4.1 基于斯格明子的计算单元性能评估</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;4.2 基于斯格明子的存内计算框架性能评估&lt;/b&gt;"><b>4.2 基于斯格明子的存内计算框架性能评估</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#154" data-title="&lt;b&gt;5 总 结&lt;/b&gt; "><b>5 总 结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 斯格明子-赛道型存储器件结构图">图1 斯格明子-赛道型存储器件结构图</a></li>
                                                <li><a href="#65" data-title="图2 存内计算架构">图2 存内计算架构</a></li>
                                                <li><a href="#71" data-title="图3 基于斯格明子的异或逻辑单元">图3 基于斯格明子的异或逻辑单元</a></li>
                                                <li><a href="#79" data-title="图4 基于斯格明子的进位逻辑门">图4 基于斯格明子的进位逻辑门</a></li>
                                                <li><a href="#86" data-title="图5 基于斯格明子逻辑门的全加器">图5 基于斯格明子逻辑门的全加器</a></li>
                                                <li><a href="#91" data-title="图6 全加器电压控制时序图">图6 全加器电压控制时序图</a></li>
                                                <li><a href="#104" data-title="图7 基于斯格明子的8位乘法器">图7 基于斯格明子的8位乘法器</a></li>
                                                <li><a href="#107" data-title="图8 基于斯格明子介质的存储单元">图8 基于斯格明子介质的存储单元</a></li>
                                                <li><a href="#112" data-title="图9 赛道型内存地址映射方式优化">图9 赛道型内存地址映射方式优化</a></li>
                                                <li><a href="#115" data-title="图10 使用赛道型地址映射的优势1例">图10 使用赛道型地址映射的优势1例</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表1 两种计算单元性能比较&lt;/b&gt;"><b>表1 两种计算单元性能比较</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表2 实验环境中关键参数配置&lt;/b&gt;"><b>表2 实验环境中关键参数配置</b></a></li>
                                                <li><a href="#132" data-title="图11 图像锐化程序在存内计算框架中具体执行过程">图11 图像锐化程序在存内计算框架中具体执行过程</a></li>
                                                <li><a href="#149" data-title="图12 与Base-16对比读写端口对移位操作数影响">图12 与Base-16对比读写端口对移位操作数影响</a></li>
                                                <li><a href="#152" data-title="图13 基于斯格明子的存内计算框架性能评估">图13 基于斯格明子的存内计算框架性能评估</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="179">


                                    <a id="bibliography_1" title="Luo Le, Liu Yi, Qian Depei.Survey on in-memory computing technology[J].Journal of Software, 2016, 27 (8) :2147-2167 (in Chinese) (罗乐, 刘轶, 钱德沛.存内计算技术研究综述[J].软件学报, 2016, 27 (8) :2147-2167) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201608017&amp;v=MDk0OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNuaFc3M0tOeWZUYkxHNEg5Zk1wNDlFWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Luo Le, Liu Yi, Qian Depei.Survey on in-memory computing technology[J].Journal of Software, 2016, 27 (8) :2147-2167 (in Chinese) (罗乐, 刘轶, 钱德沛.存内计算技术研究综述[J].软件学报, 2016, 27 (8) :2147-2167) 
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_2" title="Gokhale M, Holmes B, Iobst K.Processing in memory:The Terasys massively parallel PIM array[J].Computer, 1995, 28 (4) :23-31" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Processing in memory: the Terasys massively parallel PIM array">
                                        <b>[2]</b>
                                        Gokhale M, Holmes B, Iobst K.Processing in memory:The Terasys massively parallel PIM array[J].Computer, 1995, 28 (4) :23-31
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_3" title="Zhang Dongping, Jayasena N, Lyashevsky A, et al.TOP-PIM:Throughput-oriented programmable processing in memory[C]//Proc of the 23rd ACM Int Symp on HighPerformance Parallel and Distributed Computing.New York:ACM, 2014:85-98" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=TOP-PIM:Throughput-oriented programmable processing in memory">
                                        <b>[3]</b>
                                        Zhang Dongping, Jayasena N, Lyashevsky A, et al.TOP-PIM:Throughput-oriented programmable processing in memory[C]//Proc of the 23rd ACM Int Symp on HighPerformance Parallel and Distributed Computing.New York:ACM, 2014:85-98
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_4" title="Akin B, Franchetti F, Hoe J C.Data reorganization in memory using 3D-stacked DRAM[J].ACM SIGARCHComputer Architecture News, 2015, 43 (3) :131-143" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM24034E4C6D4CC3D45A348A575C79E3CB&amp;v=MjI1NTNvczJZcDhMZnc4NnV4SVdteng1UUE3bnF4ZEdmcnZoUnNudENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54aXhieTN3cW89TmlmSVk3RzhIdExJMg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Akin B, Franchetti F, Hoe J C.Data reorganization in memory using 3D-stacked DRAM[J].ACM SIGARCHComputer Architecture News, 2015, 43 (3) :131-143
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_5" title="Joshi M, Zhang Wangyuan, Li Tao.Mercury:A fast and energy-efficient multi-level cell based phase change memory system[C]//Proc of the 17th High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2011:345-356" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mercury:A Fast and Energy-Efficient Multi-level Cell based Phase Change Memory System">
                                        <b>[5]</b>
                                        Joshi M, Zhang Wangyuan, Li Tao.Mercury:A fast and energy-efficient multi-level cell based phase change memory system[C]//Proc of the 17th High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2011:345-356
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_6" title="K&#252;lt&#252;rsay E, Kandemir M, Sivasubramaniam A, et al.Evaluating STT-RAM as an energy-efficient main memory alternative[C]//Proc of the Performance Analysis of Systems and Software (ISPASS) .Piscataway, NJ:IEEE, 2013:256-267" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evaluating STT-RAM as an energy-efficient main memory alternative">
                                        <b>[6]</b>
                                        K&#252;lt&#252;rsay E, Kandemir M, Sivasubramaniam A, et al.Evaluating STT-RAM as an energy-efficient main memory alternative[C]//Proc of the Performance Analysis of Systems and Software (ISPASS) .Piscataway, NJ:IEEE, 2013:256-267
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_7" title="Lee B C, Ipek E, Mutlu O, et al.Architecting phase change memory as a scalable DRAM alternative[J].ACMSIGARCH Computer Architecture News, 2009, 37 (3) :2-13" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000044894&amp;v=MTQ1ODFUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZMSVZvY2FCQT1OaWZJWTdLN0h0ak5yNDlGWk84TEJIVTlvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Lee B C, Ipek E, Mutlu O, et al.Architecting phase change memory as a scalable DRAM alternative[J].ACMSIGARCH Computer Architecture News, 2009, 37 (3) :2-13
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_8" title="Parkin S, Yang Seehun.Memory on the racetrack[J].Nature Nanotechnology, 2015, 10 (3) :195-198" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Memory on the racetrack">
                                        <b>[8]</b>
                                        Parkin S, Yang Seehun.Memory on the racetrack[J].Nature Nanotechnology, 2015, 10 (3) :195-198
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_9" title="Mao Mengjie, Wen Wujie, Zhang Yaojun, et al.Exploration of GPGPU register file architecture using domain-wall-shiftwrite based racetrack memory[C]//Proc of the 51st Annual Design Automation Conf.New York:ACM, 2014:1-6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploration of GPGPU register file architecture using domain-wall-shift-write based racetrack memory">
                                        <b>[9]</b>
                                        Mao Mengjie, Wen Wujie, Zhang Yaojun, et al.Exploration of GPGPU register file architecture using domain-wall-shiftwrite based racetrack memory[C]//Proc of the 51st Annual Design Automation Conf.New York:ACM, 2014:1-6
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_10" title="Hu Qingda, Sun Guangyu, Shu Jiwu, et al.Exploring main memory design based on racetrack memory technology[C]//Proc of the 26th Great Lakes Symp on VLSI.Piscataway, NJ:IEEE, 2016:397-402" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploring main memory design based on racetrack memory technology">
                                        <b>[10]</b>
                                        Hu Qingda, Sun Guangyu, Shu Jiwu, et al.Exploring main memory design based on racetrack memory technology[C]//Proc of the 26th Great Lakes Symp on VLSI.Piscataway, NJ:IEEE, 2016:397-402
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_11" title="Yu Hao, Wang Yuhao, Chen Shuai, et al.Energy efficient in-memory machine learning for data intensive imageprocessing by non-volatile domain-wall memory[C]//Proc of the 19th Asia and South Pacific Design Automation Conf (ASP-DAC) .Piscataway, NJ:IEEE, 2014:191-196" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Energy efficient in-memory machine learning for data intensive image-processing by non-volatile domain-wall memory">
                                        <b>[11]</b>
                                        Yu Hao, Wang Yuhao, Chen Shuai, et al.Energy efficient in-memory machine learning for data intensive imageprocessing by non-volatile domain-wall memory[C]//Proc of the 19th Asia and South Pacific Design Automation Conf (ASP-DAC) .Piscataway, NJ:IEEE, 2014:191-196
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_12" title="Fert A, Cros V, Sampaio J.Skyrmions on the track[J].Nature Nanotechnology, 2013, 8 (3) :152-156" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Skyrmions on the track">
                                        <b>[12]</b>
                                        Fert A, Cros V, Sampaio J.Skyrmions on the track[J].Nature Nanotechnology, 2013, 8 (3) :152-156
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_13" title="Tomasello R, Martinez E, Zivieri R, et al.A strategy for the design of Skyrmion racetrack memories[J/OL].Scientific Reports, 2014:Article number 6784.[2018-08-02].https://www.nature.com/articles/srep06784" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A strategy for the design of skyrmion racetrack memories">
                                        <b>[13]</b>
                                        Tomasello R, Martinez E, Zivieri R, et al.A strategy for the design of Skyrmion racetrack memories[J/OL].Scientific Reports, 2014:Article number 6784.[2018-08-02].https://www.nature.com/articles/srep06784
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_14" title="Zhang Xichao, Ezawa M, Zhou Yan.Magnetic Skyrmion logic gates:Conversion, duplication and merging of Skyrmions[J/OL].Scientific Reports, 2015:Article number 9400.[2018-08-02].https://www.nature.com/articles/srep09400" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Magnetic skyrmion logic gates conversion duplication and merging of skyrmions">
                                        <b>[14]</b>
                                        Zhang Xichao, Ezawa M, Zhou Yan.Magnetic Skyrmion logic gates:Conversion, duplication and merging of Skyrmions[J/OL].Scientific Reports, 2015:Article number 9400.[2018-08-02].https://www.nature.com/articles/srep09400
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_15" title="Xing Xiangjun, Pong Philip, Zhou Yan.Skyrmion domain wall collision and domain wall-gated Skyrmion logic[J].Physical Review B, 2016, 94 (5) :054408" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Skyrmion domain wall collision and domain wall-gated skyrmion logic">
                                        <b>[15]</b>
                                        Xing Xiangjun, Pong Philip, Zhou Yan.Skyrmion domain wall collision and domain wall-gated Skyrmion logic[J].Physical Review B, 2016, 94 (5) :054408
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_16" title="Sun Guangyu, Zhang Chao, Li Hehe, et al.From device to system:Cross-layer design exploration of racetrack memory[C]//Proc of the Design, Automation and Test in Europe.San Jose, CA:EDA Consortium, 2015:1018-1023" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=From device to system cross-layer design exploration of racetrack memory">
                                        <b>[16]</b>
                                        Sun Guangyu, Zhang Chao, Li Hehe, et al.From device to system:Cross-layer design exploration of racetrack memory[C]//Proc of the Design, Automation and Test in Europe.San Jose, CA:EDA Consortium, 2015:1018-1023
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_17" title="Jeong M K, Yoon D H, Sunwoo D, et al.Balancing DRAMlocality and parallelism in shared memory CMP systems[C]//Proc of the High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2012:1-12" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Balancing DRAM locality and parallelism in shared memory CMP systems">
                                        <b>[17]</b>
                                        Jeong M K, Yoon D H, Sunwoo D, et al.Balancing DRAMlocality and parallelism in shared memory CMP systems[C]//Proc of the High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2012:1-12
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_18" title="Kang Wang, Huang Yangqi, Zheng Chentian, et al.Voltage controlled magnetic Skyrmion motion for racetrack memory[J/OL].Scientific Reports, 2016:Article number 23164.[2018-08-02].https://www.nature.com/articles/srep23164" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Voltage Controlled Magnetic Skyrmion Motion for Racetrack Memory">
                                        <b>[18]</b>
                                        Kang Wang, Huang Yangqi, Zheng Chentian, et al.Voltage controlled magnetic Skyrmion motion for racetrack memory[J/OL].Scientific Reports, 2016:Article number 23164.[2018-08-02].https://www.nature.com/articles/srep23164
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_19" title="Binkert N, Beckmann B, Black G, et al.The Gem5simulator[J].ACM SIGARCH Computer Architecture News, 2011, 39 (2) :1-7" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000147&amp;v=MjkwMDNpclJkR2VycVFUTW53WmVadUh5am1VTHZMSVZvY2FCQT1OaWZJWTdLN0h0ak5yNDlGWk9zUERYZytvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Binkert N, Beckmann B, Black G, et al.The Gem5simulator[J].ACM SIGARCH Computer Architecture News, 2011, 39 (2) :1-7
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_20" title="Li Sheng, Ahn J H, Strong R D, et al.McPAT:An integrated power, area, and timing modeling framework for multicore and manycore architectures[C]//Proc of the Annual IEEE/ACM Int Symp on Microarchitecture.Piscataway, NJ:IEEE, 2009:469-480" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=McPAT:an integrated power, area, and timing modeling framework for multicore and manycore architectures">
                                        <b>[20]</b>
                                        Li Sheng, Ahn J H, Strong R D, et al.McPAT:An integrated power, area, and timing modeling framework for multicore and manycore architectures[C]//Proc of the Annual IEEE/ACM Int Symp on Microarchitecture.Piscataway, NJ:IEEE, 2009:469-480
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_21" title="Dong Xiangyu, Xu Cong, Jouppi N, et al.NVSim:Acircuit-level performance, energy, and area model for emerging non-volatile memory[J].IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2012, 31 (7) :994-1007" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory">
                                        <b>[21]</b>
                                        Dong Xiangyu, Xu Cong, Jouppi N, et al.NVSim:Acircuit-level performance, energy, and area model for emerging non-volatile memory[J].IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2012, 31 (7) :994-1007
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(04),798-809 DOI:10.7544/issn1000-1239.2019.20180157            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于斯格明子介质的高效存内计算框架</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%BF%85%E6%88%90&amp;code=34878928&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘必成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%BE%E6%B5%B7%E5%B3%B0&amp;code=39651350&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">顾海峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E9%93%AD%E6%9D%BE&amp;code=28705993&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈铭松</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%B7%E5%AE%88%E7%8F%8D&amp;code=41491409&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谷守珍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E9%97%BB%E6%9D%B0&amp;code=25725791&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈闻杰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%B8%82%E9%AB%98%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6)&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海市高可信计算重点实验室(华东师范大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>存内计算 (processing in memory, PIM) 作为一种新兴的技术, 支持数据在存储单元内就地处理, 减少了数据的移动并增加了数据的并行处理, 在一定程度上弥补了冯·诺依曼架构的缺陷.和传统易失随机存储介质相比, 赛道型内存 (racetrack memory, RM) 具有密度大、非易失且静态功耗低等特点, 支持高效的存内计算.为解决性能与功耗问题, 提出了一种新型的基于斯格明子 (Skyrmion) 介质的非易失性存内计算框架.该框架采用斯格明子赛道内存 (Skyrmion-based racetrack memory) 作为存储单元, 采用斯格明子逻辑门 (Skyrmion-based logic gate) 构成的加法/乘法器组成计算单元, 无须大量CMOS (complementary metal oxide semiconductor) 电路辅助, 设计复杂度大大降低.同时, 通过在电路级优化存储单元读写端口数目与在系统级改进内存地址映射方式, 大幅提高该框架的运行效率.实验结果表明:相比基于磁畴壁 (domain-wall) 的非易失性存内计算框架, 提出的框架在运行时间上节省了48.1%, 同时在能耗上节省了42.9%.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%AF%E6%A0%BC%E6%98%8E%E5%AD%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">斯格明子;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E6%98%93%E5%A4%B1%E6%80%A7%E5%AD%98%E5%82%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非易失性存储;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%98%E5%86%85%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">存内计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B5%9B%E9%81%93%E5%AD%98%E5%82%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赛道存储;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">地址映射;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *陈铭松 (mschen@sei.ecnu.edu.cn) ;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61872147, 61702187);</span>
                                <span>“核高基”国家科技重大专项基金项目 (2017Z01038102-002);</span>
                                <span>中央高校基本科研业务费专项资金项目;</span>
                                <span>上海市自然科学基金项目 (15ZR1410000);</span>
                    </p>
            </div>
                    <h1><b>An Efficient Processing In Memory Framework Based on Skyrmion Material</b></h1>
                    <h2>
                    <span>Liu Bicheng</span>
                    <span>Gu Haifeng</span>
                    <span>Chen Mingsong</span>
                    <span>Gu Shouzhen</span>
                    <span>Chen Wenjie</span>
            </h2>
                    <h2>
                    <span>Shanghai Key Laboratory of Trustworthy Computing (East China Normal University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>As a new computing paradigm, processing in memory (PIM) allows the parallel computation in both processors and memories, which drastically reduce the movements between computation units and storage units. Therefore, PIM can be considered as an efficient technology to somewhat address the shortcomings of the von neumann architecture. Compared with traditional random access memories, racetrack memory has many merits including high density, non-volatility, and low static power. Therefore, it can be used for efficient PIM computing. To address the shortages of domain-wall based PIM, this paper proposes a novel PIM framework based on the Skyrmion material. In this framework, we use Skyrmion-based racetrack memories to construct storage units, and use Skyrmion-based logic gates to compose both adders and multipliers for the computation units. Since our framework does not need CMOS (complementary metal oxide semiconductor) circuits to assist the underlying computation unit construction, the design complexity is significantly reduced. Meanwhile, based on our proposed optimization methods for read and write operations at the circuit layer and address mapping mode of the memory at the system level, the performance of our framework is drastically improved. Experimental results show that compared with domain-wall based PIM framework, our approach can achieve 48.1% time improvement and 42.9% energy savings on average.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Skyrmion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Skyrmion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-volatile%20memory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-volatile memory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=processing%20in%20memory%20(PIM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">processing in memory (PIM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=racetrack%20memory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">racetrack memory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=address%20mapping&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">address mapping;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Liu Bicheng, born in 1988. MEn. His main research interests include computer architecture, processing in memory, and computer architecture. <image id="245" type="" href="images/JFYZ201904013_24500.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Gu Haifeng, born in 1991.PhD candidate. His main research interests include hardware/software co-validation, design automation of embedded systems, and software engineering. <image id="247" type="" href="images/JFYZ201904013_24700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Chen Mingsong, born in 1982. PhD, professor, PhD supervisor.Senior member of CCF. His main research interests include design automation and verification of cyber physical systems, cloud/embedded/parallel computing, computer architecture, and IoT Security.<image id="249" type="" href="images/JFYZ201904013_24900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Gu Shouzhen, born in 1987.PhD, lecturer. Member of CCF. Her main research interests include non-volatile memory, storage  architecture, and  embedded/parallel computing. <image id="251" type="" href="images/JFYZ201904013_25100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Chen Wenjie, born in 1977.PhD, associate professor.Senior member of CCF. His main research interests include software design for embedded real-time systems, logic design, and computer architecture.<image id="253" type="" href="images/JFYZ201904013_25300.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-03-07</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61872147, 61702187);</span>
                                <span>the National Science and Technology Major Project of Hegaoji (2017Z01038102-002);</span>
                                <span>the Fundamental Research Funds for the Central Universities;</span>
                                <span>the Natural Science Foundation of Shanghai (15ZR1410000);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="50">当今世界已进入大数据时代, 各种现代应用对数据处理速度的要求越来越高.然而在传统的冯·诺依曼架构中, 数据的存储和处理各自分离, 同时数据量与处理速度之间的差距也在逐步拉大, 严重制约了系统效率的进一步提高.为了克服这个困难, 文献<citation id="221" type="reference">[<a class="sup">1</a>,<a class="sup">2</a>]</citation>提出了新型存内计算 (processing in memory, PIM) 架构, 并受到广泛关注和研究<citation id="222" type="reference"><link href="183" rel="bibliography" /><link href="185" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>.在存内计算架构中, 存储单元和计算单元在内存中紧密地结合在一起, 使得数据可以直接在内存中就地进行处理, 从而极大地减少了数据在内存和处理器之间的频繁移动且增加了数据处理的并行性.</p>
                </div>
                <div class="p1">
                    <p id="51">虽然存内计算架构在一定程度上缓解了“数据搬运”的瓶颈问题, 然而由于传统存内计算建立在易失性存储器介质之上, 其物理特性限制导致整个系统泄漏功耗和动态功耗随着处理数据量的增加而急剧增长.近期各种新型非易失性内存介质 (non-volatile memory, NVM) 正因其区别与传统介质的低漏电率、高密度等一系列优良的特性而受到广泛关注<citation id="223" type="reference"><link href="187" rel="bibliography" /><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>.典型的包括相变存储器 (phase change memory, PCRAM) 、自旋力矩存储器 (spin-transfer torque memory, STT-RAM) 、赛道型存储器 (racetrack memory, RM) 等.其中RM通过将多个比特的数据存储在一条类似磁带的纳米线上, 提供了比自旋力矩存储器更高的存储密度, 比相变存储器更高的写入寿命, 以及接近静态随机存取存储器 (static random access memory, SRAM) 的读写速度<citation id="224" type="reference"><link href="193" rel="bibliography" /><link href="195" rel="bibliography" /><link href="197" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="52">赛道型存储的本身物理结构决定了其不但适用于存储数据, 也非常容易组成各种逻辑结构来进行数据处理, 因此可以用来作为存内计算的介质.第1代赛道型存储器是基于磁畴壁 (domain-wall) 介质的, 文献<citation id="225" type="reference">[<a class="sup">11</a>]</citation>在此基础上提出了一种较为通用的存内计算架构.然而这种基于磁畴壁介质的存内架构依然需要大量的CMOS (complementary metal oxide semiconductor) 外围电路来进行辅助计算, 导致了计算单元体积和能耗的增加.</p>
                </div>
                <div class="p1">
                    <p id="53">最近新型的基于斯格明子介质的第2代赛道型存储器被提出<citation id="227" type="reference"><link href="201" rel="bibliography" /><link href="203" rel="bibliography" /><link href="205" rel="bibliography" /><link href="207" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.相比磁畴壁介质, 斯格明子介质具有密度更高、能耗更低、稳定性更强以及更少受限于材料等一系列优良特性, 非常适合作为下一代存内计算的介质.同样这种介质特性也非常适合使用在嵌入式系统中, 甚至可以用来构建基于嵌入式系统的移动存内计算框架.然而目前对于斯格明子介质的研究主要集中于硬件存储功能, 缺乏关于计算功能的研究, 系统层次以及具体应用实现也很少涉及<citation id="226" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>.另一方面由于斯格明子-赛道型存储器特有的条带状物理结构, 使其具有特有的顺序读写特性, 如何用其替代现有存内计算架构下的存储单元也是亟待解决的问题.</p>
                </div>
                <div class="p1">
                    <p id="54">针对以上问题, 本文提出了一种基于斯格明子介质的存内计算框架, 主要贡献有4点:1) 结合斯格明子介质本身的物理特性, 由斯格明子逻辑门组成加法器、乘法器等计算单元并进行优化, 极大地减少了CMOS辅助电路的使用, 提高了计算效率;2) 在硬件电路层面上对于基本存储单元读写端口数等参数进行探讨, 并通过实验优化配置;3) 在系统层上对内存的地址映射方式进行改进, 提高了整个系统的运行效率;4) 以通用的图像锐化程序为例详细说明了程序在内存框架中的工作流程, 同时将本文提出的基于斯格明子介质的内存框架与目前最先进的基于磁畴壁的存内计算框架进行实验对比.</p>
                </div>
                <h3 id="55" name="55" class="anchor-tag"><b>1 基于斯格明子介质的存内计算框架</b></h3>
                <div class="p1">
                    <p id="56">基于斯格明子介质的存内计算主要包含2部分:基于斯格明子介质的存储单元和计算单元, 其中存储单元即斯格明子-赛道型存储器, 是整个框架的基础.</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>1.1 斯格明子-赛道型存储器件</b></h4>
                <div class="p1">
                    <p id="58">斯格明子-赛道型存储器<citation id="228" type="reference"><link href="201" rel="bibliography" /><link href="203" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>, 区别于磁畴壁-赛道型存储器, 是一种基于斯格明子编码的非易失性存储器.如图1所示, 数据通过斯格明子编码之后存储在一条单一的铁磁纳米线 (nanowire) 器件上.纳米线上的斯格明子由电压控制的磁各向异性 (voltage-controlled magnetic anisotropy, VCMA) 门所隔离, 每2个门之间存储一位数据.如果此区间内存在斯格明子则代表数据1, 如果不存在斯格明子则代表数据0.斯格明子-赛道型存储器件有3项基本操作:移位、读和写, 其中具有移位操作是其最重要的特性.</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 斯格明子-赛道型存储器件结构图" src="Detail/GetImg?filename=images/JFYZ201904013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 斯格明子-赛道型存储器件结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Skyrmion based nanowire device</p>

                </div>
                <div class="p1">
                    <p id="60">斯格明子-赛道型存储器件的移位操作, 是指在磁各向异性门打开时纳米线上的斯格明子可以通过在存储器两端移位端口 (shift port) 施加电流来进行向左或向右移动.为了保证移位操作之后记录在纳米线上的数据不丢失, 在纳米线两端应当有冗余的存储位供位移操作使用.整体来说所有比特数据的移位都类似于磁带操作, 和移位寄存器类似.</p>
                </div>
                <div class="p1">
                    <p id="61">斯格明子-赛道型存储器件读、写操作的基本原理类似.在存储器器件中有读写端口 (write/read port) , 即沿着纳米线方向放置的一个强磁化铁磁层, 但是其和纳米线之间由较薄的绝缘层隔开.这样的三明治结构形成了磁隧道结 (magnetic tunnel junctions, MTJs) .通过向写端口的MTJ结构中注入自旋极化电流 (spin-transfer current) 就可以在纳米线上产生一个斯格明子.同样读端口也是一个MTJ结构, 通过检测读端口MTJ隧穿电导 (tunneling conductance) 的变化就可以得知纳米线上当前位置是否存在斯格明子, 即数据是0还是1.需要注意的是, 由于写和读操作只能在固定的MTJ端口处进行, 因此纳米线上比特位数据的操作需要移动到与MTJ固定层对齐的位置才能进行, 而移位操作的方向和速度取决于控制电流的方向和幅度.</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>1.2 基于斯格明子介质的存内计算框架</b></h4>
                <div class="p1">
                    <p id="63">传统上所有的数据都是保存在和处理器分离的主存中, 二者通过总线相连接.因此在程序执行过程中所有的数据都需要迁移到处理器中, 并在处理完成之后再次写回.对于以数据为导向的应用, 这将产生严重的通信堵塞, 从而大大降低总体性能.此外在传统的内存中保存大量的数据也将产生明显的待机能耗.</p>
                </div>
                <div class="p1">
                    <p id="64">为了克服上述2个问题, 我们使用基于非易失性内存的计算架构.首先存内计算架构在一定程度上解决了数据传输瓶颈的问题, 也减少了数据传输的能耗;其次非易失性内存在极大地减少待机功耗的同时也降低了内存的动态功耗.基于斯格明子-赛道型存储器的存内计算平台整体结构如图2所示, 其中存内计算单元与存储单元以分布式的方式组合成存储-计算单元组, 这样许多频繁处理数据的操作可以在内存内部完成而无需与外部处理器进行通信, 从而极大地节省了时间与能耗的开销.同时分布式的内存处理单元也可以提供巨大的线程级并行性, 从而极大地提高系统吞吐量.</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 存内计算架构" src="Detail/GetImg?filename=images/JFYZ201904013_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 存内计算架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The structure of PIM platform</p>

                </div>
                <div class="p1">
                    <p id="66">在本文提出的基于斯格明子的存内计算框架中, 内存存储单元由基于斯格明子的赛道型存储器构成, 从而受益于其低漏电功耗、非易失性以及稳健性等优点.同时存内计算单元纯粹由基于斯格明子逻辑门的加法器、乘法器等组成, 只需要极少的CMOS电路辅助, 因此总体漏电功耗和处理数据所需的动态功耗和时间消耗都极大地减少.在本文提出的存内计算框架中, 存储-计算单元组之间通过H型内部数据通路相连接, 这样单元组与单元组之间的数据可以随时根据需要进行传输, 而外部处理器 (即CPU) 主要负责将控制指令传输给内存内部的控制单元, 由内部控制单元负责内存中存储与计算单元具体数据的调度处理.由于斯格明子既具有计算功能又具有存储功能, 因此在本文提出的存内计算框架中, 计算单元得到的结果将直接写入存储单元中, 即存储单元本身完成了类似寄存器的时序逻辑功能.</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag"><b>2 基于斯格明子介质的计算单元设计</b></h3>
                <div class="p1">
                    <p id="68">本节首先从硬件层面考虑, 提出基于斯格明子逻辑门的加法逻辑单元和进位逻辑单元设计, 再进一步提出整个全加器的设计, 最后在全加器设计的基础上提出了基于斯格明子逻辑门乘法器的设计, 并进一步对加法器进行了优化.</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>2.1 基于斯格明子逻辑门的加法逻辑</b></h4>
                <div class="p1">
                    <p id="70">典型的逻辑和运算由2个异或门组成, 然而异或逻辑门无法直接使用斯格明子器件实现.这个问题可以通过斯格明子逻辑门组合来实现<citation id="231" type="reference"><link href="205" rel="bibliography" /><link href="207" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.其中文献<citation id="229" type="reference">[<a class="sup">14</a>]</citation>实现了基于斯格明子的逻辑与门和逻辑或门, 同时包含基于斯格明子的复制 (duplication) 逻辑, 而文献<citation id="230" type="reference">[<a class="sup">15</a>]</citation>中实现了基于斯格明子的逻辑与非门和逻辑或非门.在此基础上本文构建了基于斯格明子的异或逻辑门.如图3 (b) 所示, 基于斯格明子的异或逻辑门由1个或门, 1个与非门以及1个与门组成.需要注意的是, 图3 (b) 中OR2-Gate是与非门NAND-Gate的一部分, 输入部分<i>A</i><sub><i>n</i></sub>和<i>B</i><sub><i>n</i></sub>分别代表数据<i>A</i>和<i>B</i>的第<i>n</i>位.正如图3 (a) 所示, <i>A</i>和<i>B</i>是一个存储在斯格明子纳米线上8 b的数据.在斯格明子纳米线上, 如果某个位置存在有斯格明子, 它就代表数值1;如果没有斯格明子, 它就表示数值0.因此图3 (a) 以二进制形式表示<i>A</i>=10111001, <i>B</i>=10101110.</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于斯格明子的异或逻辑单元" src="Detail/GetImg?filename=images/JFYZ201904013_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于斯格明子的异或逻辑单元  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Skyrmion nanowire-based XOR-logic</p>

                </div>
                <div class="p1">
                    <p id="72">当<i>n</i>=1时异或逻辑单元工作步骤有3个:</p>
                </div>
                <div class="p1">
                    <p id="73">1) 操作数<i>A</i><sub>1</sub>和<i>B</i><sub>1</sub>同时进入逻辑门OR1和NAND.由于<i>A</i><sub>1</sub>=1, <i>B</i><sub>1</sub>=0也即有一个斯格明子进入逻辑门OR1, 一个斯格明子进入逻辑门NAND.</p>
                </div>
                <div class="p1">
                    <p id="74">2) 代表<i>A</i><sub>1</sub>的斯格明子分别通过逻辑门OR1和NAND并保持不变.</p>
                </div>
                <div class="p1">
                    <p id="75">3) 从逻辑门OR1和NAND出来的2个斯格明子同时进入逻辑门AND, 最终合并成一个斯格明子, 从而可以得到<i>A</i><sub>1</sub>⊕<i>B</i><sub>1</sub>=1.</p>
                </div>
                <div class="p1">
                    <p id="76">通过基于斯格明子纳米线器件的异或逻辑单元我们可以实现带进位的加法逻辑单元 (<i>SUM</i>=<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>⊕<i>C</i><sub>in</sub>, 其中<i>C</i><sub>in</sub>为进位) .即通过组合2个异或逻辑单元:第1个异或逻辑单元输入是<i>A</i><sub><i>n</i></sub>和<i>B</i><sub><i>n</i></sub>, 输出是<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>;第2异或逻辑单元输入是<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>和<i>C</i><sub>in</sub>, 而输出是当前位的进位和<i>SUM</i>.</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>2.2 基于斯格明子逻辑门的进位逻辑</b></h4>
                <div class="p1">
                    <p id="78">一个典型的进位逻辑由3个与门和2个或门组成.图4显示了基于斯格明子逻辑门的进位逻辑单元具体设计细节.</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于斯格明子的进位逻辑门" src="Detail/GetImg?filename=images/JFYZ201904013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于斯格明子的进位逻辑门  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Skyrmion nanowire-based carry-logic</p>

                </div>
                <div class="p1">
                    <p id="80">如图4所示, 进位逻辑单元有3组输入:<i>A</i><sub><i>n</i></sub>和<i>B</i><sub><i>n</i></sub>, <i>A</i><sub><i>n</i></sub>和<i>C</i><sub>in</sub>, <i>B</i><sub><i>n</i></sub>和<i>C</i><sub>in</sub>, 以及一个输出:<i>C</i><sub>out</sub>.其中输入<i>C</i><sub>in</sub>为第<i>n</i>-1位的进位, 输出<i>C</i><sub>out</sub>为第<i>n</i>位的进位.进位逻辑单元具体实现细节有4点:</p>
                </div>
                <div class="p1">
                    <p id="81">1) 代表上述3组输入第<i>n</i>位数值的斯格明子粒子分别进入了3个与门, 即AND1～AND3.</p>
                </div>
                <div class="p1">
                    <p id="82">2) 第1个与门AND1的输出和第2个与门AND2的输出将同时进入第1个或门OR1.第3个与门AND3的输出将在进入第2个或门OR2之前等待OR1的输出.</p>
                </div>
                <div class="p1">
                    <p id="83">3) 第1个或门OR1的输出与第3个与门AND3的输出同时进入第2个或门OR1.</p>
                </div>
                <div class="p1">
                    <p id="84">4) 第2个或门的输出即进位的值<i>C</i><sub>out</sub>.</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.3 基于斯格明子逻辑门的全加器</b></h4>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于斯格明子逻辑门的全加器" src="Detail/GetImg?filename=images/JFYZ201904013_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于斯格明子逻辑门的全加器  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Skyrmion nanowire-based full adder</p>

                </div>
                <div class="p1">
                    <p id="87">基于斯格明子逻辑门的全加器如图5所示, 此全加器由3个主要部分构成:第1部分 (PART1) 是和运算部分, 由第1个异或逻辑组成, 它的输入是<i>A</i><sub><i>n</i></sub>和<i>B</i><sub><i>n</i></sub>, 输出是<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>.同时第1部分还有一个复制逻辑 (duplication) 以便为第3部分 (PART3) 提供输入.第2部分 (PART2) 是进位逻辑, 其输入是<i>A</i><sub><i>n</i>-1</sub>, <i>B</i><sub><i>n</i>-1</sub>, <i>C</i><sub><i>n</i>-1</sub>, 而输出是<i>C</i><sub><i>n</i></sub>即<i>n</i>-1位的进位.同时<i>C</i><sub><i>n</i></sub>会复制4份, 其中2份作为第3部分 (PART3) 的输入, 另外2份作为下一位加法的输入.第3部分 (PART3) 由第2个异或逻辑构成, 其输入是<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>和<i>C</i><sub><i>n</i></sub>, 即第1部分和第2部分的输出, 而输出就是全加器的最终结果:<i>SUM</i>=<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>⊕<i>C</i><sub><i>n</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="88">图5中的针孔形状部分代表一种能量势垒 (energy barrier) <citation id="232" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 这种能量势垒在电压为正的时候可以阻止斯格明子通过, 而在电压为0的时候允许斯格明子通过, 从而起到类似开关的作用.通过能量势垒的开关可以使得斯格明子同步进入逻辑门的2个输入端以保证逻辑门的正常工作.注意, 当<i>n</i>=1时, <i>A</i><sub><i>n</i></sub>代表数据<i>A</i>的第1位, 此时<i>A</i><sub><i>n</i>-1</sub>不存在即无任何输入, <i>B</i><sub><i>n</i>-1</sub>与<i>C</i><sub><i>n</i></sub>也相同.</p>
                </div>
                <div class="p1">
                    <p id="89">不同斯格明子逻辑门的传播时延已在文献<citation id="233" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>]</citation>中给出.基于已知的各种逻辑门的工作时间, 当整个系统的工作频率为1 000 MHz时, 通过计算得知全加器进行1位的加法需要11个时钟周期.考虑到能量势垒开关在使逻辑门输入同步的同时也使得各个逻辑门之间相互隔离, 因此当进行多个位的加法时可以利用此特性对全加器的工作流程进一步优化.受CPU流水线优化技术启发, 我们对全加器进行了优化:在1位加法计算完成之前就允许下一位的数据进入全加器, 从而极大地提高了整体工作效率.</p>
                </div>
                <div class="p1">
                    <p id="90">经过优化后的全加器电路时序图如图6所示.其中横坐标的数字1～19分别代表19个时钟周期, 每个时钟周期为1 ns;纵坐标的Gate 1～13分别对应图6所示全加器中对应的13个逻辑门的控制电压, 即每个逻辑门输入端口处能量势垒开关的电压.经过优化后的全加器主要时序逻辑为</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 全加器电压控制时序图" src="Detail/GetImg?filename=images/JFYZ201904013_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 全加器电压控制时序图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Timing diagram of 8-bit full adder</p>

                </div>
                <div class="p1">
                    <p id="92">1) 第1个时钟周期.Gate1～2, Gate5～7对应的控制电压为低电压, 因此对应输入 端口的斯格明子 (也即<i>A</i><sub><i>n</i></sub>, <i>B</i><sub><i>n</i></sub>, <i>A</i><sub><i>n</i>-1</sub>, <i>B</i><sub><i>n</i>-1</sub>, <i>C</i><sub><i>n</i>-1</sub>) 可以进入OR-Gate1, NAND-Gate2和AND-Gate5.为了保证输入同步, Gate3～4, Gate8～9和Gate11对应的控制电压为高电压.其他逻辑门对应的控制电压均保持低电压, 因为这些逻辑门还未被使用.</p>
                </div>
                <div class="p1">
                    <p id="93">2) 第2个时钟周期.Gate1～2, Gate5～7对应的控制电压变为高电压以阻止斯格明子进入对应逻辑门, 同时Gate3～4, Gate9和Gate11的控制电压继续保持高电压以完成逻辑门同步功能.Gate8的控制电压从高电压转为低电压从而使得斯格明子进入OR-Gate8, 其他逻辑门的对应控制电压依然保持不变.</p>
                </div>
                <div class="p1">
                    <p id="94">3) 第3个时钟周期.Gate9的控制电压转为低电压以便斯格明子进入OR-Gate9, 同时后续Gate10的控制电压转变为高电压以完成同步功能, 其他逻辑门的控制电压保持不变.</p>
                </div>
                <div class="p1">
                    <p id="95">4) 第6个时钟周期.Gate4的控制电压从高电压变为低电压以便斯格明子进入AND-Gate4;同时 Gate2的控制电压变为低电压以便允许下个比特的数据进入NAND-Gate2, 后续Gate3依然保持高电压.</p>
                </div>
                <div class="p1">
                    <p id="96">5) 第8个时钟周期.Gate10～11的控制电压转为低电压从而<i>A</i><sub><i>n</i></sub>⊕<i>B</i><sub><i>n</i></sub>和<i>C</i><sub><i>n</i></sub>对应的斯格明子可以进入 OR-Gate10和NAND-Gate11.Gate12～13的控制电压为了保持同步应变为高电压状态.同时Gate5～7的控住电压转为高电压, 而Gate8的控制电压转为低电压.</p>
                </div>
                <div class="p1">
                    <p id="97">6) 第13个时钟周期.Gate5～7的控制电压转为高电压以阻止斯格明子进入逻辑门, 同时Gate8, Gate10, Gate11, Gate13的控制电压转为低电压.</p>
                </div>
                <div class="p1">
                    <p id="98">7) 第14个时钟周期.可以通过输出端口是否有斯格明子判断SUM的值是0还是1, 从而得到求和运算的第1个位数值.</p>
                </div>
                <div class="p1">
                    <p id="99">8) 第15个时钟周期及以后.不断重复第10～14个时钟周期的状态, 每隔5个时钟周期就可以读出和的下一位数值.</p>
                </div>
                <div class="p1">
                    <p id="100">如图6所示, 经过计算可以得知第1位的加法需要14个时钟周期 (每个时钟周期1 ns) , 而从第2位开始每5个时钟周期全加器就可以完成一个位的加法.这是由于经过优化后全加器内部各个逻辑门之间相互独立运行, 从而可以获得类似流水线的优化效果, 考虑到在进行大量数据处理时或者随着运行频率的进一步提高优化效果依然可以进一步提高.对于常用的8 b的加法, 本文提出的基于斯格明子介质的全加器经过优化后只需要49个时钟周期即49 ns, 相比基于磁畴壁的第1代赛道存储内存加法器 (8位加法需要108 ns) <citation id="234" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>快了2.2倍.</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>2.4 基于斯格明子逻辑门的乘法器</b></h4>
                <div class="p1">
                    <p id="102">通常来说乘法可以分解为多次移位操作和加法操作, 而本文提出的存内计算框架中全加器可以通过纯粹的基于斯格明子逻辑门实现, 移位操作又是斯格明子纳米线器件自带的能力, 因此本文提出如图7所示基于斯格明子逻辑门的8位乘法器.</p>
                </div>
                <div class="p1">
                    <p id="103">在图7中, <i>A</i><sub><i>n</i></sub>代表当对应操作数<i>B</i>的第<i>n</i>位为1时, 需要将操作数<i>A</i>左移<i>n</i>-1位.例如当操作数<i>A</i>和<i>B</i>的二进制形式分别为1101和111时, 有<i>A</i><sub>0</sub>=1101, <i>A</i><sub>1</sub>=11010, <i>A</i><sub>2</sub>=110100, 此时<i>A</i>乘以<i>B</i>就等于<i>A</i><sub>0</sub>+<i>A</i><sub>1</sub>+<i>A</i><sub>2</sub>.由于操作数<i>A</i>存储在斯格明子纳米线上, 而纳米线器件本身就支持移位操作, 因此<i>A</i><sub><i>n</i></sub>可以通过将操作数<i>A</i>左移<i>n</i>位得到, 再直接输入全加器中得到乘法结果.因此基于斯格明子的乘法器可以通过重复利用已有的斯格明子全加器和本身的移位来实现, 因此大大减少了计算逻辑单元所需的空间以及时间, 同时也减少了实现存内计算框架的复杂程度.</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 基于斯格明子的8位乘法器" src="Detail/GetImg?filename=images/JFYZ201904013_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 基于斯格明子的8位乘法器  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 8-bit Skyrmion nanowire-based multiplier</p>

                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>3 基于斯格明子介质的存储单元设计</b></h3>
                <div class="p1">
                    <p id="106">在存内计算框架中存储单元与计算单元一同对整个系统的性能起着至关重要的作用.而斯格明子-赛道型存储器本身的物理特性决定其与传统的DRAM存储器随机读写的方式并不相同, 斯格明子-赛道型存储器具有顺序读写的特性.因此我们无法简单地用斯格明子存储单元直接替代DRAM存储单元.为了进一步提高斯格明子存内计算框架的效率, 我们需要根据斯格明子-赛道型存储器的本身物理特性来从底层硬件及系统软件2个层面考虑存内计算框架中存储单元的设计.</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 基于斯格明子介质的存储单元" src="Detail/GetImg?filename=images/JFYZ201904013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 基于斯格明子介质的存储单元  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Skyrmion based memory cell</p>

                </div>
                <h4 class="anchor-tag" id="108" name="108"><b>3.1 斯格明子存储单元底层硬件设计</b></h4>
                <div class="p1">
                    <p id="109">基于斯格明子的基本存储单元具体结构如图8所示.其中存储部分由RT0到RT3共4条基本赛道组成.每条赛道上可能有<i>n</i>个读写端口 (图8中圆形部分) , 这样每个单元可以一次读写4<i>n</i> (单位为b) .典型的赛道型存储器具有3个基本操作即读、写以及移位.由于其中移动数据的移位操作占据绝大部分的时间和能耗, 所以如何在不影响系统性能的情况下尽量减少数据的移位操作是亟待解决的问题.</p>
                </div>
                <div class="p1">
                    <p id="110">在图8所示结构中, 减少移位最直观有效的方法是增加读写端口的数量.但是由于读写端口本身会占用大量的空间, 因此增加读写端口会相应降低存储的密度, 同时会带来读写延时、能耗的增加以及实现工艺的复杂化, 因此需要在增加读写端口与减少数据移位之间寻找一个平衡点.同时每个基本存储单元由几条赛道组成, 以及每条赛道的长度 (即可以存储的数据量) 是多少, 都对整个读写单元的性能有着至关重要的影响.文献<citation id="235" type="reference">[<a class="sup">10</a>,<a class="sup">13</a>]</citation>经过大量实验分析得知在多数应用中, 每个基本存储单元中由4个条带组成, 每个条带存储64 b数据能取得较好性能.这时如果每条赛道的读写端口大于16, 单个存储单元占用面积以及读写时延以及功耗都会急剧增加;而当读写端口数小于16时, 单个存储单元占用面积随着端口数减少反而会增加, 因为此时条带两端需要为移位操作预留的空间也越来越大.同时在后续的实验部分中, 本文也分析了在本文提出的基于斯格明子的存内计算框架下读写端口的数量与移位操作数的相应变化, 综合考虑我们选择读写端口为16.</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.2 斯格明子存储单元系统优化</b></h4>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 赛道型内存地址映射方式优化" src="Detail/GetImg?filename=images/JFYZ201904013_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 赛道型内存地址映射方式优化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Address mapping based on Skyrmion</p>

                </div>
                <div class="p1">
                    <p id="113">由于斯格明子-赛道型存储器不同于传统的DRAM存储器具有顺序读写的特性, 因此传统的为随机读写存储器设计的系统地址映射方式并不适用于这种新型的非易失性存储器.图9 (a) 所示为传统的DRAM的地址映射方式RBC (row bank column) , 这种存储系统通常使用一种典型的开放式页面地址映射策略, 将所有相邻列的同一行映射到一个连续的区域, 使空间局部性最大化.同时, 它通过行列交织的方式来管理流水线式的内存请求.</p>
                </div>
                <div class="p1">
                    <p id="114">对于斯格明子-赛道型存储器来说, 关键问题是传统地址映射方式将每个行作为一个连续区域而不考虑移位的问题, 也不考虑这些行可能横跨了许多不同内存存储单元, 因此可能会带来非常严重的负面效应.如图10所示, 256行依次分布在第1存储单元MC1到第64存储单元MC64, 为了简化讨论, 假设内存中有64个基本存储单元, 每个存储单元只有1条存储赛道, 每条赛道只能存储4 b数据且只有1个读写端口.在传统的地址映射方式下由于内存访问都具有很高的空间局部性, 导致内存访问可能在不同存储单元之间以及存储单元内部频繁切换.在图10的例子中, 应用程序的内存访问序列为R4→R8→R1→R4→R6.这些请求只映射到2个相关存储单元 (MC1, MC2) , 从而导致了多次移位操作 (总移位为14次) .考虑到基于斯格明子的存储器存储密度极大化以及内存访问的局部性, 再结合存内计算的具体应用场景, 本文提出了一种新的地址映射方式, 即基于斯格明子介质的地址映射方式 (address mapping based on Skyrmion, AMBS) .</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 使用赛道型地址映射的优势1例" src="Detail/GetImg?filename=images/JFYZ201904013_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 使用赛道型地址映射的优势1例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 An example of using AMBS</p>

                </div>
                <div class="p1">
                    <p id="116">我们首先解释这种地址映射方案如何具体实现.AMBS将地址位 (第16 b到第31 b) 分为3部分:SN, PN, MN, 见图9 (b) .其中SN (shift number) 表示初始行和其对应访问端口的距离, 即初始数据需要移位多少次才能够被访问.PN (port number) 表示的是访问数据对应的端口序列号, 即通过第几个端口去访问数据.MN (memory cell number) 表示基本存储单元的编号.具体地说, 如果每个<i>x</i>位数据共享一个端口, 即要将内存中所有的行地址按照SN的数值划分为<i>x</i>组, 并将地址相邻的行划为同一组. AMBS策略优先在组内进行数据分配, 只有组内整个空间分配完之后, 才将后续数据分配给下一组.</p>
                </div>
                <div class="p1">
                    <p id="117">通过这种赛道型内存地址映射方式可以极大地减少移位操作, 原因主要有2方面:1) 在组间来说, 假设内存的总容量为8 GB, 每32 b数据共享一个端口, 此时每组的大小为256 MB (8 GB/32) , 此时由于内存读取的局部性, 内存访问序列有极大可能属于某一组, 因此可以减少由于较小区域的空间局部性导致的频繁移位操作.2) 在组内来说, 由于延迟和能耗主要来自于移位操作, 特别是长距离的移位操作, 因此减少移位的距离也能提高系统性能.而赛道型内存地址映射能将大部分内存读写的移位操作距离减少至1, 这是因为同一存储单元中相邻2行的地址差距非常大 (256 MB) .</p>
                </div>
                <div class="p1">
                    <p id="118">结合上述说明, 我们以图10为例来说明AMBS是如何工作的.内存访问序列为R4→R8→R1→R4→R6, 在传统的内存映射方式下, 需要14次移位操作才能够读取完这些数据, 而在基于赛道内存的操作下不需要进行任何移位任何操作就能完成内存数据的读取, 节省了大量时间和能耗的开销.而赛道型内存地址映射方式的实现方式, 可以通过在操作系统中使用一个统一的分系统管理物理页, 并形成了一个层次结构基于Shift和Port的可用页面列表, 类似于页面着色技术<citation id="236" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 根据应用程序需要的不同存储容量, 尽可能地分配一个连续的区域.因此最简单的方式, 可以使用一个静态的物理地址的映射系统, 在内存控制器中或斯格明子-赛道型存储器芯片内部实现.这样就可以在不改变现有操作系统的存储器体系接口下实现, 因此带来的额外开销也基本可以忽略.</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag"><b>4 实验与结果分析</b></h3>
                <div class="p1">
                    <p id="120">本节分别从硬件层和系统层对基于斯格明子介质的存内计算单元进行性能评估.首先对于硬件层面, 探讨了基于斯格明子逻辑门的存内计算单元的性能, 其次在系统层面上通过通用的图像锐化程序对于内存存储单元的读写端口个数与数据移位操作数的关系, 以及整个存内计算系统的时间及能耗效率进行了评估.</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>4.1 基于斯格明子的计算单元性能评估</b></h4>
                <div class="p1">
                    <p id="122">斯格明子逻辑门组成的基本运算单元作为存内计算框架的基础, 首先我们需要对其性能进行评估.本实验中所用的斯格明子器件的读写时间与能耗数据来自于文献<citation id="237" type="reference">[<a class="sup">18</a>]</citation>, 同时移位操作的能耗可以通过斯格明子纳米线的热耗散数据计算得出, 移位操作的时间可以通过斯格明子在纳米线上的移动速度计算得出.需要注意的是当斯格明子逻辑门的工作状态即输入不同时, 纳米线上的驱动电流密度也会随之变化<citation id="239" type="reference"><link href="205" rel="bibliography" /><link href="207" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.例如当逻辑与门的输入为0和1时 (即只有一个斯格明子进入与门) , 电流密度为7×10<sup>12</sup> A/m<sup>-2</sup> ;当逻辑与门的输入为1和1时 (即有2个斯格明子同时进入与门) , 电路密度为4×10<sup>12</sup> Am<sup>-2</sup>, 因此在计算整个计算单元的功耗时我们只能取其平均值.在斯格明子逻辑门中使用的纳米线长约为600 nm, 宽度约为100 nm<citation id="238" type="reference"><link href="205" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 由此我们可以计算出计算单元占用的面积.基于斯格明子计算单元对比基于磁畴壁计算单元极大地减少了额外COMS电路的使用, 不仅使得性能上有所提高, 也极大地减少了实现工艺所需的复杂度.</p>
                </div>
                <div class="p1">
                    <p id="123">表1中对比了基于斯格明子计算单元和基于磁畴壁计算单元在时间、能耗和面积上的区别.可以看出, 本文提出的基于斯格明子的存内计算单元相比目前最先进的基于磁畴壁的存内计算单元节省了54.6%的时间、42.9%的能耗以及23.1%的占用面积.这主要归功于斯格明子介质优异的物理性质:加法计算单元进行的优化, 以及乘法计算单元对于加法器的复用.同时相比基于磁畴壁计算单元, 大大减少了外围辅助电路的需求, 简化了电路设计, 使得基于斯格明子计算单元更容易被实现.</p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表1 两种计算单元性能比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Performance Comparison of Two Computing Units</b></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td rowspan="2"><br />Functional<br />Unit</td><td colspan="2"><br />8 b Full Adder</td><td colspan="2">8 b Multiplier</td></tr><tr><td><br />Skyrmion</td><td>DW</td><td>Skyrmion</td><td>DW</td></tr><tr><td><br />Speed/cycle</td><td>49</td><td>108</td><td>149</td><td>326</td></tr><tr><td><br />Energy/pJ</td><td>28</td><td>40</td><td>196</td><td>308</td></tr><tr><td><br />Area/μm<sup>-2</sup></td><td>2.0</td><td>2.6</td><td>16.8</td><td>19.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>4.2 基于斯格明子的存内计算框架性能评估</b></h4>
                <h4 class="anchor-tag" id="126" name="126">4.2.1 实验环境配置</h4>
                <div class="p1">
                    <p id="127">为了更准确评估基于斯格明子的存内计算框架的总体性能, 本文采用调整过的基于磁畴壁的存内计算框架<citation id="240" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>来作为比较对象.为了模拟应用程序在存内计算框架中的具体执行过程, 我们修改了体系结构模拟器Gem5<citation id="241" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>中内存部分, 同时为了获得具体时间和能耗数据, 我们结合了功耗和时序建模工具McPAT<citation id="242" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>建立了整个实验平台.</p>
                </div>
                <div class="p1">
                    <p id="128">表2列出了实验中的主要参数配置.其中存内计算框架中主存储单元均被设置为1 000 MHz, 与计算单元保持同步.对于基于磁畴壁的存内计算框架, 时间和能耗参数可以从扩展的NVSim<citation id="243" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>中获取.由于本文提出的内存框架具有加法器和乘法器组成的计算单元, 因此理论上任何程序中的加法和乘法操作均可以在此内存框架中完成.特别地, 本文选取了主要操作均由加法和乘法组成的图像锐化程序作为实验测试程序, 并在4.2.2节中介绍了图像锐化程序的具体执行过程.</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表2 实验环境中关键参数配置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Configuration Parameters of Experiment</b></p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />Configuration</td><td>Parameters</td></tr><tr><td><br />CPU</td><td>4 single x86 cores, out of order, 3 GHz</td></tr><tr><td><br />L1 Cache</td><td>32 KB I-cache, 32 KB D-cache, 4-way</td></tr><tr><td><br />L2 Cache</td><td>4 MB, 8-way, line size-64 B</td></tr><tr><td><br />Memory</td><td>Domain-wall memory@1 000 MHz, 8 GB<br />Skyrmion memory@1 000 MHz, 8 GB</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="130" name="130">4.2.2 基于存内计算框架的图像锐化程序实例</h4>
                <div class="p1">
                    <p id="131">为了详细说明程序是如何在基于斯格明子的存内计算框架中执行的, 以及存内计算带来的优势, 本节以图像锐化处理为例详细描述程序执行过程.</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 图像锐化程序在存内计算框架中具体执行过程" src="Detail/GetImg?filename=images/JFYZ201904013_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 图像锐化程序在存内计算框架中具体执行过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 The working process of image sharpening in PIM architecture</p>

                </div>
                <div class="p1">
                    <p id="133">图像锐化即加强图像中重要信息, 使得图像更清晰、更易于处理, 在图像处理识别等各个领域都起着非常重要的作用.由于其处理的对象是以矩阵的形式将对应像素点信息存储于内存中的数字化图片, 涉及到大量的矩阵操作, 特别适合于用PIM进行并行处理.其本质是利用微分等运算加强图像中包含边缘信息的高频部分, 代表性算法为拉普拉斯算子.拉普拉斯算子是一种二阶微分算子, 一个连续的二元函数<i>f</i> (<i>x</i>, <i>y</i>) 其拉普拉斯运算定义为</p>
                </div>
                <div class="p1">
                    <p id="134" class="code-formula">
                        <mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mn>2</mn></msup><mi>f</mi><mo>=</mo><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>f</mi></mrow><mrow><mo>∂</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>f</mi></mrow><mrow><mo>∂</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="135">对图像处理来说, 可以将拉普拉斯算子简化为</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mn>4</mn><mi>f</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mi>f</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">在数字图像处理中即表示将某个点对应像素的数值乘以4再减去其上下左右相邻像素对应的数值.在图像锐化处理的过程中, 拉普拉斯算子可以直接通过模板操作来实现, 即用拉普拉斯模板与图像中对应像素数值矩阵进行点乘来得到锐化后的图像数值.如图11所示, 其中常用的模板为</p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">G</mi><msub><mrow></mrow><mi>x</mi></msub><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>4</mn></mtd><mtd><mo>-</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139">图11以使用拉普拉斯算子模板进行图像锐化的程序为例, 说明通用程序在基于斯格明子介质的存内计算框架中执行过程.如图11所示, 基于斯格明子的存内计算框架主要包含存储单元和计算单元2部分.</p>
                </div>
                <div class="p1">
                    <p id="140">其中存储单元部分由斯格明子-赛道型存储器组成, 如图11上半部分所示, 灰色部分表示读写端口所在位置.在未使用AMBS策略之前读取2个矩阵的数据需要进行多次移位操作, 而在使用AMBS策略之后数据均存储在读写端口的位置, 读取这些数据不需要再进行任何移位操作.图11中计算单元部分由基于斯格明子的乘法器 (S-MUL) 和加法器 (S-ADDER) 等逻辑运算单元构成.同时存内计算框架不同于传统的使用外部处理器的计算框架, 在内存中还应设有专门的控制器来控制程序的执行过程.如图11下半部分所示, 图像锐化程序的执行过程可被分解为4个主要步骤:</p>
                </div>
                <div class="p1">
                    <p id="141">步骤1. 指令输入.此时控制指令由外部处理器输入到内部的控制器.包含需要处理的数据地址、需要进行的数据处理操作等.在如图11所示例子中即包含存储图片对应像素信息的3×3矩阵的地址、存储拉普拉斯模板矩阵的地址以及需要进行的对应矩阵元素的加分和乘法操作.</p>
                </div>
                <div class="p1">
                    <p id="142">步骤2. 取数据.内部控制器根据指令从存储单元对应地址处取出数据, 在图11中为一个保存图像像素信息的3×3矩阵以及一个存储拉普拉斯算子模板信息的3×3矩阵.</p>
                </div>
                <div class="p1">
                    <p id="143">步骤3. 数据处理.控制器将相应数据分配至各个逻辑运算单元进行数据处理, 直至得到需要的结果.图11中进行的是像素与模板的乘法, 即2个矩阵的点乘运算.首先将对应矩阵按行、列进行分解, 如图11中分解成 (5, 21, 8) 与 (0, -1, 0) ;再将对应数值输入相应的基于斯格明子的乘法器分别得到 (0, -21, 0) ;最后将结果通过基于斯格明子的加法器多次相加得到最终结果 (2) .</p>
                </div>
                <div class="p1">
                    <p id="144">步骤4. 数据写回.最后将处理的结果 (2) 再写回到存储单元中.</p>
                </div>
                <div class="p1">
                    <p id="145">上述过程不断重复, 直至将整个图像的数据进行类似的卷积操作之后, 就可以得到锐化后的图像.在这个过程中, 图像数据均不需要传输到外部处理器进行处理, 从而节省了大量的时间和能耗.</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146">4.2.3 实验结果</h4>
                <div class="p1">
                    <p id="147">本实验主要分为2部分:第1部分主要分析读写端口数与移位次数之间的关系, 以确定在斯格明子-赛道型存储器中基本存储单元读写端口数;第2部分将本文提出的基于斯格明子的存内计算框架与目前最先进的基于磁畴壁的存内计算框架进行对比.</p>
                </div>
                <div class="p1">
                    <p id="148">如图12所示, 我们首先研究了存储单元读写端口对程序执行过程中赛道型内存总移位数的影响.为了便于比较, 将总移位以Base-16为基准进行规格化.其中Base-<i>X</i>代表不使用AMBS内存映射策略且每个内存单元具有<i>X</i>个读写端口的情况, AMBS-<i>X</i>指的是使用AMBS映射策略且每个内存单元具有<i>X</i>个读写端口的情况.可以看出, 使用AMBS内存映射策略之后移位操作次数极大减少.这主要是由于:1) AMBS映射策略使得同一张图片的数据均被存储在同一组具有相同SN的内存中, 因此图片锐化程序读取1张图片数据时就不再需要进任何移位操作;2) AMBS映射策略使得相邻图片的数据存储在同一组或者相邻组内存中, 在这种情况下读取相邻图片数据的图片也最多需要进行一次移位操作.同时我们还可以从图12中看出, AMBS-16与AMBS-32差距较小, 而与AMBS-8差距较大.这是由于AMBS-16位移操作次数已经较少, 再增加端口数也无法大幅减少位移操作次数, 但是减少端口数会显著增减位移操作的次数.综上所述, 结合占用面积、读写延时等情况考虑, 单个基本存储单元读写端口为16时能取得较好性能.</p>
                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 与Base-16对比读写端口对移位操作数影响" src="Detail/GetImg?filename=images/JFYZ201904013_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 与Base-16对比读写端口对移位操作数影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 The impact of the read/write ports on the  shift operation compared with Base-16</p>

                </div>
                <div class="p1">
                    <p id="150">在实验的第2部分, 我们使用通用的图像锐化程序作为实验程序, 同时为了使得实验结果更具有通用性, 我们使用一系列不同分辨率的图片集作为实验比较对象.</p>
                </div>
                <div class="p1">
                    <p id="151">图13对比了在不使用AMBS策略 (Without AMBS) 与使用AMBS策略 (With AMBS) 的情况下, 基于斯格明子的存内计算框架与基准性能 (基于磁畴壁的存内计算框架) 的比较.可以计算得出, 使用AMBS策略与不使用AMBS策略相比, 存内计算框架平均能节省4.5%的时间和8.7%的能耗.容易观察到, 系统整体性能的差距要比图12中位移次数的差距小得多.这主要是因为在基于斯格明子的存内计算框架中计算单元占据了大部分的时间和能耗.同时我们也注意到当测试图片逐步增大时, 时间和能耗的减少比例也逐步扩大并趋近一个极限值.这是由于随着数据量的不断增加, 斯格明子内存框架内程序运行的并行程度也在不断提高并接近其极限.因此在一定范围内, 斯格明子存内计算框架中程序处理的数据量越大越能获得更多优势.</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201904013_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 基于斯格明子的存内计算框架性能评估" src="Detail/GetImg?filename=images/JFYZ201904013_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 基于斯格明子的存内计算框架性能评估  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201904013_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 13 Performance evaluation of PIM architecture  based on Skyrmion</p>

                </div>
                <div class="p1">
                    <p id="153">从总体上来说, 实验结果表明:在不使用AMBS映射策略下, 本文提出的基于斯格明子的存内计算框架相比目前最先进的基于磁畴壁的存内计算单元在时间上平均节省了43.6%, 在能耗上平均节省了34.2%.在使用了AMBS映射策略之后, 平均节约时间上升至48.1%, 同时平均节约能耗42.9%.</p>
                </div>
                <h3 id="154" name="154" class="anchor-tag"><b>5 总 结</b></h3>
                <div class="p1">
                    <p id="155">本文提出了基于斯格明子逻辑门的加法和乘法计算单元, 探讨了斯格明子基本存储单元的设计方式, 优化了斯格明子存储单元的地址映射方式, 并最终在此基础上建立了基于斯格明子介质的存内计算框架.本文提出的存内计算框架在获得基于斯格明子-赛道型内存的非易失性存储单元优势的同时又获得了基于斯格明子逻辑计算单元的优势.在存储单元方面, 本文首先从硬件层面探讨了斯格明子-赛道型存储单元的读写参数优化等问题, 再从系统层面提出了基于斯格明子-赛道型存储单元专用内存映射策略, 从而在总体上改善了存内计算单元的性能.在计算单元方面, 本文提出的基于斯格明子的全加器和乘法器不仅受益于斯格明子本身优异的物理特性, 同时计算单元的并行优化设计以及电路的复用也极大地提高了系统整体性能, 降低了系统实现的复杂度.实验表明:本文提出的存内计算框架与目前最先进的基于磁畴壁的存内计算框架相比, 在时间上平均节省了48.1%, 在能耗上平均节省了42.9%.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="179">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201608017&amp;v=MDc3MzlLTnlmVGJMRzRIOWZNcDQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDbmhXNzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Luo Le, Liu Yi, Qian Depei.Survey on in-memory computing technology[J].Journal of Software, 2016, 27 (8) :2147-2167 (in Chinese) (罗乐, 刘轶, 钱德沛.存内计算技术研究综述[J].软件学报, 2016, 27 (8) :2147-2167) 
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Processing in memory: the Terasys massively parallel PIM array">

                                <b>[2]</b>Gokhale M, Holmes B, Iobst K.Processing in memory:The Terasys massively parallel PIM array[J].Computer, 1995, 28 (4) :23-31
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=TOP-PIM:Throughput-oriented programmable processing in memory">

                                <b>[3]</b>Zhang Dongping, Jayasena N, Lyashevsky A, et al.TOP-PIM:Throughput-oriented programmable processing in memory[C]//Proc of the 23rd ACM Int Symp on HighPerformance Parallel and Distributed Computing.New York:ACM, 2014:85-98
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM24034E4C6D4CC3D45A348A575C79E3CB&amp;v=MDg1ODB1eElXbXp4NVFBN25xeGRHZnJ2aFJzbnRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGl4Ynkzd3FvPU5pZklZN0c4SHRMSTJvczJZcDhMZnc4Ng==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Akin B, Franchetti F, Hoe J C.Data reorganization in memory using 3D-stacked DRAM[J].ACM SIGARCHComputer Architecture News, 2015, 43 (3) :131-143
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mercury:A Fast and Energy-Efficient Multi-level Cell based Phase Change Memory System">

                                <b>[5]</b>Joshi M, Zhang Wangyuan, Li Tao.Mercury:A fast and energy-efficient multi-level cell based phase change memory system[C]//Proc of the 17th High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2011:345-356
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evaluating STT-RAM as an energy-efficient main memory alternative">

                                <b>[6]</b>Kültürsay E, Kandemir M, Sivasubramaniam A, et al.Evaluating STT-RAM as an energy-efficient main memory alternative[C]//Proc of the Performance Analysis of Systems and Software (ISPASS) .Piscataway, NJ:IEEE, 2013:256-267
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000044894&amp;v=MDU1MThqTnI0OUZaTzhMQkhVOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2TElWb2NhQkE9TmlmSVk3SzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Lee B C, Ipek E, Mutlu O, et al.Architecting phase change memory as a scalable DRAM alternative[J].ACMSIGARCH Computer Architecture News, 2009, 37 (3) :2-13
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Memory on the racetrack">

                                <b>[8]</b>Parkin S, Yang Seehun.Memory on the racetrack[J].Nature Nanotechnology, 2015, 10 (3) :195-198
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploration of GPGPU register file architecture using domain-wall-shift-write based racetrack memory">

                                <b>[9]</b>Mao Mengjie, Wen Wujie, Zhang Yaojun, et al.Exploration of GPGPU register file architecture using domain-wall-shiftwrite based racetrack memory[C]//Proc of the 51st Annual Design Automation Conf.New York:ACM, 2014:1-6
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploring main memory design based on racetrack memory technology">

                                <b>[10]</b>Hu Qingda, Sun Guangyu, Shu Jiwu, et al.Exploring main memory design based on racetrack memory technology[C]//Proc of the 26th Great Lakes Symp on VLSI.Piscataway, NJ:IEEE, 2016:397-402
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Energy efficient in-memory machine learning for data intensive image-processing by non-volatile domain-wall memory">

                                <b>[11]</b>Yu Hao, Wang Yuhao, Chen Shuai, et al.Energy efficient in-memory machine learning for data intensive imageprocessing by non-volatile domain-wall memory[C]//Proc of the 19th Asia and South Pacific Design Automation Conf (ASP-DAC) .Piscataway, NJ:IEEE, 2014:191-196
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Skyrmions on the track">

                                <b>[12]</b>Fert A, Cros V, Sampaio J.Skyrmions on the track[J].Nature Nanotechnology, 2013, 8 (3) :152-156
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A strategy for the design of skyrmion racetrack memories">

                                <b>[13]</b>Tomasello R, Martinez E, Zivieri R, et al.A strategy for the design of Skyrmion racetrack memories[J/OL].Scientific Reports, 2014:Article number 6784.[2018-08-02].https://www.nature.com/articles/srep06784
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Magnetic skyrmion logic gates conversion duplication and merging of skyrmions">

                                <b>[14]</b>Zhang Xichao, Ezawa M, Zhou Yan.Magnetic Skyrmion logic gates:Conversion, duplication and merging of Skyrmions[J/OL].Scientific Reports, 2015:Article number 9400.[2018-08-02].https://www.nature.com/articles/srep09400
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Skyrmion domain wall collision and domain wall-gated skyrmion logic">

                                <b>[15]</b>Xing Xiangjun, Pong Philip, Zhou Yan.Skyrmion domain wall collision and domain wall-gated Skyrmion logic[J].Physical Review B, 2016, 94 (5) :054408
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=From device to system cross-layer design exploration of racetrack memory">

                                <b>[16]</b>Sun Guangyu, Zhang Chao, Li Hehe, et al.From device to system:Cross-layer design exploration of racetrack memory[C]//Proc of the Design, Automation and Test in Europe.San Jose, CA:EDA Consortium, 2015:1018-1023
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Balancing DRAM locality and parallelism in shared memory CMP systems">

                                <b>[17]</b>Jeong M K, Yoon D H, Sunwoo D, et al.Balancing DRAMlocality and parallelism in shared memory CMP systems[C]//Proc of the High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2012:1-12
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Voltage Controlled Magnetic Skyrmion Motion for Racetrack Memory">

                                <b>[18]</b>Kang Wang, Huang Yangqi, Zheng Chentian, et al.Voltage controlled magnetic Skyrmion motion for racetrack memory[J/OL].Scientific Reports, 2016:Article number 23164.[2018-08-02].https://www.nature.com/articles/srep23164
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000147&amp;v=MTEwNTlRVE1ud1plWnVIeWptVUx2TElWb2NhQkE9TmlmSVk3SzdIdGpOcjQ5RlpPc1BEWGcrb0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Binkert N, Beckmann B, Black G, et al.The Gem5simulator[J].ACM SIGARCH Computer Architecture News, 2011, 39 (2) :1-7
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=McPAT:an integrated power, area, and timing modeling framework for multicore and manycore architectures">

                                <b>[20]</b>Li Sheng, Ahn J H, Strong R D, et al.McPAT:An integrated power, area, and timing modeling framework for multicore and manycore architectures[C]//Proc of the Annual IEEE/ACM Int Symp on Microarchitecture.Piscataway, NJ:IEEE, 2009:469-480
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory">

                                <b>[21]</b>Dong Xiangyu, Xu Cong, Jouppi N, et al.NVSim:Acircuit-level performance, energy, and area model for emerging non-volatile memory[J].IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2012, 31 (7) :994-1007
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201904013" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201904013&amp;v=MTM3NTVFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNuaFc3M0tMeXZTZExHNEg5ak1xNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQzZ2tpSTBoVC9vc1JrQ2loSzM0UT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

