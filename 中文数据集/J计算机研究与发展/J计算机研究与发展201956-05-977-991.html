

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128640875743750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201905009%26RESULT%3d1%26SIGN%3dPNugjdHcH2WFSnElgStK3yxXh%252bY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905009&amp;v=MTcxMTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnV3I3T0x5dlNkTEc0SDlqTXFvOUY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#65" data-title="&lt;b&gt;1 定义与性质&lt;/b&gt; "><b>1 定义与性质</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;2 障碍空间中的不确定数据聚类&lt;/b&gt; "><b>2 障碍空间中的不确定数据聚类</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#107" data-title="&lt;b&gt;2.1 静态障碍空间下不确定数据聚类算法&lt;/b&gt;"><b>2.1 静态障碍空间下不确定数据聚类算法</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;2.2 静态障碍空间中不确定数据精炼算法&lt;/b&gt;"><b>2.2 静态障碍空间中不确定数据精炼算法</b></a></li>
                                                <li><a href="#178" data-title="&lt;b&gt;2.3 动态障碍增加情况下不确定数据聚类算法&lt;/b&gt;"><b>2.3 动态障碍增加情况下不确定数据聚类算法</b></a></li>
                                                <li><a href="#206" data-title="&lt;b&gt;2.4 动态障碍减少情况下不确定数据聚类算法&lt;/b&gt;"><b>2.4 动态障碍减少情况下不确定数据聚类算法</b></a></li>
                                                <li><a href="#237" data-title="&lt;b&gt;2.5 障碍物动态移动情况下的不确定数据聚类&lt;/b&gt;"><b>2.5 障碍物动态移动情况下的不确定数据聚类</b></a></li>
                                                <li><a href="#280" data-title="&lt;b&gt;2.6 障碍空间下的不确定数据聚类算法&lt;/b&gt;"><b>2.6 障碍空间下的不确定数据聚类算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#306" data-title="&lt;b&gt;3 实验比较与分析&lt;/b&gt; "><b>3 实验比较与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#342" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="图1 障碍距离的示例">图1 障碍距离的示例</a></li>
                                                <li><a href="#113" data-title="图2 基于定理1的示例">图2 基于定理1的示例</a></li>
                                                <li><a href="#148" data-title="图3 基于规则1的示例">图3 基于规则1的示例</a></li>
                                                <li><a href="#181" data-title="图4 障碍动态增加的示例">图4 障碍动态增加的示例</a></li>
                                                <li><a href="#210" data-title="图5 障碍动态减少的示例">图5 障碍动态减少的示例</a></li>
                                                <li><a href="#245" data-title="图6 障碍物动态移动的示例">图6 障碍物动态移动的示例</a></li>
                                                <li><a href="#315" data-title="&lt;b&gt;表1 UCI实验室数据集&lt;/b&gt;"><b>表1 UCI实验室数据集</b></a></li>
                                                <li><a href="#320" data-title="&lt;b&gt;表2 算法评测有效性对比&lt;/b&gt;"><b>表2 算法评测有效性对比</b></a></li>
                                                <li><a href="#322" data-title="图7 维度&lt;i&gt;d&lt;/i&gt;对CPU执行时间的影响">图7 维度<i>d</i>对CPU执行时间的影响</a></li>
                                                <li><a href="#324" data-title="图8 维度&lt;i&gt;d&lt;/i&gt;对算法有效性的影响">图8 维度<i>d</i>对算法有效性的影响</a></li>
                                                <li><a href="#326" data-title="图9 样本数对CPU执行时间的影响">图9 样本数对CPU执行时间的影响</a></li>
                                                <li><a href="#328" data-title="图10 数据量对CPU执行时间的影响">图10 数据量对CPU执行时间的影响</a></li>
                                                <li><a href="#330" data-title="图11 数据量对算法有效性的影响">图11 数据量对算法有效性的影响</a></li>
                                                <li><a href="#332" data-title="&lt;b&gt;表3 障碍物动态减少对CPU执行时间的影响&lt;/b&gt;"><b>表3 障碍物动态减少对CPU执行时间的影响</b></a></li>
                                                <li><a href="#334" data-title="&lt;b&gt;表4 障碍物动态增加对CPU执行时间的影响&lt;/b&gt;"><b>表4 障碍物动态增加对CPU执行时间的影响</b></a></li>
                                                <li><a href="#336" data-title="&lt;b&gt;表5 障碍物动态移动对CPU执行时间的影响&lt;/b&gt;"><b>表5 障碍物动态移动对CPU执行时间的影响</b></a></li>
                                                <li><a href="#339" data-title="&lt;b&gt;表6 不同数量的障碍物对CPU执行时间的影响&lt;/b&gt;"><b>表6 不同数量的障碍物对CPU执行时间的影响</b></a></li>
                                                <li><a href="#340" data-title="&lt;b&gt;表7 障碍物不同位置分布对CPU执行时间的影响&lt;/b&gt;"><b>表7 障碍物不同位置分布对CPU执行时间的影响</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="447">


                                    <a id="bibliography_1" title="Zhang Xianchao, Liu Han, Zhang Xiaotong.Novel density-based and hierarchical density-based clustering algorithms for uncertain data[J].Neural Networks, 2017, 93 (9) :240- 255" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEB3422818A085084C3312531DF246C58&amp;v=MjA1MTlPZmNiS0hkWE9yWWRFYkpvUEJIazV4eEpnNlR4OFNucmhyV1pEZTdhU05yK1hDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6TDIyd2E0PU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Zhang Xianchao, Liu Han, Zhang Xiaotong.Novel density-based and hierarchical density-based clustering algorithms for uncertain data[J].Neural Networks, 2017, 93 (9) :240- 255
                                    </a>
                                </li>
                                <li id="449">


                                    <a id="bibliography_2" title="Zhou Aoying, Jin Cheqing, Wang Guoren, et al.A survey on the management of uncertain data[J].Chinese Journal of Computers, 2009, 32 (1) :1- 16 (in Chinese) (周傲英, 金澈清, 王国仁, 等.不确定性数据管理技术研究综述[J].计算机学报, 2009, 32 (1) :1- 16) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX200901001&amp;v=MDE0MTJPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTHo3QmRyRzRIdGpNcm85RlpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Zhou Aoying, Jin Cheqing, Wang Guoren, et al.A survey on the management of uncertain data[J].Chinese Journal of Computers, 2009, 32 (1) :1- 16 (in Chinese) (周傲英, 金澈清, 王国仁, 等.不确定性数据管理技术研究综述[J].计算机学报, 2009, 32 (1) :1- 16) 
                                    </a>
                                </li>
                                <li id="451">


                                    <a id="bibliography_3" title="Ngai W K, Kao B, Chui C K, et al.Efficient clustering of uncertain data[C] //Proc of the 6th Int Conf on Data Mining.Piscataway, NJ:IEEE, 2006:436- 445" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient clustering of uncertain data">
                                        <b>[3]</b>
                                        Ngai W K, Kao B, Chui C K, et al.Efficient clustering of uncertain data[C] //Proc of the 6th Int Conf on Data Mining.Piscataway, NJ:IEEE, 2006:436- 445
                                    </a>
                                </li>
                                <li id="453">


                                    <a id="bibliography_4" title="Wang Juntao, Su Xiaolong.An improved k-means clustering algorithm[C] //Proc of the 3rd Int Symp on Intelligent Information Technology and Security Informatics.Piscataway, NJ:IEEE, 2011:63- 67" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An improved k-means clustering algorithm">
                                        <b>[4]</b>
                                        Wang Juntao, Su Xiaolong.An improved k-means clustering algorithm[C] //Proc of the 3rd Int Symp on Intelligent Information Technology and Security Informatics.Piscataway, NJ:IEEE, 2011:63- 67
                                    </a>
                                </li>
                                <li id="455">


                                    <a id="bibliography_5" title="Wang Wei, Yang Jiong, Muntz R.STING:A statistical information grid approach to spatital data mining[C] //Proc of the 23rd Int Conf on Very Large Data Bases.San Francisco:Morgan Kaufmann, 1997:186- 195" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=STING: A statistical information grid approach to spatial data mining">
                                        <b>[5]</b>
                                        Wang Wei, Yang Jiong, Muntz R.STING:A statistical information grid approach to spatital data mining[C] //Proc of the 23rd Int Conf on Very Large Data Bases.San Francisco:Morgan Kaufmann, 1997:186- 195
                                    </a>
                                </li>
                                <li id="457">


                                    <a id="bibliography_6" title="Xu Lei, Hu Qinghua, Zhang Xisheng, et al.AdaUK-Means:An ensemble boosting clustering algorithm on uncertain objects[C] //Proc of the 7th Chinese Conf on Pattern Recognition.Berlin:Springer, 2016:27- 41" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=AdaU K-Means:an ensemble boosting clustering algorithm on uncertain objects">
                                        <b>[6]</b>
                                        Xu Lei, Hu Qinghua, Zhang Xisheng, et al.AdaUK-Means:An ensemble boosting clustering algorithm on uncertain objects[C] //Proc of the 7th Chinese Conf on Pattern Recognition.Berlin:Springer, 2016:27- 41
                                    </a>
                                </li>
                                <li id="459">


                                    <a id="bibliography_7" title="Liao Kuanteng, Liu Chuanming.An effective clustering mechanism for uncertain data mining using centroid boundary in UKmeans[C] //Proc of Int Computer Symp.Piscataway, NJ:IEEE, 2017:300- 305" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An effective clustering mechanism for uncertain data mining using centroid boundary in UKmeans">
                                        <b>[7]</b>
                                        Liao Kuanteng, Liu Chuanming.An effective clustering mechanism for uncertain data mining using centroid boundary in UKmeans[C] //Proc of Int Computer Symp.Piscataway, NJ:IEEE, 2017:300- 305
                                    </a>
                                </li>
                                <li id="461">


                                    <a id="bibliography_8" title="Hao Shengxuan, Zhou Xiaofeng, Hong Song.A new method for noise data detection based on DBSCAN and SVDD[C] //Proc of the 5th IEEE Int Conf on Cyber Technology in Automation, Control, and Intelligent Systems.Piscataway, NJ:IEEE, 2015:784- 789" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new method for noise data detection based on DBSCAN and SVDD">
                                        <b>[8]</b>
                                        Hao Shengxuan, Zhou Xiaofeng, Hong Song.A new method for noise data detection based on DBSCAN and SVDD[C] //Proc of the 5th IEEE Int Conf on Cyber Technology in Automation, Control, and Intelligent Systems.Piscataway, NJ:IEEE, 2015:784- 789
                                    </a>
                                </li>
                                <li id="463">


                                    <a id="bibliography_9" title="Kriegel H P, Pfeifle M.Hierarchical density-based clustering of uncertain data[C] //Proc of the 5th IEEE Int Conf on Data Mining.Piscataway, NJ:IEEE, 2005:689- 692" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical density-based clustering of uncertain data">
                                        <b>[9]</b>
                                        Kriegel H P, Pfeifle M.Hierarchical density-based clustering of uncertain data[C] //Proc of the 5th IEEE Int Conf on Data Mining.Piscataway, NJ:IEEE, 2005:689- 692
                                    </a>
                                </li>
                                <li id="465">


                                    <a id="bibliography_10" title="Han Liu, Zhang Xianchao, Zhang Xiaotong, et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems, 2017, 126 (12) :33- 47" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES24E24497651FD1D31EFFDCEC6D0EECBB&amp;v=MTMxNTZOaWZPZmJHOGE5UElxNFpDWXU0T2VnZzR1eFVTbjBrTFBBeVgzeFJCZWNmaE5zanRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6TDIyd2E0PQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Han Liu, Zhang Xianchao, Zhang Xiaotong, et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems, 2017, 126 (12) :33- 47
                                    </a>
                                </li>
                                <li id="467">


                                    <a id="bibliography_11" title="Erdem A, G&#252;ndem T I.M-FDBSCAN:A multicore density-based uncertain data clustering algorithm[J].Turkish Journal of Electrical Engineering &amp;amp; Computer Sciences, 2014, 22 (1) :143- 154" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=M-FDBSCAN A multi-core density-based uncertain data clustering algorithm">
                                        <b>[11]</b>
                                        Erdem A, G&#252;ndem T I.M-FDBSCAN:A multicore density-based uncertain data clustering algorithm[J].Turkish Journal of Electrical Engineering &amp;amp; Computer Sciences, 2014, 22 (1) :143- 154
                                    </a>
                                </li>
                                <li id="469">


                                    <a id="bibliography_12" title="Lu Yihong, Xia Cong.Optimal k-nearest neighbors and local density-based clustering algorithm for uncertain data[J].Control and Decision, 2016, 31 (3) :541- 546 (in Chinese) (陆亿红, 夏聪.不确定数据的最优k近邻和局部密度聚类算法[J].控制与决策, 2016, 31 (3) :541- 546) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201603023&amp;v=MjAxNzNJOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnV3I3T0xqZlNiYkc0SDlmTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Lu Yihong, Xia Cong.Optimal k-nearest neighbors and local density-based clustering algorithm for uncertain data[J].Control and Decision, 2016, 31 (3) :541- 546 (in Chinese) (陆亿红, 夏聪.不确定数据的最优k近邻和局部密度聚类算法[J].控制与决策, 2016, 31 (3) :541- 546) 
                                    </a>
                                </li>
                                <li id="471">


                                    <a id="bibliography_13" title="Han Lizhao, Qian Xuezhong, Luo Jing, et al.Multi-density clustering algorithm DBSCAN based on region division[J].Application Research of Computers, 2018, 35 (6) :1668- 1671 (in Chinese) (韩利钊, 钱雪忠, 罗靖, 等.基于区域划分的DBSCAN多密度聚类算法[J].计算机应用研究, 2018, 35 (6) :1668- 1671" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201806016&amp;v=MDgzNTQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTHo3U1pMRzRIOW5NcVk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Han Lizhao, Qian Xuezhong, Luo Jing, et al.Multi-density clustering algorithm DBSCAN based on region division[J].Application Research of Computers, 2018, 35 (6) :1668- 1671 (in Chinese) (韩利钊, 钱雪忠, 罗靖, 等.基于区域划分的DBSCAN多密度聚类算法[J].计算机应用研究, 2018, 35 (6) :1668- 1671
                                    </a>
                                </li>
                                <li id="473">


                                    <a id="bibliography_14" title="Ben Kao, Lee S D, Lee F K F.Clustering uncertain data using voronoi diagrams and R-Tree index[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering, 2010, 22 (9) :1219- 1233" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering uncertain data using voronoi diagrams and R-tree index">
                                        <b>[14]</b>
                                        Ben Kao, Lee S D, Lee F K F.Clustering uncertain data using voronoi diagrams and R-Tree index[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering, 2010, 22 (9) :1219- 1233
                                    </a>
                                </li>
                                <li id="475">


                                    <a id="bibliography_15" title="Zhang Jun, Papadias D, Mouratidis K, et al.Spatial queries in the presence of obstacles[C] //Proc of the 9th Int conf on Extending Database Technology.Berlin:Springer, 2004:366- 384" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial queries in the presence of obstacles">
                                        <b>[15]</b>
                                        Zhang Jun, Papadias D, Mouratidis K, et al.Spatial queries in the presence of obstacles[C] //Proc of the 9th Int conf on Extending Database Technology.Berlin:Springer, 2004:366- 384
                                    </a>
                                </li>
                                <li id="477">


                                    <a id="bibliography_16" title="Cao Keyan, Wang Guoren, Han Donghong, et al.Clustering algorithm of uncertain data in obstacle space[J].Journal of Frontiers of Computer Science &amp;amp; Technology, 2012, 6 (12) :1087- 1097 (in Chinese) (曹科研, 王国仁, 韩东红, 等.障碍空间中不确定数据聚类算法[J].计算机科学与探索, 2012, 6 (12) :1087- 1097) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201212005&amp;v=MTc3NjZHNEg5UE5yWTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1dyN09MalhmZmI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Cao Keyan, Wang Guoren, Han Donghong, et al.Clustering algorithm of uncertain data in obstacle space[J].Journal of Frontiers of Computer Science &amp;amp; Technology, 2012, 6 (12) :1087- 1097 (in Chinese) (曹科研, 王国仁, 韩东红, 等.障碍空间中不确定数据聚类算法[J].计算机科学与探索, 2012, 6 (12) :1087- 1097) 
                                    </a>
                                </li>
                                <li id="479">


                                    <a id="bibliography_17" title="Zhang Xueping, Du Haohua, Yang Tengfeng, et al.A novel spatial clustering with obstacles constraints based on PNPSO and K-Medoids[G] //Advances in Swarm Intelligence.Berlin:Springer, 2010:605- 610" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel spatial clustering with obstacles constraints based on PNPSO and K-me doids">
                                        <b>[17]</b>
                                        Zhang Xueping, Du Haohua, Yang Tengfeng, et al.A novel spatial clustering with obstacles constraints based on PNPSO and K-Medoids[G] //Advances in Swarm Intelligence.Berlin:Springer, 2010:605- 610
                                    </a>
                                </li>
                                <li id="481">


                                    <a id="bibliography_18" title="Zhou Jin, Pan Yuqi, Chen C L P, et al.K-medoids method based on divergence for uncertain data clustering[C] //Proc of the 46th IEEE Int Conf on Systems, Man, and Cybernetics.Piscataway, NJ:IEEE, 2017:2671- 2674" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=K-medoids method based on divergence for uncertain data clustering">
                                        <b>[18]</b>
                                        Zhou Jin, Pan Yuqi, Chen C L P, et al.K-medoids method based on divergence for uncertain data clustering[C] //Proc of the 46th IEEE Int Conf on Systems, Man, and Cybernetics.Piscataway, NJ:IEEE, 2017:2671- 2674
                                    </a>
                                </li>
                                <li id="483">


                                    <a id="bibliography_19" title="Pan Donghua, Zhao Lilei.Uncertain data cluster based on DBSCAN[C] //Proc of the 2nd Int Conf on Multimedia Technology.Piscataway, NJ:IEEE, 2011:3781- 3784" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Uncertain data cluster based on DBSCAN">
                                        <b>[19]</b>
                                        Pan Donghua, Zhao Lilei.Uncertain data cluster based on DBSCAN[C] //Proc of the 2nd Int Conf on Multimedia Technology.Piscataway, NJ:IEEE, 2011:3781- 3784
                                    </a>
                                </li>
                                <li id="485">


                                    <a id="bibliography_20" title="Hao Zhongxiao.Spatial Databases Theoretical Basis[M].Beijing:Science Press, 2013 (in Chinese) (郝忠孝.空间数据库理论基础[M].北京:科学出版社, 2013) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030372581000&amp;v=MTM1NjdTWEZxekdiTzdIdExMcllwTlplc1BEQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDdmhVcmZOS1Y4&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Hao Zhongxiao.Spatial Databases Theoretical Basis[M].Beijing:Science Press, 2013 (in Chinese) (郝忠孝.空间数据库理论基础[M].北京:科学出版社, 2013) 
                                    </a>
                                </li>
                                <li id="487">


                                    <a id="bibliography_21" title="Zhang Liping, Liu Lei, Hao Xiaohong, et al.Voronoi-based group reverse k nearest neighbor query in obstructed space[J].Journal of Computer Research and Development, 2017, 54 (4) :861- 871 (in Chinese) (张丽平, 刘蕾, 郝晓红, 等.障碍空间中基于Voronoi图的组反k最近邻查询研究[J].计算机研究与发展, 2017, 54 (4) :861- 871) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201704019&amp;v=MDE2NTJPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTHl2U2RMRzRIOWJNcTQ5RWJZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Zhang Liping, Liu Lei, Hao Xiaohong, et al.Voronoi-based group reverse k nearest neighbor query in obstructed space[J].Journal of Computer Research and Development, 2017, 54 (4) :861- 871 (in Chinese) (张丽平, 刘蕾, 郝晓红, 等.障碍空间中基于Voronoi图的组反k最近邻查询研究[J].计算机研究与发展, 2017, 54 (4) :861- 871) 
                                    </a>
                                </li>
                                <li id="489">


                                    <a id="bibliography_22" title="Wang Jianrong.Research on clustering algorithm for uncertain data based on probability distribution similarity[D].Xi’an:Xidian University, 2014 (in Chinese) (王建荣.基于概率分布相似性的不确定数据聚类算法研究[D].西安:西安电子科技大学, 2014) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014325295.nh&amp;v=MTcyODhHOVBGcXBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPVkYyNkdyQzY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Wang Jianrong.Research on clustering algorithm for uncertain data based on probability distribution similarity[D].Xi’an:Xidian University, 2014 (in Chinese) (王建荣.基于概率分布相似性的不确定数据聚类算法研究[D].西安:西安电子科技大学, 2014) 
                                    </a>
                                </li>
                                <li id="491">


                                    <a id="bibliography_23" title="Xu Lei, Hu Qinghua, Hung E, et al.Large margin clustering on uncertain data by considering probability distribution similarity[J].Neurocomputing, 2015, 158 (12) :81- 89" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEE0560042004793EE5382038E0868EF2&amp;v=MDAzNTNiUTM1TnhnekwyMndhND1OaWZPZmNiTkh0VEtyNDlCWnVzUENIc3d6R05tN3p4MVNuL2hwR2MxY2JTY01NeWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Xu Lei, Hu Qinghua, Hung E, et al.Large margin clustering on uncertain data by considering probability distribution similarity[J].Neurocomputing, 2015, 158 (12) :81- 89
                                    </a>
                                </li>
                                <li id="493">


                                    <a id="bibliography_24" title="Ma Shuai, Wang Tengjiao, Tang Shiwei, et al.A fast clustering algorithm based on reference and density[J].Journal of Software, 2003, 14 (6) :1089- 1095 (in Chinese) (马帅, 王腾蛟, 唐世渭, 等.一种基于参考点和密度的快速聚类算法[J].软件学报, 2003, 14 (6) :1089- 1095) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200306008&amp;v=MDMxNDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTnlmVGJMRzRIdExNcVk5RmJJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Ma Shuai, Wang Tengjiao, Tang Shiwei, et al.A fast clustering algorithm based on reference and density[J].Journal of Software, 2003, 14 (6) :1089- 1095 (in Chinese) (马帅, 王腾蛟, 唐世渭, 等.一种基于参考点和密度的快速聚类算法[J].软件学报, 2003, 14 (6) :1089- 1095) 
                                    </a>
                                </li>
                                <li id="495">


                                    <a id="bibliography_25" title="He Yunbin, Zhang Zhichao, Wang Jing, et al.Research for uncertain data clustering algorithm:U-PAM and UM-PAM algorithm[J].Computer Science, 2016, 43 (6) :263- 269 (in Chinese) (何云斌, 张志超, 万静, 等.不确定数据聚类的U-PAM算法和UM-PAM算法的研究[J].计算机科学, 2016, 43 (6) :263- 269) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201606054&amp;v=Mjk0OTMzenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1dyN09MejdCYjdHNEg5Zk1xWTlBWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                        He Yunbin, Zhang Zhichao, Wang Jing, et al.Research for uncertain data clustering algorithm:U-PAM and UM-PAM algorithm[J].Computer Science, 2016, 43 (6) :263- 269 (in Chinese) (何云斌, 张志超, 万静, 等.不确定数据聚类的U-PAM算法和UM-PAM算法的研究[J].计算机科学, 2016, 43 (6) :263- 269) 
                                    </a>
                                </li>
                                <li id="497">


                                    <a id="bibliography_26" title="Cao Zhenli, Sun Ruizhi, Li Meng.A method for clustering uncertain data streams based on GMM[J].Journal of Computer Research and Development, 2014, 51 (SupplⅡ) :102- 109 (in Chinese) (曹振丽, 孙瑞志, 李勐.一种基于高斯混合模型的不确定数据流聚类方法[J].计算机研究与发展, 2014, 51 (增刊Ⅱ) :102- 109) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ2014S2013&amp;v=MjY4MTREZ1dyN09MeXZTZExHNEg5V3ZyWTlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                        Cao Zhenli, Sun Ruizhi, Li Meng.A method for clustering uncertain data streams based on GMM[J].Journal of Computer Research and Development, 2014, 51 (SupplⅡ) :102- 109 (in Chinese) (曹振丽, 孙瑞志, 李勐.一种基于高斯混合模型的不确定数据流聚类方法[J].计算机研究与发展, 2014, 51 (增刊Ⅱ) :102- 109) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(05),977-991 DOI:10.7544/issn1000-1239.2019.20170979            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>障碍空间中基于Voronoi图的不确定数据聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E9%9D%99&amp;code=07002171&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B4%94%E7%BE%8E%E7%8E%89&amp;code=39589837&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">崔美玉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E4%BA%91%E6%96%8C&amp;code=07001467&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何云斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%9D%BE&amp;code=15107572&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李松</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%93%88%E5%B0%94%E6%BB%A8%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0003194&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">哈尔滨理工大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了有效解决障碍空间中的不确定数据聚类的问题, 引入计算几何中的Voronoi图对数据空间进行划分, 提出障碍空间中基于Voronoi图的不确定数据聚类算法.根据Voronoi图的性质, 提出4项聚类规则.利用KL距离进行相似性度量.根据障碍集合是否发生变化, 提出了静态障碍环境下和动态障碍环境下的不确定数据聚类算法.理论研究和实验表明:静态障碍物环境中的不确定精炼聚类算法 (简称STAO<sub>R</sub>VUBSCAN算法) 、障碍物动态增加情况下的不确定聚类算法 (简称DYNOC<sub>V</sub>UBSCAN算法) 、障碍物动态减少情况下的不确定聚类算法 (简称DYNOR<sub>V</sub>UBSCAN算法) 和障碍物动态移动情况下的不确定数据聚类算法 (简称DYNOM<sub>V</sub>UBSCAN算法) 都具有较高的效率.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%99%E6%80%81%E9%9A%9C%E7%A2%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">静态障碍;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E6%80%81%E9%9A%9C%E7%A2%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动态障碍;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KL%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KL距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不确定数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Voronoi%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Voronoi图;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    万静, wanjha@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-12-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61872105);</span>
                                <span>黑龙江省教育厅科技研究项目 (1253lz004);</span>
                                <span>黑龙江省留学归国人员科学基金 (LC2018030);</span>
                    </p>
            </div>
                    <h1><b>Uncertain Data Clustering Algorithm Based on Voronoi Diagram in Obstacle Space</b></h1>
                    <h2>
                    <span>Wan Jing</span>
                    <span>Cui Meiyu</span>
                    <span>He Yunbin</span>
                    <span>Li Song</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Harbin University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to solve the problem of the uncertain data clustering in obstacle space, the Voronoi diagram in computational geometry is introduced to divide the data space, and an uncertain data clustering algorithm based on Voronoi diagram in obstacle space is proposed. According to the properties of Voronoi diagram, four clustering rules are proposed. In order to consider the probability distribution between data, the KL distance is used as the similarity measure between data objects. Because obstacles can not always remain static in real life, and space obstacles often change dynamically. Then, according to whether the set of obstacles is changed, an uncertain data clustering algorithm in static obstacle environment and dynamic obstacle environment is proposed. Theoretical studies and experiments show that the uncertain refining clustering algorithm in the static obstacles environment (STAO<sub>R</sub>VUBSCAN) , the uncertain clustering algorithm of the dynamic increase of obstacles (DYNOC<sub>V</sub>UBSCAN) , the uncertain clustering algorithm of the dynamic reduction of obstacles (DYNOR<sub>V</sub>UBSCAN) and the uncertain clustering algorithm of the dynamic movement of obstacles (DYNOM<sub>V</sub>UBSCAN) have extremely high efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=static%20obstacles&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">static obstacles;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dynamic%20obstacles&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dynamic obstacles;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kullback-Leibler%20divergence&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kullback-Leibler divergence;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=uncertain%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">uncertain data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Voronoi%20diagram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Voronoi diagram;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Wan Jing, born in 1972.PhD.Professor. Her main research interests include database theory and application, spatial database, embedded system.<image id="381" type="formula" href="images/JFYZ201905009_38100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Cui Meiyu, born in 1994. Master candidate. Her main research interests include data mining and spatial data clustering. (254143488@qq.com) <image id="383" type="formula" href="images/JFYZ201905009_38300.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    He Yunbin, born in 1972.PhD.Professor. His main research interests include database theory and application. (hybha@163.com) <image id="385" type="formula" href="images/JFYZ201905009_38500.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Li Song, born in 1977.PhD.Professor. His main research interests include database theory and application, data mining, data query. (lisongbeifen@163.com) <image id="387" type="formula" href="images/JFYZ201905009_38700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2017-12-29</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61872105);</span>
                                <span>the Science and Technology Research Project of Heilongjiang Provincial Education Department (1253lz004);</span>
                                <span>the Scientific Research Foundation for Returned Scholars Abroad of Heilongjiang Province of China (LC2018030);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="59">近年来, 随着人们对信息技术的不断了解, 数据的聚类<citation id="499" type="reference"><link href="447" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>问题在许多应用中不断出现, 如基于传感器网络、基于位置的服务等领域.由于在数据采集过程中, 受周围环境的影响, 或者是采集仪器精度的限制, 因此数据具有不确定性.不确定数据<citation id="500" type="reference"><link href="449" rel="bibliography" /><link href="451" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>的分析与挖掘技术已成为最近几年的研究热点, 不确定数据的聚类问题, 就是如何将不确定数据集合划分成若干个簇, 使最终的结果簇内元组间相似性较大, 簇与簇之间元组相似性较小.</p>
                </div>
                <div class="p1">
                    <p id="60">现有的聚类算法大多解决的是确定数据的聚类问题, 对于不确定数据的聚类算法研究中, 主要的研究方法是对传统的面向确定数据的聚类方法进行扩展, 即在传统的聚类算法<citation id="501" type="reference"><link href="453" rel="bibliography" /><link href="455" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>如基于划分的聚类、基于密度的聚类、基于网格的聚类以及基于层次和模型的聚类方法等基础上对不确定数据进行建模, 使用合适的相似性度量方法, 进而提出不确定数据聚类算法.</p>
                </div>
                <div class="p1">
                    <p id="61">国内外学者研究了基于划分的不确定聚类算法UK-means<citation id="509" type="reference"><link href="457" rel="bibliography" /><link href="459" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>, 算法是用最小边界矩形 (minimum bounding rectangle, MBR) 来表示数据的不确定性, MBR描述了数据点可能出现的区域位置, 但UK-means算法只能发现球状簇, 并且易受参数<i>k</i>的影响.为了解决大多数聚类划分算法发现簇形状单一的缺陷, Hao等人提出采用基于密度<citation id="502" type="reference"><link href="461" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的聚类算法.Kriegel等人根据经典DBSCAN (density-based spatial clustering of applications with noise) 算法提出了FDBSCAN (a fast DBSCAN algorithm) <citation id="503" type="reference"><link href="463" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法, Han等人根据OPTICS (ordering points to identify the clustering structure) 算法提出了FOPTICS<citation id="504" type="reference"><link href="465" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>算法, FDBSCAN算法采用距离分布函数作为数据间相似性度量的标准, 而FOPTICS算法在处理大型数据集方面更有效.文献<citation id="505" type="reference">[<a class="sup">11</a>]</citation>提出了FDBSCAN算法的改进算法, 多核M-FDBSCAN (multicore-FDBSCAN) 方法是通过半聚类发生分裂和合并来构造最终的簇.基于密度的聚类算法大多需要依赖Eps和Minpts这2个参数, 陆亿红等人<citation id="506" type="reference"><link href="469" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了OLUC (optimal <i>k</i>-nearest neighbors and local density-based clustering algorithm for uncertain data) 算法, 采用动态自适应的最近<i>k</i>近邻结构, 计算局部相对密度, 降低了参数的选择和密度等级的敏感性.由于网格结构能够提高聚类速度, 因此韩利钊等人<citation id="507" type="reference"><link href="471" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出基于区域划分的DBSCAN多密度聚类算法, 利用网格相对密度差把数据空间划分成密度不同的区域, 使用网格与密度相结合的方法, 提高了聚类效率.Kao 等人<citation id="508" type="reference"><link href="473" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用Voronoi图和R树的性质, 提出剪枝策略来减少期望距离的计算.以上算法仅考虑了确定元组间的距离, 没有考虑元组间的不确定因素和数据间的概率分布, 因此采用KL距离作为数据对象间的相似性度量标准.</p>
                </div>
                <div class="p1">
                    <p id="62">选址问题在物流、生产生活方面有着广泛的应用, 如工厂、垃圾处理中心、物流中心的选址等.随着电商的发展, 网上购物的人越来越多, 物流发展迅速, 物流中心选址的好坏直接影响到服务质量、服务的效率和成本, 从而影响到利润和市场竞争力, 合适的选址会给人民生活带来便利.由于现实生活中存在一些地理条件的限制 (如江河、湖泊、建筑、车辆等) , 使得聚类分析不可能都在理想的欧氏空间中进行, 因此在进行相似性度量时, 需要考虑障碍<citation id="510" type="reference"><link href="475" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>的存在.然而现实生活中的障碍物不可能一直静止不变, 空间障碍物往往会发生动态改变, 障碍物的改变可能使得原有聚类结果发生改变, 因此研究静态障碍空间和动态障碍空间中的不确定数据聚类问题有较大的意义.</p>
                </div>
                <div class="p1">
                    <p id="63">近几年来, 带有障碍的空间聚类问题受到越来越多国内外研究者的关注, 曹科研等人<citation id="511" type="reference"><link href="477" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了一种障碍空间中的不确定数据聚类算法, 分别基于R树、最近距离区域和Voronoi图的性质, 设计了高效的剪枝策略, 并较高程度地实现了不确定数据的聚类算法.文献<citation id="512" type="reference">[<a class="sup">17</a>]</citation>提出的带障碍约束空间聚类算法比遗传K-Medoids<citation id="513" type="reference"><link href="481" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>具有较高的收敛速度.在聚类分析时, 考虑障碍的约束, 实用价值更高.</p>
                </div>
                <div class="p1">
                    <p id="64">在障碍空间中, 现有的数据聚类研究成果大多都是针对确定数据的聚类问题.为了解决障碍空间中的不确定数据聚类问题, 利用Voronoi图对数据空间进行划分.根据障碍集合是否发生变化, 提出了静态障碍环境下的不确定数据聚类算法和动态障碍环境下的不确定数据聚类算法, 其中动态障碍物分3种情况处理, 分别是障碍物动态增加时的不确定聚类算法DYNOC_VUBSCAN、障碍物动态减少时的不确定聚类算法DYNOR_VUBSCAN和障碍物动态移动情况下的不确定数据聚类算法DYNOM_VUBSCAN.理论研究和实验表明:所提算法具有较高的准确性.</p>
                </div>
                <h3 id="65" name="65" class="anchor-tag"><b>1 定义与性质</b></h3>
                <div class="p1">
                    <p id="66"><b>定义1</b>. 不确定数据点集<citation id="514" type="reference"><link href="483" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>.不确定数据集为<i>X</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>n</i></sub>}, <i>X</i><sub><i>i</i></sub>表示一个不确定数据点.<i>X</i><sub><i>i</i></sub>={ (<i>x</i><sub>1</sub>, <i>p</i><sub>1</sub>) , (<i>x</i><sub>2</sub>, <i>p</i><sub>2</sub>) , …, (<i>x</i><sub><i>d</i></sub>, <i>p</i><sub><i>d</i></sub>) }, 每个<i>x</i><sub><i>i</i></sub>表示<i>X</i><sub><i>i</i></sub>的属性值, <i>d</i>为维度数.为每一条数据的每一维属性值生成[0, 1]区间内的概率值<i>p</i><sub><i>i</i></sub>, 以元组的形式表示, 元组由数据值和概率组成.</p>
                </div>
                <div class="p1">
                    <p id="67"><b>定义2</b>. 障碍集.一个障碍用一个多边形表示, 记为<i>O</i><sub><i>i</i></sub>, 其中障碍的顶点集用<i>V</i>={<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …, <i>v</i><sub><i>k</i></sub>}表示, 障碍的边集用<i>E</i>={<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>k</i></sub>}表示, 记为<i>O</i><sub><i>i</i></sub> (<i>V</i>, <i>E</i>) .障碍集用<i>O</i>={<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, …, <i>O</i><sub><i>m</i></sub>}表示.</p>
                </div>
                <div class="p1">
                    <p id="68"><b>定义3</b>. Voronoi图<citation id="515" type="reference"><link href="485" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.给定一组生成点<i>X</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>n</i></sub>}⊂R<sup>2</sup>, 其中2&lt;<i>n</i>&lt;∞, 且当<i>i</i>≠<i>j</i>时, <i>X</i><sub><i>i</i></sub>≠<i>X</i><sub><i>j</i></sub>.其中<i>i</i>, <i>j</i>∈{1, 2, …, <i>n</i>}.由<i>X</i><sub><i>i</i></sub>所决定的区域称为Voronoi单元<i>VX</i>, Voronoi图构成为 <i>VD</i> (<i>X</i>) ={<i>VX</i> (<i>X</i><sub>1</sub>) , <i>VX</i> (<i>X</i><sub>2</sub>) , …, <i>VX</i> (<i>X</i><sub><i>n</i></sub>) }, 其中<i>VX</i> (<i>X</i><sub><i>i</i></sub>) 表示的是<i>X</i><sub><i>i</i></sub>所在的Voronoi单元.</p>
                </div>
                <div class="p1">
                    <p id="69"><b>定义4</b>. 邻接多边形<citation id="516" type="reference"><link href="487" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.共享相同边的Voronoi多边形称为邻接多边形, 它们的生成点被称为邻接生成点.Voronoi单元中存在几条边, 则就会有几个邻接多边形.如图1所示, <i>X</i><sub>11</sub>的Voronoi单元中有5条边, 对应的邻接生成点为<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>12</sub>, <i>X</i><sub>13</sub>.<i>X</i><sub>11</sub>的邻接多边形为以上5个邻接生成点所在的Voronoi单元.</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 障碍距离的示例" src="Detail/GetImg?filename=images/JFYZ201905009_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 障碍距离的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>. 1 <i>An example of obstacle distance</i></p>

                </div>
                <div class="p1">
                    <p id="71">根据<i>Voronoi</i>图的结构和定义可以得出2个基本性质.</p>
                </div>
                <div class="p1">
                    <p id="72"><b>性质1</b>. 任意2个多边形不存在公共区域<citation id="517" type="reference"><link href="481" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>.Voronoi图将不确定数据对象集合中的数据按照其最近邻特性将空间进行划分, 生成互不重叠的区域.</p>
                </div>
                <div class="p1">
                    <p id="73"><b>性质2</b>. 临近特性<citation id="518" type="reference"><link href="485" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.生成点<i>X</i><sub><i>i</i></sub>与邻接多边形中的邻接生成点距离最近.</p>
                </div>
                <div class="p1">
                    <p id="74"><b>定义5</b>. Voronoi图的<i>k</i>级邻接生成点<citation id="519" type="reference"><link href="485" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.给定一组生成点<i>X</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>n</i></sub>}⊂R<sup>2</sup>.<i>X</i><sub><i>i</i></sub>的<i>k</i>级邻接生成点定义如下:</p>
                </div>
                <div class="p1">
                    <p id="75">1) 一级邻接生成.<i>AG</i><sub>1</sub> (<i>X</i><sub><i>i</i></sub>) ={<i>X</i><sub><i>j</i></sub>|<i>VX</i> (<i>X</i><sub><i>i</i></sub>) 和<i>VX</i> (<i>X</i><sub><i>j</i></sub>) 有公共边}.</p>
                </div>
                <div class="p1">
                    <p id="76">2) <i>k</i> (<i>k</i>≥2) 级邻接生成点.<i>AG</i><sub><i>k</i></sub> (<i>X</i><sub><i>i</i></sub>) ={<i>X</i><sub><i>j</i></sub>|<i>VX</i> (<i>X</i>) 和<i>VX</i> (<i>X</i><sub><i>j</i></sub>) 有公共边, <i>X</i>∈<i>AG</i><sub><i>k</i>-1</sub> (<i>X</i><sub><i>i</i></sub>) }.</p>
                </div>
                <div class="p1">
                    <p id="77"><b>定义6</b>. 覆盖圆半径<i>R</i><sub>c</sub>.半径<i>R</i><sub>c</sub>的选取, 需要考虑的是整个不确定数据空间, 半径<i>R</i><sub>c</sub>过小, 覆盖圆内包含的不确定数据点的个数就越少, 相应的点的密度就越小, 使聚类迭代次数增加.半径<i>R</i><sub>c</sub>过大, 容易将孤立点包含在覆盖圆中, 因此<i>R</i><sub>c</sub>的确定是重要的.</p>
                </div>
                <div class="p1">
                    <p id="78"><b>定义7</b>. KL距离<citation id="520" type="reference"><link href="489" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.KL距离也叫作相对熵, KL距离衡量的是相同事件空间里的2个概率分布的差异情况, KL距离函数表达式为</p>
                </div>
                <div class="p1">
                    <p id="79"><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">∥</mo><mi>g</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>D</mi></msub><mi>f</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mi>ln</mi></mrow><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext>d</mtext><mi>x</mi></mrow></math></mathml>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="81">在定义域<i>D</i>中, 将不确定对象作为一个服从一定概率分布的随机变量.在连续的定义域中, 不确定数据用概率密度函数 (probability density function, PDF) <citation id="521" type="reference"><link href="491" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>表示, 概率密度函数用高斯核密度估计:</p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">∥</mo><mi>g</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>D</mi></msub><mi>f</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mi>ln</mi></mrow><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext>d</mtext><mi>x</mi></mrow></math></mathml>, 根据大数定律<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">∥</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>lim</mi></mrow></mstyle><mrow><mi>s</mi><mo>→</mo><mi>∞</mi></mrow></munder><mfrac><mn>1</mn><mi>s</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mtext> </mtext></mstyle><mrow><mi>ln</mi></mrow><mfrac><mrow><mi>X</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Y</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, 其中<i>s</i>表示数据样本数量, 根据文献<citation id="522" type="reference">[<a class="sup">22</a>]</citation>, KL距离表达式为</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">∥</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>s</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mtext> </mtext></mstyle><mi>ln</mi><mfrac><mrow><mi>X</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Y</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">在离散的情况下, 不确定数据用概率质量函数 (probability mass function, pmf) 表示.根据文献<citation id="523" type="reference">[<a class="sup">22</a>]</citation>, KL距离表达式为</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">∥</mo><mi>g</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>D</mi></mrow></munder><mi>f</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mi>ln</mi><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">KL距离有2个基本性质:</p>
                </div>
                <div class="p1">
                    <p id="89"><b>性质3</b>. 非对称性<citation id="524" type="reference"><link href="489" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.KL距离从直观上是个度量或距离函数, 但它并不是一个真正的度量或者距离, 因为它不具有对称性, 一般从分布<i>P</i>到分布<i>Q</i>的距离通常不一定等于分布<i>Q</i>到分布<i>P</i>的距离.即<i>D</i> (<i>P</i>‖<i>Q</i>) ≠<i>D</i> (<i>Q</i>‖<i>P</i>) .</p>
                </div>
                <div class="p1">
                    <p id="90"><b>性质4</b>. 非负性<citation id="525" type="reference"><link href="489" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.KL距离值非负, 即<i>D</i> (<i>P</i>‖<i>Q</i>) ≥0.当且仅当2个分布相同时, <i>D</i> (<i>P</i>‖<i>Q</i>) =0.</p>
                </div>
                <div class="p1">
                    <p id="91"><b>定义8</b>. 聚类半径<i>R</i><citation id="526" type="reference"><link href="489" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.聚簇网格内所有不确定数据点与代表点<i>C</i><sub><i>i</i></sub>的KL距离的均值, 即为不确定聚类半径, 其中聚簇网格内所有不确定数据点集合为<i>X</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>r</i></sub>}.聚类半径<i>R</i>表达式为</p>
                </div>
                <div class="p1">
                    <p id="92"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mi>r</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mi>f</mi></mstyle><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mrow><mi>ln</mi></mrow><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>,      (4) </p>
                </div>
                <div class="p1">
                    <p id="94">其中, <i>r</i>表示聚簇内不确定数据点的总个数.</p>
                </div>
                <div class="p1">
                    <p id="95"><b>定义9</b>. 不确定数据点之间的可视性<citation id="527" type="reference"><link href="477" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>.给定障碍集<i>O</i>和数据点<i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>, 不确定数据点<i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>是可视的当且仅当<i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>之间的连线不会穿过障碍集<i>O</i>中任何障碍的内部, 也不会与任何边集相交.数据点<i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>是不可视时, <i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>之间的连线会穿过障碍集<i>O</i>的内部或有边集相交.将存在障碍的Voronoi单元标记为阻塞Voronoi单元<i>VX</i>′.</p>
                </div>
                <div class="p1">
                    <p id="96"><b>定义10</b>. 不确定数据点之间的障碍距离<citation id="528" type="reference"><link href="477" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>.给定障碍集<i>O</i>和数据点<i>X</i><sub><i>i</i></sub>和<i>X</i><sub><i>j</i></sub>, 当<i>X</i><sub><i>i</i></sub>与<i>X</i><sub><i>j</i></sub>之间互为可视时, <i>X</i><sub><i>i</i></sub>与<i>X</i><sub><i>j</i></sub>的障碍距离为KL距离, 表示为<i>D</i> (<i>X</i><sub><i>i</i></sub>‖<i>X</i><sub><i>j</i></sub>) .当<i>X</i><sub><i>i</i></sub>与<i>X</i><sub><i>j</i></sub>之间不可视时, <i>X</i><sub><i>i</i></sub>与<i>X</i><sub><i>j</i></sub>的障碍距离表示为<i>dist</i> (<i>X</i><sub><i>i</i></sub>, <i>X</i><sub><i>j</i></sub>) , 数据点之间的障碍距离是绕过障碍的路径最小距离.<i>X</i><sub><i>i</i></sub>与<i>X</i><sub><i>j</i></sub>之间的障碍距离:</p>
                </div>
                <div class="p1">
                    <p id="97"><i>dist</i> (<i>X</i><sub><i>i</i></sub>, <i>X</i><sub><i>j</i></sub>) =min{<i>D</i> (<i>X</i><sub><i>i</i></sub>‖<i>v</i><sub><i>i</i></sub>) +</p>
                </div>
                <div class="p1">
                    <p id="98"><i>D</i> (<i>v</i><sub><i>i</i></sub>‖<i>X</i><sub><i>j</i></sub>) , <i>D</i> (<i>X</i><sub><i>i</i></sub>‖<i>v</i><sub><i>j</i></sub>) +<i>D</i> (<i>v</i><sub><i>j</i></sub>‖<i>X</i><sub><i>j</i></sub>) }.      (5) </p>
                </div>
                <div class="p1">
                    <p id="99">图1给出了不确定数据点之间的障碍距离, 其中图1中的虚线表示障碍距离, 粗实线表示无障碍时的直接距离.</p>
                </div>
                <div class="p1">
                    <p id="100">如图1所示, 根据式 (5) 障碍距离的计算, 不确定数据点<i>X</i><sub>15</sub>与<i>X</i><sub>16</sub>之间的障碍距离为</p>
                </div>
                <div class="p1">
                    <p id="101"><i>dist</i> (<i>X</i><sub>15</sub>, <i>X</i><sub>16</sub>) =min{<i>D</i> (<i>X</i><sub>15</sub>‖<i>v</i><sub>1</sub>) +<i>D</i> (<i>v</i><sub>1</sub>‖<i>X</i><sub>16</sub>) , </p>
                </div>
                <div class="p1">
                    <p id="102"><i>D</i> (<i>X</i><sub>15</sub>‖<i>v</i><sub>4</sub>) +<i>D</i> (<i>v</i><sub>4</sub>‖<i>X</i><sub>16</sub>) }.</p>
                </div>
                <div class="p1">
                    <p id="103"><b>定义11</b>. 不确定数据点的密度<citation id="529" type="reference"><link href="493" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.空间中的任意一个不确定数据点<i>X</i><sub><i>i</i></sub>, 1≤<i>i</i>≤<i>n</i>.以不确定数据点<i>X</i><sub><i>i</i></sub>为中心, <i>R</i><sub>c</sub>为半径的覆盖圆区域内的不确定数据生成点个数, 称为不确定数据点的密度, 记作<i>ρ</i> (<i>X</i><sub><i>i</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="104"><b>定义12</b>. 核心对象.根据给定阈值<i>ε</i>, 最大覆盖圆半径<i>R</i><sub>c</sub>, 若不确定数据对象<i>X</i><sub><i>i</i></sub>的最大覆盖圆中包含的不确定数据对象个数<i>ρ</i>≥<i>ε</i>时, 则称<i>X</i><sub><i>i</i></sub>为核心对象.</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>2 障碍空间中的不确定数据聚类</b></h3>
                <div class="p1">
                    <p id="106">随着数据规模越来越大, 使用基于密度的聚类算法能发现任意形状的聚簇, 并且对孤立点数据不敏感.使用Voronoi图将数据空间划分成若干个空间单元, 根据Voronoi图的邻接特性和所提出的规则对不确定数据进行聚类, 使最终的聚类结果有较高的执行效率和准确性.</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>2.1 静态障碍空间下不确定数据聚类算法</b></h4>
                <div class="p1">
                    <p id="108">静态障碍环境指的是空间障碍物集合不会发生改变, 包括障碍的位置、障碍的点集和边集都不发生变化.对此时的空间不确定数据实现聚类算法, 并提出了STAO_VUBSCAN算法.</p>
                </div>
                <div class="p1">
                    <p id="109">STAO_VUBSCAN算法的主要思想:在一定距离内, 可根据Voronoi单元与其邻接的Voronoi的级数大小, 判定局部密度大小.找出核心对象, 以不确定数据点<i>X</i><sub><i>i</i></sub>为中心, 以<i>R</i><sub>c</sub>为半径形成一个覆盖圆, 计算覆盖圆内所含的不确定数据点的个数<i>ρ</i>.若<i>ρ</i>&gt;<i>ε</i>, 则说明不确定数据点的数量较多, 表示<i>X</i><sub><i>i</i></sub>所在覆盖圆内的局部密度越大.根据局部密度的中心进而判断邻接Voronoi单元的聚类情况, 最终实现静态障碍环境下的不确定数据聚类.</p>
                </div>
                <div class="p1">
                    <p id="110"><b>定理1</b>. 若不确定数据点<i>X</i><sub><i>i</i></sub>在Voronoi图中的所有一级邻接生成点都被当作孤立点, 则此时的不确定数据点<i>X</i><sub><i>i</i></sub>也同样的视为孤立点.</p>
                </div>
                <div class="p1">
                    <p id="111">证明. 设<i>X</i><sub><i>j</i></sub>为<i>X</i><sub><i>i</i></sub>的所有一级邻接生成点, 1≤<i>j</i>≤6<citation id="530" type="reference"><link href="485" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.若 <i>X</i><sub><i>j</i></sub>为孤立点, 说明所有<i>X</i><sub><i>j</i></sub>所在覆盖圆的数据密度都较小, 不能视为核心对象.则以<i>X</i><sub><i>i</i></sub>为中心, <i>R</i><sub>c</sub>为半径的覆盖圆内的数据密度也较小.由于<i>X</i><sub><i>j</i></sub>为孤立点被剪枝, 此时所有<i>X</i><sub><i>j</i></sub>的中心<i>X</i><sub><i>i</i></sub>也必定被视为孤立点处理.</p>
                </div>
                <div class="p1">
                    <p id="112">图2中, 不确定数据点<i>X</i><sub>1</sub>为圆心的覆盖圆中, 覆盖圆内的<i>X</i><sub>1</sub>最大有2级生成点, 所以在进行相似性度量时, 只考虑2级生成点以内的不确定数据和障碍情况, 2级以外的邻接生成点和障碍物可先不作考虑, 这会简化KL距离的计算以及障碍的判断.判断每个核心对象所在的覆盖圆内数据点聚类情况, 使得聚类过程更加简便有效.</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于定理1的示例" src="Detail/GetImg?filename=images/JFYZ201905009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于定理1的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 An example based on Theorem 1</p>

                </div>
                <div class="p1">
                    <p id="114">算法STAO_VUBSCAN的主要步骤:首先选择任一未划分的不确定数据对象, 根据不确定数据点密度大小, 先对密度大的生成点设置为核心对象.将核心对象根据密度从大到小降序排序, 存放在Hash表<i>L</i>中, <i>L</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>t</i></sub>}, 1≤<i>i</i>≤<i>t</i>.根据核心对象在Hash表中的顺序来依次聚类, 将判断过的不确定数据从Hash表中删除, 直到Hash表为空为止.使用KL距离作为相似性度量标准, 寻找所有可能被聚到此类的不确定数据点, 并将这些数据点标记为一类, 并根据定理1进行部分孤立点的处理.重复以上步骤, 直到所有不确定数据对象划分完毕.</p>
                </div>
                <div class="p1">
                    <p id="115">基于以上讨论, 进一步提出静态障碍环境下的不确定数据聚类算法STAO_VUBSCAN, 如算法1所示.</p>
                </div>
                <div class="p1">
                    <p id="116"><b>算法1</b>. <i>STAO</i>_<i>VUBSCAN</i> (<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>) .</p>
                </div>
                <div class="p1">
                    <p id="117">输入:不确定数据点集<i>X</i>、障碍集合<i>O</i>、覆盖圆半径<i>R</i><sub>c</sub>, <i>ε</i>, <i>R</i>;</p>
                </div>
                <div class="p1">
                    <p id="118">输出:障碍空间下的不确定数据聚类结果<i>W</i>.</p>
                </div>
                <div class="area_img" id="388">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_38800.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="388">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_38801.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="142">首先算法1在创建Voronoi时, 构建所需的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法执行第1个for循环, 遍历不确定数据点所需的时间复杂度是<i>O</i> (<i>n</i>) .由于<i>n</i>的个数是有限的, 所以此步骤是可终止的.在对核心对象进行快速排序时所需的时间复杂度为 (<i>m</i> lg <i>m</i>) , 其中<i>m</i>表示的是核心对象的个数, <i>m</i>≪<i>n</i>.算法执行第2个for循环所需的时间复杂度为<i>O</i> (<i>t</i>) , 因为覆盖圆内核心对象<i>t</i>的数量有限, 所以此步骤也是可终止的.由以上算法的核心步骤的时间复杂度分析可知, 算法总的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法1的计算代价主要受空间数据集的规模、计算无障碍情况下距离度量的计算量和存在障碍时的障碍距离计算量的影响.</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>2.2 静态障碍空间中不确定数据精炼算法</b></h4>
                <div class="p1">
                    <p id="144">算法1已经解决了静态障碍空间中的不确定数据聚类问题.但是算法1只考虑覆盖圆内不确定数据点密度, 根据覆盖圆内不确定数据点密度大小, 定义核心对象, 而没有考虑到核心对象所在覆盖圆内的障碍的多少.针对覆盖圆内静态障碍物的分布情况, 进一步提出STAO_RVUBSCAN算法, 算法利用Voronoi图的邻接特性和提出的规则, 设计了高效的聚类方法.</p>
                </div>
                <div class="p1">
                    <p id="145"><b>规则1</b>. 如果最大覆盖圆内不确定数据点密度较大, 并且满足<i>ρ</i>≥<i>ε</i>, 但存在的障碍较多时, 则对应的不可视集合<i>S</i><sub>2</sub>中的不确定数据点就会较多, 在进行相似性度量时, 计算的是障碍距离.若<i>dist</i> (<i>X</i><sub><i>i</i></sub>, <i>X</i><sub><i>j</i></sub>) &gt;<i>R</i>, 则<i>X</i><sub><i>i</i></sub>所在覆盖圆内的不确定数据点<i>X</i><sub><i>j</i></sub>不能加入到<i>X</i><sub><i>i</i></sub>所在的簇中.</p>
                </div>
                <div class="p1">
                    <p id="146">只考虑核心对象的密度是不够的, 还需要考虑核心对象最大覆盖圆内静态障碍的密度, 障碍密度越大, 说明不可视集合<i>S</i><sub>2</sub>内的不确定数据个数就越多, 判断集合<i>S</i><sub>1</sub>中可视数据密度是否满足<i>ρ</i>≥<i>ε</i> .如果满足, 执行过程跟算法1一致.否则, 说明了核心对象周围的障碍较多, 不可视集合<i>S</i><sub>2</sub>内的不确定个数较多.在进行相似性度量时计算的是障碍距离, 因为每个障碍距离都大于没有障碍时的可视距离, 因此需要考虑核心对象是否被当作孤立点处理.</p>
                </div>
                <div class="p1">
                    <p id="147">如图3所示, 以不确定数据点<i>X</i><sub>1</sub>为圆心, <i>R</i><sub>c</sub>为半径的最大覆盖圆内不确定数据集合<i>S</i>为{<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, <i>X</i><sub>4</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>, <i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>, <i>X</i><sub>13</sub>}, 此时不确定数据点密度较大.覆盖圆内存在<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, <i>O</i><sub>3</sub> , <i>O</i><sub>4</sub> , <i>O</i><sub>5</sub>共5个障碍, 障碍将不确定数据分为2个集合, 分别为可视集合<i>S</i><sub>1</sub>和不可视集合<i>S</i><sub>2</sub>.根据分析得出, 可视集合<i>S</i><sub>1</sub>={<i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>13</sub>}, 不可视集合<i>S</i><sub>2</sub>={<i>X</i><sub>2</sub>, <i>X</i><sub>4</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>}.</p>
                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于规则1的示例" src="Detail/GetImg?filename=images/JFYZ201905009_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于规则1的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 An example based on regulation 1</p>

                </div>
                <div class="p1">
                    <p id="149">若<i>S</i><sub>1</sub>中不确定数据密度远小于<i>ε</i>, 或者<i>S</i><sub>2</sub>中不确定数据密度≥<i>ε</i>, 说明覆盖圆内不确定数据点<i>X</i><sub><i>i</i></sub>的周围存在较多的障碍, 此时<i>X</i><sub><i>i</i></sub>不能作为核心对象处理.连续域环境下, 可视集合内的距离使用式 (2) .离散域环境下, 可视集合内的距离公式使用式 (3) , 不可视集合内的障碍距离用式 (5) 度量.规则1的提出, 减少了障碍距离的判断, 使得算法的效率较大程度地提高.</p>
                </div>
                <div class="p1">
                    <p id="150">首先判断核心对象所在覆盖圆内障碍的情况, 如果核心对象内的静态障碍不影响聚类结果, 则聚类结果跟算法1相同.如果核心对象所在覆盖圆内障碍的密度较大, 只需判断不可视集合<i>S</i><sub>2</sub>中数据的聚类情况.最后根据相似性度量标准, 将覆盖圆内的不确定数据划分到合适的聚簇中.基于以上分析, 进一步提出了静态障碍环境下的不确定数据聚类精炼算法STAO_RVUBSCAN, 如算法2所示.</p>
                </div>
                <div class="p1">
                    <p id="151"><b>算法2</b>. <i>STAO</i>_<i>RVUBSCAN</i> (<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>, <i>L</i>) .</p>
                </div>
                <div class="p1">
                    <p id="152">输入:<i>X</i>, <i>O</i>, <i>R</i><sub>c</sub>, <i>ε</i>, <i>R</i>, <i>L</i>;</p>
                </div>
                <div class="p1">
                    <p id="153">输出:聚类结果<i>W</i>.</p>
                </div>
                <div class="area_img" id="390">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39000.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="176">算法2在创建Voronoi时, 构建所需的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法执行只有一个for循环, 所需的时间复杂度为<i>O</i> (<i>t</i>) , 因为覆盖圆内核心对象<i>t</i>的数量有限, 所以此步骤也是可终止的.由以上时间复杂度分析可知, 算法2总的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .</p>
                </div>
                <div class="p1">
                    <p id="177">算法2的聚类效率优于算法1, 由于规则1的提出, 过滤了大量的不确定数据点的判断, 减少了大量的计算, 也使得最终的聚类结果更准确.</p>
                </div>
                <h4 class="anchor-tag" id="178" name="178"><b>2.3 动态障碍增加情况下不确定数据聚类算法</b></h4>
                <div class="p1">
                    <p id="179">算法1和算法2研究的是静态障碍物环境下的不确定数据聚类算法, 但是现实生活中的空间障碍物往往会发生动态改变, 如空间障碍物的位置发生改变, 障碍物的点集和边集发生改变, 因此提出动态障碍情况下的不确定数据聚类算法.根据障碍物动态变化的不同情况, 分别提出障碍物动态增加、障碍物动态减少和障碍物动态移动3种情况的不确定数据的聚类算法.</p>
                </div>
                <div class="p1">
                    <p id="180">算法3研究的是障碍物动态增加时的聚类方法, 由于空间障碍物的数量可能发生变化, 空间障碍物的增加会对原始的聚类结果产生影响.如图4所示, 当障碍物增加时, 障碍集则为<i>O</i><sub>new</sub>, 其中<i>O</i>′<sub><i>i</i></sub>为新增加的障碍物.在障碍物增加之前, 可视点集合为<i>S</i><sub>1</sub>, 不可视集合为<i>S</i><sub>2</sub>.在障碍物增加之后, 设定可视点集合为<i>S</i>′<sub>1</sub>, 不可视点集合为<i>S</i>′<sub>2</sub>.</p>
                </div>
                <div class="area_img" id="181">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_181.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 障碍动态增加的示例" src="Detail/GetImg?filename=images/JFYZ201905009_181.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 障碍动态增加的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_181.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 An example of dynamic increase in obstacles</p>

                </div>
                <div class="p1">
                    <p id="182">根据新增加的障碍物的位置分析, 障碍物增加对聚类可能没有影响, 也可能有影响.</p>
                </div>
                <div class="p1">
                    <p id="183"><b>规则2</b>. 首先判断新增加障碍的位置, 然后计算障碍所在Voronoi图中不确定数据点的最大覆盖圆范围.如果新增加的障碍对聚类结果无影响, 覆盖圆范围内不影响聚类的结果, 则聚类结果与算法2 的结果相同.若新增障碍对不确定结果有影响, 覆盖圆范围内的新增障碍影响了Voronoi图中不确定数据点的聚类, 则对此覆盖圆内的不确定数据点重新聚类.重新聚类可能引起其他类的聚类, 因此根据Voronoi图的邻接特性, 需将可视性改变的不确定数据点加入到离其最近的邻接核心对象所在的聚簇中.</p>
                </div>
                <div class="p1">
                    <p id="184">如图4所示, 覆盖圆内原始障碍集合为{<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, <i>O</i><sub>3</sub>}.不可视集合<i>S</i><sub>2</sub>={<i>X</i><sub>4</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>}, 可视集合<i>S</i><sub>1</sub>={<i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>13</sub>, <i>X</i><sub>2</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>}.增加障碍<i>O</i>′<sub>4</sub>和<i>O</i>′<sub>5</sub>之后, 覆盖圆内障碍集为{<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, <i>O</i><sub>3</sub>, <i>O</i>′<sub>4</sub>, <i>O</i>′<sub>5</sub>}, 此时的可视集合<i>S</i>′<sub>1</sub>={<i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>13</sub>, <i>X</i><sub>2</sub>}, 不可视点集合<i>S</i>′<sub>2</sub>={<i>X</i><sub>4</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>}.障碍<i>O</i>′<sub>4</sub>的加入, 并没有使得不确定数据点<i>X</i><sub>1</sub>和<i>X</i><sub>8</sub>之间不可视, <i>O</i>′<sub>4</sub>的加入对覆盖圆内的不确定数据并没有影响, <i>X</i><sub>8</sub>依然存在于可视集合中.因此对新增加的障碍进行判断是有必要的.</p>
                </div>
                <div class="p1">
                    <p id="185">由以上分析可知, 障碍物的增加对不确定数据聚类的影响是局部的, 分情况判定处理会避免较多不必要的距离计算, 因此提出规则2对动态增加的障碍进行具体分析, 进一步提出了障碍物动态增加时的不确定数据聚类算法DYNOC_VUBSCAN, 如算法3所示.</p>
                </div>
                <div class="p1">
                    <p id="186"><b>算法3</b>. <i>DYNOC</i>_<i>VUBSCAN</i> (<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>) .</p>
                </div>
                <div class="p1">
                    <p id="187">输入:<i>X</i>, <i>ε</i>, <i>R</i>, <i>R</i><sub>c</sub>, <i>O</i>, 新增障碍<i>O</i>′<sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="188">输出:聚类结果<i>W</i>.</p>
                </div>
                <div class="area_img" id="391">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="205">首先算法3在创建Voronoi时, 构建所需的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法3只有一个for循环, 遍历不确定数据点所需的时间复杂度是<i>O</i> (<i>n</i>) .<i>n</i>代表的是不确定数据的总数量, 并且数量是有限的, 所以算法是可终止的.当算法3满足步骤⑥所需的条件时, 调用算法2.算法2的时间复杂度已经分析得出是<i>O</i> (<i>n</i> lg <i>n</i>) .由以上分析可知, 算法3总的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .</p>
                </div>
                <h4 class="anchor-tag" id="206" name="206"><b>2.4 动态障碍减少情况下不确定数据聚类算法</b></h4>
                <div class="p1">
                    <p id="207">数据空间的障碍物可根据实际情况动态变化, 当障碍物减少时也很有可能对原来的聚类结果产生影响.</p>
                </div>
                <div class="p1">
                    <p id="208"><b>规则3</b>. 当减少障碍物时, 没有改变最后的聚类结果, 此情况的聚类结果跟静态障碍环境下的不确定聚类算法结果相同, 使用算法2完成聚类即可.当减少的障碍物能够引发最终的聚类结果改变, 则对减少的障碍所在的Voronoi单元的最大覆盖圆内的不确定数据重新进行相似性度量计算.重新聚类可能引起其他类的聚类, 因此根据Voronoi图的邻接特性, 需将不可视变成可视时集合中的不确定数据点加入到离其最近的邻接核心对象所在的聚簇中.</p>
                </div>
                <div class="p1">
                    <p id="209">如图5所示, 图5中用虚线表示的障碍为动态减少的障碍.原始障碍集合为{<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, <i>O</i><sub>3</sub>}, 此时覆盖圆内的可视点集合为<i>S</i><sub>1</sub>={<i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>13</sub>, <i>X</i><sub>2</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>}, 不可视集合<i>S</i><sub>2</sub>={<i>X</i><sub>4</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>}.<i>O</i><sub>2</sub>和<i>O</i><sub>3</sub>为减少的障碍物.此时的障碍集合中只有<i>O</i><sub>1</sub>, 减少障碍会引发不确定数据点之间数据变为可视状态, 可视点集合的不确定数据会增多, 不可视集合中的不确定数据会减少.覆盖圆内的可视点集合为<i>S</i>′<sub>1</sub>={<i>X</i><sub>7</sub>, <i>X</i><sub>8</sub>, <i>X</i><sub>10</sub>, <i>X</i><sub>13</sub>, <i>X</i><sub>2</sub>, <i>X</i><sub>5</sub>, <i>X</i><sub>6</sub>, <i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>}, 不可视点集合为<i>S</i>′<sub>2</sub>={<i>X</i><sub>4</sub>}.障碍的减少, 使得<i>X</i><sub>9</sub>, <i>X</i><sub>11</sub>, <i>X</i><sub>12</sub>可能原本是其他簇中的不确定数据划分到<i>X</i><sub>1</sub>所在的簇中.因此, 空间障碍物的减少也会影响聚类结果的准确性.</p>
                </div>
                <div class="area_img" id="210">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_210.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 障碍动态减少的示例" src="Detail/GetImg?filename=images/JFYZ201905009_210.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 障碍动态减少的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_210.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 An example of dynamic reduction in obstacles</p>

                </div>
                <div class="p1">
                    <p id="211">根据减少的障碍物的具体位置, 减少的障碍可能对聚类影响, 也可能对聚类结果没有影响, 因此需要分析讨论.算法的主要思想:首先得到新的障碍集合<i>O</i><sub>new</sub>, 判断减少的障碍物的位置.然后根据规则3分析减少的障碍对聚类是否有影响, 最后得到障碍动态减少情况下的不确定数据聚类结果.</p>
                </div>
                <div class="p1">
                    <p id="212">基于以上讨论, 具体地给出动态障碍减少情况下的不确定数据聚类算法DYNOR_VUBSCAN, 如算法4所示.</p>
                </div>
                <div class="p1">
                    <p id="213"><b>算法4</b>. <i>DYNOR</i>_<i>VUBSCAN</i> (<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>) .</p>
                </div>
                <div class="p1">
                    <p id="214">输入:<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>, 减少的障碍<i>O</i>′<sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="215">输出:聚类结果<i>W</i>.</p>
                </div>
                <div class="area_img" id="392">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="235">首先算法4在创建Voronoi时, 构建所需的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法执行最外层的for循环, 遍历不确定数据点所需的时间复杂度是<i>O</i> (<i>qn</i>) .<i>n</i>代表的是不确定数据的总数量, 并且数量是有限的, <i>q</i>是障碍减少时, 由不可视变成可视的数据点个数, 数量也是有限的, 所以算法是可终止的.当算法4满足步骤⑧所需的条件时, 调用算法2.算法2的时间复杂度已经分析得出是<i>O</i> (<i>n</i> lg <i>n</i>) .由以上分析可知, 算法4总的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .</p>
                </div>
                <div class="p1">
                    <p id="236">由于算法根据障碍将数据划分成可视集合与不可视集合, 只需重新判断障碍减少时, 由不可视变成可视的不确定数据点聚类情况.此方法大大减少了计算量, 使得局部的进行相似性度量比重新划分聚类更有效.</p>
                </div>
                <h4 class="anchor-tag" id="237" name="237"><b>2.5 障碍物动态移动情况下的不确定数据聚类</b></h4>
                <div class="p1">
                    <p id="238">本节研究的是障碍物动态移动情况下的不确定数据聚类, 其中障碍物的动态移动指的是障碍物的点集和边集不发生改变, 只是障碍物的位置发生改变.</p>
                </div>
                <div class="p1">
                    <p id="239"><b>规则4</b>. 障碍物的动态移动可以分解成障碍物动态减少和障碍物动态增加2部分, 障碍物动态移动之前标记为<i>O</i><sub><i>i</i> beg</sub>, 障碍物移动之后标记为<i>O</i><sub><i>i</i> end</sub>.假设障碍物由位置<i>P</i>动态移动到位置<i>Q</i>, 在位置<i>P</i>时, 相当于障碍物<i>O</i><sub><i>i</i> beg</sub>动态减少, 因此需要分析障碍物动态减少时, 由不可视集合移动到可视集合中的不确定数据点的聚类情况.在位置<i>Q</i>时, 相当于障碍物<i>O</i><sub><i>i</i> end</sub>的动态增加, 因此需要分析障碍物动态增加时, 由可视集合移动到不可视集合的不确定数据点的聚类情况.</p>
                </div>
                <div class="p1">
                    <p id="240">如图6所示, 虚线箭头表示的是障碍物动态移动前后位置的变化情况, 根据障碍物动态移动的前后位置, 移动后的障碍可能对聚类结果有影响, 也可能对聚类结果没有影响, 因此可以分为4种情况分析讨论:</p>
                </div>
                <div class="p1">
                    <p id="241">1) 障碍物<i>O</i><sub><i>i</i></sub>由覆盖圆内部移动到覆盖圆内部, 如图6障碍物<i>O</i><sub>3</sub>移动到<i>O</i><sub>2</sub>的情况.</p>
                </div>
                <div class="p1">
                    <p id="242">2) 障碍物<i>O</i><sub><i>i</i></sub>在核心对象<i>X</i><sub><i>i</i></sub>所在的覆盖圆内部移动到覆盖圆外部, 如图6障碍物<i>O</i><sub>3</sub>移动到<i>O</i><sub>4</sub>的情况.</p>
                </div>
                <div class="p1">
                    <p id="243">3) 障碍物<i>O</i><sub><i>i</i></sub>在核心对象<i>X</i><sub><i>i</i></sub>所在的覆盖圆外部移动到覆盖圆内部, 如图6障碍物<i>O</i><sub>1</sub>移动到<i>O</i><sub>3</sub>的情况.</p>
                </div>
                <div class="p1">
                    <p id="244">4) 障碍物<i>O</i><sub><i>i</i></sub>在覆盖圆外移动, 如图6障碍<i>O</i><sub>1</sub>移动到<i>O</i><sub>4</sub>的情况.</p>
                </div>
                <div class="area_img" id="245">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 障碍物动态移动的示例" src="Detail/GetImg?filename=images/JFYZ201905009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 障碍物动态移动的示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 An example of dynamic movement of obstacles</p>

                </div>
                <div class="p1">
                    <p id="246">由于覆盖圆的圆心都为核心对象, 因此不确定数据的分布是密集的.情况1中的障碍<i>O</i><sub><i>i</i></sub>在覆盖圆内移动, 动态移动后的障碍集为<i>O</i><sub>new</sub>=<i>O</i>-<i>O</i><sub><i>i</i> beg</sub>+<i>O</i><sub><i>i</i> end</sub>;情况2中的障碍<i>O</i><sub><i>i</i></sub>由覆盖圆内移动到覆盖圆外, 表明障碍<i>O</i><sub><i>i</i> end</sub>所在区域的不确定数据较稀疏, 障碍移动后的位置不影响核心对象的聚类结果, 因此<i>O</i><sub>new</sub>=<i>O</i>-<i>O</i><sub><i>i</i> beg</sub>;情况3中的障碍<i>O</i><sub><i>i</i></sub>由覆盖圆外移动到覆盖圆内, 表明障碍<i>O</i><sub><i>i</i> end</sub>所在区域的不确定数据分布是密集的, 障碍<i>O</i><sub><i>i</i> end</sub>移动后的位置会影响核心对象的聚类结果, 所以<i>O</i><sub>new</sub>=<i>O</i>-<i>O</i><sub><i>i</i> beg</sub>+<i>O</i><sub><i>i</i> end</sub>;情况4中的障碍<i>O</i><sub><i>i</i></sub>在覆盖圆外移动, 表明障碍<i>O</i><sub><i>i</i> beg</sub>和障碍<i>O</i><sub><i>i</i> end</sub>所在区域的不确定数据分布是稀疏的, 障碍动态移动之后的位置不影响核心对象的聚类结果, 因此<i>O</i><sub>new</sub>=<i>O</i>-<i>O</i><sub><i>i</i> beg</sub>.</p>
                </div>
                <div class="p1">
                    <p id="247">首先标记动态移动的障碍物在移动之前的位置和移动之后的位置, 并判断符合以上哪种情况, 进而得到<i>O</i><sub>new</sub>.根据规则4, 通过调用DYNOR_VUBSCAN算法和DYNOC_VUBSCAN算法, 最终实现对动态障碍物移动时的不确定数据进行聚类.</p>
                </div>
                <div class="p1">
                    <p id="248">基于以上的分析, 给出障碍物动态移动情况下的不确定数据聚类DYNOM_VUBSCAN算法, 如算法5所示.</p>
                </div>
                <div class="p1">
                    <p id="249"><b>算法5</b>. <i>DYNOM</i>_<i>VUBSCAN</i> (<i>X</i>, <i>O</i>, <i>O</i><sub><i>i</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="250">输入:不确定数据集<i>X</i>、障碍集<i>O</i>、移动障碍<i>O</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="251">输出:聚类结果<i>W</i>.</p>
                </div>
                <div class="area_img" id="393">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="279">算法5主要通过调用算法2、算法3和算法4来实现, 由于以上算法是可终止的, 并且时间复杂度已经分析得出为<i>O</i> (<i>n</i> lg <i>n</i>) , 进而得出算法5的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .</p>
                </div>
                <h4 class="anchor-tag" id="280" name="280"><b>2.6 障碍空间下的不确定数据聚类算法</b></h4>
                <div class="p1">
                    <p id="281">通过分析定义域的情况, 分别根据离散区域或者连续域对不确定数据进行聚类, 离散域下的不确定数据用概率质量函数表示, 连续域下的不确定数据用概率密度函数表示.采用核密度估计<citation id="531" type="reference"><link href="485" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>方法得出概率密度函数, 该方法不需要输入参数, 它仅从数据本身对概率密度函数作出估计, 并且可以估计任意形状的密度函数.由于概率质量函数在进行相似性度量计算时, 比使用概率密度函数更简单, 所以对数据域的情况分开处理是有意义的.对于障碍情况的判断, 可以根据障碍集合是否变化, 判断障碍物是静态的还是动态变化的, 最终提出总算法.</p>
                </div>
                <div class="p1">
                    <p id="282">根据前面提出的静态障碍物环境下和动态障碍物环境下的不确定数据聚类算法, 本节提出RO_VUBSCAN算法, 使得最终的算法可以高效地解决静态障碍空间环境下的不确定聚类、动态障碍物增加、减少和移动情况下的不确定聚类问题.</p>
                </div>
                <div class="p1">
                    <p id="283">首先判断障碍集合是否变化, 如果障碍集合不发生改变, 说明解决的是静态障碍环境下的不确定数据聚类问题, 可调用算法2完成聚类.若障碍集合发生变化, 可根据障碍数量变化判断是障碍物动态增加、障碍物动态减少还是障碍物动态移动的, 如果是障碍动态增加时, 则调用算法3完成聚类.如果是障碍动态减少时, 则调用算法4完成聚类.如果是障碍动态移动时, 则调用算法5完成聚类.基于以上分析, 进一步提出障碍空间下的不确定聚类算法RO_VUBSCAN, 如算法6所示.</p>
                </div>
                <div class="p1">
                    <p id="284"><b>算法6</b>. RO_VUBSCAN (<i>X</i>, <i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>) .</p>
                </div>
                <div class="p1">
                    <p id="285">输入:不确定数据集<i>X</i>、障碍集<i>O</i>, <i>ε</i>, <i>R</i><sub>c</sub>;</p>
                </div>
                <div class="p1">
                    <p id="286">输出:障碍空间下的不确定数据聚类结果集<i>W</i>.</p>
                </div>
                <div class="area_img" id="394">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="394">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201905009_39401.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="304">如果定义域是连续的, 则不确定数据用概率密度函数表示, KL距离的计算使用式 (2) , 如果定义域是离散的, 则不确定数据用概率质量函数表示, 相似性度量计算使用式 (3) .在计算障碍距离时, 则使用式 (5) 进行相似性度量.</p>
                </div>
                <div class="p1">
                    <p id="305">算法6在创建Voronoi图所需的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .算法执行for循环时, 遍历不确定数据点所需的时间复杂度是<i>O</i> (<i>n</i>) .<i>n</i>代表的是不确定数据的总数量, 并且数量是有限的, 所以算法是可终止的.当算法满足步骤⑥所需的条件时, 调用算法2.算法2的时间复杂度已经分析得出是<i>O</i> (<i>n</i> lg <i>n</i>) .当算法满足步骤⑧所需的条件时, 调用算法3、算法4或者算法5, 以上算法的时间复杂度都为<i>O</i> (<i>n</i> lg <i>n</i>) .由以上分析可得出, 算法6总的时间复杂度为<i>O</i> (<i>n</i> lg <i>n</i>) .</p>
                </div>
                <h3 id="306" name="306" class="anchor-tag"><b>3 实验比较与分析</b></h3>
                <div class="p1">
                    <p id="307">本节主要通过实验对所提出的算法进行性能分析与比较.根据已有的研究成果发现, 在相似性度量方面, 大多集中在几何距离的度量上, 没有考虑数据间的概率分布.针对这些问题提出了STAO_RVUBSCAN, DYNOC_VUBSCAN, DYNOR_VUBSCAN, DYNOM_VUBSCAN等算法.由于现有的研究成果无法直接有效地处理动态障碍空间中的不确定数据的聚类问题, 因此对文献<citation id="532" type="reference">[<a class="sup">16</a>]</citation>中提出的OBS_UK_means算法中动态添加障碍和动态减少障碍, 进而分别与所提算法DYNOC_VUBSCAN, DYNOR_VUBSCAN, DYNOM_VUBSCAN进行实验比较与分析.</p>
                </div>
                <div class="p1">
                    <p id="308">根据障碍情况, 需要对OBS_UK_means算法做4种处理:</p>
                </div>
                <div class="p1">
                    <p id="309">1) 障碍集<i>O</i>=<i>O</i><sub>new</sub>时, 则与所提的静态障碍物环境下的聚类情况相同, 可利用OBS_UK_means算法与STAO_RVUBSCAN算法做实验对比.</p>
                </div>
                <div class="p1">
                    <p id="310">2) 障碍集<i>O</i>≠<i>O</i><sub>new</sub>, 并且<i>Count</i>_<i>O</i>&lt;<i>Count</i>_<i>O</i><sub>new</sub>时, 表示障碍物动态增加, 则在原有的聚类结果中添加新增障碍集, 再重新对空间中所有的不确定数据点进行聚类.将这种障碍动态增加时调用OBS_UK_means的算法与提出的DYNOC_ VUBSCA的方法做实验对比.</p>
                </div>
                <div class="p1">
                    <p id="311">3) 障碍集<i>O</i>≠<i>O</i><sub>new</sub>, 并且<i>Count</i>_<i>O</i>&gt;<i>Count</i>_<i>O</i><sub>new</sub>时, 表示障碍动态减少, 则对障碍集为<i>O</i><sub>new</sub>时的空间中所有不确定数据点重新聚类.将这种障碍动态减少时调用OBS_UK_means的算法与提出的DYNOR_ VUBSCA的方法做实验对比.</p>
                </div>
                <div class="p1">
                    <p id="312">4) 障碍集<i>O</i>≠<i>O</i><sub>new</sub>, 并且<i>Count</i>_<i>O</i>=<i>Count</i>_<i>O</i><sub>new</sub>时, 表示障碍物动态移动.对障碍集为<i>O</i><sub>new</sub>时的所有不确定数据点重新聚类, 将这种障碍动态移动时调用OBS_UK_means的算法与提出的DYNOM_ VUBSCA的方法做实验对比.</p>
                </div>
                <div class="p1">
                    <p id="313">实验环境:Windows7的64位操作系统, 采用Java编程.实验中计算机的硬件配置:8 GB内存, 500 GB硬盘, 处理器:Intel<sup>®</sup> Core<sup>TM</sup> i3处理器 (主频为2.30 GHz) .</p>
                </div>
                <div class="p1">
                    <p id="314">实验使用标准的UCI实验室数据集<citation id="533" type="reference"><link href="495" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>, 详细情况如表1所示:</p>
                </div>
                <div class="area_img" id="315">
                    <p class="img_tit"><b>表1 UCI实验室数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 UCI Laboratory Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="315" border="1"><tr><td><br />Dataset</td><td>Sample Size</td><td>Dimensionality</td><td>Category</td></tr><tr><td>Iris</td><td>150</td><td>4</td><td>3</td></tr><tr><td><br />Wine</td><td>178</td><td>13</td><td>3</td></tr><tr><td><br />Haberman</td><td>306</td><td>3</td><td>2</td></tr><tr><td><br />Heart</td><td>270</td><td>13</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="316">UCI实验室数据集中的数据表示的是确定的数据, 为便于实验, 在实验过程中对实验数据集进行了适当调整, 生成不确定数据的过程具体有5个步骤:1) 读取原始数据集的属性;2) 遍历数据集的每条数据的每个属性;3) 为每一条数据的每一维的属性值随机生成一个概率值, 概率值在[0, 1]范围之内, 最终表达的形式为:<i>X</i><sub><i>i</i></sub>={ (<i>x</i><sub>1</sub>, <i>p</i><sub>1</sub>) , (<i>x</i><sub>2</sub>, <i>p</i><sub>2</sub>) , …, (<i>x</i><sub><i>d</i></sub>, <i>p</i><sub><i>d</i></sub>) }, 其中每个<i>x</i><sub><i>i</i></sub>表示<i>X</i><sub><i>i</i></sub>的属性值, <i>d</i>为维度, <i>X</i><sub><i>i</i></sub>表示一个不确定数据点;4) 得到每条数据概率属性值;5) 输出不确定数据集.</p>
                </div>
                <div class="p1">
                    <p id="317">实验主要考虑6个方面因素:数据维度<i>d</i>、数据基数<i>n</i>、障碍物数量、障碍物分布、CPU运行时间、聚类质量.利用以上6方面作为衡量算法的指标.</p>
                </div>
                <div class="p1">
                    <p id="318">常用的聚类有效性评测有内部评价法、外部评价法和相关性测试评价.它们能对聚类结果进行评价, 得出聚类结果是否最优.实验采用评测指标 (silhouette) 作为聚类内部有效性评测, 实验采用F-measure熵<citation id="534" type="reference"><link href="497" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>作为聚类外部评测标准.</p>
                </div>
                <div class="p1">
                    <p id="319">分别对各个算法进行50次独立聚类实验, 统计每次实验的结果, 然后对每种算法求50次实验结果的平均值, 对比算法的实验结果如表2所示.结果显示, 对于以上4组数据集, RO_VUBSCAN算法的<i>F</i>-measure指标平均值和<i>S</i>指标均值均高于OBS_UK_means算法和FOPTICS算法的评测指标.通过实验可看出, RO_VUBSCAN算法表现出更好的聚类效果.</p>
                </div>
                <div class="area_img" id="320">
                    <p class="img_tit"><b>表2 算法评测有效性对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Comparison of Effectiveness of Algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="320" border="1"><tr><td><br />Dataset</td><td>Algorithm</td><td>F-measure</td><td>Silhouette</td></tr><tr><td><br /></td><td>RO_VUBSCAN</td><td>0.890 1</td><td>0.799 3</td></tr><tr><td><br />Iris</td><td>FOPTICS</td><td>0.878 0</td><td>0.803 2</td></tr><tr><td><br /></td><td>OBS_UK_means</td><td>0.853 0</td><td>0.775 1</td></tr><tr><td><br /></td><td>RO_VUBSCAN</td><td>0.793 8</td><td>0.818 9</td></tr><tr><td><br />Wine</td><td>FOPTICS</td><td>0.698 0</td><td>0.712 6</td></tr><tr><td><br /></td><td>OBS_UK_means</td><td>0.739 0</td><td>0.784 5</td></tr><tr><td><br /></td><td>RO_VUBSCAN</td><td>0.723 0</td><td>0.692 6</td></tr><tr><td><br />Haberman</td><td>FOPTICS</td><td>0.654 8</td><td>0.614 5</td></tr><tr><td><br /></td><td>OBS_UK_means</td><td>0.679 0</td><td>0.644 0</td></tr><tr><td><br /></td><td>RO_VUBSCAN</td><td>0.748 2</td><td>0.786 0</td></tr><tr><td><br />Heart</td><td>FOPTICS</td><td>0.690 3</td><td>0.758 5</td></tr><tr><td><br /></td><td>OBS_UK_means</td><td>0.712 8</td><td>0.706 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="321">图7中OBS_UK_means, RO_VUBSCAN, FOPTICS这3个算法的CPU执行时间随着维度<i>d</i>的增加而增加, 其中RO_VUBSCAN算法的CPU执行时间上升趋势较平缓.从实验结果看出, 使用KL距离相似性度量方法比其他的距离度量更高效.由于考虑障碍的存在, 随着维度的增加, OBS_UK_means算法需要考虑障碍的存在, 因此CPU执行时间大于FOPTICS算法.</p>
                </div>
                <div class="area_img" id="322">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_322.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 维度d对CPU执行时间的影响" src="Detail/GetImg?filename=images/JFYZ201905009_322.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 维度<i>d</i>对CPU执行时间的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_322.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 The effect of dimension <i>d</i> for CPU execution time</p>

                </div>
                <div class="p1">
                    <p id="323">如图8所示, 随着维度<i>d</i>的不断增加, 算法的有效性的变化曲线也呈下降趋势.通过实验, 得出在维度大于10之后的曲线, 算法的有效性变化曲线下降明显, 但STAO_RVUBSCAN算法的有效性依然较高.由于DYNOR_VUBSCAN算法和DYNOR_VUBSCAN算法处理的是动态障碍的情况, 因此有效性较静态障碍空间下STAO_RVUBSCAN算法的有效性略低一些.</p>
                </div>
                <div class="area_img" id="324">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_324.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 维度d对算法有效性的影响" src="Detail/GetImg?filename=images/JFYZ201905009_324.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 维度<i>d</i>对算法有效性的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_324.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 The effect of dimension <i>d</i> on algorithm effectiveness</p>

                </div>
                <div class="p1">
                    <p id="325">图9给出了3个算法的CPU执行时间随着不确定数据样本数变化的对比结果.随着不确定数据样本数的不断增大, FOPTICS算法在数据量增大时, CPU的执行时间急剧上升.但在数据量较小的时刻, 因为FOPTICS算法没有障碍的约束, FOPTICS算法的CPU执行时间比RO_VUBSCAN算法的执行时间少.在相同不确定数据样本数的情况下, RO_VUBSCAN的CPU执行时间一直小于OBS_UK_means算法, 因此通过实验得知RO_VUBSCAN算法更有效.</p>
                </div>
                <div class="area_img" id="326">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_326.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 样本数对CPU执行时间的影响" src="Detail/GetImg?filename=images/JFYZ201905009_326.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 样本数对CPU执行时间的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_326.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 The effect of sample number on CPU execution time</p>

                </div>
                <div class="p1">
                    <p id="327">图10给出了数据量从5 000增加到30 000的过程中, 3个算法对应的CPU执行时间的变化情况.通过实验得出, RO_VUBSCAN算法的CPU执行时间相对于OBS_UK_means, FOPTICS更少.因此得出算法RO_VUBSCAN算法更有效.</p>
                </div>
                <div class="area_img" id="328">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_328.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 数据量对CPU执行时间的影响" src="Detail/GetImg?filename=images/JFYZ201905009_328.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 数据量对CPU执行时间的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_328.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 The effect of data size on CPU execution time</p>

                </div>
                <div class="p1">
                    <p id="329">如图11所示, 分析了数据量从5 000增加到30 000期间, 随着数据量的增加, 3个聚类算法的有效性.通过实验结果可看出, FOPTICS算法的曲线平稳, 并且效率一直较高.相比于RO_VUBSCAN算法, 由于障碍的存在, 聚类的过程中, 存在着一定的误差, 在数据量增加到20 000期间有效性比FOPTICS略低, 随着数据量的继续增加, 算法的有效性比FOPTICS高.相比于OBS_UK_means算法, RO_VUBSCAN算法更有效.</p>
                </div>
                <div class="area_img" id="330">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905009_330.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 数据量对算法有效性的影响" src="Detail/GetImg?filename=images/JFYZ201905009_330.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 数据量对算法有效性的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905009_330.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 The effect of data size on the effectiveness of algorithm</p>

                </div>
                <div class="p1">
                    <p id="331">表3给出了障碍物动态减少时DYNOR_VUBSCAN算法与对比算法的CPU执行时间的比较情况.结果显示, DYNOR_VUBSCAN算法的CPU执行时间均小于对比算法, 当障碍物动态减少时, 由于对比算法需要计算全部数据, 因此CPU执行时间远大于DYNOR_VUBSCAN算法.</p>
                </div>
                <div class="area_img" id="332">
                    <p class="img_tit"><b>表3 障碍物动态减少对CPU执行时间的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 The Effect of the Dynamic Reduction of Obstacles on the Execution Time of CPU</b></p>
                    <p class="img_note"></p>
                    <table id="332" border="1"><tr><td><br />Algorithm</td><td>Number of Obstacles</td><td>CPU Time/s</td></tr><tr><td><br />DYNOR_VUBSCAN</td><td>100</td><td>10.7</td></tr><tr><td><br />OBS_UK_means</td><td>100</td><td>15.6</td></tr><tr><td><br />DYNOR_VUBSCAN</td><td>90</td><td>12.4</td></tr><tr><td><br />OBS_UK_means</td><td>90</td><td>19.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="333">表4给出了障碍物动态增加时DYNOC_VUBSCAN算法与对比算法的CPU执行时间的比较情况, 在障碍物数量动态增加时, DYNOC_VUBSCAN算法的CPU执行时间变化不大, 而对比算法的CPU执行时间变化则较大.结果表明:所提算法优于对比算法.</p>
                </div>
                <div class="area_img" id="334">
                    <p class="img_tit"><b>表4 障碍物动态增加对CPU执行时间的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 The Effect of the Dynamic Increase of Obstacles on the Execution Time of CPU</b></p>
                    <p class="img_note"></p>
                    <table id="334" border="1"><tr><td><br />Algorithm</td><td>Number of Obstacles</td><td>CPU Time/s</td></tr><tr><td><br />DYNOC_VUBSCAN</td><td>100</td><td>11.1</td></tr><tr><td><br />OBS_UK_means</td><td>100</td><td>15.9</td></tr><tr><td><br />DYNOC_VUBSCAN</td><td>110</td><td>12.8</td></tr><tr><td><br />OBS_UK_means</td><td>110</td><td>21.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="335">表5给出了障碍物动态移动时DYNOM_VUBSCAN算法与对比算法的CPU执行时间的比较情况.结果显示DYNOM_VUBSCAN算法的CPU执行时间远小于对比算法的CPU执行时间.</p>
                </div>
                <div class="area_img" id="336">
                    <p class="img_tit"><b>表5 障碍物动态移动对CPU执行时间的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 The Effect of the Dynamic Movement of Obstacles on the Execution Time of CPU</b></p>
                    <p class="img_note"></p>
                    <table id="336" border="1"><tr><td><br />Algorithm</td><td>Obstacle</td><td>Number of<br />Obstacles</td><td>CPU<br />Time/s</td></tr><tr><td><br />DYNOM_VUBSCAN</td><td><i>O</i></td><td>100</td><td>12.9</td></tr><tr><td><br />OBS_UK_means</td><td><i>O</i></td><td>100</td><td>19.2</td></tr><tr><td><br />DYNOM_VUBSCAN</td><td><i>O</i><sub>new</sub></td><td>100</td><td>14.9</td></tr><tr><td><br />OBS_UK_means</td><td><i>O</i><sub>new</sub></td><td>100</td><td>24.7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="337">表6显示了障碍物数量增加时STAO_RVUBSCAN算法与对比算法的CPU执行时间的比较情况, 在障碍物数量不断增加时, STAO_RVUBSCAN算法的CPU执行时间增加的趋势较缓慢, 而对比算法的CPU执行时间变化较大.</p>
                </div>
                <div class="p1">
                    <p id="338">表7给出了障碍物分布不同时RO_VUBSCAN算法与对比算法的CPU执行时间比较情况, 障碍物的分布是随机的, 结果显示RO_VUBSCAN算法的CPU执行时间变化不大, 并且执行时间均小于对比算法.</p>
                </div>
                <div class="area_img" id="339">
                    <p class="img_tit"><b>表6 不同数量的障碍物对CPU执行时间的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 The Effect of the Different Number of Obstacles on the Execution Time of CPU</b></p>
                    <p class="img_note"></p>
                    <table id="339" border="1"><tr><td><br />Algorithm</td><td>Number of Obstacles</td><td>CPU Time/s</td></tr><tr><td rowspan="4"><br />STAO_RVUBSCAN</td><td><br />100</td><td>13.2</td></tr><tr><td><br />200</td><td>18.7</td></tr><tr><td><br />300</td><td>26.5</td></tr><tr><td><br />400</td><td>29.7</td></tr><tr><td rowspan="4"><br />OBS_UK_means</td><td><br />100</td><td>18.6</td></tr><tr><td><br />200</td><td>33.5</td></tr><tr><td><br />300</td><td>48.2</td></tr><tr><td><br />400</td><td>63.7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="340">
                    <p class="img_tit"><b>表7 障碍物不同位置分布对CPU执行时间的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 7 The Effect of Different Location Distribution of Obstacles on the Execution Time of CPU</b></p>
                    <p class="img_note"></p>
                    <table id="340" border="1"><tr><td><br />Algorithm</td><td>Obstacle</td><td>Number of <br />Obstacles</td><td>CPU Time/s</td></tr><tr><td><br />RO_VUBSCAN</td><td><i>o</i></td><td>100</td><td>15.2</td></tr><tr><td><br />OBS_UK_means</td><td><i>o</i></td><td>100</td><td>19.8</td></tr><tr><td><br />RO_VUBSCAN</td><td><i>o</i><sub>new</sub></td><td>100</td><td>16.3</td></tr><tr><td><br />OBS_UK_means</td><td><i>o</i><sub>new</sub></td><td>100</td><td>21.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="341">通过以上实验分析可知, 提出的静态障碍物环境下的不确定数据聚类算法STAO_RVUBSCAN与动态障碍物环境下的DYNOC_VUBSCAN, DYNOR_VUBSCAN, DYNOM_VUBSCAN不确定聚类算法均具有较高的效率.</p>
                </div>
                <h3 id="342" name="342" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="343">传统的聚类算法大多是在欧氏空间进行, 没有考虑障碍的存在.由于现实生活中, 不确定数据点之间可能存在障碍, 因此本文根据障碍物集合是否发生变化, 把障碍大致分成2种情况, 分别对静态障碍空间下和动态障碍空间下的不确定数据进行聚类分析.静态障碍空间中, 提出了STAO_VUBSCAN算法和精炼算法STAO_RVUBSCAN.精炼算法的提出, 使得聚类结果更准确和高效.对于动态障碍, 考虑了障碍物动态增加、障碍物动态减少和障碍物动态移动3种情况, 分别对这3种情况进行分析, 提出了DYNOC_VUBSCAN算法、DYNOR_VUBSCAN算法和DYNOM_VUBSCAN算法.理论研究和实验分析验证表明, 提出的算法具有较高的性能.由于没有对确定数据进行聚类分析, 未来研究的重点主要是障碍物动态情况下的确定数据聚类问题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="447">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEB3422818A085084C3312531DF246C58&amp;v=MDE0MzBOdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnhnekwyMndhND1OaWZPZmNiS0hkWE9yWWRFYkpvUEJIazV4eEpnNlR4OFNucmhyV1pEZTdhU05yK1hDTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Zhang Xianchao, Liu Han, Zhang Xiaotong.Novel density-based and hierarchical density-based clustering algorithms for uncertain data[J].Neural Networks, 2017, 93 (9) :240- 255
                            </a>
                        </p>
                        <p id="449">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX200901001&amp;v=MDAzNTg3T0x6N0Jkckc0SHRqTXJvOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Zhou Aoying, Jin Cheqing, Wang Guoren, et al.A survey on the management of uncertain data[J].Chinese Journal of Computers, 2009, 32 (1) :1- 16 (in Chinese) (周傲英, 金澈清, 王国仁, 等.不确定性数据管理技术研究综述[J].计算机学报, 2009, 32 (1) :1- 16) 
                            </a>
                        </p>
                        <p id="451">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient clustering of uncertain data">

                                <b>[3]</b>Ngai W K, Kao B, Chui C K, et al.Efficient clustering of uncertain data[C] //Proc of the 6th Int Conf on Data Mining.Piscataway, NJ:IEEE, 2006:436- 445
                            </a>
                        </p>
                        <p id="453">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An improved k-means clustering algorithm">

                                <b>[4]</b>Wang Juntao, Su Xiaolong.An improved k-means clustering algorithm[C] //Proc of the 3rd Int Symp on Intelligent Information Technology and Security Informatics.Piscataway, NJ:IEEE, 2011:63- 67
                            </a>
                        </p>
                        <p id="455">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=STING: A statistical information grid approach to spatial data mining">

                                <b>[5]</b>Wang Wei, Yang Jiong, Muntz R.STING:A statistical information grid approach to spatital data mining[C] //Proc of the 23rd Int Conf on Very Large Data Bases.San Francisco:Morgan Kaufmann, 1997:186- 195
                            </a>
                        </p>
                        <p id="457">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=AdaU K-Means:an ensemble boosting clustering algorithm on uncertain objects">

                                <b>[6]</b>Xu Lei, Hu Qinghua, Zhang Xisheng, et al.AdaUK-Means:An ensemble boosting clustering algorithm on uncertain objects[C] //Proc of the 7th Chinese Conf on Pattern Recognition.Berlin:Springer, 2016:27- 41
                            </a>
                        </p>
                        <p id="459">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An effective clustering mechanism for uncertain data mining using centroid boundary in UKmeans">

                                <b>[7]</b>Liao Kuanteng, Liu Chuanming.An effective clustering mechanism for uncertain data mining using centroid boundary in UKmeans[C] //Proc of Int Computer Symp.Piscataway, NJ:IEEE, 2017:300- 305
                            </a>
                        </p>
                        <p id="461">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new method for noise data detection based on DBSCAN and SVDD">

                                <b>[8]</b>Hao Shengxuan, Zhou Xiaofeng, Hong Song.A new method for noise data detection based on DBSCAN and SVDD[C] //Proc of the 5th IEEE Int Conf on Cyber Technology in Automation, Control, and Intelligent Systems.Piscataway, NJ:IEEE, 2015:784- 789
                            </a>
                        </p>
                        <p id="463">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical density-based clustering of uncertain data">

                                <b>[9]</b>Kriegel H P, Pfeifle M.Hierarchical density-based clustering of uncertain data[C] //Proc of the 5th IEEE Int Conf on Data Mining.Piscataway, NJ:IEEE, 2005:689- 692
                            </a>
                        </p>
                        <p id="465">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES24E24497651FD1D31EFFDCEC6D0EECBB&amp;v=MzA0MzNsZkNwYlEzNU54Z3pMMjJ3YTQ9TmlmT2ZiRzhhOVBJcTRaQ1l1NE9lZ2c0dXhVU24wa0xQQXlYM3hSQmVjZmhOc2p0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Han Liu, Zhang Xianchao, Zhang Xiaotong, et al.Self-adapted mixture distance measure for clustering uncertain data[J].Knowledge-Based Systems, 2017, 126 (12) :33- 47
                            </a>
                        </p>
                        <p id="467">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=M-FDBSCAN A multi-core density-based uncertain data clustering algorithm">

                                <b>[11]</b>Erdem A, Gündem T I.M-FDBSCAN:A multicore density-based uncertain data clustering algorithm[J].Turkish Journal of Electrical Engineering &amp; Computer Sciences, 2014, 22 (1) :143- 154
                            </a>
                        </p>
                        <p id="469">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201603023&amp;v=MzE3MTMzenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1dyN09MamZTYmJHNEg5Zk1ySTlIWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Lu Yihong, Xia Cong.Optimal k-nearest neighbors and local density-based clustering algorithm for uncertain data[J].Control and Decision, 2016, 31 (3) :541- 546 (in Chinese) (陆亿红, 夏聪.不确定数据的最优k近邻和局部密度聚类算法[J].控制与决策, 2016, 31 (3) :541- 546) 
                            </a>
                        </p>
                        <p id="471">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201806016&amp;v=MDcxNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTHo3U1pMRzRIOW5NcVk5RVlvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Han Lizhao, Qian Xuezhong, Luo Jing, et al.Multi-density clustering algorithm DBSCAN based on region division[J].Application Research of Computers, 2018, 35 (6) :1668- 1671 (in Chinese) (韩利钊, 钱雪忠, 罗靖, 等.基于区域划分的DBSCAN多密度聚类算法[J].计算机应用研究, 2018, 35 (6) :1668- 1671
                            </a>
                        </p>
                        <p id="473">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering uncertain data using voronoi diagrams and R-tree index">

                                <b>[14]</b>Ben Kao, Lee S D, Lee F K F.Clustering uncertain data using voronoi diagrams and R-Tree index[J].IEEE Transactions on Knowledge &amp; Data Engineering, 2010, 22 (9) :1219- 1233
                            </a>
                        </p>
                        <p id="475">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial queries in the presence of obstacles">

                                <b>[15]</b>Zhang Jun, Papadias D, Mouratidis K, et al.Spatial queries in the presence of obstacles[C] //Proc of the 9th Int conf on Extending Database Technology.Berlin:Springer, 2004:366- 384
                            </a>
                        </p>
                        <p id="477">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201212005&amp;v=MjA0ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1dyN09MalhmZmJHNEg5UE5yWTlGWVlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Cao Keyan, Wang Guoren, Han Donghong, et al.Clustering algorithm of uncertain data in obstacle space[J].Journal of Frontiers of Computer Science &amp; Technology, 2012, 6 (12) :1087- 1097 (in Chinese) (曹科研, 王国仁, 韩东红, 等.障碍空间中不确定数据聚类算法[J].计算机科学与探索, 2012, 6 (12) :1087- 1097) 
                            </a>
                        </p>
                        <p id="479">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel spatial clustering with obstacles constraints based on PNPSO and K-me doids">

                                <b>[17]</b>Zhang Xueping, Du Haohua, Yang Tengfeng, et al.A novel spatial clustering with obstacles constraints based on PNPSO and K-Medoids[G] //Advances in Swarm Intelligence.Berlin:Springer, 2010:605- 610
                            </a>
                        </p>
                        <p id="481">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=K-medoids method based on divergence for uncertain data clustering">

                                <b>[18]</b>Zhou Jin, Pan Yuqi, Chen C L P, et al.K-medoids method based on divergence for uncertain data clustering[C] //Proc of the 46th IEEE Int Conf on Systems, Man, and Cybernetics.Piscataway, NJ:IEEE, 2017:2671- 2674
                            </a>
                        </p>
                        <p id="483">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Uncertain data cluster based on DBSCAN">

                                <b>[19]</b>Pan Donghua, Zhao Lilei.Uncertain data cluster based on DBSCAN[C] //Proc of the 2nd Int Conf on Multimedia Technology.Piscataway, NJ:IEEE, 2011:3781- 3784
                            </a>
                        </p>
                        <p id="485">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030372581000&amp;v=MjA5NTN4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3ZoVXJmTktWOFNYRnF6R2JPN0h0TExyWXBOWmVzUERCTTh6&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Hao Zhongxiao.Spatial Databases Theoretical Basis[M].Beijing:Science Press, 2013 (in Chinese) (郝忠孝.空间数据库理论基础[M].北京:科学出版社, 2013) 
                            </a>
                        </p>
                        <p id="487">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201704019&amp;v=MDg2NjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnV3I3T0x5dlNkTEc0SDliTXE0OUViWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Zhang Liping, Liu Lei, Hao Xiaohong, et al.Voronoi-based group reverse k nearest neighbor query in obstructed space[J].Journal of Computer Research and Development, 2017, 54 (4) :861- 871 (in Chinese) (张丽平, 刘蕾, 郝晓红, 等.障碍空间中基于Voronoi图的组反k最近邻查询研究[J].计算机研究与发展, 2017, 54 (4) :861- 871) 
                            </a>
                        </p>
                        <p id="489">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014325295.nh&amp;v=MjU1MTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPVkYyNkdyQzZHOVBGcXBFYlA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Wang Jianrong.Research on clustering algorithm for uncertain data based on probability distribution similarity[D].Xi’an:Xidian University, 2014 (in Chinese) (王建荣.基于概率分布相似性的不确定数据聚类算法研究[D].西安:西安电子科技大学, 2014) 
                            </a>
                        </p>
                        <p id="491">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEE0560042004793EE5382038E0868EF2&amp;v=MTI2NTB5ZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Z3pMMjJ3YTQ9TmlmT2ZjYk5IdFRLcjQ5Qlp1c1BDSHN3ekdObTd6eDFTbi9ocEdjMWNiU2NNTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Xu Lei, Hu Qinghua, Hung E, et al.Large margin clustering on uncertain data by considering probability distribution similarity[J].Neurocomputing, 2015, 158 (12) :81- 89
                            </a>
                        </p>
                        <p id="493">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200306008&amp;v=MjE2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXcjdPTnlmVGJMRzRIdExNcVk5RmJJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Ma Shuai, Wang Tengjiao, Tang Shiwei, et al.A fast clustering algorithm based on reference and density[J].Journal of Software, 2003, 14 (6) :1089- 1095 (in Chinese) (马帅, 王腾蛟, 唐世渭, 等.一种基于参考点和密度的快速聚类算法[J].软件学报, 2003, 14 (6) :1089- 1095) 
                            </a>
                        </p>
                        <p id="495">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201606054&amp;v=MTM0ODllUnFGaURnV3I3T0x6N0JiN0c0SDlmTXFZOUFZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b>He Yunbin, Zhang Zhichao, Wang Jing, et al.Research for uncertain data clustering algorithm:U-PAM and UM-PAM algorithm[J].Computer Science, 2016, 43 (6) :263- 269 (in Chinese) (何云斌, 张志超, 万静, 等.不确定数据聚类的U-PAM算法和UM-PAM算法的研究[J].计算机科学, 2016, 43 (6) :263- 269) 
                            </a>
                        </p>
                        <p id="497">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ2014S2013&amp;v=MTE2MDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1dyN09MeXZTZExHNEg5V3ZyWTlFWjRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b>Cao Zhenli, Sun Ruizhi, Li Meng.A method for clustering uncertain data streams based on GMM[J].Journal of Computer Research and Development, 2014, 51 (SupplⅡ) :102- 109 (in Chinese) (曹振丽, 孙瑞志, 李勐.一种基于高斯混合模型的不确定数据流聚类方法[J].计算机研究与发展, 2014, 51 (增刊Ⅱ) :102- 109) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201905009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905009&amp;v=MTcxMTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnV3I3T0x5dlNkTEc0SDlqTXFvOUY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlPSWlZN045QnpnZXF1Zz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

