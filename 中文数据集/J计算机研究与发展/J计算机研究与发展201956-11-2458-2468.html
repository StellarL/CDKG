

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127119360145000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJFYZ201911015%26RESULT%3d1%26SIGN%3d8luHwlOUHgaoXYUaEYfL1cLdDZQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911015&amp;v=MzI0OTlHRnJDVVJMT2VaZVJzRnl6blVML1BMeXZTZExHNEg5ak5ybzlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;1.1 脉冲噪声模型&lt;/b&gt;"><b>1.1 脉冲噪声模型</b></a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;1.2 DnCNN降噪算法简介&lt;/b&gt;"><b>1.2 DnCNN降噪算法简介</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;2 IQA-FBDA算法&lt;/b&gt; "><b>2 IQA-FBDA算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;2.1 设计思想与技术路线&lt;/b&gt;"><b>2.1 设计思想与技术路线</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;2.2 混合噪声模式分类字典的构建&lt;/b&gt;"><b>2.2 混合噪声模式分类字典的构建</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;2.3 图像质量评估模型&lt;/b&gt;"><b>2.3 图像质量评估模型</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;2.4 深层降噪模型&lt;/b&gt;"><b>2.4 深层降噪模型</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;2.5 降噪后再评估策略&lt;/b&gt;"><b>2.5 降噪后再评估策略</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#98" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="&lt;b&gt;3.1 实验设置&lt;/b&gt;"><b>3.1 实验设置</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;3.2 降噪效果比较&lt;/b&gt;"><b>3.2 降噪效果比较</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;3.3 执行时间比较&lt;/b&gt;"><b>3.3 执行时间比较</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="&lt;b&gt;4 总  结&lt;/b&gt; "><b>4 总  结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="图1 DnCNN网络的组成架构">图1 DnCNN网络的组成架构</a></li>
                                                <li><a href="#79" data-title="图2 IQA-FBDA算法的流程框图">图2 IQA-FBDA算法的流程框图</a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表1 各类噪声图像子集对应的噪声组合模式&lt;/b&gt;"><b>表1 各类噪声图像子集对应的噪声组合模式</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;表2 各类噪声图像子集所对应的PSNR值范围&lt;/b&gt;"><b>表2 各类噪声图像子集所对应的PSNR值范围</b></a></li>
                                                <li><a href="#86" data-title="图3 不同类别的噪声图像在视觉上的对比">图3 不同类别的噪声图像在视觉上的对比</a></li>
                                                <li><a href="#90" data-title="图4 基于图块级的图像质量评估模型">图4 基于图块级的图像质量评估模型</a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表3 图像质量评估模型的分类准确性&lt;/b&gt;"><b>表3 图像质量评估模型的分类准确性</b></a></li>
                                                <li><a href="#94" data-title="图5 BSD数据库中部分代表性图像">图5 BSD数据库中部分代表性图像</a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表4 各算法在单张噪声图像上的降噪效果对比&lt;/b&gt;"><b>表4 各算法在单张噪声图像上的降噪效果对比</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表5 各算法在10张常用图像上的平均降噪效果对比&lt;/b&gt;"><b>表5 各算法在10张常用图像上的平均降噪效果对比</b></a></li>
                                                <li><a href="#106" data-title="图6 在Barbara图像上的降噪效果的视觉对比">图6 在Barbara图像上的降噪效果的视觉对比</a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表6 各算法在100张BSD图像上的平均降噪效果对比&lt;/b&gt;"><b>表6 各算法在100张BSD图像上的平均降噪效果对比</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表7 各算法在100张自然图像上的平均降噪效果对比&lt;/b&gt;"><b>表7 各算法在100张自然图像上的平均降噪效果对比</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表8 各算法平均执行时间对比&lt;/b&gt;"><b>表8 各算法平均执行时间对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="150">


                                    <a id="bibliography_1" title="Xu Shaoping,Zeng Xiaoxia,Tang Yiling.Fast noise level estimation algorithm based on two-stage support vector regression[J].Journal of Computer-Aided Design &amp;amp; Computer Graphics,2018,30(3):447- 458 (in Chinese)(徐少平,曾小霞,唐祎玲.基于两阶段支持向量回归的快速噪声水平估计算法[J].计算机辅助设计与图形学学报,2018,30(3):447- 458)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201803010&amp;v=MTc3NDJDVVJMT2VaZVJzRnl6blVML1BMejdCYUxHNEg5bk1ySTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Xu Shaoping,Zeng Xiaoxia,Tang Yiling.Fast noise level estimation algorithm based on two-stage support vector regression[J].Journal of Computer-Aided Design &amp;amp; Computer Graphics,2018,30(3):447- 458 (in Chinese)(徐少平,曾小霞,唐祎玲.基于两阶段支持向量回归的快速噪声水平估计算法[J].计算机辅助设计与图形学学报,2018,30(3):447- 458)
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_2" title="Wu Jiang,You Fei,Jiang Ping.Noise variance estimation method based on regression analysis and principal component analysis[J].Journal of Electronics &amp;amp; Information Technology,2018,40(5):1195- 1201 (in Chinese)(吴疆,尤飞,蒋平.基于回归分析和主成分分析的噪声方差估计方法[J].电子与信息学报,2018,40(5):1195- 1201)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201805026&amp;v=MzE3MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUwvUElUZlNkckc0SDluTXFvOUhZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Wu Jiang,You Fei,Jiang Ping.Noise variance estimation method based on regression analysis and principal component analysis[J].Journal of Electronics &amp;amp; Information Technology,2018,40(5):1195- 1201 (in Chinese)(吴疆,尤飞,蒋平.基于回归分析和主成分分析的噪声方差估计方法[J].电子与信息学报,2018,40(5):1195- 1201)
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_3" title="Xu Shaoping,Yang Rongchang,Liu Xiaoping.Adaptive switching median filter based on noise ratio estimation[J].Journal of Optoelectronics&#183;Laser,2014,25(4):792- 800 (in Chinese)(徐少平,杨荣昌,刘小平.基于噪声估计的自适应开关型中值滤波器[J].光电子&#183;激光,2014,25(4):792- 800)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201404028&amp;v=MDYzNzM0OUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUwvUElpblJaTEc0SDlYTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Xu Shaoping,Yang Rongchang,Liu Xiaoping.Adaptive switching median filter based on noise ratio estimation[J].Journal of Optoelectronics&#183;Laser,2014,25(4):792- 800 (in Chinese)(徐少平,杨荣昌,刘小平.基于噪声估计的自适应开关型中值滤波器[J].光电子&#183;激光,2014,25(4):792- 800)
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_4" title="Zhang Kai,Zuo Wangmeng,Chen Yunjin,et al.Beyond a Gaussian denoiser:Residual learning of deep CNN for image denoising[J].IEEE Transactions on Image Processing,2017,26(7):3142- 3155" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Beyond a Gaussian Denoiser:Residual Learning of Deep CNN for Image Denoising">
                                        <b>[4]</b>
                                        Zhang Kai,Zuo Wangmeng,Chen Yunjin,et al.Beyond a Gaussian denoiser:Residual learning of deep CNN for image denoising[J].IEEE Transactions on Image Processing,2017,26(7):3142- 3155
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                    Zhang Kai,Zuo Wangmeng,Zhang Lei.FFDNet:Toward a fast and flexible solution for CNN based image denoising[J].IEEE Transactions on Image Processing,2018,27(9):4608- 4622</a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_6" title="Singh N,Thilagavathy T,Lakshmipriya R T,et al.Some studies on detection and filtering algorithms for the removal of random valued impulse noise[J].IET Image Processing,2017,11(11):953- 963" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Some studies on detection and filtering algorithms for the removal of random valued impulse noise">
                                        <b>[6]</b>
                                        Singh N,Thilagavathy T,Lakshmipriya R T,et al.Some studies on detection and filtering algorithms for the removal of random valued impulse noise[J].IET Image Processing,2017,11(11):953- 963
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_7" title="Taherkhani F,Jamzad M.Restoring highly corrupted images by impulse noise using radial basis functions interpolation[J].IET Image Processing,2018,12(1):20- 30" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Restoring highly corrupted images by impulse noise using radial basis functions interpolation">
                                        <b>[7]</b>
                                        Taherkhani F,Jamzad M.Restoring highly corrupted images by impulse noise using radial basis functions interpolation[J].IET Image Processing,2018,12(1):20- 30
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_8" title="Velayudhan D,Paul S.Two-phase approach for recovering images corrupted by Gaussian-plus-impulse noise[C] //Proc of 2016 Int Conf on Inventive Computation Technologies (ICICT).Piscataway,NJ:IEEE,2016 [2018-08-23].https://ieeexplore.ieee.org/document/7824875" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Two-phase approach for recovering images corrupted by Gaussian-plus-impulse noise">
                                        <b>[8]</b>
                                        Velayudhan D,Paul S.Two-phase approach for recovering images corrupted by Gaussian-plus-impulse noise[C] //Proc of 2016 Int Conf on Inventive Computation Technologies (ICICT).Piscataway,NJ:IEEE,2016 [2018-08-23].https://ieeexplore.ieee.org/document/7824875
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_9" title="Cai Jianfeng,Chan R H,Nikolova M.Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise[J].Inverse Problems and Imaging,2008,2(2):187- 204" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise">
                                        <b>[9]</b>
                                        Cai Jianfeng,Chan R H,Nikolova M.Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise[J].Inverse Problems and Imaging,2008,2(2):187- 204
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_10" title="Xiao Yu,Zeng Tieyong,Yu Jian,et al.Restoration of images corrupted by mixed Gaussian-impulse noise via l1-l0 minimization[J].Pattern Recognition,2011,44(8):1708- 1720" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738183&amp;v=MTAxMDFSZEdlcnFRVE1ud1plWnVIeWptVUwzSUpGd1hhaFU9TmlmT2ZiSzdIdEROcVk5RlkrZ0hEWFE2b0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Xiao Yu,Zeng Tieyong,Yu Jian,et al.Restoration of images corrupted by mixed Gaussian-impulse noise via l1-l0 minimization[J].Pattern Recognition,2011,44(8):1708- 1720
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_11" title="Zhang Jian,Xiong Ruiqin,Zhao Chen,et al.Exploiting image local and nonlocal consistency for mixed Gaussian-impulse noise removal[C] //Proc of 2012 IEEE Int Conf on Multimedia and Expo.Piscataway,NJ:IEEE,2012:592- 597" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting image local and nonlocal consistency for mixed Gaussian-impulse noise removal">
                                        <b>[11]</b>
                                        Zhang Jian,Xiong Ruiqin,Zhao Chen,et al.Exploiting image local and nonlocal consistency for mixed Gaussian-impulse noise removal[C] //Proc of 2012 IEEE Int Conf on Multimedia and Expo.Piscataway,NJ:IEEE,2012:592- 597
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_12" title="Liu Jun,Tai Xuecheng,Huang Haiyang,et al.A weighted dictionary learning model for denoising images corrupted by mixed noise[J].IEEE Transactions on Image Processing,2013,22(3):1108- 1120" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Weighted Dictionary Learning Model for Denoising Images Corrupted by Mixed Noise">
                                        <b>[12]</b>
                                        Liu Jun,Tai Xuecheng,Huang Haiyang,et al.A weighted dictionary learning model for denoising images corrupted by mixed noise[J].IEEE Transactions on Image Processing,2013,22(3):1108- 1120
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_13" title="Jiang Jielin,Zhang Lei,Yang Jian.Mixed noise removal by weighted encoding with sparse nonlocal regularization[J].IEEE Transactions on Image Processing,2014,23(6):2651- 2662" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mixed noise removal by weighted encoding with sparse nonlocal regularization">
                                        <b>[13]</b>
                                        Jiang Jielin,Zhang Lei,Yang Jian.Mixed noise removal by weighted encoding with sparse nonlocal regularization[J].IEEE Transactions on Image Processing,2014,23(6):2651- 2662
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_14" title="Huang Tao,Dong Weisheng,Xie Xuemei,et al.Mixed noise removal via Laplacian scale mixture modeling and nonlocal low-rank approximation[J].IEEE Transactions on Image Processing,2017,26(7):3171- 3186" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mixed Noise Removal via Laplacian Scale Mixture Modeling and Nonlocal Low-Rank Approximation">
                                        <b>[14]</b>
                                        Huang Tao,Dong Weisheng,Xie Xuemei,et al.Mixed noise removal via Laplacian scale mixture modeling and nonlocal low-rank approximation[J].IEEE Transactions on Image Processing,2017,26(7):3171- 3186
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_15" title="Liu Licheng,Chen Long,Chen C L P,et al.Weighted joint sparse representation for removing mixed noise in image[J].IEEE Transactions on Cybernetics,2017,47(3):600- 611" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weighted joint sparse resentation for removing mixed noise in image">
                                        <b>[15]</b>
                                        Liu Licheng,Chen Long,Chen C L P,et al.Weighted joint sparse representation for removing mixed noise in image[J].IEEE Transactions on Cybernetics,2017,47(3):600- 611
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_16" title="Ren Jingjing,Fang Xianyong,Chen Shangwen,et al.Image deblurring based on fast convolutional neural networks[J].Journal of Computer-Aided Design &amp;amp; Computer Graphics,2017,29(8):1444- 1456 (in Chinese)(任静静,方贤勇,陈尚文,等.基于快速卷积神经网络的图像去模糊[J].计算机辅助设计与图形学学报,2017,29(8):1444- 1456)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201708007&amp;v=MDQ5ODc0SDliTXA0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUwvUEx6N0JhTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        Ren Jingjing,Fang Xianyong,Chen Shangwen,et al.Image deblurring based on fast convolutional neural networks[J].Journal of Computer-Aided Design &amp;amp; Computer Graphics,2017,29(8):1444- 1456 (in Chinese)(任静静,方贤勇,陈尚文,等.基于快速卷积神经网络的图像去模糊[J].计算机辅助设计与图形学学报,2017,29(8):1444- 1456)
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_17" title="Zhang Fu,Cai Nan,Wu Jixiu,et al.Image denoising method based on a deep convolution neural network[J].IET Image Processing,2018,12(4):485- 493" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image denoising method based on a deep convolution neural network">
                                        <b>[17]</b>
                                        Zhang Fu,Cai Nan,Wu Jixiu,et al.Image denoising method based on a deep convolution neural network[J].IET Image Processing,2018,12(4):485- 493
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_18" title="Remez T,Litany O,Giryes R,et al.Class-aware fully convolutional Gaussian and Poisson denoising[J].IEEE Transactions on Image Processing,2018,27(11):5707- 5722" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Class-aware fully convolutional Gaussian and Poisson denoising">
                                        <b>[18]</b>
                                        Remez T,Litany O,Giryes R,et al.Class-aware fully convolutional Gaussian and Poisson denoising[J].IEEE Transactions on Image Processing,2018,27(11):5707- 5722
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_19" title="Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[OL].[2018-09-10].http://arxiv.org/abs/1409.1556v6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">
                                        <b>[19]</b>
                                        Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[OL].[2018-09-10].http://arxiv.org/abs/1409.1556v6
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_20" title="Nair V,Hinton G E.Rectified linear units improve restricted Boltzmann machines[C] //Proc of the 27th Int Conf on Int Conf on Machine Learning.New York:ACM,2010:807- 814" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rectified linear units improve restricted Boltzmann machines">
                                        <b>[20]</b>
                                        Nair V,Hinton G E.Rectified linear units improve restricted Boltzmann machines[C] //Proc of the 27th Int Conf on Int Conf on Machine Learning.New York:ACM,2010:807- 814
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_21" title="Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Int Conf on Machine Learning.New York:ACM,2015:448- 456" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:accelerating deep network training by reducing internal covariate shift">
                                        <b>[21]</b>
                                        Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Int Conf on Machine Learning.New York:ACM,2015:448- 456
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_22" title="Arnelaez P,Maire M,Fowlkes C,et al.Contour detection and hierarchical image segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(5):898- 916" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contour Detection and Hierarchical Image Segmentation">
                                        <b>[22]</b>
                                        Arnelaez P,Maire M,Fowlkes C,et al.Contour detection and hierarchical image segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(5):898- 916
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_23" title="Zhang Lin,Zhang Lei,Bovik A C.A feature-enriched completely blind image quality evaluator[J].IEEE Transactions on Image Processing,2015,24(8):2579- 2591" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Feature-Enriched Completely Blind Image Quality Evaluator">
                                        <b>[23]</b>
                                        Zhang Lin,Zhang Lei,Bovik A C.A feature-enriched completely blind image quality evaluator[J].IEEE Transactions on Image Processing,2015,24(8):2579- 2591
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_24" title="Ponomarenko N,Jin L,Ieremeiev O,et al.Image database TID2013:Peculiarities,results and perspectives[J].Signal Processing:Image Communication,2015,30:57- 77" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200063619&amp;v=MjgwMTlPZmJLOEg5UE5yWTlGWk8wTUNuMHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKRndYYWhVPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Ponomarenko N,Jin L,Ieremeiev O,et al.Image database TID2013:Peculiarities,results and perspectives[J].Signal Processing:Image Communication,2015,30:57- 77
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_25" title="Dabov K,Foi A,Katkovnik V,et al.Image denoising by sparse 3D transform-domain collaborative filtering[J].IEEE Transactions on Image Processing,2007,16(8):2080- 2095" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering">
                                        <b>[25]</b>
                                        Dabov K,Foi A,Katkovnik V,et al.Image denoising by sparse 3D transform-domain collaborative filtering[J].IEEE Transactions on Image Processing,2007,16(8):2080- 2095
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(11),2458-2468 DOI:10.7544/issn1000-1239.2019.20180617            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>图像质量感知的混合噪声快速盲降噪算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E5%B0%91%E5%B9%B3&amp;code=08023640&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐少平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%A9%B7%E4%BA%91&amp;code=41659138&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘婷云</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E6%B4%81&amp;code=08015454&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗洁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%B4%B5%E7%8F%8D&amp;code=41659136&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张贵珍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%94%90%E7%A5%8E%E7%8E%B2&amp;code=10558755&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐祎玲</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%98%8C%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0252160&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南昌大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的高斯-脉冲混合噪声降噪算法多基于正则化技术采用迭代求解最优目标函数值的方式实现,执行效率普遍比较低,严重限制了其实际应用范围.为此,以卷积神经网络(convolutional neural network, CNN)为核心技术提出了一种基于图像质量感知的快速盲降噪算法(image quality-aware fast blind denoising algorithm, IQA-FBDA).在训练阶段,首先基于浅层CNN卷积神经网络设计图像质量评估模型来预测待降噪图像的图像质量值;然后,依据在大量噪声图像训练集合上获得的图像质量值统计分布规律构建混合噪声模式分类字典;最后,基于该分类字典将噪声图像集合划分为16个子集并训练与各个子集相匹配的深层CNN卷积神经网络专用降噪模型.在降噪阶段,首先利用图像质量评估模型估计给定待降噪图像的质量值,然后依据所预测的图像质量值查找噪声模式分类字典并调用与之相匹配预先训练好的深层CNN降噪模型即可快速地完成盲降噪任务.实验数据表明:IQA-FBDA算法在降噪效果方面的性能达到了与主流高斯-脉冲混合噪声降噪算法相当的水平,而在执行效率方面则有极大提高,更具实用价值.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%99%8D%E5%99%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像降噪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%96%AF-%E8%84%89%E5%86%B2%E6%B7%B7%E5%90%88%E5%99%AA%E5%A3%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高斯-脉冲混合噪声;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像质量感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%99%AA%E5%A3%B0%E6%A8%A1%E5%BC%8F%E5%88%86%E7%B1%BB%E5%AD%97%E5%85%B8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">噪声模式分类字典;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">执行效率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *罗洁(110745595@qq.com);
                                </span>
                                <span>
                                    徐少平,xushaoping@ncu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61662044,61163023,51765042);</span>
                                <span>江西省自然科学基金项目(20171BAB202017);</span>
                    </p>
            </div>
                    <h1><b>An Image Quality-Aware Fast Blind Denoising Algorithm for Mixed Noise</b></h1>
                    <h2>
                    <span>Xu Shaoping</span>
                    <span>Liu Tingyun</span>
                    <span>Luo Jie</span>
                    <span>Zhang Guizhen</span>
                    <span>Tang Yiling</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Nanchang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The existing Gaussian-impulse mixed noise removal algorithms usually restore the noisy images via regularization technique by solving an optimal objective function iteratively, which results in low executive efficiency and limits their practical applications. To this end, in this paper we propose an image quality-aware fast blind denoising algorithm(IQA-FBDA), which takes convolutional neural network(CNN) as the core technique for the removal of Gaussian-impulse mixed noise. In the training phase, a shallow CNN-based image quality estimation model is first exploited to estimate the image quality of the image to be denoised. Then, according to the statistical distribution of the image qualities of a large number of noisy images, we construct a mixed noise pattern classification dictionary(MNPCD). Based on the MNPCD, the training noisy images are classified into 16 sub-classes, and then deep CNN-based denoisers for each class are trained. In the denoising phase, the image quality estimation model is first used to estimate the quality value of a given noisy image. After querying the quality value in the MNPCD, the corresponding pre-trained denoiser is exploited to achieve efficient blind image denoising. Experiments show that, compared with the state-of-the-art Gaussian-impulse mixed noise removal algorithms, the proposed one achieves comparable noise reduction effect with great improvement in terms of the execution efficiency, which makes it more practical.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20denoising&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image denoising;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gaussian-impulse%20mixed%20noise&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gaussian-impulse mixed noise;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20quality-aware&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image quality-aware;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=noise%20pattern%20classification%20dictionary&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">noise pattern classification dictionary;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network(CNN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network(CNN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=execution%20efficiency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">execution efficiency;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Xu Shaoping,born in 1976.PhD,professor and PhD supervisor.His main research interests include digital image processing machine vision,and virtual surgery simulation.<image id="238" type="formula" href="images/JFYZ201911015_23800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Liu Tingyun,born in 1996.Master candidate.Her main research interests include digital image processing and machine vision.<image id="239" type="formula" href="images/JFYZ201911015_23900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Luo Jie,born in 1978.Bachelor.Her main research interests include medical image processing and machine learning.<image id="240" type="formula" href="images/JFYZ201911015_24000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhang Guizhen,born in 1993.Master candidate.Her main research interests include digital image processing and machine vision.<image id="241" type="formula" href="images/JFYZ201911015_24100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Tang Yiling,born in 1977.PhD candidate,lecturer.Her main research interests include digital image processing and machine vision.<image id="242" type="formula" href="images/JFYZ201911015_24200.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-10</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61662044,61163023,51765042);</span>
                                <span>the Natural Science Foundation of Jiangxi Province of China(20171BAB202017);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="58">高斯噪声(Gaussian noise, GN)和脉冲噪声(impulse noise, IN)是2种常见且在各类文献中广为讨论的参数化噪声模型,高斯噪声模型常用噪声水平值(noise level)<citation id="202" type="reference"><link href="150" rel="bibliography" /><link href="152" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>来反映图像受噪声干扰的严重程度,脉冲噪声模型则以噪声比例(noise ratio)<citation id="200" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>作为描述噪声严重程度的指标.研究者们已经针对这2种类型的噪声提出了大量行之有效的降噪算法,但这些算法多是针对图像仅受高斯<citation id="203" type="reference"><link href="156" rel="bibliography" /><link href="158" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>或者脉冲噪声<citation id="204" type="reference"><link href="160" rel="bibliography" /><link href="162" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>单一干扰情况下所设计的.在现实中,图像极易同时受高斯和脉冲噪声干扰,简单地先后利用脉冲降噪算法和高斯降噪算法对其降噪很难实现高质量降噪的目的<citation id="201" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.这是因为当图像受高斯和脉冲噪声混合干扰后,2种噪声互相影响,难以将两者完全区分开并逐一处理.</p>
                </div>
                <div class="p1">
                    <p id="59">近10年来,高斯-脉冲混合噪声降噪逐渐成为图像降噪领域的热点问题<citation id="210" type="reference"><link href="166" rel="bibliography" /><link href="168" rel="bibliography" /><link href="170" rel="bibliography" /><link href="172" rel="bibliography" /><link href="174" rel="bibliography" /><link href="176" rel="bibliography" /><link href="178" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.早期Cai等人<citation id="205" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在变分框架(variational framework)下基于<i>l</i><sub>1</sub>数据保真项(data-fidelity term)以及引入了包含图像边缘局部相似先验信息的Mumford-shah正则项对混合噪声处理.为降低实现难度,该算法首先将当前像素点的亮度值与局部窗口中值滤波器的输出值进行比较,检测并移除图像中可能被脉冲噪声破坏的像素点,然后在变分框架下对图像进行复原.Cai算法的降噪效果在很大程度上依赖于对脉冲噪声检测的精度,这意味着其降噪效果会随着图像受噪声干扰严重程度的加重而显著降低.随后,Liu等人<citation id="206" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>基于最大似然估计(maximum likelihood estimation)和稀疏表示(sparse representation)技术提出了一种通用加权<i>l</i><sub>2</sub>-<i>l</i><sub>0</sub>范数能量最小化模型(energy minimi-zation model),并利用更容易逼近求解的加权保真度(weighting data fidelity)函数解决了高斯-脉冲混合噪声的降噪问题.该算法能够在很好保持图像纹理的同时有效地去除高斯-脉冲混合噪声,但由于字典学习和稀疏编码均需要耗费大量计算资源,且当噪声水平较高时,需要多次迭代才能获得较好的降噪效果,导致该算法的执行效率比较低.近期,Jiang等人<citation id="207" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种稀疏非局部正则化的加权编码(weighted encoding with sparse nonlocal regulari-zation, WESNR)混合降噪算法.该算法没有显式的脉冲噪声检测过程,而是采用加权编码(weighted encoding)的方式隐式地统一处理高斯和脉冲噪声,通过将图像稀疏性先验和非局部相似先验信息集成到正则项中并引入到变分框架下完成图像降噪任务.稀疏表示和非局部相似技术的联合使用,使得该算法对高斯-脉冲混合噪声的降噪效果达到了比较高的水平,但执行效率仍然较低.类似地,Huang等人<citation id="208" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用自然图像所具有的非局部自相似性(nonlocal self-similarity)和低秩性(low-rank),提出了一种基于拉普拉斯尺度混合(Laplacian scale mixture, LSM)模型和非局部低秩正则化(nonlocal low-rank regularization, NLR)的LSM-NLR高斯-脉冲混合噪声降噪算法.虽然文献<citation id="211" type="reference">[<a class="sup">13</a>,<a class="sup">14</a>]</citation>中的工作考虑了图块之间的相似性,但忽略了图块之间其实也存在差异.为此,Liu等人<citation id="209" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了一个加权联合稀疏表示非局部正则化(weighted joint sparse nonlocal regularization, WJSR)模型对高斯-脉冲混合噪声建模,并采用加权正交匹配追踪(weighted simultaneous orthogonal matching pursuit, W-SOMP)贪婪算法求解高度非凸的WJSR模型全局最优解.最后,基于WJSR模型、稀疏错误(sparse errors)和全局图像先验知识定义目标函数,并通过求解这个目标函数的最优值实现高斯-脉冲混合噪声的去除.该算法的执行效率受制于图像大小和噪声严重程度.综上所述,现有的各类高斯-脉冲混合降噪算法多是在主流高斯降噪算法的基础上进行扩展,使其也可以同时处理脉冲噪声.这些混合噪声降噪算法通常基于反映各种图像先验信息的正则化项来构建目标函数,在迭代优化技术支撑下通过求解目标函数最优值的方式完成降噪任务.由于算法中字典学习、非局部估计、低秩逼近等关键模块的计算复杂度太高,导致执行时间过长.而降噪算法作为诸多图像处理任务的前置预处理模块,较长的执行时间将严重拖累图像处理系统的整体性能.因此,现有的高斯-脉冲混合噪声降噪算法在执行效率方面亟待提高.</p>
                </div>
                <div class="p1">
                    <p id="60">近年来,卷积神经网络(convolutional neural network, CNN)因其强大的学习能力在图像降噪领域<citation id="215" type="reference"><link href="156" rel="bibliography" /><link href="158" rel="bibliography" /><link href="180" rel="bibliography" /><link href="182" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>得到了大量的应用,所获得的性能指标超越了许多经典的算法.例如,Zhang等人<citation id="212" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了一个端到端的CNN卷积神经网络高斯降噪(denoising convolutional neural network, DnCNN)算法,能在给定高斯噪声水平值的情况下获得令人满意的降噪效果.基于CNN训练技术的各类降噪算法在执行效率和降噪效果2个方面(尤其是执行效率方面)具有显著的综合优势,使其有望成为解决高斯-脉冲混合噪声降噪问题的新途径,但也存在若干问题需要进一步解决.例如,虽然DnCNN降噪算法可以完成盲降噪任务,但是其降噪效果会有一定程度的下降且只能处理噪声水平值在[0,55]范围内的高斯噪声.究其原因在于:DnCNN本质上是基于训练策略(training-based approach)实现的,其降噪性能在很大程度上受制于训练降噪模型时所使用的图像与待降噪图像受噪声干扰的模式、程度是否趋于一致,两者越接近,则DnCNN算法的降噪效果越好.为训练盲降噪模型,训练图像集合中就必须涵盖各种受不同噪声水平干扰的噪声图像,这必然导致模型收敛比较困难,故盲降噪版DnCNN算法的降噪效果要比非盲降噪版的差一些.为提高基于训练的降噪算法的降噪效果,一个自然的想法就是利用某种划分机制,将训练图像集合划分为多个在噪声失真程度上大致相同的子集,并在各个图像子集上训练相适应的降噪模型.这样对于给定的待降噪图像,只要能找到一个合适的降噪模型(训练集合中图像受噪声干扰的程度与待降噪图像近似)对其进行复原处理,就能保证降噪效果.近期,文献<citation id="213" type="reference">[<a class="sup">18</a>]</citation>中提出了一种基于类感知(class-aware)的全连接卷积神经网络(fully-convolutional neural network, FCNN)降噪算法,根据图像所表达的语义内容(例如人脸、宠物、花、起居室、街道等)的不同,将训练的图像集合细分为若干个具有不同语义主题的子集并训练与之相匹配的精调模型(fine-tuning model).虽然这种实现策略确实在一定程度上提高了降噪效果,但根据图像语义内容构建图像子集的方法的普适性不强,因为自然图像内容的种类远远大于文献<citation id="214" type="reference">[<a class="sup">18</a>]</citation>中提到的那几种.另外,即便图像语义内容相同,如果训练降噪模型所用图像的噪声严重程度与待降噪图像相差比较大,仍然不能获得令人满意的降噪效果.故需要寻找一种普适性更好的划分图像训练子集的标准.</p>
                </div>
                <div class="p1">
                    <p id="61">通过对大量受不同高斯-脉冲混合噪声模式(各种不同噪声水平的高斯噪声与不同噪声比例的脉冲噪声组合)干扰图像的峰值信噪比(peak signal to noise ratio, PSNR)统计分析后发现:图像受到混合模式近似(噪声水平或者噪声比例值相近)的混合噪声干扰后,其PSNR值<i>ζ</i><sub>PSNR</sub>分布范围非常接近且分布在特定的区间范围内,受图像内容的影响不大.因此,图像的PSNR质量值可以作为衡量混合噪声类型和强度的标准,它是一种比基于图像语义内容划分模型训练图像子集更具有普适性的分类依据.为此,提出了一种基于图像质量感知的快速盲降噪算法(image quality-aware fast blind denoising algorithm, IQA-FBDA).该算法首先利用基于相对浅层的CNN卷积神经网络训练的图像质量评估模型估计给定待降噪图像的<i>ζ</i><sub>PSNR</sub>值,然后依据该值查找预先构建的混合噪声模式分类字典(mixed noise pattern classification dictionary, MNPCD)以确定其所属子类类别,最后调用预先训练好的与该类别相匹配的深层CNN降噪模型快速而高质量地完成盲降噪任务.大量的实验数据表明:所提出的IQA-FBDA算法在降噪效果上达到了当前主流混合降噪算法的同等水平,而在执行效率方面则比现有的主流高斯-脉冲混合降噪算法有显著提升,更适用于那些对执行时间有严格要求的系统.</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>1 相关工作</b></h3>
                <h4 class="anchor-tag" id="63" name="63"><b>1.1 脉冲噪声模型</b></h4>
                <div class="p1">
                    <p id="64">脉冲混合噪声模型可以定义为</p>
                </div>
                <div class="area_img" id="243">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911015_24300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="67">其中,<i>y</i><sub><i>i</i></sub>,<i>x</i><sub><i>i</i></sub>,<i>w</i><sub><i>i</i></sub>,<i>n</i><sub><i>i</i></sub>分别表示第<i>i</i>个位置的噪声像素点、原始像素点、高斯噪声和脉冲噪声;<i>Ω</i>和<i>Ω</i><sup>C</sup>分别代表受高斯噪声和脉冲噪声干扰的像素点位置集合.假定像素点亮度值的取值范围为[<i>m</i><sub>min</sub>,<i>m</i><sub>max</sub>](对于8 b的灰度图像,<i>m</i><sub>min</sub>=0,<i>m</i><sub>max</sub>=255),那么固定脉冲噪声(fixed-valued impulse noise, FVIN)的取值为<i>m</i><sub>min</sub>或者<i>m</i><sub>max</sub>,随机脉冲噪声(random-valued impulse noise, RVIN)的像素值为整个灰度空间[<i>m</i><sub>min</sub>,<i>m</i><sub>max</sub>]之间的随机值,高斯噪声服从零均值正态分布N(0,<i>σ</i><sup>2</sup>).</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>1.2 DnCNN降噪算法简介</b></h4>
                <div class="p1">
                    <p id="69">Zhang等人<citation id="216" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>通过对VGG(visual geometry group)网络模型<citation id="217" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>进行修改,设计出了一个端到端的DnCNN前馈去噪卷积神经网络模型来实现噪声图像与噪声信号的分离(即图像降噪)任务.DnCNN降噪算法将残差图像作为网络的输出,利用残差学习(residual learning)技术达到图像降噪的目的.形式上,假设共有<i>N</i>张原始无失真图像,对其中任一图像<i>x</i>添加噪声得到噪声图像<i>y</i>,将噪声图像<i>y</i>和残差图像<i>v</i>=<i>y</i>-<i>x</i>分别作为网络的输入输出对(training pairs, TP),训练DnCNN降噪模型.在降噪时,对于给定的噪声图像<i>y</i>,采用DnCNN模型得到残差图像<i>R</i>(<i>y</i>)≈<i>v</i>,降噪后的图像为<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>=</mo><mi>y</mi><mo>-</mo><mi>R</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></math></mathml>,即只要将噪声图像减去通过网络模型获得的残差图像即可得到降噪后的复原图像.CNN模型训练的目标函数为残差图像<i>v</i>与估计残差图像<i>R</i>(<i>y</i>)之间的平均均方误差</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 DnCNN网络的组成架构" src="Detail/GetImg?filename=images/JFYZ201911015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 DnCNN网络的组成架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The network architecture of DnCNN</p>

                </div>
                <div class="p1">
                    <p id="71"><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ℓ</mi><mo stretchy="false">(</mo><mi>Θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>Θ</mi><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>,(2)</p>
                </div>
                <div class="p1">
                    <p id="72">其中,<i>y</i><sub><i>i</i></sub>,<i>x</i><sub><i>i</i></sub>分别表示第<i>i</i>(<i>i</i>=1,2,…,<i>N</i>)张噪声图像及其对应的原始无失真图像,<i>Θ</i>为CNN网络参数.</p>
                </div>
                <div class="p1">
                    <p id="73">如图1所示,DnCNN网络模型框架的核心由3种不同类型的卷积层构建而成.假设网络深度为<i>d</i>,第1层采用卷积层(convolutional layer, Conv)加修正线性单元(rectified linear unit, ReLU)<citation id="218" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,即图1所示的(Conv+ReLU).其中,ReLU是作为激活函数为网络提供非线性.该层使用了64个大小为3×3×1的滤波器产生64个特征映射图;第2～(<i>d</i>-1)层在卷积层和ReLU之间加入了批归一化(batch normalization, BN)操作,即图1所示的(Conv+BN+ReLU),中间层使用64个大小为3×3的滤波器.BN操作可缓解随机梯度下降(stochastic gradient descent, SGD)训练算法产生的内部协变量转移(internal covariate shift)现象,以提高网络的训练效率<citation id="219" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>;最后1层只用了1个卷积层(Conv)输出残差图像.</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>2 IQA-FBDA算法</b></h3>
                <h4 class="anchor-tag" id="75" name="75"><b>2.1 设计思想与技术路线</b></h4>
                <div class="p1">
                    <p id="76">由引言可知,基于训练策略实现的CNN降噪算法其性能取决于模型的训练集,依据图像的<i>ζ</i><sub>PSNR</sub>值划分噪声图像子集比文献<citation id="220" type="reference">[<a class="sup">18</a>]</citation>中基于图像语义内容进行划分更具普适性.因此,提出了一种基于图像质量感知的高斯-脉冲混合噪声降噪算法.该算法流程框图如图2所示,实现过程共分为2个阶段:</p>
                </div>
                <div class="p1">
                    <p id="77">1) 训练阶段.首先在大量无失真图像上添加不同噪声水平和噪声比例的高斯-脉冲混合噪声构成噪声图像总集,基于对应的无失真图像计算各个噪声图像的<i>ζ</i><sub>PSNR</sub>值.然后将整个<i>ζ</i><sub>PSNR</sub>值的动态变化空间细分为16个子范围,记录每个子范围内图像的高斯噪声水平值和脉冲噪声比例值以构建MNPCD噪声模式分类字典.此外,利用深层DnCNN网络架构(对DnCNN网络架构进行扩展训练,使其可用于高斯-脉冲混合噪声的降噪)训练与各个子集相匹配的专用精调降噪模型.考虑到实际降噪时仅有待降噪图像本身可用(没有无失真图像作为参考图像,无法计算<i>ζ</i><sub>PSNR</sub>值),本文利用噪声图像总集及其对应的图像质量值,基于CNN卷积神经网络技术构建了1个预测能力强大的图像质量评估模型,直接基于待降噪图像本身无参考地估计它的<i>ζ</i><sub>PSNR</sub>值作为图像受混合噪声干扰严重程度的度量.</p>
                </div>
                <div class="p1">
                    <p id="78">2) 降噪阶段.对于1张给定的噪声图像,首先利用图像质量评估模型估计图像的<i>ζ</i><sub>PSNR</sub>值,然后根据该质量值查询MNPCD噪声模式分类字典即可确定待降噪图像所属图像子集的类别,从而调用预先训练好的对应类别的混合噪声降噪模型实现盲降噪任务.所获得的降噪算法在降噪效果和执行效率2方面都表现出令人满意的性能.</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 IQA-FBDA算法的流程框图" src="Detail/GetImg?filename=images/JFYZ201911015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 IQA-FBDA算法的流程框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The overall framework of IQA-FBDA</p>

                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>2.2 混合噪声模式分类字典的构建</b></h4>
                <div class="p1">
                    <p id="82">不同级别的高斯噪声(噪声水平为5～30,间隔5)和脉冲噪声(噪声比例为0.1～0.5,间隔0.05)构成了54种混合组合情况的高斯-脉冲混合噪声,分别加入到BSD数据库<citation id="221" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>中的200张原始无失真图像上构成噪声图像集合,计算每张噪声图像的<i>ζ</i><sub>PSNR</sub>值作为评价图像质量的指标.根据<i>ζ</i><sub>PSNR</sub>值某一区段内混合噪声模式出现的种类和频率相对固定的特点,将所有的组合情况分为16类(其中,将高斯噪声水平<i>σ</i>&lt;5、脉冲噪声比例<i>r</i>&lt;0.1的图像单独分为第16类,该类图像受混合噪声干扰的程度比较小),每一类别具体包括的噪声组合模式以及相应的图像质量值范围列在表1～2中.</p>
                </div>
                <div class="p1">
                    <p id="83">由表1可知:脉冲噪声比例相同时,高斯噪声水平相差10以内的图像往往划分到同一个类中,表明高斯噪声水平的变化对图像质量的影响不大,且脉冲噪声比例越大,高斯噪声对图像质量的影响越不明显;当高斯噪声水平相同时,脉冲噪声比例仅仅相差0.05却没有划分到同一类,表明脉冲噪声对图像质量的影响非常大.当高斯噪声水平与脉冲噪声比例都不相同时,图像在某些时候有可能划分到同一个类中.例如<i>σ</i>=30,<i>r</i>=0.15和<i>σ</i>=15,<i>r</i>=0.20的噪声图像都被划分为第5类.由表2可知:各类图像质量值的变化范围在1.0以内,当脉冲噪声比例较小时、图像质量值相差较大(0.6～0.9)、脉冲噪声比例较大时,图像质量值相差较小(0.3～0.5).图3给出了不同类别的噪声图像的视觉对比图,其中,图3(a)～(c)被划分第5类,图3(d)～(f)被划分为第10类.由图3可知:类别不同的图像在视觉上差异比较明显,而属于同一类的图像虽然受不同模式的混合噪声干扰,但是视觉效果差别甚微,只有通过图像的<i>ζ</i><sub>PSNR</sub>值才能发现图像受不同模式的噪声干扰后发生了细微变化.综上所述,基于表1～2可以构建MNPCD混合噪声模式分类字典,对于任意给定的某个图像质量值,直接查找该分类字典(即表1和表2)就可以判定图像所属类别,并可以知道该类别主要包括哪些混合组合模式.这样,在准备深层降噪模型所需要的训练数据时,就可以按照各个子类中的混合模式生成相应的训练数据(适当地在该类噪声水平值和噪声比例值变化范围内通过插值法生成部分训练图像),从而确保所获得的训练图像集合与待降噪图像降质程度近似.</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表1 各类噪声图像子集对应的噪声组合模式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Noise Combination Patterns Corresponding to the Classes of Noisy Images Subsets</b></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td rowspan="2"><br />Noise<br />Ratios <i>r</i></td><td colspan="6"><br />Gaussian Noise Levels <i>σ</i></td></tr><tr><td><br />5</td><td>10</td><td>15</td><td>20</td><td>25</td><td>30</td></tr><tr><td><br />0.10</td><td>1</td><td>1</td><td>2</td><td>2</td><td>3</td><td>4</td></tr><tr><td><br />0.15</td><td>3</td><td>3</td><td>3</td><td>4</td><td>4</td><td>5</td></tr><tr><td><br />0.20</td><td>4</td><td>4</td><td>5</td><td>5</td><td>6</td><td>7</td></tr><tr><td><br />0.25</td><td>6</td><td>6</td><td>6</td><td>7</td><td>8</td><td>8</td></tr><tr><td><br />0.30</td><td>8</td><td>8</td><td>8</td><td>9</td><td>9</td><td>10</td></tr><tr><td><br />0.35</td><td>9</td><td>10</td><td>10</td><td>10</td><td>11</td><td>11</td></tr><tr><td><br />0.40</td><td>11</td><td>11</td><td>11</td><td>12</td><td>12</td><td>13</td></tr><tr><td><br />0.45</td><td>13</td><td>13</td><td>13</td><td>13</td><td>14</td><td>14</td></tr><tr><td><br />0.50</td><td>14</td><td>14</td><td>14</td><td>15</td><td>15</td><td>15</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="85">
                    <p class="img_tit"><b>表2 各类噪声图像子集所对应的PSNR值范围</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 The PSNR Range of Each Noisy Image Subset</b></p>
                    <p class="img_note">dB</p>
                    <table id="85" border="1"><tr><td>Class</td><td><i>ζ</i><sub>PSNR</sub></td><td>Class</td><td><i>ζ</i><sub>PSNR</sub></td><td>Class</td><td><i>ζ</i><sub>PSNR</sub></td><td>Class</td><td><i>ζ</i><sub>PSNR</sub></td><td>Class</td><td><i>ζ</i><sub>PSNR</sub></td></tr><tr><td>1</td><td>17.8 - 18.5</td><td>4</td><td>15.3 - 16.0</td><td>7</td><td>13.9 - 14.3</td><td>10</td><td>12.75 - 13.10</td><td>13</td><td>11.8 - 12.1</td></tr><tr><td><br />2</td><td>16.9 - 17.8</td><td>5</td><td>14.7 - 15.3</td><td>8</td><td>13.4 - 13.9</td><td>11</td><td>12.40 - 12.75</td><td>14</td><td>11.5 - 11.8</td></tr><tr><td><br />3</td><td>16.0 - 16.9</td><td>6</td><td>14.3 - 14.7</td><td>9</td><td>13.1 - 13.4</td><td>12</td><td>12.10 - 12.40</td><td>15</td><td>&lt;11.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同类别的噪声图像在视觉上的对比" src="Detail/GetImg?filename=images/JFYZ201911015_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同类别的噪声图像在视觉上的对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Visual comparison of different categories of noisy images</p>

                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>2.3 图像质量评估模型</b></h4>
                <div class="p1">
                    <p id="89">考虑到执行复杂度,采用浅层的CNN卷积神经网络结构在图块级(patch level)上实现图像质量评估模型,网络结构如图4所示.为训练该模型,选取了BSD数据库<citation id="222" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>中的200张图像作为训练集,加入不同模式的混合噪声后将其分解成大小为28×28的图块,将图块及其对应的<i>ζ</i><sub>PSNR</sub>值分别作为图4所示的网络结构的输入和输出.该预测模型执行预测任务时以图块作为输入,对于1张待降噪的噪声图像,随机从图像不同位置抽取30个大小为28×28的图块输入到网络,以获得的30个图块质量值的平均值代表整张待降噪图像最终的图像质量(可有效克服欠估计和过估计对预测结果的影响,排除图像内容对预测结果的影响,且执行效率高).图块大小设置为28×28以及每张图像选取的图块个数为30个是根据多次实验结果选择出的最优值.这样,根据估计出的图像质量值对照所创建的混合噪声模式分类字典就能确定待降噪图像的所属混合噪声类别.</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于图块级的图像质量评估模型" src="Detail/GetImg?filename=images/JFYZ201911015_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于图块级的图像质量评估模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The architecture of patch-based image
 quality estimator</p>

                </div>
                <div class="p1">
                    <p id="91">为了验证图像质量评估模型的准确性和混合噪声模式分类字典的有效性,在BSD数据库<citation id="223" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>中随机选取100张图像(与训练集不重叠)分别加入5种不同组合的混合噪声(如表3所示,以这5种模式组合为例),基于预测模型并根据分类字典确定各个噪声图像的类别,通过分类正确率衡量其有效性,具体实验数据列于表3中(<i>σ</i>表示高斯噪声水平,<i>r</i>代表脉冲噪声比例).由表3可知:分类正确率都在83%以上,最佳的结果达到了97%,说明所创建的噪声模式分类字典和训练的图像质量估计模型是可靠的.</p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表3 图像质量评估模型的分类准确性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Classification Accuracy of the Image Quality Estimator</b></p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td colspan="2"><br />Gaussian-Impulse <br />Mixed Noise</td><td rowspan="2">Correct<br />Classification</td><td rowspan="2">Incorrect<br />Classification</td><td rowspan="2">Accuracy<br />Rate/%</td></tr><tr><td><br /><i>σ</i></td><td><i>r</i></td></tr><tr><td>10</td><td>0.30</td><td>83</td><td>17</td><td>83</td></tr><tr><td><br />10</td><td>0.50</td><td>95</td><td>5</td><td>95</td></tr><tr><td><br />20</td><td>0.40</td><td>85</td><td>15</td><td>85</td></tr><tr><td><br />30</td><td>0.30</td><td>83</td><td>17</td><td>83</td></tr><tr><td><br />30</td><td>0.50</td><td>97</td><td>3</td><td>97</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>2.4 深层降噪模型</b></h4>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 BSD数据库中部分代表性图像" src="Detail/GetImg?filename=images/JFYZ201911015_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 BSD数据库中部分代表性图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Some representative images in BSD database</p>

                </div>
                <div class="p1">
                    <p id="95">IQA-FBDA算法中完成混合噪声降噪功能的模型是以DnCNN算法中的深层网络结构为基础,对网络的训练数据(输入-输出)进行适当变更,使其能去除图像中的高斯-脉冲混合噪声.为了训练各个子类别对应的混合噪声降噪模型,从BSD数据库中选取200张图像构成原始图像集,对于MNPCD混合噪声模式分类字典第<i>i</i>个子类,对这些图像添加该子类包括的各种模式的高斯-脉冲混合噪声(为了获得更好的降噪效果,根据该子类噪声水平和噪声比例值变化范围用插值方法生成一定量的噪声图像作为训练数据),以滑动窗口的方式从准备好的训练集图像中提取若干个大小为40×40的图块作为网络的输入(所采用的参数均与DnCNN模型相同,训练图块个数达到240 000个),以噪声图块与对应无失真图块之间的残差映射图块作为输出.在降噪阶段,以整张噪声图像作为输入,将噪声图像减去降噪模型输出的残差图像即可直接得到复原图像.</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>2.5 降噪后再评估策略</b></h4>
                <div class="p1">
                    <p id="97">鉴于图像质量评估模型预测精度,IQA-FBDA算法在实际应用时存在少量调用相邻子类降噪模型完成降噪任务的情况,导致在某些时候不能获得最优的降噪效果.为此,提出降噪后再评估策略进一步提升IQA-FBDA算法的降噪效果.具体地,在使用图像质量评估模型得到待降噪图像的<i>ζ</i><sub>PSNR</sub>值后,调用MNPCD混合噪声模式分类字典中与[<i>ζ</i><sub>PSNR</sub>-<i>v</i>,<i>ζ</i><sub>PSNR</sub>+<i>v</i>]区段内所重叠的各个降噪模型对噪声图像进行降噪,搜索范围参数<i>v</i>=0.7.然后,通过文献<citation id="224" type="reference">[<a class="sup">1</a>]</citation>中的算法评价各个降噪模型对噪声图像的降噪效果(该算法是噪声水平评估算法,其值越小,说明降噪后的图像质量越好).最后,选择最小评估值对应的复原图像作为最终的降噪结果.虽然降噪后再评估的策略使得算法的执行时间有所增加,但是基于CNN预训练的IQA-FBDA算法的全部执行时间相比于传统的混合噪声降噪算法来说仍然是非常少的.</p>
                </div>
                <h3 id="98" name="98" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <h4 class="anchor-tag" id="99" name="99"><b>3.1 实验设置</b></h4>
                <div class="p1">
                    <p id="100">为了验证所提出IQA-FBDA算法的性能,分别在10张常用图像(被各经典文献采用,包括Lena,Boat,Barbara,House,Peppers等)、100张BSD纹理分割数据库<citation id="225" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>图像(不同于训练时所使用的图像,部分图像如图5所示)和100张自然场景图像(由文献<citation id="232" type="reference">[<a class="sup">23</a>,<a class="sup">24</a>]</citation>分别提供的90张和10张用于图像质量评价的图像构成)共3种不同图像类型的数据集上进行测试.参与对比的算法包括M-BM3D(median BM3D<citation id="226" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>),WESNR<citation id="227" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>,LSM-NLR<citation id="228" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,WJSR<citation id="229" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>共4种具有代表性的降噪算法.其中,考虑到BM3D算法不适用于处理脉冲噪声且需要以已知噪声水平值作为入口参数,本文采用与文献<citation id="230" type="reference">[<a class="sup">13</a>]</citation>类似的做法,首先利用中值滤波移除噪声图像中的脉冲噪声,然后通过文献<citation id="231" type="reference">[<a class="sup">1</a>]</citation>的工作对去除脉冲噪声后的图像进行噪声水平估计,最后以该估计值作为BM3D算法的入口参数对已滤除脉冲噪声后的图像再次降噪以去除高斯噪声,改进后的算法记为M-BM3D.降噪效果的衡量指标为PSNR.所有算法运行的硬件平台均为Intel Core<sup>TM</sup> i7-6700 3.40 GHz CPU处理器,16 GB内存.软件配置均为Windows 7操作系统,Matlab 2017b编程环境.</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>3.2 降噪效果比较</b></h4>
                <div class="p1">
                    <p id="102">首先,为了验证IQA-FBDA算法去除高斯-随机脉冲混合噪声的有效性,对10张常用图像分别添加不同水平的高斯噪声(<i>σ</i>)和不同比例的脉冲噪声(<i>r</i>)构成混合噪声图像集,比较每张噪声图像使用各个对比算法复原后图像的<i>ζ</i><sub>PSNR</sub>值.限于篇幅,表4仅列出各算法在Lena,Barbara,Peppers这3张图像上的具体实验数据,表5则给出了各个算法在不同配置下在10张图像上所获得<i>ζ</i><sub>PSNR</sub>值的平均值.从表4～5可以看出,所提出的IQA-FBDA算法的降噪效果大部分情况下排在前2名,且复原图像的<i>ζ</i><sub>PSNR</sub>值与最优值相差甚微.</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表4 各算法在单张噪声图像上的降噪效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 PSNR Performance of Different Algorithms on Lena, Barbara, and Peppers Image</b></p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td rowspan="2"><br />Images</td><td rowspan="2"><i>σ</i></td><td rowspan="2"><i>r</i></td><td rowspan="2"><i>ξ</i><sub>PSNR</sub>/dB</td><td colspan="5"><br /><i>ξ</i><sub>PSNR</sub> of Different Algorithms/dB</td></tr><tr><td><br />M-BM3D</td><td>WESNR</td><td>LSM-NLR</td><td>WJSR</td><td>IQA-FBDA</td></tr><tr><td rowspan="4"><br />Lena</td><td><br />15</td><td>0.25</td><td>14.94</td><td>29.86</td><td><b>31.15</b></td><td>30.66</td><td><b>31.14</b></td><td>30.72</td></tr><tr><td><br /></td><td>0.45</td><td>12.60</td><td>26.81</td><td><b>29.19</b></td><td>27.11</td><td>28.38</td><td><b>28.99</b></td></tr><tr><td><br />25</td><td>0.25</td><td>14.33</td><td>27.30</td><td><b>29.28</b></td><td><b>29.81</b></td><td>29.16</td><td>28.56</td></tr><tr><td><br /></td><td>0.45</td><td>12.30</td><td>24.60</td><td><b>27.33</b></td><td>27.15</td><td><b>27.38</b></td><td>27.30</td></tr><tr><td rowspan="4"><br />Barbara</td><td><br />15</td><td>0.25</td><td>14.54</td><td>24.60</td><td>25.70</td><td>25.81</td><td><b>26.80</b></td><td><b>25.94</b></td></tr><tr><td><br /></td><td>0.45</td><td>12.17</td><td>22.36</td><td>23.47</td><td>22.97</td><td><b>23.58</b></td><td><b>23.69</b></td></tr><tr><td><br />25</td><td>0.25</td><td>13.99</td><td>23.29</td><td>24.00</td><td><b>25.50</b></td><td>24.42</td><td><b>24.73</b></td></tr><tr><td><br /></td><td>0.45</td><td>11.94</td><td>21.35</td><td>22.58</td><td><b>22.83</b></td><td>22.55</td><td><b>22.82</b></td></tr><tr><td rowspan="4"><br />Peppers</td><td><br />15</td><td>0.25</td><td>14.65</td><td>30.22</td><td><b>32.98</b></td><td>31.25</td><td><b>32.48</b></td><td>32.01</td></tr><tr><td><br /></td><td>0.45</td><td>12.32</td><td>26.83</td><td><b>30.27</b></td><td>27.50</td><td>29.25</td><td><b>29.81</b></td></tr><tr><td><br />25</td><td>0.25</td><td>14.11</td><td>27.72</td><td><b>30.70</b></td><td><b>30.52</b></td><td>29.87</td><td>30.09</td></tr><tr><td><br /></td><td>0.45</td><td>12.10</td><td>24.73</td><td><b>27.95</b></td><td>27.43</td><td>27.76</td><td><b>27.95</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The top 2 results are bold.</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表5 各算法在10张常用图像上的平均降噪效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Average PSNR Performance of Each Algorithm on 10 Commonly Used Images</b></p>
                    <p class="img_note">dB</p>
                    <table id="104" border="1"><tr><td rowspan="2"><br />Algorithms</td><td colspan="3"><br /><i>σ</i>=15</td><td colspan="3"><i>σ</i>=25</td></tr><tr><td><br /><i>r</i>=0.15</td><td><i>r</i>=0.25</td><td><i>r</i>=0.45</td><td><i>r</i>=0.15</td><td><i>r</i>=0.25</td><td><i>r</i>=0.45</td></tr><tr><td><br />M-BM3D</td><td>28.27</td><td>27.22</td><td>24.59</td><td>26.26</td><td>25.32</td><td>22.96</td></tr><tr><td><br />WESNR</td><td>28.83</td><td>28.20</td><td><b>26.32</b></td><td>27.24</td><td>26.62</td><td><b>24.84</b></td></tr><tr><td><br />LSM-NLR</td><td><b>29.39</b></td><td>27.70</td><td>24.71</td><td><b>27.77</b></td><td><b>27.04</b></td><td>24.70</td></tr><tr><td><br />WJSR</td><td><b>29.37</b></td><td><b>28.39</b></td><td>25.91</td><td>27.23</td><td>26.55</td><td><b>24.82</b></td></tr><tr><td><br />IQA-FBDA</td><td>29.18</td><td><b>28.43</b></td><td><b>26.24</b></td><td><b>27.74</b></td><td><b>26.70</b></td><td>24.79</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The top 2 results are bold.</p>
                </div>
                <div class="p1">
                    <p id="105">其次,为了验证IQA-FBDA算法的鲁棒性,在100张纹理图像和100张自然图像上分别进行测试,表6和表7分别列出了各算法在这2个测试图像集上不同高斯-脉冲混合噪声下的平均降噪效果.从表6～7可以看出,IQA-FBDA算法的降噪效果在大多数情况下是最优的.特别地,图像受到混合噪声干扰的程度越大,算法的降噪性能越好.考虑到表8所列的关于执行效率的数据,总体上IQA-FBDA算法在降噪效果和执行效率2个方面的综合性能要显著优于其他对比算法.需要说明的是:1) IQA-FBDA算法属于盲降噪算法,而WESNR算法、LSM-NLR算法和WJSR算法都是非盲降噪算法,需要人工设置参数,其真实性能在实际应用中并不能达到表4～7中所列数据的水平;2)固定脉冲噪声作为随机脉冲噪声的特例,所提出的IQA-FBDA算法也适用于-固定脉冲混合噪声的去除,且同样能获得令人满意的降噪效果.限于篇幅,这里不再给出具体实验数据.</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911015_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 在Barbara图像上的降噪效果的视觉对比" src="Detail/GetImg?filename=images/JFYZ201911015_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 在Barbara图像上的降噪效果的视觉对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911015_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Visual comparison of denoising effect on Barbara image</p>

                </div>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表6 各算法在100张BSD图像上的平均降噪效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Average PSNR Performance of Each Algorithm on 100 Images from BSD Database</b></p>
                    <p class="img_note">dB</p>
                    <table id="107" border="1"><tr><td rowspan="3"><br />Algorithms</td><td colspan="5"><br />Gaussian-Impulse Mixed Noise</td></tr><tr><td colspan="2"><br /><i>σ</i>=10</td><td><i>σ</i>=20</td><td colspan="2"><i>σ</i>=30</td></tr><tr><td><br /><i>r</i>=0.30</td><td><i>r</i>=0.50</td><td><i>r</i>=0.40</td><td><i>r</i>=0.30</td><td><i>r</i>=0.50</td></tr><tr><td><br />M-BM3D</td><td>25.58</td><td>23.08</td><td>23.26</td><td>22.82</td><td>20.65</td></tr><tr><td><br />WESNR</td><td>25.91</td><td>23.83</td><td>24.10</td><td>23.75</td><td>22.08</td></tr><tr><td><br />LSM-NLR</td><td><b>27.20</b></td><td>24.29</td><td>24.68</td><td>23.78</td><td>22.75</td></tr><tr><td><br />WJSR</td><td>25.95</td><td>23.57</td><td>23.98</td><td>23.37</td><td>22.25</td></tr><tr><td><br />IQA-FBDA</td><td>26.87</td><td><b>24.55</b></td><td><b>24.68</b></td><td><b>24.23</b></td><td><b>22.90</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best values are bold.</p>
                </div>
                <div class="p1">
                    <p id="108">最后,为了从视觉上对比各个算法的降噪效果,图6给出了各算法对添加了高斯-随机脉冲混合噪声(<i>σ</i>=15,<i>r</i>=0.25)的Barbara图像的降噪效果视觉对比图.从图6中可以看出,IQA-FBDA算法的降噪效果仅次于WJSR算法(但所提出的算法具有极高的执行效率),在视觉效果上两者相差甚微,表明IQA-FBDA算法在降噪效果方面是令人满意的.</p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表7 各算法在100张自然图像上的平均降噪效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 7 Average PSNR Performance of Each Algorithm on 100 Natural Images</b></p>
                    <p class="img_note">dB</p>
                    <table id="109" border="1"><tr><td rowspan="3"><br />Algorithms</td><td colspan="5"><br />Gaussian-Impulse Mixed Noise</td></tr><tr><td colspan="2"><br /><i>σ</i>=10</td><td><i>σ</i>=20</td><td colspan="2"><i>σ</i>=30</td></tr><tr><td><br /><i>s</i>=0.30</td><td><i>s</i>=0.50</td><td><i>s</i>=0.40</td><td><i>s</i>=0.30</td><td><i>s</i>=0.50</td></tr><tr><td><br />M-BM3D</td><td>28.32</td><td>22.18</td><td>25.62</td><td>21.77</td><td>21.58</td></tr><tr><td><br />WESNR</td><td>25.82</td><td>24.84</td><td>24.74</td><td>24.49</td><td>23.27</td></tr><tr><td><br />LSM-NLR</td><td>25.77</td><td>23.29</td><td>24.63</td><td><b>24.61</b></td><td>22.84</td></tr><tr><td><br />WJSR</td><td>27.06</td><td><b>25.04</b></td><td>25.55</td><td>24.10</td><td>20.38</td></tr><tr><td><br />IQA-FBDA</td><td><b>29.12</b></td><td>24.79</td><td><b>27.42</b></td><td>22.77</td><td><b>23.57</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best values are bold.</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.3 执行时间比较</b></h4>
                <div class="p1">
                    <p id="111">执行效率直接影响到降噪算法的实用性,是评价算法性能的另一个重要指标.因此,将各个对比算法对10张大小为512×512的图像进行降噪处理,以平均执行时间作为评价算法执行效率的指标,各算法在不同高斯高斯-随机脉冲混合噪声下的执行时间列于表8中.由表8可知,IQA-FBDA算法的平均执行时间在所有参与比较的算法中具有显著优势,仅次于M-BM3D算法,但其降噪效果显著优于M-BM3D算法,故IQA-FBDA算法在降噪效果和执行效率2个方面的综合性能是所有参与比较算法中最优的.其实,表8所给出的IQA-FBDA算法实验数据是在没有使用图形处理器(graphics processing unit, GPU)硬件加速条件下获得的.若使用硬件加速技术,则执行时间能进入200 ms内,其执行效率将是最高的,可以达到实时应用标准.</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表8 各算法平均执行时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 8 Average Execution Time of Different Algorithms</b></p>
                    <p class="img_note">s</p>
                    <table id="112" border="1"><tr><td rowspan="3"><br />Algorithms</td><td colspan="5"><br />Gaussian-Impulse Mixed Noise</td></tr><tr><td colspan="2"><br /><i>σ</i>=10</td><td><i>σ</i>=20</td><td colspan="2"><i>σ</i>=30</td></tr><tr><td><br /><i>r</i>=0.30</td><td><i>r</i>=0.50</td><td><i>r</i>=0.40</td><td><i>r</i>=0.30</td><td><i>r</i>=0.50</td></tr><tr><td>M-BM3D</td><td>6.9</td><td>6.7</td><td>7.2</td><td>7.3</td><td>7.1</td></tr><tr><td><br />WESNR</td><td>118.0</td><td>114.9</td><td>147.1</td><td>177.9</td><td>180.2</td></tr><tr><td><br />LSM-NLR</td><td>569.9</td><td>395.2</td><td>312.6</td><td>152.4</td><td>148.0</td></tr><tr><td><br />WJSR</td><td>4 541.3</td><td>4 285.5</td><td>11 428.7</td><td>5 060.0</td><td>5 494.2</td></tr><tr><td><br />IQA-FBDA</td><td>17.2</td><td>21.6</td><td>18.0</td><td>18.3</td><td>11.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="113" name="113" class="anchor-tag"><b>4 总  结</b></h3>
                <div class="p1">
                    <p id="114">对于任意给定的受高斯-脉冲混合噪声干扰的图像,所提出的IQA-FBDA算法通过设计无参考PSNR值预测模型以及MNPCD混合模式分类字典,能保证自动调用与之最匹配的精调深层CNN降噪模型进行降噪,在降噪效果和执行效率2个方面可取得最佳平衡.与当前主流的高斯-脉冲混合噪声降噪算法相比,IQA-FBDA算法无需为高斯-脉冲混合噪声设计复杂的理论描述模型,也无需设计复杂的迭代求解算法对其降噪,实现复杂度更低.一旦模型训练完成,整个执行过程无需人工干预,属于盲降噪算法.此外,该算法以图像质量值作为划分训练图像子集的标准,是一种比图像语义内容更具有普适性的方法,具有更广的应用范围.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="150">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201803010&amp;v=MDU2MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTC9QTHo3QmFMRzRIOW5Nckk5RVpJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Xu Shaoping,Zeng Xiaoxia,Tang Yiling.Fast noise level estimation algorithm based on two-stage support vector regression[J].Journal of Computer-Aided Design &amp; Computer Graphics,2018,30(3):447- 458 (in Chinese)(徐少平,曾小霞,唐祎玲.基于两阶段支持向量回归的快速噪声水平估计算法[J].计算机辅助设计与图形学学报,2018,30(3):447- 458)
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201805026&amp;v=MDIxMjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTC9QSVRmU2RyRzRIOW5NcW85SFlvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Wu Jiang,You Fei,Jiang Ping.Noise variance estimation method based on regression analysis and principal component analysis[J].Journal of Electronics &amp; Information Technology,2018,40(5):1195- 1201 (in Chinese)(吴疆,尤飞,蒋平.基于回归分析和主成分分析的噪声方差估计方法[J].电子与信息学报,2018,40(5):1195- 1201)
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201404028&amp;v=MDA0NzBSc0Z5em5VTC9QSWluUlpMRzRIOVhNcTQ5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Xu Shaoping,Yang Rongchang,Liu Xiaoping.Adaptive switching median filter based on noise ratio estimation[J].Journal of Optoelectronics·Laser,2014,25(4):792- 800 (in Chinese)(徐少平,杨荣昌,刘小平.基于噪声估计的自适应开关型中值滤波器[J].光电子·激光,2014,25(4):792- 800)
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Beyond a Gaussian Denoiser:Residual Learning of Deep CNN for Image Denoising">

                                <b>[4]</b>Zhang Kai,Zuo Wangmeng,Chen Yunjin,et al.Beyond a Gaussian denoiser:Residual learning of deep CNN for image denoising[J].IEEE Transactions on Image Processing,2017,26(7):3142- 3155
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                Zhang Kai,Zuo Wangmeng,Zhang Lei.FFDNet:Toward a fast and flexible solution for CNN based image denoising[J].IEEE Transactions on Image Processing,2018,27(9):4608- 4622
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Some studies on detection and filtering algorithms for the removal of random valued impulse noise">

                                <b>[6]</b>Singh N,Thilagavathy T,Lakshmipriya R T,et al.Some studies on detection and filtering algorithms for the removal of random valued impulse noise[J].IET Image Processing,2017,11(11):953- 963
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Restoring highly corrupted images by impulse noise using radial basis functions interpolation">

                                <b>[7]</b>Taherkhani F,Jamzad M.Restoring highly corrupted images by impulse noise using radial basis functions interpolation[J].IET Image Processing,2018,12(1):20- 30
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Two-phase approach for recovering images corrupted by Gaussian-plus-impulse noise">

                                <b>[8]</b>Velayudhan D,Paul S.Two-phase approach for recovering images corrupted by Gaussian-plus-impulse noise[C] //Proc of 2016 Int Conf on Inventive Computation Technologies (ICICT).Piscataway,NJ:IEEE,2016 [2018-08-23].https://ieeexplore.ieee.org/document/7824875
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise">

                                <b>[9]</b>Cai Jianfeng,Chan R H,Nikolova M.Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise[J].Inverse Problems and Imaging,2008,2(2):187- 204
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738183&amp;v=MDk5NzRud1plWnVIeWptVUwzSUpGd1hhaFU9TmlmT2ZiSzdIdEROcVk5RlkrZ0hEWFE2b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Xiao Yu,Zeng Tieyong,Yu Jian,et al.Restoration of images corrupted by mixed Gaussian-impulse noise via l1-l0 minimization[J].Pattern Recognition,2011,44(8):1708- 1720
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting image local and nonlocal consistency for mixed Gaussian-impulse noise removal">

                                <b>[11]</b>Zhang Jian,Xiong Ruiqin,Zhao Chen,et al.Exploiting image local and nonlocal consistency for mixed Gaussian-impulse noise removal[C] //Proc of 2012 IEEE Int Conf on Multimedia and Expo.Piscataway,NJ:IEEE,2012:592- 597
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Weighted Dictionary Learning Model for Denoising Images Corrupted by Mixed Noise">

                                <b>[12]</b>Liu Jun,Tai Xuecheng,Huang Haiyang,et al.A weighted dictionary learning model for denoising images corrupted by mixed noise[J].IEEE Transactions on Image Processing,2013,22(3):1108- 1120
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mixed noise removal by weighted encoding with sparse nonlocal regularization">

                                <b>[13]</b>Jiang Jielin,Zhang Lei,Yang Jian.Mixed noise removal by weighted encoding with sparse nonlocal regularization[J].IEEE Transactions on Image Processing,2014,23(6):2651- 2662
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mixed Noise Removal via Laplacian Scale Mixture Modeling and Nonlocal Low-Rank Approximation">

                                <b>[14]</b>Huang Tao,Dong Weisheng,Xie Xuemei,et al.Mixed noise removal via Laplacian scale mixture modeling and nonlocal low-rank approximation[J].IEEE Transactions on Image Processing,2017,26(7):3171- 3186
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weighted joint sparse resentation for removing mixed noise in image">

                                <b>[15]</b>Liu Licheng,Chen Long,Chen C L P,et al.Weighted joint sparse representation for removing mixed noise in image[J].IEEE Transactions on Cybernetics,2017,47(3):600- 611
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201708007&amp;v=MTM3OTVuVUwvUEx6N0JhTEc0SDliTXA0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>Ren Jingjing,Fang Xianyong,Chen Shangwen,et al.Image deblurring based on fast convolutional neural networks[J].Journal of Computer-Aided Design &amp; Computer Graphics,2017,29(8):1444- 1456 (in Chinese)(任静静,方贤勇,陈尚文,等.基于快速卷积神经网络的图像去模糊[J].计算机辅助设计与图形学学报,2017,29(8):1444- 1456)
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image denoising method based on a deep convolution neural network">

                                <b>[17]</b>Zhang Fu,Cai Nan,Wu Jixiu,et al.Image denoising method based on a deep convolution neural network[J].IET Image Processing,2018,12(4):485- 493
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Class-aware fully convolutional Gaussian and Poisson denoising">

                                <b>[18]</b>Remez T,Litany O,Giryes R,et al.Class-aware fully convolutional Gaussian and Poisson denoising[J].IEEE Transactions on Image Processing,2018,27(11):5707- 5722
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">

                                <b>[19]</b>Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[OL].[2018-09-10].http://arxiv.org/abs/1409.1556v6
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rectified linear units improve restricted Boltzmann machines">

                                <b>[20]</b>Nair V,Hinton G E.Rectified linear units improve restricted Boltzmann machines[C] //Proc of the 27th Int Conf on Int Conf on Machine Learning.New York:ACM,2010:807- 814
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:accelerating deep network training by reducing internal covariate shift">

                                <b>[21]</b>Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Int Conf on Machine Learning.New York:ACM,2015:448- 456
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contour Detection and Hierarchical Image Segmentation">

                                <b>[22]</b>Arnelaez P,Maire M,Fowlkes C,et al.Contour detection and hierarchical image segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2011,33(5):898- 916
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Feature-Enriched Completely Blind Image Quality Evaluator">

                                <b>[23]</b>Zhang Lin,Zhang Lei,Bovik A C.A feature-enriched completely blind image quality evaluator[J].IEEE Transactions on Image Processing,2015,24(8):2579- 2591
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200063619&amp;v=MTMyODFuMHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKRndYYWhVPU5pZk9mYks4SDlQTnJZOUZaTzBNQw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Ponomarenko N,Jin L,Ieremeiev O,et al.Image database TID2013:Peculiarities,results and perspectives[J].Signal Processing:Image Communication,2015,30:57- 77
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering">

                                <b>[25]</b>Dabov K,Foi A,Katkovnik V,et al.Image denoising by sparse 3D transform-domain collaborative filtering[J].IEEE Transactions on Image Processing,2007,16(8):2080- 2095
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201911015" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911015&amp;v=MzI0OTlHRnJDVVJMT2VaZVJzRnl6blVML1BMeXZTZExHNEg5ak5ybzlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0EwWjlGcXcyQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

