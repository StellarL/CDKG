

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128625385743750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201906005%26RESULT%3d1%26SIGN%3d351rwvVXc38R%252fgOWFkQPds7ZlmY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201906005&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201906005&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201906005&amp;v=MzAwODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEbVVML0JMeXZTZExHNEg5ak1xWTlGWVlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;1 背景及动机&lt;/b&gt; "><b>1 背景及动机</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="&lt;b&gt;1.1 边缘计算&lt;/b&gt;"><b>1.1 边缘计算</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;1.2 深度学习加速器&lt;/b&gt;"><b>1.2 深度学习加速器</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;1.3 安全问题和攻击模型&lt;/b&gt;"><b>1.3 安全问题和攻击模型</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;1.4 直接加密&lt;/b&gt;"><b>1.4 直接加密</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="&lt;b&gt;2 COSA安全加速器设计&lt;/b&gt; "><b>2 COSA安全加速器设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#105" data-title="&lt;b&gt;2.1 计数器模式加密&lt;/b&gt;"><b>2.1 计数器模式加密</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;2.2 COSA安全加速器架构&lt;/b&gt;"><b>2.2 COSA安全加速器架构</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;2.3 实现细节&lt;/b&gt;"><b>2.3 实现细节</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#128" data-title="&lt;b&gt;3 性能评测&lt;/b&gt; "><b>3 性能评测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#130" data-title="&lt;b&gt;3.1 实验配置&lt;/b&gt;"><b>3.1 实验配置</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;3.2 实验结果&lt;/b&gt;"><b>3.2 实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#140" data-title="&lt;b&gt;4 相关研究工作&lt;/b&gt; "><b>4 相关研究工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="&lt;b&gt;5 总  结&lt;/b&gt; "><b>5 总  结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#96" data-title="图1 边缘设备上深度学习推理加速器架构">图1 边缘设备上深度学习推理加速器架构</a></li>
                                                <li><a href="#101" data-title="图2 一个使用直接加密的安全加速器架构">图2 一个使用直接加密的安全加速器架构</a></li>
                                                <li><a href="#108" data-title="图3 不同的加密方法">图3 不同的加密方法</a></li>
                                                <li><a href="#110" data-title="图4 COSA安全深度学习加速器硬件架构">图4 COSA安全深度学习加速器硬件架构</a></li>
                                                <li><a href="#113" data-title="图5 COSA中的并行加密操作">图5 COSA中的并行加密操作</a></li>
                                                <li><a href="#119" data-title="图6 COSA中计数器模式加密工作流程">图6 COSA中计数器模式加密工作流程</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表1 GPU硬件配置参数&lt;/b&gt;"><b>表1 GPU硬件配置参数</b></a></li>
                                                <li><a href="#138" data-title="图7 不同加密方法的加速器IPCs">图7 不同加密方法的加速器IPCs</a></li>
                                                <li><a href="#139" data-title="图8 不同cache大小的计数器cache命中率">图8 不同cache大小的计数器cache命中率</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="187">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                    LeCun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436- 444</a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_2" title="Krizhevsky A, Sutskever I, Hinton G.ImageNet classifica-tion with deep convolutional neural networks[C] //Proc of the 25th Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2012:1097- 1105" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[2]</b>
                                        Krizhevsky A, Sutskever I, Hinton G.ImageNet classifica-tion with deep convolutional neural networks[C] //Proc of the 25th Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2012:1097- 1105
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_3" title="He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[3]</b>
                                        He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_4" title="Collobert R, Weston J.A unified architecture for natural language processing:Deep neural networks with multitask learning[C] //Proc of the 25th Int Conf on Machine Learning (ICML) .New York:ACM, 2008:160- 167" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A unified architecture for natural language processing:deep neural networks with multitask learning">
                                        <b>[4]</b>
                                        Collobert R, Weston J.A unified architecture for natural language processing:Deep neural networks with multitask learning[C] //Proc of the 25th Int Conf on Machine Learning (ICML) .New York:ACM, 2008:160- 167
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_5" title="Xiong W, Droppo J, Huang Xuedong, et al.The microsoft 2016 conversational speech recognition system[C] //Proc of the 2017 IEEE Int Conf on Acoustics Speech and Signal Processing (ICASSP) .Piscataway, NJ:IEEE, 2017:5255- 5259" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The microsoft 2016 conversational speech recognition system">
                                        <b>[5]</b>
                                        Xiong W, Droppo J, Huang Xuedong, et al.The microsoft 2016 conversational speech recognition system[C] //Proc of the 2017 IEEE Int Conf on Acoustics Speech and Signal Processing (ICASSP) .Piscataway, NJ:IEEE, 2017:5255- 5259
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_6" title="Silver D, Huang A, Maddison C J, et al.Mastering the game of go with deep neural networks and tree search[J].Nature, 2016, 529 (7587) :484- 489" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mastering the game of Go with deepneural networks and tree search">
                                        <b>[6]</b>
                                        Silver D, Huang A, Maddison C J, et al.Mastering the game of go with deep neural networks and tree search[J].Nature, 2016, 529 (7587) :484- 489
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_7" title="Shi Weisong, Cao Jie, Zhang Quan, et al.Edge computing:Vision and challenges[J].IEEE Internet of Things Journal, 2016, 3 (5) :637- 646" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Edge computing:Vision and challenges">
                                        <b>[7]</b>
                                        Shi Weisong, Cao Jie, Zhang Quan, et al.Edge computing:Vision and challenges[J].IEEE Internet of Things Journal, 2016, 3 (5) :637- 646
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_8" title="Kim J, Kim H, Lakshmanan K, et al.Parallel scheduling for cyber-physical systems:Analysis and case study on a self-driving car[C] //Proc of the ACM/IEEE 4th Int Conf on Cyber-physical Systems.New York:ACM, 2013:31- 40" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallel scheduling for cyber-physical systems:Analysis and case study on a self-driving car">
                                        <b>[8]</b>
                                        Kim J, Kim H, Lakshmanan K, et al.Parallel scheduling for cyber-physical systems:Analysis and case study on a self-driving car[C] //Proc of the ACM/IEEE 4th Int Conf on Cyber-physical Systems.New York:ACM, 2013:31- 40
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_9" title="Song I, Kim H J, Jeon P B.Deep learning for real-time robust facial expression recognition on a smartphone[C] //Proc of the 2014 IEEE Int Conf on Consumer Electronics (ICCE) .Piscataway, NJ:IEEE, 2014:564- 567" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning for real-time robust facial expression recognition on a smartphone">
                                        <b>[9]</b>
                                        Song I, Kim H J, Jeon P B.Deep learning for real-time robust facial expression recognition on a smartphone[C] //Proc of the 2014 IEEE Int Conf on Consumer Electronics (ICCE) .Piscataway, NJ:IEEE, 2014:564- 567
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_10" title="Shokri R, Shmatikov V.Privacy-preserving deep learning[C] //Proc of the 22nd ACM SIGSAC Conf on Computer and Communications Security (CCS) .New York:ACM, 2015:1310- 1321" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Privacy-preserving deep learning">
                                        <b>[10]</b>
                                        Shokri R, Shmatikov V.Privacy-preserving deep learning[C] //Proc of the 22nd ACM SIGSAC Conf on Computer and Communications Security (CCS) .New York:ACM, 2015:1310- 1321
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_11" title="Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative adversarial nets[C] //Proc of the Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2014:2672- 2680" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Nets">
                                        <b>[11]</b>
                                        Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative adversarial nets[C] //Proc of the Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2014:2672- 2680
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_12" title="Zuo Pengfei, Hua Yu, Zhao Ming, et al.Improving the performance and endurance of encrypted non-volatile main memory through deduplicating writes[C] //Proc of the 2018 51st Annual IEEE/ACM Int Symp on Microarchitecture (MICRO) .Piscataway, NJ:IEEE, 2018:442- 454" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving the performance and endurance of encrypted non-volatile main memory through deduplicating writes">
                                        <b>[12]</b>
                                        Zuo Pengfei, Hua Yu, Zhao Ming, et al.Improving the performance and endurance of encrypted non-volatile main memory through deduplicating writes[C] //Proc of the 2018 51st Annual IEEE/ACM Int Symp on Microarchitecture (MICRO) .Piscataway, NJ:IEEE, 2018:442- 454
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_13" title="Zuo Pengfei, Hua Yu.SecPM:A secure and persistent memory system for non-volatile memory[C] //Proc of the 10th USENIX Workshop on Hot Topics in Storage and File Systems.Berkeley, CA:USENIX Association, 2018:1- 7" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SecPM:A secure and persistent memory system for non-volatile memory">
                                        <b>[13]</b>
                                        Zuo Pengfei, Hua Yu.SecPM:A secure and persistent memory system for non-volatile memory[C] //Proc of the 10th USENIX Workshop on Hot Topics in Storage and File Systems.Berkeley, CA:USENIX Association, 2018:1- 7
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_14" title="Navarro C A, Hitschfeld-Kahler N, Mateu L.A survey on parallel computing and its applications in data-parallel problems using GPU architectures[J].Communications in Computational Physics, 2014, 15 (2) :285- 329" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SCUD&amp;filename=SCUDA2293C7DC614DD35E9052A5D851DD289&amp;v=MTAwMTNiUTM1Tnhnekx1OHdLRT1OaTdlYXNLNkhOalAzSWd4RiswT0NBaE56Qk5tNHo5NFNnN24yQm93ZU1iZ1I3S1dDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Navarro C A, Hitschfeld-Kahler N, Mateu L.A survey on parallel computing and its applications in data-parallel problems using GPU architectures[J].Communications in Computational Physics, 2014, 15 (2) :285- 329
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_15" title="Mathew S K, Sheikh F, Kounavis M, et al.53Gbps native GF (24) 2composite-field AES-encrypt/decrypt accelerator for content-protection in 45 nm high-performance microproce-ssors[C] //Proc of the IEEE Symp on VLSI Circuits (VLSIC) .Piscataway, NJ:IEEE, 2010:169- 170" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=53Gbps native GF (24)2composite-field AES-encrypt/decrypt accelerator for content-protection in 45 nm high-performance microproce-ssors">
                                        <b>[15]</b>
                                        Mathew S K, Sheikh F, Kounavis M, et al.53Gbps native GF (24) 2composite-field AES-encrypt/decrypt accelerator for content-protection in 45 nm high-performance microproce-ssors[C] //Proc of the IEEE Symp on VLSI Circuits (VLSIC) .Piscataway, NJ:IEEE, 2010:169- 170
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_16" title="Finnegan M.Self-Driving cars will create 2 petabytes of data, what are the big data opportunities for the car industry?[OL]. (2016-12-07) [2019-02-26].http://www.computerworlduk.com/news/data/boeing-787screate-half-terabyte-of-data-per-flight-says-virgin-atlantic-3433595/" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Self-Driving cars will create 2 petabytes of data,what are the big data opportunities for the car industry?[OL]">
                                        <b>[16]</b>
                                        Finnegan M.Self-Driving cars will create 2 petabytes of data, what are the big data opportunities for the car industry?[OL]. (2016-12-07) [2019-02-26].http://www.computerworlduk.com/news/data/boeing-787screate-half-terabyte-of-data-per-flight-says-virgin-atlantic-3433595/
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_17" title="Mao Yuyi, You Changsheng, Zhang Jun, et al.A survey on mobile edge computing:The communication perspective[J].IEEE Communications Surveys &amp;amp; Tutorials, 2017, 19 (4) :2322- 2358" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Survey on Mobile Edge Computing:The Communication Perspective">
                                        <b>[17]</b>
                                        Mao Yuyi, You Changsheng, Zhang Jun, et al.A survey on mobile edge computing:The communication perspective[J].IEEE Communications Surveys &amp;amp; Tutorials, 2017, 19 (4) :2322- 2358
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_18" title="Chetlur S, Woolley C, Vandermersch P, et al.CUDNN:Efficient primitives for deep learning[J].arXiv preprint arXiv:1410.0759, 2014" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CUDNN:Efficient primitives for deep learning">
                                        <b>[18]</b>
                                        Chetlur S, Woolley C, Vandermersch P, et al.CUDNN:Efficient primitives for deep learning[J].arXiv preprint arXiv:1410.0759, 2014
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_19" title="Zhang Chen, Li Peng, Sun Guangyu, et al.Optimizing FPGA-based accelerator design for deep convolutional neural networks[C] //Proc of the 2015 ACM/SIGDA Int Symp on Field-Programmable Gate Arrays.New York:ACM, 2015:161- 170" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks">
                                        <b>[19]</b>
                                        Zhang Chen, Li Peng, Sun Guangyu, et al.Optimizing FPGA-based accelerator design for deep convolutional neural networks[C] //Proc of the 2015 ACM/SIGDA Int Symp on Field-Programmable Gate Arrays.New York:ACM, 2015:161- 170
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_20" title="Jouppi N P, Young C, Patil N, et al.In-datacenter performance analysis of a tensor processing unit[C] //Proc of the 2017 ACM/IEEE 44th Annual Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2017:1- 12" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Indatacenter performance analysis of a tensor processing unit">
                                        <b>[20]</b>
                                        Jouppi N P, Young C, Patil N, et al.In-datacenter performance analysis of a tensor processing unit[C] //Proc of the 2017 ACM/IEEE 44th Annual Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2017:1- 12
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_21" title="Chen Tishi, Du Zidong, Sun Ninghui, et al.Diannao:A small-footprint high-throughput accelerator for ubiquitous machine-learning[C] //Proc of the 19th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2014:269- 284" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DianNao:A small-footprint high-throughput accelerator for ubiquitous machine-learning">
                                        <b>[21]</b>
                                        Chen Tishi, Du Zidong, Sun Ninghui, et al.Diannao:A small-footprint high-throughput accelerator for ubiquitous machine-learning[C] //Proc of the 19th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2014:269- 284
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_22" title="Chen Y H, Krishna T, Emer J, et al.14.5 Eyeriss:An energy-efficient reconfigurable accelerator for deep convolu-tional neural networks[C] //Proc of the 2016 IEEE Int Solid-State Circuits Conf (ISSCC) .Piscataway, NJ:IEEE, 2016:262- 263" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Eyeriss:An energy-efficient reconfigurable accelerator for deep convolutional neural networks">
                                        <b>[22]</b>
                                        Chen Y H, Krishna T, Emer J, et al.14.5 Eyeriss:An energy-efficient reconfigurable accelerator for deep convolu-tional neural networks[C] //Proc of the 2016 IEEE Int Solid-State Circuits Conf (ISSCC) .Piscataway, NJ:IEEE, 2016:262- 263
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_23" title="Yan C, Englender D, Prvulovic M, et al.Improving cost, performance, and security of memory encryption and authentication[C] //Proc of the 33rd Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2006:179- 190" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving Cost, Performance, andSecurity of Memory Encryption and Authentication">
                                        <b>[23]</b>
                                        Yan C, Englender D, Prvulovic M, et al.Improving cost, performance, and security of memory encryption and authentication[C] //Proc of the 33rd Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2006:179- 190
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_24" title="Daemen J, Rijmen V.The Design of Rijndael:AES-the Advanced Encryption Standard[M].Berlin:Springer Science &amp;amp; Business Media, 2013" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Design of Rijndael:AES-the Advanced Encryption Standard">
                                        <b>[24]</b>
                                        Daemen J, Rijmen V.The Design of Rijndael:AES-the Advanced Encryption Standard[M].Berlin:Springer Science &amp;amp; Business Media, 2013
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_25" title="Lipmaa H, Rogaway P, Wagner D.CTR-mode encryption[C] //Proc of the 1st NIST Workshop on Modes of Operation.Gaithersburg, MD:NIST, 2000:1- 4" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CTR-mode encryption">
                                        <b>[25]</b>
                                        Lipmaa H, Rogaway P, Wagner D.CTR-mode encryption[C] //Proc of the 1st NIST Workshop on Modes of Operation.Gaithersburg, MD:NIST, 2000:1- 4
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_26" title="Awad A, Manadhata P, Haber S, et al.Silent shredder:Zerocost shredding for secure non-volatile main memory controllers[C] //Proc of the 21st Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2016:263- 276" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Silent shredder:Zerocost shredding for secure non-volatile main memory controllers">
                                        <b>[26]</b>
                                        Awad A, Manadhata P, Haber S, et al.Silent shredder:Zerocost shredding for secure non-volatile main memory controllers[C] //Proc of the 21st Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2016:263- 276
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_27" title="Young V, Nair P J, Qureshi M K.DEUCE:Write-efficient encryption for non-volatile memories[C] //Proc of the 20th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2015:33- 44" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DEUCE Write-efficient encryption for non-volatile memories">
                                        <b>[27]</b>
                                        Young V, Nair P J, Qureshi M K.DEUCE:Write-efficient encryption for non-volatile memories[C] //Proc of the 20th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2015:33- 44
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_28" title="Bakhoda A, Yuan G L, Fung W W, et al.Analyzing CUDA workloads using a detailed GPU simulator[C] //Proc of the 2009 IEEE Int Symp on Performance Analysis of Systems and Software.Piscataway, NJ:IEEE, 2009:163- 174" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analyzing CUDA workloads using a detailed GPU simulator">
                                        <b>[28]</b>
                                        Bakhoda A, Yuan G L, Fung W W, et al.Analyzing CUDA workloads using a detailed GPU simulator[C] //Proc of the 2009 IEEE Int Symp on Performance Analysis of Systems and Software.Piscataway, NJ:IEEE, 2009:163- 174
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_29" title="Nvidia Corporation.Nvidia CUDA C programming guide[J].Nvidia Corporation, 2011, 120 (18) :1- 175" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nvidia CUDA C programming guide">
                                        <b>[29]</b>
                                        Nvidia Corporation.Nvidia CUDA C programming guide[J].Nvidia Corporation, 2011, 120 (18) :1- 175
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_30" title="Stone J E, Gohara D, Shi G.OpenCL:A parallel programming standard for heterogeneous computing systems[J].Computing in Science &amp;amp; Engineering, 2010, 12 (3) :66- 73" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OpenCL: A parallel programming standard for heterogeneous computing systems">
                                        <b>[30]</b>
                                        Stone J E, Gohara D, Shi G.OpenCL:A parallel programming standard for heterogeneous computing systems[J].Computing in Science &amp;amp; Engineering, 2010, 12 (3) :66- 73
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_31" title="Liu Sihang, Kolli A, Ren Jinglei, et al.Crash consistency in encrypted non-volatile main memory systems[C] //Proc of the 2018 IEEE Int Symp on High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2018:310- 323" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Crash consistency in encrypted non-volatile main memory systems">
                                        <b>[31]</b>
                                        Liu Sihang, Kolli A, Ren Jinglei, et al.Crash consistency in encrypted non-volatile main memory systems[C] //Proc of the 2018 IEEE Int Symp on High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2018:310- 323
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_32" title="Tram&#232;r F, Zhang F, Juels A, et al.Stealing machine learning models via prediction apis[C] //Proc of the 25th USENIX Security Symp.Berkeley, CA:USENIX Association, 2016:601- 618" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stealing machine learning models via prediction APIs">
                                        <b>[32]</b>
                                        Tram&#232;r F, Zhang F, Juels A, et al.Stealing machine learning models via prediction apis[C] //Proc of the 25th USENIX Security Symp.Berkeley, CA:USENIX Association, 2016:601- 618
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_33" title="Oh S J, Augustin M, Schiele B, et al.Towards reverse-engineering black-box neural networks[J].arXiv preprint arXiv:1711.01768, 2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards reverse-engineering black-box neural networks">
                                        <b>[33]</b>
                                        Oh S J, Augustin M, Schiele B, et al.Towards reverse-engineering black-box neural networks[J].arXiv preprint arXiv:1711.01768, 2017
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_34" title="Wang Binghui, Gong N Z.Stealing hyperparameters in machine learning[C] //Proc of the 2018 IEEE Symp on Security and Privacy (SP) .Piscataway, NJ:IEEE, 2018:36- 52" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stealing hyperparameters in machine learning">
                                        <b>[34]</b>
                                        Wang Binghui, Gong N Z.Stealing hyperparameters in machine learning[C] //Proc of the 2018 IEEE Symp on Security and Privacy (SP) .Piscataway, NJ:IEEE, 2018:36- 52
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_35" title="Naghibijouybari H, Neupane A, Qian Zhiyun, et al.Rendered insecure:GPU side channel attacks are practical[C] //Proc of the 2018 ACM SIGSAC Conf on Computer and Communications Security.New York:ACM, 2018:2139- 2153" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rendered insecure:GPU side channel attacks are practical">
                                        <b>[35]</b>
                                        Naghibijouybari H, Neupane A, Qian Zhiyun, et al.Rendered insecure:GPU side channel attacks are practical[C] //Proc of the 2018 ACM SIGSAC Conf on Computer and Communications Security.New York:ACM, 2018:2139- 2153
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_36" title="Hua Weizhi, Zhang Zhiru, Suh G E.Reverse engineering convolutional neural networks through side-channel information leaks[C] //Proc of the 2018 55th ACM/ESDA/IEEE Design Automation Conf (DAC) .Piscataway, NJ:IEEE, 2018:No.4" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reverse engineering convolutional neural networks through side-channel information leaks">
                                        <b>[36]</b>
                                        Hua Weizhi, Zhang Zhiru, Suh G E.Reverse engineering convolutional neural networks through side-channel information leaks[C] //Proc of the 2018 55th ACM/ESDA/IEEE Design Automation Conf (DAC) .Piscataway, NJ:IEEE, 2018:No.4
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(06),1161-1169 DOI:10.7544/issn1000-1239.2019.20190109            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向深度学习加速器的安全加密方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B7%A6%E9%B9%8F%E9%A3%9E&amp;code=33078178&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">左鹏飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%8E%E5%AE%87&amp;code=29635181&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华宇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E6%96%B0%E9%94%8B&amp;code=42095396&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢新锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E6%9D%8F&amp;code=42095397&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡杏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E6%BA%90&amp;code=41249902&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢源</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%AF%E4%B8%B9&amp;code=07589486&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冯丹</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%85%89%E7%94%B5%E5%9B%BD%E5%AE%B6%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83(%E5%8D%8E%E4%B8%AD%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6)&amp;code=0045381&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉光电国家研究中心(华中科技大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%AD%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0045381&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华中科技大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8A%A0%E5%B7%9E%E5%A4%A7%E5%AD%A6%E5%9C%A3%E8%8A%AD%E8%8A%AD%E6%8B%89%E5%88%86%E6%A0%A1&amp;code=1701674&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加州大学圣芭芭拉分校</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着机器学习特别是深度学习技术的飞速发展, 其应用场景也越来越广, 并逐渐从云计算向边缘计算上扩展.在深度学习中, 深度学习模型作为模型提供商的知识产权是非常重要的数据.发现部署在边缘计算设备上的深度学习加速器有泄露在其上存储的深度学习模型的风险.攻击者通过监听深度学习加速器和设备内存之间的总线就能很容易地截获到深度学习模型数据, 所以加密该内存总线上的数据传输是非常重要的.但是, 直接地在加速器上使用内存加密会极大地降低加速器的性能.为了解决这个问题, 提出了一个有效的安全深度学习加速器架构称作COSA.COSA通过利用计数器模式加密不仅提高了加速器的安全性, 而且能够把解密操作从内存访问的关键路径中移走来极大地提高加速器性能.在GPGPU-Sim上实现了提出的COSA架构, 并使用神经网络负载测试了其性能.实验结果显示COSA相对于直接加密的架构提升了3倍以上的性能, 相对于一个不加密的加速器性能只下降了13%左右.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9F%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%B9%E7%BC%98%E8%AE%BE%E5%A4%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">边缘设备;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%89%E5%85%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">安全;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%80%BB%E7%BA%BF%E7%9B%91%E5%90%AC%E6%94%BB%E5%87%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">总线监听攻击;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    左鹏飞, pfzuo@hust.edu.cn, born in 1992.PhD candidate.Student member of CCF. His main research interests include memory system and architecture, storage system, security and deep learning.;
                                </span>
                                <span>
                                    *华宇, csyhua@hust.edu.cn, born in 1978.PhD, professor, PhD supervisor.Distinguished member of CCF, senior member of ACM and IEEE.His main research interests include cloud storage systems, non-volatile memory, big data analytics, artificial intelligence hardware and software infrastructure, etc.;
                                </span>
                                <span>
                                    Xie Xinfeng, born in 1995.PhD candidate.His main research interests include computer architecture, programming language, and heterogeneous system.;
                                </span>
                                <span>
                                    Hu Xing, born in 1988.PhD.Her mainresearch interests include emerging memory systems, neural network acceleration and security.;
                                </span>
                                <span>
                                    Xie Yuan, born in 1973.PhD, professor, PhD supervisor.IEEE Fellow.His main research interests include VLSI design, electronic design automation, computer architecture, and embedded systems design.;
                                </span>
                                <span>
                                    Feng Dan, born in 1970.PhD, professor, PhD supervisor.Distinguished member of CCF.Her main research interests include computer architecture, massive storage systems, and parallel file systems.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61772212, 61821003);</span>
                    </p>
            </div>
                    <h1><b>A Secure Encryption Scheme for Deep Learning Accelerators</b></h1>
                    <h2>
                    <span>Zuo Pengfei</span>
                    <span>Hua Yu</span>
                    <span>Xie Xinfeng</span>
                    <span>Hu Xing</span>
                    <span>Xie Yuan</span>
                    <span>Feng Dan</span>
            </h2>
                    <h2>
                    <span>Wuhan National Laboratory for Optoelectronics (Huazhong University of Science and Technology)</span>
                    <span>School of Computer, Huazhong University of Science and Technology</span>
                    <span>University of California at Santa Barbara</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the rapid development of machine learning techniques, especially deep learning (DL) , their application domains are wider and wider and increasingly expanded from cloud computing to edge computing. In deep learning, DL models as the intellectual property (IP) of model providers become important data. We observe that DL accelerators deployed on edge devices for edge computing have the risk of leaking DL models stored on them. Attackers are able to easily obtain the DL model data by snooping the memory bus connecting the on-chip accelerator and off-chip device memory. Therefore, encrypting data transmitted on the memory bus is non-trivial. However, directly using memory encryption in DL accelerators significantly decreases their performance. To address this problem, this paper proposes COSA, a COunter mode Secure deep learning Accelerator architecture. COSA achieves higher security level than direct encryption and removes decryption operations from the critical path of memory accesses by leveraging counter mode encryption. We have implemented COSA in GPGPU-Sim and evaluated it using the neural network workload. Experimental results show COSA improves the performance of the secure accelerator by over 3 times compared with direct encryption and causes only 13% performance decrease compared with an insecure accelerator without using encryption.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=accelerator&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">accelerator;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=edge%20device&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">edge device;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=security&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">security;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=bus%20snooping%20attack&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">bus snooping attack;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-01</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61772212, 61821003);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="81">在过去的10年里, 机器学习和边缘计算是2个被广泛关注的领域.一方面, 机器学习特别是深度学习技术<citation id="259" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>最近取得了巨大的突破, 在图片识别<citation id="264" type="reference"><link href="189" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、语音识别<citation id="265" type="reference"><link href="193" rel="bibliography" /><link href="195" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、游戏<citation id="260" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等领域实现了比人类更高的准确率和效率.另一方面, 随着边缘设备计算能力和存储容量的不断提升, 和不需要向云端远程传输数据等优势, 边缘计算<citation id="261" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>也非常受欢迎.因此, 越来越多的应用和产品开始探索和结合机器学习和边缘计算两者的优势, 最典型的应用是无人驾驶汽车<citation id="262" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和智能手机<citation id="263" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>.通过在其上部署深度学习加速器, 无人驾驶汽车可以进行本地计算来实时地对当前路况做出反应, 而不用连接到高延迟的远程控制中心.</p>
                </div>
                <div class="p1">
                    <p id="82">在深度学习中, 深度学习模型是其核心, 被认为是需要重点保护的机密信息<citation id="266" type="reference"><link href="205" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>.这是因为深度学习模型是由模型提供商花费大量财力训练出来的, 是他们知识产权的重要组成部分和他们业务的核心竞争力来源.另外, 深度学习模型通常是使用用户的隐私数据训练出来的, 深度学习模型的泄露还会披露训练数据的相关隐私信息.更重要的是, 当恶意的敌手获取到深度学习模型后, 他可以有针对性地实施对该深度学习应用的对抗攻击<citation id="267" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="83">然而我们发现相对于云计算, 边缘计算上的机器学习系统产生了新的安全问题.这是因为边缘计算设备上的机器学习系统更容易地被物理访问.因此, 边缘设备上的机器学习系统会受到基于物理访问的攻击, 例如总线监听攻击 (bus snooping attack) <citation id="271" type="reference"><link href="209" rel="bibliography" /><link href="211" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>.攻击者通过监听深度学习加速器和内存之间总线上传输的数据, 就很容易地获取到该机器学习系统中的深度学习模型.所以加密深度学习加速器的内存总线中传输的数据非常重要.一种直接的方法是, 在深度学习加速器的片上加入加密 (如AES) 逻辑电路<citation id="268" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.当加速器需要写数据到内存中时, 先加密该数据再将密文写入;当加速器需要从内存中读数据时, 先读密文数据到片上再解密.然而, 这种直接加密的方法极大地降低了深度学习加速器的性能.主要是因为深度学习加速器 (如GPU) 通过高并发来获得高的性能, 其性能对内存访问吞吐量极其敏感.内存总线的吞吐量在160 GBps左右<citation id="269" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 但目前最好的硬件实现的加密电路吞吐量只有10 GBps左右<citation id="270" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 从而大大限制了数据访问的吞吐量和降低了加速器性能.</p>
                </div>
                <div class="p1">
                    <p id="84">为了解决这个问题, 本文提出一个高效的安全机器学习加速器架构COSA, 其利用计数器模式加密把解密操作从内存访问的关键路径中移走.具体地, 当加速器在内存中读取密文数据的同时, COSA使用一个秘钥、内存行地址和该行的计数器通过AES电路计算出一个临时数据.当密文数据从内存中读取出来后, COSA把密文数据和这个临时数据进行异或操作就解密出了明文数据.可见.加密操作和内存读操作并行地执行了, 只有一个异或操作在内存访问的关键路径上, 大大提升了加速器性能.本文的主要贡献包括3方面:</p>
                </div>
                <div class="p1">
                    <p id="85">1) 发现了边缘设备上深度学习加速器易受基于物理访问攻击的安全问题, 并分析了加密对加速器性能的影响.</p>
                </div>
                <div class="p1">
                    <p id="86">2) 提出了一个高效的安全深度学习加速器架构COSA, 通过把解密操作从内存访问的关键路径中移走来提升加速器性能.</p>
                </div>
                <div class="p1">
                    <p id="87">3) 在GPGPU-Sim上实现了提出的COSA架构, 并使用公开的神经网络负载进行测试, 验证了本文提出方法的有效性.</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>1 背景及动机</b></h3>
                <div class="p1">
                    <p id="89">本节首先介绍深度学习加速器的相关背景, 然后介绍边缘设备上深度学习加速器的安全性问题, 最后讨论一个保证深度学习加速器安全性的直接加密方法.</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>1.1 边缘计算</b></h4>
                <div class="p1">
                    <p id="91">由于位于网络边缘的设备上产生的数据越来越多, 数据的传输速度成为了云计算模式的瓶颈.巨大的带宽开销和高的响应延时极大地降低了云计算的效率.例如一辆自动驾驶汽车每秒产生的数据高达1 GB<citation id="272" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 其很难通过云计算来处理数据做实时的决策.为了解决这个问题, 边缘计算的概念被提出<citation id="273" type="reference"><link href="199" rel="bibliography" /><link href="219" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">17</a>]</sup></citation>.边缘计算利用边缘设备上的硬件资源来直接在本地进行计算, 这将大大减少了数据处理延时和边缘设备的能耗开销.</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>1.2 深度学习加速器</b></h4>
                <div class="p1">
                    <p id="93">深度学习技术在许多领域得到了广泛地应用, 如图片识别、语音识别、自然语言处理、游戏等, 甚至可以实现比人类更高的准确率和效率.但是, 深度学习的高效性依赖于极大的计算开销.深度学习加速器的出现提高了边缘设备的算力, 使得深度学习在边缘计算中的使用成为了可能.</p>
                </div>
                <div class="p1">
                    <p id="94">GPU是一种最常用的神经网络加速器<citation id="274" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 由于其强大的并行处理能力非常适用于神经网络中的大量矩阵/向量乘运算和浮点运算.FPGA也常被用作神经网络加速器<citation id="275" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 由于其可编程的特性可支持灵活地设计新的硬件结构来匹配神经网络算法.另外还有一些专用的深度学习加速器产品, 如Google的TPU<citation id="276" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、寒武纪的Diannao<citation id="277" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、麻省理工学院 (MIT) 提出的Eyeriss<citation id="278" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>等.</p>
                </div>
                <div class="p1">
                    <p id="95">大部分神经网络推理加速器都可以抽象为如图1所示的硬件架构.加速器片上会集成很多支持高并发计算的处理单元 (processing element, PE) , 一块cache用来存储最近经常被访问的热数据.由于cache的容量很小, 其不能存储全部的深度学习模型.整个的深度学习模型会存储在片外的大容量DRAM内存中, 加速器需要通过GDDR总线连接片外的DRAM.GDDR总线是一种针对GPU等加速器专门设计的总线, 其具有比传统CPU的DDR总线更高的带宽, 从而可以支持更高的内存访问吞吐量.</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 边缘设备上深度学习推理加速器架构" src="Detail/GetImg?filename=images/JFYZ201906005_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 边缘设备上深度学习推理加速器架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The architecture of the deep learning inference accelerator on edge devices</p>

                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>1.3 安全问题和攻击模型</b></h4>
                <div class="p1">
                    <p id="98">在深度学习中, 深度学习模型作为模型提供商的知识产权是非常重要的数据.我们发现部署在边缘计算设备上的深度学习加速器有泄露其上存储的深度学习模型的风险.与云计算不同, 边缘计算中的设备 (如无人驾驶汽车) 很容易被物理地访问.所以, 边缘设备上的深度学习加速器就很容易受到基于物理访问攻击, 如总线监听攻击<citation id="279" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.如图1所示, 攻击者可以在GDDR内存总线上安装一个探听器, 来截获片外内存与片上加速器之间传输的数据, 进而获取到整个深度学习模型.另外, 本文不考虑总线篡改攻击, 其可以通过完整性校验技术抵御<citation id="280" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 与本文的研究工作是正交的.</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>1.4 直接加密</b></h4>
                <div class="p1">
                    <p id="100">加密深度学习加速器的内存总线中传输的数据非常重要.如图2所示, 一种直接的方法是, 在深度学习加速器片上的内存控制器中加入加密逻辑电路, 如高级加密标准 (advanced encryption standard, AES) <citation id="281" type="reference"><link href="233" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>逻辑电路.当内存控制器需要将一个内存行写回到片外DRAM内存中时, 先将该内存行的数据加密再将密文写入;当加速器需要从内存中读数据时, 先读密文数据到片上再解密出明文.</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 一个使用直接加密的安全加速器架构" src="Detail/GetImg?filename=images/JFYZ201906005_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 一个使用直接加密的安全加速器架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 A secure accelerator architecture using direct  encryption</p>

                </div>
                <div class="p1">
                    <p id="102">在这种直接加密 (direct encryption) 的架构中, 每次内存读写都需要通过AES做加密或解密, 并且加解密操作是在内存访问的关键路径上.然而, 目前最好的硬件实现的加密电路吞吐量在10 GBps左右<citation id="282" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 其远低于内存总线的吞吐量 (160 GBps左右<citation id="283" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>) .使得大量的读写请求在等待AES电路来做加解密, 大大增加了计算单元的等待周期从而降低了加速器的性能, 如3.2节的实验评估所示.</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag"><b>2 COSA安全加速器设计</b></h3>
                <div class="p1">
                    <p id="104">本文提出一个高效的安全深度学习加速器架构 (COunter mode Secure Accelerator for deep learning, COSA) , 其利用计数器模式加密 (counter mode encryption) <citation id="284" type="reference"><link href="231" rel="bibliography" /><link href="235" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">25</a>]</sup></citation>, 把解密操作从内存访问的关键路径中移走来极大地提高安全加速器的性能, 并且可以实现更高的安全性.本节首先介绍计数器模式加密方法, 接着介绍如何在安全的深度学习加速器中有效地使用计数器模式加密, 最后介绍COSA的实现细节.</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>2.1 计数器模式加密</b></h4>
                <div class="p1">
                    <p id="106">加密内存行的一种简单的方法是用一个全局的秘钥 (key) 加密所有的内存行, 如图3 (a) 所示.但是, 相同的内存行使用相同的秘钥总是生成相同的密文, 那么攻击者简单地对比密文数据就可以知道哪些内存行的明文数据是一样的.因此, 这种加密方法很容易受到字典攻击 (dictionary attacks) 和重播攻击 (retry attacks) <citation id="285" type="reference"><link href="237" rel="bibliography" /><link href="239" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">27</a>]</sup></citation>.一种改进的方法是, 使用一个全局秘钥联合该内存行的地址 (line addr) 来加密该内存行的数据, 如图3 (b) 所示.那么, 位于不同内存行地址的相同数据会被加密成不同的密文, 可以避免不同内存行之间的字典攻击和重播攻击.但是, 在相同行地址先后写入的相同数据的密文却是相同的.因此, 这种加密方法会有对同一行地址的字典攻击和重播攻击的风险.</p>
                </div>
                <div class="p1">
                    <p id="107">一种更安全的方法是计数器模式加密<citation id="286" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>, 其给每个内存行分配一个计数器 (counter) , 并使用一个全局的秘钥、该内存行的地址和该内存行的计数器加密该内存行的数据, 如图3 (c) 所示.对于每次写, 该内存行的计数器加一.那么, 即使在相同行地址先后写入相同的明文数据, 其产生的密文也是不同的, 从而实现了高的安全性.</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同的加密方法" src="Detail/GetImg?filename=images/JFYZ201906005_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同的加密方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Different encryption methods</p>

                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>2.2 COSA安全加速器架构</b></h4>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 COSA安全深度学习加速器硬件架构" src="Detail/GetImg?filename=images/JFYZ201906005_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 COSA安全深度学习加速器硬件架构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The COSA hardware architecture</p>

                </div>
                <div class="p1">
                    <p id="111">通过使用计数器模式加密, 本文提出了一种高效的安全深度学习加速器架构COSA, 如图4所示.COSA在片外内存中分配了一块空间用来存储所有内存行对应的计数器值, 并在加速器片上增加了一个计数器cache (counter cache) 来存储最近经常被访问的内存行的计数器值.COSA并不是用AES电路逻辑直接对内存行的数据进行加解密, 而是使用一个全局秘钥、内存行地址和内存行计数器通过AES电路逻辑计算出一个一次性的填充数据 (one-time pad, OTP) .该填充数据和内存行的密文数据进行简单的异或操作就生成了明文数据;同样地, 该填充数据和内存行的明文数据进行异或操作就生成了密文数据<citation id="287" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="112">这样做的好处是可以并行地执行AES计算和数据读操作.具体地, 当一个读请求到DRAM内存中取数据的同时, COSA使用该内存行的地址、计数器值和全局秘钥通过AES电路逻辑计算出一个一次性填充数据 (OTP) .等密文内存行被读取到片上时, COSA直接将该填充数据 (OTP) 和密文内存行异或就解密出了明文数据.可见, AES计算步骤被成功地从读操作的关键路径上移走, 只有异或操作的延迟被加在了读操作的关键路径上, 如图5所示:</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 COSA中的并行加密操作" src="Detail/GetImg?filename=images/JFYZ201906005_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 COSA中的并行加密操作  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_113.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The parallel encryption in COSA</p>

                </div>
                <div class="p1">
                    <p id="114">需要注意的是, 只有当读请求将要访问的内存行所对应的计数器缓存在片上计数器cache中时, AES计算才能和DRAM内存中的读操作并行执行.如果其所对应的计数器没有缓存在计数器cache中, COSA必须到内存中先读取计数器来形成OTP, 再异或数据密文来解密.这样的话, AES计算延迟依然在读请求的关键路径上.</p>
                </div>
                <div class="p1">
                    <p id="115">为了解决这个问题, COSA增强DRAM内存中计数器存储的空间局部性并通过预取来提高计数器cache的命中率.具体地, 每个内存行对应的计数器是个8 B的值, 而加速器 (如GPU) 的内存行大小通常是128 B.COSA把连续的16个物理地址所对应内存行的计数器存储在一个128 B的内存行中.那么, 当一个计数器被访问时, 连续的16个内存行的计数器会在一次内存访问中被预取到计数器cache中.接下来如果有对剩余15个计数器的访问, 都会命中cache, 从而提升了计时器cache的命中率.</p>
                </div>
                <div class="p1">
                    <p id="116">由于每个128 B的内存行需要8 B的计数器, COSA只需要6.25% (=8 B/128 B) 的内存空间来存储全部的计数器.</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117"><b>2.3 实现细节</b></h4>
                <div class="p1">
                    <p id="118">本节介绍安全深度学习加速器COSA的实现细节, 如图6所示. 位于片上的加速器会对片外的DRAM内存发送读写操作请求, 这些读写请求都会先放入如图6中下半部分所示的L2到DRAM队列 (L2→DRAM Queue) 中.另一方面, 片外的DRAM内存会返回读请求的数据到片上加速器 (图6中的上半部分所示) .</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_119.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 COSA中计数器模式加密工作流程" src="Detail/GetImg?filename=images/JFYZ201906005_119.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 COSA中计数器模式加密工作流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_119.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 The workflow of counter mode encryption in COSA</p>

                </div>
                <div class="p1">
                    <p id="120">首先介绍片上加速器向片外内存发送请求的流程.发送的请求包括读 (R) 和写 (W) 两种请求, 不管是读请求还是写请求都需要先查询计数器cache.这是因为写请求需要获取对应的计数器值来加密写入的数据, 读请求需要获取对应的计数器值来并行地执行AES计算作解密.根据请求的类型和计数器cache是否命中, COSA需要分别处理4种情况:</p>
                </div>
                <div class="p1">
                    <p id="121">1) 写请求+cache不命中 (W+Miss) .当一个内存写请求对应的计数器值不在计数器cache中时, COSA生成一个对该计数器值的读请求到片外内存, 并把该写请求加到解密等待缓存 (encryption waiting buffer) 中.如果解密等待缓存已满的话, 该写请求会等待, 直到解密等待缓存非满时再被加入.</p>
                </div>
                <div class="p1">
                    <p id="122">2) 写请求+cache命中 (W+Hit) .当一个内存写请求对应的计数器值在计数器cache中时, COSA使用该计数器通过AES计算出一个OTP来加密该写请求, 然后把该写请求发送到片外内存.</p>
                </div>
                <div class="p1">
                    <p id="123">3) 读请求+cache不命中 (R+Miss) .当一个读请求对应的计数器值不在计数器cache中时, COSA生成一个对该计数器值的读请求到片外内存, 然后继续把该读请求发送到片外内存.</p>
                </div>
                <div class="p1">
                    <p id="124">4) 读请求+cache命中 (R+Hit) .当一个读请求对应的计数器在计数器cache中时, COSA把该读请求发送到片外内存, 同时, 使用它的计数器通过AES计算出一个OTP, 并把该OTP放到OTP缓存中.</p>
                </div>
                <div class="p1">
                    <p id="125">再介绍COSA处理片外内存返回到片上的读请求的流程.返回的读请求可能是数据行或计数器行, 所以分为2种情况:</p>
                </div>
                <div class="p1">
                    <p id="126">1) 数据行 (data) .当读请求返回的是数据行时, COSA首先查询OTP缓存中是否有其对应的OTP.如果有, 则直接解密该数据行, 并删除OTP缓存中对应的该数据的OTP;如果没有, 继续查询计数器cache中是否存在其对应的计数器.如果计数器cache命中, 则解密该数据行;如果cache不命中, COSA将该数据行放入解密等待缓存 (decryption waiting buffer) 中.</p>
                </div>
                <div class="p1">
                    <p id="127">2) 计数器行 (counter) .当读请求返回的是计数器行时, COSA先查询解密等待队列中是否有其对应的数据行.如果有, 则解密该数据行并将解密后的数据发送到DRAM→L2队列.COSA继续查询加密等待队列中是否有其对应的数据行.如果有, 则加密该数据行, 并将该被加密的数据行写入到内存.最后, COSA将该计数器写入到计数器cache中.</p>
                </div>
                <h3 id="128" name="128" class="anchor-tag"><b>3 性能评测</b></h3>
                <div class="p1">
                    <p id="129">为了不失一般性, 本文使用GPU一种最常用的深度学习加速器来实现提出的COSA方案.然而, 本文提出的安全加密方法COSA实现在深度学习加速器的内存控制器中, 从而也适用于其他的深度学习加速器, 如基于FPGA和ASIC的加速器.</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>3.1 实验配置</b></h4>
                <div class="p1">
                    <p id="131">1) GPU配置.通过使用GPGPU-Sim<citation id="288" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>, 实现了本文提出的安全深度学习加速器方案COSA.GPGPU-Sim是一个被广泛使用的周期级的商用GPU性能模拟器, 其可以支持运行CUDA<citation id="289" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>和OpenCL<citation id="290" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>程序.在测试中, 使用GPGPU-Sim模拟的GPU的配置如表1所示.在GPU中的每个内存控制器中加入了一个16阶流水线的AES电路, 其加密块大小是128 bit, 对一个内存行 (128 B) 的加解密延迟是40 cycles<citation id="291" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>.COSA中encryption waiting buffer, decryption waiting buffer和OTP buffer的大小都为16.</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表1 GPU硬件配置参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Configuration Parameters of the Simulated GPU</b></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />Configuration Items</td><td>Configuration Parameters</td></tr><tr><td><br />Number of Shader Cores</td><td>28</td></tr><tr><td><br />Warp Size</td><td>32 threads</td></tr><tr><td><br />SIMD Pipeline Width</td><td>8</td></tr><tr><td><br />Number of Threads per Core</td><td>1 024</td></tr><tr><td><br />Number of CTAs per Core</td><td>8</td></tr><tr><td><br />Number of Registers per Core</td><td>16 384</td></tr><tr><td><br />Shared Memory per Core</td><td>16 KB</td></tr><tr><td><br />Constant Cache Size per Core</td><td>8 KB</td></tr><tr><td><br />Texture Cache Size per Core</td><td>64 KB</td></tr><tr><td><br />L1 Cache</td><td>16 KB</td></tr><tr><td><br />L2 Cache</td><td>128 KB×6</td></tr><tr><td><br />GDDR3 Memory Timing <br /> (cycle) </td><td>CCD=2, RRD=8, RCD=12, <br />RAS=25, RP=10, RC=35, <br />CL=10, WL=7, CDLR=6, <br />WR=11</td></tr><tr><td><br />Bandwidth per Memory Module</td><td>8 Byte/cycle</td></tr><tr><td><br />DRAM Request Queue Capacity</td><td>32 requests</td></tr><tr><td><br />Memory Controller</td><td>×6, FRFCFS</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">2) 数据集.使用SPASS2009-Benchmarks<citation id="292" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>中的神经网络负载 (neural network, NN) 来评估COSA的性能.该NN负载使用卷积神经网络 (convolutional neural network) 来识别手写数字.已经训练好的神经网络权重数据和待识别的手写数字输入已经预先放在片外DRAM内存中.该NN负载允许同时识别多个手写数字来提高并行性, 总共识别来自美国国家标准技术局 (National Institute of Standards Technology, NIST) 数据库的28个手写数字.</p>
                </div>
                <div class="p1">
                    <p id="134">3) 实验对比.实验对比了一个没安全保证的神经网络加速器 (Un-encr) , 和一个如1.3节描述的采用直接加密 (direct encryption) 的神经网络加速器.</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135"><b>3.2 实验结果</b></h4>
                <div class="p1">
                    <p id="136">实验测试了不同架构的深度学习加速器的每周期执行指令数 (instructions per cycle, IPC) , 如图7所示.由于本文提出的安全深度学习加速器COSA的片上部署了一个计数器cache, 不同的计数器cache大小会影响其性能.所以实验也评估了COSA在不同计数器cache大小情况下的性能.</p>
                </div>
                <div class="p1">
                    <p id="137">从实验结果中发现, 相对于一个没有加密的加速器 (Un-encryption) , 使用直接加密 (direct encryption) 的加速器性能大大地降低了, 其IPC降低高达80%, 如图7所示.这是因为在使用直接加密的加速器中加密操作是在内存访问的关键路径上, 加密电路逻辑相对非常低的吞吐量严重影响了加速器的性能.本文提出的COSA, 相对于直接加密方法极大地提高了加速器的性能.随着每个内存控制器中计数器cache的大小从8 KB增加到64 KB, COSA相对于直接加密方法实现了3.1倍到5.0倍的性能提升.当计数器cache的大小为64 KB, COSA只比不加密的安全加速器慢13%左右.这是因为COSA利用计数器模式加密把很多读请求的解密步骤从内存访问的关键路径中移走了.COSA会产生一些额外的内存访问来读取计数器, 但是这不会显著影响性能, 因为内存有足够高的带宽.另外, 更大的片上计数器cache容量可以实现更高的性能提升, 这是由于更大的计数器cache有更高的cache 命中率, 如图8所示.</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同加密方法的加速器IPCs" src="Detail/GetImg?filename=images/JFYZ201906005_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同加密方法的加速器IPCs  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 IPCs of accelerators with different encryption  schemes</p>

                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906005_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同cache大小的计数器cache命中率" src="Detail/GetImg?filename=images/JFYZ201906005_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同cache大小的计数器cache命中率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906005_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 The hit ratio of the counter cache with  different sizes</p>

                </div>
                <h3 id="140" name="140" class="anchor-tag"><b>4 相关研究工作</b></h3>
                <div class="p1">
                    <p id="141">本节首先从算法和架构层面讨论机器学习模型安全性相关的研究工作, 然后讨论内存加密相关的研究工作.</p>
                </div>
                <div class="p1">
                    <p id="142">1) 模型提取攻击.①算法层面.现有的一些工作把机器学习模型看做为一个黑盒子, 然后提出一些算法通过观察该黑盒子的输入和输出数据来提取或推测模型相关的信息.Tramer等人<citation id="293" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>假设机器学习系统输出的分类标签的置信分数 (confidence scores) 和模型结构 (model architecture) 是已知的, 并证实可以通过置信分数来推测模型参数相关的信息.Oh等人<citation id="294" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>假设模型结构是未知的, 然后提出一个元模型 (metamodel) 方法来获取模型结构相关的信息.Wang等人<citation id="295" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>提出了一个获取机器学习模型的超参数 (hyperparameter) 的方法.超参数一般被用于平衡目标函数中的正则项和损失函数, 知道超参数可以进一步帮助攻击者获取模型参数.②系统和架构层面.现有的一些方法通过利用操作系统或体系架构的一些信息来推测机器学习模型的相关信息.Naghibijouybari等人<citation id="296" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>提出利用操作系统中的侧信道信息, 如内存分配API、GPU硬件的性能计数器和时序等, 来推测神经网络模型的相关信息如神经元的个数.Hua等人<citation id="297" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>提出利用机器学习加速器体系架构中的侧信道信息如内存访问模式, 来推测神经网络的结构信息.</p>
                </div>
                <div class="p1">
                    <p id="143">与这些现有的攻击相比, 本文关注的是一个更加危险的攻击也就是总线监听攻击.通过总线监听攻击, 攻击者不用推测就可以直接获取到机器学习模型的所有数据, 包括网络结构和权重参数等.为了抵御这种攻击, 本文提出了一个有效的安全加速器架构COSA.</p>
                </div>
                <div class="p1">
                    <p id="144">2) 内存加密.内存加密被广泛地应用在安全CPU系统中<citation id="298" type="reference"><link href="209" rel="bibliography" /><link href="211" rel="bibliography" /><link href="231" rel="bibliography" /><link href="237" rel="bibliography" /><link href="239" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">23</a>,<a class="sup">26</a>,<a class="sup">27</a>]</sup></citation>.由于CPU系统中的DDR内存总线带宽 (10～30 GBps) 和AES加密逻辑的带宽 (10 GBps) 差不多, 所以在CPU系统中使用内存加密并不会带来太大的性能损失.然而, 机器学习加速器系统如GPU的GDDR总线带宽远高于AES加密逻辑的带宽, 并且加速器的性能是带宽敏感的, 内存加密会极大地影响加速器的性能.本文提出了COSA安全加速器架构来有效地解决这个问题.</p>
                </div>
                <h3 id="145" name="145" class="anchor-tag"><b>5 总  结</b></h3>
                <div class="p1">
                    <p id="146">我们发现部署在边缘计算设备上的深度学习加速器有泄露其上存储的深度学习模型的风险.攻击者通过监听深度学习加速器和设备内存之间的总线就能很容易地截获到模型数据.为了解决这个问题, 本文提出了一个有效的安全深度学习加速器架构称作COSA.COSA通过利用计数器模式加密不仅提高了加速器的安全性, 并且能够把解密操作从内存访问的关键路径中移走来极大地提高加速器性能.我们在GPGPU-Sim上实现了提出的COSA架构, 并使用神经网络负载测试了其性能.实验结果显示COSA相对于直接加密的架构提升了3倍以上的性能, 相对于一个不加密的加速器性能只下降了13%左右.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="305" type="formula" href="images/JFYZ201906005_30500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">左鹏飞</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="306" type="formula" href="images/JFYZ201906005_30600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">华宇</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="307" type="formula" href="images/JFYZ201906005_30700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">谢新锋</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="308" type="formula" href="images/JFYZ201906005_30800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">胡杏</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="309" type="formula" href="images/JFYZ201906005_30900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">谢源</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="310" type="formula" href="images/JFYZ201906005_31000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">冯丹</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="187">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                LeCun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436- 444
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[2]</b>Krizhevsky A, Sutskever I, Hinton G.ImageNet classifica-tion with deep convolutional neural networks[C] //Proc of the 25th Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2012:1097- 1105
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[3]</b>He Kaiming, Zhang Xiangyu, Ren Shaoqing, et al.Deep residual learning for image recognition[C] //Proc of the IEEE Conf on Computer Vision and Pattern Recognition.Piscataway, NJ:IEEE, 2016:770- 778
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A unified architecture for natural language processing:deep neural networks with multitask learning">

                                <b>[4]</b>Collobert R, Weston J.A unified architecture for natural language processing:Deep neural networks with multitask learning[C] //Proc of the 25th Int Conf on Machine Learning (ICML) .New York:ACM, 2008:160- 167
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The microsoft 2016 conversational speech recognition system">

                                <b>[5]</b>Xiong W, Droppo J, Huang Xuedong, et al.The microsoft 2016 conversational speech recognition system[C] //Proc of the 2017 IEEE Int Conf on Acoustics Speech and Signal Processing (ICASSP) .Piscataway, NJ:IEEE, 2017:5255- 5259
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mastering the game of Go with deepneural networks and tree search">

                                <b>[6]</b>Silver D, Huang A, Maddison C J, et al.Mastering the game of go with deep neural networks and tree search[J].Nature, 2016, 529 (7587) :484- 489
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Edge computing:Vision and challenges">

                                <b>[7]</b>Shi Weisong, Cao Jie, Zhang Quan, et al.Edge computing:Vision and challenges[J].IEEE Internet of Things Journal, 2016, 3 (5) :637- 646
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallel scheduling for cyber-physical systems:Analysis and case study on a self-driving car">

                                <b>[8]</b>Kim J, Kim H, Lakshmanan K, et al.Parallel scheduling for cyber-physical systems:Analysis and case study on a self-driving car[C] //Proc of the ACM/IEEE 4th Int Conf on Cyber-physical Systems.New York:ACM, 2013:31- 40
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning for real-time robust facial expression recognition on a smartphone">

                                <b>[9]</b>Song I, Kim H J, Jeon P B.Deep learning for real-time robust facial expression recognition on a smartphone[C] //Proc of the 2014 IEEE Int Conf on Consumer Electronics (ICCE) .Piscataway, NJ:IEEE, 2014:564- 567
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Privacy-preserving deep learning">

                                <b>[10]</b>Shokri R, Shmatikov V.Privacy-preserving deep learning[C] //Proc of the 22nd ACM SIGSAC Conf on Computer and Communications Security (CCS) .New York:ACM, 2015:1310- 1321
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Nets">

                                <b>[11]</b>Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative adversarial nets[C] //Proc of the Int Conf on Neural Information Processing Systems (NerIPS) .New York:ACM, 2014:2672- 2680
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving the performance and endurance of encrypted non-volatile main memory through deduplicating writes">

                                <b>[12]</b>Zuo Pengfei, Hua Yu, Zhao Ming, et al.Improving the performance and endurance of encrypted non-volatile main memory through deduplicating writes[C] //Proc of the 2018 51st Annual IEEE/ACM Int Symp on Microarchitecture (MICRO) .Piscataway, NJ:IEEE, 2018:442- 454
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SecPM:A secure and persistent memory system for non-volatile memory">

                                <b>[13]</b>Zuo Pengfei, Hua Yu.SecPM:A secure and persistent memory system for non-volatile memory[C] //Proc of the 10th USENIX Workshop on Hot Topics in Storage and File Systems.Berkeley, CA:USENIX Association, 2018:1- 7
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SCUD&amp;filename=SCUDA2293C7DC614DD35E9052A5D851DD289&amp;v=MzAyNzhqUDNJZ3hGKzBPQ0FoTnpCTm00ejk0U2c3bjJCb3dlTWJnUjdLV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Z3pMdTh3S0U9Tmk3ZWFzSzZITg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Navarro C A, Hitschfeld-Kahler N, Mateu L.A survey on parallel computing and its applications in data-parallel problems using GPU architectures[J].Communications in Computational Physics, 2014, 15 (2) :285- 329
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=53Gbps native GF (24)2composite-field AES-encrypt/decrypt accelerator for content-protection in 45 nm high-performance microproce-ssors">

                                <b>[15]</b>Mathew S K, Sheikh F, Kounavis M, et al.53Gbps native GF (24) 2composite-field AES-encrypt/decrypt accelerator for content-protection in 45 nm high-performance microproce-ssors[C] //Proc of the IEEE Symp on VLSI Circuits (VLSIC) .Piscataway, NJ:IEEE, 2010:169- 170
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Self-Driving cars will create 2 petabytes of data,what are the big data opportunities for the car industry?[OL]">

                                <b>[16]</b>Finnegan M.Self-Driving cars will create 2 petabytes of data, what are the big data opportunities for the car industry?[OL]. (2016-12-07) [2019-02-26].http://www.computerworlduk.com/news/data/boeing-787screate-half-terabyte-of-data-per-flight-says-virgin-atlantic-3433595/
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Survey on Mobile Edge Computing:The Communication Perspective">

                                <b>[17]</b>Mao Yuyi, You Changsheng, Zhang Jun, et al.A survey on mobile edge computing:The communication perspective[J].IEEE Communications Surveys &amp; Tutorials, 2017, 19 (4) :2322- 2358
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CUDNN:Efficient primitives for deep learning">

                                <b>[18]</b>Chetlur S, Woolley C, Vandermersch P, et al.CUDNN:Efficient primitives for deep learning[J].arXiv preprint arXiv:1410.0759, 2014
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks">

                                <b>[19]</b>Zhang Chen, Li Peng, Sun Guangyu, et al.Optimizing FPGA-based accelerator design for deep convolutional neural networks[C] //Proc of the 2015 ACM/SIGDA Int Symp on Field-Programmable Gate Arrays.New York:ACM, 2015:161- 170
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Indatacenter performance analysis of a tensor processing unit">

                                <b>[20]</b>Jouppi N P, Young C, Patil N, et al.In-datacenter performance analysis of a tensor processing unit[C] //Proc of the 2017 ACM/IEEE 44th Annual Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2017:1- 12
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DianNao:A small-footprint high-throughput accelerator for ubiquitous machine-learning">

                                <b>[21]</b>Chen Tishi, Du Zidong, Sun Ninghui, et al.Diannao:A small-footprint high-throughput accelerator for ubiquitous machine-learning[C] //Proc of the 19th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2014:269- 284
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Eyeriss:An energy-efficient reconfigurable accelerator for deep convolutional neural networks">

                                <b>[22]</b>Chen Y H, Krishna T, Emer J, et al.14.5 Eyeriss:An energy-efficient reconfigurable accelerator for deep convolu-tional neural networks[C] //Proc of the 2016 IEEE Int Solid-State Circuits Conf (ISSCC) .Piscataway, NJ:IEEE, 2016:262- 263
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving Cost, Performance, andSecurity of Memory Encryption and Authentication">

                                <b>[23]</b>Yan C, Englender D, Prvulovic M, et al.Improving cost, performance, and security of memory encryption and authentication[C] //Proc of the 33rd Int Symp on Computer Architecture (ISCA) .Piscataway, NJ:IEEE, 2006:179- 190
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Design of Rijndael:AES-the Advanced Encryption Standard">

                                <b>[24]</b>Daemen J, Rijmen V.The Design of Rijndael:AES-the Advanced Encryption Standard[M].Berlin:Springer Science &amp; Business Media, 2013
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CTR-mode encryption">

                                <b>[25]</b>Lipmaa H, Rogaway P, Wagner D.CTR-mode encryption[C] //Proc of the 1st NIST Workshop on Modes of Operation.Gaithersburg, MD:NIST, 2000:1- 4
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Silent shredder:Zerocost shredding for secure non-volatile main memory controllers">

                                <b>[26]</b>Awad A, Manadhata P, Haber S, et al.Silent shredder:Zerocost shredding for secure non-volatile main memory controllers[C] //Proc of the 21st Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2016:263- 276
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DEUCE Write-efficient encryption for non-volatile memories">

                                <b>[27]</b>Young V, Nair P J, Qureshi M K.DEUCE:Write-efficient encryption for non-volatile memories[C] //Proc of the 20th Int Conf on Architectural Support for Programming Languages and Operating Systems (ASPLOS) .New York:ACM, 2015:33- 44
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analyzing CUDA workloads using a detailed GPU simulator">

                                <b>[28]</b>Bakhoda A, Yuan G L, Fung W W, et al.Analyzing CUDA workloads using a detailed GPU simulator[C] //Proc of the 2009 IEEE Int Symp on Performance Analysis of Systems and Software.Piscataway, NJ:IEEE, 2009:163- 174
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nvidia CUDA C programming guide">

                                <b>[29]</b>Nvidia Corporation.Nvidia CUDA C programming guide[J].Nvidia Corporation, 2011, 120 (18) :1- 175
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OpenCL: A parallel programming standard for heterogeneous computing systems">

                                <b>[30]</b>Stone J E, Gohara D, Shi G.OpenCL:A parallel programming standard for heterogeneous computing systems[J].Computing in Science &amp; Engineering, 2010, 12 (3) :66- 73
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Crash consistency in encrypted non-volatile main memory systems">

                                <b>[31]</b>Liu Sihang, Kolli A, Ren Jinglei, et al.Crash consistency in encrypted non-volatile main memory systems[C] //Proc of the 2018 IEEE Int Symp on High Performance Computer Architecture (HPCA) .Piscataway, NJ:IEEE, 2018:310- 323
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stealing machine learning models via prediction APIs">

                                <b>[32]</b>Tramèr F, Zhang F, Juels A, et al.Stealing machine learning models via prediction apis[C] //Proc of the 25th USENIX Security Symp.Berkeley, CA:USENIX Association, 2016:601- 618
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards reverse-engineering black-box neural networks">

                                <b>[33]</b>Oh S J, Augustin M, Schiele B, et al.Towards reverse-engineering black-box neural networks[J].arXiv preprint arXiv:1711.01768, 2017
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stealing hyperparameters in machine learning">

                                <b>[34]</b>Wang Binghui, Gong N Z.Stealing hyperparameters in machine learning[C] //Proc of the 2018 IEEE Symp on Security and Privacy (SP) .Piscataway, NJ:IEEE, 2018:36- 52
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rendered insecure:GPU side channel attacks are practical">

                                <b>[35]</b>Naghibijouybari H, Neupane A, Qian Zhiyun, et al.Rendered insecure:GPU side channel attacks are practical[C] //Proc of the 2018 ACM SIGSAC Conf on Computer and Communications Security.New York:ACM, 2018:2139- 2153
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reverse engineering convolutional neural networks through side-channel information leaks">

                                <b>[36]</b>Hua Weizhi, Zhang Zhiru, Suh G E.Reverse engineering convolutional neural networks through side-channel information leaks[C] //Proc of the 2018 55th ACM/ESDA/IEEE Design Automation Conf (DAC) .Piscataway, NJ:IEEE, 2018:No.4
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201906005" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201906005&amp;v=MzAwODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEbVVML0JMeXZTZExHNEg5ak1xWTlGWVlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGYzeWRZV1dUc1RIc3hUaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

