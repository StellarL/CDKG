

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127157596082500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201909005%26RESULT%3d1%26SIGN%3dE6zjzBN96oTRxi6cQx0Zcf9nPEQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909005&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909005&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909005&amp;v=MDMwMzVxcUJ0R0ZyQ1VSTE9lWmVSc0Z5L25WN3ZBTHl2U2RMRzRIOWpNcG85RllZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="&lt;b&gt;1.1 生成式对抗网络(GAN&lt;/b&gt;)"><b>1.1 生成式对抗网络(GAN</b>)</a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;1.2 众包标注数据&lt;/b&gt;"><b>1.2 众包标注数据</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;1.3 实体标记不一致&lt;/b&gt;"><b>1.3 实体标记不一致</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="&lt;b&gt;2 BiLSTM-Attention-CRF-crowd模型设计&lt;/b&gt; "><b>2 BiLSTM-Attention-CRF-crowd模型设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;2.1 基于GAN模型的共同特征学习&lt;/b&gt;"><b>2.1 基于GAN模型的共同特征学习</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;2.2 BiLSTM-Attention-CRF子模型&lt;/b&gt;"><b>2.2 BiLSTM-Attention-CRF子模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="&lt;b&gt;3 实验及结果分析&lt;/b&gt; "><b>3 实验及结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#109" data-title="&lt;b&gt;3.1 数据来源&lt;/b&gt;"><b>3.1 数据来源</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;3.2 基线模型分组&lt;/b&gt;"><b>3.2 基线模型分组</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;3.3 实验结果评价&lt;/b&gt;"><b>3.3 实验结果评价</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="图1 模型图">图1 模型图</a></li>
                                                <li><a href="#124" data-title="图2 模型关于不同类型实体的性能对比">图2 模型关于不同类型实体的性能对比</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表1 模型性能对比表&lt;/b&gt;"><b>表1 模型性能对比表</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;表2 实体名及对应缩写表&lt;/b&gt;"><b>表2 实体名及对应缩写表</b></a></li>
                                                <li><a href="#140" data-title="图3 各模型性能比较图">图3 各模型性能比较图</a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;表3 各模型综合性能评价表&lt;/b&gt;"><b>表3 各模型综合性能评价表</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title="Ratinov L,Roth D.Design challenges and misconceptions in named entity recognition[C] //Proc of the 13th Conf on Computational Natural Language Learning.Stroudsburg:ACL,2009:147- 155" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Design challenges and misconceptions in named entity recognition">
                                        <b>[1]</b>
                                        Ratinov L,Roth D.Design challenges and misconceptions in named entity recognition[C] //Proc of the 13th Conf on Computational Natural Language Learning.Stroudsburg:ACL,2009:147- 155
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title="Finkel J R,Grenager T,Manning C.Incorporating non-local information into information extraction systems by Gibbs sampling[C] //Proc of the 43rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg:ACL,2005:363- 370" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling">
                                        <b>[2]</b>
                                        Finkel J R,Grenager T,Manning C.Incorporating non-local information into information extraction systems by Gibbs sampling[C] //Proc of the 43rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg:ACL,2005:363- 370
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title="Hal D III.Frustratingly easy domain adaptation[C] //Proc of the 45th Annual Meeting of the Association for Computa-tional Linguistics.Stroudsburg:ACL,2007:256- 263" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Frustratingly Easy Domain Adaptation">
                                        <b>[3]</b>
                                        Hal D III.Frustratingly easy domain adaptation[C] //Proc of the 45th Annual Meeting of the Association for Computa-tional Linguistics.Stroudsburg:ACL,2007:256- 263
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title="Snow R,O&#39;Connor B,Jurafsky D,et al.Cheap and fast-but is it good?evaluating non-expert annotations for natural language tasks[C] //Proc of the Conf on Empirical Methods in Natural Language Processing.Stroudsburg:ACL,2008:254- 263" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cheap and Fast-But is it Good?Evaluating Non-Expert Annotations for Natural Language Tasks">
                                        <b>[4]</b>
                                        Snow R,O&#39;Connor B,Jurafsky D,et al.Cheap and fast-but is it good?evaluating non-expert annotations for natural language tasks[C] //Proc of the Conf on Empirical Methods in Natural Language Processing.Stroudsburg:ACL,2008:254- 263
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title="Rodrigues F,Pereira F,Ribeiro B.Sequence labeling with multiple annotators[J].Machine Learning,2014,95(2):165- 181" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14040800005327&amp;v=MjIxOTA0K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUwzSUoxd1RheEk9Tmo3QmFySzhIdFhNcDQ5RlpPc0tEMw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Rodrigues F,Pereira F,Ribeiro B.Sequence labeling with multiple annotators[J].Machine Learning,2014,95(2):165- 181
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title="Zhao Hai,Chunyu K.Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition[C] //Proc of the 6th SIGHAN Workshop on Chinese Language Processing.Stroudsburg:ACL,2008:106- 111" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition">
                                        <b>[6]</b>
                                        Zhao Hai,Chunyu K.Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition[C] //Proc of the 6th SIGHAN Workshop on Chinese Language Processing.Stroudsburg:ACL,2008:106- 111
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title="Huang Zhiheng,Xu Wei,Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J/OL].arXiv preprint arXiv:1508.0191 2015" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">
                                        <b>[7]</b>
                                        Huang Zhiheng,Xu Wei,Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J/OL].arXiv preprint arXiv:1508.0191 2015
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title="Ramamoorthy S,Murugan S.An attentive sequence model for adverse drug event extraction from biomedical text[J].arXiv preprint arXiv:1801.0625 2018" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An attentive sequence model for adverse drug event extraction from biomedical text">
                                        <b>[8]</b>
                                        Ramamoorthy S,Murugan S.An attentive sequence model for adverse drug event extraction from biomedical text[J].arXiv preprint arXiv:1801.0625 2018
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title="Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Neural Information Processing System.New York:Curran Associates,2014:2672- 2680" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">
                                        <b>[9]</b>
                                        Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Neural Information Processing System.New York:Curran Associates,2014:2672- 2680
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title="Wang Wanliang,Li Zhuorong.Advance in generative adversarial network[J].Journal on Communications,2018,39(2):135- 148 (in Chinese)(王万良,李卓蓉.生成式对抗网络研究进展[J].通信学报,2018,39(2):135- 148)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201802014&amp;v=MDE4NDJDVVJMT2VaZVJzRnkvblZMN0lNVFhUYkxHNEg5bk1yWTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Wang Wanliang,Li Zhuorong.Advance in generative adversarial network[J].Journal on Communications,2018,39(2):135- 148 (in Chinese)(王万良,李卓蓉.生成式对抗网络研究进展[J].通信学报,2018,39(2):135- 148)
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title="Zhang Yizhe,Gan Zhe,Lawrence C.Generating text via adversarial training[C] //Proc of the 30th Neural Information Processing Systems Workshop on Adversarial Training.New York:Curran Associate,2016:2852- 2858" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generating text via adversarial training">
                                        <b>[11]</b>
                                        Zhang Yizhe,Gan Zhe,Lawrence C.Generating text via adversarial training[C] //Proc of the 30th Neural Information Processing Systems Workshop on Adversarial Training.New York:Curran Associate,2016:2852- 2858
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title="Yu Lantao,Zhang Weinan,Wang Jun,et al.SeqGAN:Sequence generative adversarial nets with policy gradient[C] //Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017.arXiv:1609.05473" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Seq GAN:sequence generative adversarial nets with policy gradient">
                                        <b>[12]</b>
                                        Yu Lantao,Zhang Weinan,Wang Jun,et al.SeqGAN:Sequence generative adversarial nets with policy gradient[C] //Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017.arXiv:1609.05473
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title="Li Jiwei,Will M,Shi Tianlin,et al.Adversarial learning for neural dialogue generation[J].arXiv preprint arXiv1701.06547,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial learning for neural dialogue generation">
                                        <b>[13]</b>
                                        Li Jiwei,Will M,Shi Tianlin,et al.Adversarial learning for neural dialogue generation[J].arXiv preprint arXiv1701.06547,2017
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title="Kusner M J,Hernandeslobato J M.GANS for sequences of discrete elements with the gumbel-softmax distribution[J].arXiv preprint arXiv1611.04051,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GANS for sequences of discrete elements with the gumbel-softmax distribution">
                                        <b>[14]</b>
                                        Kusner M J,Hernandeslobato J M.GANS for sequences of discrete elements with the gumbel-softmax distribution[J].arXiv preprint arXiv1611.04051,2016
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title="Dredze M,Talukdar P P,Crammer K.Sequence learning from data with multiple labels[C/OL] //Proc of ECML/PKDD Workshop on Learning from Multi-Label Data.2009:39- 48[2018-08-15].https://www.academia.edu/2809854/Sequence_learning_from_data_with_multiple_labels" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sequence learning from data with multiple labels[C/OL]">
                                        <b>[15]</b>
                                        Dredze M,Talukdar P P,Crammer K.Sequence learning from data with multiple labels[C/OL] //Proc of ECML/PKDD Workshop on Learning from Multi-Label Data.2009:39- 48[2018-08-15].https://www.academia.edu/2809854/Sequence_learning_from_data_with_multiple_labels
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title="Dawid A P,Skene A M.Maximum likelihood estimation of observer error-rates using the EM algorithm[J].Applied Statistics,1979,28(1):20- 28" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maximum likelihood estimation of observer error-rates using the EM algorithm">
                                        <b>[16]</b>
                                        Dawid A P,Skene A M.Maximum likelihood estimation of observer error-rates using the EM algorithm[J].Applied Statistics,1979,28(1):20- 28
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title="Kajino H,Tsuboi Y,Kashima H.A convex formulation for learning from crowds[C] //Proc of the 26th AAAI on Artificial Intelligence.Menlo Park,CA:AAAI,2012:73- 79" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A convex formulation for learning from crowds">
                                        <b>[17]</b>
                                        Kajino H,Tsuboi Y,Kashima H.A convex formulation for learning from crowds[C] //Proc of the 26th AAAI on Artificial Intelligence.Menlo Park,CA:AAAI,2012:73- 79
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title="Nguyen A T,Wallace B C,Li J J,et al.Aggregating and predicting sequence labels from crowd annotations[C] //Proc of the Association for Computational Linguistics.Strouds-burg:ACL,2017:299- 309" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aggregating and predicting sequence labels from crowd annotations">
                                        <b>[18]</b>
                                        Nguyen A T,Wallace B C,Li J J,et al.Aggregating and predicting sequence labels from crowd annotations[C] //Proc of the Association for Computational Linguistics.Strouds-burg:ACL,2017:299- 309
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title="Yang Yaosheng,Zhang Meishan,Chen Wenliang,et al.Adversarial learning for Chinese NER from crowd annotations[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:1627- 1634" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial Learning for Chinese NER from Crowd Annotations">
                                        <b>[19]</b>
                                        Yang Yaosheng,Zhang Meishan,Chen Wenliang,et al.Adversarial learning for Chinese NER from crowd annotations[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:1627- 1634
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title="Robert L,Chih-Hsuan W,Lu Zhiyong.tmChem:A high performance approach for chemical named entity recognition and normalization[J].Journal of Cheminformatics,2015,7(1):S1- S3" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=tmChem:a high performance approach for chemical named entity recognition and normalization">
                                        <b>[20]</b>
                                        Robert L,Chih-Hsuan W,Lu Zhiyong.tmChem:A high performance approach for chemical named entity recognition and normalization[J].Journal of Cheminformatics,2015,7(1):S1- S3
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title="Luo Ling,Yang Zhihao,Yang Pei,et al.An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition[J].Bioinformatics,2017,34(8):1381- 1388" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition">
                                        <b>[21]</b>
                                        Luo Ling,Yang Zhihao,Yang Pei,et al.An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition[J].Bioinformatics,2017,34(8):1381- 1388
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title="Syed Z,Padia A,Finin T,et al.UCO:A unified cybersecurity ontology[C] //Proc of the 36th AAAI Workshop on Artificial Intelligence for Cyber Security.Menlo Park,CA:AAAI,2016:1381- 1388" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=UCO:A unified cybersecurity ontology">
                                        <b>[22]</b>
                                        Syed Z,Padia A,Finin T,et al.UCO:A unified cybersecurity ontology[C] //Proc of the 36th AAAI Workshop on Artificial Intelligence for Cyber Security.Menlo Park,CA:AAAI,2016:1381- 1388
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(09),1851-1858 DOI:10.7544/issn1000-1239.2019.20180733            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合GAN与BiLSTM-Attention-CRF的领域命名实体识别</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%99%97&amp;code=42840452&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张晗</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%B8%8A%E5%8D%9A&amp;code=40858288&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭渊博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%B6%9B&amp;code=40897805&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李涛</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%88%98%E7%95%A5%E6%94%AF%E6%8F%B4%E9%83%A8%E9%98%9F%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E5%AF%86%E7%A0%81%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1702647&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">战略支援部队信息工程大学密码工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%83%91%E5%B7%9E%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0048752&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑州大学软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>领域内命名实体识别通常面临领域内标注数据缺乏以及由于实体名称多样性导致的同一文档中实体标注不一致等问题.针对以上问题,利用生成式对抗网络(generative adversarial network, GAN)可以生成数据的特点,将生成式对抗网络与BiLSTM-Attention-CRF模型相结合.首先以BiLSTM-Attention作为生成式对抗网络的生成器模型,以CNN作为判别器模型,从众包标注数据集中整合出与专家标注数据分布一致的正样本标注数据来解决领域内标注数据缺乏的问题;然后通过在BiLSTM-Attention-CRF模型中引入文档层面的全局向量,计算每个单词与该全局向量的关系得出其新的特征表示以解决由于实体名称多样化造成的同一文档中实体标注不一致问题;最后,在基于信息安全领域众包标注数据集上的实验结果表明,该模型在各项指标上显著优于同类其他模型方法.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%86%E5%9F%9F%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">领域命名实体识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成式对抗网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%97%E5%8C%85%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">众包标注数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9E%E4%BD%93%E6%A0%87%E6%B3%A8%E4%B8%80%E8%87%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">实体标注一致;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BiLSTM-Attention-CRF%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BiLSTM-Attention-CRF模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张晗,zhang_han@zzu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61501515);</span>
                                <span>河南省重点科技攻关项目(172102210002);</span>
                                <span>郑州大学青年骨干教师项目(2017ZDGGJS048);</span>
                    </p>
            </div>
                    <h1><b>Domain Named Entity Recognition Combining GAN and BiLSTM-Attention-CRF</b></h1>
                    <h2>
                    <span>Zhang Han</span>
                    <span>Guo Yuanbo</span>
                    <span>Li Tao</span>
            </h2>
                    <h2>
                    <span>Department of Cryptogram Engineering, Strategic Support Force Information Engineering University</span>
                    <span>Software College, Zhengzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Domain named entity recognition usually faces the lack of domain annotation data and the inconsistency of entity annotation in the same document due to the diversity of entity names in the domain. To issue the above problems, our work draws on the combination of the generative adversarial network(GAN) which can generate data and the BiLSTM-Attention-CRF model. Firstly, BiLSTM-Attention is used as the generator model of GAN, and CNN is used as the discriminant model. The two models use the crowd annotations and the expert annotations to train respectively, and integrate the positive annotation data consistent with the expert annotation data distribution from the crowd annotations to solve the problem of lack of annotation data in the domain; then we also introduce a new method to obtain the new feature representation of each word in the document through introducing a document-level global feature in the BiLSTM-Attention-CRF model in order to solve the problem of inconsistency of the entity in the same document caused by the diversification of the entity name. Finally, taking the crowd annotations in the information security field as a sample, a comprehensive horizontal evaluation experiment is carried out by learning the common features and applying them to the training BiLSTM-Attention-CRF model for the identification of named entities in the information security field. The results show that compared with the existing models and methods, the model we proposed has made great progress on various indicators, reflecting its superiority.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=domain%20named%20entity%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">domain named entity recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20adversarial%20network(GAN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative adversarial network(GAN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=crowd%20annotations&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">crowd annotations;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=entity%20annotations%20consistent&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">entity annotations consistent;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BiLSTM-Attention-CRF%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BiLSTM-Attention-CRF model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Zhang Han,born in 1985.PhD candidate in software engineering at Strategic Support Force Information Engineering University. Lecturer in Zhengzhou University.Her main research interest is natural language processing.&lt;image id="205" type="formula" href="images/JFYZ201909005_20500.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Guo Yuanbo,born in 1975.Received his PhD degree in computer science from Xidian University,China,in 2005.Professor in Strategic  Support  Force  Information Engineering University.Member of IEEE, senior member of Chinese Institute of Electronics and senior member of CCF. His main research interests include insider threat detection,security analytics and security architectures.(yuanbo_g@hotmail. com)&lt;image id="207" type="formula" href="images/JFYZ201909005_20700.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Li Tao,born in 1992.PhD candidate in computer science and technology at Strategic Support Force Information Engineering University.His main research interest is knowledge graph.(1527105421@qq.com)&lt;image id="209" type="formula" href="images/JFYZ201909005_20900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-01</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61501515);</span>
                                <span>the Key Scientific and Technological Research Project of Henan Province(172102210002);</span>
                                <span>the Young Scholar Teachers Project of Zhengzhou University(2017ZDGGJS048);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="47">领域命名实体识别(named entity recognition, NER)<citation id="169" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>旨在从文本中提取出各种类型的实体,其结果可用于领域中后续的其他复杂任务诸如关系提取、领域知识图谱的构建等.与通用领域的命名实体识别任务相比,特殊领域的命名实体识别经常会面临着领域标注数据缺乏以及由于领域内实体名称的多样性而导致的同一文档中实体标注不一致问题<citation id="170" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="48">为了解决由于领域内标注数据缺乏而导致的模型性能问题,文献<citation id="171" type="reference">[<a class="sup">3</a>]</citation>提出使用具有大量标注数据的通用领域数据集(如新闻领域)来训练模型,使得模型可以从中学习到更多特定领域的特征分布,从而提高模型在特定领域数据上的性能.但是显然使用通用领域训练数据中的词汇特征分布来估计专业领域中的数据特征分布会导致偏差太大的问题.为了快速高效且低成本地获取领域内大型标注数据集,文献<citation id="172" type="reference">[<a class="sup">4</a>]</citation>提出可以使用Amazon Mechanical Turk来快速且低成本地收集标签数据,并且证明了众包标注数据对于训练模型来说是可用的.相比于专家标注来说,众包具有低成本、大规模等优点,因此随着众包技术的成熟,国内外众包的应用也越加广泛,其中以亚马逊的Amazon Mechanical Turk和维基百科最为著名.目前,国内也出现了不少众包平台,如百度众包、阿里众包和搜狗输入法等.这些众包平台大都属于通用众包平台,虽然准确率经过平台筛选之后还算理想,但是,针对专业领域来说,其缺点也非常明显,这些来自于非专业人员的标注数据远远要比来自于专家标注的数据质量低并且含有极大的噪声,这部分数据如果直接拿来使用,会给模型造成偏差.因此需要针对众包标注数据的质量进行建模,整合出高质量的共识标注.文献<citation id="173" type="reference">[<a class="sup">5</a>]</citation>采用多数投票法来实现高质量共识标注.这种方法尽管可以获得较高质量的标注数据,但是需要耗费大量的人力,同样的一句话需要交由至少3个注释者标注,这样才能通过多数投票法选取出相对准确的标注.而且对于一些本身含义就比较模糊的句子或者实体,标注者之间可能很难达到统一,这样无疑会影响到最终选择结果的正确性.</p>
                </div>
                <div class="p1">
                    <p id="49">除此之外,目前常用来进行命名实体识别任务的模型,如条件随机场(conditional random field, CRF)<citation id="174" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>模型、双向长短记忆网络+条件随机场(bi-directional long short-term memory+conditional random field, BiLSTM-CRF)<citation id="175" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>模型,大都仅仅只是从单词和句子层面来考虑单词的特征表示.但是由于这些模型自身设计的限制,输入序列无论长短都会编码成一个固定长度的向量表示,当输入序列过长时,编码器可能会丢掉上下文中一些比较重要的特征信息,这样就容易造成因为实体名称多样化所带来的同一文档中实体标注不一致问题.例如:Internet Explorer和IE指代的是同一个实体,但是由于表示方法不同以及在文中位置不同,很可能会出现两者标注不一致的情况,从而影响到后续任务的完成效果.为了提高模型的性能,文献<citation id="176" type="reference">[<a class="sup">8</a>]</citation>在BiLSTM-CRF模型的基础上添加了注意力(attention)机制,它打破了传统编码器-解码器结构在编解码时都依赖于内部一个固定长度向量的限制,可以通过训练一个模型来对输入字符串的特征进行重点选择性学习并且在模型输出时将输出序列与各选择特征按照权重进行关联.但是这种模型如果要达到比较理想的效果,在训练时要求用到更加大量准确的标注数据.生成式对抗网络(generative adversarial network, GAN)模型具有生成数据的特点,而Goodfellow等人<citation id="177" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>从理论上证明了当GAN模型收敛时,生成数据具有和真实数据相同的分布<citation id="178" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="50">基于GAN的这个特点,本文在众包标注数据集中引入GAN模型,以少量专家标注数据作为判别器中的真实数据,以众包标注数据作为生成器所生成的模拟数据,通过对抗学习,整合出众包标注数据中与真实数据分布一致的正样本数据并将其与BiLSTM-Attention-CRF模型相结合,提出了一种新的模型BiLSTM-Attention-CRF-crowd,该模型由GAN和BiLSTM-Attention-CRF这2个子模型组成.首先,通过GAN模型在给定的众包标注数据集上寻找出标注数据的共有特征以整合出最佳的唯一共识标注,解决目前众包数据中质量不高的问题;然后使用通过GAN模型所生成的标注数据来训练BiLSTM-Attention-CRF模型进行领域命名实体识别,并引入文档层面的全局特征向量,通过计算每个单词与全局向量的关系得出其新的特征表示,以解决同一实体在同一文档中可能出现的标记不一致问题.</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag"><b>1 相关工作</b></h3>
                <h4 class="anchor-tag" id="52" name="52"><b>1.1 生成式对抗网络(GAN</b>)</h4>
                <div class="p1">
                    <p id="53">相对于在计算机视觉领域的应用,GAN模型在语言处理领域的应用较少,原因在于图像和视频数据的取值是连续的,可直接使用梯度下降法对生成器和判别器进行训练,而文本中的字母、单词都是离散的,无法直接应用梯度下降法,需要对其进行修改.文献<citation id="179" type="reference">[<a class="sup">11</a>]</citation>所提出的TextGAN模型采用一些技巧对离散变量进行处理,例如,采用光滑近似来逼近长短记忆网络(long short-term memory, LSTM)的离散输出,并在生成器训练过程中采用特征匹配技术.由于LSTM 的参数明显多于卷积神经网络(convolutional neural network, CNN)的参数个数而更难训练,TextGAN 的判别器仅在生成器多次更新后才进行一次更新.文献<citation id="180" type="reference">[<a class="sup">12</a>]</citation>提出的SeqGAN借鉴强化学习处理离散输出问题,将判别器输出的误差视为强化学习中的奖赏值,并将生成器的训练过程看作强化学习中的决策过程,应用于诗句、演讲文本以及音乐生成.文献<citation id="181" type="reference">[<a class="sup">13</a>]</citation>和文献<citation id="182" type="reference">[<a class="sup">14</a>]</citation>分别将GAN 应用于开放式对话文本生成和上下文无关语法(context-free grammar, CFG)<citation id="183" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>.本文主要借鉴了文献<citation id="184" type="reference">[<a class="sup">11</a>]</citation>中对离散变量的处理方法及其进行特征匹配的目标函数.</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>1.2 众包标注数据</b></h4>
                <div class="p1">
                    <p id="55">文献<citation id="185" type="reference">[<a class="sup">15</a>]</citation>提出了一种从多个标签中进行学习的条件随机场(conditional random field, CRF)模型,但是CRF可以学习的特征是有限的;文献<citation id="186" type="reference">[<a class="sup">16</a>]</citation>所提Dawid&amp;Skene模型假定每一个标注者出现每一类标注错误的概率确定,这样就可以用一个统一的混淆矩阵来描述标注者的标注质量,最后通过最大似然估计就可以得到所有的实体标注概率,其中也包括每个实体的正确标注.这属于比较理想化的情况,在实际应用中,由于众包数据来源的多样性,很难确定每个标注者的错误概率.文献<citation id="187" type="reference">[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</citation>虽然所使用的模型不同,但其本质都是对标注者身份进行区别,将标注正确率较高的标注者身份提取出来,从而提高他们标注的可信度,这样做确实提高了模型的性能,但是对标注的选取过于依赖某个标注者的可信度.</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>1.3 实体标记不一致</b></h4>
                <div class="p1">
                    <p id="57">为解决实体标记不一致问题,通常采用基于规则的后处理方式来强调标记一致性.如文献<citation id="188" type="reference">[<a class="sup">20</a>]</citation>中设置规则如果某实体在文档中被NER模型至少标记了2次,则在该文档中其他位置出现的该实体也被标记同样的类别.但是这种后处理方式并不一定能改善模型的性能,反而可能会因为实体被错误地标记而引入更多的噪声.此外,文献<citation id="189" type="reference">[<a class="sup">1</a>]</citation>和文献<citation id="190" type="reference">[<a class="sup">2</a>]</citation>通过使用非本地信息来强调标签的一致性从而提高序列模型的性能,但收效并非十分明显.文献<citation id="191" type="reference">[<a class="sup">21</a>]</citation>提出的模型虽然也考虑了文档层面的特征表示,但该模型应用于化学领域,该领域内有很多公开标注的数据集可以直接进行使用,无需再考虑领域数据缺乏的问题.</p>
                </div>
                <div class="p1">
                    <p id="58">本文所提模型不再对标注者身份进行鉴别,而是利用GAN模型生成数据的特点,从众包标注数据集中生成与专家标注数据趋于一致的标注数据,从而解决领域内标注数据准确率不高的问题.</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag"><b>2 BiLSTM-Attention-CRF-crowd模型设计</b></h3>
                <div class="p1">
                    <p id="60">模型所要完成的任务包括2个方面.子任务1:学习众包标注数据的共有特征,以整合出最优的单一共识标注;子任务2:以子任务1所生成的标注数据集作为训练数据,训练BiLSTM-Attention-CRF模型进行领域内命名实体识别并解决同一文档内同一实体标记不一致问题.模型图如图1所示.</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型图" src="Detail/GetImg?filename=images/JFYZ201909005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909005_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Model diagram</p>

                </div>
                <div class="p1">
                    <p id="62">该模型由2个子模型组合而成.图1左侧描述的是GAN模型,由生成器BiLSTM-Attention和判别器CNN构成.众包标注数据作为生成器的输入在经过BiLSTM层和Attention层处理之后形成新的特征表示,该特征表示传入到由专家标注数据训练的CNN中,由CNN来判别这些特征分布与专家标注数据分布是否趋于一致,如果一致则为正样本数据,可以作为图1右侧所示模型的训练语料;反之则为负样本数据,重新传递回BiLSTM层对该层进行优化.图1右侧描述的是进行命名实体识别的BiLSTM-Attention-CRF模型,该模型由GAN模型所生成的正样本数据训练而成,为了解决由领域实体多样化所带来的实体标注不一致问题,加入了基于整篇文档的全局向量<i><b>r</b></i><sup>g</sup><sub><i>i</i></sub>,通过Attention层来计算<i><b>r</b></i><sup>g</sup><sub><i>i</i></sub>与当前单词的关系权重得出该单词新的特征表表示并传递给CRF层进行识别标记.</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63"><b>2.1 基于GAN模型的共同特征学习</b></h4>
                <div class="p1">
                    <p id="64">GAN模型以博弈论中二人零和博弈为核心思想.结构中包含2个模型:生成模型和判别模型,将随机变量作为生成模型的输入,经过其非线性映射,输出对应的信号作为判别模型的输入,由判别模型来判断该信号来自于真实数据的概率.因此,二者的目标是截然相反的,判断模型的目标是通过最大化对数似然函数以判断信号的来源,而生成模型的目标则是最小化对数似然函数,使得输出信号的分布逼近于真实数据的分布.</p>
                </div>
                <div class="p1">
                    <p id="65">本文将对抗思想应用于寻找众包标注数据中的共同特征.因此将不再对标注者的标注质量进行评价估计,而是利用GAN模型可以生成数据的思想,先利用少量的专家标注数据训练出一个判别模型,然后将众包标注数据作为生成模型的输入,输出这些数据的特征分布传递给判别模型,由判别模型来进行判断生成的特征分布与真实数据的特征分布的异同,反复训练模型并生成数据,直到最后判别器无法再对二者进行区别为止,此时判别模型所输出的结果即是标注数据的共同特征也即是我们要整合出的最优单一共识标注.GAN模型如图1左侧框图所示,主要由2部分组成:BiLSTM-Attention构成的生成模型以及CNN构成的判别模型.CNN上面的<i>max</i>_<i>pooling</i>层和<i>softmax</i>层主要是对CNN层生成的特征图进行最大化选择以及对选择之后的新特征进行归一化,以此判断是否与训练CNN的专家标注数据特征分布一致.</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">2.1.1 BiLSTM-Attention生成模型</h4>
                <div class="p1">
                    <p id="67">给定众包标注数据集中的一个句子<i>s</i>={<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>w</i><sub><i>n</i></sub>},<i>w</i><sub><i>i</i></sub>表示句子中识别出的命名实体单词,<i>y</i>={<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>,…,<i>y</i><sub><i>n</i></sub>}为标注集,其中<i>y</i><sub><i>i</i></sub>表示命名实体<i>w</i><sub><i>i</i></sub>所对应的类别标签.用向量<mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>表示单词<i><b>w</b></i><sub><i><b>i</b></i></sub>和标注<i><b>y</b></i><sub><i><b>i</b></i></sub>通过<b>word</b>2<b>vec</b>训练出来的联合向量,以此作为生成模型<b>BiLSTM</b>的输入,则得到特征<i><b>h</b></i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>,<i><b>h</b></i><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>,…,<i><b>h</b></i><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>为</p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup><mo>⋯</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup><mo>=</mo><mi>B</mi><mi>i</mi><mi>L</mi><mi>s</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>,(1)</p>
                </div>
                <div class="p1">
                    <p id="69">其中,<i>BiLs</i>作为模型BiLSTM的缩写.为了获取到更加重要的特征,此时,在判别模型CNN之前再加上一层Attention机制以获得新的特征<i><b>h</b></i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="70"><i>f</i>(<i><b>h</b></i><sub><i>i</i></sub>,<i><b>h</b></i><sub><i>j</i></sub>)=(<i><b>h</b></i><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>)<sup>T</sup><i><b>W</b></i><sub><i>a</i></sub><i><b>h</b></i><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>,</p>
                </div>
                <div class="p1">
                    <p id="71"><i><b>h</b></i><sub><i>i</i></sub>=<mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup><mo>,</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="72"><i>a</i><sub><i>ij</i></sub>=<i>softmax</i>(<i>f</i>(<i><b>h</b></i><sub><i>i</i></sub><sub>-1</sub>,<i><b>h</b></i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>)),(2)</p>
                </div>
                <div class="p1">
                    <p id="73">其中,<i><b>W</b></i><sub><i>a</i></sub>为模型参数.</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">2.1.2 CNN判别模型</h4>
                <div class="p1">
                    <p id="75">利用CNN卷积神经网络作为判别器,将窗口大小设置为5<citation id="192" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,可以得出<i><b>h</b></i><sub><i>i</i></sub>新的特征表示<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>2</mn></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>2</mn></mrow></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></math></mathml>.(3)</p>
                </div>
                <div class="p1">
                    <p id="77">其中,<i><b>W</b></i><sub>c</sub>为CNN模型参数,在接下来的池化层,我们选用max-over-time pooling<citation id="193" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的方法选取出最大值<i><b>h</b></i><sub>new</sub>:</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">}</mo></mrow></math></mathml>.(4)</p>
                </div>
                <div class="p1">
                    <p id="79">该池化方法认为具有最高值的特征才是最重要的特征,有效地过滤掉信息量较少的单词组合,并且可以保证提取的特征与输入句子的长度无关.</p>
                </div>
                <div class="p1">
                    <p id="80">通过一个<i>softmax</i>层来将特征<i><b>h</b></i><sub>new</sub>映射到输出<i>D</i>(<i><b>h</b></i><sub>new</sub>)∈[0,1],以此来判断输入特征是否与专家标注数据特征分布一致.</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">2.1.3 模型目标</h4>
                <div class="p1">
                    <p id="82">我们采用了文献<citation id="194" type="reference">[<a class="sup">11</a>]</citation>中类似特征匹配的方法,设<i>S</i>为专家标注数据集,迭代优化生成式对抗网络模型目标函数为</p>
                </div>
                <div class="p1">
                    <p id="83">minimizing:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>D</mi></msub><mo>=</mo><mo>-</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>s</mi><mo>:</mo><mi>S</mi></mrow></msub><mspace width="0.25em" /><mrow><mi>ln</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mi>E</mi><msub><mrow></mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>:</mo><mi>p</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mrow><mi>ln</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">minimizing:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mi>L</mi><msub><mrow></mrow><mi>G</mi></msub><mo>=</mo><mtext>t</mtext><mtext>r</mtext><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mi>s</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub><mspace width="0.25em" /><mo>+</mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mo stretchy="false">(</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mi>s</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>+</mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>-</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub><mo stretchy="false">)</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">其中,<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub></mrow></math></mathml>和<i>Σ</i><sub><i>s</i></sub>分别表示专家标注数据和生成模型处理后的数据特征向量的协方差矩阵;<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>,</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub></mrow></math></mathml>分别表示专家标注数据和生成模型处理后的数据的平均特征,它们的值是从小批量数据里根据经验估算出来的.这里,<i>L</i><sub><i>G</i></sub>表示2个多元高斯分布<i>dtri</i>(<i>μ</i><sub><i>s</i></sub>,<i>Σ</i><sub><i>s</i></sub>)和<mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mi>t</mi><mi>r</mi><mi>i</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">μ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub><mo>,</mo><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></msub><mo stretchy="false">)</mo></mrow></math></mathml>之间的Jensen-Shannon差异.这样做的目的主要是从技术上为修改生成模型提供更强的信号,使得生成模型输出的特征分布与判别模型中的专家标注数据特征分布更加趋于一致<citation id="195" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="88">这里存在一个问题,即当生成模型的输出值为离散值时,判别模型的误差梯度无法利用反向传播算法回到生成模型,我们采用文献<citation id="196" type="reference">[<a class="sup">11</a>]</citation>所提到的方法将返回给生成模型BiLSTM的特征向量<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">v</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo stretchy="false">)</mo></mrow></math></mathml>表示为</p>
                </div>
                <div class="p1">
                    <p id="89"><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">v</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mtext>e</mtext></msub><mspace width="0.25em" /><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">V</mi><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>˚</mo><mi>L</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(7)</p>
                </div>
                <div class="p1">
                    <p id="90">其中,。表示元素积运算,<i><b>V</b></i>是用于计算单词分布的权重矩阵,<i><b>W</b></i><sub>e</sub>为模型参数,当<i>L</i>→∞时,该公式近似于BiLSTM的默认输入向量计算公式.</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>2.2 BiLSTM-Attention-CRF子模型</b></h4>
                <div class="p1">
                    <p id="92">由于领域内实体名称的多样性,以单词特征及句子特征作为特征学习的模型在进行命名实体识别任务时,可能会出现同一实体在同一文档内标记不一致问题.</p>
                </div>
                <div class="p1">
                    <p id="93">子模型BiLSTM-Attention-CRF在经典BiLSTM-CRF模型的基础上加入Attention机制来关注当前实体与文档中其他所有单词的相关性,得到该单词在文档层面的特征表示,以解决实体标记不一致问题.模型结构图如图1右侧所示.</p>
                </div>
                <div class="p1">
                    <p id="94">用<i>D</i>={<i>s</i><sub>1</sub>,<i>s</i><sub>2</sub>,…,<i>s</i><sub><i>m</i></sub>}表示文档,文档中的每一个句子<i>s</i><sub><i>i</i></sub>=(<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>w</i><sub><i>n</i></sub>),这里<i>w</i><sub><i>i</i></sub>表示单词.将文档<i>D</i>中所包含的<i>N</i>个单词作为BiLSTM的输入,得到单词<i>w</i><sub><i>i</i></sub>的新的表示<i><b>h</b></i>′<sub><i>i</i></sub> (此处<i><b>h</b></i>′<sub><i>i</i></sub>与式(1)中<i><b>h</b></i><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>u</mtext><mtext>r</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>的计算方法相同),并将其作为Attention层的输入,这里Attention层主要用来计算当前单词<i>w</i><sub><i>i</i></sub>与文档中其他单词<i>w</i><sub><i>j</i></sub>(<i>j</i>=1,2,…,<i>i</i>-1,<i>i</i>+1,…,<i>N</i>)的相关性,该Attention权重值<i>b</i><sub><i>ij</i></sub>可表示为</p>
                </div>
                <div class="p1">
                    <p id="95"><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>,(8)</p>
                </div>
                <div class="p1">
                    <p id="96"><i>f</i>(<i>w</i><sub><i>i</i></sub>,<i>w</i><sub><i>j</i></sub>)的计算方法如式(2)所示.</p>
                </div>
                <div class="p1">
                    <p id="97">此时,可以得出单词<i>w</i><sub><i>i</i></sub>基于文档层面的一个全局特征表示<i><b>r</b></i><sup>g</sup><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><msubsup><mrow></mrow><mi>i</mi><mtext>g</mtext></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi mathvariant="bold-italic">h</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>.(9)</p>
                </div>
                <div class="p1">
                    <p id="99">单词<i>w</i><sub><i>i</i></sub>在Attention层的输出<i><b>c</b></i><sub><i>i</i></sub>可表示为</p>
                </div>
                <div class="p1">
                    <p id="100"><i><b>c</b></i><sub><i>i</i></sub>=tanh(<i><b>W</b></i><sub>g</sub>[<i><b>r</b></i><sup>g</sup><sub><i>i</i></sub>,<i><b>h</b></i><sub><i>i</i></sub>]).(10)</p>
                </div>
                <div class="p1">
                    <p id="101">将<i><b>c</b></i><sub><i>i</i></sub>传递给更上层的CRF作为输入,这里CRF主要用来预测2个部分:一是计算每个<i><b>c</b></i><sub><i>i</i></sub>对应标签的得分<i>o</i><sub><i>i</i></sub>;二是通过转换矩阵<i><b>T</b></i>(用于定义2个连续标签的分数)和<i>o</i><sub><i>i</i></sub>采用维比特算法来计算出最佳标注序列,其计算过程为</p>
                </div>
                <div class="p1">
                    <p id="102"><i>o</i><sub><i>i</i></sub>=<i><b>Wc</b></i><sub><i>i</i></sub>,(11)</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>o</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>+</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">)</mo></mrow></math></mathml>,(12)</p>
                </div>
                <div class="p1">
                    <p id="104"><i>y</i><sup>result</sup>=arg max(<i>score</i>(<i>D</i>,<i>y</i>)),(13)</p>
                </div>
                <div class="p1">
                    <p id="105">其中,函数<i>score</i>()是用来计算输入文档<i>D</i> 的标签序列<i>y</i>={<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>,…,<i>y</i><sub><i>N</i></sub>}的分数,<i>y</i><sup>result</sup>是最终输出的标签序列的结果(即BIO标签),<i><b>W</b></i>表示模型参数.</p>
                </div>
                <div class="p1">
                    <p id="106">本文所提出的BiLSTM-Attention-CRF子模型除了可以用于识别新文档中的实体之外,还可以将其用于众包标注数据集中,对实体进行再次识别以提高众包标注数据集的质量.</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag"><b>3 实验及结果分析</b></h3>
                <div class="p1">
                    <p id="108">本文的实验目标主要是从2个方面来验证BiLSTM-Attention-CRF-crowd模型的有效性,在此我们将基线模型根据其要比较的任务不同分为2组:1)将本文所提出的模型和第1组基线模型应用在信息安全领域的众包标注数据上,来验证BiLSTM-Attention-CRF-crowd模型在整合共识标注方面优于其他基线模型的能力;2)将本文所提出的模型和第2组基线模型应用在信息安全领域的相关文献上进行特定实体识别,来验证BiLSTM-Attention-CRF-crowd模型对同一实体在同一文档中的标注一致能力,并且对该模型和第2组基线模型在领域命名实体识别任务上的性能做了对比.</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>3.1 数据来源</b></h4>
                <div class="p1">
                    <p id="110">本文实验所使用的数据集主要来自于信息安全领域,包括来自于we live security,threatpost等处的博客文章、CVE(common vulnerabilities and exposures)描述、微软安全公告以及信息安全类文章摘要,我们从中摘取了10 187条句子(其中连续段落包括20篇摘要、45篇博客文章、59段CVE描述以及50篇微软安全公告),将每条句子分配给3个注释者来完成,以此作为众包标注数据集.标注者只需要从句子中标注出4种类型的命名实体:product,vulnerability,attacker,version.此外,由2名专家来标注其中随机抽取的1 000条句子,以训练GAN模型中的判别模型.</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.2 基线模型分组</b></h4>
                <div class="p1">
                    <p id="112">将基线模型分为2组进行实验.</p>
                </div>
                <div class="p1">
                    <p id="113">第1组.学习众包标注数据的共同特征,我们考虑使用下面2个模型作为比较模型.</p>
                </div>
                <div class="p1">
                    <p id="114">1) 多数投票(majority vote, MV).即文献<citation id="197" type="reference">[<a class="sup">5</a>]</citation>提到的一种方法.</p>
                </div>
                <div class="p1">
                    <p id="115">2) Dawid&amp;Skene模型.即文献<citation id="198" type="reference">[<a class="sup">16</a>]</citation>用到的模型.</p>
                </div>
                <div class="p1">
                    <p id="116">第2组.在未标注文本上预测命名实体序列,考虑使用下面4个模型作为比较模型.</p>
                </div>
                <div class="p1">
                    <p id="117">1) BiLSTM-Attention-CRF.即文献<citation id="199" type="reference">[<a class="sup">8</a>]</citation>中用到的模型,使用未加处理的标注者标注数据直接训练.</p>
                </div>
                <div class="p1">
                    <p id="118">2) BiLSTM-Attention-CRF-VT.即文献<citation id="200" type="reference">[<a class="sup">8</a>]</citation>中用到的模型,使用通过多数投票法选择出的可用标注数据训练.</p>
                </div>
                <div class="p1">
                    <p id="119">3) Dawid&amp;Skene-LSTM.即文献<citation id="201" type="reference">[<a class="sup">18</a>]</citation>用到的模型.</p>
                </div>
                <div class="p1">
                    <p id="120">4) CRF-MA.即文献<citation id="202" type="reference">[<a class="sup">5</a>]</citation>用到的模型,我们使用了该文作者提供的源代码.</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>3.3 实验结果评价</b></h4>
                <div class="p1">
                    <p id="122">实验中所采用的评价指标分别为准确率(用<i>P</i>表示)、召回率(用<i>R</i>表示)以及<i>F</i>1值.</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">3.3.1 整合众包标注数据模型性能比较</h4>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909005_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 模型关于不同类型实体的性能对比" src="Detail/GetImg?filename=images/JFYZ201909005_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 模型关于不同类型实体的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909005_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Performance comparison of models with
 different types of entities</p>

                </div>
                <h4 class="anchor-tag" id="125" name="125">1) 本模型在众包标注数据集中对不同类型实体标注整合性能评价.</h4>
                <div class="p1">
                    <p id="126">为了验证本文提出模型对不同类型实体标注上的整合性能,针对3.1节提出的4种类型实体在众包标注数据集中的整合结果进行了对比.从图2中可以看出,BiLSTM-Attention-CRF-crowd模型在类型product和类型version上表现性能较好,主要原因在于类型product表示的类别是产品,一般情况下,这种类型的实体虽然属于领域内实体,但是对于大众来说认知度比较高,因此标注的准确率相对也比较高;而类型version有相对固定的模式,比如出现在产品名之后,通常用数字表示,对于这类有固定模式的实体,因为其特征更容易学习,因此模型表现的性能最好.类型vulnerability和类型attacker属于信息安全领域内相对较为专业的实体类型,在众包标注数据集中标注的准确率较低,并且没有固定的模式可以遵循,因此性能表现稍弱.</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">2) 本模型与其他比较模型的性能比较</h4>
                <div class="p1">
                    <p id="128">考虑使用各个模型从训练语料中获得的正确标注语句的正确率作为评价标准,正确率可计算为</p>
                </div>
                <div class="area_img" id="130">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201909005_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="131">实验结果如表1所示:</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表1 模型性能对比表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Model Performance Comparison</b></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />Method</td><td>Accuracy</td></tr><tr><td><br />MV<sup>[5]</sup></td><td>65.3</td></tr><tr><td><br />Dawid&amp;Skene<sup>[16]</sup></td><td>72.5</td></tr><tr><td><br />BiLSTM-Attention-CRF-crowd</td><td>78.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">由表1可以看出,多数投票(MV)的性能相对较差,这是因为领域的专业性以及标注者标注水平的高低分布不均,对于一些模糊性的实体识别很难达到统一;本文所提出的模型表现最好,该模型除了可以获得训练语料库中原有的正确标注语句之外,还可以将训练语料库中一些原本不正确的标注语句通过反复优化之后的生成模型生成与专家标注数据特征分布趋于一致的正样本数据,并且通过BiLSTM-Attention-CRF子模型的再次提取,提高了训练语料库中正确标注语句的正确率.</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">3.3.2 领域命名实体识别模型性能比较</h4>
                <div class="p1">
                    <p id="135">由于本文所提出的模型在进行命名实体识别任务时主要针对同一实体在同一文档中前后标记的不一致问题,因此我们需要从未标注语料库中选择段落或者文档作为输入.为保证实验的客观性,我们随机选择了50篇摘要、20篇博客以及20篇微软安全公告作为测试语料.</p>
                </div>
                <h4 class="anchor-tag" id="136" name="136">1) 各模型对实体标注一致性的性能比较</h4>
                <div class="p1">
                    <p id="137">本文从各文档中选取出4种信息安全领域内比较常见的实体,如表2所示:</p>
                </div>
                <div class="area_img" id="138">
                    <p class="img_tit"><b>表2 实体名及对应缩写表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Entity Name and Their Abbreviations</b></p>
                    <p class="img_note"></p>
                    <table id="138" border="1"><tr><td><br />Full Name</td><td>Abbreviation</td></tr><tr><td><br />Advanced Persistent Threat</td><td>APT</td></tr><tr><td><br />FireWall</td><td>FW</td></tr><tr><td><br />Zero day attack</td><td>0 Day Attack</td></tr><tr><td><br />Intrusion Detection Systems</td><td>IDS</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="139">由图3中可以看出BiLSTM-Attention-CRF-crowd模型的性能相对来说要优于其他模型,其中以在实体APT和实体IDS上性能表现最为突出,主要原因在于实体APT和实体IDS对应的实体在文档中出现次数相对较多,并且通常与整个文档的内容有密切的联系,此时通过Attention层所计算出的该单词与文档层面全局向量的关系更为密切,从而得出的特征表示更为显著,此时模型的性能相较于其他模型来说有明显提高.</p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909005_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 各模型性能比较图" src="Detail/GetImg?filename=images/JFYZ201909005_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 各模型性能比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909005_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Model performance comparison</p>

                </div>
                <h4 class="anchor-tag" id="141" name="141">2) 各模型对领域内命名实体识别综合性能比较</h4>
                <div class="p1">
                    <p id="142">由表3可以看出,就正确率而言,直接使用不加处理的众包标注数据作为训练数据所训练出的BiLSTM-Attention-CRF模型和BiLSTM-Attention-CRF-crowd模型的表现较为出色,这也意味着使用众包标注数据来对NER模型进行训练确实是可取的,而以多数投票法选择语料标注作为训练数据的BiLSTM-Attention-CRF-VT模型以及通过混淆矩阵和最大似然估计来确定正确标注的Dawid&amp;Skene-LSTM模型表现较为平庸.BiLSTM-Attention-CRF-VT模型表现不佳的原因可能是由于信息安全领域内文本语句的复杂性和专业性,很多实体是无法通过投票选取出来的,另外还因为投票选择所丢掉的上下文信息很可能是重要的,丢掉了这些上下文信息很可能就丢掉了重要的特征信息.Dawid&amp;Skene-LSTM模型则更注重对标注者标注质量的估计,但是事实上标注者的标注质量通常并非是稳定的,会受到各种情况的影响,另外该模型对初始值的设置也并不理想,影响最后结果收敛到最优解.</p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit"><b>表3 各模型综合性能评价表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comprehensive Performance Evaluation</b></p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td><br />Model</td><td><i>P</i></td><td><i>R</i></td><td><i>F</i>1</td></tr><tr><td><br />BiLSTM-Attention-CRF<sup>[8]</sup></td><td>87.7</td><td>80</td><td>83.67</td></tr><tr><td><br />CRF-MA<sup>[5]</sup></td><td>81.97</td><td>76</td><td>78.87</td></tr><tr><td><br />Dawid&amp;Skene-LSTM<sup>[18]</sup></td><td>79.23</td><td>74.48</td><td>76.78</td></tr><tr><td><br />BiLSTM-Attention-CRF-VT<sup>[8]</sup></td><td>80.7</td><td>75.1</td><td>77.8</td></tr><tr><td><br />BiLSTM-Attention-CRF-crowd</td><td>89.3</td><td>85.2</td><td>87.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="144">结合以上实验,本文所提出的对抗式学习模型BiLSTM-Attention-CRF-crowd的性能要优于本文所引用的其他模型,有较为出色的表现能力.</p>
                </div>
                <h3 id="145" name="145" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="146">本文的主要工作包括3个方面:1)通过GAN模型在给定的众包标注数据集上寻找出标注数据的共有特征以生成最佳的唯一共识标注,解决目前众包数据中准确率不高、标注的不一致性等问题;2)将这些通过GAN模型所生成的注释数据来作为训练数据,训练模型进行命名实体识别任务;3)提出BiLSTM-Attention-CRF-crowd模型解决统一实体在同一文档中的标注不一致问题.我们在信息安全领域的数据集上评估了本文所提出的模型,结果表明:其性能优于本文中所提到的其他作为基线的模型.</p>
                </div>
                <div class="p1">
                    <p id="147">目前,BiLSTM-Attention-CRF-crowd模型主要应用于对名词及名词性短语类型的实体进行识别,对于识别领域内一些有特殊要求的类型实体,例如安全领域本体UCO<citation id="203" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>中的consequence类,该类别下的实体类型通常为动词短语(如steal login credentials,control the system等),模型尚待进一步研究.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Design challenges and misconceptions in named entity recognition">

                                <b>[1]</b>Ratinov L,Roth D.Design challenges and misconceptions in named entity recognition[C] //Proc of the 13th Conf on Computational Natural Language Learning.Stroudsburg:ACL,2009:147- 155
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling">

                                <b>[2]</b>Finkel J R,Grenager T,Manning C.Incorporating non-local information into information extraction systems by Gibbs sampling[C] //Proc of the 43rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg:ACL,2005:363- 370
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Frustratingly Easy Domain Adaptation">

                                <b>[3]</b>Hal D III.Frustratingly easy domain adaptation[C] //Proc of the 45th Annual Meeting of the Association for Computa-tional Linguistics.Stroudsburg:ACL,2007:256- 263
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cheap and Fast-But is it Good?Evaluating Non-Expert Annotations for Natural Language Tasks">

                                <b>[4]</b>Snow R,O'Connor B,Jurafsky D,et al.Cheap and fast-but is it good?evaluating non-expert annotations for natural language tasks[C] //Proc of the Conf on Empirical Methods in Natural Language Processing.Stroudsburg:ACL,2008:254- 263
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14040800005327&amp;v=MDAyODhaT3NLRDM0K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUwzSUoxd1RheEk9Tmo3QmFySzhIdFhNcDQ5Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Rodrigues F,Pereira F,Ribeiro B.Sequence labeling with multiple annotators[J].Machine Learning,2014,95(2):165- 181
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition">

                                <b>[6]</b>Zhao Hai,Chunyu K.Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition[C] //Proc of the 6th SIGHAN Workshop on Chinese Language Processing.Stroudsburg:ACL,2008:106- 111
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">

                                <b>[7]</b>Huang Zhiheng,Xu Wei,Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J/OL].arXiv preprint arXiv:1508.0191 2015
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An attentive sequence model for adverse drug event extraction from biomedical text">

                                <b>[8]</b>Ramamoorthy S,Murugan S.An attentive sequence model for adverse drug event extraction from biomedical text[J].arXiv preprint arXiv:1801.0625 2018
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">

                                <b>[9]</b>Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Neural Information Processing System.New York:Curran Associates,2014:2672- 2680
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201802014&amp;v=MzAxMDZPZVplUnNGeS9uVkw3SU1UWFRiTEc0SDluTXJZOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Wang Wanliang,Li Zhuorong.Advance in generative adversarial network[J].Journal on Communications,2018,39(2):135- 148 (in Chinese)(王万良,李卓蓉.生成式对抗网络研究进展[J].通信学报,2018,39(2):135- 148)
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generating text via adversarial training">

                                <b>[11]</b>Zhang Yizhe,Gan Zhe,Lawrence C.Generating text via adversarial training[C] //Proc of the 30th Neural Information Processing Systems Workshop on Adversarial Training.New York:Curran Associate,2016:2852- 2858
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Seq GAN:sequence generative adversarial nets with policy gradient">

                                <b>[12]</b>Yu Lantao,Zhang Weinan,Wang Jun,et al.SeqGAN:Sequence generative adversarial nets with policy gradient[C] //Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2017.arXiv:1609.05473
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial learning for neural dialogue generation">

                                <b>[13]</b>Li Jiwei,Will M,Shi Tianlin,et al.Adversarial learning for neural dialogue generation[J].arXiv preprint arXiv1701.06547,2017
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GANS for sequences of discrete elements with the gumbel-softmax distribution">

                                <b>[14]</b>Kusner M J,Hernandeslobato J M.GANS for sequences of discrete elements with the gumbel-softmax distribution[J].arXiv preprint arXiv1611.04051,2016
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sequence learning from data with multiple labels[C/OL]">

                                <b>[15]</b>Dredze M,Talukdar P P,Crammer K.Sequence learning from data with multiple labels[C/OL] //Proc of ECML/PKDD Workshop on Learning from Multi-Label Data.2009:39- 48[2018-08-15].https://www.academia.edu/2809854/Sequence_learning_from_data_with_multiple_labels
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maximum likelihood estimation of observer error-rates using the EM algorithm">

                                <b>[16]</b>Dawid A P,Skene A M.Maximum likelihood estimation of observer error-rates using the EM algorithm[J].Applied Statistics,1979,28(1):20- 28
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A convex formulation for learning from crowds">

                                <b>[17]</b>Kajino H,Tsuboi Y,Kashima H.A convex formulation for learning from crowds[C] //Proc of the 26th AAAI on Artificial Intelligence.Menlo Park,CA:AAAI,2012:73- 79
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aggregating and predicting sequence labels from crowd annotations">

                                <b>[18]</b>Nguyen A T,Wallace B C,Li J J,et al.Aggregating and predicting sequence labels from crowd annotations[C] //Proc of the Association for Computational Linguistics.Strouds-burg:ACL,2017:299- 309
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial Learning for Chinese NER from Crowd Annotations">

                                <b>[19]</b>Yang Yaosheng,Zhang Meishan,Chen Wenliang,et al.Adversarial learning for Chinese NER from crowd annotations[C] //Proc of the 32nd AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2018:1627- 1634
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=tmChem:a high performance approach for chemical named entity recognition and normalization">

                                <b>[20]</b>Robert L,Chih-Hsuan W,Lu Zhiyong.tmChem:A high performance approach for chemical named entity recognition and normalization[J].Journal of Cheminformatics,2015,7(1):S1- S3
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition">

                                <b>[21]</b>Luo Ling,Yang Zhihao,Yang Pei,et al.An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition[J].Bioinformatics,2017,34(8):1381- 1388
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=UCO:A unified cybersecurity ontology">

                                <b>[22]</b>Syed Z,Padia A,Finin T,et al.UCO:A unified cybersecurity ontology[C] //Proc of the 36th AAAI Workshop on Artificial Intelligence for Cyber Security.Menlo Park,CA:AAAI,2016:1381- 1388
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201909005" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909005&amp;v=MDMwMzVxcUJ0R0ZyQ1VSTE9lWmVSc0Z5L25WN3ZBTHl2U2RMRzRIOWpNcG85RllZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raHF4d0pzaDFuTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

