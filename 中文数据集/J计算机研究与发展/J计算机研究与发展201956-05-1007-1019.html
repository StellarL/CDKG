

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128641411681250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201905011%26RESULT%3d1%26SIGN%3dTzwDnIUSx6AMYFGK0oDSBKwKItU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201905011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905011&amp;v=Mjk3OTlHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMeXZTZExHNEg5ak1xbzlFWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#98" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#100" data-title="&lt;b&gt;1.1 难度预测&lt;/b&gt;"><b>1.1 难度预测</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;1.2 文本建模&lt;/b&gt;"><b>1.2 文本建模</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="&lt;b&gt;2 数据驱动的试题难度预测模型&lt;/b&gt; "><b>2 数据驱动的试题难度预测模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#114" data-title="&lt;b&gt;2.1 问题定义&lt;/b&gt;"><b>2.1 问题定义</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;2.2 模型整体框架&lt;/b&gt;"><b>2.2 模型整体框架</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;2.3 模型结构&lt;/b&gt;"><b>2.3 模型结构</b></a></li>
                                                <li><a href="#186" data-title="&lt;b&gt;2.4 模型训练&lt;/b&gt;"><b>2.4 模型训练</b></a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;2.5 难度预测&lt;/b&gt;"><b>2.5 难度预测</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#202" data-title="&lt;b&gt;3 模型验证实验&lt;/b&gt; "><b>3 模型验证实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#203" data-title="&lt;b&gt;3.1 数据集介绍&lt;/b&gt;"><b>3.1 数据集介绍</b></a></li>
                                                <li><a href="#210" data-title="&lt;b&gt;3.2 实验评价指标&lt;/b&gt;"><b>3.2 实验评价指标</b></a></li>
                                                <li><a href="#230" data-title="&lt;b&gt;3.3 对比实验&lt;/b&gt;"><b>3.3 对比实验</b></a></li>
                                                <li><a href="#236" data-title="&lt;b&gt;3.4 实验结果及分析&lt;/b&gt;"><b>3.4 实验结果及分析</b></a></li>
                                                <li><a href="#250" data-title="&lt;b&gt;3.5 案例分析&lt;/b&gt;"><b>3.5 案例分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#255" data-title="&lt;b&gt;4 结 论&lt;/b&gt; "><b>4 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="&lt;b&gt;表1 试题关联知识点Q矩阵示例&lt;/b&gt;"><b>表1 试题关联知识点Q矩阵示例</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表2 数学试题示例&lt;/b&gt;"><b>表2 数学试题示例</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表3 答题记录示例&lt;/b&gt;"><b>表3 答题记录示例</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表4 试题难度预测问题涉及的符号及解释&lt;/b&gt;"><b>表4 试题难度预测问题涉及的符号及解释</b></a></li>
                                                <li><a href="#135" data-title="图1 模型框架图">图1 模型框架图</a></li>
                                                <li><a href="#142" data-title="图2 模型结构">图2 模型结构</a></li>
                                                <li><a href="#205" data-title="图4 6所学校在同场期末考试中的得分率">图4 6所学校在同场期末考试中的得分率</a></li>
                                                <li><a href="#206" data-title="&lt;b&gt;表5 数据集相关统计分析&lt;/b&gt;"><b>表5 数据集相关统计分析</b></a></li>
                                                <li><a href="#208" data-title="图3 试题特征长度分布">图3 试题特征长度分布</a></li>
                                                <li><a href="#239" data-title="图5 3种模型实验结果">图5 3种模型实验结果</a></li>
                                                <li><a href="#242" data-title="图6 对比实验结果">图6 对比实验结果</a></li>
                                                <li><a href="#248" data-title="图7 2种context划分方式实验结果">图7 2种context划分方式实验结果</a></li>
                                                <li><a href="#252" data-title="图8 某试卷3种模型预测得分率与真实值比较">图8 某试卷3种模型预测得分率与真实值比较</a></li>
                                                <li><a href="#254" data-title="&lt;b&gt;表6 案例分析各模型评价指标值&lt;/b&gt;"><b>表6 案例分析各模型评价指标值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="379">


                                    <a id="bibliography_1" title="Mao Jingfei.Exploration of difficulty prediction methods for questions in college entrance examination[J].Education Science, 2008, 24 (6) :22-26 (in Chinese) (毛竞飞.高考命题中试题难度预测方法探索[J].教育科学, 2008, 24 (6) :22-26) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYKO200806006&amp;v=MDc2NjJDVVJMT2VaZVJxRmlEZ1c3N0lMelRBWWJHNEh0bk1xWTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Mao Jingfei.Exploration of difficulty prediction methods for questions in college entrance examination[J].Education Science, 2008, 24 (6) :22-26 (in Chinese) (毛竞飞.高考命题中试题难度预测方法探索[J].教育科学, 2008, 24 (6) :22-26) 
                                    </a>
                                </li>
                                <li id="381">


                                    <a id="bibliography_2" title="Liu Qi, Chen Enhong, Zhu Tianyu, et al.Research on educational data mining for online intelligent learning[J].Pattern Recognition and Artificial Intelligence, 2018, 31 (1) :77-90 (in Chinese) (刘淇, 陈恩红, 朱天宇, 等.面向在线智慧学习的教育数据挖掘技术研究[J].模式识别与人工智能, 2018, 31 (1) :77-90) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201801009&amp;v=MjYxMDFEN1liTEc0SDluTXJvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUs=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Liu Qi, Chen Enhong, Zhu Tianyu, et al.Research on educational data mining for online intelligent learning[J].Pattern Recognition and Artificial Intelligence, 2018, 31 (1) :77-90 (in Chinese) (刘淇, 陈恩红, 朱天宇, 等.面向在线智慧学习的教育数据挖掘技术研究[J].模式识别与人工智能, 2018, 31 (1) :77-90) 
                                    </a>
                                </li>
                                <li id="383">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                    Liu Qi, Chen Enhong, Huang Zhenya, et al.Cognitive ability analysis of students for personalized learning[J].Communications of the CCF, 2017, 13 (4) :28-35 (in Chinese) (刘淇, 陈恩红, 黄振亚, 等.面向个性化学习的学生认知能力分析[J].计算机学会通讯, 2017, 13 (4) :28-35) </a>
                                </li>
                                <li id="385">


                                    <a id="bibliography_4" title="Fan Xitao.Item response theory and classical test theory:An empirical comparison of their item?person statistics[J].Educational and Psychological Measurement, 1998, 58 (3) :357-381" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Item Response Theory and Classical Test Theory: An Empirical Comparison of their Item/Person Statistics">
                                        <b>[4]</b>
                                        Fan Xitao.Item response theory and classical test theory:An empirical comparison of their item?person statistics[J].Educational and Psychological Measurement, 1998, 58 (3) :357-381
                                    </a>
                                </li>
                                <li id="387">


                                    <a id="bibliography_5" title="De La Torre J.DINA model and parameter estimation:Adidactic[J].Journal of Educational and Behavioral Statistics, 2009, 34 (1) :115-130" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DINA Model and Parameter Estimation: A Didactic">
                                        <b>[5]</b>
                                        De La Torre J.DINA model and parameter estimation:Adidactic[J].Journal of Educational and Behavioral Statistics, 2009, 34 (1) :115-130
                                    </a>
                                </li>
                                <li id="389">


                                    <a id="bibliography_6" title="Dong Shenghong, Qi Shuqing, Dai Haiqi, et al.Research on manual assignment methods for difficulty and distinction parameters[J].Testing Research, 2005, 1 (1) :25-32 (in Chinese) (董圣鸿, 漆书青, 戴海琦, 等.题目难度, 区分度参数人工赋值方法的研究[J].考试研究, 2005, 1 (1) :25-32) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KSYA200501004&amp;v=MjUwMTg3SUxqN1NiN0c0SHRUTXJvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        Dong Shenghong, Qi Shuqing, Dai Haiqi, et al.Research on manual assignment methods for difficulty and distinction parameters[J].Testing Research, 2005, 1 (1) :25-32 (in Chinese) (董圣鸿, 漆书青, 戴海琦, 等.题目难度, 区分度参数人工赋值方法的研究[J].考试研究, 2005, 1 (1) :25-32) 
                                    </a>
                                </li>
                                <li id="391">


                                    <a id="bibliography_7" title="Beck J, Stern M, Woolf B P.Using the student model to control problem difficulty[C]Proc of the 6th Int Conf on User Modeling.Berlin:Springer, 1997:277-288" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using the student model to control problem difficulty">
                                        <b>[7]</b>
                                        Beck J, Stern M, Woolf B P.Using the student model to control problem difficulty[C]Proc of the 6th Int Conf on User Modeling.Berlin:Springer, 1997:277-288
                                    </a>
                                </li>
                                <li id="393">


                                    <a id="bibliography_8" title="Kubinger K D, Gottschall C H.Item difficulty of multiple choice tests dependant on different item response formats--An experiment in fundamental research on psychological assessment[J].Psychology Science, 2007, 49 (4) :361-374" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Item difficulty of multiple choice tests dependant on different item response formats – An experiment in fundamental research on psychological assessment">
                                        <b>[8]</b>
                                        Kubinger K D, Gottschall C H.Item difficulty of multiple choice tests dependant on different item response formats--An experiment in fundamental research on psychological assessment[J].Psychology Science, 2007, 49 (4) :361-374
                                    </a>
                                </li>
                                <li id="395">


                                    <a id="bibliography_9" title="Wu Runze, Liu Qi, Liu Yuping, et al.Cognitive modelling for predicting examinee performance[C]Proc of the 24th Int Joint Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2015:1017-1024" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cognitive modelling for predicting examinee performance">
                                        <b>[9]</b>
                                        Wu Runze, Liu Qi, Liu Yuping, et al.Cognitive modelling for predicting examinee performance[C]Proc of the 24th Int Joint Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2015:1017-1024
                                    </a>
                                </li>
                                <li id="397">


                                    <a id="bibliography_10" title="Zhu Tianyu, Huang Zhenya, Chen Enhong, et al.Cognitive diagnosis based personalized question recommendation[J].Chinese Journal of Computers, 2017, 40 (1) :176-191 (in Chinese) (朱天宇, 黄振亚, 陈恩红, 等.基于认知诊断的个性化试题推荐方法[J].计算机学报, 2017, 40 (1) :176-191) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201701010&amp;v=MTk5MTZXNzdJTHo3QmRyRzRIOWJNcm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Zhu Tianyu, Huang Zhenya, Chen Enhong, et al.Cognitive diagnosis based personalized question recommendation[J].Chinese Journal of Computers, 2017, 40 (1) :176-191 (in Chinese) (朱天宇, 黄振亚, 陈恩红, 等.基于认知诊断的个性化试题推荐方法[J].计算机学报, 2017, 40 (1) :176-191) 
                                    </a>
                                </li>
                                <li id="399">


                                    <a id="bibliography_11" title="DiBello L V, Roussos L A, Stout W.31a review of cognitively diagnostic assessment and a summary of psychometric models[J].Handbook of Statistics, 2007, 26:979-1030" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702265773&amp;v=MDY4MTd1MEtDM3M2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0ZzY2F4ST1OaWZPZmJLN0h0RE5xSTlIWg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        DiBello L V, Roussos L A, Stout W.31a review of cognitively diagnostic assessment and a summary of psychometric models[J].Handbook of Statistics, 2007, 26:979-1030
                                    </a>
                                </li>
                                <li id="401">


                                    <a id="bibliography_12" title="Zhang Xiao, Sha Ruxue.Research advance in DINA model of cognitive diagnosis[J].China Examinations, 2013 (1) :32-37 (in Chinese) (张潇, 沙如雪.认知诊断DINA模型研究进展[J].中国考试, 2013 (1) :32-37) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KSYJ201301007&amp;v=MTMxNzMzenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMajdTWkxHNEg5TE1ybzlGWTRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Zhang Xiao, Sha Ruxue.Research advance in DINA model of cognitive diagnosis[J].China Examinations, 2013 (1) :32-37 (in Chinese) (张潇, 沙如雪.认知诊断DINA模型研究进展[J].中国考试, 2013 (1) :32-37) 
                                    </a>
                                </li>
                                <li id="403">


                                    <a id="bibliography_13" title="Maris E.Estimating multiple classification latent class models[J].Psychometrika, 1999, 64 (2) :187-212" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001076879&amp;v=MDUwNDN0RkN6a1c3ckFJVjQ9Tmo3QmFyTzRIdEhOcjRoRGJPd0dZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVk&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Maris E.Estimating multiple classification latent class models[J].Psychometrika, 1999, 64 (2) :187-212
                                    </a>
                                </li>
                                <li id="405">


                                    <a id="bibliography_14" title="Wu Ruize, Xu Guandong, Chen Enhong, et al.Knowledge or gaming?:Cognitive modelling based on multiple-attempt response[C]Proc of the 26th Int Conf on World Wide Web Companion.New York:ACM, 2017:321-329" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge or gaming?:Cognitive modelling based on multiple-attempt response">
                                        <b>[14]</b>
                                        Wu Ruize, Xu Guandong, Chen Enhong, et al.Knowledge or gaming?:Cognitive modelling based on multiple-attempt response[C]Proc of the 26th Int Conf on World Wide Web Companion.New York:ACM, 2017:321-329
                                    </a>
                                </li>
                                <li id="407">


                                    <a id="bibliography_15" title="Chen Yuying, Liu Qi, Huang Zhenya, et al.Tracking knowledge proficiency of students with educational priors[C]Proc of the 26th ACM Conf on Information and Knowledge Management.New York:ACM, 2017:989-998" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tracking knowledge proficiency of students with educational priors">
                                        <b>[15]</b>
                                        Chen Yuying, Liu Qi, Huang Zhenya, et al.Tracking knowledge proficiency of students with educational priors[C]Proc of the 26th ACM Conf on Information and Knowledge Management.New York:ACM, 2017:989-998
                                    </a>
                                </li>
                                <li id="409">


                                    <a id="bibliography_16" title="Huang Zhenya, Liu Qi, Chen Enhong, et al.Question difficulty prediction for reading problems in standard tests[C]Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:1352-1359" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Question Difficulty Prediction for READING Problems in Standard Tests">
                                        <b>[16]</b>
                                        Huang Zhenya, Liu Qi, Chen Enhong, et al.Question difficulty prediction for reading problems in standard tests[C]Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:1352-1359
                                    </a>
                                </li>
                                <li id="411">


                                    <a id="bibliography_17" title="Wang Weiqiang, Gao Wen, Duan Lijuan.Text mining on the Internet[J].Computer Science, 2000, 27 (4) :32-36 (in Chinese) (王伟强, 高文, 段立娟.Internet上的文本数据挖掘[J].计算机科学, 2000, 27 (4) :32-36) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA200004009&amp;v=MTQ1MjZHNEh0SE1xNDlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMejdCYjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Wang Weiqiang, Gao Wen, Duan Lijuan.Text mining on the Internet[J].Computer Science, 2000, 27 (4) :32-36 (in Chinese) (王伟强, 高文, 段立娟.Internet上的文本数据挖掘[J].计算机科学, 2000, 27 (4) :32-36) 
                                    </a>
                                </li>
                                <li id="413">


                                    <a id="bibliography_18" title="Wei Shunping.Learning analysis technology:Mining educational data’s value in the era of big data[J].Modern Educational Technology, 2013, 2 (23) :5-11 (in Chinese) (魏顺平.学习分析技术:挖掘大数据时代下教育数据的价值[J].现代教育技术, 2013, 2 (23) :5-11) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XJJS201302003&amp;v=MjYyMzVGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lQU2ZCZmJHNEg5TE1yWTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Wei Shunping.Learning analysis technology:Mining educational data’s value in the era of big data[J].Modern Educational Technology, 2013, 2 (23) :5-11 (in Chinese) (魏顺平.学习分析技术:挖掘大数据时代下教育数据的价值[J].现代教育技术, 2013, 2 (23) :5-11) 
                                    </a>
                                </li>
                                <li id="415">


                                    <a id="bibliography_19" title="Yang Pei, Yang Zhihao, Luo Ling, et al.An attention-based approach for chemical compound and drug named entity recognition[J].Journal of Computer Research and Development, 2018, 55 (7) :1548-1556 (in Chinese) (杨培, 杨志豪, 罗凌, 等.基于注意机制的化学药物命名实体识别[J].计算机研究与发展, 2018, 55 (7) :1548-1556) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201807017&amp;v=MzE3NjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMeXZTZExHNEg5bk1xSTlFWTRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Yang Pei, Yang Zhihao, Luo Ling, et al.An attention-based approach for chemical compound and drug named entity recognition[J].Journal of Computer Research and Development, 2018, 55 (7) :1548-1556 (in Chinese) (杨培, 杨志豪, 罗凌, 等.基于注意机制的化学药物命名实体识别[J].计算机研究与发展, 2018, 55 (7) :1548-1556) 
                                    </a>
                                </li>
                                <li id="417">


                                    <a id="bibliography_20" title="Zhang Ying, Wang Chao, Guo Wenya, et al.Multi-source emotion tagging for online news comments using bidirectional hierarchical semantic representation model[J].Journal of Computer Research and Development, 2018, 55 (5) :933-944 (in Chinese) (张莹, 王超, 郭文雅, 等.基于双向分层语义模型的多源新闻评论情绪预测[J].计算机研究与发展, 2018, 55 (5) :933-944) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805005&amp;v=MTU5OTE0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUx5dlNkTEc0SDluTXFvOUZZWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Zhang Ying, Wang Chao, Guo Wenya, et al.Multi-source emotion tagging for online news comments using bidirectional hierarchical semantic representation model[J].Journal of Computer Research and Development, 2018, 55 (5) :933-944 (in Chinese) (张莹, 王超, 郭文雅, 等.基于双向分层语义模型的多源新闻评论情绪预测[J].计算机研究与发展, 2018, 55 (5) :933-944) 
                                    </a>
                                </li>
                                <li id="419">


                                    <a id="bibliography_21" title="Gao Yunlong, Zuo Wanli, Wang Ying, et al.Sentence classification model based on sparse and self-taught convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (1) :179-187 (in Chinese) (高云龙, 左万利, 王英, 等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展, 2018, 55 (1) :179-187) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801016&amp;v=MDM3NTdCdEdGckNVUkxPZVplUnFGaURnVzc3SUx5dlNkTEc0SDluTXJvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Gao Yunlong, Zuo Wanli, Wang Ying, et al.Sentence classification model based on sparse and self-taught convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (1) :179-187 (in Chinese) (高云龙, 左万利, 王英, 等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展, 2018, 55 (1) :179-187) 
                                    </a>
                                </li>
                                <li id="421">


                                    <a id="bibliography_22" title="Chen Ke, Liang Bin, Ke Wende, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957 (in Chinese) (陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805006&amp;v=MTM2Mjc0SDluTXFvOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUx5dlNkTEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Chen Ke, Liang Bin, Ke Wende, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957 (in Chinese) (陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957) 
                                    </a>
                                </li>
                                <li id="423">


                                    <a id="bibliography_23" title="Miner G, Elder IV J, Hill T.Practical Text Mining and Statistical Analysis for Non-Structured Text Data Applications[M].Amsterdam, Netherlands:Academic Press, 2012" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Practical Text Mining and Statistical Analysis for Non-Structured Text Data Applications">
                                        <b>[23]</b>
                                        Miner G, Elder IV J, Hill T.Practical Text Mining and Statistical Analysis for Non-Structured Text Data Applications[M].Amsterdam, Netherlands:Academic Press, 2012
                                    </a>
                                </li>
                                <li id="425">


                                    <a id="bibliography_24" title="Mikolov T, Sutskever I, Chen Kai, et al.Distributed representations of words and phrases and their compositionality[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MITPress, 2013:3111-3119" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">
                                        <b>[24]</b>
                                        Mikolov T, Sutskever I, Chen Kai, et al.Distributed representations of words and phrases and their compositionality[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MITPress, 2013:3111-3119
                                    </a>
                                </li>
                                <li id="427">


                                    <a id="bibliography_25" title="Le Q, Mikolov T.Distributed representations of sentences and documents[C]Proc of the 31st Int Conf on Machine Learning.New York:ACM, 2014:1188-1196" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of sentences and documents">
                                        <b>[25]</b>
                                        Le Q, Mikolov T.Distributed representations of sentences and documents[C]Proc of the 31st Int Conf on Machine Learning.New York:ACM, 2014:1188-1196
                                    </a>
                                </li>
                                <li id="429">


                                    <a id="bibliography_26" title="LeCun Y, Bottou L, Bengio Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">
                                        <b>[26]</b>
                                        LeCun Y, Bottou L, Bengio Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324
                                    </a>
                                </li>
                                <li id="431">


                                    <a id="bibliography_27" title="Graves A, Liwicki M, Fern&#225;ndez S, et al.A novel connectionist system for unconstrained handwriting recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (5) :855-868" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel connectionist system for unconstrained handwriting recognition">
                                        <b>[27]</b>
                                        Graves A, Liwicki M, Fern&#225;ndez S, et al.A novel connectionist system for unconstrained handwriting recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (5) :855-868
                                    </a>
                                </li>
                                <li id="433">


                                    <a id="bibliography_28" title="Cambria E, Gastaldo P, Bisio F, et al.An ELM-based model for affective analogical reasoning[J].Neurocomputing, 2015, 149:443-455" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700312704&amp;v=MDkzMzJaK29OQzN3OW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGc2NheEk9TmlmT2ZiSzhIOURNcUk5Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[28]</b>
                                        Cambria E, Gastaldo P, Bisio F, et al.An ELM-based model for affective analogical reasoning[J].Neurocomputing, 2015, 149:443-455
                                    </a>
                                </li>
                                <li id="435">


                                    <a id="bibliography_29" title="Bowman S R, Angeli G, Potts C, et al.A large annotated corpus for learning natural language inference[EB?OL]. (2015-08-21) [2018-08-17].https:arxiv.org?abs?1508.05326" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A large annotated corpus for learning natural language inference">
                                        <b>[29]</b>
                                        Bowman S R, Angeli G, Potts C, et al.A large annotated corpus for learning natural language inference[EB?OL]. (2015-08-21) [2018-08-17].https:arxiv.org?abs?1508.05326
                                    </a>
                                </li>
                                <li id="437">


                                    <a id="bibliography_30" title="Yin Wenpeng, Ebert S, Sch&#252;tze H.Attention-based convolutional neural network for machine comprehension[EB?OL]. (2016-02-13) [2018-08-17].https:arxiv.org?abs?1602.04341" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based convolutional neural network for machine comprehension[EB?OL]">
                                        <b>[30]</b>
                                        Yin Wenpeng, Ebert S, Sch&#252;tze H.Attention-based convolutional neural network for machine comprehension[EB?OL]. (2016-02-13) [2018-08-17].https:arxiv.org?abs?1602.04341
                                    </a>
                                </li>
                                <li id="439">


                                    <a id="bibliography_31" title="Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=Mjk5MDZqbVVMdkpLRnNjYXhJPU5pZkpaYks5SHRqTXFvOUZaT29MRFhVeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[31]</b>
                                        Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780
                                    </a>
                                </li>
                                <li id="441">


                                    <a id="bibliography_32" title="Gers F A, Schmidhuber J, Cummins F.Learning to forget:Continual prediction with LSTM[J].Neural Computation, 2000, 12 (10) :2451-2471" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011769&amp;v=MDU1MTFKWmJLOUh0ak1xbzlGWk9vT0Mzb3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRnNjYXhJPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[32]</b>
                                        Gers F A, Schmidhuber J, Cummins F.Learning to forget:Continual prediction with LSTM[J].Neural Computation, 2000, 12 (10) :2451-2471
                                    </a>
                                </li>
                                <li id="443">


                                    <a id="bibliography_33" title="Benesty J, Chen Jingdong, Huang Yiteng, et al.Noise Reduction in Speech Processing[M].Berlin:Springer, 2009:37-40" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Noise Reduction in Speech Processing">
                                        <b>[33]</b>
                                        Benesty J, Chen Jingdong, Huang Yiteng, et al.Noise Reduction in Speech Processing[M].Berlin:Springer, 2009:37-40
                                    </a>
                                </li>
                                <li id="445">


                                    <a id="bibliography_34" title="Liu Qi, Chen Enhong, Xiong Hui, et al.Enhancing collaborative filtering by user interest expansion via personalized ranking[J].IEEE Transactions on Systems, Man, and Cybernetics:Part B, 2012, 42 (1) :218-233" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancing Collaborative Filtering by User Interest Expansion via Personalized Ranking">
                                        <b>[34]</b>
                                        Liu Qi, Chen Enhong, Xiong Hui, et al.Enhancing collaborative filtering by user interest expansion via personalized ranking[J].IEEE Transactions on Systems, Man, and Cybernetics:Part B, 2012, 42 (1) :218-233
                                    </a>
                                </li>
                                <li id="447">


                                    <a id="bibliography_35" title="Cox D R.The regression analysis of binary sequences[J].Journal of the Royal Statistical Society:Series B, 1958, 20 (2) :215-242" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603922913&amp;v=MzEyNjlMdkpLRnNjYXhJPU5pZlllcks4SDlQTXFZOUdiZWtOQlgwNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[35]</b>
                                        Cox D R.The regression analysis of binary sequences[J].Journal of the Royal Statistical Society:Series B, 1958, 20 (2) :215-242
                                    </a>
                                </li>
                                <li id="449">


                                    <a id="bibliography_36" title="Drucker H, Burges C J C, Kaufman L, et al.Support vector regression machines[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 1997:155-161" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Support vector regression machines">
                                        <b>[36]</b>
                                        Drucker H, Burges C J C, Kaufman L, et al.Support vector regression machines[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 1997:155-161
                                    </a>
                                </li>
                                <li id="451">


                                    <a id="bibliography_37" title="Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MTcyODhIdEhOckl0Rlp1d09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDemtXN3JBSVY0PU5qN0Jhck80&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[37]</b>
                                        Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(05),1007-1019 DOI:10.7544/issn1000-1239.2019.20180366            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>数据驱动的数学试题难度预测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%9F%E5%A8%81&amp;code=41873588&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">佟威</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E9%A3%9E&amp;code=10335950&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%B7%87&amp;code=24386328&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘淇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%81%A9%E7%BA%A2&amp;code=14554511&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈恩红</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0002522&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学技术大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现代化国家题库系统建设是教育考试改革发展的重要保障, 也是促进我国教育考试现代化的重要手段.试题难度是入库试题的核心参数, 对于命题、组卷、分数报告甚至是考试公平性保障都有着直接影响.由于我国国家考试的特点, 很难通过类似国外考试机构的考前试测等方式提前获取试题难度参数, 传统的试题难度评估任务通常由人工完成, 即由命题专家对试题难度进行评估.这样的做法耗时耗力, 且难以保证客观性, 因此借助先进信息技术手段探索试题难度的自动化判断具有较大的研究意义, 更是体现着中国特色教育考试背景下的中国智慧和中国解决方案.以利用试题文本和答题记录数据实现数据驱动的数学试题难度自动化预测模型为目标, 提出了分别基于卷积神经网络 (convolutional neural network, CNN) 和循环神经网络 (recurrent neural network, RNN) 的数学试题难度预测模型C-MIDP (CNN for mathematical item difficulty prediction) 和R-MIDP (RNN for mathematical item difficulty prediction) , 以及二者的混合模型H-MIDP (hybrid model for mathematical item difficulty prediction) .具体地, 利用所提出的模型直接学习试题文本表征, 将考试试题得分率作为标签训练模型, 整个过程不需要提供知识标注等教育先验信息.然后, 考虑到不同考试中学生群体的不可比性, 在训练时提出一种基于context的训练方式;最后, 可通过输入试题特征到训练好的模型中进行难度预测.模型在真实的试题数据上取得了较好的实验结果.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%99%E8%82%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">教育;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%98%E5%BA%93&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">题库;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%BE%E5%BA%A6%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">难度预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本挖掘;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *刘淇, qiliuql@ustc.edu.cn;
                                </span>
                                <span>
                                    佟威, tongw@mail.neea.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>全国教育科学规划基金项目 (FCB160610);</span>
                                <span>国家自然科学基金项目 (61672483, U1605251);</span>
                                <span>中国科协青年人才托举工程&amp;CCF青年人才发展计划项目 (CCF-QNRCFZ (17-19) 03);</span>
                                <span>中国科学院青年创新促进会会员专项基金项目 (2014299);</span>
                    </p>
            </div>
                    <h1><b>Data Driven Prediction for the Difficulty of Mathematical Items</b></h1>
                    <h2>
                    <span>Tong Wei</span>
                    <span>Wang Fei</span>
                    <span>Liu Qi</span>
                    <span>Chen Enhong</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, University of Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The construction of item banking system is an important guarantee for the reform and development of educational examination, and meanwhile, is also an essential means to promote the modernization of examination. In such a system, item difficulty is one of the most important parameters, which has a direct influence on item designing, test paper organization, result report and even the fairness guarantee. Unfortunately, due to the unique education background and test characteristics in China, it is difficult to evaluate item difficulty through pre-test organization like some foreign countries. Thus, traditional efforts usually refer to the manual evaluation by expertise (e.g., experienced teachers) . However, this way tends to be laborious, time-consuming and subjective in some way. Therefore, it is of great value to automatically judge the difficulty of items by information technology. Along this line, in this paper, we aim to propose a data-driven solution to predict the item difficulty in mathematics leveraged by the historical test logs and the corresponding item materials. Specifically, we propose a C-MIDP model and a R-MIDP model, which are based on CNN and RNN respectively, and further a hybrid H-MIDP model combined with both C-MIDP and R-MIDP. In the models, we directly learn item sematic representation from its text and train its difficulty with the statistic score rates among tests, where the whole modeling do not need any expertise, such as knowledge labeling. Then, we adopt a context-dependent training strategy considering the incomparability between different groups. Finally, with the trained models, we can predict each item difficulty only with its text input. Extensive experiments on a real-world dataset demonstrate that the proposed models perform very well.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=education&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">education;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=item%20banking%20system&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">item banking system;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=difficulty%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">difficulty prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text mining;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Tong Wei, born in 1984.PhD candidate. His main research interests include statistics, data analysis in education database.<image id="296" type="formula" href="images/JFYZ201905011_29600.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Fei, born in 1997. Master candidate. His main research interests include data mining and deep learning.<image id="299" type="formula" href="images/JFYZ201905011_29900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Liu Qi, born in 1986.PhD, associate professor. His main research interests include data mining and knowledge discovery in database, machine learning method and application.<image id="304" type="formula" href="images/JFYZ201905011_30400.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Chen Enhong, born in 1968. PhD, professor and PhD supervisor.His main research interests include data mining and machine learning, social network analysis, and recommender systems.<image id="303" type="formula" href="images/JFYZ201905011_30300.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-05-22</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Fund for National Plan of Education Science (FCB160610);</span>
                                <span>the National Natural Science Foundation of China (61672483, U1605251);</span>
                                <span>the Young Talent Promotion Program of China Association for Science and Technology&amp;the Young Talent Development Program of CCF (CCF-QNRCFZ (17-19) 03);</span>
                                <span>the Special for the Member of Youth Innovation Promotion Association of Chinese Academy of Sciences (2014299);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="81">教育是人才培养的重要途径, 而考试自古以来就是评价教育成果、进行人才选拔的重要方式, 在国家经济社会发展中发挥着重要的作用.党和国家高度重视教育工作, 提出了加快建设教育现代化、建设教育强国以及办好人民满意的教育的总体要求.新时代的教育考试改革要紧密结合当前和今后一个时期国家和社会层面对人才价值的需求和判断, 紧密结合先进的信息技术手段, 为新一轮高考改革和政策制定提供更多的体现着中国智慧的中国解决方案.</p>
                </div>
                <div class="p1">
                    <p id="82">长久以来, 试题难度, 特别是高考试题难度, 都是教育考试国家题库建设, 甚至全社会重点关注的指标参数, 对保障考试安全平稳顺利实施、服务高校人才选拔、合理引导中学教学都有关键影响.如今教育越来越受重视, 对教育质量的要求逐渐增加, 如何高效、准确地评估试题难度自然也成为了一个重要的研究问题.</p>
                </div>
                <div class="p1">
                    <p id="83">传统方法中, 试题难度评估大多是由人工进行<citation id="453" type="reference"><link href="379" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.通常考试的命题人员和审校人员由具有充足专业知识和丰富教学经验的老师或专家担任, 在设计试题时除了考虑涵盖的必备知识和关键能力等内容相关的属性和维度, 也需要控制试题难度在合理范围, 命题和审校人员以自身知识和经验评估试题难度.另外也有以试测的形式请部分样本学生试做样题, 根据学生实际答题情况评估试题难度, 之后对样题稍作更改和重组投入使用, 例如TOEFL考试和SAT (scholastic assessment test) 考试题等<citation id="454" type="reference"><link href="379" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="84">在教育数据挖掘领域, 试题评估是一个重要的研究方向, 现有方法已经对试题多种参数 (如难度、区分度、猜测度等) 进行了评估分析<citation id="457" type="reference"><link href="381" rel="bibliography" /><link href="383" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>.其中应用最为广泛的是来自教育心理学的认知诊断理论.认知诊断通过利用学生答题记录对学生试题得分进行建模, 从而评估试题参数和学生能力.常见的认知诊断模型包括基于项目反映理论 (item response theory, IRT) <citation id="455" type="reference"><link href="385" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的潜在特质模型和以DINA (deterministic inputs, noisy “and” gate) 模型<citation id="456" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>为代表的潜在分类模型等.其中IRT通过类逻辑斯蒂回归模型, 结合学生的潜在能力, 可以评估试题在难度、区分度和猜测度属性上的数值;而DINA进一步结合Q矩阵 (或称“试题关联知识点矩阵”) , 且将学生能力描述成多维知识点掌握向量, 建模学生得分, 可以得到试题失误率、猜测率等参数.其中Q矩阵是人工标注的用以表示试题包含知识点的矩阵.表1是一个简单的Q矩阵示例, 其中每一行代表一个试题, 每一列代表一个知识点.如表1第1行表示试题<i>q</i><sub>1</sub>包含知识点<i>s</i><sub>1</sub>和<i>s</i><sub>4</sub>, 但不包含知识点<i>s</i><sub>2</sub>和<i>s</i><sub>3</sub>.Q矩阵的完备性将影响到建模结果的准确性, 然而Q矩阵通常由人工提供, 因此其完备性也常常难以保证.另外, 也有学者通过特征工程的方式, 提取试题诸如考察点、迷惑性、复杂性等特征后利用机器学习方法 (如线性回归、神经网络等) 实现难度预测<citation id="458" type="reference"><link href="379" rel="bibliography" /><link href="389" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">6</a>]</sup></citation>.</p>
                </div>
                <div class="area_img" id="85">
                    <p class="img_tit"><b>表1 试题关联知识点Q矩阵示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Example of Item Associated Q-matrix</b></p>
                    <p class="img_note"></p>
                    <table id="85" border="1"><tr><td rowspan="2"><br />Item</td><td colspan="4"><br />Knowledge Points</td></tr><tr><td><br /><i>s</i><sub>1</sub></td><td><i>s</i><sub>2</sub></td><td><i>s</i><sub>3</sub></td><td><i>s</i><sub>4</sub></td></tr><tr><td><br /><i>q</i><sub>1</sub></td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td><br /><i>q</i><sub>2</sub></td><td>0</td><td>1</td><td>1</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="86">然而, 不论是传统的人工评估, 还是现有的认知诊断或机器学习建模, 在国家教育日益深化改革的背景下, 应对试题难度预测这个问题上, 都有各自的局限性, 具体体现在3个方面:</p>
                </div>
                <div class="p1">
                    <p id="87">1) 人力、时间消耗大.人工的试题难度评估较为耗时耗力, 而入库试题资源量庞大, 且某些学科试题更迭频繁, 这些都使得纯人工的试题难度预测变得不切实际.且认知诊断中的Q矩阵也由人工标注, 同样需要消耗较多的人力与时间.</p>
                </div>
                <div class="p1">
                    <p id="88">2) 对先验知识的依赖.人工的试题难度评估结果除试题本身外, 很大程度上依赖于评估者自身的水平和对试题的认知程度;同样, 认知诊断模型通常也需要预先提供试题的Q矩阵.这些都使得评估或预测结果客观性或准确性不足.</p>
                </div>
                <div class="p1">
                    <p id="89">3) 特征工程中人工定义的特征较为缺少试题语义, 是试题的浅层表示.且部分特征 (如试题复杂性、灵活性、干扰性等) 的判定仍然需要人工进行, 非客观性和界限模糊等问题同样存在.</p>
                </div>
                <div class="p1">
                    <p id="90">我国国家考试具有高利害性、社会关注度极高等特点, 很难通过考前试测等方式提前获取试题难度参数, 目前仍然按照传统的试题难度评估方式, 由人工进行<citation id="459" type="reference"><link href="379" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.随着大数据、人工智能时代的到来, 众多先进的机器学习、深度学习算法为国家题库现代化建设和入库试题的难度参数估计赋予了更多方法和途径.基于人工智能的试题难度预测以往年产生的大量数据作为训练样本, 能够有效解决试题安全保密要求和试测曝光两者之间的矛盾, 有效调整传统人工估计难度中存在的偏差和波动.要实现高效、准确的试题难度评估, 需要解决3个挑战:</p>
                </div>
                <div class="p1">
                    <p id="91">1) 如何从包含复杂语义的试题文本出发, 挖掘其中可用于难度预测的重要信息.高效的试题难度预测自动化方法应尽量避免知识点标注等人工劳动, 因此要求模型具有较强的文本信息挖掘能力.</p>
                </div>
                <div class="p1">
                    <p id="92">2) 如何减少人工干预, 使得评价结果更加客观.诸如试题知识点标注或经验性的特征设计等都难以避免地引入个人倾向, 使得结果客观性难以保证.</p>
                </div>
                <div class="p1">
                    <p id="93">3) 如何克服不同考生群体在不同试卷版本中作答数据的比较.这些数据得到的试题得分率往往具有样本依赖性, 实际难度差异很大的试题从数据呈现的结果来看可能非常接近, 反之亦然.如果不能克服这个问题, 预估结果会出现很大误差.</p>
                </div>
                <div class="p1">
                    <p id="94">各项考试, 特别是国家考试, 都在一定程度上存在此类问题.本文从数学试题难度预测着手, 提出了针对数学试题的模型C-MIDP (CNN for mathematical item difficulty prediction) , R-MIDP (RNN for mathe-matical item difficulty prediction) 和H-MIDP (hybrid model for mathematical item difficulty prediction) , 利用试题文本和学生答题记录进行难度预测.3种模型均为神经网络结构, 其中C-MIDP以CNN (convolutional neural network) 为基础, R-MIDP以RNN (recurrent neural network) 为基础, H-MIDP则为二者的混合模型.难度的预测分为3步:1) 使用word2vec词向量对训练集的试题文本进行表征, 作为模型输入.以word2vec词向量构建的试题表征, 可以较好地保留试题语义, 使得神经网络能够基于试题文本自身挖掘出重要信息, 同时保证客观性.2) 从答题记录中获取各场考试中试题的得分率, 考虑得分率的适用范围, 设计context相关的方式进行模型训练, 将“以偏概全”变为“以小见大”.3) 将需要预测难度的试题文本进行表征, 输入到训练好的模型中, 获得难度预测值.本文的主要贡献点有3个方面:</p>
                </div>
                <div class="p1">
                    <p id="95">1) 提出针对数学试题的难度预测模型, 实现高效的数学试题难度预测, 并在真实数据集上取得了较好的实验结果;</p>
                </div>
                <div class="p1">
                    <p id="96">2) 模型是数据驱动的, 训练和预测都不需要人工提供关于试题的先验知识, 提高了预测结果的客观性, 且因减少了人工参与因而提高了预测效率;</p>
                </div>
                <div class="p1">
                    <p id="97">3) 考虑到不同考试中学生群体能力的差异性, 训练时采用的是context相关的训练方式, 提高了预测的准确率.</p>
                </div>
                <h3 id="98" name="98" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="99">本节将从难度预测和文本建模2个方面介绍相关工作.</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"><b>1.1 难度预测</b></h4>
                <div class="p1">
                    <p id="101">传统教育中, 难度评估大多是人工进行的.教育者利用自己的知识储备和教学经验评估试题难度, 以设计或选择合适的试题, 评估的结果通常随评估者知识、经验的差异出现不同.</p>
                </div>
                <div class="p1">
                    <p id="102">在教育学领域中, 有学者研究影响试题难度的具体因素, 如Beck等人<citation id="460" type="reference"><link href="391" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>认为试题特征和学生能力都是试题难度的影响因素.在试题方面, Kubinger等人<citation id="461" type="reference"><link href="393" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>指出试题类型、试题结构以及知识深度等因素都与试题难度有关;而在学生能力方面, 也有许多理论和模型被提出, 其中认知诊断是重要的研究方向, 其目标是利用试题和学生的答题记录, 对学生的学习过程进行建模, 挖掘学生对知识或技能的掌握程度.</p>
                </div>
                <div class="p1">
                    <p id="103">在教育数据挖掘领域, 认知诊断是一类重要的研究方向, 其目标是利用试题和学生的答题记录, 对学生的学习过程进行建模, 挖掘学生对知识或技能的掌握程度, 从而通过能力分析、试题推荐、学生分组等方式优化学生的学习过程<citation id="463" type="reference"><link href="395" rel="bibliography" /><link href="397" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>.认知诊断模型根据不同的分类方式可分为离散模型和连续模型, 或分为一维技能模型和多维技能模型.常见认知诊断模型包括基于项目反应理论 (item response theory, IRT) 的模型、DINA模型和它们的改进模型<citation id="464" type="reference"><link href="379" rel="bibliography" /><link href="385" rel="bibliography" /><link href="399" rel="bibliography" /><link href="401" rel="bibliography" /><link href="403" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">4</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>等, 模型中通常会考虑试题的难度、区分度、失误可能性、猜对可能性等因素<citation id="465" type="reference"><link href="399" rel="bibliography" /><link href="405" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">14</a>]</sup></citation>, 有些研究中还会融合教育学理论, 如学习曲线和遗忘曲线<citation id="462" type="reference"><link href="407" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>等.尽管这些模型考虑了试题难度等因素, 但通常作为参数, 或是通过已知的Q矩阵计算, 因而需要人为提供较多的先验知识.</p>
                </div>
                <div class="p1">
                    <p id="104">有学者将传统机器学习结合特征工程的方法运用到试题难度预测中.文献<citation id="466" type="reference">[<a class="sup">1</a>]</citation>中作者定义了试题考察的能力、知识点重要程度、试题迷惑性、复杂性、灵活性等特征, 将这些特征值作为神经网络的输入, 预测试题难度.尽管这些人工定义的特征能够反映试题的一些重要信息, 但是基于经验人工筛选出的试题表征, 对试题语义没有加以利用.且部分此类特征值的确定并非是可统计的, 而是由经验判断的, 其客观性和准确性难以保证.</p>
                </div>
                <div class="p1">
                    <p id="105">以上工作具有相同的局限性:即都需要较多的人为干预, 如提供先验知识或教学经验和劳动力.而本文所提出的模型是数据驱动的, 所需要的只是试题文本和答题记录, 从而避免上述问题.</p>
                </div>
                <div class="p1">
                    <p id="106">目前已有学者进行了针对英语试题的难度预测工作<citation id="467" type="reference"><link href="409" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 受其启发, 本文提出了针对数学试题的难度预测模型.</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>1.2 文本建模</b></h4>
                <div class="p1">
                    <p id="108">本文提出的模型针对试题的纯文本输入, 且不需要提供试题的诸如知识点等先验信息, 因此对模型的文本建模与信息提取能力要求较高.</p>
                </div>
                <div class="p1">
                    <p id="109">随着大数据时代的到来, 文本数据挖掘现已广泛运用于互联网<citation id="468" type="reference"><link href="411" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、教育<citation id="469" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、医疗<citation id="470" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、媒体<citation id="471" type="reference"><link href="417" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>等领域, 涉及的技术包括文本聚类、文本分类<citation id="472" type="reference"><link href="419" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、情感分析<citation id="473" type="reference"><link href="421" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>、文本推荐<citation id="474" type="reference"><link href="423" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>等.与之相关的自然语言处理 (natural language process, NLP) 也在文本处理、自然语言理解、人机交互等领域具有重要意义.Mikolov等人<citation id="475" type="reference"><link href="425" rel="bibliography" /><link href="427" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>提出word2vec和doc2vec, 尽管作为语言模型训练的副产物, 但由于其维度低和保持部分语义特征等优点, 被大量运用到文本建模的数据表征中, 使得许多模型的效果得以提升.</p>
                </div>
                <div class="p1">
                    <p id="110">在模型方面, 过去文本数据挖掘方法通常需要分析文本的词法、语法、语义特征, 人为地构造一些具体的结构.近年来, 深度学习的兴起使得文本数据挖掘有了新的探索路径, CNN<citation id="476" type="reference"><link href="429" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>和RNN<citation id="477" type="reference"><link href="431" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>对文本类数据具有较好的拟合能力, 避免了对词法、语法等先验知识的要求.相关工作如情感识别<citation id="478" type="reference"><link href="433" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>、文本蕴含<citation id="479" type="reference"><link href="435" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>、机器理解<citation id="480" type="reference"><link href="437" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>等.</p>
                </div>
                <div class="p1">
                    <p id="111">多层CNN神经网络可从词、短语、句子等不同层次挖掘文本信息;RNN则适合挖掘长程的逻辑关系.因此2种模型都可用于试题难度预测的建模当中.基于此, 本文提出了基于CNN的难度预测模型C-MIDP和基于RNN的难度预测模型R-MIDP, 并且考虑到CNN和RNN各自的优缺点, 将CNN和RNN结合, 提出H-MIDP, 进一步提高预测的准确率.</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag"><b>2 数据驱动的试题难度预测模型</b></h3>
                <div class="p1">
                    <p id="113">本节中将给出问题的形式化定义, 介绍模型的整体框架, 具体介绍3种不同的难度预测模型.</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>2.1 问题定义</b></h4>
                <div class="p1">
                    <p id="115">模型训练所需要的数据为真实的数学考试试题及答题记录, 考试为正式的统一测评 (如期中考试、期末考试、月考等) , 试题为常规考试题型 (如选择、填空或简答题) .表2为1道数学试题文本数据示例, 数据包括试题ID、题面、答案和解析.表3为答题记录结构示例, 1条记录代表1个学生在1场考试中某道题的得分, 将具有相同试卷ID、学校ID和考试日期的答题记录集合定义为同一场考试<i>T</i><sub><i>i</i></sub>记录集合.</p>
                </div>
                <div class="p1">
                    <p id="116">对于考试、试题、得分率等概念的形式化定义及本文应对的问题定义如下:</p>
                </div>
                <div class="p1">
                    <p id="117">定义<i>Q</i>={<i>Q</i><sub>1</sub>, <i>Q</i><sub>2</sub>, …, <i>Q</i><sub><i>n</i></sub>}为试题集合, <i>T</i>={<i>T</i><sub>1</sub>, <i>T</i><sub>2</sub>, …, <i>T</i><sub><i>m</i></sub>}为数学考试集合.<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo></mrow></math></mathml>, 其中<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Q</mi><mo>˜</mo></mover></math></mathml><sub><i>i</i></sub>和<mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>i</i></sub>分别为考试<i>T</i><sub><i>i</i></sub>中的习题集合和得分率集合.<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">}</mo><mo>, </mo><mover accent="true"><mi>Q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>∈</mo><mi>Q</mi><mo>, </mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>为考试<i>T</i><sub><i>i</i></sub>中的试题数;<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">}</mo><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub></mrow></math></mathml>为考试<i>T</i><sub><i>i</i></sub>中第<i>j</i>道题的得分率, 以得分率作为考试<i>T</i><sub><i>i</i></sub>中试题难度的真实值.得分率的计算为</p>
                </div>
                <div class="p1">
                    <p id="123"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mtext>考</mtext><mtext>试</mtext><mi>i</mi><mtext>中</mtext><mtext>试</mtext><mtext>题</mtext><mi>j</mi><mtext>的</mtext><mtext>得</mtext><mtext>分</mtext><mtext>之</mtext><mtext>和</mtext></mrow><mrow><mtext>考</mtext><mtext>试</mtext><mi>i</mi><mtext>中</mtext><mtext>试</mtext><mtext>题</mtext><mi>j</mi><mtext>答</mtext><mtext>题</mtext><mtext>记</mtext><mtext>录</mtext><mtext>数</mtext><mo>×</mo><mtext>试</mtext><mtext>题</mtext><mi>j</mi><mtext>总</mtext><mtext>分</mtext></mrow></mfrac></mrow></math></mathml>. (1) </p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表2 数学试题示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Example of Mathematical Item</b></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br />Attribute</td><td>Value</td></tr><tr><td><br />Item ID (<i>Q</i><sub><i>i</i></sub>) </td><td>00004b28-4a67-4a51</td></tr><tr><td><br />Question</td><td>已知<i>a</i>, <i>b</i>, <i>c</i>分别为△<i>ABC</i>内角<i>A</i>, <i>B</i>, <i>C</i>的对边, <i>a</i><sup>2</sup>=<i>bc</i>, 则∠<i>A</i>的最大值为__.</td></tr><tr><td><br />Solution</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mtext>π</mtext><mn>3</mn></mfrac></mrow></math></td></tr><tr><td><br /><i>Analysis</i></td><td>本题考查余弦定理及基本不等式, 根据题意利用余弦定理及基本不等式即可求得结果.解答:在△<i>ABC</i>中, <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>cos</mi></mrow><mtext> </mtext><mi>A</mi><mo>=</mo><mfrac><mrow><mi>b</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>c</mi><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mi>a</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>b</mi><mi>c</mi></mrow></mfrac><mo>≥</mo><mfrac><mrow><mn>2</mn><mi>b</mi><mi>c</mi><mo>-</mo><mi>b</mi><mi>c</mi></mrow><mrow><mn>2</mn><mi>b</mi><mi>c</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></math>, 因此<i>A</i>的最大值为<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mtext>π</mtext><mn>3</mn></mfrac></mrow></math></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表3 答题记录示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Example of Answer Log</b></p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td><br />Attribute</td><td>Value</td></tr><tr><td><br />Paper ID</td><td>ff3110a0-fd51-4dfd-a6c7</td></tr><tr><td><br />School ID</td><td>2300000001000002</td></tr><tr><td><br />Test Date</td><td>2017-1-17</td></tr><tr><td><br />Student ID</td><td>4444000020013967</td></tr><tr><td><br />Item ID</td><td>a8da5256-fe26-451b</td></tr><tr><td><br />Full Score</td><td>12</td></tr><tr><td><br />Get Score</td><td>10</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="127"><b>定义1</b>. 给定数学试题集合<i>Q</i>和数学考试记录集合<i>T</i>, 其中<i>Q</i>包含每道试题的文本, <i>T</i>包含每场考试的试题和对应的得分率, 目标是对数学试题建模, 使得通过输入试题特征到模型中可以得到试题的难度预测值.</p>
                </div>
                <div class="p1">
                    <p id="128">表4给出了问题涉及到的符号和对应的描述:</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表4 试题难度预测问题涉及的符号及解释</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Related Symbols and Explanations</b></p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />Symbol</td><td>Explanation</td></tr><tr><td><br /><i>Q</i></td><td>Set of all items</td></tr><tr><td><br /><i>Q</i><sub><i>i</i></sub></td><td>Item <i>i</i></td></tr><tr><td><br /><i>R</i><sub><i>i</i></sub></td><td>Average score of item <i>i</i></td></tr><tr><td><br /><i>P</i><sub><i>i</i></sub></td><td>Predicted difficulty of item <i>i</i></td></tr><tr><td><br /><i>T</i></td><td>Set of all mathematical tests</td></tr><tr><td><br /><i>T</i><sub><i>i</i></sub></td><td>Mathematical test <i>i</i></td></tr><tr><td><br /><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Q</mi><mo>˜</mo></mover></math><sub><i>i</i></sub></td><td>Item set in <i>T</i><sub><i>i</i></sub></td></tr><tr><td><br /><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Q</mi><mo>˜</mo></mover></math><sub><i>i j</i></sub></td><td>Item <i>j</i> in <i>T</i><sub><i>i</i></sub></td></tr><tr><td><br /><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math><sub><i>i</i></sub></td><td>Set of average scores in <i>T</i><sub><i>i</i></sub></td></tr><tr><td><br /><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math><sub><i>i j</i></sub></td><td>Average score of item <i>j</i> in <i>T</i><sub><i>i</i></sub></td></tr><tr><td><br /><b><i>X</i></b><sub><i>q</i></sub></td><td>Feature of item <i>q</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>2.2 模型整体框架</b></h4>
                <div class="p1">
                    <p id="131">本节介绍本文提出的数学试题难度预测模型的整体框架, 整体流程如图1, 分成2个阶段:训练阶段和预测阶段.在训练阶段, 根据将答题记录中的试题文本进行表征后得到训练特征, 作为模型训练的输入, 并从答题记录获取每一场考试中各道试题的得分率作为试题难度的标签, 考虑不同考试中试题得分率的不可比性, 训练时采用context相关的成对试题目标函数;在预测阶段, 将待预测试题的文本经同样的表征方式得到预测特征, 将其输入训练得到的模型, 获得难度的预测值.模型分3部分介绍:</p>
                </div>
                <div class="p1">
                    <p id="132">1) 模型结构.C-MIDP, R-MIDP, H-MIDP这3个模型均为神经网络模型, 其中C-MIDP以CNN网络为基础, R-MIDP以RNN网络为基础, H-MIDP为前两者的融合.</p>
                </div>
                <div class="p1">
                    <p id="133">2) 模型训练.训练时以试题文本的词向量特征作为输入, 试题得分率作为标签.考虑到不同考试中不同学生群体的得分率具有一定的不可比性, 本模型采用context相关 (context-dependent) 的方式, 将同一场考试中成对试题预测难度的差值与实际差值比较, 计算目标函数值.</p>
                </div>
                <div class="p1">
                    <p id="134">3) 预测.试题难度预测是context无关的, 将预处理过的试题特征作为输入, 得到试题的绝对难度.</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型框架图" src="Detail/GetImg?filename=images/JFYZ201905011_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_135.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Model framework</p>

                </div>
                <h4 class="anchor-tag" id="136" name="136"><b>2.3 模型结构</b></h4>
                <div class="p1">
                    <p id="137">本文提出的3种模型接受试题特征作为输入, 输出为试题的预测难度.试题特征通过对文本字符的词向量拼接获得, 具体步骤:</p>
                </div>
                <div class="p1">
                    <p id="138">步骤1. 获取试题中文词语或英文字符的表征向量.使用word2vec<citation id="481" type="reference"><link href="425" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>方法, 以数学试题文本集合为训练数据, 训练得到文本库中每个词语或字符的词向量<b><i>w</i></b><sub><i>i</i></sub>∈R<sup><i>d</i><sub>0</sub>×1</sup>.以训练得到的词向量作为对应词语或字符的表征向量, 相比one-hot的表征方式, 维数更低, 且能够保持一定的语义特征.</p>
                </div>
                <div class="p1">
                    <p id="139">步骤2. 构建试题的初始表征向量.将试题分词并去除停用词, 剩余的词语或字符按原文顺序以对应的词向量替换, 得到试题初始表征向量<b><i>X</i></b>′<sub><i>q</i></sub>∈R<sup><i>d</i><sub>0</sub>×<i>n</i></sup>, 其中<i>n</i>为词向量数量.</p>
                </div>
                <div class="p1">
                    <p id="140">步骤3. 修改<b><i>X</i></b>′<sub><i>q</i></sub>长度得到试题最终表示向量<b><i>X</i></b><sub><i>q</i></sub>.由于模型输入的特征需为固定长度, 因此选择合适的长度<i>N</i> (<i>N</i>为词向量数量, 实验中设置<i>N</i>=600, 具体见3.1节) , 若<i>n</i>&lt;<i>N</i>, 则用<i>N</i>-<i>n</i>个零向量填充, 反之若<i>n</i>&gt;<i>N</i>, 则删去最后<i>n</i>-<i>N</i>个词向量.最终得到的<b><i>X</i></b><sub><i>q</i></sub>作为试题的表征向量.</p>
                </div>
                <div class="p1">
                    <p id="141">将试题文本转换成向量特征后, 输入模型进行语义理解.图2是3种模型的结构图, 其中图2 (a) ～ (c) 分别是C-MIDP模型、R-MIDP模型和H-MIDP模型.</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 模型结构" src="Detail/GetImg?filename=images/JFYZ201905011_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Model structures</p>

                </div>
                <h4 class="anchor-tag" id="143" name="143">2.3.1 C-MIDP模型</h4>
                <div class="p1">
                    <p id="144">试题文本包含较丰富的语义, 要使模型能够不依赖Q矩阵等先验知识, 就必须能够从文本中挖掘足够的信息.相关研究表示, 局部重要的词句对于文本理解具有重要的意义<citation id="482" type="reference"><link href="437" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>.例如在理解试题时, 我们只需理解其中最重要的知识概念描述 (如公式、定义等) 即可理解整个试题的语义.因此, 本文利用CNN中的卷积-池化从局部到整体的方式挖掘试题文本中的主要信息<citation id="483" type="reference"><link href="437" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>.具体地, 本文提出C-MIDP模型, 它以CNN为基础, 使用的多层卷积与池化层可以从不同层次学习试题信息.例如C-MIDP可以以试题中的数字或运算符为基础扩大范围, 提取由这些数字或运算符等组成公式信息;再进一步联系公式的上下文获取更大范围的信息, 逐步获取整个试题的主要信息, 这个过程也符合人真实的阅读习惯.</p>
                </div>
                <div class="p1">
                    <p id="145">C-MIDP模型结构如图2 (a) 所示, 模型包括输入层、2层卷积层和Max Pooling层、全连接层和输出层.输入层接受试题特征<b><i>X</i></b><sub><i>q</i></sub>∈R<sup><i>d</i><sub>0</sub>×<i>N</i></sup>.<b><i>X</i></b><sub><i>q</i></sub>在第1个卷积层通过<i>d</i><sub>1</sub>个<i>k</i>×1的卷积核执行卷积操作, 输出<i>d</i><sub>1</sub>个channel的隐层.</p>
                </div>
                <div class="p1">
                    <p id="146">具体地, 给定输入<b><i>X</i></b><sub><i>q</i></sub>= (<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>N</i></sub>) , <b><i>w</i></b><sub><i>i</i></sub>∈R<sup><i>d</i><sub>0</sub>×1</sup>, 通过卷积获得隐层<b><i>H</i></b><sup>c</sup>= (<b><i>h</i></b><sup>c</sup><sub>1</sub>, <b><i>h</i></b><sup>c</sup><sub>2</sub>, …, <b><i>h</i></b><sup>c</sup><sub><i>N</i>+<i>k</i>-1</sub>) ∈R<sup><i>d</i><sub>1</sub>× (<i>N</i>+<i>k</i>-1) </sup>, 其中:</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mtext>c</mtext></msubsup><mo>=</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>d</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mi mathvariant="bold-italic">G</mi></mstyle><mo>×</mo><mo stretchy="false"> (</mo><mi>w</mi><mspace width="0.25em" /><msubsup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>j</mi></msubsup><mo>, </mo><mi>w</mi><mspace width="0.25em" /><msubsup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mi>k</mi><mo>+</mo><mn>2</mn></mrow><mi>j</mi></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>w</mi><mspace width="0.25em" /><msubsup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup><mo>, </mo><mi>w</mi><mspace width="0.25em" /><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="148"><b><i>G</i></b>∈R<sup><i>d</i><sub>1</sub>×<i>k</i></sup>, 即<i>d</i><sub>1</sub>个长度为<i>k</i>的卷积核;<i>w</i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>表示<b><i>w</i></b><sub><i>i</i></sub>的第<i>j</i>维元素值;<b><i>b</i></b>∈R<sup><i>d</i><sub>1</sub>×1</sup>, 为偏置项;<i>ReLU</i>=max (0, <i>x</i>) 为非线性激活函数.</p>
                </div>
                <div class="p1">
                    <p id="150">第1层卷积层的输出<b><i>H</i></b><sup>c</sup>经过p-max池化层, 以选出其中最重要的信息, 得到新的隐层<b><i>H</i></b><sup>cp</sup>= (<b><i>h</i></b><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mtext>c</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>, <b><i>h</i></b><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mtext>c</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>, …, <b><i>h</i></b><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo>-</mo><mo stretchy="false"> (</mo><mi>Ν</mi><mo>+</mo><mi>k</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>/</mo><mi>p</mi><mo>-</mo></mrow><mrow><mtext>c</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>) , 其中:</p>
                </div>
                <div class="area_img" id="154">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201905011_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="156"><b><i>H</i></b><sup>cp</sup>再次经过一层卷积层和p-max池化层, 具体操作与第1层类似.设第2层卷积层的卷积核数量为<i>d</i><sub>2</sub>, 取第2层Max Pooling层的窗口大小为| (<i>N</i>+<i>k</i>-1) /<i>p</i>|, 此时输出的隐层<b><i>H</i></b><sup>c</sup><sub>2</sub>∈R<i><sup>d</sup></i><sup><sub>2</sub></sup><sup>×1</sup>, 转置后经过一层全连接层, 输出试题难度的预测值<i>P</i><i><sub>q</sub></i>.</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158">2.3.2 R-MIDP模型</h4>
                <div class="p1">
                    <p id="159">除此之外, 文本的序列语义与逻辑信息对于理解试题也非常重要.例如公式中的一个数字本身可能不包含多少信息, 但若与它前面的若干个字符联系, 可能就表现出重要的语义.基于此, 本文提出R-MIDP模型, 它以RNN为基础, 利用RNN中的Cell模块保存历史信息, 学习到试题文本的序列语义或逻辑信息.具体地, R-MIDP模型是一个双向LSTM的网络结构, LSTM采用经典的3门结构<citation id="484" type="reference"><link href="439" rel="bibliography" /><link href="441" rel="bibliography" /><sup>[<a class="sup">31</a>,<a class="sup">32</a>]</sup></citation>, 在理解试题的过程中, 可以从正向和反向2个方向学习试题语义逻辑, 使语义更加完整.</p>
                </div>
                <div class="p1">
                    <p id="160">如图2 (b) 所示, R-MIDP模型包括输入层、双向LSTM隐层、Max Pooling层、全连接层和输出层.输入层接受试题特征<b><i>X</i></b><sub><i>q</i></sub>= (<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>N</i></sub>) ∈R<sup><i>d</i><sub>0</sub>×<i>N</i></sup>, LSTM层输出维度为<i>d</i>, 经过单层LSTM得到隐层<b><i>H</i></b><sup>r</sup>= (<b><i>h</i></b><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mtext>r</mtext></msubsup></mrow></math></mathml>, <b><i>h</i></b><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mtext>r</mtext></msubsup></mrow></math></mathml>, …, <b><i>h</i></b><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>d</mi><mtext>r</mtext></msubsup></mrow></math></mathml>) <sup>T</sup>= (<b><i>y</i></b><sub>1</sub>, <b><i>y</i></b><sub>2</sub>, …, <b><i>y</i></b><sub><i>N</i></sub>) ∈R<sup><i>d</i>×<i>N</i></sup>, 其中<b><i>h</i></b><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mtext>r</mtext></msubsup></mrow></math></mathml>= (<i>h</i><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mn>1</mn></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>, <i>h</i><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mn>2</mn></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>, …, <i>h</i><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>Ν</mi></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>) , 正向输入时的<b><i>y</i></b><sub><i>t</i></sub>由下列LSTM计算公式获得:</p>
                </div>
                <div class="p1">
                    <p id="168"><b><i>i</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub>ii</sub><b><i>w</i></b><sub><i>t</i></sub>+<b><i>b</i></b><sub>ii</sub>+<b><i>W</i></b><sub>hi</sub><b><i>y</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub>hi</sub>) , (4) </p>
                </div>
                <div class="p1">
                    <p id="169"><b><i>f</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub>if</sub><b><i>w</i></b><sub><i>t</i></sub>+<b><i>b</i></b><sub>if</sub>+<b><i>W</i></b><sub>hf</sub><b><i>y</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub>hf</sub>) , (5) </p>
                </div>
                <div class="p1">
                    <p id="170"><b><i>g</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub>ig</sub><b><i>w</i></b><sub><i>t</i></sub>+<b><i>b</i></b><sub>ig</sub>+<b><i>W</i></b><sub>hg</sub><b><i>y</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub>hg</sub>) , (6) </p>
                </div>
                <div class="p1">
                    <p id="171"><b><i>o</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub>io</sub><b><i>w</i></b><sub><i>t</i></sub>+<b><i>b</i></b><sub>io</sub>+<b><i>W</i></b><sub>ho</sub><b><i>y</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub>ho</sub>) , (7) </p>
                </div>
                <div class="p1">
                    <p id="172"><b><i>c</i></b><sub><i>t</i></sub>=<b><i>f</i></b><sub><i>t</i></sub>*<b><i>c</i></b><sub><i>t</i>-1</sub>+<b><i>i</i></b><sub><i>t</i></sub>*<b><i>g</i></b><sub><i>t</i></sub>, (8) </p>
                </div>
                <div class="p1">
                    <p id="173"><b><i>y</i></b><sub><i>t</i></sub>=<b><i>o</i></b><sub><i>t</i></sub>*tanh (<b><i>c</i></b><sub><i>t</i></sub>) , (9) </p>
                </div>
                <div class="p1">
                    <p id="174">其中<b><i>i</i></b><sub><i>t</i></sub>, <b><i>f</i></b><sub><i>t</i></sub>, <b><i>o</i></b><sub><i>t</i></sub>分别为输入门、遗忘门、输出门, <b><i>w</i></b><sub><i>t</i></sub>为时刻<i>t</i>输入, <b><i>y</i></b><sub><i>t</i>-1</sub>为时刻<i>t</i>-1时LSTM Cell的输出, <b><i>c</i></b><sub><i>t</i></sub>为时刻<i>t</i>时Cell的状态, <i>σ</i>为sigmoid函数, *为卷积运算.<b><i>H</i></b><sup>r</sup>经过p-max池化层并转置后得到新的隐层<b><i>H</i></b><sup>rp</sup>= (<i>h</i><mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mtext>r</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>, <i>h</i><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mtext>r</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>, …, <i>h</i><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>d</mi><mrow><mtext>r</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>) , 其中:</p>
                </div>
                <div class="p1">
                    <p id="178"><i>h</i><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mtext>r</mtext><mtext>p</mtext></mrow></msubsup></mrow></math></mathml>=max (<i>h</i><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mn>1</mn></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>, <i>h</i><mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mn>2</mn></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>, …, <i>h</i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>Ν</mi></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>) .</p>
                </div>
                <div class="p1">
                    <p id="183"><b><i>H</i></b><sup>rp</sup>再经过一层全连接层, 最终输出试题难度的预测值<i>P</i><sub><i>q</i></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="184" name="184">2.3.3 H-MIDP模型</h4>
                <div class="p1">
                    <p id="185">更进一步, 本文结合C-MIDP和R-MIDP这2个模型的优势, 提出一种混合模型H-MIDP, 以期同时对试题文本的局部重要语义和序列逻辑信息进行有效建模.H-MIDP结构如图2 (c) 所示.模型前半部分分为并行的2部分, 其中一部分与C-MIDP相同, 输入特征经2层卷积层和Max Pooling层后得到隐层值<b><i>H</i></b><sup>c</sup><sub>2</sub>;另一部分与R-MIDP相同, 输入特征经LSTM和Max Pooling层后得到隐层值<b><i>H</i></b><sup>rp</sup>, 将<b><i>H</i></b><sup>c</sup><sub>2</sub>与<b><i>H</i></b><sup>rp</sup>拼接得到<b><i>H</i></b>∈R<sup>1× (<i>d</i><sub>2</sub>+<i>d</i>) </sup>, 经过2层全连接层得到试题难度的预测值<i>P</i><sub><i>q</i></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="186" name="186"><b>2.4 模型训练</b></h4>
                <div class="p1">
                    <p id="187">在通常的有监督模型中, 常规的训练方法是以训练数据的试题表征向量作为输入, 以试题得分率作为标签, 模型的损失函数 (loss function) :</p>
                </div>
                <div class="p1">
                    <p id="188"><mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>Τ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>q</mi></munder><mo stretchy="false"> (</mo></mstyle><mi>Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo>-</mo><mi>R</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>, (10) </p>
                </div>
                <div class="p1">
                    <p id="190">其中, <i>T</i>为整个数学考试训练集, <i>P</i><sub><i>q</i></sub>和<i>R</i><sub><i>q</i></sub>分别为试题<i>q</i>的预测难度和实际得分率.</p>
                </div>
                <div class="p1">
                    <p id="191">这种方式在计算试题得分率时常以试题为单位进行, 其训练时其实是不区分不同学生群体或不同场考试的.但实际上, 不同考试中由于学生群体的不同, 得分率是具有一定不可比性的.例如假设<i>A</i>校和<i>B</i>校使用同一份试卷进行考试, <i>A</i>校的试题<i>a</i>得分率为0.8, <i>B</i>校的试题<i>b</i>得分率为0.7, 不能简单地认为试题<i>b</i>比试题<i>a</i>更难, 因为<i>A</i>校学生的整体水平可能强于<i>B</i>校学生, 而实际<i>A</i>校的试题<i>b</i>得分率为0.9, <i>B</i>校的试题<i>a</i>得分率0.6, 因而判断试题<i>a</i>的难于试题<i>b</i>更合理.</p>
                </div>
                <div class="p1">
                    <p id="192">由此可知, 试题得分率受到学生群体水平差异性的影响.为了能够消除这种影响, 本文认为, 当考试学生群体处于相同的context范围下, 通过考试计算的试题得分率才具有可比性.此处, context可以定义为同一个班级、同一所学校、同一场考试等.例如, 在同一场考试中, 若试题<i>a</i>得分率低于试题<i>b</i>, 即可认为<i>a</i>比<i>b</i>难.本文将在实验部分中具体对此范围进行实验说明.</p>
                </div>
                <div class="p1">
                    <p id="193">具体地, 本文的3种模型采用context相关的训练方式, 模型的损失函数:</p>
                </div>
                <div class="p1">
                    <p id="194"><i>L</i> (<i>T</i>) =<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>Τ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>Q</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>Q</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>-</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mtext> </mtext><mi>i</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>, (11) </p>
                </div>
                <div class="p1">
                    <p id="196">其中, <i>T</i><sub><i>t</i></sub>表示context范围<i>t</i>, <i>P</i><sub><i>t i</i></sub>和<i>P</i><sub><i>t j</i></sub>分别指context <i>T</i><sub><i>t</i></sub>中试题<i>Q</i><sub><i>i</i></sub>和<i>Q</i><sub><i>j</i></sub>的预测难度, <mathml id="197"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>t i</i></sub>和<mathml id="198"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>t j</i></sub>分别指context <i>T</i><sub><i>t</i></sub>中试题<i>Q</i><sub><i>i</i></sub>和<i>Q</i><sub><i>j</i></sub>的实际难度 (得分率) .</p>
                </div>
                <div class="p1">
                    <p id="199">使用这样的模型损失函数可以消除不同学生群体的差异性, 获取其中的共性, 使得训练得到的模型能够预测试题的真实难度 (对于所有答题记录涉及到的学生全体而言的难度, 而不是对于其中某场考试的学生群体) .</p>
                </div>
                <h4 class="anchor-tag" id="200" name="200"><b>2.5 难度预测</b></h4>
                <div class="p1">
                    <p id="201">模型训练完毕, 进行试题难度的预测时, 将需要预测的试题表征向量输入训练得到的模型中 (C-MIDP或R-MIDP或H-MIDP) , 得到的模型输出值即为试题难度的预测值.在实际应用情境下, 如果收集的群体答题数据量充足且答题分布均匀, 则可以认为模型的输出值可以预测试题对于该群体的难度值 (或得分率) .</p>
                </div>
                <h3 id="202" name="202" class="anchor-tag"><b>3 模型验证实验</b></h3>
                <h4 class="anchor-tag" id="203" name="203"><b>3.1 数据集介绍</b></h4>
                <div class="p1">
                    <p id="204">数据来自科大讯飞股份有限公司采集的国内多个中学2014—2017年的考试试题和答题记录, 相关统计见表5.</p>
                </div>
                <div class="area_img" id="205">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_205.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 6所学校在同场期末考试中的得分率" src="Detail/GetImg?filename=images/JFYZ201905011_205.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 6所学校在同场期末考试中的得分率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_205.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Scoring rates of 6 schools in a final exam</p>

                </div>
                <div class="area_img" id="206">
                    <p class="img_tit"><b>表5 数据集相关统计分析</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Statistical Analysis of Data Set</b></p>
                    <p class="img_note"></p>
                    <table id="206" border="1"><tr><td><br />Attribute</td><td>Value</td></tr><tr><td><br />Amount of Schools</td><td>1 314</td></tr><tr><td><br />Amount of Tests</td><td>5 185</td></tr><tr><td><br />Average Amount of Items per Test</td><td>18.33</td></tr><tr><td><br />Amount of Different Items</td><td>53 027</td></tr><tr><td><br />Amount of Logs</td><td>57 457 353</td></tr><tr><td><br />Amount of Students</td><td>1 035 526</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="207">对试题文本数据预处理后统计每道题的特征长度 (即分词后有效词项数目) , 得到其分布如图3所示, 图3中横坐标为特征长度, 纵坐标为试题数量.由统计结果知特征长度大于600的不到总试题数的0.2%, 因此实验中取特征向量长度<i>N</i>=600, 实际少于600的试题用零填充, 多于600的试题截取前600个词项作为试题特征.</p>
                </div>
                <div class="area_img" id="208">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 试题特征长度分布" src="Detail/GetImg?filename=images/JFYZ201905011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 试题特征长度分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Distribution of item feature length</p>

                </div>
                <div class="p1">
                    <p id="209">选取使用某一份试卷不同场考试的答题记录, 绘制不同学校的试题得分率折线图如图4所示, 可以看到, 不同学校在各个试题上的得分率虽有明显差异, 但试题之间的得分率相对差异却相近.图4中<i>A</i>校 (最上方绿色折线) 的试题<i>Q</i><sub>10</sub>的得分率为0.3, <i>B</i>校 (最下方橙色折线) 的试题<i>Q</i><sub>9</sub>的得分率为0.22, 但不能简单以此判断试题<i>Q</i><sub>10</sub>的难度低于<i>Q</i><sub>9</sub>, 因为<i>A</i>校的整体能力强于<i>B</i>校.实际上, <i>A</i>校的试题<i>Q</i><sub>9</sub>的得分率为0.4, <i>B</i>校的试题<i>Q</i><sub>10</sub>的得分率为0.08, 可以看到不论是<i>A</i>校还是<i>B</i>校, 试题<i>Q</i><sub>9</sub>的得分率高于试题<i>Q</i><sub>10</sub>的得分率, 因此判断试题<i>Q</i><sub>9</sub>的难度低于<i>Q</i><sub>10</sub>更合理.这正验证了2.4节中的观点.</p>
                </div>
                <h4 class="anchor-tag" id="210" name="210"><b>3.2 实验评价指标</b></h4>
                <h4 class="anchor-tag" id="211" name="211">3.2.1 皮尔森相关系数 (Pearson correlation coeffi-cient, PCC) </h4>
                <div class="p1">
                    <p id="212">PCC是教育学常用的评价指标, 可以衡量每一场考试中试题实际难度与模型预测难度之间的相关性<citation id="485" type="reference"><link href="443" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>.实验中PCC具体定义为</p>
                </div>
                <div class="p1">
                    <p id="213"><i>L</i><sub>PCC</sub>=<mathml id="214"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>R</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>R</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow></math></mathml>, (12) </p>
                </div>
                <div class="p1">
                    <p id="215">其中, <i>m</i><sub><i>i</i></sub>为某场考试<i>i</i>中的试题数, <i>P</i><sub><i>i j</i></sub>为该场考试中试题<i>j</i>的预测难度, <mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><sub><i>i</i></sub>为该场考试中试题的平均预测难度, <mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>i j</i></sub>为该场考试中试题<i>j</i>的实际难度, <mathml id="218"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>¯</mo></mover></math></mathml><sub><i>i</i></sub>为该场考试中试题的平均实际难度.</p>
                </div>
                <div class="p1">
                    <p id="219">PCC取值在区间[-1, 1], 越大的绝对值意味着越高的线性相关性, 且PCC&gt;0表示正相关, PCC&lt;0表示负相关.</p>
                </div>
                <h4 class="anchor-tag" id="220" name="220">3.2.2 一致性 (degree of agreement, DOA) </h4>
                <div class="p1">
                    <p id="221">DOA可以衡量一场考试中试题对之间难度预测值相对大小的准确性<citation id="486" type="reference"><link href="445" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>.其计算为</p>
                </div>
                <div class="p1">
                    <p id="222"><mathml id="223"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>Ο</mtext><mtext>A</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mn>1</mn><mo>≤</mo><mi>a</mi><mo>, </mo><mi>b</mi><mo>≤</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>σ</mi></mstyle><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>a</mi></mrow></msub><mo>, </mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub><mo stretchy="false">) </mo><mo>∧</mo><mi>σ</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>a</mi></mrow></msub><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mn>1</mn><mo>≤</mo><mi>a</mi><mo>, </mo><mi>b</mi><mo>≤</mo><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>σ</mi></mstyle><mo stretchy="false"> (</mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>a</mi></mrow></msub><mo>, </mo><mover accent="true"><mi>R</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>b</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, (13) </p>
                </div>
                <div class="p1">
                    <p id="224">其中, <i>m</i><sub><i>i</i></sub>为某场考试中的试题数, <i>P</i><sub><i>i a</i></sub>和<i>P</i><sub><i>i b</i></sub>分别为该场考试中试题<i>a</i>和试题<i>b</i>的预测难度, <mathml id="225"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>i a</i></sub>和<mathml id="226"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>˜</mo></mover></math></mathml><sub><i>i b</i></sub>分别为该场考试中试题<i>a</i>和试题<i>b</i>的实际难度.<i>σ</i> (<i>x</i>, <i>y</i>) 的定义为</p>
                </div>
                <div class="area_img" id="227">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201905011_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="229">DOA取值范围在区间[0, 1], DOA越大表明预测的试题对之间相对难度大小关系越准确.</p>
                </div>
                <h4 class="anchor-tag" id="230" name="230"><b>3.3 对比实验</b></h4>
                <div class="p1">
                    <p id="231">为验证本文提出的模型效果, 将与4种baseline预测方法进行对比:</p>
                </div>
                <div class="p1">
                    <p id="232">1) logistic回归<citation id="487" type="reference"><link href="447" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>.传统的线性回归模型, 模型输入特征为试题的词袋特征, 采用context无关的训练方式.</p>
                </div>
                <div class="p1">
                    <p id="233">2) 支持向量机 (SVM) <citation id="488" type="reference"><link href="449" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>.SVM在线性和非线性回归问题中都比较常见, 是机器学习中重要的算法.对比模型采用非线性高斯核, 输入为试题的词袋特征, 并采用context无关的训练方式.</p>
                </div>
                <div class="p1">
                    <p id="234">3) 随机森林 (random forest) <citation id="489" type="reference"><link href="451" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>.随机森林回归模型是常用的非线性模型, 在许多回归任务上具有良好的表现.模型输入同样采用试题的词袋特征, 且采用context无关的训练方式.</p>
                </div>
                <div class="p1">
                    <p id="235">4) 神经网络context无关训练方式.本文的3种模型结构不变, 但训练方式改为context无关, 即采用式 (10) 作为损失函数, 以试题的预测难度与实际得分率的差值平方和作为目标函数.3种模型分别以CNN-I, RNN-I, Hybrid-I指代.</p>
                </div>
                <h4 class="anchor-tag" id="236" name="236"><b>3.4 实验结果及分析</b></h4>
                <h4 class="anchor-tag" id="237" name="237">3.4.1 模型对比实验</h4>
                <div class="p1">
                    <p id="238">本节将比较C-MIDP, R-MIDP, H-MIDP这3种模型的实验结果, 以及分析与baseline模型实验结果的对比.此处, C-MIDP, R-MIDP, H-MIDP这3种模型中的context定义为同一场考试范围, 即式 (11) 中的<i>T</i><sub><i>t</i></sub>表示第<i>t</i>场考试.实验分别取数据集中考试数量的40%, 30%, 20%, 10%作为测试集, 同时删除训练集中在测试集出现的试题, 这些重复试题若在训练集中得到拟合, 将不适合用作模型测试.注意到, 考试可能是一个班级单独的测试, 也可能是整个年级统考, 或者多所学校联考, 这里我们采取的划分方式是:同一所学校同一天使用同一份试卷划分为一场考试, 作为计算试题得分率的context, 在此基础上训练C-MIDP, R-MIDP, H-MIDP模型.最终得到各个模型在测试集上的 PCC与DOA指标的值如图5所示.</p>
                </div>
                <div class="area_img" id="239">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_239.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种模型实验结果" src="Detail/GetImg?filename=images/JFYZ201905011_239.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 3种模型实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_239.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Experiment results of three models</p>

                </div>
                <div class="p1">
                    <p id="240">从图5中实验结果可知, C-MIDP, R-MIDP, H-MIDP模型都有良好的表现, 并且可以看到, 在测试集比例为40%, 30%, 20%, 10%情况下, H-MIDP的测试指标均高于C-MIDP和R-MIDP.</p>
                </div>
                <div class="p1">
                    <p id="241">图6是本文3种模型与对比模型实验结果, 从图6中可以看出3项对比信息:</p>
                </div>
                <div class="area_img" id="242">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_242.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 对比实验结果" src="Detail/GetImg?filename=images/JFYZ201905011_242.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 对比实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_242.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Results contrast experiments</p>

                </div>
                <div class="p1">
                    <p id="243">1) 在使用context无关的训练方式前提下, logistic回归效果最差, 显然线性回归不能够胜任试题难度预测任务;SVM回归效果较logistic回归更好;随机森林回归在3种非神经网络baseline模型中表现最好;CNN-I, RNN-I, Hybrid-I这3种神经网络模型的实验结果明显优于前3种非神经网络模型, 说明神经网络对此任务的建模能力更强.</p>
                </div>
                <div class="p1">
                    <p id="244">2) 比较3种神经网络模型的context相关与context无关2种训练方式的实验结果, 可以看到, 尽管使用context无关训练方式 (CNN-I, RNN-I, Hybrid-I) 已经获得良好的实验结果, 但使用context相关训练方式后, 模型效果有了进一步的提升, 说明在试题难度预测这个任务当中, context相关的训练方式更适合.</p>
                </div>
                <div class="p1">
                    <p id="245">3) 随着测试集比例的降低 (即训练数据的增加) , 3种模型的效果均提升.测试集的比例降到10%时, 3种神经网络模型的PCC达到0.66以上, DOA达到0.74以上.在实际教育环境中, 数据量足够的情况下, 能够达到良好的预测效果.</p>
                </div>
                <h4 class="anchor-tag" id="246" name="246">3.4.2 context划分方式对预测结果的影响</h4>
                <div class="p1">
                    <p id="247">本节将讨论不同的context划分对于试题难度预测结果的影响.这里的context划分等价于考试的划分, 例如在一场多校联考中, 可以将一个班级的记录划分为一场考试, 也可以将一所学校的记录划分为一场考试, 或者将各个学校的所有记录共同作为一场考试.本节针对数据采用2种不同的划分方式:1) 将同一所学校同一天使用相同试卷划分为一个context;2) 将使用相同试卷的所有记录划分为一个context.依此进行实验, 研究context划分方式对试题难度预测结果的影响.</p>
                </div>
                <div class="area_img" id="248">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_248.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 2种context划分方式实验结果" src="Detail/GetImg?filename=images/JFYZ201905011_248.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 2种context划分方式实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_248.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Experiment results of two different context division</p>

                </div>
                <div class="p1">
                    <p id="249">图7是2种划分方式的在测试集上的PCC和DOA指标的直方图.可以看到2种划分方式的实验结果有明显差距, 第1种划分方式的实验结果优于第2种划分方式, 说明context的划分方式对预测结果是有影响的.在本实验数据集上, 若将考试的范围细化到学校层面, 可以更好地区分来自不同学校学生群体的差异性, 从而获得更稳定的试题难度.在实际应用中, 模型的实际训练与使用中需根据测试结果选择合适的context划分方式.</p>
                </div>
                <h4 class="anchor-tag" id="250" name="250"><b>3.5 案例分析</b></h4>
                <div class="p1">
                    <p id="251">本节选取测试集比例为40%时测试集中的1场考试试题, 使用C-MIDP, R-MIDP, H-MIDP模型进行难度预测, 比较预测结果, 以说明本文的3种模型的有效性.图8是各模型预测结果折线图, 其中实际得分率是将数据集中所有使用该份试卷试题的答题记录得分率取平均得到, 以更准确反映试题实际难度.</p>
                </div>
                <div class="area_img" id="252">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201905011_252.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 某试卷3种模型预测得分率与真实值比较" src="Detail/GetImg?filename=images/JFYZ201905011_252.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 某试卷3种模型预测得分率与真实值比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201905011_252.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Comparison between score rates predicted by 3 models and ground truth on a test paper</p>

                </div>
                <div class="p1">
                    <p id="253">表6是评价指标PCC, DOA, RMSE值.可以看到H-MIDP的3种指标的值均优于C-MIDP和R-MIDP, 但C-MIDP和R-MIDP的评价值也在可接受范围.观察图8, 可以看到3种模型在大多数试题上的预测值能够接近实际得分率, 或者在试题相对难度关系上接近, 其中H-MIDP的预测曲线与真实值最为接近, 说明模型能够通过context相关的训练方式来预测试题绝对难度.</p>
                </div>
                <div class="area_img" id="254">
                    <p class="img_tit"><b>表6 案例分析各模型评价指标值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Metrics Values of Models in Case Study</b></p>
                    <p class="img_note"></p>
                    <table id="254" border="1"><tr><td><br />Model</td><td>PCC</td><td>DOA</td><td>RMSE</td></tr><tr><td><br />C-MIDP</td><td>0.766</td><td>0.788</td><td>0.171</td></tr><tr><td><br />R-MIDP</td><td>0.627</td><td>0.723</td><td>0.179</td></tr><tr><td><br />H-MIDP</td><td>0.797</td><td>0.823</td><td>0.136</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="255" name="255" class="anchor-tag"><b>4 结 论</b></h3>
                <div class="p1">
                    <p id="256">为解决准确、高效地预测数学试题难度所面临的难题, 辅助中国特色教育考试国家题库建设, 本文提出了数据驱动的基于神经网络的难度预测模型.具体地, 首先设计了基于卷积神经网络的C-MIDP模型和基于循环神经网络的R-MIDP模型学习试题文本的序列逻辑信息;进一步, 结合2种模型的优势, 提出混合H-MIDP模型.3种模型均直接对试题文本进行理解和语义表征, 可保留试题描述的局部语义和语序信息;然后, 为应对不同考试中学生群体具有不可比性的问题, 在模型训练时考虑答题记录的上下文, 采用context相关的训练方式;最后, 所提出的模型只需根据试题文本即可预测新试题难度属性, 无需人工标注先验知识信息.本文在真实数据集上进行了大量实验, 实验结果表明了本文所提出的模型具有良好的性能.</p>
                </div>
                <div class="p1">
                    <p id="257">本文的模型具有进一步改良的空间和向其他学科扩展的可能性.在未来研究中, 可以考虑新的模型结构对试题文本理解的影响, 如Attention网络、Memory网络等.其次, 探索更为准确和稳定的context的划分方式, 以减少对试题难度预估结果的影响.我们还将考虑针对不同试题类型设计更为精准的预测模型.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="379">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYKO200806006&amp;v=MjQ0MTFxRmlEZ1c3N0lMelRBWWJHNEh0bk1xWTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Mao Jingfei.Exploration of difficulty prediction methods for questions in college entrance examination[J].Education Science, 2008, 24 (6) :22-26 (in Chinese) (毛竞飞.高考命题中试题难度预测方法探索[J].教育科学, 2008, 24 (6) :22-26) 
                            </a>
                        </p>
                        <p id="381">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201801009&amp;v=MTkxNjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lLRDdZYkxHNEg5bk1ybzlGYllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Liu Qi, Chen Enhong, Zhu Tianyu, et al.Research on educational data mining for online intelligent learning[J].Pattern Recognition and Artificial Intelligence, 2018, 31 (1) :77-90 (in Chinese) (刘淇, 陈恩红, 朱天宇, 等.面向在线智慧学习的教育数据挖掘技术研究[J].模式识别与人工智能, 2018, 31 (1) :77-90) 
                            </a>
                        </p>
                        <p id="383">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                Liu Qi, Chen Enhong, Huang Zhenya, et al.Cognitive ability analysis of students for personalized learning[J].Communications of the CCF, 2017, 13 (4) :28-35 (in Chinese) (刘淇, 陈恩红, 黄振亚, 等.面向个性化学习的学生认知能力分析[J].计算机学会通讯, 2017, 13 (4) :28-35) 
                            </a>
                        </p>
                        <p id="385">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Item Response Theory and Classical Test Theory: An Empirical Comparison of their Item/Person Statistics">

                                <b>[4]</b>Fan Xitao.Item response theory and classical test theory:An empirical comparison of their item?person statistics[J].Educational and Psychological Measurement, 1998, 58 (3) :357-381
                            </a>
                        </p>
                        <p id="387">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DINA Model and Parameter Estimation: A Didactic">

                                <b>[5]</b>De La Torre J.DINA model and parameter estimation:Adidactic[J].Journal of Educational and Behavioral Statistics, 2009, 34 (1) :115-130
                            </a>
                        </p>
                        <p id="389">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KSYA200501004&amp;v=MDU3ODg2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUxqN1NiN0c0SHRUTXJvOUZZSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>Dong Shenghong, Qi Shuqing, Dai Haiqi, et al.Research on manual assignment methods for difficulty and distinction parameters[J].Testing Research, 2005, 1 (1) :25-32 (in Chinese) (董圣鸿, 漆书青, 戴海琦, 等.题目难度, 区分度参数人工赋值方法的研究[J].考试研究, 2005, 1 (1) :25-32) 
                            </a>
                        </p>
                        <p id="391">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using the student model to control problem difficulty">

                                <b>[7]</b>Beck J, Stern M, Woolf B P.Using the student model to control problem difficulty[C]Proc of the 6th Int Conf on User Modeling.Berlin:Springer, 1997:277-288
                            </a>
                        </p>
                        <p id="393">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Item difficulty of multiple choice tests dependant on different item response formats – An experiment in fundamental research on psychological assessment">

                                <b>[8]</b>Kubinger K D, Gottschall C H.Item difficulty of multiple choice tests dependant on different item response formats--An experiment in fundamental research on psychological assessment[J].Psychology Science, 2007, 49 (4) :361-374
                            </a>
                        </p>
                        <p id="395">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cognitive modelling for predicting examinee performance">

                                <b>[9]</b>Wu Runze, Liu Qi, Liu Yuping, et al.Cognitive modelling for predicting examinee performance[C]Proc of the 24th Int Joint Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2015:1017-1024
                            </a>
                        </p>
                        <p id="397">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201701010&amp;v=MjYzNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXNzdJTHo3QmRyRzRIOWJNcm85RVpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Zhu Tianyu, Huang Zhenya, Chen Enhong, et al.Cognitive diagnosis based personalized question recommendation[J].Chinese Journal of Computers, 2017, 40 (1) :176-191 (in Chinese) (朱天宇, 黄振亚, 陈恩红, 等.基于认知诊断的个性化试题推荐方法[J].计算机学报, 2017, 40 (1) :176-191) 
                            </a>
                        </p>
                        <p id="399">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702265773&amp;v=MzI2NzZyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRnNjYXhJPU5pZk9mYks3SHRETnFJOUhadTBLQzNzNm9CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>DiBello L V, Roussos L A, Stout W.31a review of cognitively diagnostic assessment and a summary of psychometric models[J].Handbook of Statistics, 2007, 26:979-1030
                            </a>
                        </p>
                        <p id="401">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KSYJ201301007&amp;v=MjcyMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMajdTWkxHNEg5TE1ybzlGWTRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Zhang Xiao, Sha Ruxue.Research advance in DINA model of cognitive diagnosis[J].China Examinations, 2013 (1) :32-37 (in Chinese) (张潇, 沙如雪.认知诊断DINA模型研究进展[J].中国考试, 2013 (1) :32-37) 
                            </a>
                        </p>
                        <p id="403">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001076879&amp;v=MjIyNTl0RkN6a1c3ckFJVjQ9Tmo3QmFyTzRIdEhOcjRoRGJPd0dZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVk&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Maris E.Estimating multiple classification latent class models[J].Psychometrika, 1999, 64 (2) :187-212
                            </a>
                        </p>
                        <p id="405">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge or gaming?:Cognitive modelling based on multiple-attempt response">

                                <b>[14]</b>Wu Ruize, Xu Guandong, Chen Enhong, et al.Knowledge or gaming?:Cognitive modelling based on multiple-attempt response[C]Proc of the 26th Int Conf on World Wide Web Companion.New York:ACM, 2017:321-329
                            </a>
                        </p>
                        <p id="407">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tracking knowledge proficiency of students with educational priors">

                                <b>[15]</b>Chen Yuying, Liu Qi, Huang Zhenya, et al.Tracking knowledge proficiency of students with educational priors[C]Proc of the 26th ACM Conf on Information and Knowledge Management.New York:ACM, 2017:989-998
                            </a>
                        </p>
                        <p id="409">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Question Difficulty Prediction for READING Problems in Standard Tests">

                                <b>[16]</b>Huang Zhenya, Liu Qi, Chen Enhong, et al.Question difficulty prediction for reading problems in standard tests[C]Proc of the 31st AAAI Conf on Artificial Intelligence.Menlo Park, CA:AAAI, 2017:1352-1359
                            </a>
                        </p>
                        <p id="411">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA200004009&amp;v=Mjc4MjJDVVJMT2VaZVJxRmlEZ1c3N0lMejdCYjdHNEh0SE1xNDlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Wang Weiqiang, Gao Wen, Duan Lijuan.Text mining on the Internet[J].Computer Science, 2000, 27 (4) :32-36 (in Chinese) (王伟强, 高文, 段立娟.Internet上的文本数据挖掘[J].计算机科学, 2000, 27 (4) :32-36) 
                            </a>
                        </p>
                        <p id="413">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XJJS201302003&amp;v=MTMyMzVxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXNzdJUFNmQmZiRzRIOUxNclk5Rlo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Wei Shunping.Learning analysis technology:Mining educational data’s value in the era of big data[J].Modern Educational Technology, 2013, 2 (23) :5-11 (in Chinese) (魏顺平.学习分析技术:挖掘大数据时代下教育数据的价值[J].现代教育技术, 2013, 2 (23) :5-11) 
                            </a>
                        </p>
                        <p id="415">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201807017&amp;v=MTMwNDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUx5dlNkTEc0SDluTXFJOUVZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Yang Pei, Yang Zhihao, Luo Ling, et al.An attention-based approach for chemical compound and drug named entity recognition[J].Journal of Computer Research and Development, 2018, 55 (7) :1548-1556 (in Chinese) (杨培, 杨志豪, 罗凌, 等.基于注意机制的化学药物命名实体识别[J].计算机研究与发展, 2018, 55 (7) :1548-1556) 
                            </a>
                        </p>
                        <p id="417">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805005&amp;v=MTI2NzNvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGaURnVzc3SUx5dlNkTEc0SDluTXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Zhang Ying, Wang Chao, Guo Wenya, et al.Multi-source emotion tagging for online news comments using bidirectional hierarchical semantic representation model[J].Journal of Computer Research and Development, 2018, 55 (5) :933-944 (in Chinese) (张莹, 王超, 郭文雅, 等.基于双向分层语义模型的多源新闻评论情绪预测[J].计算机研究与发展, 2018, 55 (5) :933-944) 
                            </a>
                        </p>
                        <p id="419">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801016&amp;v=MDU0NzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZpRGdXNzdJTHl2U2RMRzRIOW5Ncm85RVk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Gao Yunlong, Zuo Wanli, Wang Ying, et al.Sentence classification model based on sparse and self-taught convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (1) :179-187 (in Chinese) (高云龙, 左万利, 王英, 等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展, 2018, 55 (1) :179-187) 
                            </a>
                        </p>
                        <p id="421">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201805006&amp;v=MDM1MTA1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMeXZTZExHNEg5bk1xbzlGWW9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Chen Ke, Liang Bin, Ke Wende, et al.Chinese micro-blog sentiment analysis based on multi-channels convolutional neural networks[J].Journal of Computer Research and Development, 2018, 55 (5) :945-957 (in Chinese) (陈珂, 梁斌, 柯文德, 等.基于多通道卷积神经网络的中文微博情感分析[J].计算机研究与发展, 2018, 55 (5) :945-957) 
                            </a>
                        </p>
                        <p id="423">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Practical Text Mining and Statistical Analysis for Non-Structured Text Data Applications">

                                <b>[23]</b>Miner G, Elder IV J, Hill T.Practical Text Mining and Statistical Analysis for Non-Structured Text Data Applications[M].Amsterdam, Netherlands:Academic Press, 2012
                            </a>
                        </p>
                        <p id="425">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">

                                <b>[24]</b>Mikolov T, Sutskever I, Chen Kai, et al.Distributed representations of words and phrases and their compositionality[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MITPress, 2013:3111-3119
                            </a>
                        </p>
                        <p id="427">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of sentences and documents">

                                <b>[25]</b>Le Q, Mikolov T.Distributed representations of sentences and documents[C]Proc of the 31st Int Conf on Machine Learning.New York:ACM, 2014:1188-1196
                            </a>
                        </p>
                        <p id="429">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">

                                <b>[26]</b>LeCun Y, Bottou L, Bengio Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324
                            </a>
                        </p>
                        <p id="431">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel connectionist system for unconstrained handwriting recognition">

                                <b>[27]</b>Graves A, Liwicki M, Fernández S, et al.A novel connectionist system for unconstrained handwriting recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (5) :855-868
                            </a>
                        </p>
                        <p id="433">
                            <a id="bibliography_28" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700312704&amp;v=MTI0NzVQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGc2NheEk9TmlmT2ZiSzhIOURNcUk5Rlorb05DM3c5b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[28]</b>Cambria E, Gastaldo P, Bisio F, et al.An ELM-based model for affective analogical reasoning[J].Neurocomputing, 2015, 149:443-455
                            </a>
                        </p>
                        <p id="435">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A large annotated corpus for learning natural language inference">

                                <b>[29]</b>Bowman S R, Angeli G, Potts C, et al.A large annotated corpus for learning natural language inference[EB?OL]. (2015-08-21) [2018-08-17].https:arxiv.org?abs?1508.05326
                            </a>
                        </p>
                        <p id="437">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based convolutional neural network for machine comprehension[EB?OL]">

                                <b>[30]</b>Yin Wenpeng, Ebert S, Schütze H.Attention-based convolutional neural network for machine comprehension[EB?OL]. (2016-02-13) [2018-08-17].https:arxiv.org?abs?1602.04341
                            </a>
                        </p>
                        <p id="439">
                            <a id="bibliography_31" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MzE3MzFRVE1ud1plWnVIeWptVUx2SktGc2NheEk9TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[31]</b>Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735-1780
                            </a>
                        </p>
                        <p id="441">
                            <a id="bibliography_32" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011769&amp;v=MTM1NDBIdGpNcW85RlpPb09DM293b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0ZzY2F4ST1OaWZKWmJLOQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[32]</b>Gers F A, Schmidhuber J, Cummins F.Learning to forget:Continual prediction with LSTM[J].Neural Computation, 2000, 12 (10) :2451-2471
                            </a>
                        </p>
                        <p id="443">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Noise Reduction in Speech Processing">

                                <b>[33]</b>Benesty J, Chen Jingdong, Huang Yiteng, et al.Noise Reduction in Speech Processing[M].Berlin:Springer, 2009:37-40
                            </a>
                        </p>
                        <p id="445">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancing Collaborative Filtering by User Interest Expansion via Personalized Ranking">

                                <b>[34]</b>Liu Qi, Chen Enhong, Xiong Hui, et al.Enhancing collaborative filtering by user interest expansion via personalized ranking[J].IEEE Transactions on Systems, Man, and Cybernetics:Part B, 2012, 42 (1) :218-233
                            </a>
                        </p>
                        <p id="447">
                            <a id="bibliography_35" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603922913&amp;v=MjE0OTBmWWVySzhIOVBNcVk5R2Jla05CWDA2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0ZzY2F4ST1OaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[35]</b>Cox D R.The regression analysis of binary sequences[J].Journal of the Royal Statistical Society:Series B, 1958, 20 (2) :215-242
                            </a>
                        </p>
                        <p id="449">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Support vector regression machines">

                                <b>[36]</b>Drucker H, Burges C J C, Kaufman L, et al.Support vector regression machines[C]Proc of the 26th Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 1997:155-161
                            </a>
                        </p>
                        <p id="451">
                            <a id="bibliography_37" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDMwOTZ6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkN6a1c3ckFJVjQ9Tmo3QmFyTzRIdEhOckl0Rlp1d09ZM2s1&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[37]</b>Breiman L.Random forests[J].Machine Learning, 2001, 45 (1) :5-32
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201905011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201905011&amp;v=Mjk3OTlHRnJDVVJMT2VaZVJxRmlEZ1c3N0lMeXZTZExHNEg5ak1xbzlFWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4ajlSL2ZSTUZMbVBaQVM3az0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

