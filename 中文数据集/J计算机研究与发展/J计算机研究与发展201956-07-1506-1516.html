

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127908755743750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201907014%26RESULT%3d1%26SIGN%3d7i%252bo0JOpR2GeupvO4HpUw13LGKk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201907014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201907014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201907014&amp;v=MDc1MTZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXJtVmJ2Tkx5dlNkTEc0SDlqTXFJOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;1 相关研究&lt;/b&gt; "><b>1 相关研究</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="&lt;b&gt;1.1 否定与不确定覆盖域检测&lt;/b&gt;"><b>1.1 否定与不确定覆盖域检测</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;1.2  BiLSTM-CRF模型&lt;/b&gt;"><b>1.2  BiLSTM-CRF模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="&lt;b&gt;2 汉语否定与不确定覆盖域检测&lt;/b&gt; "><b>2 汉语否定与不确定覆盖域检测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="&lt;b&gt;2.1 BiLSTM-CRF模型&lt;/b&gt;"><b>2.1 BiLSTM-CRF模型</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;2.2 面向汉语的否定与不确定覆盖域检测模型&lt;/b&gt;"><b>2.2 面向汉语的否定与不确定覆盖域检测模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#139" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#141" data-title="&lt;b&gt;3.1 实验设置&lt;/b&gt;"><b>3.1 实验设置</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;3.2 实验结果及分析&lt;/b&gt;"><b>3.2 实验结果及分析</b></a></li>
                                                <li><a href="#194" data-title="&lt;b&gt;3.3 与现有方法的性能比较&lt;/b&gt;"><b>3.3 与现有方法的性能比较</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#202" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#122" data-title="图1 BiLSTM-CRF模型框架">图1 BiLSTM-CRF模型框架</a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;表1 汉语否定与不确定语料库 (CNeSp) 数据统计&lt;/b&gt;"><b>表1 汉语否定与不确定语料库 (CNeSp) 数据统计</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;表2 不同模型和不同特征对否定覆盖域检测系统性能影响&lt;/b&gt; %"><b>表2 不同模型和不同特征对否定覆盖域检测系统性能影响</b> %</a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表3 不同模型和不同特征对不确定覆盖域检测系统性能影响&lt;/b&gt; %"><b>表3 不同模型和不同特征对不确定覆盖域检测系统性能影响</b> %</a></li>
                                                <li><a href="#179" data-title="&lt;b&gt;表4 不同标记方案系统&lt;i&gt;PCS&lt;/i&gt;性能比较&lt;/b&gt; %"><b>表4 不同标记方案系统<i>PCS</i>性能比较</b> %</a></li>
                                                <li><a href="#180" data-title="图2 训练数据集大小对系统性能的影响">图2 训练数据集大小对系统性能的影响</a></li>
                                                <li><a href="#183" data-title="图3 位置特征维度和LSTM隐藏层维度对系统性能的影响">图3 位置特征维度和LSTM隐藏层维度对系统性能的影响</a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;表5 不同系统&lt;i&gt;PCS&lt;/i&gt;性能比较&lt;/b&gt;"><b>表5 不同系统<i>PCS</i>性能比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="239">


                                    <a id="bibliography_1" title="Blanco E, Dan M.Semantic representation of negation using focus detection[C] //Proc of the 49th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2011:581- 589" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semantic representation of negation using focus detection">
                                        <b>[1]</b>
                                        Blanco E, Dan M.Semantic representation of negation using focus detection[C] //Proc of the 49th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2011:581- 589
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_2" title="Medlock B, Briscoe T.Weakly supervised learning for hedge classification in scientific literature[C] //Proc of the 45th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2007:992- 999" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weakly supervised learning for hedge classification in scientific literature">
                                        <b>[2]</b>
                                        Medlock B, Briscoe T.Weakly supervised learning for hedge classification in scientific literature[C] //Proc of the 45th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2007:992- 999
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_3" title="Qian Zhong, Li Peifeng, Zhu Qiaoming, et al.Speculation and negation scope detection via convolutional neural networks[C] //Proc of EMNLP&#39;16.Stroudsburg, PA:ACL, 2016:815- 825" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speculation and negation scope detection via convolutional neural networks">
                                        <b>[3]</b>
                                        Qian Zhong, Li Peifeng, Zhu Qiaoming, et al.Speculation and negation scope detection via convolutional neural networks[C] //Proc of EMNLP&#39;16.Stroudsburg, PA:ACL, 2016:815- 825
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_4" title="Zou Bowei, Zhou Guodong, Zhu Qiaoming.Tree kernel-based negation and speculation scope detection with structured syntactic parse features[C] //Proc of EMNLP&#39;13.Stroudsburg, PA:ACL, 2013:968- 976" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tree kernel-based negation and speculation scope detection with structured syntactic parse features">
                                        <b>[4]</b>
                                        Zou Bowei, Zhou Guodong, Zhu Qiaoming.Tree kernel-based negation and speculation scope detection with structured syntactic parse features[C] //Proc of EMNLP&#39;13.Stroudsburg, PA:ACL, 2013:968- 976
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_5" title="Fancellu F, Lopez A, Webber B.Neural networks for negation scope detection[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:495- 504" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural networks for negation scope detection">
                                        <b>[5]</b>
                                        Fancellu F, Lopez A, Webber B.Neural networks for negation scope detection[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:495- 504
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_6" title="Vincze V.The BioScope corpus:Annotation for negation, uncertainty and their scope in biomedical texts[C] //Proc of the 46th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2008:38- 45" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The BioScope corpus:Annotation for negation,uncertainty and their scope in biomedical texts">
                                        <b>[6]</b>
                                        Vincze V.The BioScope corpus:Annotation for negation, uncertainty and their scope in biomedical texts[C] //Proc of the 46th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2008:38- 45
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_7" title="Vincze V.The CoNLL-2010 shared task:Learning to detect hedges and their scope in natural language text[C] //Proc of the 48th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2010:1- 12" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The CoNLL-2010 shared task:Learning to detect hedges and their scope in natural language text">
                                        <b>[7]</b>
                                        Vincze V.The CoNLL-2010 shared task:Learning to detect hedges and their scope in natural language text[C] //Proc of the 48th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2010:1- 12
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_8" title="Zou Bowei, Zhu Qiaoming, Zhou Guodong.Negation and speculation identification in Chinese language[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:656- 665" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Negation and Speculation Identification in Chinese Language">
                                        <b>[8]</b>
                                        Zou Bowei, Zhu Qiaoming, Zhou Guodong.Negation and speculation identification in Chinese language[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:656- 665
                                    </a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_9" title="Zou Bowei, Qian Zhong, Chen Zhancheng, et al.Negative and speculation information extraction for natural language Texts[J].Journal of Software, 2016, 27 (2) :309- 328 (in Chinese) (邹博伟, 钱忠, 陈站成, 等.面向自然语言文本的否定性与不确定性信息抽取[J].软件学报, 2016, 27 (2) :309- 328) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201602009&amp;v=MTE5MTE0TzN6cXFCdEdGckNVUkxPZVplUnJGeXJtVmJ2Tk55ZlRiTEc0SDlmTXJZOUZiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Zou Bowei, Qian Zhong, Chen Zhancheng, et al.Negative and speculation information extraction for natural language Texts[J].Journal of Software, 2016, 27 (2) :309- 328 (in Chinese) (邹博伟, 钱忠, 陈站成, 等.面向自然语言文本的否定性与不确定性信息抽取[J].软件学报, 2016, 27 (2) :309- 328) 
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_10" title="Cho K, Merrienboer B, Gulcehre C, et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation[C].//Proc of EMNLP&#39;14.Stroudsburg, PA:ACL, 2014:1724- 1734" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning phrase representations using RNN encoder-decoder for sta-tistical machine translation">
                                        <b>[10]</b>
                                        Cho K, Merrienboer B, Gulcehre C, et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation[C].//Proc of EMNLP&#39;14.Stroudsburg, PA:ACL, 2014:1724- 1734
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_11" title="Bahdanau D, Cho K, Bengio Y.Neural machine translation by jointly learning to align and translate[J].arXiv preprint arXiv:1409.0473, 2014" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[11]</b>
                                        Bahdanau D, Cho K, Bengio Y.Neural machine translation by jointly learning to align and translate[J].arXiv preprint arXiv:1409.0473, 2014
                                    </a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_12" title="Santos C, Gattit M.Deep convolutional neural networks for sentiment Analysis of short texts[C] //Proc of the 25th Int Conf on Computational Linguistics.New York:ACM, 2014:69- 78" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural networks for sentiment analysis of short texts">
                                        <b>[12]</b>
                                        Santos C, Gattit M.Deep convolutional neural networks for sentiment Analysis of short texts[C] //Proc of the 25th Int Conf on Computational Linguistics.New York:ACM, 2014:69- 78
                                    </a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_13" title="Wang Jin, Yu L-C, Lai K R, et al.Dimensional sentiment analysis using a regional CNN-LSTM model[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:225- 230" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensional sentiment analysis using a regional CNN-LSTM model">
                                        <b>[13]</b>
                                        Wang Jin, Yu L-C, Lai K R, et al.Dimensional sentiment analysis using a regional CNN-LSTM model[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:225- 230
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_14" title="Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of EMNLP&#39;15.Stroudsburg, PA:ACL, 2015:1753- 1762" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant supervision for relation extraction via piecewise convolutional neural networks">
                                        <b>[14]</b>
                                        Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of EMNLP&#39;15.Stroudsburg, PA:ACL, 2015:1753- 1762
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_15" title="Lin Yankai, Shen Shiqi, Liu Zhiyuan, et al.Neural relation extraction with selective attention over instances[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:2124- 2133" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural relation extraction with selective attention over instances">
                                        <b>[15]</b>
                                        Lin Yankai, Shen Shiqi, Liu Zhiyuan, et al.Neural relation extraction with selective attention over instances[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:2124- 2133
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_16" title="Ma Xuezhe, Hovy E.End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:1064- 1074" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-end sequence labeling via bi-directional lstm-cnns-crf">
                                        <b>[16]</b>
                                        Ma Xuezhe, Hovy E.End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:1064- 1074
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_17" title="Lample G, Ballesteros M, Subramanian S, et al.Neural architectures for named entity recognition[C] //Proc of the 52nd Conf of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies (NAACL-HLT) .Stroudsburg, PA:ACL, 2016:260- 270" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural architectures for named entity recognition">
                                        <b>[17]</b>
                                        Lample G, Ballesteros M, Subramanian S, et al.Neural architectures for named entity recognition[C] //Proc of the 52nd Conf of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies (NAACL-HLT) .Stroudsburg, PA:ACL, 2016:260- 270
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                    Lafferty J, Mccallum A, Pereira F.Conditional random fields:Probabilistic models for segmenting and labeling sequence data[C] //Proc of the 18th Int Conf on Machine Learning.New York:ACM, 2001:282- 289</a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_19" title="Chapman W, Bridewell W, Hanbury P.A simple algorithm for identifying negated findings and diseases in discharge summaries[J].Journal of Biomedical Informatics, 2001, 34 (5) :301- 310" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300411428&amp;v=MDc3NDJySUlsMFNiaGM9TmlmT2ZiSzdIdEROckk5RllPb09DSDR4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Chapman W, Bridewell W, Hanbury P.A simple algorithm for identifying negated findings and diseases in discharge summaries[J].Journal of Biomedical Informatics, 2001, 34 (5) :301- 310
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_20" title="Huang Zhiheng, Xu Wei, Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv preprint arXiv:1508.01991, 2015" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">
                                        <b>[20]</b>
                                        Huang Zhiheng, Xu Wei, Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv preprint arXiv:1508.01991, 2015
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_21" title="Morante R, Liekens A, Daelemans W.Learning the scope of negation in biomedical texts[C] //Proc of EMNLP&#39;08.Stroudsburg, PA:ACL, 2008:715- 724" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning the Scope of Negation in Biomedical Texts">
                                        <b>[21]</b>
                                        Morante R, Liekens A, Daelemans W.Learning the scope of negation in biomedical texts[C] //Proc of EMNLP&#39;08.Stroudsburg, PA:ACL, 2008:715- 724
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_22" title="Goller C, Kuchler A.Learning task-dependent distributed representations by backpropagation through structure[C] //Proc of ICNN&#39;96.Piscataway, NJ:IEEE, 1996:347- 352" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning task-dependent distributed representations by backpropagation through structure">
                                        <b>[22]</b>
                                        Goller C, Kuchler A.Learning task-dependent distributed representations by backpropagation through structure[C] //Proc of ICNN&#39;96.Piscataway, NJ:IEEE, 1996:347- 352
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_23" title="Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735- 1780" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MjE3OTQvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxySUlsMFNiaGM9TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735- 1780
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_24" title="Graves A, Schmidhuber J.Framewise phoneme classification with bidirectional LSTM and other neural network architectures[J].Neural Networks, 2005, 18 (5) :602- 610" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300069870&amp;v=MDM5MjBUTW53WmVadUh5am1VTHJJSWwwU2JoYz1OaWZPZmJLN0h0RE9ySTlGWk8wR0JIczVvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Graves A, Schmidhuber J.Framewise phoneme classification with bidirectional LSTM and other neural network architectures[J].Neural Networks, 2005, 18 (5) :602- 610
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_25" title="Graves A, Mohamed A, Hinton G.Speech recognition with deep recurrent neural networks[C] //Proc of the 13th IEEE Int Conf on Communications.Piscataway, NJ:IEEE, 2013:6645- 6649" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speech recognition with deep recurrent neural networks">
                                        <b>[25]</b>
                                        Graves A, Mohamed A, Hinton G.Speech recognition with deep recurrent neural networks[C] //Proc of the 13th IEEE Int Conf on Communications.Piscataway, NJ:IEEE, 2013:6645- 6649
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_26" title="Santos C N D, Xiang Bing, Zhou Bowen.Classifying relations by ranking with convolutional neural networks[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:626- 634" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classifying relations by ranking with convolutio nal neural networks">
                                        <b>[26]</b>
                                        Santos C N D, Xiang Bing, Zhou Bowen.Classifying relations by ranking with convolutional neural networks[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:626- 634
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_27" title="He Hangfeng, Fancellu F, Webber B.Neural networks for negation cue detection in Chinese[C] //Proc of SemBEaR&#39;17.Stroudsburg, PA:ACL, 2017:59- 63" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural networks for negation cue detection in Chinese">
                                        <b>[27]</b>
                                        He Hangfeng, Fancellu F, Webber B.Neural networks for negation cue detection in Chinese[C] //Proc of SemBEaR&#39;17.Stroudsburg, PA:ACL, 2017:59- 63
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_28" title="Shi Tianze, Liu Zhiyuan, Liu Yang, et al.Learning cross-lingual word embeddings via matrixco-factorization[C] //Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2017:567- 572" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning cross-lingual word embeddings via matrixco-factorization">
                                        <b>[28]</b>
                                        Shi Tianze, Liu Zhiyuan, Liu Yang, et al.Learning cross-lingual word embeddings via matrixco-factorization[C] //Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2017:567- 572
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(07),1506-1516 DOI:10.7544/issn1000-1239.2019.20180725            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>汉语否定与不确定覆盖域检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B6%E9%9D%99&amp;code=38884930&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">叶静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E5%8D%9A%E4%BC%9F&amp;code=33805768&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹博伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B4%AA%E5%AE%87&amp;code=25038035&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">洪宇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B2%88%E9%BE%99%E9%AA%A7&amp;code=41093929&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈龙骧</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%B7%A7%E6%98%8E&amp;code=05968617&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱巧明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E5%9B%BD%E6%A0%8B&amp;code=13898054&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周国栋</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%8B%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0240077&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏州大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>自然语言文本中存在大量否定和不确定表述, 识别这些信息并将其与确定性内容分离, 对自然语言处理的下游应用, 如信息抽取、信息检索、情感分析等, 都具有十分重要的意义.与英语相比, 面向汉语的否定与不确定覆盖域检测研究目前较为匮乏.提出了一个基于双向长短期记忆 (bidirectional long short-term memory, BiLSTM) 网络和条件随机场 (conditional random fields, CRF) 的融合模型, 将覆盖域检测任务作为序列标注问题, 针对给定的否定或不确定关键词, 识别其在句子中的语义作用范围.该模型既具有LSTM (long short-term memory) 网络能够利用前向与后向上下文信息的特性, 同时又能够借助CRF层获取输出标签之间的依赖关系, 这得益于该框架能够有效地对序列信息及长距离上下文依赖信息进行编码的优势.在CNeSp语料集上的实验结果验证了模型的有效性, 其中, 在金融新闻子数据集上, 否定与不确定覆盖域检测准确率分别达到79.16%和76.79%, 比目前基于传统机器学习的汉语覆盖域检测方法分别提升了25.06%和34.46%.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%A6%E5%AE%9A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">否定;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E7%A1%AE%E5%AE%9A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不确定;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A6%86%E7%9B%96%E5%9F%9F%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">覆盖域检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BiLSTM-CRF%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BiLSTM-CRF模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">序列标注;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    Ye Jing, born in 1994.Master candidate. Her main research interest is information extraction. jye.scu@gmail.com;
                                </span>
                                <span>
                                    *Zou Bowei, born in 1984.PhD.His main research  interests  include information extraction and discourse analysis. zoubowei@suda.edu.cn;
                                </span>
                                <span>
                                    Hong Yu, born in 1978.PhD.Associate professor in Soochow University.His main research  interests  include information extraction and discourse analysis.;
                                </span>
                                <span>
                                    Shen Longxiang, born in 1995.Master candidate.His main research interest is information extraction.;
                                </span>
                                <span>
                                    Zhu Qiaoming, born in 1964. PhD. Professor in Soochow University. His main research interests include Chinese computing, information extraction.;
                                </span>
                                <span>
                                    Zhou Guodong, born in 1967. PhD. Professor in Soochow University. His main research interests include natural language understanding, Chinese computing and information extraction.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61703293, 61672367, 61751206);</span>
                    </p>
            </div>
                    <h1><b>Negation and Speculation Scope Detection in Chinese</b></h1>
                    <h2>
                    <span>Ye Jing</span>
                    <span>Zou Bowei</span>
                    <span>Hong Yu</span>
                    <span>Shen Longxiang</span>
                    <span>Zhu Qiaoming</span>
                    <span>Zhou Guodong</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Soochow University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>There are a great deal of negative and speculative expressions in natural language texts. Identifying such information and separating them from the affirmative content plays a critical role in a variety of downstream applications of natural language processing, such as information extraction, information retrieval, and sentiment analysis. Compared with that in English, current research on negative and speculative scope detection for Chinese is scarce. In this paper, we come up with a fusion model based on bidirectional long-term memory (BiLSTM) networks and conditional random fields (CRF) , and recast the scope detection problem as a sequence-labeling task. Given a negative or speculative keyword, we need to identify its semantic scope in sentence. This model can learn not only the forward and backward context information by LSTM networks but also the dependency relationship between the output labels via a CRF layer, which is motivated by the superiority of sequential architecture in effectively encoding order information and long-range context dependency. The experimental results on CNeSp corpus show the effectiveness of our proposed model. On the financial dataset, our approach achieves the performance of 79.16% and 76.79% with the improvements of 25.06% and 34.46% for negation and speculation, respectively, compared with the state-of-the-art.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=negation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">negation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=speculation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">speculation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=scope%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">scope detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BiLSTM-CRF%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BiLSTM-CRF model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sequence%20labeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sequence labeling;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-01</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61703293, 61672367, 61751206);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="75">自然语言文本存在大量否定与不确定语义表述, 将其与事实性信息分离处理, 能够为自然语言处理的下游应用 (如知识库构建、信息抽取、情感分析等) 提供准确性保证.本文旨在研究识别出句子中包含否定或不确定语义的文本片段.其中, 否定语义指对某一命题或断言的存在或发生进行反转<citation id="295" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>;不确定语义指事物的类属边界或性质状态不明确, 人们对事物属性处于一种模糊认识状态<citation id="296" type="reference"><link href="241" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="76">通常地, 否定与不确定表述由一个关键词或短语及其在句子中支配的语义作用范围 (覆盖域) 组成.例句<sup>①</sup>:</p>
                </div>
                <div class="p1">
                    <p id="77"><b>例1</b>. 我建议大家和提醒其他人[不要到这家酒店]!</p>
                </div>
                <div class="p1">
                    <p id="78"><b>例2</b>. [唯一觉得还可以的是中餐厅], 用餐也不贵.</p>
                </div>
                <div class="p1">
                    <p id="79">其中, 例1中否定关键词“不要”的语义作用范围是“不要到这家酒店”, 而前半句内容并未受否定关键词的影响;同样, 例2中表示不确定语义的关键词为“觉得”, 其对应的语义作用范围是“唯一觉得还可以的是中餐厅的菜”, 句子中其余部分未包含不确定语义.</p>
                </div>
                <div class="p1">
                    <p id="80">覆盖域检测 (scope detection) 是否定与不确定性信息抽取研究中的核心任务, 对给定的否定或不确定关键词, 识别其在句子中管辖的文本片段.覆盖域检测研究最早集中于生物信息抽取领域, 自动抽取科技文献或病程记录中被否定或推测的实体或文本<citation id="297" type="reference"><link href="243" rel="bibliography" /><link href="245" rel="bibliography" /><link href="247" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>.近年来, 该任务逐渐开始作为基础的自然语言理解任务, 受到广泛关注<citation id="298" type="reference"><link href="243" rel="bibliography" /><link href="245" rel="bibliography" /><link href="247" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="81">由于语料资源相对缺乏, 面向汉语的否定与不确定检测研究仍处于探索阶段, 现有方法大都基于规则或传统的特征工程方法<citation id="300" type="reference"><link href="239" rel="bibliography" /><link href="241" rel="bibliography" /><link href="245" rel="bibliography" /><link href="249" rel="bibliography" /><link href="251" rel="bibliography" /><link href="253" rel="bibliography" /><link href="255" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">4</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.例如Zou等人<citation id="299" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了一种基于树核的否定与不确定覆盖域检测方法, 其中抽取了包括词性、成分句法与依存句法等21种特征模板.这些方法需要领域专家进行特征模板的设计, 费时费力, 且可扩展性较差.相比传统方法, 神经网络模型能够从原始数据中自主学习, 获取更深层次、更抽象的潜在特征, 其优势已在自然语言处理领域的其他任务, 如机器翻译<citation id="301" type="reference"><link href="257" rel="bibliography" /><link href="259" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>、情感分析<citation id="302" type="reference"><link href="261" rel="bibliography" /><link href="263" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>、信息抽取<citation id="303" type="reference"><link href="265" rel="bibliography" /><link href="267" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>等中, 得到了验证.</p>
                </div>
                <div class="p1">
                    <p id="82">本文首次采用神经网络模型解决面向汉语的否定与不确定覆盖域检测问题, 将其作为序列标注任务, 采用双向长短期记忆网络 (bidirectional long short-term memory, BiLSTM) <citation id="305" type="reference"><link href="269" rel="bibliography" /><link href="271" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>和条件随机场 (conditional random fields, CRF) <citation id="304" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>进行建模.首先, 将句子中每个词通过预训练的词向量进行向量化, 并将每个词的相关特征 (位置、词性、句法特征、依存特征) 进行向量化, 然后进行组合作为BiLSTM网络的输入, 通过BiLSTM学习上下文信息, 并通过CRF层学习相邻标签之间的依赖关系, 最终解码出最优的标签序列.</p>
                </div>
                <div class="p1">
                    <p id="83">在CNeSp语料库<citation id="306" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>上的实验结果表明:本文基于BiLSTM-CRF模型的覆盖域检测方法性能分别达到79.16% (否定) 和76.79% (不确定) , 比目前基于传统机器学习的系统分别提升了25.06%和34.46%.</p>
                </div>
                <div class="p1">
                    <p id="84">本文的主要贡献可归纳为3个方面:</p>
                </div>
                <div class="p1">
                    <p id="85">1) 将覆盖域识别任务作为序列标注问题, 提出了一种面向汉语覆盖域检测任务的基于双向长短期记忆网络 (BiLSTM) 与条件随机场 (CRF) 融合模型, 该模型能够有效地学习和优化上远距离下文中的依赖关系;</p>
                </div>
                <div class="p1">
                    <p id="86">2) 探索了词性、相对位置、成分句法标记、依存句法路径等特征在基于神经网络模型中, 对覆盖域检测任务的影响;</p>
                </div>
                <div class="p1">
                    <p id="87">3) 较大程度地提升了汉语覆盖域检测系统性能, 为相关研究提供了基准系统.</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>1 相关研究</b></h3>
                <div class="p1">
                    <p id="89">本节主要介绍否定与不确定覆盖域检测任务的研究进展, 以及BiLSTM-CRF模型在自然语言处理领域中的相关应用.</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>1.1 否定与不确定覆盖域检测</b></h4>
                <div class="p1">
                    <p id="91">覆盖域检测研究最早出现于面向生物信息文本的自然语言处理领域.早期的覆盖域检测方法通常基于启发式规则.例如Chapman等人<citation id="307" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>发布了基于正则表达式算法的NegEx系统;Huang等人<citation id="308" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>在句法树结构上, 利用启发式规则判定句法树结构是否处于某个否定关键词的作用范围之内.基于规则的方法实现简单且准确率较高, 但其可扩展性较差;随着BioScope语料库的发布<citation id="309" type="reference"><link href="249" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 基于特征工程的方法逐渐成为主流, 例如Morante等人<citation id="310" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>首次采用机器学习方法对否定关键词的覆盖域进行检测, 此后, 其又融合浅层句法特征与依存句法特征, 获得了CoNLL'2010-Task2 评测的最优性能.</p>
                </div>
                <div class="p1">
                    <p id="92">由于缺少语料资源, 面向汉语的否定与不确定覆盖域检测研究起步较晚.Zou等人<citation id="311" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>标注了汉语否定与不确定语料库 (CNeSp) , 该语料库共16 841句, 其中包含科技文献、金融新闻、酒店评论3种不同领域的数据集.同时提出了一个基于特征工程的基准系统, 该系统的性能达到54.10% (否定) 和42.33% (不确定) .本文提出的模型在该语料库上进行验证与比较.</p>
                </div>
                <div class="p1">
                    <p id="93">以上基于特征工程的方法不仅依赖大量的领域知识和经验, 模型的泛化能力也较差.而本文提出基于双向长短期记忆网络和条件随机场的覆盖域检测模型能够有效利用上下文信息, 并考虑相邻标记的依赖关系, 自动学习潜在特征.</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>1.2  BiLSTM-CRF模型</b></h4>
                <div class="p1">
                    <p id="95">近年来, 神经网络模型在自然语言处理的各个任务中均取得了突破性进展.其中, 循环神经网络 (recurrent neural network, RNN) <citation id="312" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>能够很好地处理序列信息并从中学习有效特征, 其最初由Goller等人<citation id="313" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出;但由于RNN在深度学习中存在梯度消失和梯度爆炸问题, Hochreiter等人<citation id="314" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>继而提出了RNN的变体长短期记忆网络 (LSTM) ;之后, 在单向LSTM 学习序列特征时, 其仅考虑该序列的上文信息, 而忽略了下文信息.为克服这个问题, Graves等人<citation id="316" type="reference"><link href="285" rel="bibliography" /><link href="287" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>提出双向LSTM (BiLSTM) 模型, 并将其应用于语音识别任务, 该模型能够在一定时间内充分利用上下文信息;此外, 条件随机场 (CRF) 由Lafferty等人于2001年<citation id="315" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出, 在序列标注任务中, CRF能够学习相邻标记之间的依赖关系.</p>
                </div>
                <div class="p1">
                    <p id="96">基于BiLSTM和CRF模型在序列标注任务中的各自优势, 相关研究尝试将其进行融合.例如Huang等人<citation id="317" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>首次将BiLSTM与CRF的融合模型用于词性标注、语块分析、命名实体识别3类序列标注任务;Ma等人<citation id="318" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>将BiLSTM, CRF, CNN这3种模型进行融合并应用于端到端的序列标注任务中;Lample等人<citation id="319" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>将BiLSTM-CRF模型用于命名实体识别任务中.BiLSTM-CRF模型在以上序列标注任务中均取得了较高性能, 基于此, 本文尝试将该模型应用于面向汉语的否定与不确定覆盖域检测任务中.</p>
                </div>
                <h3 id="97" name="97" class="anchor-tag"><b>2 汉语否定与不确定覆盖域检测</b></h3>
                <div class="p1">
                    <p id="98">本节首先介绍BiLSTM-CRF模型, 其次我们将覆盖域检测作为序列标注任务, 给出序列标记方案及特征集合.</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>2.1 BiLSTM-CRF模型</b></h4>
                <div class="p1">
                    <p id="100">LSTM单元能够有效消除冗余的上下文信息, 并学习长距离依赖特征, 因而被广泛应用于解决序列标注任务上.LSTM单元通常包含4个部分:输入门 (input gate) 、遗忘门 (forget gate) 、输出门 (output gate) 和细胞状态 (cell) .形式地, 设<b><i>x</i></b>为输入, <b><i>h</i></b>为隐藏状态的输出.LSTM单元的状态不仅取决于当前输入<b><i>x</i></b><sub><i>t</i></sub>, 还受到上一时刻的输出值<b><i>h</i></b><sub><i>t</i>-1</sub>的影响.单个LSTM单元更新步骤为</p>
                </div>
                <div class="p1">
                    <p id="101"><b><i>i</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>i</i></sub><b><i>x</i></b><sub><i>t</i></sub>+<b><i>U</i></b><sub><i>i</i></sub><b><i>h</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub><i>i</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="102"><b><i>f</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>f</i></sub><b><i>x</i></b><sub><i>t</i></sub>+<b><i>U</i></b><sub><i>f</i></sub><b><i>h</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub><i>f</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="103"><b><i>o</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sub><i>o</i></sub><b><i>x</i></b><sub><i>t</i></sub>+<b><i>U</i></b><sub><i>o</i></sub><b><i>h</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub><i>o</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="104"><b><i>c</i></b><sub><i>t</i></sub>=<b><i>f</i></b><sub><i>t</i></sub>⨂<b><i>c</i></b><sub><i>t</i>-1</sub>+<b><i>i</i></b><sub><i>t</i></sub>⨂tanh (<b><i>W</i></b><sub><i>c</i></sub><b><i>x</i></b><sub><i>t</i></sub>+<b><i>U</i></b><sub><i>c</i></sub><b><i>h</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b><sub><i>c</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="105"><b><i>h</i></b><sub><i>t</i></sub>=<b><i>o</i></b><sub><i>t</i></sub>⨂tanh (<b><i>c</i></b><sub><i>t</i></sub>) , (1) </p>
                </div>
                <div class="p1">
                    <p id="106">其中, <b><i>i</i></b><sub><i>t</i></sub>, <b><i>f</i></b><sub><i>t</i></sub>, <b><i>o</i></b><sub><i>t</i></sub>, <b><i>c</i></b><sub><i>t</i></sub>, 分别表示时刻<i>t</i>输入门、遗忘门、输出门和细胞状态的输出, <b><i>x</i></b><sub><i>t</i></sub>和<b><i>h</i></b><sub><i>t</i></sub>表示时刻<i>t</i>的输入向量和隐藏层向量, <i>σ</i> (·) 表示sigmoid激活函数, <b><i>W</i></b>和<b><i>b</i></b>分别表示权重矩阵和偏置向量, 下标表示其所属归类, 例如<b><i>W</i></b><sub><i>i</i></sub>和<b><i>b</i></b><sub><i>i</i></sub>分别表示属于输入门结构中的权重矩阵和偏置向量.</p>
                </div>
                <div class="p1">
                    <p id="107">由于LSTM结构无法同时学习2个方向的上下文特征, 本文采用双向LSTM (BiLSTM) 模型.如图1所示, 该模型包含2个不同方向的并行层、前向层和后向层, 分别从句子的前端和末端开始运行, 存储2个方向的上下文信息.</p>
                </div>
                <div class="p1">
                    <p id="108">在覆盖域检测中, 当前词的标签通常与其周围的词存在关联, 例如表示出现于关键词之前的标签B必须位于表示出现于关键词后的标签A (具体标记方案参见2.2节) .CRF模型能够通过相邻词之间的条件概率, 学习标签之间的依赖关系, 本文在BiLSTM结构上层增加CRF结构, 以获得全局最优的标签序列.给定句子:</p>
                </div>
                <div class="p1">
                    <p id="109"><i>x</i>= (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="110">其预测标签序列为</p>
                </div>
                <div class="p1">
                    <p id="111"><i>y</i>= (<i>y</i><sub>1</sub>, <i>y</i><sub>2</sub>, …, <i>y</i><sub><i>n</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="112">得分为</p>
                </div>
                <div class="p1">
                    <p id="113"><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mi>A</mi></mstyle><msub><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub></mrow></math></mathml>, (2) </p>
                </div>
                <div class="p1">
                    <p id="115">其中, <b><i>C</i></b>为BiLSTM网络的输出, 大小为<i>n</i>×<i>k</i>, <i>k</i>表示不同标签个数, <i>C</i><sub><i>i</i>, <i>j</i></sub>表示句子中第<i>i</i>个词的第<i>j</i>个标签的得分;<i>A</i><sub><i>i</i>, <i>j</i></sub>表示第<i>i</i>个标签到第<i>j</i>个标签的转移概率, 矩阵<b><i>A</i></b>大小为 (<i>k</i>+2) × (<i>k</i>+2) , 由于在一个句子首尾添加了START和END标签, 即<i>y</i><sub>0</sub>和<i>y</i><sub><i>n</i>+1</sub>.对句子所有可能的标签序列采用柔性最大值 (softmax) 进行归一化: </p>
                </div>
                <div class="area_img" id="340">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201907014_34000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="117">其中, <i>Y</i>表示所有可能的标签序列集合.训练过程中, 对正确标签序列进行最大化似然概率的计算:</p>
                </div>
                <div class="p1">
                    <p id="118"><i>L</i>=max ln (<i>p</i> (<i>y</i>|<i>x</i>) ) . (4) </p>
                </div>
                <div class="p1">
                    <p id="119">最后, 在解码端将最高得分的标签序列作为最终的标签序列输出:</p>
                </div>
                <div class="p1">
                    <p id="120"><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>¯</mo></mover><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>max</mi></mrow></mstyle><mi>Y</mi></munder><mspace width="0.25em" /><mi>s</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>, </mo><mi>Y</mi><mo stretchy="false">) </mo></mrow></math></mathml>. (5) </p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907014_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 BiLSTM-CRF模型框架" src="Detail/GetImg?filename=images/JFYZ201907014_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 BiLSTM-CRF模型框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907014_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Framework of the BiLSTM-CRF model</p>

                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>2.2 面向汉语的否定与不确定覆盖域检测模型</b></h4>
                <div class="p1">
                    <p id="124">本文提出的基于BiLSTM-CRF的覆盖域检测模型框架如图1所示.首先, 将句子中的单词进行向量化表示, 除了词向量 (<b><i>W</i></b><sub>E</sub>) , 本文还探索了其他特征, 如位置特征 (<b><i>P</i></b><sub>E</sub>) 、句法结构特征 (<b><i>C</i></b><sub>E</sub>) 、词性特征 (<b><i>N</i></b><sub>E</sub>) 、依存特征 (<b><i>D</i></b><sub>E</sub>) .然后, 将嵌入层向量送入前向LSTM和后向LSTM, 学习相关的上下文特征, 再将输出进行拼接, 作为CRF层的输入, 学习标签依赖关系, 最终解码出全局最优的标签序列.此外, 本模型为了减少过拟合, 在BiLSTM网络两端各添加了dropout层.</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">1) 标记方案</h4>
                <div class="p1">
                    <p id="126">本文采用BAO标记方案, 含义如下.</p>
                </div>
                <div class="p1">
                    <p id="127">标记B (before) :位于覆盖域内, 关键词之前;</p>
                </div>
                <div class="p1">
                    <p id="128">标记A (after) :位于覆盖域内, 关键词之后, 包含关键词;</p>
                </div>
                <div class="p1">
                    <p id="129">标记O (outside) :位于覆盖域之外.</p>
                </div>
                <div class="p1">
                    <p id="130">对分词后的句子进行标记举例:</p>
                </div>
                <div class="p1">
                    <p id="131"><b>例3</b>. 唯一/B 觉得/A 还/A 可以/A 的/A 是/A 中餐厅/A 的/A 菜/A , /O 用餐/O 也/O 不贵/O ./O</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">2) Embedding层</h4>
                <div class="p1">
                    <p id="133">该层作为模型的输入, 本文将词及其对应的特征进行编码.给定句子<i>S</i>= (<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>n</i></sub>) , 首先用向量矩阵<b><i>W</i></b><sub>E</sub>将每个词转化成维度大小为<i>d</i><sub>w</sub>的向量, 其中, <b><i>W</i></b><sub>E</sub>∈R<sup><i>d</i><sub>w</sub>×|<i>V</i>|</sup>, <i>V</i>表示词表.</p>
                </div>
                <div class="p1">
                    <p id="134">在自然语言处理领域, 相关研究已经验证了词性、相对位置、成分句法、依存句法等特征的重要性<citation id="320" type="reference"><link href="245" rel="bibliography" /><link href="253" rel="bibliography" /><link href="255" rel="bibliography" /><link href="289" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">26</a>]</sup></citation>.本文同时探索了这些特征对覆盖域检测任务 的有效性, 其向量化表示如下.</p>
                </div>
                <div class="p1">
                    <p id="135">词性.向量矩阵<b><i>N</i></b><sub>E</sub>将每个词的词性映射为一个维度为<i>d</i><sub>nat</sub>的实值向量, 其中, <b><i>N</i></b><sub>E</sub>∈R<sup><i>d</i><sub>nat</sub>×|<i>V</i><sub>nat</sub>|</sup>, <i>V</i><sub>nat</sub>表示词性集合, 采用随机初始化;</p>
                </div>
                <div class="p1">
                    <p id="136">相对位置.向量矩阵<b><i>P</i></b><sub>E</sub>将每个词与关键词之间的相对距离映射为一个维度为<i>d</i><sub>pos</sub>的实值向量, 其中, <b><i>P</i></b><sub>E</sub>∈R<sup><i>d</i><sub>pos</sub>×|<i>V</i><sub>pos</sub>|</sup>, <i>V</i><sub>pos</sub>表示相对距离的集合, 采用随机初始化;</p>
                </div>
                <div class="p1">
                    <p id="137">短语句法节点.向量矩阵<b><i>C</i></b><sub>E</sub>将每个词在句法树中的父亲节点映射为一个维度为<i>d</i><sub>con</sub>的实值向量, 其中, <b><i>C</i></b><sub>E</sub>∈R<sup><i>d</i><sub>con</sub>×|<i>V</i><sub>con</sub>|</sup>, <i>V</i><sub>con</sub>表示成分句法节点的集合, 采用随机初始化;</p>
                </div>
                <div class="p1">
                    <p id="138">依存句法节点.向量矩阵<b><i>D</i></b><sub>E</sub>将每个词在依存句法树中的父节点映射为一个维度为<i>d</i><sub>dep</sub>的实值向量, 其中, <b><i>D</i></b><sub>E</sub>∈R<sup><i>d</i><sub>dep</sub>×|<i>V</i><sub>dep</sub>|</sup>, <i>V</i><sub>dep</sub>表示依存句法节点的集合, 采用随机初始化.</p>
                </div>
                <h3 id="139" name="139" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="140">本节首先介绍实验数据集、参数设置以及实验所采用评价指标、基准系统;然后给出实验结果, 对参数的选择进行比较, 并对错误结果进行分析;最后, 与现有的覆盖域检测系统进行比较, 验证本文方法的有效性.</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141"><b>3.1 实验设置</b></h4>
                <div class="p1">
                    <p id="142">本文实验数据采用CNeSp语料库.该语料库包含科技文献、金融新闻、酒店评论3种类型的数据集, 共16 841句, 其中覆盖域实例数据为6 429个<citation id="321" type="reference"><link href="253" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.每个实例均标注了否定或不确定关键词及对应的覆盖域.表1对CNeSp语料库进行了统计.可以看出, 酒店评论数据的句子平均长度最短, 其覆盖域平均长度也最短;总体来说, 不确定覆盖域长度大于否定覆盖域.此外, 值得注意的是, 在酒店评论数据集中, 否定实例的比例为52.9%, 远高于其他2种类型的数据集, 其原因是在酒店评论数据中负面评论较为常见, 而在表述负面观点时, 通常包含否定语义.</p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit"><b>表1 汉语否定与不确定语料库 (CNeSp) 数据统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Statistics of the CNeSp Corpus</b></p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td><br />Type</td><td>Item</td><td>Scientific Literature</td><td>Financial News</td><td>Hotel Reviews</td></tr><tr><td><br /></td><td>Sentences</td><td>4 630</td><td>7 213</td><td>4 998</td></tr><tr><td><br /></td><td>Average Length of Sentences</td><td>30.4</td><td>30.7</td><td>24.1</td></tr><tr><td><br /></td><td>Keywords</td><td>44</td><td>201</td><td>128</td></tr><tr><td><br />Negation</td><td>Ratioof Sentences/%</td><td>13.2</td><td>17.5</td><td>52.9</td></tr><tr><td><br /></td><td>Average Length of Scopes</td><td>9.1</td><td>7.2</td><td>5.1</td></tr><tr><td><br /></td><td>Keywords</td><td>154</td><td>280</td><td>179</td></tr><tr><td><br />Speculation</td><td>Ratioof Sentences/%</td><td>21.6</td><td>30.5</td><td>22.6</td></tr><tr><td><br /></td><td>Average Length of Scopes</td><td>12.3</td><td>15.0</td><td>6.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="144">实验分别将3个数据集按照70%, 15%, 15%的比例划分为训练集、验证集和测试集<citation id="322" type="reference"><link href="291" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>.本文采用准确率 (precision) 、召回率 (recall) 和<i>F</i><sub>1</sub>值评价模型在标签标记时的性能.而在评价覆盖域检测的准确性时, 本文采用该任务的标准评价指标<citation id="323" type="reference"><link href="243" rel="bibliography" /><link href="245" rel="bibliography" /><link href="253" rel="bibliography" /><link href="255" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>, 正确覆盖域的百分比 (percentage of correct scopes, <i>PCS</i>) , 其计算方式为覆盖域标记正确句子数目与句子总数目的比值.两类评价指标各有侧重, <i>F</i><sub>1</sub>值以词为单位, 主要评价模型在标注序列中对每个单元的识别性能;而<i>PCS</i>指标以句子为单位, 直接衡量模型在覆盖域检测任务上的性能.总体而言, 后者作为主要性能指标, 比前者更严格.</p>
                </div>
                <div class="p1">
                    <p id="145">本文采用斯坦福句法分析工具 (CoreNLP) 获得句法特征<sup>①</sup>;中文分词工具采用结巴软件<sup>②</sup>;通过CLSim<sup>③</sup>预训练出50维的词向量进行向量化<citation id="324" type="reference"><link href="293" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>.超参数设置方面, 词性特征、位置特征、短语句法特征和依存句法特征维度均为20, <i>dropout</i>=0.4, LSTM隐藏层维度为150, 学习率为0.015.本文选择带冲量 (<i>momentum</i>) 的随机梯度下降 (stochastic gradient descent, SGD) 算法训练神经网络模型, 其中<i>momentum</i>=0.9.</p>
                </div>
                <div class="p1">
                    <p id="146">为比较不同模型及不同特征的性能, 本文采用3个模型作为基准系统.</p>
                </div>
                <div class="p1">
                    <p id="147">1) LSTM_P.采用单向长短期记忆网络, 输入为词向量和位置特征.</p>
                </div>
                <div class="p1">
                    <p id="148">2) BiLSTM_P.采用双向长短期记忆网络, 输入为词向量和位置特征.</p>
                </div>
                <div class="p1">
                    <p id="149">3) BiLSTM-CRF_P.该系统为本文提出的方法, 在BiLSTM网络上添加了CRF层, 输入为词向量和位置特征.</p>
                </div>
                <div class="p1">
                    <p id="150">此外, 为验证不同特征对覆盖域检测任务的有效性, 文本在BiLSTM-CRF_P模型上分别添加不同类型的特征.注意, 由于位置特征在该任务上最为重要, 因此在对比不同特征影响时, 系统中始终保留此特征.对比系统有5个:</p>
                </div>
                <div class="p1">
                    <p id="151">1) BiLSTM-CRF.输入仅包含词向量.</p>
                </div>
                <div class="p1">
                    <p id="152">2) BiLSTM-CRF_P_POS.输入包含词向量、位置特征、词性特征.</p>
                </div>
                <div class="p1">
                    <p id="153">3) BiLSTM-CRF_P_C.输入包含词向量、位置特征、短语句法特征.</p>
                </div>
                <div class="p1">
                    <p id="154">4) BiLSTM-CRF_P_D.输入包含词向量、位置特征、依存句法特征.</p>
                </div>
                <div class="p1">
                    <p id="155">5) BiLSTM-CRF_P_C_ POS.输入包含词向量、位置特征、词性特征、短语句法特征.</p>
                </div>
                <h4 class="anchor-tag" id="156" name="156"><b>3.2 实验结果及分析</b></h4>
                <h4 class="anchor-tag" id="157" name="157">3.2.1 不同模型对系统性能的影响</h4>
                <div class="p1">
                    <p id="158">表2和表3中行1～3对比了采用不同的序列标注模型的性能.可以看出, 本文系统 (BiLSTM-CRF_P) 获得了最好性能, 否定和不确定覆盖域检测的正确率 (<i>PCS</i>) 分别达到77.17%和76.43%.此外, 对比实验结果可以看出:1) BiLSTM模型的性能在不同类型的数据集上均比LSTM模型高出15%左右, 其原因主要是BiLSTM能够从前向和后向2个方向上学习, 比后者能够更加充分地利用上下文信息;2) 与BiLSTM相比, 本文提出的基于BiLSTM-CRF覆盖域检测系统在否定和不确定性能上均有较大幅度的提升 (<i>PCS</i>性能提升在10%左右) , 其原因主要是覆盖域通常为连续的文本片段, 相邻词之间具有较强的依赖关系, CRF模型能够通过对转移概率的学习更好地捕捉相邻标签之间的依赖关系, 弥补了BiLSTM的不足, 使得系统性能获得较大提升.</p>
                </div>
                <div class="area_img" id="159">
                    <p class="img_tit"><b>表2 不同模型和不同特征对否定覆盖域检测系统性能影响</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Influence of Different Models and Fearures on Performance of Systems onThree Different Datasets for Scope Detection in Negation</b></p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td rowspan="2"><br />Systems</td><td colspan="2"><br />Scientific Literature</td><td colspan="2">Financial News</td><td colspan="2">Hotel Reviews</td></tr><tr><td><br /><i>F</i><sub>1</sub></td><td><i>PCS</i></td><td><i>F</i><sub>1</sub></td><td><i>PCS</i></td><td><i>F</i><sub>1</sub></td><td><i>PCS</i></td></tr><tr><td><br />LSTM_P</td><td>75.47</td><td>22.50</td><td>75.72</td><td>45.91</td><td>87.34</td><td>45.95</td></tr><tr><td><br />BiLSTM_P</td><td>81.54</td><td>35.00</td><td>89.61</td><td>68.49</td><td>93.46</td><td>59.04</td></tr><tr><td><br />BiLSTM-CRF_P</td><td>87.08</td><td>62.50</td><td>89.31</td><td>77.17</td><td>94.74</td><td>72.73</td></tr><tr><td><br />BiLSTM-CRF</td><td>59.49</td><td>48.00</td><td>61.72</td><td>51.12</td><td>76.33</td><td>46.15</td></tr><tr><td><br />BiLSTM-CRF_P_ POS</td><td>88.83</td><td><b>63.10</b></td><td>89.70</td><td><b>79.16</b></td><td>94.63</td><td>73.13</td></tr><tr><td><br />BiLSTM-CRF_P_C</td><td><b>93.90</b></td><td>62.50</td><td>89.03</td><td>77.92</td><td>94.72</td><td><b>74.13</b></td></tr><tr><td><br />BiLSTM-CRF_P_D</td><td>82.08</td><td>60.00</td><td><b>90.08</b></td><td>76.87</td><td><b>93.83</b></td><td>70.73</td></tr><tr><td><br />BiLSTM-CRF_P_C_POS</td><td>88.48</td><td>62.75</td><td>89.22</td><td>78.41</td><td>94.67</td><td><b>74.13</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best result is bold.</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表3 不同模型和不同特征对不确定覆盖域检测系统性能影响</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Influence of Different Models and Fearures on Performance of Systems on Three Different Datasets for Scope Detection in Speculation</b></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td rowspan="2"><br />Systems</td><td colspan="2"><br />Scientific Literature</td><td colspan="2">Financial News</td><td colspan="2">Hotel Reviews</td></tr><tr><td><br /><i>F</i><sub>1</sub></td><td><i>PCS</i></td><td><i>F</i><sub>1</sub></td><td><i>PCS</i></td><td><i>F</i><sub>1</sub></td><td><i>PCS</i></td></tr><tr><td><br />LSTM_P</td><td>81.94</td><td>38.44</td><td>86.66</td><td>50.98</td><td>68.44</td><td>40.06</td></tr><tr><td><br />BiLSTM_P</td><td>85.10</td><td>50.45</td><td>91.19</td><td>68.33</td><td>87.17</td><td>53.03</td></tr><tr><td><br />BiLSTM-CRF_P</td><td>85.91</td><td>65.47</td><td>88.60</td><td>76.43</td><td>87.27</td><td>62.54</td></tr><tr><td><br />BiLSTM-CRF</td><td>60.42</td><td>45.43</td><td>60.26</td><td>46.85</td><td>62.19</td><td>47.16</td></tr><tr><td><br />BiLSTM-CRF_P_ POS</td><td>85.84</td><td>64.38</td><td>91.86</td><td><b>76.79</b></td><td><b>89.18</b></td><td><b>63.11</b></td></tr><tr><td><br />BiLSTM-CRF_P_C</td><td><b>86.34</b></td><td><b>67.87</b></td><td><b>92.20</b></td><td>76.03</td><td>86.94</td><td>61.67</td></tr><tr><td><br />BiLSTM-CRF_P_D</td><td>84.88</td><td>64.56</td><td>92.12</td><td>76.79</td><td>87.47</td><td>62.64</td></tr><tr><td><br />BiLSTM-CRF_P_C_POS</td><td>86.12</td><td>66.31</td><td>91.67</td><td>76.81</td><td>86.89</td><td>61.94</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best result is bold.</p>
                </div>
                <div class="p1">
                    <p id="161">表2和表3中行3～8对比了采用不同特征时BiLSTM-CRF系统的性能.可以看出:</p>
                </div>
                <div class="p1">
                    <p id="162">1) 仅采用词向量作为输入的BiLSTM-CRF模型时, 由于缺乏足够的特征, 其性能相比其他系统差距较大.</p>
                </div>
                <div class="p1">
                    <p id="163">2) 加入位置特征后 (BiLSTM-CRF_P) , 其性能获得明显提升, 接近最好的系统性能.说明位置特征对覆盖域检测任务最为重要.注意, 在实验中本文同时也尝试了在BiLSTM-CRF模型中单独加入其他特征, 其性能虽有提升, 但均与位置特征有较大差距.</p>
                </div>
                <div class="p1">
                    <p id="164">3) 在BiLSTM-CRF_P模型中分别加入词性特征 (BiLSTM-CRF_P_POS) 和短语句法特征 (BiLSTM-CRF_P_C) 时性能均有小幅度提升, 在不同语料集上都达到各自最好性能.然而, 当同时添加以上2个特征 (BiLSTM-CRF_P_C_POS) 时性能反而有所下降, 其原因可能在于这2个特征包含的语法信息较为相似, 同时添加时存在较大冗余, 反而降低了系统的泛化性能.</p>
                </div>
                <div class="p1">
                    <p id="165">4) 加入依存特征 (BiLSTM-CRF_P_D) 后, 系统性能几乎未获得提升, 其原因可能是由于依存句法表示词之间的依赖关系, 而BiLSTM-CRF模型本身善于学习这种关系.</p>
                </div>
                <h4 class="anchor-tag" id="166" name="166">3.2.2 标记方案对系统性能的影响</h4>
                <div class="p1">
                    <p id="167">除了2.2节中介绍的BAO标记方案, 本文还尝试2种标记方案.</p>
                </div>
                <h4 class="anchor-tag" id="168" name="168">1) BIO标记方案</h4>
                <div class="p1">
                    <p id="169">B:覆盖域内的第1个词;</p>
                </div>
                <div class="p1">
                    <p id="170">I:覆盖域中除第1个词之外的其他词;</p>
                </div>
                <div class="p1">
                    <p id="171">O:不在覆盖域中的.</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172">2) IO标记方案</h4>
                <div class="p1">
                    <p id="341">I:覆盖域中的词;</p>
                </div>
                <div class="p1">
                    <p id="173">O:不在覆盖域中的词.</p>
                </div>
                <div class="p1">
                    <p id="174">表4以BiLSTM-CRF_P_POS系统为例, 给出了采用不同标记方案时覆盖域检测系统的性能比较.可以看出, BAO标记方案获得了最好的性能.此外, 除科技文献数据集外, 其他数据集上的性能差别不大, 其原因可能是该数据集上的否定覆盖域实例仅有161个, 远小于其他数据集, 导致模型训练不稳定, 测试集上的泛化性能较差.</p>
                </div>
                <h4 class="anchor-tag" id="175" name="175">3.2.3 训练数据集大小对系统性能的影响</h4>
                <div class="p1">
                    <p id="176">图2验证了训练集大小对本文模型性能的影响.可以看出:训练集由60%逐渐增加至100%, 系统性能提升较为缓慢 (仅提升了6.7%) ;而训练集由10%提升至60%过程中, 系统性能上升幅度较大.该结论说明训练本文提出的模型所需的数据量占CNeSp语料训练集的60%左右.</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177">3.2.4 超参数对系统性能的影响</h4>
                <div class="p1">
                    <p id="178">本节验证了超参数设置对模型的影响, 旨在为相关研究提供参考.实验采用BiLSTM-CRF_P_POS模型, 数据采用金融新闻否定覆盖域数据集.由表2和表3的实验结果可以看出位置特征在本文模型中的有效性, 本文尝试采用不同维度对位置特征进行向量化表示.图3 (a) 给出了位置特征维度对系统性能的影响.可以看出, 在维度为20时, 系统性能最好;特征维度继续增大时, 其表示信息的能力开始变弱, 导致系统性能逐渐降低.</p>
                </div>
                <div class="area_img" id="179">
                    <p class="img_tit"><b>表4 不同标记方案系统<i>PCS</i>性能比较</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Comparison of the Systems with Different Label Schemes in <i>PCS</i></b></p>
                    <p class="img_note"></p>
                    <table id="179" border="1"><tr><td rowspan="2"><br />Systems</td><td colspan="2"><br />Scientific Literature</td><td colspan="2">Financial News</td><td colspan="2">Hotel Reviews</td></tr><tr><td><br />Negation</td><td>Speculation</td><td>Negation</td><td>Speculation</td><td>Negation</td><td>Speculation</td></tr><tr><td><br />IO</td><td>45.00</td><td>64.56</td><td>76.43</td><td>74.95</td><td>68.03</td><td>60.23</td></tr><tr><td><br />BIO</td><td>52.50</td><td>64.26</td><td>77.17</td><td>76.25</td><td>71.23</td><td>60.52</td></tr><tr><td><br />BAO</td><td><b>63.10</b></td><td><b>67.87</b></td><td><b>79.16</b></td><td><b>76.79</b></td><td><b>74.13</b></td><td><b>63.11</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best result is bold.</p>
                </div>
                <div class="area_img" id="180">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907014_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练数据集大小对系统性能的影响" src="Detail/GetImg?filename=images/JFYZ201907014_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练数据集大小对系统性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907014_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Comparison of the performance when utilizing different sizes of training set</p>

                </div>
                <div class="p1">
                    <p id="182">LSTM单元的隐藏层维度对神经网络模型的性能具有一定的影响, 其在训练阶段容易出现过拟合:隐藏层维度偏大使得模型更复杂, 泛化能力下降;隐藏层维度偏小则可能导致学习能力下降.因此, 本文尝试用了不同维度的LSTM隐藏层, 实验结果如图3 (b) 所示.可以看出:适当提升隐藏层的维度能够使系统性能获得提升, 当隐藏层维度达到150时, 系统性能达到最高值;而继续增大隐藏层维度时, 系统性能开始降低, 说明其泛化性能下降, 出现过拟合.</p>
                </div>
                <div class="area_img" id="183">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201907014_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 位置特征维度和LSTM隐藏层维度对系统性能的影响" src="Detail/GetImg?filename=images/JFYZ201907014_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 位置特征维度和LSTM隐藏层维度对系统性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201907014_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Effect of performance with different feature dimensions and different  hidden layer dimensions of LSTM</p>

                </div>
                <h4 class="anchor-tag" id="184" name="184">3.2.5 错误分析</h4>
                <div class="p1">
                    <p id="185">本节对实验结果进行了定性分析, 在金融新闻测试集上, 分别选取了BiLSTM-CRF_P_POS系统的否定与不确定覆盖域各50个错误实例进行分析.主要集中在2类错误<sup>①</sup>:</p>
                </div>
                <div class="p1">
                    <p id="186">1) 当句子中存在多个关键词时, 在识别当前关键词对应的覆盖域时, 会受到其他关键词的影响 (否定, 23/50;不确定, 26/50) .</p>
                </div>
                <div class="p1">
                    <p id="187"><b>例3</b>. ([虽然股市不再继续下跌], 但是也<u>没有</u>上升趋势) …</p>
                </div>
                <div class="p1">
                    <p id="188"><b>例4</b>. ([这意味着变盘走好], 近期<u>可能</u>不会再跌至这个点位之下) .</p>
                </div>
                <div class="p1">
                    <p id="189">例3中当前关键词为“不再”, 其对应覆盖域为方括号所示, 由于受到关键词“没有”的影响, 系统最终识别为圆括号所示;同样, 例4中, 当前关键词为“意味着”, 但受到关键词“可能”的影响, 覆盖域也被识别错误.该类型错误占所有错误的50%左右.未来研究中, 可以尝试采用随机初始化非当前关键词向量, 以减弱其他关键词的影响.</p>
                </div>
                <div class="p1">
                    <p id="190">2) 覆盖域中位于关键词之前的部分无法识别 (否定, 16/50;不确定, 13/50) .</p>
                </div>
                <div class="p1">
                    <p id="191"><b>例5</b>. …[国内公布的相关数据 (不太令人意) ]…</p>
                </div>
                <div class="p1">
                    <p id="192"><b>例6</b>. …[他也 (建议如果基本面预期不是太差) ]…</p>
                </div>
                <div class="p1">
                    <p id="193">在例5和例6 中, 位于关键词之前的覆盖域片段均未被正确识别.本文对金融新闻数据集的3 978 个否定与不确定覆盖域实例进行了统计, 其中77%以关键词为开始, 换言之, 这些句子中没有标签为B的实例, 此类错误可能由于训练不足导致.在未来工作中, 可以尝试调整训练集中包含标签B的实例分布, 使模型能够有效地学习.</p>
                </div>
                <h4 class="anchor-tag" id="194" name="194"><b>3.3 与现有方法的性能比较</b></h4>
                <div class="p1">
                    <p id="195">目前, 面向汉语的否定与不确定覆盖域检测处于探索阶段, 相关研究较为匮乏.因此, 本文采用2个英文中最好的系统, 以及1个汉语上最好的系统进行比较.</p>
                </div>
                <div class="p1">
                    <p id="196">1) CNN_C和CNN_D.Qian等人<citation id="325" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将覆盖域检测作为分类任务, 分别采用短语句法路径与依存句法路径作为特征, 该方法获得了目前英文BioScope语料上的最好性能.</p>
                </div>
                <div class="p1">
                    <p id="197">2) BiLSTM.Fancellu等人<citation id="326" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>将覆盖域检测作为序列标注任务, 与本文不同的是缺少CRF层, 同时添加了词性特征.</p>
                </div>
                <div class="p1">
                    <p id="198">3) MetaTree.文献<citation id="327" type="reference">[<a class="sup">8</a>]</citation>在发布汉语覆盖域检测语料的同时, 提出了一个基于元决策树的基准系统, 该系统融合了CRF模型与卷积树核模型.</p>
                </div>
                <div class="p1">
                    <p id="199">表5比较了本文模型与以上4个模型在CNeSp语料库上的性能.</p>
                </div>
                <div class="area_img" id="200">
                    <p class="img_tit"><b>表5 不同系统<i>PCS</i>性能比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Comparison with the States-of-the-art System in <i>PCS</i></b></p>
                    <p class="img_note">%</p>
                    <table id="200" border="1"><tr><td rowspan="2"><br />Systems</td><td colspan="2"><br />Scientific Literature</td><td colspan="2">Financial News</td><td colspan="2">Hotel Reviews</td></tr><tr><td><br />Negation</td><td>Speculation</td><td>Negation</td><td>Speculation</td><td>Negation</td><td>Speculation</td></tr><tr><td><br />CNN_C (Ref [3]) </td><td>15.12</td><td>23.42</td><td>30.52</td><td>39.15</td><td>27.77</td><td>29.97</td></tr><tr><td><br />CNN_D (Ref [3]</td><td>30.68</td><td>29.52</td><td>33.08</td><td>43.32</td><td>30.89</td><td>33.04</td></tr><tr><td><br />BiLSTM (Ref [5]) </td><td>38.41</td><td>50.45</td><td>67.49</td><td>68.87</td><td>64.74</td><td>52.16</td></tr><tr><td><br />MetaTree (Ref [9]) </td><td><b>69.84</b></td><td>58.47</td><td>54.10</td><td>42.33</td><td>69.57</td><td>51.29</td></tr><tr><td><br />BiLSTM_CRF (Ours) </td><td>63.10</td><td><b>67.89</b></td><td><b>79.16</b></td><td><b>76.79</b></td><td><b>74.13</b></td><td><b>63.11</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The best result is bold.</p>
                </div>
                <div class="p1">
                    <p id="201">可以看出, 除了在科技文献数据集上的否定覆盖域检测之外, 本文基于BiLSTM-CRF模型的覆盖域检测系统性能较最好系统均有大幅度提升.其中, 本文方法与基于CNN模型的2种方法相比, 具有显著提升.其原因是CNN方法将该任务作为分类任务, 对每一个词独立地进行标签分类, 而本文将其作为序列标注任务, 通过BiLSTM学习上下文信息, 能够有效学习到覆盖域的连续特征.此外, 通过添加CRF层与BiLSTM方法相比有了进一步改善, 说明CRF学习标签之间依赖关系对本任务更为有效.而在科技文献数据集上, 否定覆盖域检测性能比MetaTree低6.74%.其原因可能是该数据训练集的实例过少, 仅有121个实例, 从而导致神经网络很难学到有效特征.</p>
                </div>
                <h3 id="202" name="202" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="203">本文提出了一种基于双向LSTM网络与CRF融合模型的否定与不确定覆盖域检测方法, 该模型借助BiLSTM网络学习上下文特征和长距离特征, 并通过CRF层学习相邻标签之间的依赖关系, 在CNeSp语料库上取得了目前的最好性能.此外, 本文验证了位置特征、词性特征和短语句法特征在覆盖域检测任务中的有效性.</p>
                </div>
                <div class="p1">
                    <p id="204">未来工作除了尝试进一步优化模型以解决3.2.5节中提到的主要错误之外, 还需要研究跨领域的覆盖域检测任务.此外, 由于面向英语的覆盖域检测模型相对成熟, 如何将这些方法迁移到面向汉语的覆盖域检测任务中也是未来工作需要探索的方向.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="348" type="formula" href="images/JFYZ201907014_34800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">叶静</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="349" type="formula" href="images/JFYZ201907014_34900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">邹博伟</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="350" type="formula" href="images/JFYZ201907014_35000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">洪宇</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="351" type="formula" href="images/JFYZ201907014_35100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">沈龙骧</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="352" type="formula" href="images/JFYZ201907014_35200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">朱巧明</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="353" type="formula" href="images/JFYZ201907014_35300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">周国栋</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="239">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semantic representation of negation using focus detection">

                                <b>[1]</b>Blanco E, Dan M.Semantic representation of negation using focus detection[C] //Proc of the 49th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2011:581- 589
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weakly supervised learning for hedge classification in scientific literature">

                                <b>[2]</b>Medlock B, Briscoe T.Weakly supervised learning for hedge classification in scientific literature[C] //Proc of the 45th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2007:992- 999
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speculation and negation scope detection via convolutional neural networks">

                                <b>[3]</b>Qian Zhong, Li Peifeng, Zhu Qiaoming, et al.Speculation and negation scope detection via convolutional neural networks[C] //Proc of EMNLP'16.Stroudsburg, PA:ACL, 2016:815- 825
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tree kernel-based negation and speculation scope detection with structured syntactic parse features">

                                <b>[4]</b>Zou Bowei, Zhou Guodong, Zhu Qiaoming.Tree kernel-based negation and speculation scope detection with structured syntactic parse features[C] //Proc of EMNLP'13.Stroudsburg, PA:ACL, 2013:968- 976
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural networks for negation scope detection">

                                <b>[5]</b>Fancellu F, Lopez A, Webber B.Neural networks for negation scope detection[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:495- 504
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The BioScope corpus:Annotation for negation,uncertainty and their scope in biomedical texts">

                                <b>[6]</b>Vincze V.The BioScope corpus:Annotation for negation, uncertainty and their scope in biomedical texts[C] //Proc of the 46th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2008:38- 45
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The CoNLL-2010 shared task:Learning to detect hedges and their scope in natural language text">

                                <b>[7]</b>Vincze V.The CoNLL-2010 shared task:Learning to detect hedges and their scope in natural language text[C] //Proc of the 48th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2010:1- 12
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Negation and Speculation Identification in Chinese Language">

                                <b>[8]</b>Zou Bowei, Zhu Qiaoming, Zhou Guodong.Negation and speculation identification in Chinese language[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:656- 665
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201602009&amp;v=MTI2NTBSckZ5cm1WYnZOTnlmVGJMRzRIOWZNclk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Zou Bowei, Qian Zhong, Chen Zhancheng, et al.Negative and speculation information extraction for natural language Texts[J].Journal of Software, 2016, 27 (2) :309- 328 (in Chinese) (邹博伟, 钱忠, 陈站成, 等.面向自然语言文本的否定性与不确定性信息抽取[J].软件学报, 2016, 27 (2) :309- 328) 
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning phrase representations using RNN encoder-decoder for sta-tistical machine translation">

                                <b>[10]</b>Cho K, Merrienboer B, Gulcehre C, et al.Learning phrase representations using RNN encoder-decoder for statistical machine translation[C].//Proc of EMNLP'14.Stroudsburg, PA:ACL, 2014:1724- 1734
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[11]</b>Bahdanau D, Cho K, Bengio Y.Neural machine translation by jointly learning to align and translate[J].arXiv preprint arXiv:1409.0473, 2014
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural networks for sentiment analysis of short texts">

                                <b>[12]</b>Santos C, Gattit M.Deep convolutional neural networks for sentiment Analysis of short texts[C] //Proc of the 25th Int Conf on Computational Linguistics.New York:ACM, 2014:69- 78
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensional sentiment analysis using a regional CNN-LSTM model">

                                <b>[13]</b>Wang Jin, Yu L-C, Lai K R, et al.Dimensional sentiment analysis using a regional CNN-LSTM model[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:225- 230
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant supervision for relation extraction via piecewise convolutional neural networks">

                                <b>[14]</b>Zeng Daojian, Liu Kang, Chen Yubo, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C] //Proc of EMNLP'15.Stroudsburg, PA:ACL, 2015:1753- 1762
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural relation extraction with selective attention over instances">

                                <b>[15]</b>Lin Yankai, Shen Shiqi, Liu Zhiyuan, et al.Neural relation extraction with selective attention over instances[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:2124- 2133
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-end sequence labeling via bi-directional lstm-cnns-crf">

                                <b>[16]</b>Ma Xuezhe, Hovy E.End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF[C] //Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2016:1064- 1074
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural architectures for named entity recognition">

                                <b>[17]</b>Lample G, Ballesteros M, Subramanian S, et al.Neural architectures for named entity recognition[C] //Proc of the 52nd Conf of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies (NAACL-HLT) .Stroudsburg, PA:ACL, 2016:260- 270
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                Lafferty J, Mccallum A, Pereira F.Conditional random fields:Probabilistic models for segmenting and labeling sequence data[C] //Proc of the 18th Int Conf on Machine Learning.New York:ACM, 2001:282- 289
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300411428&amp;v=MjA4OTdINHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklJbDBTYmhjPU5pZk9mYks3SHRETnJJOUZZT29PQw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Chapman W, Bridewell W, Hanbury P.A simple algorithm for identifying negated findings and diseases in discharge summaries[J].Journal of Biomedical Informatics, 2001, 34 (5) :301- 310
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">

                                <b>[20]</b>Huang Zhiheng, Xu Wei, Yu Kai.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv preprint arXiv:1508.01991, 2015
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning the Scope of Negation in Biomedical Texts">

                                <b>[21]</b>Morante R, Liekens A, Daelemans W.Learning the scope of negation in biomedical texts[C] //Proc of EMNLP'08.Stroudsburg, PA:ACL, 2008:715- 724
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning task-dependent distributed representations by backpropagation through structure">

                                <b>[22]</b>Goller C, Kuchler A.Learning task-dependent distributed representations by backpropagation through structure[C] //Proc of ICNN'96.Piscataway, NJ:IEEE, 1996:347- 352
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MTMzMzd0ak1xbzlGWk9vTERYVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklJbDBTYmhjPU5pZkpaYks5SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural Computation, 1997, 9 (8) :1735- 1780
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300069870&amp;v=MzI1ODJET3JJOUZaTzBHQkhzNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxySUlsMFNiaGM9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Graves A, Schmidhuber J.Framewise phoneme classification with bidirectional LSTM and other neural network architectures[J].Neural Networks, 2005, 18 (5) :602- 610
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speech recognition with deep recurrent neural networks">

                                <b>[25]</b>Graves A, Mohamed A, Hinton G.Speech recognition with deep recurrent neural networks[C] //Proc of the 13th IEEE Int Conf on Communications.Piscataway, NJ:IEEE, 2013:6645- 6649
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classifying relations by ranking with convolutio nal neural networks">

                                <b>[26]</b>Santos C N D, Xiang Bing, Zhou Bowen.Classifying relations by ranking with convolutional neural networks[C] //Proc of the 53rd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2015:626- 634
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural networks for negation cue detection in Chinese">

                                <b>[27]</b>He Hangfeng, Fancellu F, Webber B.Neural networks for negation cue detection in Chinese[C] //Proc of SemBEaR'17.Stroudsburg, PA:ACL, 2017:59- 63
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning cross-lingual word embeddings via matrixco-factorization">

                                <b>[28]</b>Shi Tianze, Liu Zhiyuan, Liu Yang, et al.Learning cross-lingual word embeddings via matrixco-factorization[C] //Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, PA:ACL, 2017:567- 572
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="3" href="javascript:void(0)">
                            <b>1</b> 以加粗字体表示关键词, 以方括号表示关键词对应的覆盖域.
                        </span>
                    </p>
                    <p>
                        <span id="5" href="javascript:void(0)">
                            <b>2</b> http://nlp.stanford.edu/software/lex-parser.shtml
                        </span>
                    </p>
                    <p>
                        <span id="7" href="javascript:void(0)">
                            <b>3</b> https://pypi.org/project/jieba/
                        </span>
                    </p>
                    <p>
                        <span id="9" href="javascript:void(0)">
                            <b>4</b> http://nlp.csai.tsinghua.edu.cn/～lzy/src/acl2015 bilingual.html
                        </span>
                    </p>
                    <p>
                        <span id="11" href="javascript:void(0)">
                            <b>5</b> 加粗字体表示当前关键词, 下划线表示无关关键词, 方括号表示覆盖域正确答案, 小括号表示系统识别的覆盖域.
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201907014" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201907014&amp;v=MDc1MTZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeXJtVmJ2Tkx5dlNkTEc0SDlqTXFJOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYzUnVBSWx5SGFiYTNMUVZPVXZxUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

