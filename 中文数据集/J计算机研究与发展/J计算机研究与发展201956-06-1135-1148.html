

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128624377150000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201906002%26RESULT%3d1%26SIGN%3dcJnwAwNq5FSRcAYRr2LpekXsPp8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201906002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201906002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201906002&amp;v=MTAwOTJxWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEbVVyM09MeXZTZExHNEg5ak0=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#146" data-title="&lt;b&gt;1 类脑基本思想&lt;/b&gt; "><b>1 类脑基本思想</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#147" data-title="&lt;b&gt;1.1 图灵机&lt;/b&gt;"><b>1.1 图灵机</b></a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;1.2 冯&lt;/b&gt;&#183;&lt;b&gt;诺依曼体系结构&lt;/b&gt;"><b>1.2 冯</b>·<b>诺依曼体系结构</b></a></li>
                                                <li><a href="#153" data-title="&lt;b&gt;1.3 人工神经网络&lt;/b&gt;"><b>1.3 人工神经网络</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;1.4 生物神经网络&lt;/b&gt;"><b>1.4 生物神经网络</b></a></li>
                                                <li><a href="#162" data-title="&lt;b&gt;1.5 类脑机&lt;/b&gt;"><b>1.5 类脑机</b></a></li>
                                                <li><a href="#168" data-title="&lt;b&gt;1.6 大脑解析进展&lt;/b&gt;"><b>1.6 大脑解析进展</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#174" data-title="&lt;b&gt;2 类脑机研究进展&lt;/b&gt; "><b>2 类脑机研究进展</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#178" data-title="&lt;b&gt;2.1 斯坦福大学的Neurogrid与BrainStorm&lt;/b&gt;"><b>2.1 斯坦福大学的Neurogrid与BrainStorm</b></a></li>
                                                <li><a href="#181" data-title="&lt;b&gt;2.2 从软件仿真到IBM TrueNorth芯片&lt;/b&gt;"><b>2.2 从软件仿真到IBM TrueNorth芯片</b></a></li>
                                                <li><a href="#187" data-title="&lt;b&gt;2.3 欧洲的SpiNNaker和BrainScaleS&lt;/b&gt;"><b>2.3 欧洲的SpiNNaker和BrainScaleS</b></a></li>
                                                <li><a href="#191" data-title="&lt;b&gt;2.4 我国相关进展&lt;/b&gt;"><b>2.4 我国相关进展</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#198" data-title="&lt;b&gt;3 脉冲神经网络体系结构SpiNNaker&lt;/b&gt; "><b>3 脉冲神经网络体系结构SpiNNaker</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#201" data-title="&lt;b&gt;3.1 体系结构&lt;/b&gt;"><b>3.1 体系结构</b></a></li>
                                                <li><a href="#206" data-title="&lt;b&gt;3.2 海量脉冲异步传输机制&lt;/b&gt;"><b>3.2 海量脉冲异步传输机制</b></a></li>
                                                <li><a href="#216" data-title="&lt;b&gt;3.3 SpiNNaker软件系统&lt;/b&gt;"><b>3.3 SpiNNaker软件系统</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#229" data-title="&lt;b&gt;4 类脑机的信息处理潜力&lt;/b&gt; "><b>4 类脑机的信息处理潜力</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#231" data-title="&lt;b&gt;4.1 脉冲神经网络&lt;/b&gt;"><b>4.1 脉冲神经网络</b></a></li>
                                                <li><a href="#244" data-title="&lt;b&gt;4.2 脉冲神经网络的能力不低于图灵机&lt;/b&gt;"><b>4.2 脉冲神经网络的能力不低于图灵机</b></a></li>
                                                <li><a href="#254" data-title="&lt;b&gt;4.3 噪声可以提高脉冲神经网络的性能&lt;/b&gt;"><b>4.3 噪声可以提高脉冲神经网络的性能</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#262" data-title="&lt;b&gt;5 总结与展望&lt;/b&gt; "><b>5 总结与展望</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#203" data-title="图1 SpiNNaker系统的层次结构">图1 SpiNNaker系统的层次结构</a></li>
                                                <li><a href="#204" data-title="图2 SpiNNaker系统的网络拓扑结构">图2 SpiNNaker系统的网络拓扑结构</a></li>
                                                <li><a href="#211" data-title="图3 神经脉冲数据包结构">图3 神经脉冲数据包结构</a></li>
                                                <li><a href="#209" data-title="图4 源地址广播的实现机制">图4 源地址广播的实现机制</a></li>
                                                <li><a href="#215" data-title="图5 SpiNNaker的软件系统结构">图5 SpiNNaker的软件系统结构</a></li>
                                                <li><a href="#227" data-title="图6 时间驱动和事件驱动的模拟方式">图6 时间驱动和事件驱动的模拟方式</a></li>
                                                <li><a href="#234" data-title="图7 脉冲神经元示意图与积分发放模型">图7 脉冲神经元示意图与积分发放模型</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="337">


                                    <a id="bibliography_1" title="Huang Tiejun, Shi Luping, Tang Huajin, et al.Research on multimedia technology 2015—Advances and trend of brain-like computing[J].Journal of Image and Graphics, 2016, 21 (11) :1411- 1424 (in Chinese) (黄铁军, 施路平, 唐华锦, 等.多媒体技术研究:2015——类脑计算的研究进展与发展趋势[J].中国图象图形学报, 2016, 21 (11) :1411- 1424) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201611001&amp;v=MTg4MjVMT2VaZVJxRmlEbVVyM09QeXJmYkxHNEg5Zk5ybzlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Huang Tiejun, Shi Luping, Tang Huajin, et al.Research on multimedia technology 2015—Advances and trend of brain-like computing[J].Journal of Image and Graphics, 2016, 21 (11) :1411- 1424 (in Chinese) (黄铁军, 施路平, 唐华锦, 等.多媒体技术研究:2015——类脑计算的研究进展与发展趋势[J].中国图象图形学报, 2016, 21 (11) :1411- 1424) 
                                    </a>
                                </li>
                                <li id="339">


                                    <a id="bibliography_2" title="Huang Tiejun.Imitating the brain with neurocomputer—A “new” way towards artificial general intelligence[J].International Journal of Automation and Computing, 2017, 14 (5) :520- 531" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD1B27613353A15C3C4AD5535A4B69FA5F&amp;v=MTU2NTVHWWVoK0RYbEt6R1VYbTB0NFRYem4zUlpIZjd2aU5ML3BDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6THUrd3E0PU5qN0JhckxLSE5iS3JveA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Huang Tiejun.Imitating the brain with neurocomputer—A “new” way towards artificial general intelligence[J].International Journal of Automation and Computing, 2017, 14 (5) :520- 531
                                    </a>
                                </li>
                                <li id="341">


                                    <a id="bibliography_3" title="Hodgkin A L, Huxley A.A quantitative description of membrane current and its application to conduction and excitation in nerve[J].The Journal of Physiology, 1952, 117 (4) :500- 544" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A quantitative description of membrane current and its application to conduction and excitation in nerve">
                                        <b>[3]</b>
                                        Hodgkin A L, Huxley A.A quantitative description of membrane current and its application to conduction and excitation in nerve[J].The Journal of Physiology, 1952, 117 (4) :500- 544
                                    </a>
                                </li>
                                <li id="343">


                                    <a id="bibliography_4" title="Hebb D O.The Organization of Behaviour:A Neuropsy-chological Theory[M].New York:Science Editions, 1949" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Organization of Behavior">
                                        <b>[4]</b>
                                        Hebb D O.The Organization of Behaviour:A Neuropsy-chological Theory[M].New York:Science Editions, 1949
                                    </a>
                                </li>
                                <li id="345">


                                    <a id="bibliography_5" title="Tsodyks M, Pawelzik K, Markram H.Neural networks with dynamic synapses[J].Neural Computation, 1998, 10 (4) :821- 835" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011588&amp;v=MjIwNDY5RlpPb09DWFF4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0YwVmFCUT1OaWZKWmJLOUh0ak1xbw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Tsodyks M, Pawelzik K, Markram H.Neural networks with dynamic synapses[J].Neural Computation, 1998, 10 (4) :821- 835
                                    </a>
                                </li>
                                <li id="347">


                                    <a id="bibliography_6" title="Bi Guoqiang, Poo Muming.Synaptic modifications in cultured hippocampal neurons:Dependence on spike timing, synaptic strength, and postsynaptic cell type[J].Journal of Neuroscience, 1998, 18 (24) :10464- 10472" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type">
                                        <b>[6]</b>
                                        Bi Guoqiang, Poo Muming.Synaptic modifications in cultured hippocampal neurons:Dependence on spike timing, synaptic strength, and postsynaptic cell type[J].Journal of Neuroscience, 1998, 18 (24) :10464- 10472
                                    </a>
                                </li>
                                <li id="349">


                                    <a id="bibliography_7" title="Bi Guoqiang, Poo Muming.Distributed synaptic modification in neural networks induced by patterned stimulation[J].Nature, 1999, 401 (6755) :792- 796" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed synaptic modification in neural networks induced by patterned stimulation">
                                        <b>[7]</b>
                                        Bi Guoqiang, Poo Muming.Distributed synaptic modification in neural networks induced by patterned stimulation[J].Nature, 1999, 401 (6755) :792- 796
                                    </a>
                                </li>
                                <li id="351">


                                    <a id="bibliography_8" title="Song Sen, Miller K D, Abbott L F.Competitive Hebbian learning through spike-timing-dependent synaptic plasticity[J].Nature Neuroscience, 2000, 3 (9) :919- 926" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Competitive Hebbian learning through spike-timing-dependent synaptic plasticity">
                                        <b>[8]</b>
                                        Song Sen, Miller K D, Abbott L F.Competitive Hebbian learning through spike-timing-dependent synaptic plasticity[J].Nature Neuroscience, 2000, 3 (9) :919- 926
                                    </a>
                                </li>
                                <li id="353">


                                    <a id="bibliography_9" title="Song Sen, Abbott L F.Cortical development and remapping through spike timing-dependent plasticity[J].Neuron, 2001, 32 (2) :339- 350" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300028648&amp;v=MjczMTZaZVp1SHlqbVVMdkpLRjBWYUJRPU5pZk9mYks3SHRET3JJOUZaT2tIQ25neG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Song Sen, Abbott L F.Cortical development and remapping through spike timing-dependent plasticity[J].Neuron, 2001, 32 (2) :339- 350
                                    </a>
                                </li>
                                <li id="355">


                                    <a id="bibliography_10" title="Vogelstein J T, Amunts K, Andreou A, et al.Grand challenges for global brain sciences[J].arXiv preprint arXiv:1608.06548, 2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Grand challenges for global brain sciences">
                                        <b>[10]</b>
                                        Vogelstein J T, Amunts K, Andreou A, et al.Grand challenges for global brain sciences[J].arXiv preprint arXiv:1608.06548, 2016
                                    </a>
                                </li>
                                <li id="357">


                                    <a id="bibliography_11" title="Gao Ruixuan, Asano S M, Upadhyayula S, et al.Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution[J].Science, 2019, 363 (6424) :eaau8302" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution">
                                        <b>[11]</b>
                                        Gao Ruixuan, Asano S M, Upadhyayula S, et al.Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution[J].Science, 2019, 363 (6424) :eaau8302
                                    </a>
                                </li>
                                <li id="359">


                                    <a id="bibliography_12" title="Hodges A, Turing A.The Enigma[M].London:Vintage, 1992" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Enigma">
                                        <b>[12]</b>
                                        Hodges A, Turing A.The Enigma[M].London:Vintage, 1992
                                    </a>
                                </li>
                                <li id="361">


                                    <a id="bibliography_13" title="Turing A.Computing machinery and intelligence—AM Turing[J].Mind, 1950, 59 (236) :433- 460" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computing Machinery and Intelligence">
                                        <b>[13]</b>
                                        Turing A.Computing machinery and intelligence—AM Turing[J].Mind, 1950, 59 (236) :433- 460
                                    </a>
                                </li>
                                <li id="363">


                                    <a id="bibliography_14" title="Neumann J V.The computer and the brain[J].Annals of the History of Computing, 1958, 11 (3) :161- 163" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Computer and the Brain">
                                        <b>[14]</b>
                                        Neumann J V.The computer and the brain[J].Annals of the History of Computing, 1958, 11 (3) :161- 163
                                    </a>
                                </li>
                                <li id="365">


                                    <a id="bibliography_15" title="Reeke G N, Sporns O, Edelman G M.Synthetic neural modeling:The ‘Darwin&#39; series of recognition automata[J].Proceedings of the IEEE, 1990, 78 (9) :1498- 1530" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Synthetic neural modeling: The &amp;#39;Darwin&amp;#39; series of recognition automata">
                                        <b>[15]</b>
                                        Reeke G N, Sporns O, Edelman G M.Synthetic neural modeling:The ‘Darwin&#39; series of recognition automata[J].Proceedings of the IEEE, 1990, 78 (9) :1498- 1530
                                    </a>
                                </li>
                                <li id="367">


                                    <a id="bibliography_16" title="Edelman G M.Learning in and from brain-based devices[J].Science, 2007, 318 (5853) :1103- 1105" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning in and from brain-based devices">
                                        <b>[16]</b>
                                        Edelman G M.Learning in and from brain-based devices[J].Science, 2007, 318 (5853) :1103- 1105
                                    </a>
                                </li>
                                <li id="369">


                                    <a id="bibliography_17" title="Izhikevich E M, Edelman G M.Large-scale model of mammalian thalamocortical systems[J].Proceedings of the National Academy of Sciences, 2008, 105 (9) :3593- 3598" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large-scale model of mammalian thalamocortical systems">
                                        <b>[17]</b>
                                        Izhikevich E M, Edelman G M.Large-scale model of mammalian thalamocortical systems[J].Proceedings of the National Academy of Sciences, 2008, 105 (9) :3593- 3598
                                    </a>
                                </li>
                                <li id="371">


                                    <a id="bibliography_18" title="Mead C.Analog VLSI and Neural Systems[M].Reading, MA:Addison-Wesley, 1989" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analog VLSI and Neural Systems">
                                        <b>[18]</b>
                                        Mead C.Analog VLSI and Neural Systems[M].Reading, MA:Addison-Wesley, 1989
                                    </a>
                                </li>
                                <li id="373">


                                    <a id="bibliography_19" title="Mead C.Neuromorphic electronic systems[J].Proceedings of the IEEE, 1990, 78 (10) :1629- 1636" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neuromorphic electronic systems">
                                        <b>[19]</b>
                                        Mead C.Neuromorphic electronic systems[J].Proceedings of the IEEE, 1990, 78 (10) :1629- 1636
                                    </a>
                                </li>
                                <li id="375">


                                    <a id="bibliography_20" title="Mead C, Ismail M.Analog VLSI Implementation of Neural Systems[M].Berlin:Springer, 1989" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analog VLSI Implementation of Neural Systems">
                                        <b>[20]</b>
                                        Mead C, Ismail M.Analog VLSI Implementation of Neural Systems[M].Berlin:Springer, 1989
                                    </a>
                                </li>
                                <li id="377">


                                    <a id="bibliography_21" title="Benjamin B V, Gao P, McQuinn E, et al.Neurogrid:A mixed-analog-digital multichip system for large-scale neural simulations[J].Proceedings of the IEEE, 2014, 102 (5) :699- 716" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neurogrid:A Mixed-Analog-Digital Multichip System for Large-Scale Neural Simulations">
                                        <b>[21]</b>
                                        Benjamin B V, Gao P, McQuinn E, et al.Neurogrid:A mixed-analog-digital multichip system for large-scale neural simulations[J].Proceedings of the IEEE, 2014, 102 (5) :699- 716
                                    </a>
                                </li>
                                <li id="379">


                                    <a id="bibliography_22" title="Markram H.The blue brain project[J].Nature Reviews Neuroscience, 2006, 7 (2) :153- 160" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The blue brain project">
                                        <b>[22]</b>
                                        Markram H.The blue brain project[J].Nature Reviews Neuroscience, 2006, 7 (2) :153- 160
                                    </a>
                                </li>
                                <li id="381">


                                    <a id="bibliography_23" title="Modha D S, Ananthanarayanan R, Esser S K, et al.Cognitive computing[J].Communications of the ACM, 2011, 54 (8) :62- 71" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000077&amp;v=MDc2MDNtVUx2SktGMFZhQlE9TmlmSVk3SzdIdGpOcjQ5RlpPc1BESHMrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Modha D S, Ananthanarayanan R, Esser S K, et al.Cognitive computing[J].Communications of the ACM, 2011, 54 (8) :62- 71
                                    </a>
                                </li>
                                <li id="383">


                                    <a id="bibliography_24" >
                                        <b>[24]</b>
                                    Amunts K.Human brain project of European Union[EB/OL].[2016-07-25].http://www.humanbrainproject.eu/ (Amunts K.欧盟人类大脑计划[EB/OL].[2016-07-25].http://www.humanbrainproject.eu/) </a>
                                </li>
                                <li id="385">


                                    <a id="bibliography_25" title="Merolla P A, Arthur J V, Alvarez-Icaza R, et al.A million spiking-neuron integrated circuit with a scalable communication network and interface[J].Science, 2014, 345 (6197) :668- 673" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A million spiking-neuron integrated circuit with a scalable communication network and interface">
                                        <b>[25]</b>
                                        Merolla P A, Arthur J V, Alvarez-Icaza R, et al.A million spiking-neuron integrated circuit with a scalable communication network and interface[J].Science, 2014, 345 (6197) :668- 673
                                    </a>
                                </li>
                                <li id="387">


                                    <a id="bibliography_26" title="Furber S B, Galluppi F, Temple S, et al.The SpiNNaker project[J].Proceedings of the IEEE, 2014, 102 (5) :652- 665" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The SpiNNaker project">
                                        <b>[26]</b>
                                        Furber S B, Galluppi F, Temple S, et al.The SpiNNaker project[J].Proceedings of the IEEE, 2014, 102 (5) :652- 665
                                    </a>
                                </li>
                                <li id="389">


                                    <a id="bibliography_27" title="Brown A D, Furber S B, Reeve J S, et al.SpiNNaker—programming model[J].IEEE Transactions on Computers, 2015, 64 (6) :1769- 1782" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spi NNaker-programming model">
                                        <b>[27]</b>
                                        Brown A D, Furber S B, Reeve J S, et al.SpiNNaker—programming model[J].IEEE Transactions on Computers, 2015, 64 (6) :1769- 1782
                                    </a>
                                </li>
                                <li id="391">


                                    <a id="bibliography_28" title="Schemmel J, Briiderle D, Griibl A, et al.A wafer-scale neuromorphic hardware system for large-scale neural modeling[C] //Proc of 2010 IEEE Int Symp on Circuits and Systems.Piscataway, NJ:IEEE, 2010:1947- 1950" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A wafer-scale neuromorphic hardware system for large-scale neural modeling">
                                        <b>[28]</b>
                                        Schemmel J, Briiderle D, Griibl A, et al.A wafer-scale neuromorphic hardware system for large-scale neural modeling[C] //Proc of 2010 IEEE Int Symp on Circuits and Systems.Piscataway, NJ:IEEE, 2010:1947- 1950
                                    </a>
                                </li>
                                <li id="393">


                                    <a id="bibliography_29" title="Scholze S, Eisenreich H, H&#246;ppner S, et al.A 32 GBit/s communication SoC for a waferscale neuromorphic system[J].INTEGRATION, the VLSI Journal, 2012, 45 (1) :61- 75" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300402415&amp;v=MTc2MzJDSDA4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0YwVmFCUT1OaWZPZmJLN0h0RE9ySTlGWU9zTg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                        Scholze S, Eisenreich H, H&#246;ppner S, et al.A 32 GBit/s communication SoC for a waferscale neuromorphic system[J].INTEGRATION, the VLSI Journal, 2012, 45 (1) :61- 75
                                    </a>
                                </li>
                                <li id="395">


                                    <a id="bibliography_30" title="Meier K.A mixed-signal universal neuromorphic computing system[C] //Proc of 2015 IEEE Int Electron Devices Meeting (IEDM) .Piscataway, NJ:IEEE, 2015:4.6.1- 4.6.4" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A mixed-signal universal neuromorphic computing system">
                                        <b>[30]</b>
                                        Meier K.A mixed-signal universal neuromorphic computing system[C] //Proc of 2015 IEEE Int Electron Devices Meeting (IEDM) .Piscataway, NJ:IEEE, 2015:4.6.1- 4.6.4
                                    </a>
                                </li>
                                <li id="397">


                                    <a id="bibliography_31" >
                                        <b>[31]</b>
                                    Yan Aoshuang.Special edition of China brain project[N].People&#39;s Daily.2015-11-17 (in Chinese) (闫傲霜.北京脑计划专版[N].人民日报.2015-11-17) </a>
                                </li>
                                <li id="399">


                                    <a id="bibliography_32" title="Furber S B, Lester D R, Plana L A, et al.Overview of the SpiNNaker system architecture[J].IEEE Transactions on Computers, 2012, 62 (12) :2454- 2467" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Overview of the spinnaker system architecture">
                                        <b>[32]</b>
                                        Furber S B, Lester D R, Plana L A, et al.Overview of the SpiNNaker system architecture[J].IEEE Transactions on Computers, 2012, 62 (12) :2454- 2467
                                    </a>
                                </li>
                                <li id="401">


                                    <a id="bibliography_33" title="Maass W.Networks of spiking neurons:The third generation of neural network models[J].Neural Networks, 1997, 10 (9) :1659- 1671" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070896&amp;v=MDYwMjdRVE1ud1plWnVIeWptVUx2SktGMFZhQlE9TmlmT2ZiSzdIdERPckk5RlpPd1BCSFUvb0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[33]</b>
                                        Maass W.Networks of spiking neurons:The third generation of neural network models[J].Neural Networks, 1997, 10 (9) :1659- 1671
                                    </a>
                                </li>
                                <li id="403">


                                    <a id="bibliography_34" title="McCulloch W S, Pitts W.A logical calculus of the ideas immanent in nervous activity[J].Bulletin of Mathematical Biophysics, 1943, 5 (4) :115- 133" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001082082&amp;v=Mjc4Nzl4Y01IN1I3cWVidWR0RkN6a1c3ekpJbGc9Tmo3QmFyTzRIdEhOcjRkSFpPTU5ZM2s1ekJkaDRqOTlTWHFScnhv&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[34]</b>
                                        McCulloch W S, Pitts W.A logical calculus of the ideas immanent in nervous activity[J].Bulletin of Mathematical Biophysics, 1943, 5 (4) :115- 133
                                    </a>
                                </li>
                                <li id="405">


                                    <a id="bibliography_35" title="Rosenblatt F.Principles of neurodynamics:Perceptrons and the theory of brain mechanisms[R].Washington, DC:Spartan Books, 1961" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Principles of neurodynamics:Perceptrons and the theory of brain mechanisms">
                                        <b>[35]</b>
                                        Rosenblatt F.Principles of neurodynamics:Perceptrons and the theory of brain mechanisms[R].Washington, DC:Spartan Books, 1961
                                    </a>
                                </li>
                                <li id="407">


                                    <a id="bibliography_36" title="O&#39;Reilly R C, Munakata Y.Computational Explorations in Cognitive Neuroscience:Understanding the Mind by Simulating the Brain[M].Cambridge, MA:MIT Press, 2000" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computational Explorations in Cognitive Neuroscience:Understanding the Mind by Simulating the Brain">
                                        <b>[36]</b>
                                        O&#39;Reilly R C, Munakata Y.Computational Explorations in Cognitive Neuroscience:Understanding the Mind by Simulating the Brain[M].Cambridge, MA:MIT Press, 2000
                                    </a>
                                </li>
                                <li id="409">


                                    <a id="bibliography_37" title="Izhikevich E M.Which model to use for cortical spiking neurons?[J].IEEE Transactions on Neural Networks, 2004, 15 (5) :1063- 1070" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Which model to use for cortical spiking neurons?">
                                        <b>[37]</b>
                                        Izhikevich E M.Which model to use for cortical spiking neurons?[J].IEEE Transactions on Neural Networks, 2004, 15 (5) :1063- 1070
                                    </a>
                                </li>
                                <li id="411">


                                    <a id="bibliography_38" >
                                        <b>[38]</b>
                                    Yu Zhaofei.Inference and learning in spiking neural networks[D].Beijing:Tsinghua University, 2017 (in Chinese) (余肇飞.脉冲神经网络的推理与学习问题研究[D].北京:清华大学, 2017) </a>
                                </li>
                                <li id="413">


                                    <a id="bibliography_39" title="Toledo-Rodriguez M, Blumenfeld B, Wu Caizhi, et al.Correlation maps allow neuronal electrical properties to be predicted from single-cell gene expression profiles in rat neocortex[J].Cerebral Cortex, 2004, 14 (12) :1310- 1327" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Correlation Maps Allow Neuronal Electrical Properties to be Predicted from Single-cell Gene Expression Profiles in Rat Neocortex">
                                        <b>[39]</b>
                                        Toledo-Rodriguez M, Blumenfeld B, Wu Caizhi, et al.Correlation maps allow neuronal electrical properties to be predicted from single-cell gene expression profiles in rat neocortex[J].Cerebral Cortex, 2004, 14 (12) :1310- 1327
                                    </a>
                                </li>
                                <li id="415">


                                    <a id="bibliography_40" title="Knight B W.Dynamics of encoding in a population of neurons[J].The Journal of General Physiology, 1972, 59 (6) :734- 766" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamics of encoding in a population of neurons">
                                        <b>[40]</b>
                                        Knight B W.Dynamics of encoding in a population of neurons[J].The Journal of General Physiology, 1972, 59 (6) :734- 766
                                    </a>
                                </li>
                                <li id="417">


                                    <a id="bibliography_41" title="Abbott L F.Lapicque&#39;s introduction of the integrate-and-fire model neuron (1907) [J].Brain Research Bulletin, 1999, 50 (5/6) :303- 304" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100754953&amp;v=MjEyMjZET3JvOUZZKzRMQlhrNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGMFZhQlE9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[41]</b>
                                        Abbott L F.Lapicque&#39;s introduction of the integrate-and-fire model neuron (1907) [J].Brain Research Bulletin, 1999, 50 (5/6) :303- 304
                                    </a>
                                </li>
                                <li id="419">


                                    <a id="bibliography_42" title="Hodgkin A L, Huxley A F, Katz B.Measurement of current-voltage relations in the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :424- 448" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Measurement of current-voltage relations in the membrane of the giant axon of Loligo">
                                        <b>[42]</b>
                                        Hodgkin A L, Huxley A F, Katz B.Measurement of current-voltage relations in the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :424- 448
                                    </a>
                                </li>
                                <li id="421">


                                    <a id="bibliography_43" title="Hodgkin A L, Huxley A F.Currents carried by sodium and potassium ions through the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :449- 472" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Currents carried by sodium and potassium ions through the membrane of the giant axon of loligo">
                                        <b>[43]</b>
                                        Hodgkin A L, Huxley A F.Currents carried by sodium and potassium ions through the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :449- 472
                                    </a>
                                </li>
                                <li id="423">


                                    <a id="bibliography_44" title="Hodgkin A L, Huxley A F.The components of membrane conductance in the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :473- 496" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The components of membrane conductance in the giant axon of Loligo">
                                        <b>[44]</b>
                                        Hodgkin A L, Huxley A F.The components of membrane conductance in the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :473- 496
                                    </a>
                                </li>
                                <li id="425">


                                    <a id="bibliography_45" title="Izhikevich E M.Neural excitability, spiking and bursting[J].International Journal of Bifurcation and Chaos, 2000, 10 (6) :1171- 1266" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural excitability, spiking and bursting">
                                        <b>[45]</b>
                                        Izhikevich E M.Neural excitability, spiking and bursting[J].International Journal of Bifurcation and Chaos, 2000, 10 (6) :1171- 1266
                                    </a>
                                </li>
                                <li id="427">


                                    <a id="bibliography_46" title="Izhikevich E M.Simple model of spiking neurons[J].IEEE Transactions on Neural Networks, 2003, 14 (6) :1569- 1572" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simple model of spiking neurons">
                                        <b>[46]</b>
                                        Izhikevich E M.Simple model of spiking neurons[J].IEEE Transactions on Neural Networks, 2003, 14 (6) :1569- 1572
                                    </a>
                                </li>
                                <li id="429">


                                    <a id="bibliography_47" title="Kistler W M, Gerstner W, Hemmen J L.Reduction of the Hodgkin-Huxley equations to a single-variable threshold model[J].Neural Computation, 1997, 9 (5) :1015- 1045" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014159&amp;v=MTc0MjI5RlpPb0xEWGt3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0YwVmFCUT1OaWZKWmJLOUh0ak1xbw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[47]</b>
                                        Kistler W M, Gerstner W, Hemmen J L.Reduction of the Hodgkin-Huxley equations to a single-variable threshold model[J].Neural Computation, 1997, 9 (5) :1015- 1045
                                    </a>
                                </li>
                                <li id="431">


                                    <a id="bibliography_48" title="Gerstner W, Kistler W M, Naud R, et al.Neuronal Dynamics:From Single Neurons to Networks and Models of Cognition[M].Cambridge, UK:Cambridge University Press, 2014" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neuronal Dynamics:From Single Neurons to Networks and Models of Cognition">
                                        <b>[48]</b>
                                        Gerstner W, Kistler W M, Naud R, et al.Neuronal Dynamics:From Single Neurons to Networks and Models of Cognition[M].Cambridge, UK:Cambridge University Press, 2014
                                    </a>
                                </li>
                                <li id="433">


                                    <a id="bibliography_49" title="Turing A M.On computable numbers, with an application to the Entscheidungsproblem[J].Proceedings of the London Mathematical Society, 1937, 2 (1) :230- 265" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On computable numbers, with an application to the Entscheidungsproblem">
                                        <b>[49]</b>
                                        Turing A M.On computable numbers, with an application to the Entscheidungsproblem[J].Proceedings of the London Mathematical Society, 1937, 2 (1) :230- 265
                                    </a>
                                </li>
                                <li id="435">


                                    <a id="bibliography_50" title="Schacter D L.Searching for Memory:The Brain, the Mind, and the Past[M].New York:Basic Books, 1996" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Searching for Memory:The Brain the Mind and the Past">
                                        <b>[50]</b>
                                        Schacter D L.Searching for Memory:The Brain, the Mind, and the Past[M].New York:Basic Books, 1996
                                    </a>
                                </li>
                                <li id="437">


                                    <a id="bibliography_51" title="Sipser M.Introduction to the Theory of Computation[M].Boston:Thomson Course Technology, 2006" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Introduction to the Theory of Computation">
                                        <b>[51]</b>
                                        Sipser M.Introduction to the Theory of Computation[M].Boston:Thomson Course Technology, 2006
                                    </a>
                                </li>
                                <li id="439">


                                    <a id="bibliography_52" title="Maass W.Lower bounds for the computational power of networks of spiking neurons[J].Neural Computation, 1996, 8 (1) :1- 40" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090200014016&amp;v=MTgxMjVSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGMFZhQlE9TmlmSlpiSzlIdGpNclk5RlpPb0xESDAvb0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[52]</b>
                                        Maass W.Lower bounds for the computational power of networks of spiking neurons[J].Neural Computation, 1996, 8 (1) :1- 40
                                    </a>
                                </li>
                                <li id="441">


                                    <a id="bibliography_53" title="Hopcroft J E.Introduction to Automata Theory, Languages, and Computation[M].Chennai, India:Pearson Education India, 2008" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Introduction to Automata Theory,Languages,and Computation">
                                        <b>[53]</b>
                                        Hopcroft J E.Introduction to Automata Theory, Languages, and Computation[M].Chennai, India:Pearson Education India, 2008
                                    </a>
                                </li>
                                <li id="443">


                                    <a id="bibliography_54" title="Horne B G, Hush D R.Bounds on the complexity of recurrent neural network implementations of finite state machines[J].Neural Networks, 1996, 9 (2) :359- 366" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300071200&amp;v=MTU2MTRxUVRNbndaZVp1SHlqbVVMdkpLRjBWYUJRPU5pZk9mYks3SHRET3JJOUZaT3dPRG53NW9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[54]</b>
                                        Horne B G, Hush D R.Bounds on the complexity of recurrent neural network implementations of finite state machines[J].Neural Networks, 1996, 9 (2) :359- 366
                                    </a>
                                </li>
                                <li id="445">


                                    <a id="bibliography_55" title="Cannon R C, O&#39;Donnell C, Nolan M F.Stochastic ion channel gating in dendritic neurons:Morphology dependence and probabilistic synaptic activation of dendritic spikes[J].PLoS Computational Biology, 2010, 6 (8) :e1000886" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLA7A0AE2BE8972E6FE835AAF468DE815AB&amp;v=MDcyNTBmQ3BiUTM1Tnhnekx1K3dxND1OaWZIYjdUSkhxQzVyZjB3Yk9JSURnay91V01iNlRvTU9Rbm1xaHBCRExxVlFNdnRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[55]</b>
                                        Cannon R C, O&#39;Donnell C, Nolan M F.Stochastic ion channel gating in dendritic neurons:Morphology dependence and probabilistic synaptic activation of dendritic spikes[J].PLoS Computational Biology, 2010, 6 (8) :e1000886
                                    </a>
                                </li>
                                <li id="447">


                                    <a id="bibliography_56" title="Flight M H.Synaptic transmission:On the probability of release[J].Nature Reviews Neuroscience, 2008, 9 (10) :736- 737" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Synaptic transmission: On the probability of release">
                                        <b>[56]</b>
                                        Flight M H.Synaptic transmission:On the probability of release[J].Nature Reviews Neuroscience, 2008, 9 (10) :736- 737
                                    </a>
                                </li>
                                <li id="449">


                                    <a id="bibliography_57" title="Azouz R, Gray C M.Cellular mechanisms contributing to response variability of cortical neurons in vivo[J].Journal of Neuroscience, 1999, 19 (6) :2209- 2223" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cellular mechanisms contributing to response variability of cortical neurons in vivo">
                                        <b>[57]</b>
                                        Azouz R, Gray C M.Cellular mechanisms contributing to response variability of cortical neurons in vivo[J].Journal of Neuroscience, 1999, 19 (6) :2209- 2223
                                    </a>
                                </li>
                                <li id="451">


                                    <a id="bibliography_58" title="Brascamp J W, Van Ee R, Noest A J, et al.The time course of binocular rivalry reveals a fundamental role of noise[J].Journal of Vision, 2006, 6 (11) :1244- 1256" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The time course of binocular rivalry reveals a fundamental role of noise">
                                        <b>[58]</b>
                                        Brascamp J W, Van Ee R, Noest A J, et al.The time course of binocular rivalry reveals a fundamental role of noise[J].Journal of Vision, 2006, 6 (11) :1244- 1256
                                    </a>
                                </li>
                                <li id="453">


                                    <a id="bibliography_59" title="Maass W.Noise as a resource for computation and learning in networks of spiking neurons[J].Proceedings of the IEEE, 2014, 102 (5) :860- 880" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Noise as a Resource for Computation and Learning in Networks of Spiking Neurons,&amp;quot;">
                                        <b>[59]</b>
                                        Maass W.Noise as a resource for computation and learning in networks of spiking neurons[J].Proceedings of the IEEE, 2014, 102 (5) :860- 880
                                    </a>
                                </li>
                                <li id="455">


                                    <a id="bibliography_60" title="Buesing L, Bill J, Nessler B, et al.Neural dynamics as sampling:A model for stochastic computation in recurrent networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (11) :e1002211" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLA7FCEA3A0D1D3DE6FCC0191E722573919&amp;v=MTY2NTZiN1RPYmFTOXJQNUZFT3A3RHdoTXlXQmdtVDk4UVg2WHF4QTNmTFdYVEx1V0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Z3pMdSt3cTQ9TmlmSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[60]</b>
                                        Buesing L, Bill J, Nessler B, et al.Neural dynamics as sampling:A model for stochastic computation in recurrent networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (11) :e1002211
                                    </a>
                                </li>
                                <li id="457">


                                    <a id="bibliography_61" title="Pecevski D, Buesing L, Maass W.Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (12) :e1002294" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAEDC51431B76A42DE9124301AA7662473&amp;v=MTI2MzBNYTZ6MTVTMy9qM1dNeWY3U1dRYjJjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx1K3dxND1OaWZIYjhiTWJkVE5xNHhFRnV3SmZYZzd1Mg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[61]</b>
                                        Pecevski D, Buesing L, Maass W.Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (12) :e1002294
                                    </a>
                                </li>
                                <li id="459">


                                    <a id="bibliography_62" title="Probst D, Petrovici M A, Bytschok I, et al.Probabilistic inference in discrete spaces can be implemented into networks of LIF neurons[J].Frontiers in Computational Neuroscience, 2015, 9:1- 11" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probabilistic inference in discrete spaces can be implemented into networks of LIF neurons">
                                        <b>[62]</b>
                                        Probst D, Petrovici M A, Bytschok I, et al.Probabilistic inference in discrete spaces can be implemented into networks of LIF neurons[J].Frontiers in Computational Neuroscience, 2015, 9:1- 11
                                    </a>
                                </li>
                                <li id="461">


                                    <a id="bibliography_63" title="Habenschuss S, Jonke Z, Maass W.Stochastic computations in cortical microcircuit models[J].PLoS Computational Biology, 2013, 9 (11) :e1003311" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAE6E4359D3F95971D35B1F537D771481D&amp;v=MDQzMzVQcW9ZeFo1MEdDWFUrem1JUTcwMThQbnJocTJZeWZyT1FUYnZyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx1K3dxND1OaWZIYjhhK2E5WA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[63]</b>
                                        Habenschuss S, Jonke Z, Maass W.Stochastic computations in cortical microcircuit models[J].PLoS Computational Biology, 2013, 9 (11) :e1003311
                                    </a>
                                </li>
                                <li id="463">


                                    <a id="bibliography_64" title="Kappel D, Habenschuss S, Legenstein R, et al.Synaptic sampling:A Bayesian approach to neural network plasticity and rewiring[C] //Proc of Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:370- 378" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Synaptic sampling:A bayesian approach to neural network plasticity and rewiring">
                                        <b>[64]</b>
                                        Kappel D, Habenschuss S, Legenstein R, et al.Synaptic sampling:A Bayesian approach to neural network plasticity and rewiring[C] //Proc of Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:370- 378
                                    </a>
                                </li>
                                <li id="465">


                                    <a id="bibliography_65" title="Kappel D, Habenschuss S, Legenstein R, et al.Network plasticity as Bayesian inference[J].PLoS Computational Biology, 2015, 11 (11) :e1004485" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAC49EBCD3788D1B0993AFB6063D58CF54&amp;v=MTU2NDFpZkhiOEM4RjZTKzNQdEdZK01IZUgxTHp4OGE2VTRMT25uaXFoRkJmTHJuTTcrYkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU54Z3pMdSt3cTQ9Tg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[65]</b>
                                        Kappel D, Habenschuss S, Legenstein R, et al.Network plasticity as Bayesian inference[J].PLoS Computational Biology, 2015, 11 (11) :e1004485
                                    </a>
                                </li>
                                <li id="467">


                                    <a id="bibliography_66" title="Yu Zhaofei, Kappel D, Legenstein R, et al.CaMKII activation supports reward-based neural network optimization through Hamiltonian sampling[J].arXiv preprint arXiv:1606.00157, 2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CaMKII activation supports reward-based neural network optimization through Hamiltonian sampling">
                                        <b>[66]</b>
                                        Yu Zhaofei, Kappel D, Legenstein R, et al.CaMKII activation supports reward-based neural network optimization through Hamiltonian sampling[J].arXiv preprint arXiv:1606.00157, 2016
                                    </a>
                                </li>
                                <li id="469">


                                    <a id="bibliography_67" title="Kappel D, Legenstein R, Habenschuss S, et al.A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning[J].eNeuro, 2018, 5 (2) :ENEURO.0301-17.2018" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning">
                                        <b>[67]</b>
                                        Kappel D, Legenstein R, Habenschuss S, et al.A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning[J].eNeuro, 2018, 5 (2) :ENEURO.0301-17.2018
                                    </a>
                                </li>
                                <li id="471">


                                    <a id="bibliography_68" title="Jonke Z, Habenschuss S, Maass W.Solving constraint satisfaction problems with networks of spiking neurons[J].Frontiers in Neuroscience, 2016, 10:1- 16" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Solving constraint satisfaction problems with networks of spiking neurons">
                                        <b>[68]</b>
                                        Jonke Z, Habenschuss S, Maass W.Solving constraint satisfaction problems with networks of spiking neurons[J].Frontiers in Neuroscience, 2016, 10:1- 16
                                    </a>
                                </li>
                                <li id="473">


                                    <a id="bibliography_69" title="Hopfield J J, Tank D W.Computing with neural circuits:A model[J].Science, 1986, 233 (4764) :625- 633" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computing with neural circuits: a model">
                                        <b>[69]</b>
                                        Hopfield J J, Tank D W.Computing with neural circuits:A model[J].Science, 1986, 233 (4764) :625- 633
                                    </a>
                                </li>
                                <li id="475">


                                    <a id="bibliography_70" title="Aarts E, Korst J.Simulated Annealing and Boltzmann Machines[M].New York:John Wiley, 1989" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simulated annealing and Boltzmann machines">
                                        <b>[70]</b>
                                        Aarts E, Korst J.Simulated Annealing and Boltzmann Machines[M].New York:John Wiley, 1989
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(06),1135-1148 DOI:10.7544/issn1000-1239.2019.20190240            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>类脑机的思想与体系结构综述</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E9%93%81%E5%86%9B&amp;code=11679435&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄铁军</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E8%82%87%E9%A3%9E&amp;code=42095393&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">余肇飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%80%A1%E4%BF%8A&amp;code=06749000&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘怡俊</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%B3%BB&amp;code=0038515&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京大学计算机科学技术系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0038515&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东工业大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>经典计算机的理论边界在1936年就由图灵确定了, 冯·诺依曼体系结构计算机也受限于图灵机模型.囿于神经形态器件的缺失, 神经网络模型一直在经典计算机上运行.然而, 冯·诺依曼体系结构与神经网络的异步并行结构及通信机制并不匹配, 表现之一是功耗巨大, 发展面向神经网络的体系结构, 对于人工智能乃至一般意义上的信息处理都是重要方向.类脑机是仿照生物神经网络、采用神经形态器件构造的、以时空信息处理为特征的智能机器.类脑机的思想在计算机发明之前就提出了, 研究开发实践也已经进行了30多年, 多台类脑系统已经上线运行, 其中SpiNNaker专注于类脑系统的体系结构研究, 提出了一种行之有效的类脑方案.未来20年左右, 预计模式动物大脑和人脑的精细解析将逐步完成, 模拟生物神经元和神经突触信息处理功能的神经形态器件及集成工艺将逐步成熟, 结构逼近大脑、性能远超大脑的类脑机有望实现.类脑机像生物大脑一样都是脉冲神经网络, 神经形态器件具有真正的随机性, 因此类脑机具备丰富的非线性动力学行为.已证明任何图灵机均可由脉冲神经网络构造出来, 类脑机在理论上是否能够超越图灵机, 是需要突破的一个重大问题.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B1%BB%E8%84%91%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">类脑机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%84%89%E5%86%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">脉冲神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E5%BD%A2%E6%80%81%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经形态计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E7%81%B5%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图灵机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%AA%81%E8%A7%A6%E5%8F%AF%E5%A1%91%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">突触可塑性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黄铁军, tjhuang@pku.edu.cn, born in 1970. PhD. Professor and PhD supervisor.Member of CCF, ACM and IEEE.His main research interests include visual information processing and neuromorphic computing.;
                                </span>
                                <span>
                                    Yu Zhaofei, born in 1990.PhD.Member of IEEE.His main research interests include brain-like computing and machine learning.;
                                </span>
                                <span>
                                    Liu Yijun, born in 1977. PhD and professor. His main research interests include neuromorphic computing, computer architecture and integrated circuit design.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-16</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61425025);</span>
                                <span>广东省重点领域研发计划项目 (2018B030338001);</span>
                    </p>
            </div>
                    <h1><b>Brain-like Machine: Thought and Architecture</b></h1>
                    <h2>
                    <span>Huang Tiejun</span>
                    <span>Yu Zhaofei</span>
                    <span>Liu Yijun</span>
            </h2>
                    <h2>
                    <span>Department of Computer Science and Technology, Peking University</span>
                    <span>School of Information Engineering, Guangdong University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The theoretical limitation of the classical computing machinery, including all the computers with von Neumann architecture, was defined by Alan Turing in 1936. Owing to lack of the hardware neuromorphic devices, neural networks have been implemented with computers to realize artificial intelligence for decades. However, the von Neumann architecture doesn't match with the asynchronous parallel structure and communication mechanism of the neural networks, with consequences such as huge power consumption. To develop the neural network oriented architecture for artificial intelligence and common information processing is an important direction for architecture research. Brain-like machine is an intelligent machine which is constructed with neuromorphic devices according to the structure of biological neural network, and is better on spatio-temporal information processing than classic computer. The idea of brain-like machine had been proposed before the invention of computer. The research and development practice has been carried out for more than three decades. As one of the several brain-like systems being in operation, SpiNNaker focuses on the research on the architecture of brain-like systems with an effective brain-like scheme. In the next 20 years or so, it is expected that the detailed analysis of model animal brain and human brain will be completed step by step, and the neuromorphic devices and integrated processes will be gradually mature, and the brain-like machine with structure close to the brain and performance far beyond the brain is expected to be realized. As a kind of spiking neural networks, and with neuromorphic devices which behavior is true random, the brain-like machine can emerge abundant nonlinear dynamic behaviors. It had been proven that any Turing machine can be constructed with spiking neural network. Whether the brain-like machine can transcend the theoretical limitation of the Turing machine? This is a big open problem to break through.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=brain-like%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">brain-like machine;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spiking%20neural%20network%20(SNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spiking neural network (SNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neuromorphic%20computing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neuromorphic computing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Turing%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Turing machine;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=synaptic%20plasticity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">synaptic plasticity;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-16</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61425025);</span>
                                <span>the Key Research and Development Program of Guangdong Province (2018B030338001);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="146" name="146" class="anchor-tag"><b>1 类脑基本思想</b></h3>
                <h4 class="anchor-tag" id="147" name="147"><b>1.1 图灵机</b></h4>
                <div class="p1">
                    <p id="148">众所周知, 现代计算机产生的数学基础是数理逻辑, 物理基础是开关电路.数理逻辑的研究对象是证明和计算这2个直观概念符号化后的形式系统.1936年阿兰·麦席森·图灵 (Alan Mathison Turing, 1912—1954) 为了研究不可计算数而提出了图灵机模型, 这一看似简单的思想实验抓住了数理逻辑和抽象符号处理的本质, 划定了计算的理论边界:计算是机械式执行长度有限的算法的过程, 这种计算都可以由图灵机完成;所有算法都可以编码成为一个整数, 因此是可数的;尽管如此, 并不存在枚举出所有算法的算法.</p>
                </div>
                <div class="p1">
                    <p id="149">但是, 现在很多人把计算这个概念随意泛化为任意的信息处理过程, 这是不合适的.图灵机的状态和操作对象都是离散的, 在图灵可计算意义下, 1和0.1111… (无穷循环小数) 是2个不同的数, 产生这2个可计算数的图灵机也是不同的, 图灵机并不能发现在极限意义下两者相等.极限是人类大脑的创造, 在这个意义上, 人脑是超越图灵机的.</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150"><b>1.2 冯</b>·<b>诺依曼体系结构</b></h4>
                <div class="p1">
                    <p id="151">1938年克劳德·艾尔伍德·香农提出开关电路模型, 在数理逻辑和电路实现之间架起了桥梁.1946年首台计算机ENIAC研制成功, 实际上是一个近1.8万个电子管作为开关的大型开关电路系统.之前的1945年, 参与了ENIAC项目的冯·诺依曼 (John von Neumann, 1903—1957) 提出存储和计算分离的EDVAC结构, 这篇报告分15章, 长达百页, 但是后来成为经典的“冯·诺依曼体系结构”只是其中的前3章, 篇幅不到全文十分之一, 之后报告重点就转到了神经系统.第15章没写完, 冯·诺依曼后来也没继续写下去, 而是转向研究怎样用不可靠元件设计可靠的自动机, 以及建造自己能再生产的自动机.</p>
                </div>
                <div class="p1">
                    <p id="152">冯·诺依曼体系结构被经典计算机沿用至今, 虽然有各种优化, 但无根本性变化.在摩尔定律作用下, 冯·诺依曼体系结构计算机的性能呈指数增长, 一直作为包括人工智能在内的各种信息应用的基础平台.2004年至2005年前后, 丹纳德尺度缩微定律 (在半导体的尺寸不断缩小的同时其功耗密度大致保持不变) 失效, 普遍认为摩尔定律在持续50年后将于2020年左右走到尽头, 迫使人们重新思考计算机的体系结构问题.</p>
                </div>
                <h4 class="anchor-tag" id="153" name="153"><b>1.3 人工神经网络</b></h4>
                <div class="p1">
                    <p id="154">1956年, 人工智能的概念正式登上历史舞台.60多年来, 人工智能经历了3次浪潮, 基本思想可大致划分为三大流派:符号主义、连接主义和行为主义, 从不同侧面抓住了智能的部分特征.连接主义也称神经网络学派, 其基本思想是:既然人脑智能是由神经网络产生的, 那就通过人工方式构造神经网络, 进而产生智能.</p>
                </div>
                <div class="p1">
                    <p id="155">神经网络思想的提出早于计算机的发明, 1943年麦卡洛克和皮茨把神经元想象成“全或无”的逻辑开关, 他们提出的神经元模型至今还是人工神经网络使用的基本单元.80多年来, 人们提出了各种各样的人工神经网络, 但是实现神经元和神经突触功能的物理器件一直未能发展起来.相比之下, 冯·诺依曼体系结构计算机凭借集成电路摩尔定律的支持, 性能呈指数增长, 因此, 缺少物理实现载体的人工神经网络逐步“寄生”在计算机上运行.但必须指出的是, 人工神经网络结构和冯·诺依曼体系结构毫无可比性, 从体系结构角度看, 冯·诺依曼体系结构不是实现神经网络运行的合理方案.</p>
                </div>
                <div class="p1">
                    <p id="156">2006以来, 多层神经网络和机器学习相结合的深度学习在图像和语音识别等领域取得突破性进展, 大规模深度神经网络和大数据训练对计算能力提出了更高需求, 经典计算机运行神经网络能耗居高不下, 按照神经网络的结构设计新的机器结构, 已是大势所趋和必然选择.</p>
                </div>
                <h4 class="anchor-tag" id="157" name="157"><b>1.4 生物神经网络</b></h4>
                <div class="p1">
                    <p id="158">经典的人工神经网络 (artificial neural network, ANN) 借鉴了生物神经网络的基本特征, 但过度简化.1) 人工神经网络采用的神经元模型还是1943年提出的简化模型, 与生物神经元的标准数学模型霍奇金-赫胥黎微分方程相距甚远, 不是简单的数值计算;2) 人类大脑是由数百种不同类型的上千亿的神经细胞所构成的极为复杂的生物组织, 每个神经元通过数千甚至上万个神经突触和其他神经元相连接, 即使采用简化的神经元模型, 用目前最强大的计算机来模拟人脑, 也还有2个数量级的差异;3) 生物神经网络是一种复杂的脉冲神经网络 (spiking neural network, SNN) , 采用动作电位表达和传递信息, 按照非线性动力学机制处理信息, 目前的深度学习等人工神经网络的时序特性还很初级.</p>
                </div>
                <div class="p1">
                    <p id="159">仅就神经元模型而言, 采用数字计算方法仿真生物神经元, 计算复杂度比人工神经元模型要高多个数量级.即使采用简化的脉冲神经网络模型——泄漏积分发放 (leaky integrate-and-fire, LIF) 模型来实时仿真人类大脑, 也约需要100台太湖之光超级计算机.</p>
                </div>
                <div class="p1">
                    <p id="160">更严重的是, 神经网络结构和冯·诺依曼体系结构大相径庭, 这对性能的影响更为致命.2010年左右提出的评价超级计算机的新指标——在大型随机图上每秒穿越的边数 (traversed edges per second, TEPS) , 能够兼顾计算性能和通讯性能.如果将2个大脑神经元之间的一次脉冲传递类比为在图上穿越一个边, 采用TEPS指标, 人脑比当今最快的超级计算机也要快一个数量级.</p>
                </div>
                <div class="p1">
                    <p id="161">与生物神经网络相比, 人工神经网络过度简化, 要实现更强的智能, 需要更复杂、更精细的神经网络, 最直接的蓝本就是生物神经网络.当前在计算机上采用软件方式仿真实现神经网络只是权宜之计, 网络规模难以扩大, 更直接的方案是直接按照神经网络结构设计全新的体系结构.</p>
                </div>
                <h4 class="anchor-tag" id="162" name="162"><b>1.5 类脑机</b></h4>
                <div class="p1">
                    <p id="163">理解意识现象和功能背后的发生机理 (简称“理解智能”) 是人类的终极性问题, 制造类似人脑的具有自我意识的智能机器 (简称“制造智能”) 是工程技术领域重大挑战.一种常见看法是制造智能的前提是理解智能, 这实际上把问题的解决建立在解决另一个更难问题的基础上, 犯了本末倒置的错误.</p>
                </div>
                <div class="p1">
                    <p id="164">要实现更强的机器智能乃至通用人工智能, 首先要分清大脑的结构 (主要是皮层神经网络) 和大脑的功能 (智能、意识) 这2个层次.尽管目标是实现智能功能, 但理解智能机器困难, 更现实的做法是回到结构层次, 尝试先制造出具有同样结构的机器, 通过训练产生预期功能.自古以来人类的很多工程实践都是采用这种技术路线, 以深度学习为例, 其网络结构清晰、效果好, 但机理不清楚, 可解释性理论是下一步需要突破的问题, 而不是设计深度神经网络的前提.</p>
                </div>
                <div class="p1">
                    <p id="165">从人类大脑出发研究更强的机器智能乃至通用人工智能, 我们认为更可行的技术路线是先结构仿脑, 再功能类脑, 最后才是理解大脑.因此, 本文的“类脑”, 主要是指结构类脑, 即仿真、模拟和借鉴大脑神经网络结构和基元 (神经元、神经突触) 信息处理过程, 中心任务是制造类脑机 (brain-like machine) , 或称神经机 (neuromachine) <citation id="477" type="reference"><link href="337" rel="bibliography" /><link href="339" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.制造出这样的智能机器, 理解机器智能的机理, 将能加速对人类大脑智能奥秘的揭开.</p>
                </div>
                <div class="p1">
                    <p id="166">类脑机是仿照生物神经网络、采用神经形态器件构造的、以时空信息处理为特征的智能机器.与生物神经系统一样, 类脑机是一种脉冲神经网络, 采用光电微纳器件模拟生物神经元和神经突触的信息处理功能, 在仿真精度达到一定范围后, 有望具备生物大脑类似的信息处理功能和系统行为.简言之, 类脑机不是等待理解智能的机理后再进行模拟, 而是绕过这个更为困难的科学问题, 通过结构仿真等工程技术手段间接达到功能模拟的目的.</p>
                </div>
                <div class="p1">
                    <p id="167">生物是类脑机的原型, 生物智能活动主要是接收来自环境的多种刺激、实时处理并及时响应, 这也是类脑机的主要功能和存在目的.</p>
                </div>
                <h4 class="anchor-tag" id="168" name="168"><b>1.6 大脑解析进展</b></h4>
                <div class="p1">
                    <p id="169">类脑机的体系结构源自生物大脑, 这就需要获得生物大脑基本单元 (各类神经元和神经突触等) 的功能及其连接关系 (网络结构) .人脑拥有数百种、上千亿个神经元 (即10<sup>11</sup>数量级) , 每个神经元通过数千乃至上万神经突触和其他神经元相连接 (连接数量达到10<sup>14</sup>数量级) .尽管如此, 人脑神经系统仍然是一个复杂度有限的物理结构, 采用神经科学实验手段, 从分子生物学和细胞生物学层次解析大脑神经元和突触的物理化学特性, 理解神经元和突触的信号加工和信息处理特性, 并无突破不了的技术障碍.</p>
                </div>
                <div class="p1">
                    <p id="170">神经系统解析贯穿了神经科学百年历史.1906年, 诺贝尔生理学或医学奖授予“在神经系统结构研究上的工作”的卡米洛·高尔基 (Camilo Golgi, 1843—1926) 和圣地亚哥·拉蒙·卡哈尔 (Santiago Ramon y Cajal, 1852—1934) , 他们提出神经元染色法并绘制了大量精美的生物神经网络图谱, 沿用至今.1939年剑桥大学阿兰·霍奇金和博士后安德鲁·赫胥黎开始研究神经元信号加工过程, 自制工具测量到神经元的静息电位和动作电位.二战爆发, 他们投笔从戎, 1946年重新拿起膜片钳, 精细测量神经元传递电信号 (或称神经脉冲, 更准确地称为动作电位) 的动态过程, 并给出了精确描述这一动力学过程的微分方程, 称为霍奇金-赫胥黎方程 (Hodgkin-Huxley方程, 简称HH方程) <citation id="478" type="reference"><link href="341" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.HH模型对不同类型的神经元具有通用性, 1963年获得诺贝尔奖.</p>
                </div>
                <div class="p1">
                    <p id="171">加拿大生理心理学家唐纳德·赫布1949年提出赫布法则 (Hebb's Law) :同时激发的神经元之间的突触连接会增强<citation id="479" type="reference"><link href="343" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 至今这都是人工神经网络模型广泛采用的基本原则.1952年, 中国现代神经科学奠基人张香桐 (1907—2007) 发现树突具有电兴奋性, 树突上的突触可能对神经元的兴奋精细调节起重要作用, 1992年国际神经网络学会授予张香桐终身成就奖, 评价他“…为树突电流在神经整合中起重要作用这一概念提供了直接证据……为我们将来发展使用微分方程和连续时间变数的神经网络、而不再使用数字脉冲逻辑的电子计算机奠定了基础”.1998年, Tsodyks和Markram等人提出了神经突触计算模型<citation id="480" type="reference"><link href="345" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.同年, 毕国强和蒲慕明提出了神经突触脉冲时间依赖的可塑性 (spike-timing dependent plasticity, STDP) 机制<citation id="481" type="reference"><link href="347" rel="bibliography" /><link href="349" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>:反复出现的突触前脉冲有助于紧随其后产生的突触后动作电位并将导致长期增强, 相反的时间关系将导致长期抑制.2000年, 宋森等人给出了STDP的数学模型<citation id="482" type="reference"><link href="351" rel="bibliography" /><link href="353" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="172">2008年, 美国工程院把“大脑反向工程”列为本世纪14个重大工程问题之一.2013年以来, 欧洲“人类大脑计划”以及美、日、韩和我国的“脑计划”相继登场, 都把大脑结构图谱绘制作为重要内容.2014年, “单细胞分辨的全脑显微光学切片断层成像”获得国家自然科学二等奖, 并被欧洲人类大脑计划用作鼠脑仿真的基础数据.2016年3月, 美国情报高级研究计划署 (IARPA) 启动大脑皮层网络机器智能 (MICrONS) 计划, 对1 mm<sup>3</sup>的大脑皮层进行反向工程, 并运用这些发现改善机器学习和人工智能算法.2016年4月, 全球脑计划研讨会 (the Global Brain Workshop 2016) 提出需要应对三大挑战, 第一个挑战就是绘制大脑结构图谱<citation id="483" type="reference"><link href="355" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>:“在10年内, 我们希望能够完成包括但不限于以下动物大脑的解析:果蝇、斑马鱼、鼠、狨猴, 并将开发出大型脑图谱绘制分析工具.”2016年9月8日, 日本东海大学宣布绘制出包括十多万神经元的果蝇大脑神经网络三维模型, 2019年1月, 《Science》封面文章报道只用了3天时间就对果蝇完整大脑进行了纳米级成像<citation id="484" type="reference"><link href="357" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="173">2018年, 我国在北京怀柔开始建设“多模态跨尺度生物医学成像”国家重大科技基础设施, 将具备从埃米到米、从微秒到小时跨越10个空间与时间尺度的解析能力, 分步骤实现多种模式动物大脑的高精度动态解析.各方面的进展表明, 人脑神经网络精细图谱有望在20年内完成.</p>
                </div>
                <h3 id="174" name="174" class="anchor-tag"><b>2 类脑机研究进展</b></h3>
                <div class="p1">
                    <p id="175">类脑机不是一个新想法.早在计算机发明之前的1943年, 图灵和香农就曾围绕想象中的“电脑”进行过争论, 香农提议把“文化的东西”灌输给电脑, 而图灵高声反驳:“不, 我对建造一颗强大的大脑不感兴趣, 我想要的不过是一颗寻常的大脑, 跟美国电报电话公司董事长的脑袋瓜差不多即可<citation id="485" type="reference"><link href="359" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.”1950年, 图灵在开辟人工智能方向的论文《计算机与智能》中明确表示:“真正的智能机器必须具有学习能力, 制造这种机器的方法:先制造一个模拟童年大脑的机器, 再教育训练<citation id="486" type="reference"><link href="361" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.”冯·诺依曼也曾认真思考过大脑, 根据他未完成的西列曼演讲整理而成的《计算机与人脑》一书1958年出版<citation id="487" type="reference"><link href="363" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 上半部分为计算机, 下半部分为人脑, 讨论神经元、神经脉冲、神经网络以及人脑的信息处理机制.</p>
                </div>
                <div class="p1">
                    <p id="176">实践意义上的类脑机研制可以追溯到20世纪80年代.美国生物学家杰拉尔德·艾德曼 (Gerald Maurice Edelman, 1929—2014) 1981年提出了统称为“综合神经建模 (synthetic neural modeling) ”的理论, 即逼近真实解剖和生理数据的神经系统大规模仿真<citation id="488" type="reference"><link href="365" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 并研制了一系列名为“Darwin”的“仿脑机” (brain-based-devices, BBD) <citation id="489" type="reference"><link href="367" rel="bibliography" /><link href="369" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>, 通过从多种仿真神经回路中进行选择而实现学习.起初是软件, 1992年开始采用硬件, 以2005—2007年研制的达尔文10号和11号为例, 仿真约50个脑区、10万神经元和140万突触连接, 通过模拟啮齿类动物走迷宫的过程, 理解大脑空间记忆的形成过程.基于BBD的足球机器人于2004—2006年参加RoboCup机器人足球公开赛, 曾5局全胜卡内基梅隆大学基于经典人工智能的系统.</p>
                </div>
                <div class="p1">
                    <p id="177">现代微电子学和大规模集成电路先驱、加州理工学院教授卡弗·米德 (Carver Andress Mead, 1934—) 也是在20世纪80年代把兴趣转向了生物神经系统的, 与艾德曼关注神经元群体和神经环路不同, 米德的关注点在神经元的硬件实现, 开创了“神经形态工程 (Neuromorphic Engineering) ”这个方向<citation id="491" type="reference"><link href="371" rel="bibliography" /><link href="373" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>, 提出采用亚阈值模拟电路来仿真脉冲神经网络, 并提出了“神经形态处理器 (Neuromorphic Processors) ”的概念.1989年5月, 米德在电路与系统研讨会 (International Symposium on Circuits and Systems, ISCAS) 会议期间组织了“模拟集成神经系统 (Analog Integrated Neural Systems) ”研讨会<citation id="490" type="reference"><link href="375" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 主要参会人员至今仍然活跃在这一领域.</p>
                </div>
                <h4 class="anchor-tag" id="178" name="178"><b>2.1 斯坦福大学的Neurogrid与BrainStorm</b></h4>
                <div class="p1">
                    <p id="179">米德1989年招收的博士生博阿汉 (Kwabena Boahen) 2005年加入斯坦福大学, 成立了“硅脑” (Brains in Silicon) 实验室, 2009年研制出了神经形态电路板Neurogrid, 每块板16颗Neurocore芯片.每颗芯片内集成了65 536个神经元, 每个神经元用340个亚阈值工作状态的晶体管模拟, 这样一块Neurogrid板就支持100万个神经元和60亿个突触联结, 能耗只有5 W.每个Neurocore芯片都包括一个路由器, 能够在其本地芯片、父芯片及其2个子芯片之间传送脉冲数据包.路由器支持多播树路由组织, 其中脉冲数据被点对点传送到位于树中所有预期目的地之上的节点, 然后到达所有目的地, 需要时可以复制.据称Neurogrid在神经系统模拟方面可媲美能耗1 MW的超级计算机<citation id="492" type="reference"><link href="377" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="180">Neurogrid团队2017年开发了新一代神经形态芯片BrainStorm, 这一项目2013年启动, 由美国海军研究办公室资助, 最后的成果将成为嵌入式应用和集群服务器上的计算芯片, 可以运行全脑模型.目前还没有相关论文解释该项目的细节, 但博阿汉指出Brainstorm与其他已有神经形态芯片设计存在着很大不同:“目前有很多神经形态设备使用的是超级计算机所使用的路由机制, 就像网格一样.问题在于, 在网格架构中你只能进行点对点信号传递.如果你想一次发出多个信号, 系统就会锁死.”博阿汉说Brainstorm是首个实现从高层次描述合成的脉冲神经网络的芯片, 能解决多维非线性微分方程描述的问题, 或者说是基于当前状态与输入随时间变化而变化的那类问题.</p>
                </div>
                <h4 class="anchor-tag" id="181" name="181"><b>2.2 从软件仿真到IBM TrueNorth芯片</b></h4>
                <div class="p1">
                    <p id="182">2005年, 瑞士洛桑联邦理工学院 (EPFL) 亨利·马克拉姆 (Henry Markram, 1962—) 牵头“蓝色大脑计划”, 在IBM蓝色基因超级计算机上仿真大脑皮层<citation id="493" type="reference"><link href="379" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.2007年IBM Almaden研究中心认知计算研究组在美国国防高级研究计划局 (DARPA) 支持下开展神经形态自适应可塑性可扩展电子系统 (systems of neuromorphic adaptive plastic scalable electronics, SyNAPSE) 研究, 开发了大脑模拟软件——皮层模拟器 (cortical simulator) , 2009年在蓝色基因超级计算机上实现了8.61 T个神经突触的猫脑模拟<citation id="494" type="reference"><link href="381" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 所采用的神经元模型是简化的LIF, 即使如此, 根据计算能力测算, 实时模拟人类大脑也需要100台太湖之光超级计算机.同样在2009年, 马克拉姆团队在蓝色基因超级计算机上构造出出生2周大鼠的新皮质柱精细模型, 包括1万个神经元和数千万个突触连接, 实现了生物神经网络才拥有的伽马振荡现象.在此基础上, 由马克拉姆领衔的欧洲“人类大脑计划”于2013年1月获得欧盟批准, 提出整合从单分子探测到大脑整体结构解析, 实现全脑仿真模拟<citation id="495" type="reference"><link href="383" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="183">IBM主导的SyNAPSE项目在超级计算机上进行大脑皮层仿真基础上, 为了突破规模瓶颈, 也开发了神经形态芯片TrueNorth芯片<citation id="496" type="reference"><link href="385" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>, 2014年Science将之列为年度十大科学进展.</p>
                </div>
                <div class="p1">
                    <p id="184">TrueNorth采用成熟的CMOS集成电路工艺, 神经元采用简单的LIF模型, 每片集成4 096个核, 每核内有256个输入神经元和256个输出神经元, 突触状态、神经元状态和参数、脉冲目的地址、轴突延迟等均用静态随机存储器记录.单片集成100万个神经元和2.56亿突触连接, 耗费54亿个晶体管, 单个芯片平均放电频率20 Hz, 单神经元放电功耗26 pJ, 芯片功耗低至65 mW, 大约是晶体管数量相当的传统CPU功耗的<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mn>5</mn><mtext> </mtext><mn>0</mn><mn>0</mn><mn>0</mn></mrow></mfrac></mrow></math></mathml>.基于这款芯片, IBM建立了Corelet编程模型、算法库和相应的软件开发环境, 结合Compass模拟器, 用户可以快速尝试不同的模型和参数, 从中找出优化的方案.</p>
                </div>
                <div class="p1">
                    <p id="186">2016年4月, 采用TrueNorth, 美国劳伦斯·利弗莫尔国家实验室和IBM公司公布了一款智能超级计算机, 实验室数据科学副主任吉姆·布雷斯表示:“仿神经运算为我们创造了令人激动的新机会, 这正是我们国家安全任务的核心——高性能运算和模拟技术的未来发展方向.仿神经计算机的潜在能力, 以及它可以实现的机器智能, 将改变我们研究科学的方式.”</p>
                </div>
                <h4 class="anchor-tag" id="187" name="187"><b>2.3 欧洲的SpiNNaker和BrainScaleS</b></h4>
                <div class="p1">
                    <p id="188">为了实现全脑仿真的目标, 欧洲人类大脑计划支持了2台大型神经形态计算系统的研制:英国曼彻斯特大学的SpiNNaker系统和德国海德堡大学的BrainScaleS, 2016年3月2台阶段样机正式上线运行.</p>
                </div>
                <div class="p1">
                    <p id="189">SpiNNaker<citation id="497" type="reference"><link href="387" rel="bibliography" /><link href="389" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">27</a>]</sup></citation>源于2005年开始的EPSRC项目, 负责人是ARM处理器发明人史蒂夫·佛伯 (Steve Furber, 1953—) .SpiNNaker系统采用定制ARM处理器作为基本单元, 分为5代, 最初的102机使用了约10<sup>2</sup>个ARM核, 计划2020年完成的106机则集成了约10<sup>6</sup>个ARM核.SpiNNaker研究的中心任务就是探索新的体系结构, 采用包交换来模拟神经元之间的异步稀疏脉冲交换, 可以在物理连接大大少于大脑的情况下实现相同性能的信息交换, 具体细节将在第3节详细介绍.</p>
                </div>
                <div class="p1">
                    <p id="190">BrainScaleS由德国海德堡大学卡尔海因茨·迈耶 (Karlheinz Meier, 1955—2018) 教授负责<citation id="499" type="reference"><link href="391" rel="bibliography" /><link href="393" rel="bibliography" /><sup>[<a class="sup">28</a>,<a class="sup">29</a>]</sup></citation>, 前身是2005—2010年的FACTES项目, 特点是从微观层面研究神经元的信号处理特性及模拟电路实现, 在介观层面研究突触可塑性及数字电路实现, 在8英寸晶园上实现了20万神经元和5千万突触, 晶圆内总线速度达每秒1 T脉冲, 晶圆间分布式通信速度每秒10 G脉冲.在人类大脑计划支持下, 2016年完成了20块晶圆、400万神经元和10亿突触的神经形态计算系统<citation id="498" type="reference"><link href="395" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>, 速度比生物系统快1万倍.2022年 (也就是人类大脑计划结束前) 预计构造出一个500块到5 000块晶圆组成的大型系统, 即使是500块方案, 也能同时仿真5亿神经元, 由于其速度比生物神经元高万倍, 因此将具备实时仿真人类大脑的能力.</p>
                </div>
                <h4 class="anchor-tag" id="191" name="191"><b>2.4 我国相关进展</b></h4>
                <div class="p1">
                    <p id="192">我国类脑研究起步较晚, 但近年来十分活跃, 北京大学、清华大学、中国科学院自动化研究所、浙江大学、四川大学等单位成立了多个类脑计算或类脑智能方面的研究中心.</p>
                </div>
                <div class="p1">
                    <p id="193">2015年9月1日, 北京市科学技术委员会正式发布“北京脑科学研究”专项规划, 从“脑认知与脑医学”和“脑认知与类脑计算”2个方面进行布局<citation id="500" type="reference"><link href="397" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>.“脑认知与类脑计算”沿着“结构仿真、器件逼近和功能超越”这条技术路线, 布局了3个层次、9个方面的科研任务:建设四大基础性公共平台 (大脑解析仿真平台、认知功能模拟平台、神经形态器件平台和类脑计算机系统平台) , 开发2款类脑计算处理器芯片 (类脑处理器和机器学习处理器) , 研制类脑计算机软硬件系统, 在视听感知、自主学习、自然会话三大类脑智能方向取得突破并实现规模应用.经过3年多的持续支持, 北京已经在类脑计算方面形成了较为系统的技术积累, 清华大学研制的天机系列芯片和北京大学研制的超速全时视网膜芯片是其中的代表性成果.</p>
                </div>
                <div class="p1">
                    <p id="194">清华大学团队提出了类脑混合计算范式架构, 开发了“天机”系列类脑芯片.2015年11月研制出首款跨模态异构融合神经形态类脑计算芯片, 可进行大规模神经元网络的模拟, 具有超高速、实时、低功耗等特点, 相关结果于2016年12月发表在《Science》智能机器人特刊.2017年10月研制成功天机2代神经形态芯片, 采用28纳米半导体技术, 集成了千万突触和约4万个神经元, 同时支持脉冲神经网络算法和人工神经网络算法, 与IBM TrueNorth相比, 在芯片密度、速度和带宽都有大幅度提升.2018年利用脉冲神经网络的时空特性, 实现了在时空域的SNN误差反向传播算法, 解决了函数逼近的方法处理脉冲发放时刻不可导问题, 建立了SNN全连接及卷积神经网络新算法.</p>
                </div>
                <div class="p1">
                    <p id="195">北京大学在北京“脑认知与类脑计算”支持下, 围绕视觉系统解析仿真开展研究, 研制出类脑机的“眼睛”.2015—2016年对灵长类视网膜进行了高精度解析仿真, 实现了视网膜中央凹神经细胞和神经环路精细建模, 提出了模拟视网膜机理的仿生视频脉冲编码模型.2017—2018年初, 研制成功脉冲阵列式超速全时仿视网膜芯片.生物视觉信息处理机制虽然优越, 但受限于生理限制, “主频”很慢, 灵长类视网膜每秒发放的神经脉冲数平均不超过数十个.仿视网膜芯片脉冲发放频率达到40 000 Hz, “超速”人眼千倍, 能够“看清”高速旋转叶片的文字.“全时”是指从芯片采集的神经脉冲序列中重构出任意时刻的画面, 这是真正机器视觉的基础, 有望重塑包括表示、编码、检测、跟踪、识别在内的整个视觉信息处理体系.</p>
                </div>
                <div class="p1">
                    <p id="196">浙江大学及杭州电子科技大学联合研究团队主要面向低功耗嵌入式应用领域, 于2015年研发了一款基于CMOS数字逻辑的脉冲神经网络芯片“达尔文”, 支持基于LIF神经元模型的脉冲神经网络建模.2016 IEEE CIS计算智能相关的暑期学校将达尔文芯片作为一个案例供所有参加人员编程实践与应用开发.</p>
                </div>
                <div class="p1">
                    <p id="197">2017年国家自然基金委信息科学部研究确定了“人工智能 (F06) ”代码, 专门设置了“认知与神经科学启发的人工智能 (F0607) ”方向, 其中与类脑直接相关的支持方向包括:视听觉感知模型、神经信息编码与解码、神经系统建模与分析、神经形态工程、类脑芯片、类脑计算.从2018年起, 我国类脑领域的基础研究已经全面展开.</p>
                </div>
                <h3 id="198" name="198" class="anchor-tag"><b>3 脉冲神经网络体系结构SpiNNaker</b></h3>
                <div class="p1">
                    <p id="199">SpiNNaker是脉冲神经网络体系结构 (The spiking neural network architecture) 的缩写, 是英国曼彻斯特大学Steve Furber教授带领的先进处理器技术团队 (APT) 研发的类脑计算系统, 研究始于2005年, 目的是借鉴大脑神经网络结构研究新的计算体系结构.</p>
                </div>
                <div class="p1">
                    <p id="200">SpiNNaker是一个大型脉冲神经网络, 采用独特的全局异步局部同步 (GALS) 互连网络结构, 最新系统将不同时域的一百万ARM微处理器核心和1 200个互连计算主板高效集成为1台高度并行的超级计算机, 每秒执行200万亿次定点运算操作, 支持实时事件驱动的编程模式, 适用于生物神经网络的实时模拟.</p>
                </div>
                <h4 class="anchor-tag" id="201" name="201"><b>3.1 体系结构</b></h4>
                <div class="p1">
                    <p id="202">SpiNNaker系统由ARM微处理器核心、多核CPU芯片、计算主板、机架、机柜和整机等6个不同的层次构成, 如图1所示.2018年11月上线的最新系统采用的微处理器核心是200 MHz的32-bit ARM968微处理器, 拥有32 KB指令存储器和64 KB数据存储器, 不带浮点运算单元.每颗多核CPU芯片包含18颗ARM968和一个中央片上网络路由器, 用异步片上网络连接.48颗SpiNNaker多核CPU芯片构成一块计算主板.24块主板组成一个机架.5个机架构成一个机柜.10个机柜组成整个SpiNNaker系统.因此, SpiNNaker系统包含的ARM CPU数量为18×48×24×5×10=1 036 800个.一个200 MHz的ARM CPU可以生物实时模拟1 000～10 000个IF (integrate-and-fire) 级别的简单神经元模型, 整个SpiNNaker系统理论上可以生物实时模拟10～100亿个这样的神经元.</p>
                </div>
                <div class="area_img" id="203">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_203.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SpiNNaker系统的层次结构" src="Detail/GetImg?filename=images/JFYZ201906002_203.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SpiNNaker系统的层次结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_203.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Hierarchical structure of SpiNNaker</p>

                </div>
                <div class="area_img" id="204">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SpiNNaker系统的网络拓扑结构[32]" src="Detail/GetImg?filename=images/JFYZ201906002_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SpiNNaker系统的网络拓扑结构<citation id="501" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Network topology of the SpiNNaker system<citation id="502" type="reference"><link href="399" rel="bibliography" /><sup>[32]</sup></citation><sup></sup></p>

                </div>
                <div class="p1">
                    <p id="205">SpiNNaker多核CPU芯片包含一个6端口的通信路由器与其他芯片连接.整个系统形成一个六边形平面网格 (hexagon 2D mesh) 的拓扑结构, 如图2 (a) 所示, 平面网格结构的左右和上下方向的边缘接口相连, 最终构成一个轮胎形态的环状结构, 如图2 (b) 所示 (其中CMP为chip multiple processors的缩写, 表示多核处理器芯片) .</p>
                </div>
                <h4 class="anchor-tag" id="206" name="206"><b>3.2 海量脉冲异步传输机制</b></h4>
                <div class="p1">
                    <p id="207">人脑中的每个神经元通过神经突触与成千上万其他神经元相连接, 每个神经脉冲要传递给成千上万个神经元, 这种高扇出 (fan-out) 的多播 (multicast) 传输方式对传统超级计算机来说是个巨大挑战.传统超算支持点对点的大数据块传输非常高效, 但实现海量短小神经脉冲数据包的多播传输效率很低.</p>
                </div>
                <div class="p1">
                    <p id="208">SpiNNaker系统研发了一种适用于大规模脉冲神经网络模拟的高效“源地址多播传输”机制.SpiNNaker支持相邻神经元数据包 (nearest neighbor package) 传输、点对点数据包 (point-to-point package) 传输、固定路径 (fixed route package) 传输、神经脉冲数据包 (the neural event package) 传输等4种不同的数据包传输方式.前3种数据包用于初始化、状态检测、控制信息和参数传递等.</p>
                </div>
                <div class="p1">
                    <p id="210">神经脉冲数据包传输是SpiNNaker中最重要的传输方式, 其数据包的格式如图3所示.神经脉冲数据包为40 b或72 b, 包括32 b数据载荷和8 b控制字, 还可以额外携带一个32 b的数据载荷.通常意义上的神经脉冲数据包不需要携带数据, 一个数据包的到来代表着一个神经脉冲到来的事件.在SpiNNaker系统中, 负载是发送该神经脉冲的神经元的32 b源地址 (可能遵循一定的规则, 如16 b代表CPU编码, 16 b代表在该CPU中模拟的神经元地址) .然而, 这个结构中并没有说明目的地址, 数据包如何被精确地传递到成千上万个目的地呢?SpiNNaker提出了“源地址多播传输”机制——数据包经过的路由器根据32 b源地址查找路由表, 将该数据包复制到不同的输出口, 一级级传递下去.</p>
                </div>
                <div class="area_img" id="211">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_211.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 神经脉冲数据包结构[32]" src="Detail/GetImg?filename=images/JFYZ201906002_211.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 神经脉冲数据包结构<citation id="503" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_211.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Neural spike package layout<citation id="504" type="reference"><link href="399" rel="bibliography" /><sup>[32]</sup></citation><sup></sup></p>

                </div>
                <div class="area_img" id="209">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_209.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 源地址广播的实现机制" src="Detail/GetImg?filename=images/JFYZ201906002_209.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 源地址广播的实现机制  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_209.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Propagation mechanism of source-addressed multicasting</p>

                </div>
                <div class="p1">
                    <p id="212">如图4所示, 每颗多核CPU芯片的路由器有东 (E) 、西 (W) 、东南 (SE) 、西南 (SW) 、东北 (NE) 和西北 (NW) 6个传输方向, 简称a, b, c, d, e, f, 还有一个“local”方向表示该芯片本地18颗CPU的传输方向.路由器中有一个路由表.路由表在实现上是一个CAM芯片, 存储许多行 (如1 024行) 的路由信息, 支持所有行源地址的并行比较.每行有左右2列, 左边代表一个发送数据包的源地址, 右边代表传输的方向, 由多位构成, 表示多个方向.</p>
                </div>
                <div class="p1">
                    <p id="213">路由器接收到一个数据包后, 根据包的源地址并行查找路由表.如果查到, 路由器就按照路由表的方向指示向一个或多个方向传输该数据包;如果没有查到, 路由器将包按照来的方向直接传递 (a→d, b→e, c→f, d→a, e→b, f→c) .如图4所示, 假如节点4传递一个数据包到节点7, 源地址为4;节点7路由表中没有4, 按照直线传给10;节点10路由表中显示源地址为4的数据包按照d方向传递给9;节点9路由表再按照d, c方向传递给节点8和节点12 (这时数据包被复制了) , 以此类推.路由表的信息在脉冲神经网络运行之前由sPyNNaker软件系统 (3.3节介绍) 统一初始化.</p>
                </div>
                <div class="p1">
                    <p id="214">采用源地址多播传输机制进行海量神经脉冲的高扇出分发传递, 使得数据包无需指明众多的目的地址就能够大规模地按照指定方向进行多播并行传输, 有利于保证数据包格式的规范性, 大大缩短了数据包的长度, 提高了传输的速度.</p>
                </div>
                <div class="area_img" id="215">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_215.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 SpiNNaker的软件系统结构[32]" src="Detail/GetImg?filename=images/JFYZ201906002_215.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 SpiNNaker的软件系统结构<citation id="505" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_215.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Software system architecture of SpiNNaker<citation id="506" type="reference"><link href="399" rel="bibliography" /><sup>[32]</sup></citation><sup></sup></p>

                </div>
                <h4 class="anchor-tag" id="216" name="216"><b>3.3 SpiNNaker软件系统</b></h4>
                <div class="p1">
                    <p id="217">SpiNNaker的软件系统称为sPyNNaker, 可以将PyNN语言描述的脉冲神经网络解析并在SpiNNaker系统中仿真运行.PyNN语言是一种基于Python的跨平台脉冲神经网络描述高级语言, 支持主流的脉冲神经网络软件仿真平台, 包括NEST, NEURON和Brian, 因此SpiNNaker和BrainScaleS都支持它, 以兼任支持各种脉冲神经网络模型.</p>
                </div>
                <div class="p1">
                    <p id="218">sPyNNaker软件系统架构如图5所示, 各部分组成和功能均有显示.</p>
                </div>
                <div class="p1">
                    <p id="219">1) Front End Interface:PyNN.PyNN的前端接口模块, 用户可以在客户端利用PyNN接口编写脉冲神经网络模型.</p>
                </div>
                <div class="p1">
                    <p id="220">2) Mapping:Placement, Partitioning, Routing, Data Gnenration.将PyNN描述的脉冲神经网络根据用户分配的硬件资源分解并映射到相应的CPU、内存和路由表中, 生成配置信息.</p>
                </div>
                <div class="p1">
                    <p id="221">3) Python Interface to SpiNNaker Hardware.负责客户端与SpiNNaker硬件系统的接口, 包括将配置信息通过互联网下载到SpiNNaker计算机、传输模拟控制命令、将SpiNNaker的模拟结果传回到前端等功能.</p>
                </div>
                <div class="p1">
                    <p id="222">4) Visualization. SpiNNaker的虚拟可视化界面.</p>
                </div>
                <div class="p1">
                    <p id="223">5) SARK (SpiNNaker application runtime kernel) .底层的硬件管理, 主要控制DMA、网络接口和通信控制器等.</p>
                </div>
                <div class="p1">
                    <p id="224">6) Event-Driven SpiN1API.支持事件驱动的操作系统, 主要负责维护CPU内核中的任务安排进程、任务调度进程和快速事件响应等3个主要进程, 支持实时事件模拟.</p>
                </div>
                <div class="p1">
                    <p id="225">7) User Application Code.与神经网络生成和模拟相关的应用开发库文件, 支持不同神经元模型、延时模型和脉冲源等.</p>
                </div>
                <div class="p1">
                    <p id="226">sPyNNaker采用时间驱动 (time-driven) 和事件驱动 (event-driven) 两种混合驱动方式来模拟脉冲神经网络, 时间驱动模拟神经元的变化, 事件驱动模拟突触的变化, 如图6所示.CPU用时间轮询的方式模拟生物时间, 例如Δ<i>T</i> CPU时间模拟1 ms的生物时间, 在Δ<i>T</i>时间内, CPU轮询该CPU中模拟的所有神经元, 更新它们的状态.CPU同时还需要响应来自于本CPU中神经元或者外部神经元发送的神经脉冲到达的事件, 支持以组播的方式更新相连接的突触, 并更新神经元的状态.各神经元状态变化后可能产生新的神经脉冲, 触发事件驱动.</p>
                </div>
                <div class="area_img" id="227">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_227.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 时间驱动和事件驱动的模拟方式[32]" src="Detail/GetImg?filename=images/JFYZ201906002_227.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 时间驱动和事件驱动的模拟方式<citation id="507" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_227.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Time-driven and event-driven simulation mode<citation id="508" type="reference"><link href="399" rel="bibliography" /><sup>[32]</sup></citation><sup></sup></p>

                </div>
                <div class="p1">
                    <p id="228">综上, 通过sPyNNaker软件系统, 用户可以远程使用SpiNNaker虚拟机, 开发和操作接口与目前主流的脉冲神经网络仿真平台类似.</p>
                </div>
                <h3 id="229" name="229" class="anchor-tag"><b>4 类脑机的信息处理潜力</b></h3>
                <div class="p1">
                    <p id="230">类脑机和大脑都是脉冲神经网络.本节先介绍采用脉冲神经网络构造任意图灵机的一种方法, 它证明了脉冲神经网络的信息处理能力不低于图灵机;然后介绍脉冲神经网络如何超越人工神经网络;最后介绍噪声可以提高脉冲神经网络的性能, 使得脉冲神经网络具有实现马尔可夫链蒙特卡洛 (Markov chain Monte Carlo, MCMC) 采样与求解约束满足NP-hard问题的能力.</p>
                </div>
                <h4 class="anchor-tag" id="231" name="231"><b>4.1 脉冲神经网络</b></h4>
                <div class="p1">
                    <p id="232">脉冲神经网络也被称为第三代人工神经网络<citation id="509" type="reference"><link href="401" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>, 与前两代人工神经网络McCulloch-Pitts-Neuron<citation id="510" type="reference"><link href="403" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>, Perceptron<citation id="511" type="reference"><link href="405" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>不同, 脉冲神经网络认为神经元脉冲发放以及脉冲之间的时间间隔也是一种重要的特性, 更贴近于人脑中的真实神经元<citation id="512" type="reference"><link href="407" rel="bibliography" /><link href="409" rel="bibliography" /><sup>[<a class="sup">36</a>,<a class="sup">37</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="233">一个典型的生物神经元的结构如图7所示, 主要包括树突、胞体和轴突3个部分.树突收集其他神经元传来的信息并通过电流的形式将其传给胞体, 胞体相当于一个中央处理器, 树突传来的电流引起胞体膜电位变化, 当膜电位超过一定阈值时, 神经元将发放一个脉冲信号 (称为动作电位) 并通过轴突传给其他神经元.动作电位是一个幅值大约100 mV、持续时间1～2 ms的电脉冲<citation id="513" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">39</a>]</sup></citation>.</p>
                </div>
                <div class="area_img" id="234">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201906002_234.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 脉冲神经元示意图与积分发放模型[38]" src="Detail/GetImg?filename=images/JFYZ201906002_234.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 脉冲神经元示意图与积分发放模型<citation id="514" type="reference"><link href="411" rel="bibliography" /><sup>[<a class="sup">38</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201906002_234.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 A spiking neuron and integrate-and-fire model<citation id="515" type="reference"><link href="411" rel="bibliography" /><sup>[38]</sup></citation><sup></sup></p>

                </div>
                <div class="p1">
                    <p id="235">计算神经科学家根据生物神经元的特性建立了诸多脉冲神经元模型, 主要包括积分发放 (integrate-and-fire) 模型<citation id="516" type="reference"><link href="415" rel="bibliography" /><link href="417" rel="bibliography" /><sup>[<a class="sup">40</a>,<a class="sup">41</a>]</sup></citation>、Hodgkin-Huxley模型<citation id="517" type="reference"><link href="341" rel="bibliography" /><link href="419" rel="bibliography" /><link href="421" rel="bibliography" /><link href="423" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">42</a>,<a class="sup">43</a>,<a class="sup">44</a>]</sup></citation>、Izhikevich模型<citation id="518" type="reference"><link href="425" rel="bibliography" /><link href="427" rel="bibliography" /><sup>[<a class="sup">45</a>,<a class="sup">46</a>]</sup></citation>和脉冲响应 (spike response) 模型<citation id="519" type="reference"><link href="429" rel="bibliography" /><link href="431" rel="bibliography" /><sup>[<a class="sup">47</a>,<a class="sup">48</a>]</sup></citation>.这些模型以不同的精度描述了生物神经元产生动作电位的动态过程.</p>
                </div>
                <div class="p1">
                    <p id="236">常用的积分发放模型最简单如图7所示, 它将神经元的膜表示为一个电容器<i>C</i>, 当神经元接受输入电流时, 神经元的膜电位<i>u</i> (<i>t</i>) 可以表示为</p>
                </div>
                <div class="p1">
                    <p id="237"><mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><mfrac><mrow><mtext>d</mtext><mi>u</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mtext>d</mtext><mi>t</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>R</mi><mi>Ι</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></math></mathml>,      (1) </p>
                </div>
                <div class="p1">
                    <p id="239">其中, <i>R</i>, <i>I</i> (<i>t</i>) , <i>u</i><sub>res<i>t</i></sub>分别表示神经元的电阻、输入电流和静息电位.当时刻<i>t</i>神经元的膜电位<i>u</i> (<i>t</i>) 超过一个阈值<i>θ</i>时, 神经元将发放一个脉冲且膜电位复位到<i>u</i><sub><i>r</i></sub>&lt;<i>θ</i>, 即:</p>
                </div>
                <div class="p1">
                    <p id="240"><mathml id="241"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>lim</mi></mrow></mstyle><mrow><mi>δ</mi><mo>→</mo><mn>0</mn><msup><mrow></mrow><mo>+</mo></msup></mrow></munder><mi>u</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mi>δ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>u</mi><msub><mrow></mrow><mi>r</mi></msub></mrow></math></mathml>.      (2) </p>
                </div>
                <div class="p1">
                    <p id="242">前神经元的轴突与后神经元的树突相互接触之处叫做突触, 它影响着神经元之间的交换信息<citation id="520" type="reference"><link href="347" rel="bibliography" /><link href="349" rel="bibliography" /><link href="351" rel="bibliography" /><link href="353" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.当突触前神经元发放一个脉冲时, 将通过突触在后突触神经元的树突上产生一个电势变化, 也叫做突触后电位 (postsynaptic potential, PSP) .突触后电位的取值可正可负, 其中正的电位叫做兴奋性突触后电位 (excitatory postsynaptic potential, EPSP) , 负的电位称为抑制性突触后电位 (inhibitory post-synaptic potential, IPSP) .</p>
                </div>
                <div class="p1">
                    <p id="243">单个神经元的计算能力有限, 当一群神经聚集在一起构成脉冲神经网络时可以实现复杂的计算.一个脉冲神经网络可以被定义为一个图<i>G</i>= (<i>V</i>, <i>E</i>) , 其中节点<i>V</i>表示神经元的集合, 边<i>E</i>⊂<i>V</i>×<i>V</i>表示突触的集合.不同脉冲神经网络可以用不同的图结构表示.</p>
                </div>
                <h4 class="anchor-tag" id="244" name="244"><b>4.2 脉冲神经网络的能力不低于图灵机</b></h4>
                <div class="p1">
                    <p id="245">本节证明利用脉冲神经网络发放脉冲之间的相位差就可以实现图灵机.</p>
                </div>
                <div class="p1">
                    <p id="246">图灵机的基本思想就是用机器来模拟人们用纸笔进行数学计算的过程<citation id="521" type="reference"><link href="433" rel="bibliography" /><sup>[<a class="sup">49</a>]</sup></citation>, 它包括一条无限长的纸带 (多条纸带为推广情况) 、一个读写头、一个状态寄存器和一套控制程序指令.其中, 纸带上包含一个个连续的存储格子, 每个格子存储一个数字或者符号;读写头可以在纸带上移动, 并可以读取纸带上的内容或者写入新的内容;状态寄存器用于存储机器当前所处的状态且机器状态数量有限;控制程序指令可以根据机器当前所处状态以及当前读写头所指格子上的数字或符号来确定读写头的移动方向 (左移一格或者右移一格) .理论证明, 图灵机可以模拟人类所能进行的任何计算过程<citation id="522" type="reference"><link href="435" rel="bibliography" /><link href="437" rel="bibliography" /><sup>[<a class="sup">50</a>,<a class="sup">51</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="247">Maass<citation id="523" type="reference"><link href="439" rel="bibliography" /><sup>[<a class="sup">52</a>]</sup></citation>证明了对于任意给定的<i>d</i>∈<i>N</i>, 都存在一个有限规模的脉冲神经网络<i>N</i><sub>TM</sub> (<i>d</i>) , 它可以实时模拟任意的包含<i>d</i>条无限长纸带的图灵机.主要证明包括3个步骤:</p>
                </div>
                <div class="p1">
                    <p id="248">1) 构建几种局部脉冲神经网络, 分别实现延时器、信号抑制器、振荡器、起搏器、同步器、脉冲相位大小比较器、布尔阈值电路以及相位乘法运算 (相位乘以一个固定常数) .</p>
                </div>
                <div class="p1">
                    <p id="249">2) 证明有限规模的脉冲神经网络可以实现堆栈的功能, 从而可以缓存数据.具体来说, 堆栈中一串二值序列〈<i>b</i><sub>1</sub>, <i>b</i><sub>2</sub>, …, <i>b</i><sub><i>l</i></sub>〉∈{0, 1}<sup>*</sup>可以表示为振荡器<i>O</i><sub><i>S</i></sub>的相位差:</p>
                </div>
                <div class="p1">
                    <p id="250" class="code-formula">
                        <mathml id="250"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>φ</mi><msub><mrow></mrow><mi>S</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mi>b</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>×</mo><mn>2</mn><msup><mrow></mrow><mrow><mo>-</mo><mi>i</mi><mo>-</mo><mi>c</mi></mrow></msup><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="251">其中, <i>φ</i><sub><i>S</i></sub>表示振荡器<i>O</i><sub><i>S</i></sub>与具有相同周期的一个起搏器的相位差;参数<i>c</i>用于控制相位差的大小, 保证相位差小于振荡器的震荡周期, 在此基础上证明入栈 (push) 和出栈 (pop) 指令可以由式 (1) 中定义的基本网络实现.</p>
                </div>
                <div class="p1">
                    <p id="252">3) 根据文献<citation id="524" type="reference">[<a class="sup">53</a>]</citation>, 任意的包含<i>d</i>条无限长的纸带的图灵机可以类似地包含2<i>d</i>个堆栈的类似的图灵机实现, 其中每条纸带读写头所指处的左右2个部分分别用一个堆栈来表示, 因此图灵机的计算可以转化为入栈和出栈的操作;再结合文献<citation id="525" type="reference">[<a class="sup">54</a>]</citation>, 可以进一步证明任意图灵机的计算过程可以通过有限个布尔阈值电路来模拟, 而脉冲神经网络又可以实现布尔阈值电路, 因此脉冲神经网络可以模拟图灵机的计算过程.</p>
                </div>
                <div class="p1">
                    <p id="253">Maass<citation id="526" type="reference"><link href="439" rel="bibliography" /><sup>[<a class="sup">52</a>]</sup></citation>指出脉冲神经网络的能力优于图灵机, 主要原因有2点:1) 相比于图灵机, 脉冲神经网络的输入输出可以为任意的实数;2) 图灵机的基本操作只能作用于有限的位数, 而脉冲神经网络的序列存储于相位<i>φ</i><sub><i>S</i></sub>中, 因此基本操作可以直接改变整个序列.</p>
                </div>
                <h4 class="anchor-tag" id="254" name="254"><b>4.3 噪声可以提高脉冲神经网络的性能</b></h4>
                <div class="p1">
                    <p id="255">4.1节中介绍的积分发放等脉冲神经元模型都是确定性模型, 事实上单个神经元的离子通道门控<citation id="527" type="reference"><link href="445" rel="bibliography" /><sup>[<a class="sup">55</a>]</sup></citation>、神经递质的突触释放<citation id="528" type="reference"><link href="447" rel="bibliography" /><sup>[<a class="sup">56</a>]</sup></citation>、皮层细胞反应变异性<citation id="529" type="reference"><link href="449" rel="bibliography" /><sup>[<a class="sup">57</a>]</sup></citation>和人脑的认知活动<citation id="530" type="reference"><link href="451" rel="bibliography" /><sup>[<a class="sup">58</a>]</sup></citation>都具有随机性.Maass<citation id="531" type="reference"><link href="453" rel="bibliography" /><sup>[<a class="sup">59</a>]</sup></citation>指出噪声可以作为脉冲神经网络计算和学习的资源, 可以提高脉冲神经网络的计算性能, 下面分别介绍相关工作.</p>
                </div>
                <div class="p1">
                    <p id="256">Gerstner等人<citation id="532" type="reference"><link href="431" rel="bibliography" /><sup>[<a class="sup">48</a>]</sup></citation>认为噪声存在于神经元发放的阈值上, 这样神经元的膜电位取任何值时神经元都可以发放, 膜电位越大时发放概率越高, 这样的模型也叫做随机脉冲响应模型.在此基础上Buesing等人<citation id="533" type="reference"><link href="455" rel="bibliography" /><sup>[<a class="sup">60</a>]</sup></citation>将神经元的发放过程理解为一个采样过程, 他们证明了一个包含<i>K</i>个相互连接神经元<i>z</i><sub>1</sub>, <i>z</i><sub>2</sub>, …, <i>z</i><sub><i>K</i></sub>的脉冲神经网络可以表示一个概率分布<i>p</i> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>K</i></sub>) , 进一步若神经元的发放概率与随机变量<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>K</i></sub>的后验概率满足条件 (神经适应条件) :</p>
                </div>
                <div class="p1">
                    <p id="257"><mathml id="258"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>τ</mi></mfrac><mfrac><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mrow><mo>\</mo><mi>i</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>0</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mrow><mo>\</mo><mi>i</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>,      (4) </p>
                </div>
                <div class="p1">
                    <p id="259">则神经元的发放活动等价于MCMC采样.其中, <i>p</i> (<i>z</i><sub><i>i</i></sub> (<i>t</i>) =1) 表示神经元<i>z</i><sub><i>i</i></sub>在时刻<i>t</i>发放一个脉冲的概率;<i>x</i><sub>＼<i>i</i></sub>表示除了<i>x</i><sub><i>i</i></sub>之外的其他随机变量;<i>τ</i>表示神经元发放之后的抑制期的时长.基于此结论, Buesing等人<citation id="534" type="reference"><link href="455" rel="bibliography" /><sup>[<a class="sup">60</a>]</sup></citation>证明了脉冲神经网络可以实现边缘概率推理, 他们证明了如果概率分布服从玻尔兹曼分布, 则神经适应条件可以由脉冲神经网络中神经元的连接自然实现.当网络的动态性收敛时, 脉冲神经元可以看作是在对平稳分布 (目标分布) 进行采样, 统计一段时间内神经元发放时间占总时间的比例即为边缘概率.Pecevski等人<citation id="535" type="reference"><link href="457" rel="bibliography" /><sup>[<a class="sup">61</a>]</sup></citation>指出文献<citation id="536" type="reference">[<a class="sup">60</a>]</citation>的研究只适用于二值随机变量, 提出了3种方法将以上结果推广到一般图模型:1) 证明通过增加辅助变量可以将任意分布转化为玻尔兹曼分布;2) 利用马尔可夫毯来扩展神经适应条件;3) 利用因式分解来扩展神经适应条件.Probst等人<citation id="537" type="reference"><link href="459" rel="bibliography" /><sup>[<a class="sup">62</a>]</sup></citation>将这3种方法推广到积分发放神经元模型, 证明了基于电导的积分发放神经元可以实现MCMC采样与边缘推理.Habenschuss等人<citation id="538" type="reference"><link href="461" rel="bibliography" /><sup>[<a class="sup">63</a>]</sup></citation>研究了脉冲神经网络采样推理的收敛速度, 并证明脉冲神经网络所表示的概率分布将以指数速度收敛到平稳分布.</p>
                </div>
                <div class="p1">
                    <p id="260">噪声还可以存在于神经元的突触上, Kappel等人<citation id="541" type="reference"><link href="463" rel="bibliography" /><link href="465" rel="bibliography" /><sup>[<a class="sup">64</a>,<a class="sup">65</a>]</sup></citation>发现如果在突触上叠加符合维纳过程的随机噪声, 突触参数的动态性可以实现Langvein采样.据此他们提出了突触采样学习框架, 并证明了整个网络参数所表示的分布将收敛于一个平稳分布, 该框架不仅可以实现脉冲神经网络的学习, 而且解释了脉冲神经网络持续重新布线的原因.Yu等人<citation id="539" type="reference"><link href="467" rel="bibliography" /><sup>[<a class="sup">66</a>]</sup></citation>提出哈密顿突触采样学习框架, 揭示了实现突触可塑性的重要分子CaMKII加速脉冲神经网络学习的计算机理.Kappel等人<citation id="540" type="reference"><link href="469" rel="bibliography" /><sup>[<a class="sup">67</a>]</sup></citation>进一步将突触采样框架应用到奖励学习问题中, 解释了多巴胺、STDP和噪声时人脑强化学习的基础.</p>
                </div>
                <div class="p1">
                    <p id="261">此外Jonke等人<citation id="542" type="reference"><link href="471" rel="bibliography" /><sup>[<a class="sup">68</a>]</sup></citation>证明了包含噪声的脉冲神经网络具有求解NP-hard约束满足问题的能力.其主要思想是基于机, 一方面Hopfield等人<citation id="543" type="reference"><link href="473" rel="bibliography" /><sup>[<a class="sup">69</a>]</sup></citation>和Aarts等人<citation id="544" type="reference"><link href="475" rel="bibliography" /><sup>[<a class="sup">70</a>]</sup></citation>已证明玻尔兹曼机可以求解NP-hard约束满足问题;另一方面包含噪声的脉冲神经网络可以模拟任意的玻尔兹曼机, 因此可以用脉冲神经网络求解NP-hard约束满足问题.Jonke等人<citation id="545" type="reference"><link href="471" rel="bibliography" /><sup>[<a class="sup">68</a>]</sup></citation>还发现了相比于人工神经网络, 脉冲神经网络在求解约束满足问题时具有更快的求解速度.</p>
                </div>
                <h3 id="262" name="262" class="anchor-tag"><b>5 总结与展望</b></h3>
                <div class="p1">
                    <p id="263">经典计算机的理论基础是图灵1936年奠定的, 图灵机的理论边界那个时刻就已经明确.冯·诺依曼体系结构是图灵机的一种物理实现模型, 采用这种体系结构的经典计算机能力的理论边界当然受限于图灵机模型.</p>
                </div>
                <div class="p1">
                    <p id="264">神经网络是人工智能三大流派之一, 从智能实现载体层次“自底向上”地开展研究, 现在看来是构筑机器智能物理基础的最主要的可行路线.大规模神经网络的复杂结构和异步通信机制迥异于冯·诺依曼体系结构, 在经典计算机上进行神经信息处理的功耗也越来越难以承受, 发展面向神经网络的体系结构, 对人工智能还是一般意义上的信息处理都是必由之路.</p>
                </div>
                <div class="p1">
                    <p id="265">目前广泛应用的人工神经网络与生物神经网络相比, 还过于简化.模拟动物大脑和人脑的精细解析有望在20年内逐步完成, 这将成为未来神经网络体系结构的基本蓝图, 基于这一蓝图研制的类脑机, 将成为实现更强人工智能乃至通用人工智能的物理平台.</p>
                </div>
                <div class="p1">
                    <p id="266">类脑机的思想在计算机发明之前就提出了, 研究开发实践也已经进行了30多年, 多台类脑系统已经上线运行, 其中SpiNNaker专注于类脑系统的体系结构研究, 提出了一种行之有效的类脑方案.</p>
                </div>
                <div class="p1">
                    <p id="267">以SpiNNaker为代表的类脑机采用传统计算硬件和软件实现脉冲神经网络, 因此没超出经典图灵机的范畴.随着神经形态器件的发展, 未来20年, 有望研制出逼近乃至超越生物脑的类脑机, 硬件神经元和神经突触将具有真正的随机性, 硬件的神经环路也将像生物神经网络一样具备丰富的非线性动力学行为, 是否能够突破可计算性的理论边界、超越图灵机?这是一个尚待解决的重大理论问题, 类脑机的研究开发和实现应该有助于这个问题的解决.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="549" type="formula" href="images/JFYZ201906002_54900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">黄铁军</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="550" type="formula" href="images/JFYZ201906002_55000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">余肇飞</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="551" type="formula" href="images/JFYZ201906002_55100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘怡俊</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="337">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201611001&amp;v=MDA4MTR6cXFCdEdGckNVUkxPZVplUnFGaURtVXIzT1B5cmZiTEc0SDlmTnJvOUZaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Huang Tiejun, Shi Luping, Tang Huajin, et al.Research on multimedia technology 2015—Advances and trend of brain-like computing[J].Journal of Image and Graphics, 2016, 21 (11) :1411- 1424 (in Chinese) (黄铁军, 施路平, 唐华锦, 等.多媒体技术研究:2015——类脑计算的研究进展与发展趋势[J].中国图象图形学报, 2016, 21 (11) :1411- 1424) 
                            </a>
                        </p>
                        <p id="339">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD1B27613353A15C3C4AD5535A4B69FA5F&amp;v=MDM4MTM3dmlOTC9wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx1K3dxND1OajdCYXJMS0hOYktyb3hHWWVoK0RYbEt6R1VYbTB0NFRYem4zUlpIZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Huang Tiejun.Imitating the brain with neurocomputer—A “new” way towards artificial general intelligence[J].International Journal of Automation and Computing, 2017, 14 (5) :520- 531
                            </a>
                        </p>
                        <p id="341">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A quantitative description of membrane current and its application to conduction and excitation in nerve">

                                <b>[3]</b>Hodgkin A L, Huxley A.A quantitative description of membrane current and its application to conduction and excitation in nerve[J].The Journal of Physiology, 1952, 117 (4) :500- 544
                            </a>
                        </p>
                        <p id="343">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Organization of Behavior">

                                <b>[4]</b>Hebb D O.The Organization of Behaviour:A Neuropsy-chological Theory[M].New York:Science Editions, 1949
                            </a>
                        </p>
                        <p id="345">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011588&amp;v=MjI3MzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRjBWYUJRPU5pZkpaYks5SHRqTXFvOUZaT29PQ1hReA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Tsodyks M, Pawelzik K, Markram H.Neural networks with dynamic synapses[J].Neural Computation, 1998, 10 (4) :821- 835
                            </a>
                        </p>
                        <p id="347">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type">

                                <b>[6]</b>Bi Guoqiang, Poo Muming.Synaptic modifications in cultured hippocampal neurons:Dependence on spike timing, synaptic strength, and postsynaptic cell type[J].Journal of Neuroscience, 1998, 18 (24) :10464- 10472
                            </a>
                        </p>
                        <p id="349">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed synaptic modification in neural networks induced by patterned stimulation">

                                <b>[7]</b>Bi Guoqiang, Poo Muming.Distributed synaptic modification in neural networks induced by patterned stimulation[J].Nature, 1999, 401 (6755) :792- 796
                            </a>
                        </p>
                        <p id="351">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Competitive Hebbian learning through spike-timing-dependent synaptic plasticity">

                                <b>[8]</b>Song Sen, Miller K D, Abbott L F.Competitive Hebbian learning through spike-timing-dependent synaptic plasticity[J].Nature Neuroscience, 2000, 3 (9) :919- 926
                            </a>
                        </p>
                        <p id="353">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300028648&amp;v=MjQzMzBqbVVMdkpLRjBWYUJRPU5pZk9mYks3SHRET3JJOUZaT2tIQ25neG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Song Sen, Abbott L F.Cortical development and remapping through spike timing-dependent plasticity[J].Neuron, 2001, 32 (2) :339- 350
                            </a>
                        </p>
                        <p id="355">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Grand challenges for global brain sciences">

                                <b>[10]</b>Vogelstein J T, Amunts K, Andreou A, et al.Grand challenges for global brain sciences[J].arXiv preprint arXiv:1608.06548, 2016
                            </a>
                        </p>
                        <p id="357">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution">

                                <b>[11]</b>Gao Ruixuan, Asano S M, Upadhyayula S, et al.Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution[J].Science, 2019, 363 (6424) :eaau8302
                            </a>
                        </p>
                        <p id="359">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Enigma">

                                <b>[12]</b>Hodges A, Turing A.The Enigma[M].London:Vintage, 1992
                            </a>
                        </p>
                        <p id="361">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computing Machinery and Intelligence">

                                <b>[13]</b>Turing A.Computing machinery and intelligence—AM Turing[J].Mind, 1950, 59 (236) :433- 460
                            </a>
                        </p>
                        <p id="363">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Computer and the Brain">

                                <b>[14]</b>Neumann J V.The computer and the brain[J].Annals of the History of Computing, 1958, 11 (3) :161- 163
                            </a>
                        </p>
                        <p id="365">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Synthetic neural modeling: The &amp;#39;Darwin&amp;#39; series of recognition automata">

                                <b>[15]</b>Reeke G N, Sporns O, Edelman G M.Synthetic neural modeling:The ‘Darwin' series of recognition automata[J].Proceedings of the IEEE, 1990, 78 (9) :1498- 1530
                            </a>
                        </p>
                        <p id="367">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning in and from brain-based devices">

                                <b>[16]</b>Edelman G M.Learning in and from brain-based devices[J].Science, 2007, 318 (5853) :1103- 1105
                            </a>
                        </p>
                        <p id="369">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large-scale model of mammalian thalamocortical systems">

                                <b>[17]</b>Izhikevich E M, Edelman G M.Large-scale model of mammalian thalamocortical systems[J].Proceedings of the National Academy of Sciences, 2008, 105 (9) :3593- 3598
                            </a>
                        </p>
                        <p id="371">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analog VLSI and Neural Systems">

                                <b>[18]</b>Mead C.Analog VLSI and Neural Systems[M].Reading, MA:Addison-Wesley, 1989
                            </a>
                        </p>
                        <p id="373">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neuromorphic electronic systems">

                                <b>[19]</b>Mead C.Neuromorphic electronic systems[J].Proceedings of the IEEE, 1990, 78 (10) :1629- 1636
                            </a>
                        </p>
                        <p id="375">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analog VLSI Implementation of Neural Systems">

                                <b>[20]</b>Mead C, Ismail M.Analog VLSI Implementation of Neural Systems[M].Berlin:Springer, 1989
                            </a>
                        </p>
                        <p id="377">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neurogrid:A Mixed-Analog-Digital Multichip System for Large-Scale Neural Simulations">

                                <b>[21]</b>Benjamin B V, Gao P, McQuinn E, et al.Neurogrid:A mixed-analog-digital multichip system for large-scale neural simulations[J].Proceedings of the IEEE, 2014, 102 (5) :699- 716
                            </a>
                        </p>
                        <p id="379">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The blue brain project">

                                <b>[22]</b>Markram H.The blue brain project[J].Nature Reviews Neuroscience, 2006, 7 (2) :153- 160
                            </a>
                        </p>
                        <p id="381">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000077&amp;v=MjQyNzlJWTdLN0h0ak5yNDlGWk9zUERIcytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdkpLRjBWYUJRPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Modha D S, Ananthanarayanan R, Esser S K, et al.Cognitive computing[J].Communications of the ACM, 2011, 54 (8) :62- 71
                            </a>
                        </p>
                        <p id="383">
                            <a id="bibliography_24" >
                                    <b>[24]</b>
                                Amunts K.Human brain project of European Union[EB/OL].[2016-07-25].http://www.humanbrainproject.eu/ (Amunts K.欧盟人类大脑计划[EB/OL].[2016-07-25].http://www.humanbrainproject.eu/) 
                            </a>
                        </p>
                        <p id="385">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A million spiking-neuron integrated circuit with a scalable communication network and interface">

                                <b>[25]</b>Merolla P A, Arthur J V, Alvarez-Icaza R, et al.A million spiking-neuron integrated circuit with a scalable communication network and interface[J].Science, 2014, 345 (6197) :668- 673
                            </a>
                        </p>
                        <p id="387">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The SpiNNaker project">

                                <b>[26]</b>Furber S B, Galluppi F, Temple S, et al.The SpiNNaker project[J].Proceedings of the IEEE, 2014, 102 (5) :652- 665
                            </a>
                        </p>
                        <p id="389">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spi NNaker-programming model">

                                <b>[27]</b>Brown A D, Furber S B, Reeve J S, et al.SpiNNaker—programming model[J].IEEE Transactions on Computers, 2015, 64 (6) :1769- 1782
                            </a>
                        </p>
                        <p id="391">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A wafer-scale neuromorphic hardware system for large-scale neural modeling">

                                <b>[28]</b>Schemmel J, Briiderle D, Griibl A, et al.A wafer-scale neuromorphic hardware system for large-scale neural modeling[C] //Proc of 2010 IEEE Int Symp on Circuits and Systems.Piscataway, NJ:IEEE, 2010:1947- 1950
                            </a>
                        </p>
                        <p id="393">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300402415&amp;v=MTE0NDRDSDA4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZKS0YwVmFCUT1OaWZPZmJLN0h0RE9ySTlGWU9zTg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b>Scholze S, Eisenreich H, Höppner S, et al.A 32 GBit/s communication SoC for a waferscale neuromorphic system[J].INTEGRATION, the VLSI Journal, 2012, 45 (1) :61- 75
                            </a>
                        </p>
                        <p id="395">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A mixed-signal universal neuromorphic computing system">

                                <b>[30]</b>Meier K.A mixed-signal universal neuromorphic computing system[C] //Proc of 2015 IEEE Int Electron Devices Meeting (IEDM) .Piscataway, NJ:IEEE, 2015:4.6.1- 4.6.4
                            </a>
                        </p>
                        <p id="397">
                            <a id="bibliography_31" >
                                    <b>[31]</b>
                                Yan Aoshuang.Special edition of China brain project[N].People's Daily.2015-11-17 (in Chinese) (闫傲霜.北京脑计划专版[N].人民日报.2015-11-17) 
                            </a>
                        </p>
                        <p id="399">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Overview of the spinnaker system architecture">

                                <b>[32]</b>Furber S B, Lester D R, Plana L A, et al.Overview of the SpiNNaker system architecture[J].IEEE Transactions on Computers, 2012, 62 (12) :2454- 2467
                            </a>
                        </p>
                        <p id="401">
                            <a id="bibliography_33" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070896&amp;v=MDMzOTJLRjBWYUJRPU5pZk9mYks3SHRET3JJOUZaT3dQQkhVL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2Sg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[33]</b>Maass W.Networks of spiking neurons:The third generation of neural network models[J].Neural Networks, 1997, 10 (9) :1659- 1671
                            </a>
                        </p>
                        <p id="403">
                            <a id="bibliography_34" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001082082&amp;v=MTQxNzU5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ3prVzd6SklsZz1OajdCYXJPNEh0SE5yNGRIWk9NTlkzazV6QmRoNGo5&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[34]</b>McCulloch W S, Pitts W.A logical calculus of the ideas immanent in nervous activity[J].Bulletin of Mathematical Biophysics, 1943, 5 (4) :115- 133
                            </a>
                        </p>
                        <p id="405">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Principles of neurodynamics:Perceptrons and the theory of brain mechanisms">

                                <b>[35]</b>Rosenblatt F.Principles of neurodynamics:Perceptrons and the theory of brain mechanisms[R].Washington, DC:Spartan Books, 1961
                            </a>
                        </p>
                        <p id="407">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computational Explorations in Cognitive Neuroscience:Understanding the Mind by Simulating the Brain">

                                <b>[36]</b>O'Reilly R C, Munakata Y.Computational Explorations in Cognitive Neuroscience:Understanding the Mind by Simulating the Brain[M].Cambridge, MA:MIT Press, 2000
                            </a>
                        </p>
                        <p id="409">
                            <a id="bibliography_37" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Which model to use for cortical spiking neurons?">

                                <b>[37]</b>Izhikevich E M.Which model to use for cortical spiking neurons?[J].IEEE Transactions on Neural Networks, 2004, 15 (5) :1063- 1070
                            </a>
                        </p>
                        <p id="411">
                            <a id="bibliography_38" >
                                    <b>[38]</b>
                                Yu Zhaofei.Inference and learning in spiking neural networks[D].Beijing:Tsinghua University, 2017 (in Chinese) (余肇飞.脉冲神经网络的推理与学习问题研究[D].北京:清华大学, 2017) 
                            </a>
                        </p>
                        <p id="413">
                            <a id="bibliography_39" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Correlation Maps Allow Neuronal Electrical Properties to be Predicted from Single-cell Gene Expression Profiles in Rat Neocortex">

                                <b>[39]</b>Toledo-Rodriguez M, Blumenfeld B, Wu Caizhi, et al.Correlation maps allow neuronal electrical properties to be predicted from single-cell gene expression profiles in rat neocortex[J].Cerebral Cortex, 2004, 14 (12) :1310- 1327
                            </a>
                        </p>
                        <p id="415">
                            <a id="bibliography_40" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamics of encoding in a population of neurons">

                                <b>[40]</b>Knight B W.Dynamics of encoding in a population of neurons[J].The Journal of General Physiology, 1972, 59 (6) :734- 766
                            </a>
                        </p>
                        <p id="417">
                            <a id="bibliography_41" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100754953&amp;v=MDU5MzJZKzRMQlhrNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2SktGMFZhQlE9TmlmT2ZiSzdIdERPcm85Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[41]</b>Abbott L F.Lapicque's introduction of the integrate-and-fire model neuron (1907) [J].Brain Research Bulletin, 1999, 50 (5/6) :303- 304
                            </a>
                        </p>
                        <p id="419">
                            <a id="bibliography_42" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Measurement of current-voltage relations in the membrane of the giant axon of Loligo">

                                <b>[42]</b>Hodgkin A L, Huxley A F, Katz B.Measurement of current-voltage relations in the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :424- 448
                            </a>
                        </p>
                        <p id="421">
                            <a id="bibliography_43" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Currents carried by sodium and potassium ions through the membrane of the giant axon of loligo">

                                <b>[43]</b>Hodgkin A L, Huxley A F.Currents carried by sodium and potassium ions through the membrane of the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :449- 472
                            </a>
                        </p>
                        <p id="423">
                            <a id="bibliography_44" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The components of membrane conductance in the giant axon of Loligo">

                                <b>[44]</b>Hodgkin A L, Huxley A F.The components of membrane conductance in the giant axon of Loligo[J].The Journal of Physiology, 1952, 116 (4) :473- 496
                            </a>
                        </p>
                        <p id="425">
                            <a id="bibliography_45" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural excitability, spiking and bursting">

                                <b>[45]</b>Izhikevich E M.Neural excitability, spiking and bursting[J].International Journal of Bifurcation and Chaos, 2000, 10 (6) :1171- 1266
                            </a>
                        </p>
                        <p id="427">
                            <a id="bibliography_46" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simple model of spiking neurons">

                                <b>[46]</b>Izhikevich E M.Simple model of spiking neurons[J].IEEE Transactions on Neural Networks, 2003, 14 (6) :1569- 1572
                            </a>
                        </p>
                        <p id="429">
                            <a id="bibliography_47" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014159&amp;v=MjI3NzFKS0YwVmFCUT1OaWZKWmJLOUh0ak1xbzlGWk9vTERYa3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMdg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[47]</b>Kistler W M, Gerstner W, Hemmen J L.Reduction of the Hodgkin-Huxley equations to a single-variable threshold model[J].Neural Computation, 1997, 9 (5) :1015- 1045
                            </a>
                        </p>
                        <p id="431">
                            <a id="bibliography_48" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neuronal Dynamics:From Single Neurons to Networks and Models of Cognition">

                                <b>[48]</b>Gerstner W, Kistler W M, Naud R, et al.Neuronal Dynamics:From Single Neurons to Networks and Models of Cognition[M].Cambridge, UK:Cambridge University Press, 2014
                            </a>
                        </p>
                        <p id="433">
                            <a id="bibliography_49" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On computable numbers, with an application to the Entscheidungsproblem">

                                <b>[49]</b>Turing A M.On computable numbers, with an application to the Entscheidungsproblem[J].Proceedings of the London Mathematical Society, 1937, 2 (1) :230- 265
                            </a>
                        </p>
                        <p id="435">
                            <a id="bibliography_50" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Searching for Memory:The Brain the Mind and the Past">

                                <b>[50]</b>Schacter D L.Searching for Memory:The Brain, the Mind, and the Past[M].New York:Basic Books, 1996
                            </a>
                        </p>
                        <p id="437">
                            <a id="bibliography_51" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Introduction to the Theory of Computation">

                                <b>[51]</b>Sipser M.Introduction to the Theory of Computation[M].Boston:Thomson Course Technology, 2006
                            </a>
                        </p>
                        <p id="439">
                            <a id="bibliography_52" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090200014016&amp;v=MTU2MTl3WmVadUh5am1VTHZKS0YwVmFCUT1OaWZKWmJLOUh0ak1yWTlGWk9vTERIMC9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[52]</b>Maass W.Lower bounds for the computational power of networks of spiking neurons[J].Neural Computation, 1996, 8 (1) :1- 40
                            </a>
                        </p>
                        <p id="441">
                            <a id="bibliography_53" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Introduction to Automata Theory,Languages,and Computation">

                                <b>[53]</b>Hopcroft J E.Introduction to Automata Theory, Languages, and Computation[M].Chennai, India:Pearson Education India, 2008
                            </a>
                        </p>
                        <p id="443">
                            <a id="bibliography_54" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300071200&amp;v=MjgxMTlpclJkR2VycVFUTW53WmVadUh5am1VTHZKS0YwVmFCUT1OaWZPZmJLN0h0RE9ySTlGWk93T0RudzVvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[54]</b>Horne B G, Hush D R.Bounds on the complexity of recurrent neural network implementations of finite state machines[J].Neural Networks, 1996, 9 (2) :359- 366
                            </a>
                        </p>
                        <p id="445">
                            <a id="bibliography_55" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLA7A0AE2BE8972E6FE835AAF468DE815AB&amp;v=MzA5MTVIYjdUSkhxQzVyZjB3Yk9JSURnay91V01iNlRvTU9Rbm1xaHBCRExxVlFNdnRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6THUrd3E0PU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[55]</b>Cannon R C, O'Donnell C, Nolan M F.Stochastic ion channel gating in dendritic neurons:Morphology dependence and probabilistic synaptic activation of dendritic spikes[J].PLoS Computational Biology, 2010, 6 (8) :e1000886
                            </a>
                        </p>
                        <p id="447">
                            <a id="bibliography_56" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Synaptic transmission: On the probability of release">

                                <b>[56]</b>Flight M H.Synaptic transmission:On the probability of release[J].Nature Reviews Neuroscience, 2008, 9 (10) :736- 737
                            </a>
                        </p>
                        <p id="449">
                            <a id="bibliography_57" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cellular mechanisms contributing to response variability of cortical neurons in vivo">

                                <b>[57]</b>Azouz R, Gray C M.Cellular mechanisms contributing to response variability of cortical neurons in vivo[J].Journal of Neuroscience, 1999, 19 (6) :2209- 2223
                            </a>
                        </p>
                        <p id="451">
                            <a id="bibliography_58" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The time course of binocular rivalry reveals a fundamental role of noise">

                                <b>[58]</b>Brascamp J W, Van Ee R, Noest A J, et al.The time course of binocular rivalry reveals a fundamental role of noise[J].Journal of Vision, 2006, 6 (11) :1244- 1256
                            </a>
                        </p>
                        <p id="453">
                            <a id="bibliography_59" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Noise as a Resource for Computation and Learning in Networks of Spiking Neurons,&amp;quot;">

                                <b>[59]</b>Maass W.Noise as a resource for computation and learning in networks of spiking neurons[J].Proceedings of the IEEE, 2014, 102 (5) :860- 880
                            </a>
                        </p>
                        <p id="455">
                            <a id="bibliography_60" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLA7FCEA3A0D1D3DE6FCC0191E722573919&amp;v=MDg4MjJ4Z3pMdSt3cTQ9TmlmSGI3VE9iYVM5clA1RkVPcDdEd2hNeVdCZ21UOThRWDZYcXhBM2ZMV1hUTHVXQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[60]</b>Buesing L, Bill J, Nessler B, et al.Neural dynamics as sampling:A model for stochastic computation in recurrent networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (11) :e1002211
                            </a>
                        </p>
                        <p id="457">
                            <a id="bibliography_61" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAEDC51431B76A42DE9124301AA7662473&amp;v=MDc2NjB1Mk1hNnoxNVMzL2ozV015ZjdTV1FiMmNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGd6THUrd3E0PU5pZkhiOGJNYmRUTnE0eEVGdXdKZlhnNw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[61]</b>Pecevski D, Buesing L, Maass W.Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons[J].PLoS Computational Biology, 2011, 7 (12) :e1002294
                            </a>
                        </p>
                        <p id="459">
                            <a id="bibliography_62" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probabilistic inference in discrete spaces can be implemented into networks of LIF neurons">

                                <b>[62]</b>Probst D, Petrovici M A, Bytschok I, et al.Probabilistic inference in discrete spaces can be implemented into networks of LIF neurons[J].Frontiers in Computational Neuroscience, 2015, 9:1- 11
                            </a>
                        </p>
                        <p id="461">
                            <a id="bibliography_63" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAE6E4359D3F95971D35B1F537D771481D&amp;v=MzEyNDFTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx1K3dxND1OaWZIYjhhK2E5WFBxb1l4WjUwR0NYVSt6bUlRNzAxOFBucmhxMll5ZnJPUVRidnJDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[63]</b>Habenschuss S, Jonke Z, Maass W.Stochastic computations in cortical microcircuit models[J].PLoS Computational Biology, 2013, 9 (11) :e1003311
                            </a>
                        </p>
                        <p id="463">
                            <a id="bibliography_64" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Synaptic sampling:A bayesian approach to neural network plasticity and rewiring">

                                <b>[64]</b>Kappel D, Habenschuss S, Legenstein R, et al.Synaptic sampling:A Bayesian approach to neural network plasticity and rewiring[C] //Proc of Advances in Neural Information Processing Systems.Cambridge, MA:MIT Press, 2015:370- 378
                            </a>
                        </p>
                        <p id="465">
                            <a id="bibliography_65" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJLA&amp;filename=SJLAC49EBCD3788D1B0993AFB6063D58CF54&amp;v=MDQ1MTZGNlMrM1B0R1krTUhlSDFMeng4YTZVNExPbm5pcWhGQmZMcm5NNytiQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1Tnhnekx1K3dxND1OaWZIYjhDOA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[65]</b>Kappel D, Habenschuss S, Legenstein R, et al.Network plasticity as Bayesian inference[J].PLoS Computational Biology, 2015, 11 (11) :e1004485
                            </a>
                        </p>
                        <p id="467">
                            <a id="bibliography_66" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CaMKII activation supports reward-based neural network optimization through Hamiltonian sampling">

                                <b>[66]</b>Yu Zhaofei, Kappel D, Legenstein R, et al.CaMKII activation supports reward-based neural network optimization through Hamiltonian sampling[J].arXiv preprint arXiv:1606.00157, 2016
                            </a>
                        </p>
                        <p id="469">
                            <a id="bibliography_67" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning">

                                <b>[67]</b>Kappel D, Legenstein R, Habenschuss S, et al.A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning[J].eNeuro, 2018, 5 (2) :ENEURO.0301-17.2018
                            </a>
                        </p>
                        <p id="471">
                            <a id="bibliography_68" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Solving constraint satisfaction problems with networks of spiking neurons">

                                <b>[68]</b>Jonke Z, Habenschuss S, Maass W.Solving constraint satisfaction problems with networks of spiking neurons[J].Frontiers in Neuroscience, 2016, 10:1- 16
                            </a>
                        </p>
                        <p id="473">
                            <a id="bibliography_69" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computing with neural circuits: a model">

                                <b>[69]</b>Hopfield J J, Tank D W.Computing with neural circuits:A model[J].Science, 1986, 233 (4764) :625- 633
                            </a>
                        </p>
                        <p id="475">
                            <a id="bibliography_70" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simulated annealing and Boltzmann machines">

                                <b>[70]</b>Aarts E, Korst J.Simulated Annealing and Boltzmann Machines[M].New York:John Wiley, 1989
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201906002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201906002&amp;v=MTAwOTJxWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRmlEbVVyM09MeXZTZExHNEg5ak0=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4vMkp4bGZlYm4vSTducm9BaWpOUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

