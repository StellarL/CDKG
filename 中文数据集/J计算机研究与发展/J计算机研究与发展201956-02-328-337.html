<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133243512783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201902009%26RESULT%3d1%26SIGN%3dXbG5L8SjYzhmlg4UYigMffjXri8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201902009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201902009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902009&amp;v=MTI2MTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTduVzcvSkx5dlNkTEc0SDlqTXJZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#221" data-title="&lt;b&gt;1&lt;/b&gt;&lt;b&gt;相关工作&lt;/b&gt; "><b>1</b><b>相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#223" data-title="&lt;b&gt;1.1&lt;/b&gt;&lt;b&gt;移动群智感知&lt;/b&gt;"><b>1.1</b><b>移动群智感知</b></a></li>
                                                <li><a href="#225" data-title="&lt;b&gt;1.2&lt;/b&gt;&lt;b&gt;移动轨迹预测&lt;/b&gt;"><b>1.2</b><b>移动轨迹预测</b></a></li>
                                                <li><a href="#227" data-title="&lt;b&gt;1.3&lt;/b&gt;&lt;b&gt;群智感知任务分配&lt;/b&gt;"><b>1.3</b><b>群智感知任务分配</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#230" data-title="&lt;b&gt;2&lt;/b&gt;&lt;b&gt;CrowdTracker系统框架&lt;/b&gt; "><b>2</b><b>CrowdTracker系统框架</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#235" data-title="&lt;b&gt;3&lt;/b&gt;&lt;b&gt;群智跟踪方法实现&lt;/b&gt; "><b>3</b><b>群智跟踪方法实现</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#237" data-title="&lt;b&gt;3.1&lt;/b&gt;&lt;b&gt;预测目标车辆移动模型&lt;/b&gt;"><b>3.1</b><b>预测目标车辆移动模型</b></a></li>
                                                <li><a href="#258" data-title="&lt;b&gt;3.2&lt;/b&gt;&lt;b&gt;群智跟踪任务分配方法&lt;/b&gt;"><b>3.2</b><b>群智跟踪任务分配方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#295" data-title="&lt;b&gt;4&lt;/b&gt;&lt;b&gt;实验评估&lt;/b&gt; "><b>4</b><b>实验评估</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#297" data-title="&lt;b&gt;4.1&lt;/b&gt;&lt;b&gt;MPRE方法评估&lt;/b&gt;"><b>4.1</b><b>MPRE方法评估</b></a></li>
                                                <li><a href="#304" data-title="&lt;b&gt;4.2&lt;/b&gt;&lt;b&gt;任务分配的方法评估&lt;/b&gt;"><b>4.2</b><b>任务分配的方法评估</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#315" data-title="&lt;b&gt;5&lt;/b&gt;&lt;b&gt;总结与展望&lt;/b&gt; "><b>5</b><b>总结与展望</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#219" data-title="图1 CrowdTracker示例">图1 CrowdTracker示例</a></li>
                                                <li><a href="#232" data-title="图2 CrowdTracker系统框架">图2 CrowdTracker系统框架</a></li>
                                                <li><a href="#245" data-title="图3 移动Markov链模型">图3 移动Markov链模型</a></li>
                                                <li><a href="#247" data-title="图4 城市区域网格化">图4 城市区域网格化</a></li>
                                                <li><a href="#301" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;b&gt;成都市出租车轨迹实验数据集&lt;/b&gt;"><b>表1</b><b>成都市出租车轨迹实验数据集</b></a></li>
                                                <li><a href="#302" data-title="图5 MPRE结果">图5 MPRE结果</a></li>
                                                <li><a href="#309" data-title="图6 候选参与者人数与平均任务覆盖率的关系">图6 候选参与者人数与平均任务覆盖率的关系</a></li>
                                                <li><a href="#311" data-title="图7 算法对参与者平均移动距离的影响">图7 算法对参与者平均移动距离的影响</a></li>
                                                <li><a href="#312" data-title="图8 算法运行时间对比">图8 算法运行时间对比</a></li>
                                                <li><a href="#314" data-title="图9 算法参与者平均移动距离与计算时间的乘积对比">图9 算法参与者平均移动距离与计算时间的乘积对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="350">


                                    <a id="bibliography_1" title="Liu Liang, Zhang Xi, Ma Huadong.Dynamic node collaboration for mobile target tracking in wireless camera sensor networks[C]Proc of the 28th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2009:1188-1196" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic node collaboration for mobile target tracking in wireless camera sensor networks">
                                        <b>[1]</b>
                                        Liu Liang, Zhang Xi, Ma Huadong.Dynamic node collaboration for mobile target tracking in wireless camera sensor networks[C]Proc of the 28th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2009:1188-1196
                                    </a>
                                </li>
                                <li id="352">


                                    <a id="bibliography_2" title="Li Yiming, Bhanu B.Utility-based dynamic camera assignment and hand-off in a video network[C]Proc of the2nd ACM/IEEE Int Conf on Distributed Smart Cameras.Piscataway, NJ:IEEE, 2008:1-9" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Utility-based dynamic camera assignment and hand-off in a video network">
                                        <b>[2]</b>
                                        Li Yiming, Bhanu B.Utility-based dynamic camera assignment and hand-off in a video network[C]Proc of the2nd ACM/IEEE Int Conf on Distributed Smart Cameras.Piscataway, NJ:IEEE, 2008:1-9
                                    </a>
                                </li>
                                <li id="354">


                                    <a id="bibliography_3" title="Guo Bin, Yu Zhiwen, Zhou Xingshe, et al.From participatory sensing to mobile crowd sensing[C]Proc of the 12th IEEE Int Conf on Pervasive Computing and Communications Workshops.Piscataway, NJ:IEEE, 2014:593-598" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=From participatory sensing to mobile crowd sensing">
                                        <b>[3]</b>
                                        Guo Bin, Yu Zhiwen, Zhou Xingshe, et al.From participatory sensing to mobile crowd sensing[C]Proc of the 12th IEEE Int Conf on Pervasive Computing and Communications Workshops.Piscataway, NJ:IEEE, 2014:593-598
                                    </a>
                                </li>
                                <li id="356">


                                    <a id="bibliography_4" title="Goldman J, Shilton K, Burke J, et al.Participatory sensing:A citizen-powered approach to illuminating the patterns that shape our world[J].Ethics in Science&amp;amp;Engineering National Clearinghouse, 2009, 4 (2) :117-134" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Participatory Sensing:A Citizen-Powered Approach to Illuminating the Patterns that Shape our World">
                                        <b>[4]</b>
                                        Goldman J, Shilton K, Burke J, et al.Participatory sensing:A citizen-powered approach to illuminating the patterns that shape our world[J].Ethics in Science&amp;amp;Engineering National Clearinghouse, 2009, 4 (2) :117-134
                                    </a>
                                </li>
                                <li id="358">


                                    <a id="bibliography_5" title="Merlino G, Arkoulis S, Distefano S, et al.Mobile crowdsensing as a service:A platform for applications on top of sensing clouds[J].Future Generation Computer Systems, 2016, 56 (2) :623-639" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500408081&amp;v=MTM3MzU9TmlmT2ZiSzlIOVBPcW85RllPc0hESFE0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSmx3Y2FoTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Merlino G, Arkoulis S, Distefano S, et al.Mobile crowdsensing as a service:A platform for applications on top of sensing clouds[J].Future Generation Computer Systems, 2016, 56 (2) :623-639
                                    </a>
                                </li>
                                <li id="360">


                                    <a id="bibliography_6" title="Dan Jiang, Yuan Yu.A multi-object motion-tracking method for video surveillance[C]Proc of the 8th Acis Int Conf on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing.Piscataway, NJ:IEEE, 2007:402-405" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Multi-object Motion-tracking Method for Video Surveillance">
                                        <b>[6]</b>
                                        Dan Jiang, Yuan Yu.A multi-object motion-tracking method for video surveillance[C]Proc of the 8th Acis Int Conf on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing.Piscataway, NJ:IEEE, 2007:402-405
                                    </a>
                                </li>
                                <li id="362">


                                    <a id="bibliography_7" title="Serby D, Kollermeier E, Gool L V.Probabilistic object tracking using multiple features[C]Proc of the 17th Int Conf on Pattern Recognition.Piscataway, NJ:IEEE, 2004:184-187" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probabilistic object tracking using multiple features">
                                        <b>[7]</b>
                                        Serby D, Kollermeier E, Gool L V.Probabilistic object tracking using multiple features[C]Proc of the 17th Int Conf on Pattern Recognition.Piscataway, NJ:IEEE, 2004:184-187
                                    </a>
                                </li>
                                <li id="364">


                                    <a id="bibliography_8" title="Wang Yong, Wang Dianhong, Fang Wu.Automatic node selection and target tracking in wireless camera sensor networks[J].Computers&amp;amp;Electrical Engineering, 2014, 40 (2) :484-493" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700122627&amp;v=MDc4MDBaZVp1SHlqbVViN0lKbHdjYWhNPU5pZk9mYks4SDlETXFJOUZaZWtOQ240K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Wang Yong, Wang Dianhong, Fang Wu.Automatic node selection and target tracking in wireless camera sensor networks[J].Computers&amp;amp;Electrical Engineering, 2014, 40 (2) :484-493
                                    </a>
                                </li>
                                <li id="366">


                                    <a id="bibliography_9" title="Kim S, Robson C, Zimmerman T, et al.Creek watch:Pairing usefulness and usability for successful citizen science[C]Proc of the 19th Special Interest Group on ComputerHuman Interaction Conf on Human Factors in Computing Systems.New York:ACM, 2011:2125-2134" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Creek watch:Pairing usefulness and usability for successful citizen science">
                                        <b>[9]</b>
                                        Kim S, Robson C, Zimmerman T, et al.Creek watch:Pairing usefulness and usability for successful citizen science[C]Proc of the 19th Special Interest Group on ComputerHuman Interaction Conf on Human Factors in Computing Systems.New York:ACM, 2011:2125-2134
                                    </a>
                                </li>
                                <li id="368">


                                    <a id="bibliography_10" title="Uddin M Y S, Wang Hongyan, Saremi F, et al.PhotoNet:A similarity-aware picture delivery service for situation awareness[C]Proc of the 32nd Real-Time Systems Symp.Piscataway, NJ:IEEE, 2011:317-326" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PhotoNet:A similarity-aware picture delivery service for situation awareness">
                                        <b>[10]</b>
                                        Uddin M Y S, Wang Hongyan, Saremi F, et al.PhotoNet:A similarity-aware picture delivery service for situation awareness[C]Proc of the 32nd Real-Time Systems Symp.Piscataway, NJ:IEEE, 2011:317-326
                                    </a>
                                </li>
                                <li id="370">


                                    <a id="bibliography_11" title="Chen Huihui, Guo Bin, Yu Zhiwen, et al.Toward real-time and cooperative mobile visual sensing and sharing[C]Proc of the 35th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2016:1-9" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Toward real-time and cooperative mobile visual sensing and sharing">
                                        <b>[11]</b>
                                        Chen Huihui, Guo Bin, Yu Zhiwen, et al.Toward real-time and cooperative mobile visual sensing and sharing[C]Proc of the 35th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2016:1-9
                                    </a>
                                </li>
                                <li id="372">


                                    <a id="bibliography_12" title="Hua Yu, He Wenbo, Liu Xue, et al.SmartEye:Real-time and efficient cloud image sharing for disaster environments[C]Proc of the 34th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2015:1616-1624" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SmartEye:Real-time and efficient cloud image sharing for disaster environments">
                                        <b>[12]</b>
                                        Hua Yu, He Wenbo, Liu Xue, et al.SmartEye:Real-time and efficient cloud image sharing for disaster environments[C]Proc of the 34th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2015:1616-1624
                                    </a>
                                </li>
                                <li id="374">


                                    <a id="bibliography_13" title="Xu Mengwen, Wang Dong, Li Jian.DESTPRE:A datadriven approach to destination prediction for taxi rides[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:729-739" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DESTPRE:A datadriven approach to destination prediction for taxi rides">
                                        <b>[13]</b>
                                        Xu Mengwen, Wang Dong, Li Jian.DESTPRE:A datadriven approach to destination prediction for taxi rides[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:729-739
                                    </a>
                                </li>
                                <li id="376">


                                    <a id="bibliography_14" title="Xue A Y, Zhang Rui, Zheng Yu, et al.Destination prediction by sub-trajectory synthesis and privacy protection against such prediction[C]Proc of the 28th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2013:254-265" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Destination prediction by sub-trajectory synthesis and privacy protection against such prediction">
                                        <b>[14]</b>
                                        Xue A Y, Zhang Rui, Zheng Yu, et al.Destination prediction by sub-trajectory synthesis and privacy protection against such prediction[C]Proc of the 28th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2013:254-265
                                    </a>
                                </li>
                                <li id="378">


                                    <a id="bibliography_15" title="Gambs S, Killijian M O, Cortez M N D P.Next place prediction using mobility Markov chains[C]Proc of the 1st Workshop on Measurement, Privacy, and Mobility.New York:ACM, 2012:3" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Next place prediction using mobility Markov chains">
                                        <b>[15]</b>
                                        Gambs S, Killijian M O, Cortez M N D P.Next place prediction using mobility Markov chains[C]Proc of the 1st Workshop on Measurement, Privacy, and Mobility.New York:ACM, 2012:3
                                    </a>
                                </li>
                                <li id="380">


                                    <a id="bibliography_16" title="Papadias D, Shen Qiongmao, Tao Yufei, et al.Group nearest neighbor queries[C]Proc of the 19th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2004:301-312" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Group Nearest Neighbor Queries">
                                        <b>[16]</b>
                                        Papadias D, Shen Qiongmao, Tao Yufei, et al.Group nearest neighbor queries[C]Proc of the 19th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2004:301-312
                                    </a>
                                </li>
                                <li id="382">


                                    <a id="bibliography_17" title="Reddy S, Estrin D, Srivastava M.Recruitment framework for participatory sensing data collections[C]Proc of the 8th Int Conf on Pervasive Computing.New York:ACM, 2010:138-155" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recruitment framework for participatory sensing data collections">
                                        <b>[17]</b>
                                        Reddy S, Estrin D, Srivastava M.Recruitment framework for participatory sensing data collections[C]Proc of the 8th Int Conf on Pervasive Computing.New York:ACM, 2010:138-155
                                    </a>
                                </li>
                                <li id="384">


                                    <a id="bibliography_18" title="Cardone G, Foschini L, Bellavista P, et al.Fostering participaction in smart cities:A geo-social crowdsensing platform[J].IEEE Communications Magazine, 2013, 51 (6) :112-119" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fostering Participaction in Smart Cities:a geo-social crowdsensing platform">
                                        <b>[18]</b>
                                        Cardone G, Foschini L, Bellavista P, et al.Fostering participaction in smart cities:A geo-social crowdsensing platform[J].IEEE Communications Magazine, 2013, 51 (6) :112-119
                                    </a>
                                </li>
                                <li id="386">


                                    <a id="bibliography_19" title="Li Chengte, Shan M K.Team formation for generalized tasks in expertise social networks[C]Proc of the 2nd IEEE Int Conf on Social Computing.Piscataway, NJ:IEEE, 2010:9-16" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Team formation for generalized tasks in expertise social networks">
                                        <b>[19]</b>
                                        Li Chengte, Shan M K.Team formation for generalized tasks in expertise social networks[C]Proc of the 2nd IEEE Int Conf on Social Computing.Piscataway, NJ:IEEE, 2010:9-16
                                    </a>
                                </li>
                                <li id="388">


                                    <a id="bibliography_20" title="Liu Yan, Guo Bin, Wang Yang, et al.TaskMe:Multi-task allocation in mobile crowd sensing[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:403-414" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Task Me:multitask allocation in mobile crowd sensing">
                                        <b>[20]</b>
                                        Liu Yan, Guo Bin, Wang Yang, et al.TaskMe:Multi-task allocation in mobile crowd sensing[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:403-414
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(02),328-337 DOI:10.7544/issn1000-1239.2019.20170808            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>CrowdTracker:一种基于移动群智感知的目标跟踪方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%99%AF%E7%91%B6&amp;code=36872635&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">景瑶</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%96%8C&amp;code=15618550&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E8%8D%9F%E6%85%A7&amp;code=30823091&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈荟慧</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B2%B3%E8%B6%85%E5%88%9A&amp;code=41207716&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">岳超刚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%9F%B1&amp;code=11229341&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王柱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%BC%E5%BF%97%E6%96%87&amp;code=09118006&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">於志文</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0085569&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>面向目标跟踪问题提出一种基于移动群智感知的解决方案CrowdTracker.不同于基于视频监控的目标跟踪方法, 通过基于群智的多人协作拍照方式实现对移动目标的轨迹预测和跟踪, 其优化目标为在保证准确实时地对目标进行跟踪的同时尽可能地减少用户激励的成本 (假设激励与完成任务的参与者人数和参与者完成任务所移动的距离成正比) .为实现该目标, 提出了目标移动性预测的方法MPRE和任务分配的方法T-centric, P-centric.T-centric是以任务为中心的参与者选择方法, 而P-centric是以人为中心的任务选择方法.MPRE通过分析大量的车辆历史轨迹建立城市里车辆的移动模型以预测目标下一步的位置.在预测的区域内通过T-centric或P-centric方法进行跟踪任务分配.通过一个大规模的真实数据集对移动性预测方法MPRE和2种任务分配算法进行实验评估, 实验结果表明:CrowdTracker能有效地在实现目标实时跟踪的同时降低激励成本.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A7%BB%E5%8A%A8%E7%BE%A4%E6%99%BA%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">移动群智感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8B%8D%E7%85%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">拍照;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E7%A7%BB%E5%8A%A8%E6%80%A7%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标移动性预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">任务分配;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *郭斌 (guob@nwpu.edu.cn) ;
                                </span>
                                <span>
                                    景瑶 jy_jingyao@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-10-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61332005, 61772428, 61402369);</span>
                                <span>国家“九七三”重点基础研究发展计划基金项目 (2015CB352400);</span>
                    </p>
            </div>
                    <h1><b>CrowdTracker: Object Tracking Using Mobile Crowd Sensing</b></h1>
                    <h2>
                    <span>Jing Yao</span>
                    <span>Guo Bin</span>
                    <span>Chen Huihui</span>
                    <span>Yue Chaogang</span>
                    <span>Wang Zhu</span>
                    <span>Yu Zhiwen</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, Northwestern Polytechnical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This paper proposes CrowdTracker, a novel object tracking system based on mobile crowd sensing (MCS) . Different from other studies that are based on video surveillance, CrowdTracker recurits people to collaboratively take photos of the object to achieve object movement prediction and tracking. The optimization objective of CrowdTracker is to effectively track the moving object in real time and minimize the cost of user incentives. The incentive is determined by the number of workers assigned and the total distance that workers move to complete the task. In order to achieve the objective, CrowdTracker proposes an algorithm MPRE to predict the object moving pattern, and two task allocation algorithms, namely T-centric and P-centric, are proposed. T-centric selects workers in a task-centric way, while P-centric allocates tasks in a people-centric manner. By analyzing a large number of historical vehicle trajectories, MPRE builds a moving model of vehicle to predict the object's next position. In the predicted regions, CrowdTracker selects an optimal set of workers for the tracking task by utilizing T-centric or P-centric. Experiments are conducted on a large-scale real-world dataset. The experimental results show that CrowdTracker can effectively track the object in real time and reduce the incentive cost at the same time.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=mobile%20crowd%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">mobile crowd sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=photo%20taking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">photo taking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20movement%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object movement prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=task%20allocation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">task allocation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Jing Yao, born in 1994.Master candidate.Her main research interest is mobile crowd sensing.<image id="338" type="formula" href="images/JFYZ201902009_33800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Guo Bin, born in 1980.Professor, PhD supervisor.His main research interests include ubiquitous computing, mobile crowd sensing, and HCI.<image id="341" type="formula" href="images/JFYZ201902009_34100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Chen Huihui, born in 1979.PhD.Her main research interest is mobile crowd sensing.<image id="343" type="formula" href="images/JFYZ201902009_34300.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Yue Chaogang, born in 1994.Master candidate.His main research interest is mobile crowd sensing.<image id="345" type="formula" href="images/JFYZ201902009_34500.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Zhu, born in 1983.Associate professor.His main research interests include pervasive computing, social network analysis, and healthcare.<image id="347" type="formula" href="images/JFYZ201902009_34700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Yu Zhiwen, born in 1977.Professor, PhDsupervisor.Member of CCF.His main research interests cover ubiquitous computing and HCI.<image id="349" type="formula" href="images/JFYZ201902009_34900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2017-10-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61332005, 61772428, 61402369);</span>
                                <span>the National Basic Research Program of China (973 Program) (2015CB352400);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="217">一直以来, 公共安全问题是城市生活面临的一大挑战, 移动目标跟踪技术作为公共安全领域中的一项重要技术更是研究者们关注的热门课题.城市发生突发状况后, 政府和警察常常通过各种数据来追踪可疑车辆和人, 其中视频监控是最常用的数据.现有的对于移动目标跟踪的研究主要基于网络视频监控数据方式<sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup>.该类研究主要针对如何部署摄像头达到最大化道路覆盖以及基于图像的运动目标检测算法设计.这种基于网络视频监控的方法需要预先在广泛的城市区域内部署大量的摄像头, 设备成本高且覆盖范围有限.随着可内嵌多种传感器的智能手机的快速普及和应用, 移动群智感知技术<sup><a class="sup">[3]</a></sup>作为一种新的感知模式逐步发展起来, 它依赖大量普通用户的移动设备及其具备的丰富的感知能力来完成大规模、复杂的城市与社会感知任务<sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup>.大量的用户通过智能手机随时随地感知着城市生活的韵律, 这为解决城市生活中的公共安全问题带来了新的思路.人们可以随时随地使用智能手机拍摄视频、照片, 并在一定法律约束范围内作为证据使用.如果将人们手中的智能手机看做移动的监控摄像头, 那么这就可以实现一种新的基于群智感知的视频监控系统.</p>
                </div>
                <div class="p1">
                    <p id="218">基于该思路, 本文面向目标跟踪问题提出一种基于移动群智感知的解决方案CrowdTracker:通过多人协作拍照方式实现对移动目标的轨迹预测和跟踪.本文主要针对移动目标中的车辆进行群智跟踪.CrowdTracker的示例如图1所示.城市发生公共安全事件后, 警察和政府在CrowdTracker平台上发布待跟踪的目标车辆信息, 包括车辆颜色、型号、车牌号码等.CrowdTracker平台上的用户<i>A</i>在网格区域<i>n</i><sub>1</sub>内发现目标车辆, 对该车辆拍照并上传照片信息以及位置信息, 启动对该目标的跟踪任务.CrowdTracker服务器端通过分析城市中大量的车辆轨迹数据, 预测出该目标车辆下一步可能往区域<i>n</i><sub>2</sub>移动, 并提前在<i>n</i><sub>2</sub>内通知平台参与者等待目标出现.当参与者<i>B</i>和<i>C</i>再次发现目标时同样进行拍照并上传信息, 如此循环, 得到目标车辆出现过的网格序列<i>n</i><sub>1</sub>-<i>n</i><sub>2</sub>-<i>n</i><sub>3</sub>-<i>n</i><sub>4</sub>即为车辆的移动轨迹, 最终实现基于群智感知的移动目标跟踪.</p>
                </div>
                <div class="area_img" id="219">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CrowdTracker示例" src="Detail/GetImg?filename=images/JFYZ201902009_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 CrowdTracker示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 A scenario of CrowdTracker</p>

                </div>
                <div class="p1">
                    <p id="220">为了实现这个目标, 本文提出了预测目标移动模型的方法MPRE (movement prediction) 和任务分配的方法T-centric, P-centric.MPRE首先通过分析大量的车辆历史轨迹建立城市里车辆位置的移动概率模型.当目标出现在城市某位置时, 通过该移动模型找到目标下一步移动概率最大的位置区域, 进而在该区域内预先安排参与者.本文提出的T-centric和P-centric方法以实现在跟踪任务下的参与者优选和任务地点优选, 要求达到参与者与任务地点最佳匹配, 使参与者能在一定时间约束内到达指定任务点的同时, 所移动的距离最短, 激励成本最少.T-centric是以任务为中心的参与者选择方法, 而P-centric是以人为中心的任务选择方法.本文通过成都市二环内1个月的出租车轨迹数据集对以上3种算法进行实验评估, 实验结果表明, 本文提出的CrowdTracker能有效地实现目标实时跟踪.</p>
                </div>
                <h3 id="221" name="221" class="anchor-tag"><b>1</b><b>相关工作</b></h3>
                <div class="p1">
                    <p id="222">目前常用的目标跟踪方法主要是通过预先部署的网络视频监控系统进行<sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup>.现有的技术主要针对如何部署摄像头达到最大化道路覆盖、如何调用摄像头来追踪目标以及基于图像的目标检测算法设计等<sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup>.与传统的预先部署固定的网络视频监控系统不同的是, 本文旨在利用群智的思想将人们手中智能手机的摄像头看作移动的监控摄像头, 提出基于群智的多人协作拍照的方式对移动目标进行实时跟踪.下面就本文的相关工作进行介绍.</p>
                </div>
                <h4 class="anchor-tag" id="223" name="223"><b>1.1</b><b>移动群智感知</b></h4>
                <div class="p1">
                    <p id="224">基于移动群智感知的工作包括数据采集、管理、分析到最终提供服务等.移动群智感知的数据包括2种产生方式:移动群智感知和移动社交网络数据.移动群智感知就是利用人们手中的智能手机感知周边的信息.比如“哥本哈根车轮”项目在自行车车轮里安装一些传感器, 并通过用户手机将收集的数据发送至后台服务器, 这样依靠群体的力量就可以感知整个城市不同角落的温度、湿度和CO<sub>2</sub>浓度;利用手机拍照发现城市中被污染的河流<sup><a class="sup">[9]</a></sup>、损坏的建筑物<sup><a class="sup">[10]</a></sup>、感知生活中的社会热点事件<sup><a class="sup">[11]</a></sup>、帮助城市进行灾难救援等<sup><a class="sup">[12]</a></sup>.与本文工作不同的是, 这些感知任务主要关注静态的目标.CrowdTracker是利用多人协作拍照的方式对移动目标进行实时跟踪, 需要对群智参与者的行为进行时间约束, 在时间序列下, 多个参与者完成拍照任务的位置序列即为目标的移动轨迹.</p>
                </div>
                <h4 class="anchor-tag" id="225" name="225"><b>1.2</b><b>移动轨迹预测</b></h4>
                <div class="p1">
                    <p id="226">CrowdTracker旨在保证准确实时地对目标进行跟踪的同时尽可能地减少用户激励的成本.减少激励成本首先要缩小跟踪任务的范围, 减少参与者数量.因此需要通过目标的当前位置信息, 预测目标下一步的移动模型.现有的很多研究通过分析城市车辆的轨迹数据挖掘车辆移动的规律, 预测车辆行驶的目的地.Xu等人<sup><a class="sup">[13]</a></sup>用纯数据驱动的方式分析城市车辆的轨迹数据进行目的地预测.与本文工作不同的是, 文献[13]研究的是长距离的最终目的地预测, 本文的移动预测旨在通过目标上一状态预测下一时刻位置状态.Xue等人<sup><a class="sup">[14]</a></sup>和Gambs等人<sup><a class="sup">[15]</a></sup>用基于概率模型的Markov链进行下一站预测.Xue等人<sup><a class="sup">[14]</a></sup>将轨迹序列网格化的思想也为本文工作提供了思路.</p>
                </div>
                <h4 class="anchor-tag" id="227" name="227"><b>1.3</b><b>群智感知任务分配</b></h4>
                <div class="p1">
                    <p id="228">任务分配是移动群智感知的关键挑战之一, 如何进行任务分配对数据采集的全面性、任务完成率和数据采集质量等都具有重要影响.面向移动群智感知的参与者选择是以物理空间位置为基础进行选择, 任务的类型分为单个群智感知任务和多个并发感知任务2种.在单任务分配问题中, Papadias等人<sup><a class="sup">[16]</a></sup>研究在已知给定集合点的情况下, 寻找其他的点使其到给定集合点的距离最小;Reddy等人<sup><a class="sup">[17]</a></sup>主要研究在考虑空间位置、时间要求以及参与者行为习惯的情况下, 选择出合适的参与者完成任务;Cardone等人<sup><a class="sup">[18]</a></sup>考虑在参与者个数一定的情况下, 最大限度地提高感知任务的空间覆盖范围.Li等人<sup><a class="sup">[19]</a></sup>研究团队形成问题, 即寻找一个有特定技能的专家小组, 每个人完成一个给定的任务, 同时最小化团队之间的交流成本.Liu等人<sup><a class="sup">[20]</a></sup>研究了移动群智感知中面向多任务并发的参与者选择问题, 不同于其他参与者选择问题, 该文选择出的参与者不再局限于只能完成1个任务, 参与者可以在规定时间内尽可能的完成多个任务, 由此降低群智平台的成本.</p>
                </div>
                <div class="p1">
                    <p id="229">本文提出的CrowdTracker首先对目标下一步的移动进行预测, 然后在预测的区域内进行跟踪任务分配.在该区域内的每一个任务点的任务是同时进行且有时间限制的, 每个参与者只能在规定的时间内在1个任务点等待目标的出现.因此, 本文的任务分配是一个并发的单任务分配问题.针对该问题, CrowdTracker提出了T-centric和P-centric方法实现在跟踪任务下的参与者优选和任务地点优选, 使参与者能在一定时间约束内到达指定任务点的同时所移动的距离最短.</p>
                </div>
                <h3 id="230" name="230" class="anchor-tag"><b>2</b><b>CrowdTracker系统框架</b></h3>
                <div class="p1">
                    <p id="231">CrowdTracker的系统框架如图2所示, 主要包括客户端APP和服务器端2部分.客户端APP主要用于任务启动者和任务执行者采集数据.服务器端对客户端上传的数据进行一系列分析处理后通知被选择的参与者并给出下一步任务执行的指示, 保证跟踪任务的持续执行.</p>
                </div>
                <div class="area_img" id="232">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_232.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 CrowdTracker系统框架" src="Detail/GetImg?filename=images/JFYZ201902009_232.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 CrowdTracker系统框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_232.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The framework of CrowdTracker</p>

                </div>
                <div class="p1">
                    <p id="233">图2中的数据采集模块展示了使用客户端进行数据采集的基本流程.城市发生共公共安全事件后, 警察和政府在CrowdTracker平台上发布待跟踪的目标车辆信息, 包括车辆的颜色、型号和车牌号码等.CrowdTracker平台上的用户在城市某一位置发现目标, 立即对其拍摄1张照片用<i>pic</i>来表示.<i>pic</i>中保存了用户拍照时刻的图像、GPS位置坐标和时间戳等信息, 用一个五元组 (<i>id</i>, <i>img</i>, <i>lon</i>, <i>lat</i>, <i>t</i>) 表示.<i>id</i>是拍照用户的唯一标识, <i>img</i>代表图像信息, <i>lon</i>和<i>lat</i>分别表示用户当前位置的经纬度, 也代表了目标当前的位置信息, <i>t</i>表示拍照时间.上传该五元组信息至服务器端, 启动该目标的跟踪任务.服务器对客户端发起的任务请求分析处理后, 给出该跟踪任务下一步的计划, 并通知CrowdTracker平台上被选中执行下一步任务的参与者.参与者按照任务指示在一定的时间内到达指定任务地点, 等待目标出现, 在一定时间内发现目标后对目标进行拍照并再次上传信息, 完成该步跟踪任务.</p>
                </div>
                <div class="p1">
                    <p id="234">具体地, CrowdTracker群智跟踪方法的详细内容将在第4节进行介绍.</p>
                </div>
                <h3 id="235" name="235" class="anchor-tag"><b>3</b><b>群智跟踪方法实现</b></h3>
                <div class="p1">
                    <p id="236">图2中的群智跟踪方法模块展示了服务器端对客户端上传的数据进行分析的基本流程.该模块主要分为3个部分:目标车辆移动预测模型、群智跟踪任务分配以及最终的任务推送.</p>
                </div>
                <h4 class="anchor-tag" id="237" name="237"><b>3.1</b><b>预测目标车辆移动模型</b></h4>
                <div class="p1">
                    <p id="238">客户端上传数据中的经纬度信息代表了目标当前的位置.基于该位置信息, 预测目标下一步的移动, 进而有针对性地在预测的区域内进行跟踪任务分配, 准确跟踪目标的同时减少平台的激励成本.</p>
                </div>
                <div class="p1">
                    <p id="239">城市中车辆的移动看似杂乱无序, 实则存在潜在的模式.例如上班高峰期的车辆大都由住宅区流向商业区, 而下班高峰期的车辆大都由商业区流向住宅区.这种规律对于预测车辆的移动模型具有一定的意义.本文提出了基于移动Markov链 (mobility Markov chain, MMC) 的MPRE方法来预测车辆移动.Markov链是数学中具有Markov性质的离散时间随机过程.在该过程中, 在给定当前知识或信息的情况下, 过去 (即当前以前的历史状态) 对于预测将来 (即当前以后的未来状态) 是无关的.<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …描述了Markov链中的一种状态序列, <i>X</i><sub><i>n</i></sub>的值表示在时刻<i>n</i>的状态, 如果<i>X</i><sub><i>n</i>+1</sub>对于过去状态的条件概率分布仅是<i>X</i><sub><i>n</i></sub>的一个函数, 则<i>X</i><sub><i>n</i>+1</sub>时刻的状态见式 (1) :</p>
                </div>
                <div class="p1">
                    <p id="240"><i>P</i> (<i>X</i><sub><i>n</i>+1</sub>=<i>x</i>|<i>X</i><sub>1</sub>=<i>x</i><sub>1</sub>, <i>X</i><sub>2</sub>=<i>x</i><sub>2</sub>, …, <i>X</i><sub><i>n</i></sub>=<i>x</i><sub><i>n</i></sub>) =</p>
                </div>
                <div class="p1">
                    <p id="241"><i>P</i> (<i>X</i><sub><i>n</i>+1</sub>=<i>x</i>|<i>X</i><sub><i>n</i></sub>=<i>x</i><sub><i>n</i></sub>) . (1) </p>
                </div>
                <div class="p1">
                    <p id="242">移动Markov链是模型化地将用户或者车辆等的移动行为转化为一系列离散随机过程, 如图3所示, 也就是Markov链中的状态序列{<i>n</i><sub>1</sub>, <i>n</i><sub>2</sub>, …}, 每个状态节点对应一个位置区域.由Markov性质可得, 从一个状态<i>n</i><sub><i>i</i></sub>到另一个状态<i>n</i><sub><i>j</i></sub>的转移概率<i>P</i><sub><i>i j</i></sub>是条件概率, 只取决于状态<i>n</i><sub><i>i</i></sub>.利用MMC进行下一状态预测时, 重要的是获取转移矩阵的参数, 也就是不同位置状态间的移动概率<i>P</i><sub><i>i j</i></sub>, 式 (2) 中<i>N</i><sub><i>i</i></sub>表示所有包含节点<i>n</i><sub><i>i</i></sub>的轨迹数目, <i>N</i><sub><i>i</i>, <i>j</i></sub>表示从节点<i>n</i><sub><i>i</i></sub>到<i>n</i><sub><i>j</i></sub>的轨迹数目.<i>N</i><sub><i>i</i>, <i>j</i></sub>与<i>N</i><sub><i>i</i></sub>的商即为转移概率<i>P</i><sub><i>i j</i></sub>的值.</p>
                </div>
                <div class="p1">
                    <p id="243"><mathml id="244"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></math></mathml>. (2) </p>
                </div>
                <div class="area_img" id="245">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 移动Markov链模型" src="Detail/GetImg?filename=images/JFYZ201902009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 移动Markov链模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_245.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Mobility Markov chain</p>

                </div>
                <div class="p1">
                    <p id="246">具体地, 基于MMC的思想, 本文提出MPRE的方法对车辆的移动进行预测.在进行MPRE之前首先对城市区域进行网格化处理, 如图4所示:</p>
                </div>
                <div class="area_img" id="247">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 城市区域网格化" src="Detail/GetImg?filename=images/JFYZ201902009_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 城市区域网格化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Grid on the example</p>

                </div>
                <div class="p1">
                    <p id="248">将城市区域分为大小为<i>g</i>×<i>g</i> (单位m<sup>2</sup>) 的单元格, 每个单元格<i>n</i><sub><i>i</i></sub>代表MMC中的一个位置状态.进一步, 为了更好地发现城市中车辆的移动规律, 构建MMC中各个位置状态之间的转移概率矩阵, 本文对大量的原始车辆轨迹序列进行网格化处理.车辆的原始轨迹信息由一系列时间连续的GPS点形成, 对这些轨迹信息进行网格化即判断每一个GPS点属于哪一个网格区域, 若连续时间的GPS点序列在同一网格位置, 则记为1个网格位置.最终, 网格序列即为轨迹序列<i>G</i><sub><i>i</i></sub>={<i>n</i><sub>1</sub>, <i>n</i><sub>2</sub>, …}.大量轨迹进行网格化后得到轨迹序列集合<i>G</i>={<i>G</i><sub>1</sub>, <i>G</i><sub>2</sub>, …}.同样地, 当目标出现在城市某位置时, 将经纬度数据转化为网格位置<i>n</i><sub><i>i</i></sub>.车辆轨迹序列集合<i>G</i>和目标位置<i>n</i><sub><i>i</i></sub>作为MPRE的输入.MPRE算法具体流程见算法1.</p>
                </div>
                <div class="p1">
                    <p id="249"><b>算法1</b>. MPRE.</p>
                </div>
                <div class="p1">
                    <p id="250">输入:轨迹序列集合<i>G</i>、目标位置<i>n</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="251">输出:<i>P</i><sub>max</sub>对应的位置点<i>n</i><sub><i>j</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="252">① 基于式 (2) , 从<i>G</i>中学习出各个位置状态间的转移矩阵<b><i>P</i></b>;</p>
                </div>
                <div class="p1">
                    <p id="253">② 逐行搜索矩阵<b><i>P</i></b>, 定位到目标位置<i>n</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="254">③ 在<i>n</i><sub><i>i</i></sub>对应的行里, 查找出转移概率最大的<i>P</i><sub>max</sub>对应的下一步位置<i>n</i><sub><i>j</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="255">④ 输出<i>P</i><sub>max</sub>对应的位置点<i>n</i><sub><i>j</i></sub>, 即为目标下一步可能移动的位置;</p>
                </div>
                <div class="p1">
                    <p id="256">⑤ 结束.</p>
                </div>
                <div class="p1">
                    <p id="257">MPRE通过分析大量的车辆历史轨迹序列计算出城市各个位置间的的转移概率, 迁出位置间的转移概率矩阵<b><i>P</i></b>= (<i>P</i><sub><i>i j</i></sub>) .如图4所示, 当目标出现在城市某位置<i>n</i><sub>5</sub>时, 搜索矩阵<b><i>P</i></b>, 找到目标下一步移动概率最大<i>P</i><sub>56</sub>对应的位置区域<i>n</i><sub>6</sub>, 即为目标下一步可能移动的位置, 进而在该区域内预先安排参与者.</p>
                </div>
                <h4 class="anchor-tag" id="258" name="258"><b>3.2</b><b>群智跟踪任务分配方法</b></h4>
                <div class="p1">
                    <p id="259">通过预测车辆移动模块中的MPRE方法确定出目标下一步移动的位置范围, 在该区域内预先安排参与者.每一个区域内都有多条路, 且1条路覆盖一定的范围, 如何在1条路上进行任务地点选择是首先需要思考的问题.分析路网的拓扑结构, 路网是由多条路连接形成, 而每条路是由路网节点 (起始点、终止点) 连接形成, 路网节点就是形成整个道路网络的关键位置.因此, 本文考虑将OpenStreetMap路网数据中的节点数据作为1条路上的任务点, 达到最大化道路覆盖.在此基础上, 本文提出T-centric和P-centric方法以实现在跟踪任务下的参与者优选和任务地点优选, 使参与者能在一定时间约束内到达指定任务点的同时所移动的距离最短.T-centric是以任务为中心的参与者选择方法, 而P-centric是以人为中心的任务选择方法.</p>
                </div>
                <div class="p1">
                    <p id="260">对于每一步跟踪任务<i>T</i>, 即1个网格内的任务分配问题定义如下:城市网格化的步长为<i>g</i> (单位m) , 每个<i>g</i>×<i>g</i> (单位m<sup>2</sup>) 的网格内的路网节点数量为<i>s</i>, 则设定<i>s</i>个并发任务<i>T</i>={<i>t</i><sub>1</sub>, <i>t</i><sub>2</sub>, …, <i>t</i><sub><i>s</i></sub>}.每个任务<i>t</i><sub><i>i</i></sub>需要1个人来完成, 任务的位置为<i>lt</i><sub><i>i</i></sub>, 每个网格的候选者集合<i>C</i>={<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>j</i></sub>, …}, 候选者的位置为<i>lc</i><sub><i>i</i></sub>.<i>u</i><sub><i>i</i></sub>表示完成任务<i>t</i><sub><i>i</i></sub>的参与者, 完成任务<i>t</i><sub><i>i</i></sub>的参与者<i>u</i><sub><i>i</i></sub>需要移动的距离为<i>d</i><sub><i>i</i></sub> (见式 (3) ) , 完成1步跟踪任务<i>T</i>, 所有参与者所移动的总距离为<i>D</i><sub><i>T</i></sub>.假设每个用户移动平均速度为<i>V</i><sub><i>u</i></sub> (单位m/min) , 城市中车辆移动的平均速度为<i>V</i><sub><i>c</i></sub> (单位m/min) .该问题的目标函数是安排参与者与任务的最佳匹配, 使参与者能在一定时间约束内 (目标进入网格区域之前) 到达指定任务点的同时所移动的距离<i>d</i><sub><i>i</i></sub>最短, 即所有参与者移动的总距离<i>D</i><sub><i>T</i></sub>最短 (见式 (4) ) , 时间约束见式 (5) .具体地, 针对该任务分配问题, 考虑系统的2个核心要素任务和人, 分别提出以任务为中心的参与者选择方法T-centric和以人为中心的任务选择方法P-centric.</p>
                </div>
                <div class="p1">
                    <p id="261"><i>d</i><sub><i>i</i></sub>=|<i>lt</i><sub><i>i</i></sub>-<i>lc</i><sub><i>i</i></sub>|, (3) </p>
                </div>
                <div class="p1">
                    <p id="262"><mathml id="263"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo>=</mo><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>, (4) </p>
                </div>
                <div class="p1">
                    <p id="264">满足</p>
                </div>
                <div class="p1">
                    <p id="265"><mathml id="266"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mi>V</mi><msub><mrow></mrow><mi>u</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow><mo>≤</mo><mrow><mo>|</mo><mrow><mfrac><mi>g</mi><mrow><mi>V</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></math></mathml>. (5) </p>
                </div>
                <h4 class="anchor-tag" id="267" name="267">3.2.1 T-centric任务分配算法</h4>
                <div class="p1">
                    <p id="268">T-centric是以任务为中心的参与者选择方法, 采用贪心启发算法的思想.首先在任务集合<i>T</i>中随机选择1个任务作为初始任务, 然后从侯选者集合<i>C</i>中选出满足时间约束的参与者集合.若该参与者集合为空, 则表明没有能够完成该任务的参与者;若不为空, 则存在能够完成该任务的参与者, 进一步在该参与者集合中选出与任务点距离最短的参与者, 形成1个参与者与任务点的最佳匹配.在原任务集合以及候选参与者集合中剔除掉已经形成匹配的参与者和任务, 接着对下一个任务进行参与者选择, 以此类推, 按照该方法, 直到任务集合中的每一个任务都找到1个最佳的参与者.详见算法2.</p>
                </div>
                <div class="p1">
                    <p id="269"><b>算法2</b>. T-centric.</p>
                </div>
                <div class="p1">
                    <p id="270">输入:任务集合<i>T</i>、候选参与者集合<i>C</i>;</p>
                </div>
                <div class="p1">
                    <p id="271">输出:能被覆盖的任务点集合<i>t</i>以及相应的参与者集合<i>u</i>.</p>
                </div>
                <div class="p1">
                    <p id="272">① 随机选取初始任务<i>t</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="273">② <i>C</i>中能在<mathml id="274"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mfrac><mi>g</mi><mrow><mi>V</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></math></mathml> (单位min) 内到达该任务点的参与者集合<i>u</i><sub><i>i</i>.</sub>={<i>u</i><sub><i>i</i>1</sub>, <i>u</i><sub><i>i</i>2</sub>, …};</p>
                </div>
                <div class="p1">
                    <p id="275">③ 若集合<i>u</i><sub><i>i</i>.</sub>为空, 则该任务点无法被覆盖;若|<i>u</i><sub><i>i</i>.</sub>|≥1, 则在该集合中选择离任务距离最近的参与者<i>u</i><sub><i>i</i></sub>覆盖该任务点;</p>
                </div>
                <div class="p1">
                    <p id="276">④ 在任务集合<i>T</i>中剔除<i>t</i><sub><i>i</i></sub>, 在参与者集合<i>C</i>中剔除<i>u</i><sub><i>i</i></sub>对应的<i>c</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="277">⑤ 在剩余任务集合中随机选取任务<i>t</i><sub><i>i</i>+1</sub>;</p>
                </div>
                <div class="p1">
                    <p id="278">⑥ 循环执行②～⑤步, 直至所有任务执行完;</p>
                </div>
                <div class="p1">
                    <p id="279">⑦ 输出能被覆盖的所有任务点<i>t</i><sub><i>i</i></sub>以及相应的参与者<i>u</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="280">⑧ 结束.</p>
                </div>
                <h4 class="anchor-tag" id="281" name="281">3.2.2 P-centric任务分配算法</h4>
                <div class="p1">
                    <p id="282">P-centric是以人为中心的任务选择方法.首先在候选参与者集合<i>C</i>中随机选择1个参与者, 然后从任务集合<i>T</i>中选择出该参与者能在一定时间约束内到达的任务集合.若该任务集合为空, 则表明该参与者没有能力完成任何一个任务;若不为空, 则存在能够完成的任务, 进一步在该任务集合中选出与参与者距离最短的任务, 形成1个参与者与任务点的最佳匹配.在原任务集合以及候选参与者集合中剔除掉已经形成匹配的参与者和任务, 接着对下一个参与者进行任务选择, 以此类推, 按照该方法, 直到对于参与者集合中的每一个人都找到最佳的任务点, 详见算法3.</p>
                </div>
                <div class="p1">
                    <p id="283"><b>算法3</b>. P-centric.</p>
                </div>
                <div class="p1">
                    <p id="284">输入:任务集合<i>T</i>、候选参与者集合<i>C</i>;</p>
                </div>
                <div class="p1">
                    <p id="285">输出:能被覆盖的任务点集合<i>t</i>以及相应的参与者集合<i>c</i>.</p>
                </div>
                <div class="p1">
                    <p id="286">① 随机选取候选参与者集合<i>C</i>中的1个<i>c</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="287">② 选择参与者<i>c</i><sub><i>i</i></sub>能在<mathml id="288"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mfrac><mi>g</mi><mrow><mi>V</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></math></mathml> (单位min) 内到达的任务集合<i>t</i><sub><i>i</i>.</sub>={<i>t</i><sub><i>i</i>1</sub>, <i>t</i><sub><i>i</i>2</sub>, …};</p>
                </div>
                <div class="p1">
                    <p id="289">③ 若集合<i>t</i><sub><i>i</i>.</sub>为空, 则该用户无法覆盖任何任务点;若|<i>t</i><sub><i>i</i>.</sub>|≥1, 则在该集合中选择离参与者距离最近的任务点<i>t</i><sub><i>i</i></sub>去完成;</p>
                </div>
                <div class="p1">
                    <p id="290">④ 在候选参与者集合中剔除<i>c</i><sub><i>i</i></sub>, 在任务集合<i>T</i>中剔除<i>t</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="291">⑤ 在剩余的候选参与者集合中随机选取参与者<i>c</i><sub><i>i</i>+1</sub>;</p>
                </div>
                <div class="p1">
                    <p id="292">⑥ 循环执行②～⑤步, 直至所有任务执行完;</p>
                </div>
                <div class="p1">
                    <p id="293">⑦ 输出能被覆盖的所有任务点<i>t</i><sub><i>i</i></sub>以及相应的参与者<i>c</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="294">⑧ 结束.</p>
                </div>
                <h3 id="295" name="295" class="anchor-tag"><b>4</b><b>实验评估</b></h3>
                <div class="p1">
                    <p id="296">本文提出的基于群智的多人协作拍照方式实现对移动目标的实时跟踪, 旨在保证准确实时地对目标进行跟踪的同时尽可能地减少用户激励的成本.为了实现这个目标, 提出了预测目标移动模型的方法MPRE和任务分配的方法T-centric和P-centric.本节分别对每一个方法进行实验验证.</p>
                </div>
                <h4 class="anchor-tag" id="297" name="297"><b>4.1</b><b>MPRE方法评估</b></h4>
                <div class="p1">
                    <p id="298">为了验证MPRE方法的精度, 本文对成都市的出租车轨迹数据进行了分析.表1展示了实验数据集的基本统计信息.本文选取了1个月内成都市二环内13 605辆出租车从6点到23点的GPS点序列.原始数据中包含车辆ID、经纬度、载客状态 (1表示载客, 0表示空车) 以及时间戳信息.根据原始轨迹数据中车辆载客状态的变化, 将每辆车1天内连续的GPS点分割为多条轨迹.当车辆状态由0变为1则表明一条轨迹的开始, 车辆状态由1变为0则表明这条轨迹结束.将城市区域分为大小为<i>g</i>×<i>g</i> (单位m<sup>2</sup>) 的单元格, 对每一条原始车辆轨迹进行网格化, 总共有大约4 010 960条轨迹, 其中10<sup>4</sup>条轨迹用于测试集, 其余用做组建训练集.从训练集中学习出各个位置状态间的转移矩阵<b><i>P</i></b>.1条测试轨迹<i>G</i><sub><i>i</i></sub>={<i>n</i><sub>1</sub>, <i>n</i><sub>2</sub>, …}总共有|<i>G</i><sub><i>i</i></sub>|个位置状态, 对于除了最后一个位置状态外的每一个<i>n</i><sub><i>i</i></sub>, 从转移矩阵中得到概率最高的位置即为MPRE预测的下一位置.对于这条测试轨迹, 预测正确的位置状态数量<i>m</i><sub><i>i</i></sub>占轨迹中|<i>G</i><sub><i>i</i></sub>|-1个位置数量的比率即为MPRE对该条轨迹预测的正确率.所有测试轨迹的正确率求平均得到MPRE预测的正确率<i>Acc</i>为</p>
                </div>
                <div class="p1">
                    <p id="299"><mathml id="300"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mn>0</mn><msup><mrow></mrow><mn>4</mn></msup></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>1</mn><mn>0</mn><msup><mrow></mrow><mn>4</mn></msup></mrow></munderover><mrow><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mstyle></mrow></math></mathml>. (6) </p>
                </div>
                <div class="area_img" id="301">
                    <p class="img_tit"><b>表1</b><b>成都市出租车轨迹实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1</b><b>Taxi Trajectory Dataset in Chengdu</b></p>
                    <p class="img_note"></p>
                    <table id="301" border="1"><tr><td><br />Area</td><td>Period/month</td><td>Time</td><td>Number of Vehicles</td><td>Size of Dataset/GB</td><td>Number of Trajectories</td></tr><tr><td><br />10 km×10 km</td><td>1</td><td>6:00—23:00</td><td>13 605</td><td>15</td><td>4 010 960</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="302">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_302.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 MPRE结果" src="Detail/GetImg?filename=images/JFYZ201902009_302.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 MPRE结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_302.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The result of MPRE</p>

                </div>
                <div class="p1">
                    <p id="303">图5展示了不同测试集、不同网格步长情况下的实验结果.由于大量的训练集更能反映整体数据的规律, 在同一网格粒度下, 训练集数量越多, 可能MPRE的准确率越高.本文首先设置了4个不同大小的训练集.训练集1中有10<sup>6</sup>条轨迹数据, 训练集2有2×10<sup>6</sup>条, 训练集3有3×10<sup>6</sup>条, 训练集4中有4×10<sup>6</sup>条轨迹数据.在同一训练集下, 改变网格粒度, 对10<sup>4</sup>条轨迹数据进行测试.一方面, 1个粗的网格粒度 (例如<i>g</i>=500 m) , 由于每个网格覆盖的面积较大, 可能会使预测精度降低.另一方面, 由于覆盖面积大, 训练数据中更多的原始GPS轨迹点会落入相同的网格区域, 匹配到的轨迹数目可能更高, 从而提高MPRE的准确率.因此, 需要找到一个平衡的网格粒度使得MPRE的准确率达到最佳.图5中的实验结果表明, 随着数据量的增加, MPRE的准确率越来越高.在训练集4中, 网格粒度在<i>g</i>=200 m和<i>g</i>=400 m下表现出较高的预测准确率, 能达到70%左右.对比MPRE算法在2种粒度下的运行时间, 越细粒度的网格, 网格数量越多, 算法的时间复杂度越高.因此, 综合考虑下本文选择<i>g</i>=400 m的网格粒度, 以下的实验如果没有特别说均在<i>g</i>=400 m的网格粒度下进行.</p>
                </div>
                <h4 class="anchor-tag" id="304" name="304"><b>4.2</b><b>任务分配的方法评估</b></h4>
                <div class="p1">
                    <p id="305">通过预测车辆移动模块中的MPRE方法确定出目标下一步移动的位置范围, 在该区域内预先安排参与者.在进行任务分配之前, 首先, 确定区域内的任务位置.本文从OpenStreetMap中得到成都市路网数据, 将路网数据中的节点作为一条路上的任务点.其次, 确定用户位置.本文有成都市出租车的载客状态数据, 考虑到出租车由载客状态1转变为空车状态0则表明该位置有乘客下车, 即可以认为该位置有用户.因此, 本文使用出租车载客状态发生变化时的位置作为候选参与者的位置.本文提出了T-centric和P-centric方法以在网格内进行参与者和任务点的优选.T-centric是以任务为中心进行参与者选择, 而P-centric是以人为中心进行任务的选择.2种方法的解决思路不同, 选出的参与者与任务的最佳匹配也不同, 因此需要通过实验验证2种方法的性能.为了降低CrowdTracker平台的用户激励成本, 在任务分配中要求参与者能在一定时间约束内到达指定任务点的同时所移动的距离最短.因此对比2种方法所选出的参与者的平均移动距离.在任务个数以及参与者人数一定的情况下, 选出的参与者与任务的最佳匹配数量越多, 说明能够完成的任务越多.因此, 另一个需要对比的指标是任务的覆盖率.最后针对该问题选择出性能较好的算法.</p>
                </div>
                <div class="p1">
                    <p id="306">以下的实验均在400 m×400 m的网格粒度下进行 (<i>g</i>=400 m) .由于该实验主要研究不同地点的任务对参与者选择的影响, 所以希望保持每个参与者完成任务的移动方式相同, 即本文认为参与者都是通过步行的方式完成任务, 每个参与者移动的速度为60 m/min即<i>V</i><sub><i>u</i></sub>=60 m/min, 车辆移动的平均速度是30 km/h即<i>V</i><sub><i>c</i></sub>=500 m/min, 则参与者要在<mathml id="307"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mfrac><mi>g</mi><mrow><mi>V</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></math></mathml> (单位min) 的时间约束内能到达任务地点, 即参与者与任务的距离约束在48 m以内.考虑到实验的准确性, 以下的实验数据都是通过多次实验平均而来.</p>
                </div>
                <div class="p1">
                    <p id="308">在任务分配问题中, 有2个因素对分配结果影响较大.一个是任务个数, 另一个是候选者人数.由于路网中节点的数量和位置是一定的, 也就是说任务的个数以及任务地点是一定的, 因此本次实验主要研究不同候选参与者人数下的2种算法的性能.将成都市二环内10 km×10 km范围 (625个网格) 的1 017个路网节点作为任务地点.保持其他因素不变, 将完成任务的时间设为10:00—10:10, 对于这625个网格中的每一个网格, 以该段时间出现在区域内的用户为候选者, 所有网格总共有40 700个候选者.改变候选者人数的总量, 在每一个网格区域内进行任务分配, 最终对每个网格得到一系列参与者与任务地点的最佳匹配.每个网格内任务的覆盖率定义为形成最佳匹配的任务点的个数与该网格所有任务点数量的比值, 对所有网格的任务完成率求均值得到平均任务完成率.对所有参与者完成任务所移动的距离<i>D</i><sub><i>T</i></sub>求均值得到平均移动距离, 平均移动距离越小, CrowdTracker平台用户激励成本越小.</p>
                </div>
                <div class="area_img" id="309">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_309.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 候选参与者人数与平均任务覆盖率的关系" src="Detail/GetImg?filename=images/JFYZ201902009_309.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 候选参与者人数与平均任务覆盖率的关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_309.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Average task coverage</p>

                </div>
                <div class="p1">
                    <p id="310">图6展示了候选参与者人数与平均任务覆盖率的关系.实验结果表明, 随着候选参与者人数的增加, T-centric和P-centric的平均任务覆盖率均呈现增长趋势.该结果说明了群智任务中的一个典型问题, 在一定程度上, 参与者人数的多少决定了群智任务的完成率.对比2种算法的结果, 同等参与者人数下, P-centric比T-centric的任务覆盖率相对较高, 但差别不是很大.图7展示了算法对参与者平均移动距离的影响, 明显看出, 同等参与者人数下, P-centric比T-centric的平均移动距离大.本文研究的问题中, 候选参与者的人数比任务的数量多, P-centric是以人为中心去选择在时间约束内且距离最近的任务, 对于参与者来说选出的任务是距离其最近的, 但是对于任务来说选出的参与者不一定是最近的, 因此, P-centric的移动距离较大.但是在算法运行时间上如图8所示, 同样的原因, 由于候选参与者的人数比任务的数量要多, T-centric在以任务为中心选择参与者时需要计算的参与者数据量大, 计算时间长.因此, 针对本文的问题, 为了更好地反映算法的性能, 以参与者平均移动距离与计算时间的乘积大小作为衡量算法性能的指标, 乘积越小, 算法性能越好.如图9所示, P-centric比T-centric的平均乘积小, P-centric以人为中心的方法更适合本文的任务分配问题.</p>
                </div>
                <div class="area_img" id="311">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_311.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 算法对参与者平均移动距离的影响" src="Detail/GetImg?filename=images/JFYZ201902009_311.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 算法对参与者平均移动距离的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_311.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Average traveled distance</p>

                </div>
                <div class="area_img" id="312">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_312.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 算法运行时间对比" src="Detail/GetImg?filename=images/JFYZ201902009_312.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 算法运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_312.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Running time</p>

                </div>
                <div class="area_img" id="314">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902009_314.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 算法参与者平均移动距离与计算时间的乘积对比" src="Detail/GetImg?filename=images/JFYZ201902009_314.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 算法参与者平均移动距离与计算时间的乘积对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902009_314.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 The product of average distance traveled  and running time</p>

                </div>
                <h3 id="315" name="315" class="anchor-tag"><b>5</b><b>总结与展望</b></h3>
                <div class="p1">
                    <p id="316">本文主要研究了基于移动群智感知的目标跟踪, 提出了一种新的解决方案CrowdTracker:通过基于群智的多人协作拍照方式实现对移动目标的实时跟踪.CrowdTracker在保证准确实时地对目标进行跟踪的同时尽可能地减少用户激励的成本.为了实现这个目标, 本文提出了预测目标移动模型的方法MPRE和任务分配的方法T-centric, P-centric.T-centric是以任务为中心的参与者选择方法, 而P-centric是以人为中心的任务选择方法.MPRE首先通过分析大量的车辆历史轨迹建立城市里车辆位置的移动模型, 进而预测移动目标下一步的位置范围, 在该位置范围内通过T-centric或P-centric方法进行跟踪任务分配.最后, 通过大规模的真实数据集对3种算法进行实验评估, 综合考虑实验结果, MPRE在<i>g</i>=400 m的网格粒度下能保证预测准确率较高且算法运行时间较短, 因此本文选择在<i>g</i>=400 m的网格粒度下分配跟踪任务.结果表明以人为中心的任务选择方法P-centric更适合本文提出的跟踪任务分配问题, 保证任务覆盖率的同时用户激励成本较小且算法的运行时间更短, 能有效地实现目标实时跟踪.</p>
                </div>
                <div class="p1">
                    <p id="317">未来的工作主要包括2方面:1) 考虑基于固定部署摄像头与基于移动群智感知的目标跟踪方法相结合, 更好地利用城市中现有的资源, 降低目标跟踪的成本;2) 要结合图像处理方法来辅助用户快速定位目标, 降低用户参与负担.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="350">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic node collaboration for mobile target tracking in wireless camera sensor networks">

                                <b>[1]</b>Liu Liang, Zhang Xi, Ma Huadong.Dynamic node collaboration for mobile target tracking in wireless camera sensor networks[C]Proc of the 28th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2009:1188-1196
                            </a>
                        </p>
                        <p id="352">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Utility-based dynamic camera assignment and hand-off in a video network">

                                <b>[2]</b>Li Yiming, Bhanu B.Utility-based dynamic camera assignment and hand-off in a video network[C]Proc of the2nd ACM/IEEE Int Conf on Distributed Smart Cameras.Piscataway, NJ:IEEE, 2008:1-9
                            </a>
                        </p>
                        <p id="354">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=From participatory sensing to mobile crowd sensing">

                                <b>[3]</b>Guo Bin, Yu Zhiwen, Zhou Xingshe, et al.From participatory sensing to mobile crowd sensing[C]Proc of the 12th IEEE Int Conf on Pervasive Computing and Communications Workshops.Piscataway, NJ:IEEE, 2014:593-598
                            </a>
                        </p>
                        <p id="356">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Participatory Sensing:A Citizen-Powered Approach to Illuminating the Patterns that Shape our World">

                                <b>[4]</b>Goldman J, Shilton K, Burke J, et al.Participatory sensing:A citizen-powered approach to illuminating the patterns that shape our world[J].Ethics in Science&amp;Engineering National Clearinghouse, 2009, 4 (2) :117-134
                            </a>
                        </p>
                        <p id="358">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500408081&amp;v=MzA5NTVGWU9zSERIUTRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbHdjYWhNPU5pZk9mYks5SDlQT3FvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Merlino G, Arkoulis S, Distefano S, et al.Mobile crowdsensing as a service:A platform for applications on top of sensing clouds[J].Future Generation Computer Systems, 2016, 56 (2) :623-639
                            </a>
                        </p>
                        <p id="360">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Multi-object Motion-tracking Method for Video Surveillance">

                                <b>[6]</b>Dan Jiang, Yuan Yu.A multi-object motion-tracking method for video surveillance[C]Proc of the 8th Acis Int Conf on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing.Piscataway, NJ:IEEE, 2007:402-405
                            </a>
                        </p>
                        <p id="362">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probabilistic object tracking using multiple features">

                                <b>[7]</b>Serby D, Kollermeier E, Gool L V.Probabilistic object tracking using multiple features[C]Proc of the 17th Int Conf on Pattern Recognition.Piscataway, NJ:IEEE, 2004:184-187
                            </a>
                        </p>
                        <p id="364">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700122627&amp;v=MDE3NDRUTW53WmVadUh5am1VYjdJSmx3Y2FoTT1OaWZPZmJLOEg5RE1xSTlGWmVrTkNuNCtvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Wang Yong, Wang Dianhong, Fang Wu.Automatic node selection and target tracking in wireless camera sensor networks[J].Computers&amp;Electrical Engineering, 2014, 40 (2) :484-493
                            </a>
                        </p>
                        <p id="366">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Creek watch:Pairing usefulness and usability for successful citizen science">

                                <b>[9]</b>Kim S, Robson C, Zimmerman T, et al.Creek watch:Pairing usefulness and usability for successful citizen science[C]Proc of the 19th Special Interest Group on ComputerHuman Interaction Conf on Human Factors in Computing Systems.New York:ACM, 2011:2125-2134
                            </a>
                        </p>
                        <p id="368">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PhotoNet:A similarity-aware picture delivery service for situation awareness">

                                <b>[10]</b>Uddin M Y S, Wang Hongyan, Saremi F, et al.PhotoNet:A similarity-aware picture delivery service for situation awareness[C]Proc of the 32nd Real-Time Systems Symp.Piscataway, NJ:IEEE, 2011:317-326
                            </a>
                        </p>
                        <p id="370">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Toward real-time and cooperative mobile visual sensing and sharing">

                                <b>[11]</b>Chen Huihui, Guo Bin, Yu Zhiwen, et al.Toward real-time and cooperative mobile visual sensing and sharing[C]Proc of the 35th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2016:1-9
                            </a>
                        </p>
                        <p id="372">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SmartEye:Real-time and efficient cloud image sharing for disaster environments">

                                <b>[12]</b>Hua Yu, He Wenbo, Liu Xue, et al.SmartEye:Real-time and efficient cloud image sharing for disaster environments[C]Proc of the 34th IEEE Int Conf on Computer Communications.Piscataway, NJ:IEEE, 2015:1616-1624
                            </a>
                        </p>
                        <p id="374">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DESTPRE:A datadriven approach to destination prediction for taxi rides">

                                <b>[13]</b>Xu Mengwen, Wang Dong, Li Jian.DESTPRE:A datadriven approach to destination prediction for taxi rides[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:729-739
                            </a>
                        </p>
                        <p id="376">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Destination prediction by sub-trajectory synthesis and privacy protection against such prediction">

                                <b>[14]</b>Xue A Y, Zhang Rui, Zheng Yu, et al.Destination prediction by sub-trajectory synthesis and privacy protection against such prediction[C]Proc of the 28th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2013:254-265
                            </a>
                        </p>
                        <p id="378">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Next place prediction using mobility Markov chains">

                                <b>[15]</b>Gambs S, Killijian M O, Cortez M N D P.Next place prediction using mobility Markov chains[C]Proc of the 1st Workshop on Measurement, Privacy, and Mobility.New York:ACM, 2012:3
                            </a>
                        </p>
                        <p id="380">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Group Nearest Neighbor Queries">

                                <b>[16]</b>Papadias D, Shen Qiongmao, Tao Yufei, et al.Group nearest neighbor queries[C]Proc of the 19th Int Conf on Data Engineering.Piscataway, NJ:IEEE, 2004:301-312
                            </a>
                        </p>
                        <p id="382">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recruitment framework for participatory sensing data collections">

                                <b>[17]</b>Reddy S, Estrin D, Srivastava M.Recruitment framework for participatory sensing data collections[C]Proc of the 8th Int Conf on Pervasive Computing.New York:ACM, 2010:138-155
                            </a>
                        </p>
                        <p id="384">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fostering Participaction in Smart Cities:a geo-social crowdsensing platform">

                                <b>[18]</b>Cardone G, Foschini L, Bellavista P, et al.Fostering participaction in smart cities:A geo-social crowdsensing platform[J].IEEE Communications Magazine, 2013, 51 (6) :112-119
                            </a>
                        </p>
                        <p id="386">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Team formation for generalized tasks in expertise social networks">

                                <b>[19]</b>Li Chengte, Shan M K.Team formation for generalized tasks in expertise social networks[C]Proc of the 2nd IEEE Int Conf on Social Computing.Piscataway, NJ:IEEE, 2010:9-16
                            </a>
                        </p>
                        <p id="388">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Task Me:multitask allocation in mobile crowd sensing">

                                <b>[20]</b>Liu Yan, Guo Bin, Wang Yang, et al.TaskMe:Multi-task allocation in mobile crowd sensing[C]Proc of the 28th ACM Int Joint Conf on Pervasive and Ubiquitous Computing.New York:ACM, 2016:403-414
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201902009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902009&amp;v=MTI2MTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTduVzcvSkx5dlNkTEc0SDlqTXJZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
